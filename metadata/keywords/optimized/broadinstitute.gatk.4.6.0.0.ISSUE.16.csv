quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Security,"0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1541,Validat,ValidateVariants,1541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,000195.1 (182896 bp); 23:38:14.600 DEBUG GenomeLocParser - GL000212.1 (186858 bp); 23:38:14.600 DEBUG GenomeLocParser - GL000222.1 (186861 bp); 23:38:14.601 DEBUG GenomeLocParser - GL000200.1 (187035 bp); 23:38:14.601 DEBUG GenomeLocParser - GL000193.1 (189789 bp); 23:38:14.601 DEBUG GenomeLocParser - GL000194.1 (191469 bp); 23:38:14.601 DEBUG GenomeLocParser - GL000225.1 (211173 bp); 23:38:14.601 DEBUG GenomeLocParser - GL000192.1 (547496 bp); 23:38:14.601 DEBUG GenomeLocParser - NC_007605 (171823 bp); 23:38:14.601 DEBUG GenomeLocParser - hs37d5 (35477943 bp); 23:38:15.218 INFO IntervalArgumentCollection - Processing 13461 bp from intervals; 23:38:15.222 INFO GermlineCNVCaller - No annotated intervals were provided...; 23:38:15.222 INFO GermlineCNVCaller - No GC-content annotations for intervals found; explicit GC-bias correction will not be performed...; 23:38:15.235 INFO GermlineCNVCaller - Running the tool in the COHORT mode...; 23:38:15.236 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 23:38:15.237 INFO GermlineCNVCaller - Aggregating read-count file /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/inputs/371827342/P0000335.b37.counts.hdf5 (1 / 5); 23:38:15.653 INFO GermlineCNVCaller - Aggregating read-count file /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/inputs/-1425124017/P0000480.b37.counts.hdf5 (2 / 5); 23:38:15.905 INFO GermlineCNVCaller - Aggregating read-count file /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/inputs/1072891920/P0000481.b37.counts.hdf5 (3 / 5); 23:38:16.174 INFO GermlineCNVCaller - Aggregating read-count file /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:11805,Validat,Validating,11805,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['Validat'],['Validating']
Security,"04_random, chr17_gl000205_random, chr17_gl000206_random, chr18_gl000207_random, chr19_gl000208_random, chr19_gl000209_random, chr21_gl000210_random, chrUn_gl000211, chrUn_gl000212, chrUn_gl000213, chrUn_gl000214, chrUn_gl000215, chrUn_gl000216, chrUn_gl000217, chrUn_gl000218, chrUn_gl000219, chrUn_gl000220, chrUn_gl000221, chrUn_gl000222, chrUn_gl000223, chrUn_gl000224, chrUn_gl000225, chrUn_gl000226, chrUn_gl000227, chrUn_gl000228, chrUn_gl000229, chrUn_gl000230, chrUn_gl000231, chrUn_gl000232, chrUn_gl000233, chrUn_gl000234, chrUn_gl000235, chrUn_gl000236, chrUn_gl000237, chrUn_gl000238, chrUn_gl000239, chrUn_gl000240, chrUn_gl000241, chrUn_gl000242, chrUn_gl000243, chrUn_gl000244, chrUn_gl000245, chrUn_gl000246, chrUn_gl000247, chrUn_gl000248, chrUn_gl000249]; reads contigs = []; 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:163); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.validateToolInputs(GATKSparkTool.java:469); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:361); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccess",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:34739,validat,validateDictionaries,34739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['validat'],['validateDictionaries']
Security,05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradleLauncher.java:151); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.Factories$1.create(Factories.java:22); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.971 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:148); 22:05:55.972 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:112); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:106); 22:05:55.973 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:63); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106); 22:05:55.976 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:5150,access,access,5150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,1,['access'],['access']
Security,"0:00.685 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:00:00.685 INFO PostprocessGermlineCNVCalls - Deflater: IntelDeflater; 17:00:00.685 INFO PostprocessGermlineCNVCalls - Inflater: IntelInflater; 17:00:00.685 INFO PostprocessGermlineCNVCalls - GCS max retries/reopens: 20; 17:00:00.685 INFO PostprocessGermlineCNVCalls - Requester pays: disabled; 17:00:00.685 INFO PostprocessGermlineCNVCalls - Initializing engine; 17:00:04.480 INFO PostprocessGermlineCNVCalls - Done initializing engine; 17:00:07.582 INFO PostprocessGermlineCNVCalls - Shutting down engine; [October 29, 2020 5:00:07 PM MSK] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2468347904; java.lang.IllegalArgumentException: Records were not strictly sorted in dictionary order.; 	at org.broadinstitute.hellbender.tools.copynumber.arguments.CopyNumberArgumentValidationUtils.validateIntervals(CopyNumberArgumentValidationUtils.java:60); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.AbstractLocatableCollection.getShardedCollectionSortOrder(AbstractLocatableCollection.java:142); 	at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.onTraversalStart(PostprocessGermlineCNVCalls.java:297); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /home/lmbs02/bio/biosoft/gatk/gatk-4.1.9.0/gat",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-718787427:2939,validat,validateIntervals,2939,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-718787427,1,['validat'],['validateIntervals']
Security,"0:05:57.036 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr16:10185 the annotation AS_VarDP=59|115|0 was not a numerical value and was ignored; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Reducible annotation 'AS_VarDP' detected, add -G StandardAnnotation -G AS_StandardAnnotation to the command to annotate in the final VC with this annotation.; 00:07:26.991 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.02938786500000001,Cpu time(s),0.029037034000000003; [August 25, 2021 12:07:27 AM EDT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.55 minutes.; Runtime.totalMemory()=1807745024; java.lang.NullPointerException; at java.util.HashMap.putMapEntries(HashMap.java:500); at java.util.HashMap.putAll(HashMap.java:784); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:211); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:281); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.uti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:8102,Hash,HashMap,8102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['Hash'],['HashMap']
Security,"0; 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 01:13:16.078 INFO HaplotypeCaller - Initializing engine; 01:13:17.087 INFO HaplotypeCaller - Shutting down engine; [January 18, 2020 1:13:17 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2216689664; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:621); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:563); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:160); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275). I have tried with different versions of Java, still it persists.; Please suggest any solution.; Thank you.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6384:2788,validat,validateDictionaries,2788,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6384,2,['validat'],"['validateDictionaries', 'validateSequenceDictionaries']"
Security,0> (ø)` | :arrow_down: |; | [...tools/funcotator/dataSources/TableFuncotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL1RhYmxlRnVuY290YXRpb24uamF2YQ==) | `60% <100%> (ø)` | `20 <0> (ø)` | :arrow_down: |; | [.../tools/copynumber/utils/MergeAnnotatedRegions.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9ucy5qYXZh) | `100% <100%> (ø)` | `3 <3> (?)` | |; | [...ils/annotatedinterval/AnnotatedIntervalHeader.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL2Fubm90YXRlZGludGVydmFsL0Fubm90YXRlZEludGVydmFsSGVhZGVyLmphdmE=) | `100% <100%> (ø)` | `6 <6> (?)` | |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `85.965% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...nder/tools/copynumber/utils/TagGermlineEvents.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL1RhZ0dlcm1saW5lRXZlbnRzLmphdmE=) | `100% <100%> (ø)` | `3 <3> (?)` | |; | [...ataSources/xsv/LocatableXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `85.185% <61.538%> (+0.491%)` | `24 <0> (-4)` | :arrow_down: |; | [...g/broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-361355746:2779,Validat,ValidateBasicSomaticShortMutations,2779,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-361355746,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,"100 KB.; 20:38:27.207 INFO StructuralVariationDiscoveryPipelineSpark - Processing 501267 raw alignments from 426041 contigs.; 18/01/12 20:38:27 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2518 KB). The maximum recommended task size is 100 KB.; 20:38:35.835 INFO StructuralVariationDiscoveryPipelineSpark - Primitive filtering based purely on MQ left 339065 contigs.; 20:38:37.378 INFO StructuralVariationDiscoveryPipelineSpark - 17574 contigs with chimeric alignments potentially giving SV signals.; 18/01/12 20:38:37 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 284.0 in stage 25.0 (TID 43189, cw-test-w-6.c.broad-dsde-methods.internal, executor 7): java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:3305,validat,validateArg,3305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['validat'],['validateArg']
Security,"11:26:21.683 INFO Concordance - Deflater: IntelDeflater ; ; 11:26:21.684 INFO Concordance - Inflater: IntelInflater ; ; 11:26:21.684 INFO Concordance - GCS max retries/reopens: 20 ; ; 11:26:21.684 INFO Concordance - Requester pays: disabled ; ; 11:26:21.684 INFO Concordance - Initializing engine ; ; 11:26:22.217 INFO FeatureManager - Using codec VCFCodec to read file file:///scicore/home/cichon/GROUP/memory\_optimization/variants/filtered/NA12878.vcf.gz ; ; 11:26:22.497 INFO FeatureManager - Using codec VCFCodec to read file file:///scicore/home/cichon/GROUP/memory\_optimization/variants/filtered/sample1\_affect.filtered.vcf ; ; 11:26:22.663 INFO Concordance - Done initializing engine ; ; 11:26:22.672 INFO ProgressMeter - Starting traversal ; ; 11:26:22.672 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute ; ; 11:26:22.682 INFO Concordance - Shutting down engine ; ; \[November 11, 2021 11:26:22 AM CET\] org.broadinstitute.hellbender.tools.walkers.validation.Concordance done. Elapsed time: 0.02 minutes. ; ; Runtime.totalMemory()=559939584 ; ; java.lang.NullPointerException ; ; at htsjdk.variant.variantcontext.VariantContextComparator.compare(VariantContextComparator.java:87) ; ; at org.broadinstitute.hellbender.engine.AbstractConcordanceWalker$ConcordanceIterator.next(AbstractConcordanceWalker.java:192) ; ; at org.broadinstitute.hellbender.engine.AbstractConcordanceWalker$ConcordanceIterator.next(AbstractConcordanceWalker.java:174) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) ; ; at org.broadinstitute.hellbender.engine.AbstractConcordanceWalker.traverse(AbstractConcordanceWalker.java:132) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7562:4391,validat,validation,4391,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7562,1,['validat'],['validation']
Security,"12 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per container); 17/10/11 14:19:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/11 14:19:12 INFO yarn.Client: Setting up container launch context for our AM; 17/10/11 14:19:12 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/11 14:19:12 INFO yarn.Client: Preparing resources for our AM container; 17/10/11 14:19:12 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Client: Submitting application 6 to ResourceManager; 17/10/11 14:19:13 INFO impl.YarnClientImpl: Submitted application application_1507683879816_0006; 17/10/11 14:19:14 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:14 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:15 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:15 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster reg",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:6228,Secur,SecurityManager,6228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['Secur'],['SecurityManager']
Security,12892.readnamesort.bam -R hdfs://sn1:8020/user/$USER/gatk/human_g1k_v37.fasta -O hdfs://sn1:8020/user/$USER/gatk/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -- --sparkRunner SPARK --sparkMaster spark://sn1:7077 --driver-memory 8G --num-executors 4 --executor-cores 9 --executor-memory 27g; ```. ```; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:464); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:458); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.validateToolInputs(GATKSparkTool.java:402); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:312); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:185); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSub,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2020:1127,validat,validateToolInputs,1127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2020,1,['validat'],['validateToolInputs']
Security,"12:11:34.899 INFO PlotACNVResults - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 12:11:34.899 INFO PlotACNVResults - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:11:34.899 INFO PlotACNVResults - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 12:11:34.899 INFO PlotACNVResults - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:11:34.899 INFO PlotACNVResults - Defaults.USE_CRAM_REF_DOWNLOAD : false; 12:11:34.900 INFO PlotACNVResults - Deflater IntelDeflater; 12:11:34.900 INFO PlotACNVResults - Initializing engine; 12:11:34.900 INFO PlotACNVResults - Done initializing engine; 12:11:35.009 INFO PlotACNVResults - Shutting down engine; [February 15, 2017 12:11:35 PM EST] org.broadinstitute.hellbender.tools.exome.plotting.PlotACNVResults done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=1502085120; java.lang.IllegalArgumentException: There must be at least one contig above the threshold length in the sequence dictionary.; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:673); 	at org.broadinstitute.hellbender.tools.exome.plotting.PlotACNVResults.doWork(PlotACNVResults.java:120); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:96); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:116); 	at org.broadinstitute.hellbender.Main.main(Main.java:158); ```. ---. @samuelklee commented on [Wed Feb 22 2017](https://github.com/broadinstitute/gatk-protected/issues/902#issuecomment-281814944). Hmm, perhaps I should not be using `ReferenceUtils.loadFastaDictionary` to load the dictionary, or this method needs to check that the file it is loading is ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2941:2953,validat,validateArg,2953,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2941,1,['validat'],['validateArg']
Security,"14:50:59.205 INFO FilterMutectCalls - Deflater: IntelDeflater; 14:50:59.205 INFO FilterMutectCalls - Inflater: IntelInflater; 14:50:59.205 INFO FilterMutectCalls - GCS max retries/reopens: 20; 14:50:59.205 INFO FilterMutectCalls - Requester pays: disabled; 14:50:59.205 INFO FilterMutectCalls - Initializing engine; 14:51:00.692 INFO FeatureManager - Using codec VCFCodec to read file file:///workdir/mparment/data/process/A2683/PTC2_unfiltered.vcf.gz; 14:51:01.406 INFO FilterMutectCalls - Done initializing engine; 14:51:02.360 INFO FilterMutectCalls - Shutting down engine; [December 12, 2020 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6996:3674,Hash,HashMap,3674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996,1,['Hash'],['HashMap']
Security,"15:18.986 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 03:15:18.987 INFO PostprocessGermlineCNVCalls - Deflater: IntelDeflater; 03:15:18.988 INFO PostprocessGermlineCNVCalls - Inflater: IntelInflater; 03:15:18.988 INFO PostprocessGermlineCNVCalls - GCS max retries/reopens: 20; 03:15:18.989 INFO PostprocessGermlineCNVCalls - Requester pays: disabled; 03:15:18.990 INFO PostprocessGermlineCNVCalls - Initializing engine; 03:15:43.480 INFO PostprocessGermlineCNVCalls - Done initializing engine; 03:15:47.833 INFO PostprocessGermlineCNVCalls - Shutting down engine; [April 15, 2024, 3:15:47 AM CST] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=1207959552; java.lang.IllegalArgumentException: Records were not strictly sorted in dictionary order.; 	at org.broadinstitute.hellbender.tools.copynumber.arguments.CopyNumberArgumentValidationUtils.validateIntervals(CopyNumberArgumentValidationUtils.java:74); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.AbstractLocatableCollection.getShardedCollectionSortOrder(AbstractLocatableCollection.java:142); 	at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.onTraversalStart(PostprocessGermlineCNVCalls.java:388); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1096); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /data/xiangxd/project/software/callers/gatk_4.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8776:21332,validat,validateIntervals,21332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8776,1,['validat'],['validateIntervals']
Security,166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306); 	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162); 	at org.apac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:7102,Hash,HashMap,7102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,"19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:2995,Validat,ValidateVariants,2995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,2,"['Validat', 'validat']","['ValidateVariants', 'validations']"
Security,2); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.apache.hadoop.ipc.Client.call(Client.java:1475); 	at org.apache.hadoop.ipc.Client.call(Client.java:1412); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229); 	at com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:255); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191); 	at org.ap,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:9751,secur,security,9751,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['secur'],['security']
Security,2); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:237); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:488); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:468); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:458); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLinePro,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:3593,secur,security,3593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['secur'],['security']
Security,2); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106); 	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73); 	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1228); 	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1213); 	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1201); 	at org.apache.hadoop.hdfs.DFSInputStream.fe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:6510,secur,security,6510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['secur'],['security']
Security,2); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Failed to read bam header from /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:1930,secur,security,1930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['secur'],['security']
Security,2.936 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 15:47:53.565 INFO ProgressMeter - ENA|LVXK01000001|LVXK01000001.1:19555 0.2 90 508.0; 15:48:05.962 INFO ProgressMeter - ENA|LVXK01000001|LVXK01000001.1:136820 0.4 600 1563.5; 15:48:16.023 INFO ProgressMeter - ENA|LVXK01000001|LVXK01000001.1:360783 0.6 1560 2828.9; 15:48:19.342 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.010346494000000001; 15:48:19.342 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 6.453042841; 15:48:19.347 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 10.39 sec; 15:48:19.348 INFO Mutect2 - Shutting down engine; [28 novembre 2019 15:48:19 CET] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.72 minutes.; Runtime.totalMemory()=3822583808; java.lang.IllegalArgumentException: Cannot construct fragment from more than two reads; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725); 	at org.broadinstitute.hellbender.utils.read.Fragment.create(Fragment.java:36); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:595); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); 	at or,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-559553558:3831,validat,validateArg,3831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-559553558,1,['validat'],['validateArg']
Security,"2833200,787;ReadPosRankSum=0.252	GT:AD:DP:GQ:PL:SB	0/2:411,2,357,0,0:770:99:14840,11462,50871,0,41338,45112,17297,53328,47568,2147483647,16108,52933,46273,64838,62381:201,210,177,182; chr13	32944610	.	T	<NON_REF>	.	.	END=32944794	GT:DP:GQ:MIN_DP:PL	0/0:627:99:265:0,120,1800; ```. #### Steps to reproduce; * init; ```; hg19=pipeline/hg19/hg19_chM_male_mask.fa; ```; * reproduce of 4.0.8.1; ```; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.gvcf -ERC GVCF && tail target.4.0.8.1.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.8.1/gatk-4.0.8.1/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.8.1.vcf && tail target.4.0.8.1.vcf; ```; * reproduce of 4.0.9.0; ```; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.gvcf -ERC GVCF && tail target.4.0.9.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.0.9.0/gatk-4.0.9.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.0.9.0.vcf && tail target.4.0.9.0.vcf; ```; * reproduce of 4.1.2.0; ```; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.gvcf -ERC GVCF && tail target.4.1.2.0.gvcf; github.com/broadinstitute/gatk/releases/download/4.1.2.0/gatk-4.1.2.0/gatk HaplotypeCaller -R $hg19 -I target.1k.bam -L target.bed -O target.4.1.2.0.vcf && tail target.4.1.2.0.vcf; ```. #### Expected behavior; 1. expose the rule that the second variant (T>TAAAA) filtered (especially for version 4.0.9.0).; 2. give the right QUAL of the second variant; 3. then this type of variant can be retain in VCF as default operation or with some addition parameters.; 4. can GATK have ability to detect the `real` variant such as TTT>AAAA. #### Actual behavior; ~~_Tell us what happens instead_~~; unknown",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5975:7132,expose,expose,7132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5975,1,['expose'],['expose']
Security,2:40.673 INFO Funcotator - HTSJDK Version: 2.20.1; 06:42:40.673 INFO Funcotator - Picard Version: 2.20.5; 06:42:40.673 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 06:42:40.673 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 06:42:40.673 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 06:42:40.673 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 06:42:40.673 INFO Funcotator - Deflater: IntelDeflater; 06:42:40.674 INFO Funcotator - Inflater: IntelInflater; 06:42:40.674 INFO Funcotator - GCS max retries/reopens: 20; 06:42:40.674 INFO Funcotator - Requester pays: disabled; 06:42:40.674 INFO Funcotator - Initializing engine; 06:42:41.406 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/GenomicsDBImport/200923_A00268_0517_AHKL37DSXY/Set20-5_L2_159A59.somatic.filterMutectCalls.vcf.gz; 06:42:41.561 INFO Funcotator - Done initializing engine; 06:42:41.561 INFO Funcotator - Validating Sequence Dictionaries...; 06:42:41.589 INFO Funcotator - Processing user transcripts/defaults/overrides...; 06:42:41.590 INFO Funcotator - Initializing data sources...; 06:42:41.594 INFO DataSourceUtils - Initializing data sources from directory: /data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g; 06:42:41.596 INFO DataSourceUtils - Data sources version: 1.7.2020521g; 06:42:41.597 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200521g.tar.gz; 06:42:41.597 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521.tar.gz; 06:42:41.609 INFO DataSourceUtils - Resolved data source file path: file:///data/nws/WES/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///data/nws/WES/reference/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7090:2643,Validat,Validating,2643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7090,1,['Validat'],['Validating']
Security,2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:108); at org.gradle.api.internal.tasks.execution.ResolveBeforeExecutionOutputsTaskExecuter.execute(ResolveBeforeExecutionOutputsTaskExecuter.java:67); at org.gradle.api.internal.tasks.execution.ResolveAfterPreviousExecutionStateTaskExecuter.execute(ResolveAfterPreviousExecutionStateTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:94); at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:95); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57); at org.gradle.api.internal.tasks,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:2077,Validat,ValidatingTaskExecuter,2077,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716,1,['Validat'],['ValidatingTaskExecuter']
Security,2xvdWQuamF2YQ==) | `70.811% <0%> (ø)` | `40 <0> (ø)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/utils/IndexUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbmRleFV0aWxzLmphdmE=) | `80.702% <100%> (ø)` | `16 <2> (ø)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `86.957% <100%> (ø)` | `14 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/SplitIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1NwbGl0SW50ZXJ2YWxzLmphdmE=) | `88.235% <100%> (ø)` | `6 <2> (ø)` | :arrow_down: |; | [...der/tools/walkers/variantutils/SelectVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50cy5qYXZh) | `80.663% <100%> (ø)` | `125 <0> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/engine/FeatureInput.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZUlucHV0LmphdmE=) | `94.203% <100%> (ø)` | `16 <0> (ø)` | :arrow_down: |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `82.857% <66.667%> (ø)` | `34 <0> (ø)` | :arrow_down: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352845785:3650,Validat,ValidateVariants,3650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352845785,1,['Validat'],['ValidateVariants']
Security,"3.793 INFO CreateReadCountPanelOfNormals - ------------------------------------------------------------; 12:33:53.794 INFO CreateReadCountPanelOfNormals - The Genome Analysis Toolkit (GATK) v4.1.0.0; 12:33:53.794 INFO CreateReadCountPanelOfNormals - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Initializing engine; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 19/02/18 12:33:53 INFO SparkContext: Running Spark version 2.2.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar) to method sun.security.krb5.Config.getInstance(); WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:33:54.187 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 12:33:54.263 INFO CreateReadCountPanelOfNormals - Shutting down engine; [February 18, 2019 at 12:33:54 PM CST] org.broadinstitute.hellbender.tools.copynumber.CreateReadCountPanelOfNormals done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2147483648; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at org.apache.spark.SparkConf.validateSettings(SparkConf.scala:546); 	at org.apache.spark.SparkContext.<init>(SparkContext.scala:373); 	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.createSparkContext(SparkContextFactory.java:178)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:1763,authenticat,authentication,1763,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,1,['authenticat'],['authentication']
Security,30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; 18/01/09 18:30:54 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 18/01/09 18:30:54 INFO spark.SparkContext: Submitted application: BwaAndMarkDuplicatesPipelineSpark; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'sparkDriver' on port 38793.; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering MapOutputTracker; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering BlockManagerMaster; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/01/09 18:30:55 INFO storage.DiskBlockManager: Created local directory at /tmp/sun/blockmgr-b03058dc-763a-449c-bd05-18f3304c01ea; 18/01/09 18:30:55 INFO memory.MemoryStore: MemoryStore started with capacity 2004.6 MB; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering OutputCommitCoordinator; 18/01/09 18:30:55 INFO util.log: Logging initialized @25356ms; 18/01/09 18:30:55 INFO server.Server: jetty-9.3.z-SNAPSHOT; 18/01/09 ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:5677,Secur,SecurityManager,5677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,3,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,32 INFO FeatureManager - Using codec IntervalListCodec to read file file:///gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/scatter/scatter_30.interval_list; 23:44:42.739 DEBUG FeatureDataSource - Cache statistics for FeatureInput /gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/scatter/scatter_30.interval_list:/gpfs/hpc/home/lijc/xiangxud/project/test/NGS_WES_test/4_tools_vcf/gatk4/info/scatter/scatter_30.interval_list:; 23:44:42.740 DEBUG FeatureCache - Cache hit rate was 0.00% (0 out of 0 total queries); 23:44:42.743 INFO IntervalArgumentCollection - Processing 1022379 bp from intervals; 23:44:42.756 INFO GermlineCNVCaller - Reading and validating annotated intervals...; 23:44:43.119 INFO GermlineCNVCaller - GC-content annotations for intervals found; explicit GC-bias correction will be performed...; 23:44:43.160 INFO GermlineCNVCaller - Running the tool in COHORT mode...; 23:44:43.160 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 23:44:43.160 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 23:44:43.160 DEBUG GenomeLocParser - chr1 (248956422 bp); 23:44:43.161 DEBUG GenomeLocParser - chr2 (242193529 bp); 23:44:43.161 DEBUG GenomeLocParser - chr3 (198295559 bp); 23:44:43.161 DEBUG GenomeLocParser - chr4 (190214555 bp); 23:44:43.161 DEBUG GenomeLocParser - chr5 (181538259 bp); 23:44:43.161 DEBUG GenomeLocParser - chr6 (170805979 bp); 23:44:43.161 DEBUG GenomeLocParser - chr7 (159345973 bp); 23:44:43.161 DEBUG GenomeLocParser - chr8 (145138636 bp); 23:44:43.161 DEBUG GenomeLocParser - chr9 (138394717 bp); 23:44:43.161 DEBUG GenomeLocParser - chr10 (133797422 bp); 23:44:43.161 DEBUG GenomeLocParser - chr11 (135086622 bp); 23:44:43.161 DEBUG GenomeLocParser - chr12 (133275309 bp); 23:44:43.161 DEBUG GenomeLocParser - chr13 (114364328 bp); 23:44:43.161 DEBUG GenomeLocParser - chr14 (107043718 bp); 23:44:43.161 DEBUG GenomeLocParser - chr15 (1019911,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8938:20244,Validat,Validating,20244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8938,1,['Validat'],['Validating']
Security,321 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:54:55.321 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:54:55.321 INFO PathSeqPipelineSpark - Initializing engine; 17:54:55.321 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:54:55 INFO SparkContext: Running Spark version 2.2.0; 18/04/24 17:54:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/04/24 17:54:56 INFO SparkContext: Submitted application: PathSeqPipelineSpark; 18/04/24 17:54:56 INFO SecurityManager: Changing view acls to: userx; 18/04/24 17:54:56 INFO SecurityManager: Changing modify acls to: userx; 18/04/24 17:54:56 INFO SecurityManager: Changing view acls groups to:; 18/04/24 17:54:56 INFO SecurityManager: Changing modify acls groups to:; 18/04/24 17:54:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(userx); groups with view permissions: Set(); users with modify permissions: Set(userx); groups with modify permissions: Set(); 18/04/24 17:54:57 INFO Utils: Successfully started service 'sparkDriver' on port 59501.; 18/04/24 17:54:57 INFO SparkEnv: Registering MapOutputTracker; 18/04/24 17:54:57 INFO SparkEnv: Registering BlockManagerMaster; 18/04/24 17:54:57 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/04/24 17:54:57 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/04/24 17:54:57 INFO DiskBlockManager: Created local directory at /tmp/userx/blockmgr-213553f6-dd2d-455d-85ef-3ed03ae12f7f; 18/04/24 17:54:57 INFO MemoryStore: MemoryStore started with capacity 366.3 MB; 18/04/24 17:54:57 INFO SparkEnv: Registering OutputCommitCoordin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:7915,Secur,SecurityManager,7915,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"334:50070; volumes:; - /data0/reference/hg19-ucsc/:/reference/hg19-ucsc/; - /data0/output/:/output/; - /data/ngs/:/ngs/; datanode:; image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8; networks:; - workbench; volumes:; - datanode:/hadoop/dfs/data; environment:; SERVICE_PRECONDITION: ""namenode:50070""; # depends_on:; # - namenode; env_file:; - ./hadoop.env; deploy:; mode: global; restart_policy:; condition: on-failure; labels:; traefik.docker.network: workbench; traefik.port: 50075. volumes:; datanode:; namenode:. networks:; workbench:; external: true; ```; the datanodes and namenode and spark master and workers are all working.; My hardware resources are:; 16 core and 1Tb memory ssd and 56Gb ram for 3 machines. I have this problem when I launch the version(GATK) v4.0.4.0 but not with this version v4.0.2.0-4-gb59d863-SNAPSHOT:. >java.lang.IllegalStateException: Duplicate key -1; 	at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$mark$2142e97f$1(MarkDuplicatesSpark.java:82); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(J",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:3705,Hash,HashMap,3705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['Hash'],['HashMap']
Security,35% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `22.807% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...er/tools/walkers/variantutils/VariantsToTable.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGUuamF2YQ==) | `93.182% <ø> (ø)` | `75 <0> (ø)` | :arrow_down: |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `82.857% <ø> (ø)` | `34 <0> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/tools/GetSampleName.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9HZXRTYW1wbGVOYW1lLmphdmE=) | `62.5% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | ... and [36 more](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4070#issuecomment-355848388:3461,Validat,ValidateVariants,3461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4070#issuecomment-355848388,1,['Validat'],['ValidateVariants']
Security,"3; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Deflater: IntelDeflater; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Inflater: IntelInflater; 13:15:05.204 INFO FuncotatorDataSourceDownloader - GCS max retries/reopens: 20; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Requester pays: disabled; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Initializing engine; 13:15:05.205 INFO FuncotatorDataSourceDownloader - Done initializing engine; 13:15:05.205 INFO FuncotatorDataSourceDownloader - Germline data sources selected.; 13:15:05.207 INFO FuncotatorDataSourceDownloader - Collecting expected checksum...; 13:19:33.264 INFO FuncotatorDataSourceDownloader - Shutting down engine; [November 18, 2023 1:19:33 PM CST] org.broadinstitute.hellbender.tools.funcotator.FuncotatorDataSourceDownloader done. Elapsed time: 4.48 minutes.; Runtime.totalMemory()=1967128576; code: 0; message: All 3 retries failed. Waited a total of 14000 ms between attempts; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: All 3 retries failed. Waited a total of 14000 ms between attempts; 	at com.google.cloud.storage.contrib.nio.CloudStorageRetryHandler.handleRetryForStorageException(CloudStorageRetryHandler.java:135); 	at com.google.cloud.storage.contrib.nio.CloudStorageRetryHandler.handleStorageException(CloudStorageRetryHandler.java:115); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:253); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:2600,checksum,checksum,2600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['checksum'],['checksum']
Security,"4 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:4763,Validat,ValidateBAM,4763,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,4,['Validat'],"['ValidateBAM', 'ValidateBamsWf', 'ValidateSamFile']"
Security,"4 on spark2.0.0, I found they were incompatible. It seems that the interface isn't match. The error log looks like below. Exception in thread ""main"" java.lang.NoSuchMethodError: scala.collection.Seq.aggregate(Ljava/lang/Object;Lscala/Function2;Lscala/Function2;)Ljava/lang/Object;; at org.bdgenomics.adam.models.NonoverlappingRegions.mergeRegions(NonoverlappingRegions.scala:75); at org.bdgenomics.adam.models.NonoverlappingRegions.<init>(NonoverlappingRegions.scala:55); at org.bdgenomics.adam.models.NonoverlappingRegions$.apply(NonoverlappingRegions.scala:169); at org.bdgenomics.adam.util.TwoBitRecord$.apply(TwoBitFile.scala:193); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.bdgenomics.adam.util.TwoBitFile.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:311); at org.broadinstitute.hellbender.engine.spark.SparkCommandLi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:1064,Hash,HashMap,1064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,1,['Hash'],['HashMap']
Security,"45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:2593,Validat,ValidateVariants,2593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"47:51.534 INFO IntelPairHmm - Requested threads: 4; 11:47:51.534 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 11:47:51.557 INFO ProgressMeter - Starting traversal; 11:47:51.557 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 11:47:52.683 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 11:47:52.683 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 11:47:52.683 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.24 sec; 11:47:52.684 INFO Mutect2 - Shutting down engine; [July 2, 2020 11:47:52 AM CEST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2511863808; java.lang.IllegalArgumentException: Read bases and read quality arrays aren't the same size: Bases: 38 vs Base Q's: 38 vs Insert Q's: 146 vs Delete Q's: 146.; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:734); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.createQualityModifiedRead(PairHMMLikelihoodCalculationEngine.java:205); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.modifyReadQualities(PairHMMLikelihoodCalculationEngine.java:268); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:236); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:164); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:246); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:299); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); 	at ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-652912482:5242,validat,validateArg,5242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-652912482,1,['validat'],['validateArg']
Security,"4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:4386,Validat,ValidateBAM,4386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBAM']
Security,"5 INFO BlockManager:54 - BlockManager stopped; 2019-05-14 17:07:05 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-05-14 17:07:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-05-14 17:07:05 INFO SparkContext:54 - Successfully stopped SparkContext; 17:07:05.631 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 14, 2019 5:07:05 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 41.02 minutes.; Runtime.totalMemory()=23321378816; java.lang.IllegalArgumentException: Wrong FS: hdfs://scc:-1/project/casa/gcad/adsp.cc/sv/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.contig-sam-file.sam, expected: hdfs://scc; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105); at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:397); at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:393); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:393); at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:337); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:908); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:889); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:786); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:775); at hdfs.jsr203.HadoopFileSystem.newOutputStream(HadoopFileSystem.java:554); at hdfs.jsr203.HadoopFileSystem.newByteChannel(HadoopFileSystem.java:395); at hdfs.jsr203.HadoopPath.newByteChannel(HadoopPath.java:558); at hdfs.jsr203.HadoopFileSystemProvider.newByteChannel(Hado",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942:1472,access,access,1472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942,1,['access'],['access']
Security,"5 INFO FilterMutectCalls - Deflater: IntelDeflater; 14:50:59.205 INFO FilterMutectCalls - Inflater: IntelInflater; 14:50:59.205 INFO FilterMutectCalls - GCS max retries/reopens: 20; 14:50:59.205 INFO FilterMutectCalls - Requester pays: disabled; 14:50:59.205 INFO FilterMutectCalls - Initializing engine; 14:51:00.692 INFO FeatureManager - Using codec VCFCodec to read file file:///workdir/mparment/data/process/A2683/PTC2_unfiltered.vcf.gz; 14:51:01.406 INFO FilterMutectCalls - Done initializing engine; 14:51:02.360 INFO FilterMutectCalls - Shutting down engine; [December 12, 2020 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFilte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6996:3688,Hash,HashMap,3688,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996,1,['Hash'],['HashMap']
Security,5-70-gdc3237e-SNAPSHOT; 14:19:10.289 INFO PrintReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:19:10.290 INFO PrintReadsSpark - Deflater: IntelDeflater; 14:19:10.290 INFO PrintReadsSpark - Inflater: IntelInflater; 14:19:10.290 INFO PrintReadsSpark - GCS max retries/reopens: 20; 14:19:10.290 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:19:10.290 INFO PrintReadsSpark - Initializing engine; 14:19:10.290 INFO PrintReadsSpark - Done initializing engine; 17/10/11 14:19:10 INFO spark.SparkContext: Running Spark version 1.6.0; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 43567.; 17/10/11 14:19:11 INFO slf4j.Slf4jLogger: Slf4jLogger started; 17/10/11 14:19:11 INFO Remoting: Starting remoting; 17/10/11 14:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 45501.; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/11 14:19,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:3303,Secur,SecurityManager,3303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['Secur'],['SecurityManager']
Security,"5. 10:47:20.577 INFO ProgressMeter - chr1:211951736 4.0 17700000 4421996.7. 10:47:30.580 INFO ProgressMeter - chr1:220837654 4.2 18418000 4417386.9. 10:47:40.592 INFO ProgressMeter - chr1:229536819 4.3 19156000 4417642.0. 10:47:50.595 INFO ProgressMeter - chr1:237917173 4.5 19861000 4410598.8. 10:48:00.598 INFO ProgressMeter - chr1:246682719 4.7 20561000 4403066.6. 10:48:10.604 INFO ProgressMeter - chr2:6733404 4.8 21270000 4397838.6. 10:48:20.605 INFO ProgressMeter - chr2:15144861 5.0 21942000 4385607.8. 10:48:30.607 INFO ProgressMeter - chr2:24131740 5.2 22650000 4381143.4. 10:48:40.610 INFO ProgressMeter - chr2:32916253 5.3 23467000 4397382.8. 10:48:43.217 INFO LeftAlignIndels - Shutting down engine. [August 18, 2020 10:48:43 AM EDT] org.broadinstitute.hellbender.tools.LeftAlignIndels done. Elapsed time: 5.40 minutes. Runtime.totalMemory()=2076049408. java.lang.IllegalArgumentException: the range cannot contain negative indices. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:108). at org.broadinstitute.hellbender.utils.IndexRange.shift(IndexRange.java:73). at org.broadinstitute.hellbender.utils.IndexRange.shiftLeft(IndexRange.java:77). at org.broadinstitute.hellbender.utils.read.AlignmentUtils.leftAlignIndels(AlignmentUtils.java:735). at org.broadinstitute.hellbender.tools.LeftAlignIndels.apply(LeftAlignIndels.java:78). at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.Iterator.forEachRemaining(Iterator.java:116). at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801). at jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6765:6108,validat,validateArg,6108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765,1,['validat'],['validateArg']
Security,"5.223 INFO DenoiseReadCounts - Initializing engine; 20:08:45.223 INFO DenoiseReadCounts - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 20:08:45.300 INFO DenoiseReadCounts - Reading read-counts file (BT1813.counts.hdf5)...; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5F.c line 604 in H5Fopen(): unable to open file; major: File accessibilty; minor: Unable to open file; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fint.c line 1085 in H5F_open(): unable to read superblock; major: File accessibilty; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fsuper.c line 277 in H5F_super_read(): file signature not found; major: File accessibilty; minor: Not an HDF5 file; 20:08:49.800 INFO DenoiseReadCounts - Shutting down engine; [May 18, 2021 8:08:49 PM EDT] org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=1789919232; org.broadinstitute.hdf5.HDF5LibException: exception when opening '/hpf/largeprojects/tabori/projects/bmmrd/CNA_project/gatk_cna/gatk/analysis/lgg/cnvponC2.pon.hdf5' with READ_ONLY mode: Not an HDF5 file; at org.broadinstitute.hdf5.HDF5File.open(HDF5File.java:490); at org.broadinstitute.hdf5.HDF5File.<init>(HDF5File.java:82); at org.broadinstitute.hdf5.HDF5File.<init>(HDF5File.java:66); at org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts.doWork(DenoiseReadCounts.java:188); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7258:4486,access,accessibilty,4486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7258,1,['access'],['accessibilty']
Security,5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9Qb3dlckNhbGN1bGF0aW9uVXRpbHMuamF2YQ==) | `96.667% <100%> (+1.429%)` | `18 <7> (+3)` | :arrow_up: |; | [...tmutpileup/BasicSomaticShortMutationValidator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CYXNpY1NvbWF0aWNTaG9ydE11dGF0aW9uVmFsaWRhdG9yLmphdmE=) | `62.5% <100%> (+1.974%)` | `5 <0> (ø)` | :arrow_down: |; | [...ion/basicshortmutpileup/BasicValidationResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CYXNpY1ZhbGlkYXRpb25SZXN1bHQuamF2YQ==) | `96.774% <100%> (+0.222%)` | `16 <2> (+1)` | :arrow_up: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `83.636% <100%> (+0.15%)` | `19 <0> (ø)` | :arrow_down: |; | [...dateBasicSomaticShortMutationsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zSW50ZWdyYXRpb25UZXN0LmphdmE=) | `100% <100%> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5062#issuecomment-408490831:2311,Validat,ValidateBasicSomaticShortMutations,2311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5062#issuecomment-408490831,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,"514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Version: Version:4.alpha.2-170-g8d06823-SNAPSHOT; 19:03:42.998 INFO ValidateSamFile - Defaults.BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.COMPRESSION_LEVEL : 1; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_INDEX : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_MD5 : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CUSTOM_READER_FACTORY : ; 19:03:42.999 INFO ValidateSamFile - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 19:03:42.999 INFO ValidateSamFile - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.REFERENCE_FASTA : null; 19:03:43.000 INFO ValidateSamFile - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.000 INFO ValidateSamFile - Initializing engine; 19:03:43.000 INFO ValidateSamFile - Done initializing engine; ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 24466, Read name 20FUKAAXX100202:7:46:13035:77621, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97940, Read name 20FUKAAXX100202:5:7:21464:86224, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97955, Read na",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:1731,Validat,ValidateSamFile,1731,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,1,['Validat'],['ValidateSamFile']
Security,52%)` | |; | [...aplotypecaller/HaplotypeCallerIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `57.339% <0%> (-30.767%)` | `89% <0%> (+4%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...utils/variant/GATKVariantContextUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzVW5pdFRlc3QuamF2YQ==) | `61.598% <0%> (-24.25%)` | `160% <0%> (ø)` | |; | [...walkers/validation/ConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `79.444% <0%> (-20.556%)` | `3% <0%> (-3%)` | |; | [...kers/vqsr/VariantGaussianMixtureModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVmFyaWFudEdhdXNzaWFuTWl4dHVyZU1vZGVsVW5pdFRlc3QuamF2YQ==) | `62.857% <0%> (-20.162%)` | `13% <0%> (ø)` | |; | [.../walkers/vqsr/TruthSensitivityTrancheUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJ1dGhTZW5zaXRpdml0eVRyYW5jaGVVbml0VGVzdC5qYXZh) | `66.667% <0%> (-19.048%)` | `12% <0%> (ø)` | |; | [...stitute/hellbender/utils/nio/PathLineIterator.java](h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5710#issuecomment-466524542:2858,validat,validation,2858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5710#issuecomment-466524542,1,['validat'],['validation']
Security,53216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCleaner$.org$apache$sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:6958,Hash,HashTable,6958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashTable']
Security,"557000 1924140.1; 01:10:44.052 INFO ProgressMeter - 5:18554429 10.9 20887000 1924971.5; 01:10:54.053 INFO ProgressMeter - 5:23247594 11.0 21241000 1927979.5; 01:11:04.057 INFO ProgressMeter - 5:25901452 11.2 21588000 1930263.3; 01:11:14.089 INFO ProgressMeter - 5:32482380 11.4 21916000 1930729.5; 01:11:24.106 INFO ProgressMeter - 5:38674297 11.5 22249000 1931652.6; 01:11:34.133 INFO ProgressMeter - 5:49679881 11.7 22573000 1931754.3; 01:11:44.145 INFO ProgressMeter - 5:53234595 11.9 22925000 1934259.1; 04:10:15.659 INFO ProgressMeter - 6:1726401 190.4 23183000 121774.0; 04:10:25.671 INFO ProgressMeter - 6:10206926 190.5 23517000 123420.2; 04:10:31.341 INFO BaseRecalibrator - Shutting down engine; [February 22, 2021 at 4:10:31 AM PST] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 190.65 minutes.; Runtime.totalMemory()=1268776960; java.lang.IllegalStateException: cigar is completely soft-clipped; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:129); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:143); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.consolidateCigar(BaseRecalibrationEngine.java:293); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:118); at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:189)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7092:8787,validat,validate,8787,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7092,1,['validat'],['validate']
Security,5:41:49.029 INFO Funcotator - HTSJDK Version: 2.23.0; 15:41:49.029 INFO Funcotator - Picard Version: 2.22.8; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:41:49.029 INFO Funcotator - Deflater: IntelDeflater; 15:41:49.029 INFO Funcotator - Inflater: IntelInflater; 15:41:49.029 INFO Funcotator - GCS max retries/reopens: 20; 15:41:49.029 INFO Funcotator - Requester pays: disabled; 15:41:49.029 INFO Funcotator - Initializing engine; 15:41:49.471 INFO FeatureManager - Using codec VCFCodec to read file file:///home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf; 15:41:49.489 INFO Funcotator - Done initializing engine; 15:41:49.489 INFO Funcotator - Validating Sequence Dictionaries...; 15:41:49.490 INFO Funcotator - Processing user transcripts/defaults/overrides...; 15:41:49.490 INFO Funcotator - Initializing data sources...; 15:41:49.492 INFO DataSourceUtils - Initializing data sources from directory: /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s; 15:41:49.492 INFO DataSourceUtils - Data sources version: 1.7.2020429s; 15:41:49.492 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 15:41:49.492 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 15:41:49.496 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/achilles_lineage_results.import.txt -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/achilles/hg19/achilles_lin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6758:4657,Validat,Validating,4657,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758,1,['Validat'],['Validating']
Security,"6.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 240; 17:21:06.647 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 230; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4488; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1355; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1675; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 17:21:06.648 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/01/25 17:21:07 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 29.0 in stage 61.0 (TID 60915, cwhelan-hg00514-1-cram-samtools-bam-feature-w-1.c.broad-dsde-methods.internal, executor 48): java.lang.IllegalArgumentException: Unexpected CIGAR format with deletion neighboring clipping; cigar elements are: [1190M, 4D, 53M, 2I, 26M, 2I, 31M, 2D, 1450S]; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.validateCigar(SvCigarUtils.java:134); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.getUnclippedReadLength(SvCigarUtils.java:161); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.computeAssociatedDistOnRead(SvCigarUtils.java:330); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.AlignmentInterval.readIntervalAlignedToRefSpan(AlignmentInterval.java:634); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.extractAltHaplotypeSeq(CpxVariantDetector.java:852); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.access$300(CpxVariantDetector.java:47); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector$AnnotatedContig.annotate(CpxVariantDetector.java:194); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDet",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:5001,validat,validateArg,5001,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['validat'],['validateArg']
Security,"6:08:17 UTC 2019] ValidateSamFile --INPUT CQ-NEQAS-2018.ILLUMINA.library.000000000-BCFDC.1.1.sorted.bam --MODE SUMMARY --MAX_OUTPUT 100 --IGNORE_WARNINGS false --VALIDATE_INDEX true --INDEX_VALIDATION_STRINGENCY EXHAUSTIVE --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --SKIP_MATE_VALIDATION false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrowser.bed.bgz --known-sites snp151flagged_tablebrowser.bed.bgz`; ```; ERROR: return code 3; STDERR:; 15:46:35.795 INFO NativeLibraryLoader - Loading libgkl_compression.so from j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:1834,validat,validations,1834,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['validat'],['validations']
Security,6e7635897e1a6a773af5684511e2358d369af94?src=pr&el=desc) will **increase** coverage by `0.002%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4310 +/- ##; ===============================================; + Coverage 79.065% 79.067% +0.002% ; - Complexity 16582 16583 +1 ; ===============================================; Files 1048 1048 ; Lines 59504 59504 ; Branches 9717 9717 ; ===============================================; + Hits 47047 47048 +1 ; Misses 8682 8682 ; + Partials 3775 3774 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4310?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...bender/tools/walkers/mutect/FilterMutectCalls.java](https://codecov.io/gh/broadinstitute/gatk/pull/4310/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9GaWx0ZXJNdXRlY3RDYWxscy5qYXZh) | `95.833% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/4310/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `88.542% <ø> (ø)` | `28 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/4310/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `92% <ø> (ø)` | `15 <0> (ø)` | :arrow_down: |; | [...ls/walkers/mutect/CreateSomaticPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4310/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHMuamF2YQ==) | `87.273% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/exome/FilterByOrientationBias.java](https://codecov.io/gh/broadinstitute/gatk/pull/4310/di,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4310#issuecomment-361770954:1236,validat,validation,1236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4310#issuecomment-361770954,1,['validat'],['validation']
Security,7 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20; 20:41:37.627 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 20:41:37.627 INFO PathSeqPipelineSpark - Initializing engine; 20:41:37.627 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/23 20:41:38 INFO SparkContext: Running Spark version 2.2.0; 18/04/23 20:41:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/04/23 20:41:38 INFO SparkContext: Submitted application: PathSeqPipelineSpark; 18/04/23 20:41:39 INFO SecurityManager: Changing view acls to: zorzan; 18/04/23 20:41:39 INFO SecurityManager: Changing modify acls to: zorzan; 18/04/23 20:41:39 INFO SecurityManager: Changing view acls groups to:; 18/04/23 20:41:39 INFO SecurityManager: Changing modify acls groups to:; 18/04/23 20:41:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(zorzan); groups with view permissions: Set(); users with modify permissions: Set(zorzan); groups with modify permissions: Set(); 18/04/23 20:41:41 INFO Utils: Successfully started service 'sparkDriver' on port 36273.; 18/04/23 20:41:41 INFO SparkEnv: Registering MapOutputTracker; 18/04/23 20:41:41 INFO SparkEnv: Registering BlockManagerMaster; 18/04/23 20:41:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/04/23 20:41:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/04/23 20:41:41 INFO DiskBlockManager: Created local directory at /tmp/zorzan/blockmgr-994d8501-06ce-4315-84ff-3c29de358ae1; 18/04/23 20:41:41 INFO MemoryStore: MemoryStore started with capacity 4.0 GB; 18/04/23 20:41:41 INFO SparkEnv: Registering OutputCommitCoordi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:6995,Secur,SecurityManager,6995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"78 INFO HaplotypeCaller - GCS max retries/reopens: 20; 01:13:16.078 INFO HaplotypeCaller - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 01:13:16.078 INFO HaplotypeCaller - Initializing engine; 01:13:17.087 INFO HaplotypeCaller - Shutting down engine; [January 18, 2020 1:13:17 AM IST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2216689664; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); 	at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:621); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:563); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:160); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:275). Please suggest any solution.; Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-575601220:2673,validat,validateDictionaries,2673,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-575601220,3,['validat'],"['validateDictionaries', 'validateSequenceDictionaries']"
Security,"7:30.580 INFO ProgressMeter - chr1:220837654 4.2 18418000 4417386.9. 10:47:40.592 INFO ProgressMeter - chr1:229536819 4.3 19156000 4417642.0. 10:47:50.595 INFO ProgressMeter - chr1:237917173 4.5 19861000 4410598.8. 10:48:00.598 INFO ProgressMeter - chr1:246682719 4.7 20561000 4403066.6. 10:48:10.604 INFO ProgressMeter - chr2:6733404 4.8 21270000 4397838.6. 10:48:20.605 INFO ProgressMeter - chr2:15144861 5.0 21942000 4385607.8. 10:48:30.607 INFO ProgressMeter - chr2:24131740 5.2 22650000 4381143.4. 10:48:40.610 INFO ProgressMeter - chr2:32916253 5.3 23467000 4397382.8. 10:48:43.217 INFO LeftAlignIndels - Shutting down engine. [August 18, 2020 10:48:43 AM EDT] org.broadinstitute.hellbender.tools.LeftAlignIndels done. Elapsed time: 5.40 minutes. Runtime.totalMemory()=2076049408. java.lang.IllegalArgumentException: the range cannot contain negative indices. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:108). at org.broadinstitute.hellbender.utils.IndexRange.shift(IndexRange.java:73). at org.broadinstitute.hellbender.utils.IndexRange.shiftLeft(IndexRange.java:77). at org.broadinstitute.hellbender.utils.read.AlignmentUtils.leftAlignIndels(AlignmentUtils.java:735). at org.broadinstitute.hellbender.tools.LeftAlignIndels.apply(LeftAlignIndels.java:78). at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.Iterator.forEachRemaining(Iterator.java:116). at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801). at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481). at java.util",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6765:6187,validat,validate,6187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765,1,['validat'],['validate']
Security,"8,26:0.261:13:10:2100,793:37:29; ```. **output GatherVcfs to .vcf.gz allows for duplicate records**; ```; WMCF9-CB5:precomputed_results shlee$ java -jar $PICARD GatherVcfs I=split3_8.vcf.gz I=split2_8.vcf.gz O=../test_gathervcf_split8_overlap.vcf.gz; [Wed Jun 07 14:51:32 EDT 2017] picard.vcf.GatherVcfs INPUT=[split3_8.vcf.gz, split2_8.vcf.gz] OUTPUT=../test_gathervcf_split8_overlap.vcf.gz VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=true CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [Wed Jun 07 14:51:32 EDT 2017] Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Picard version: 2.9.2-SNAPSHOT; INFO	2017-06-07 14:51:32	GatherVcfs	Checking inputs.; INFO	2017-06-07 14:51:32	GatherVcfs	Checking file headers and first records to ensure compatibility.; INFO	2017-06-07 14:51:32	GatherVcfs	Gathering by copying gzip blocks. Will not be able to validate position non-overlap of files.; WARNING	2017-06-07 14:51:32	GatherVcfs	Index creation not currently supported when gathering block compressed VCFs.; INFO	2017-06-07 14:51:32	GatherVcfs	Gathering /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/precomputed_results/split3_8.vcf.gz; INFO	2017-06-07 14:51:32	GatherVcfs	Gathering /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/precomputed_results/split2_8.vcf.gz; [Wed Jun 07 14:51:32 EDT 2017] picard.vcf.GatherVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=257425408; WMCF9-CB5:precomputed_results shlee$ gzcat ../test_gathervcf_split8_overlap.vcf.gz | grep -v '##' ; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NORMAL	TUMOR; chr6	33414233	.	GT	G	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=28.24;RPA=5,4;RU=T;STR;TLOD=154.53	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:112,0:0.00:0:0:3730,0:62:50	0/1:66,70:0.534:25:41:2209,2350:26:40; chr6	33442919	.	A	C	.	alt_allele_i",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306889518:2414,validat,validate,2414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306889518,1,['validat'],['validate']
Security,"8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1297,Validat,ValidateVariants,1297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"80k is what I had easy access to and what I'm the most invested in; benchmarking right now. Master does fine with the same params. It's slow,; but no failures. We decided to split into 1000 shards (Eric is convinced; that there's a substantial startup cost per shard so we do better in total; cpu-hours on fewer shards) and each of those takes about 24 hours. On Thu, May 10, 2018, 11:09 AM Louis Bergelson <notifications@github.com>; wrote:. > @ldgauthier <https://github.com/ldgauthier> You're running 80k? Does that; > run using the current master version of GATK? I assumed you were rerunning; > a 20k shard with the same settings we had used for the 20k.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388082988>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdLdlQoWlC8kjRvJJermDYEjltVUFks5txFgigaJpZM4TOtSm>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388183296:23,access,access,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388183296,1,['access'],['access']
Security,"86); - Remove AI/AN from VDS docs [VS-726] (#8096); - Add flag for cost_observability table writing to support sub-cohort use case [VS-521] (#8093); - Document STS delivery process for VDS [VS-727] (#8101); - delete obsolete callset_QC directory and its contents [VS-318] (#8108); - doc link typo and add check for control samples in AVRO export (#8110); - Add defaults for scatter_count in GvsExtractCohortFromSampleNames [VS-496] (#8109); - Escape table names properly in ValidateVat WDL (#8116); - Vs 741 fix indefinite freeze in split intervals task when using exome data (#8113); - VAT Readme updates (#8090); - WDL and python scripts to use the VDS in the VAT (#8077); - VS-757 - Use JASIX to make sub-jsons of annotated output of Nirvana (#8133); - add note about permissions for P&S workflow to work (#8135); - VS-759 (and VS-760) (#8137); - VS-765. Scatter the RemoveDuplicates task. (#8144); - update delivery docs based on latest VDS delivery run [VS-770] (#8150); - Add monitoring to index vcf (#8151); - Make some noise when VDS validation succeeds (#8155); - Handle empty genes annotation file. (#8153); - Add escapes for otherwise problematic dataset / table names. (#8162); - New WDL to create VAT tsvs from previously generated BigQuery table. (#8165); - Treat withdrawn samples in sub-cohort prepare correctly [VS-772] (#8156); - Remove unused VAT Creation WDL (#8172); - Gg consistently use dataset name as input parameter (#8173); - AoU cleanup docs, round 1 [VS-671] (#8104); - VDS docs remove samples and correct GT [VS-807] (#8178); - [VS-693] Add support for VQSR Lite to GvsCreateFilterSet (#8157); - VAT Documentation Update Round 1 [VS-531]; - VS-530 VDS creation documentation for AoU (#8169); - Update beta docs to tell people not to use free credits (#8184); - VS-816 Keeping ingestion under quota (#8193); - CromwellOnAzure + Azure SQL DB + AAD first steps doc [VS-805] (#8191); - Edit and re-format VDS -> VAT doc [VS-821] (#8187); - VS-820 Incorporate code to stay un",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:31469,validat,validation,31469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['validat'],['validation']
Security,"89); - Pinned typing_extensions python package to 4.1.1 to fix conda environment. (#7802); - WeightedSplitInterval fixes [VS-384] [VS-332] (#7795); - Replace Travis with GithubActions (#7754); - Docker build only lfs pulls main/src/resources/large (#7727); - Clean up gatk jars -- looks like we are not passing them properly in the extract (#7788); - Fix typo that broke git lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were trying to grep a binary file (#7837); - Cleanup scripts/variantstore [VS-414] (#7834); - Merge VAT TSV files into single bgzipped file [VS-304] (#7848); - Handle fully and partially loaded samples [VS-262] [VS-258] (#7843); - Ingest Error Handling Fixes [VS-261] (#7841); - First cut at a python notebook to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868); - VET Ingest Validation / Allow Ingest of non-VQSR'ed data (#7870); - Fix AoU workflow bugs (#7874); - Curate input arrays to skip already ingested sample data [VS-246] (#7862); - KM upload GVS product sheet (#7883); - Default extract scatter width [VS-415] (#7878); - Volatile tasks review [VS-447] (#7880); - Update Quickstart Integration for X/Y scaling changes ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:24455,validat,validate,24455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['validat'],['validate']
Security,"90 4.1 67150 16425.7; 09:53:22.294 INFO ProgressMeter - 1:20576686 4.3 71380 16776.4; 09:53:32.681 INFO ProgressMeter - 1:21106727 4.4 73230 16538.3; 09:53:44.258 INFO ProgressMeter - 1:21270052 4.6 73820 15975.4; 09:53:54.757 INFO ProgressMeter - 1:21754504 4.8 75500 15742.8; 09:54:04.928 INFO ProgressMeter - 1:23419224 5.0 81370 16387.6; 09:54:15.956 INFO ProgressMeter - 1:23812728 5.1 82750 16070.6; 09:54:31.008 INFO ProgressMeter - 1:24023237 5.4 83470 15457.4; 09:54:33.610 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 58.921665822; 09:54:33.611 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 72.92 sec; 09:54:33.612 INFO Mutect2 - Shutting down engine; [March 7, 2019 9:54:33 AM EST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 5.51 minutes.; Runtime.totalMemory()=193003520; java.lang.IllegalArgumentException: readMaxLength must be > 0 but got 0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:152); 	at org.broadinstitute.hellbender.utils.pairhmm.N2MemoryPairHMM.initialize(N2MemoryPairHMM.java:28); 	at org.broadinstitute.hellbender.utils.pairhmm.LoglessPairHMM.initialize(LoglessPairHMM.java:7); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:177); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.initializePairHMM(PairHMMLikelihoodCalculationEngine.java:242); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:177); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:229); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:232); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(Assemb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844:4754,validat,validateArg,4754,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844,1,['validat'],['validateArg']
Security,"9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:11:33.871 INFO PrintReadsSpark - Initializing engine; 18:11:33.871 INFO PrintReadsSpark - Done initializing engine; 17/10/13 18:11:33 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 17/10/13 18:11:34 WARN spark.SparkConf: spark.master yarn-client is deprecated in Spark 2.0+, please instead use ""yarn"" with specified deploy mode.; 17/10/13 18:11:34 INFO spark.SparkContext: Submitted application: PrintReadsSpark; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing view acls groups to: ; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing modify acls groups to: ; 17/10/13 18:11:34 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); groups with view permissions: Set(); users with modify permissions: Set(hdfs); groups with modify permissions: Set(); 17/10/13 18:11:34 INFO util.Utils: Successfully started service 'sparkDriver' on port 45754.; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/13 18:11:34 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 17/10/13 18:11:34 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 17/10/13 18:11:34 INFO storage.DiskBlockManager: Created local directory at /tmp/hdfs/blockmgr-ea0e0669-2981-4277-80a0-a67eddf1001d; 17/10/13 18:11:34 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering OutputCommitCoordinator; 17/10/13 18:11:34 INFO util.log: Logging initialized @3816ms; 17/10/13 18:11:34 INFO server.Server: jetty-9.3.z-SNAPSHOT; 17/10/13 ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:4266,Secur,SecurityManager,4266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,3,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,": 20; 08:37:16.409 INFO GermlineCNVCaller - Requester pays: disabled; 08:37:16.409 INFO GermlineCNVCaller - Initializing engine; 08:37:21.698 INFO GermlineCNVCaller - Done initializing engine; 08:37:22.015 INFO GermlineCNVCaller - Retrieving intervals from read-count file (results/200219_X008378.counts.tsv)...; 08:37:22.119 INFO GermlineCNVCaller - No annotated intervals were provided...; 08:37:22.120 INFO GermlineCNVCaller - No GC-content annotations for intervals found; explicit GC-bias correction will not be performed...; 08:37:22.194 INFO GermlineCNVCaller - Running the tool in the COHORT mode...; 08:37:22.195 INFO GermlineCNVCaller - Shutting down engine; [February 26, 2019 8:37:22 AM GMT] org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller done. Elapsed time: 0.29 minutes.; Runtime.totalMemory()=330301440; java.lang.IllegalArgumentException: Output directory results/190226.181217_K00178.CNVCaller does not exist.; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.validateArguments(GermlineCNVCaller.java:361); at org.broadinstitute.hellbender.tools.copynumber.GermlineCNVCaller.doWork(GermlineCNVCaller.java:281); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); Using GATK jar /mnt/storage/apps/software/gatk/4.1.0.0/gatk-package-4.1.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compress",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-467406398:15857,validat,validateArg,15857,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-467406398,1,['validat'],['validateArg']
Security,":///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn --executor-memory 48G --driver-memory 16g --driver-cores 2 --executor-cores 8 --num-executors 8. ```; 18/03/07 13:24:26 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q14.scc.bu.edu:42456 with 25.4 GB RAM, BlockManagerId(2, scc-q14.scc.bu.edu, 42456, None); 18/03/07 13:24:27 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 247.0 KB, free 8.4 GB); 18/03/07 13:24:28 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.5 KB, free 8.4 GB); 18/03/07 13:24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in mem",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:1499,secur,security,1499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304,1,['secur'],['security']
Security,"://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-), but then for Haplotypecaller, and you have opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1608,Validat,ValidateVariants,1608,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['Validat'],['ValidateVariants']
Security,":01,31] [info] Running with database db.url = jdbc:hsqldb:mem:c4b3296a-4b73-4053-b6bf-d4eeb71c8956;shutdown=false;hsqldb.tx=mvcc; [2019-10-01 02:53:01,85] [info] Slf4jLogger started; [2019-10-01 02:53:02,22] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-876ccf5"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-10-01 02:53:02,28] [info] Metadata summary refreshing every 1 second.; [2019-10-01 02:53:02,31] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-10-01 02:53:02,31] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-10-01 02:53:02,32] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-10-01 02:53:02,32] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-10-01 02:53:02,40] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-10-01 02:53:02,43] [info] SingleWorkflowRunnerActor: Version 46.1; [2019-10-01 02:53:02,44] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-10-01 02:53:02,49] [info] Unspecified type (Unspecified version) workflow c55a06f3-abc1-4db1-8e0f-ea0303caab2c submitted; [2019-10-01 02:53:02,51] [info] SingleWorkflowRunnerActor: Workflow submitted c55a06f3-abc1-4db1-8e0f-ea0303caab2c; [2019-10-01 02:53:02,51] [info] 1 new workflows fetched by cromid-876ccf5: c55a06f3-abc1-4db1-8e0f-ea0303caab2c; [2019-10-01 02:53:02,52] [info] WorkflowManagerActor Starting workflow c55a06f3-abc1-4db1-8e0f-ea0303caab2c; [2019-10-01 02:53:02,53] [info] WorkflowManagerActor Successfully started WorkflowActor-c55a06f3-abc1-4db1-8e0f-ea0303caab2c; [2019-10-01 02:53:02,53] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2019-10-01 02:53:02,55",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6189:1661,hash,hash-lookup,1661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6189,1,['hash'],['hash-lookup']
Security,:05.915 WARN HaplotypeCallerSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: HaplotypeCallerSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 09:38:05.915 INFO HaplotypeCallerSpark - Initializing engine; 09:38:05.915 INFO HaplotypeCallerSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/08/15 09:38:06 INFO SparkContext: Running Spark version 2.4.5; 09:38:06.440 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/08/15 09:38:06 INFO SparkContext: Submitted application: HaplotypeCallerSpark; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xc278); groups with view permissions: Set(); users with modify permissions: Set(xc278); groups with modify permissions: Set(); 20/08/15 09:38:06 INFO Utils: Successfully started service 'sparkDriver' on port 33339.; 20/08/15 09:38:06 INFO SparkEnv: Registering MapOutputTracker; 20/08/15 09:38:06 INFO SparkEnv: Registering BlockManagerMaster; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/08/15 09:38:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8d90ed7-8009-437a-8d5e-571b3a582f62; 20/08/15 09:38:06 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 20/08/15 09:38:06 INFO SparkEnv: Registering OutputCommitCoordinator; 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6750:4339,Secur,SecurityManager,4339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,":08.688 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Deflater: IntelDeflater; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Inflater: IntelInflater; 12:49:08.688 INFO PostprocessGermlineCNVCalls - GCS max retries/reopens: 20; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Requester pays: disabled; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Initializing engine; 12:49:12.598 INFO PostprocessGermlineCNVCalls - Done initializing engine; 12:49:15.678 INFO PostprocessGermlineCNVCalls - Shutting down engine; [October 29, 2020 12:49:15 PM MSK] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2457862144; java.lang.IllegalArgumentException: Records were not strictly sorted in dictionary order.; 	at org.broadinstitute.hellbender.tools.copynumber.arguments.CopyNumberArgumentValidationUtils.validateIntervals(CopyNumberArgumentValidationUtils.java:60); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.AbstractLocatableCollection.getShardedCollectionSortOrder(AbstractLocatableCollection.java:142); 	at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.onTraversalStart(PostprocessGermlineCNVCalls.java:297); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924:9617,validat,validateIntervals,9617,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924,1,['validat'],['validateIntervals']
Security,":11:36 INFO yarn.Client: Requesting a new application from cluster with 3 NodeManagers; 17/10/13 18:11:36 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per container); 17/10/13 18:11:36 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/13 18:11:36 INFO yarn.Client: Setting up container launch context for our AM; 17/10/13 18:11:36 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/13 18:11:36 INFO yarn.Client: Preparing resources for our AM container; 17/10/13 18:11:37 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-c7e5eece-205e-4bce-a69b-4168c9b79045/__spark_conf__2918234914787361986.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507856833944_0003/__spark_conf__.zip; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); groups with view permissions: Set(); users with modify permissions: Set(hdfs); groups with modify permissions: Set(); 17/10/13 18:11:37 INFO yarn.Client: Submitting application application_1507856833944_0003 to ResourceManager; 17/10/13 18:11:37 INFO impl.YarnClientImpl: Submitted application application_1507856833944_0003; 17/10/13 18:11:37 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1507856833944_0003 and attemptId None; 17/10/13 18:11:38 INFO yarn.Client: Application report for application_1507856833944_0003 (state: ACCEPTED); 17/10/13 18:11:38 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster h",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:10633,Secur,SecurityManager,10633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['Secur'],['SecurityManager']
Security,":30:57 INFO yarn.Client: Requesting a new application from cluster with 4 NodeManagers; 18/01/09 18:30:58 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (18432 MB per container); 18/01/09 18:30:58 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 18/01/09 18:30:58 INFO yarn.Client: Setting up container launch context for our AM; 18/01/09 18:30:58 INFO yarn.Client: Setting up the launch environment for our AM container; 18/01/09 18:30:58 INFO yarn.Client: Preparing resources for our AM container; 18/01/09 18:30:59 INFO yarn.Client: Uploading resource file:/tmp/sun/spark-5a3e539e-2e2b-4da2-b218-2bda166bd4c0/__spark_conf__7100950787185363106.zip -> hdfs://tele-1:8020/user/sun/.sparkStaging/application_1515493209401_0001/__spark_conf__.zip; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:31:00 INFO yarn.Client: Submitting application application_1515493209401_0001 to ResourceManager; 18/01/09 18:31:00 INFO impl.YarnClientImpl: Submitted application application_1515493209401_0001; 18/01/09 18:31:00 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1515493209401_0001 and attemptId None; 18/01/09 18:31:01 INFO yarn.Client: Application report for application_1515493209401_0001 (state: ACCEPTED); 18/01/09 18:31:01 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster hos",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:11871,Secur,SecurityManager,11871,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,":39:44 INFO org.spark_project.jetty.server.Server: Started @3988ms; 17/11/27 20:39:44 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@7fbe38a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/27 20:39:44 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/27 20:39:45 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at droazen-test-cluster-m/10.240.0.10:8032; 17/11/27 20:39:47 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1511814592376_0002; 17/11/27 20:39:52 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@7fbe38a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 20:39:52.363 INFO CountReadsSpark - Shutting down engine; [November 27, 2017 8:39:52 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=630718464; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:340); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:74); 	at com.google.cloud.RetryHelper.runWithRetries(Ret",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:5710,secur,security,5710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,2,"['access', 'secur']","['access', 'security']"
Security,:50:33 PM EST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:6790,Hash,HashMap,6790,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,":57.036 INFO ProgressMeter - Starting traversal; 00:05:57.036 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr16:10185 the annotation AS_VarDP=59|115|0 was not a numerical value and was ignored; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Reducible annotation 'AS_VarDP' detected, add -G StandardAnnotation -G AS_StandardAnnotation to the command to annotate in the final VC with this annotation.; 00:07:26.991 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.02938786500000001,Cpu time(s),0.029037034000000003; [August 25, 2021 12:07:27 AM EDT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.55 minutes.; Runtime.totalMemory()=1807745024; java.lang.NullPointerException; at java.util.HashMap.putMapEntries(HashMap.java:500); at java.util.HashMap.putAll(HashMap.java:784); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:211); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:281); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:8055,Hash,HashMap,8055,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['Hash'],['HashMap']
Security,":; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6, 2018 12:55:31 PM EDT; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.084 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 12:55:32.084 INFO LeftAlignAndTrimVariants - Picard ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:1356,authenticat,authentication,1356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,1,['authenticat'],['authentication']
Security,; 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1855,secur,security,1855,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['secur'],['security']
Security,; 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1721,secur,security,1721,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['secur'],['security']
Security,; ## master #3228 +/- ##; ===============================================; + Coverage 80.419% 80.427% +0.008% ; Complexity 17290 17290 ; ===============================================; Files 1165 1165 ; Lines 62596 62597 +1 ; Branches 9768 9768 ; ===============================================; + Hits 50339 50345 +6 ; + Misses 8352 8347 -5 ; Partials 3905 3905; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `83.704% <100%> (+0.122%)` | `36 <0> (ø)` | :arrow_down: |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ291bnRGYWxzZVBvc2l0aXZlcy5qYXZh) | `93.548% <100%> (ø)` | `7 <1> (ø)` | :arrow_down: |; | [.../tools/walkers/validation/FalsePositiveRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vRmFsc2VQb3NpdGl2ZVJlY29yZC5qYXZh) | `100% <100%> (ø)` | `7 <2> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.649% <0%> (+2.027%)` | `34% <0%> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3228#issuecomment-314209891:1519,validat,validation,1519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3228#issuecomment-314209891,1,['validat'],['validation']
Security,"; - 317 remove excess header values in VCF extract (#7786); - correct auth in split intervals (#7790); - Add code to (optionally) zero pad the vcf filename. (#7783); - LoadData `maxRetries` parameterized, default increased [VS-383] (#7791); - Update to latest version of ah_var_store gatk override jar (#7793); - GvsUnified WDL to wrap the 6 core GVS WDLs [VS-382] (#7789); - Pinned typing_extensions python package to 4.1.1 to fix conda environment. (#7802); - WeightedSplitInterval fixes [VS-384] [VS-332] (#7795); - Replace Travis with GithubActions (#7754); - Docker build only lfs pulls main/src/resources/large (#7727); - Clean up gatk jars -- looks like we are not passing them properly in the extract (#7788); - Fix typo that broke git lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were trying to grep a binary file (#7837); - Cleanup scripts/variantstore [VS-414] (#7834); - Merge VAT TSV files into single bgzipped file [VS-304] (#7848); - Handle fully and partially loaded samples [VS-262] [VS-258] (#7843); - Ingest Error Handling Fixes [VS-261] (#7841); - First cut at a python notebook to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:23942,validat,validate,23942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['validat'],['validate']
Security,"; --master yarn-client \; --driver-memory 8G \; --conf spark.driver.maxResultSize=0 \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; --conf spark.yarn.executor.memoryOverhead=600 \; --executor-memory ${execMem}g \; --num-executors $execs \; --executor-cores $cores \; bin/cleanHellbender/gatk/build/libs/gatk-all-*-spark.jar \; ReadsPipelineSpark \; --sparkMaster yarn-client \; -I hdfs:///user/akiezun/CEUTrio.HiSeq.WEx.b37.NA12892.bam \; -R hdfs:///user/droazen/bqsr/human_g1k_v37.2bit \; --programName ${name} \; -O $bamout \; --knownSites hdfs:////user/akiezun/dbsnp_138.b37.excluding_sites_after_129.vcf \; --emit_original_quals \; --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES; ```. exec=24; cores=5; execMem=25. fails with . ```; java.lang.IllegalArgumentException: SimpleInterval is 1 based, so start must be >= 1, start: 0; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:58); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.baq.BAQ.getReferenceWindowForRead(BAQ.java:525); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:46); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:41); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithRefBases.lambda$addBases$c54addeb$1(BroadcastJoinReadsWithRefBases.java:52); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.convert.Wrapper",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1234:1070,validat,validatePositions,1070,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1234,1,['validat'],['validatePositions']
Security,; ===============================================; Files 1065 1065 ; Lines 58788 58788 ; Branches 9578 9578 ; ===============================================; + Hits 46310 46315 +5 ; + Misses 8752 8746 -6 ; - Partials 3726 3727 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3989?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `90.323% <ø> (ø)` | `12 <0> (ø)` | :arrow_down: |; | [...r/tools/walkers/validation/RemoveNearbyIndels.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzLmphdmE=) | `90.476% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/tools/GatherVcfsCloud.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9HYXRoZXJWY2ZzQ2xvdWQuamF2YQ==) | `70.811% <0%> (ø)` | `40 <0> (ø)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/utils/IndexUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbmRleFV0aWxzLmphdmE=) | `80.702% <100%> (ø)` | `16 <2> (ø)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/3989/diff?src=pr&el=tree#diff-c3JjL21haW4va,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352845785:1528,validat,validation,1528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3989#issuecomment-352845785,1,['validat'],['validation']
Security,=) | `56.522% <0%> (-36.335%)` | `2 <0> (ø)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/6010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `63.158% <100%> (+1.825%)` | `18 <1> (+1)` | :arrow_up: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/6010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `82.873% <100%> (+0.095%)` | `78 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/spark/pathseq/PathSeqBwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/6010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFCd2FTcGFyay5qYXZh) | `67.391% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...tools/spark/validation/CompareDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/6010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay92YWxpZGF0aW9uL0NvbXBhcmVEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `89.63% <100%> (ø)` | `40 <0> (ø)` | :arrow_down: |; | [...lbender/tools/spark/pathseq/PathSeqScoreSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/6010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFTY29yZVNwYXJrLmphdmE=) | `58.491% <100%> (+1.083%)` | `7 <0> (ø)` | :arrow_down: |; | [...lkers/varianteval/evaluators/VariantEvaluator.java](https://codecov.io/gh/broadinstitute/gatk/pull/6010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnRldmFsL2V2YWx1YXRvcnMvVmFyaWFudEV2YWx1YXRvci5qYXZh) | `70% <0%> (-12.353%)` | `12% <0%> (ø)` | |; | [...ls/walkers/varianteval/util/EvaluationContext.java](https://codecov.io,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6010#issuecomment-503050294:2196,validat,validation,2196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6010#issuecomment-503050294,1,['validat'],['validation']
Security,"=; 10:33:06.428 INFO SparkContext - Submitted application: SortSamSpark; 10:33:06.446 INFO ResourceProfile - Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 600, script: , vendor: , cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0); 10:33:06.454 INFO ResourceProfile - Limiting resource is cpu; 10:33:06.455 INFO ResourceProfileManager - Added ResourceProfile id: 0; 10:33:06.500 INFO SecurityManager - Changing view acls to: root; 10:33:06.501 INFO SecurityManager - Changing modify acls to: root; 10:33:06.501 INFO SecurityManager - Changing view acls groups to:; 10:33:06.502 INFO SecurityManager - Changing modify acls groups to:; 10:33:06.502 INFO SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 10:33:06.755 INFO Utils - Successfully started service 'sparkDriver' on port 34861.; 10:33:06.784 INFO SparkEnv - Registering MapOutputTracker; 10:33:06.815 INFO SparkEnv - Registering BlockManagerMaster; 10:33:06.827 INFO BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 10:33:06.828 INFO BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up; 10:33:06.831 INFO SparkEnv - Registering BlockManagerMasterHeartbeat; 10:33:06.846 INFO DiskBlockManager - Created local directory at /raid/tmp/d6/c66ba827e22dbc38625af1cbc85adc/tmp/blockmgr-8dc41ac8-6cf4-4424-9b15-7e2cbfc9e538; 10:33:06.872 INFO MemoryStore - MemoryStore started with capacity 1076.2 GiB; 10:33:06.886 INFO SparkEnv - Registering OutputCommitCoordinator; 10:33:06.916 INFO log - Logging initialized @3948ms to org.sparkproject.jetty.util.log.Slf4j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:42048,Secur,SecurityManager,42048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,3,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,===================; Files 1059 1056 -3 ; Lines 59177 59149 -28 ; Branches 9616 9615 -1 ; ==============================================; - Hits 46750 46744 -6 ; + Misses 8689 8667 -22 ; Partials 3738 3738; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4094?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...kers/variantutils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `85.915% <ø> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `82.022% <ø> (ø)` | `23 <0> (ø)` | :arrow_down: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `85.965% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...pipelines/metrics/CollectMultipleMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <ø> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `87.037% <ø> (ø)` | `9 <0> (ø)` | :arrow_dow,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187:1542,Validat,ValidateBasicSomaticShortMutations,1542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,====================; Files 1089 1090 +1 ; Lines 64159 64937 +778 ; Branches 10344 10510 +166 ; ===============================================; + Hits 51600 52279 +679 ; - Misses 8498 8569 +71 ; - Partials 4061 4089 +28; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4878?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/read/markduplicates/sparkrecords/PairedEnds.java](https://codecov.io/gh/broadinstitute/gatk/pull/4878/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9QYWlyZWRFbmRzLmphdmE=) | `100% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/read/ReadUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4878/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1JlYWRVdGlscy5qYXZh) | `80% <100%> (+0.142%)` | `202 <3> (+3)` | :arrow_up: |; | [...tools/spark/validation/CompareDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4878/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay92YWxpZGF0aW9uL0NvbXBhcmVEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `84.946% <100%> (+0.502%)` | `24 <3> (ø)` | :arrow_down: |; | [...itute/hellbender/engine/spark/GATKRegistrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4878/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1JlZ2lzdHJhdG9yLmphdmE=) | `100% <100%> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...icates/sparkrecords/MarkDuplicatesSparkRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/4878/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9NYXJrRHVwbGljYXRlc1NwYXJrUmVjb3JkLmphdmE=) | `100% <100%> (ø)` | `7 <3> (ø)` | :arrow_down: |; | [...ils/read/markduplicates/sparkrecords/Fragment.java](https://co,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4878#issuecomment-396338920:1555,validat,validation,1555,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4878#issuecomment-396338920,1,['validat'],['validation']
Security,====================================; + Hits 38890 52186 +13296 ; + Misses 21482 8384 -13098 ; + Partials 4232 4024 -208; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4970?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nce/SegmentedCpxVariantSimpleVariantExtractor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NlZ21lbnRlZENweFZhcmlhbnRTaW1wbGVWYXJpYW50RXh0cmFjdG9yLmphdmE=) | `93.96% <100%> (+8.949%)` | `71 <0> (+5)` | :arrow_up: |; | [.../sv/discovery/inference/CpxVariantInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnRJbnRlcnByZXRlci5qYXZh) | `79.839% <100%> (+74.921%)` | `26 <0> (+25)` | :arrow_up: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `85.965% <0%> (-0.94%)` | `7% <0%> (-6%)` | |; | [.../hellbender/tools/genomicsdb/GenomicsDBImport.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnQuamF2YQ==) | `75.758% <0%> (-0.591%)` | `53% <0%> (+7%)` | |; | [...llbender/tools/genomicsdb/GenomicsDBConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJDb25zdGFudHMuamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...r/tools/walkers/annotator/ClippingRankSumTest.java](https://co,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4970#issuecomment-401503431:1658,Validat,ValidateBasicSomaticShortMutations,1658,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4970#issuecomment-401503431,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,"=================================================; 10:33:06.427 INFO ResourceUtils - No custom resources configured for spark.driver.; 10:33:06.428 INFO ResourceUtils - ==============================================================; 10:33:06.428 INFO SparkContext - Submitted application: SortSamSpark; 10:33:06.446 INFO ResourceProfile - Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 600, script: , vendor: , cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0); 10:33:06.454 INFO ResourceProfile - Limiting resource is cpu; 10:33:06.455 INFO ResourceProfileManager - Added ResourceProfile id: 0; 10:33:06.500 INFO SecurityManager - Changing view acls to: root; 10:33:06.501 INFO SecurityManager - Changing modify acls to: root; 10:33:06.501 INFO SecurityManager - Changing view acls groups to:; 10:33:06.502 INFO SecurityManager - Changing modify acls groups to:; 10:33:06.502 INFO SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 10:33:06.755 INFO Utils - Successfully started service 'sparkDriver' on port 34861.; 10:33:06.784 INFO SparkEnv - Registering MapOutputTracker; 10:33:06.815 INFO SparkEnv - Registering BlockManagerMaster; 10:33:06.827 INFO BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 10:33:06.828 INFO BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up; 10:33:06.831 INFO SparkEnv - Registering BlockManagerMasterHeartbeat; 10:33:06.846 INFO DiskBlockManager - Created local directory at /raid/tmp/d6/c66ba827e22dbc38625af1cbc85adc/tmp/blockmgr-8dc41ac8-6cf4-4424-9b15-7e2cbfc9e538; 10:33:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:41912,Secur,SecurityManager,41912,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['Secur'],['SecurityManager']
Security,"=com.google.protobuf:protobuf-java&package-manager=gradle&previous-version=3.23.4&new-version=3.25.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/gatk/network/alerts). </details>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9004:4437,secur,security,4437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9004,2,"['Secur', 'secur']","['Security', 'security']"
Security,"> @colinhercus I was able to re-run your command successfully on the latest master branch (not in a release yet). I believe PR #6240 fixed the issue. @Rohit-Satyam @danielecook there's a good chance the errors you encountered are also fixed. If not, please let me know. In reference to your reply, I wish to inform you the problem still stands. > java.lang.IllegalArgumentException: Cannot construct fragment from more than two reads; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725); at org.broadinstitute.hellbender.utils.read.Fragment.create(Fragment.java:36); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1376); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:595); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLinePro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643:480,validat,validateArg,480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643,1,['validat'],['validateArg']
Security,> @lbergelson @gokalpcelik any chance of giving me access to the workspace for the 330 whole exomes?. Hi @nalinigans ; Unfortunately this is on my private company server but I may be able to conduct tests if you need me to. I can generate a fork of gatk and update GenomicsDB to test it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2434590689:51,access,access,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2434590689,1,['access'],['access']
Security,"> Another potential solution is to audit every Dataflow (and spark) code that can receive SAMRecords as input, and make sure they call some utility ""putHeadersBack"" function. I agree. I think this is the most practical solution. (Having the coder/serializer do it is difficult, as it's hard to get the header to the serializer, unless it is passed statically, which I think we'd rather avoid.). This would look something like `reads.map(read -> ReadUtils.addHeader(header, read))`, and would be added after every shuffle. Since we should be very aware where every shuffle is happening (and we want to minimize their number) it shouldn't be too onerous. The other related point that Uri has touched on is the need for an efficient encoding of reads (even without the header), which is critical to making the computations run in a reasonable amount of time. The approach I've taken in https://github.com/broadinstitute/hellbender/pull/899 is to use the htsjdk BAMEncoder to serialize reads (Hadoop-BAM does something very similar), and it works very well in my tests of sorting large BAMs. Does https://github.com/broadinstitute/hellbender/pull/899 plus ""putHeadersBack"" sound like a reasonable solution?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141004828:35,audit,audit,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141004828,1,['audit'],['audit']
Security,"> Hi @icemduru Looks like your slurm workload manager was configured to have a limit of 48GBs of maximum process memory size per execution. Your java instance is set with -Xmx45G which will cover most of this limit and leaves only a handful of memory space for the native GenomicsDB library. Native libraries work above the heapsize so it is better for you to set your -Xmx to a more sensible size of 8~12GB and leave rest of the memory space to the native library to use.; > ; > Keep in mind that this memory limit on slurm could be set per user not per task therefore you may need to run a single contig at a time or maybe 2 of them simultaneously. Otherwise slurm may interefere with all the tasks and cancel all your jobs.; > ; > One final reminder. We strongly recommend users to set th; [slurm-22680938.out_text.txt](https://github.com/user-attachments/files/16608314/slurm-22680938.out_text.txt); e temporary directory to somewhere else other than /tmp. Slurm workload manager interferes with this preference and sometimes results in premature termination of the gatk processes due to deletion of extracted native library and accessory files.; > ; > I hope this helps. Thank you for your help, but unfortunately it didn't resolve the issue. I've already tried allocating 10GB of memory using the -Xmx10g flag and redirecting the temporary directory away from /tmp. However, GATK is still attempting to consume more than 48GB of RAM, resulting in the termination of my run.; [slurm-22680938.out_text.txt](https://github.com/user-attachments/files/16608325/slurm-22680938.out_text.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2287941632:1133,access,accessory,1133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2287941632,1,['access'],['accessory']
Security,"> Hm - I don't think we can take that last change. Theres not much use in validating args after they've been used by the constructors. Let me see if there is an alternative. Well in the prior commit I just caught CommandLineException (https://github.com/broadinstitute/gatk/pull/6973/commits/814839f498cda8ce627a47229d77fb6cac7ca6e0), but this seemed hacky. . Why cant there be a separate method to create the class and validate args? . There is VariantEvalEngine.validateAndInitialize(), where some classes do analogous checks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827857883:74,validat,validating,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827857883,3,['validat'],"['validate', 'validateAndInitialize', 'validating']"
Security,"> How do you know ""without affecting sensitivity"" ?. I ran our validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3988#issuecomment-352884724:63,validat,validations,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3988#issuecomment-352884724,1,['validat'],['validations']
Security,"> I don't think we've made any guarantees about the thread safety of Funcotator or the associated datasource classes.; > ; > Also, this account seems to be a bot and I can't access its listed home page…; > ; > I can audit the class at some point. https://codesafe.qianxin.com/#/home",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7376#issuecomment-894740783:174,access,access,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7376#issuecomment-894740783,2,"['access', 'audit']","['access', 'audit']"
Security,"> It gives us the ability to easily aggregate records across multiple FeatureInputs, and (potentially, if we wanted) to retrieve records by type rather than by source. Regardless of doing full injection FeatureContext seems rather unnecessary to me; the query ability that you mention is provided by FeatureManger on which the FeatureContext delegates on given the genomeLoc of the locus or read.... I don't see why the tool cannot be exposed to FeatureManager directly. Is this done to make sure that walkers are of the right type? I mean if you are working on aread walker and you need to look for information beyond the read's genomeLoc that means that you must consider a different walker type or develop a new one?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76763116:193,inject,injection,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76763116,2,"['expose', 'inject']","['exposed', 'injection']"
Security,"> It seems like the patch in 4.1.6 didn't go far enough and that exception needs to be replaced with a continue in all cases. That would work, but I see where I caused the regression upstream. I chopped leading and trailing deletions from haplotype cigars, same as for read cigars, but for haplotypes we want to keep these deletions because the start and end positions need to remain pegged to the reference start and end. I have a fix + regression test branch, which is running on every M2 validation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-609115892:491,validat,validation,491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-609115892,1,['validat'],['validation']
Security,> [...] you need to build within a full git clone of the GATK repository [...]. I build as part of the FreeBSD package build. Package builders can never build from git clones because git clones don't preserve fingerprints and fingerprints are needed to maintain security (repeatability of builds). Could you please consider adding an alternative way of determining of version through a build option?. Packages on all OSes would benefit from this. Thank you.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7143#issuecomment-799722491:262,secur,security,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7143#issuecomment-799722491,1,['secur'],['security']
Security,"? I can take a look a this issue. ---. @vdauwera commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275578721). Oh, they gave me access to the files but I never took the next step of figuring out which files are relevant. There are twenty thousand samples... I'm not sure what is the best way to approach this. ---. @ldgauthier commented on [Wed Mar 01 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-283365248). It would be too computationally expensive and just generally painful to get; that dropped allele. I'd suggest making a unit test with some fake data.; You'll need two positions: one upstream with a deletion to generate the *; and one for the SNP. I think the dropped allele was a 1bp deletion at the; same position that generated the representation with the extra base at the; end. Give that one a really low quality in its gvcf so it gets dropped.; PLs don't really matter as long as they jive with the quals and aren't hom; ref. You can just grab numbers from any other valid vcf. I think you can do; it with three samples: one with the upstream deletion and *, one with the; AC SNP and one with the low quality deletion. Other combinations will; probably also produce the same bug. There may be an even simpler way to reproduce the bug without the low; quality deletion but I suspect this will work. On Jan 26, 2017 10:02 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. Oh, they gave me access to the files but I never took the next step of; figuring out which files are relevant. There are twenty thousand samples...; I'm not sure what is the best way to approach this. —; You are receiving this because you commented. Reply to this email directly, view it on GitHub; <https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275578721>,; or mute the thread; <https://github.com/notifications/unsubscribe-auth/AGRhdKIgGAjH5_n3wlZ0E2A5xw1TeFg1ks5rWV5DgaJpZM4KQT_3>; .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2959:4669,access,access,4669,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2959,1,['access'],['access']
Security,@Bowen1992 I'm not sure I understand exactly what the problem is. . Is this a problem specific to running tools with genomicsDB? ; What is ParaStor? It sounds like some sort of enterprise file system? Is other software fast when writing to ParaStor? I'm sure we'll be able to debug this since I don't think we have access to a similar system.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8546#issuecomment-1758332891:315,access,access,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8546#issuecomment-1758332891,1,['access'],['access']
Security,"@DanishIntizar Hello! Thank you for this pr. This is great to see an official plugin from amazon available. I appreciate that you took the time to make it an optional include. I think if we're going to include it we might as well just add it as one of our normal dependencies though. Assuming there aren't any dependency conflicts it **should** (always a risky statement) be independent from everything else. . Thanks also for identifying the different issues you mentioned. It's expected that it won't work with most picard tools as you discovered, but we're actively in the process of updating more of them too support Paths instead of Files so that will slowly improve. The second issue is more worrisome. We regularly use an equivalent provider with google to read reference files through the exact same code, so I suspect there is either some sort of mismatched assumptions in the way they are handling things. Maybe something strange with the Path.resolve methods or the like. (Or in in the much worse potential case a bug in their look ahead caching.). I'd like to look into that before we'd merge this. Ideally we would have tests for this. Are there any public AWS paths we could read from without any secret authentication?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8672#issuecomment-1930094721:1218,authenticat,authentication,1218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8672#issuecomment-1930094721,1,['authenticat'],['authentication']
Security,"@EdwardDixon Sure, here's my suggested repair process:. 1. If you haven't already, add an ""upstream"" remote to your git clone via `git remote add upstream git@github.com:broadinstitute/gatk.git` (or `https://github.com/broadinstitute/gatk.git` if you don't have ssh authentication set up with github). 2. `git fetch upstream`. 3. Copy the files you actually intended to change in this PR into a temp directory somewhere. 4. Create a new temporary branch off of `upstream/master`: `git checkout -b avxcheck_repaired upstream/master`. 5. Copy the files you saved in step 3 back into their original locations in the working tree. 6. `git commit -a`. 7. Examine the diff against upstream/master via `git diff upstream/master HEAD`. Verify that the diff is what you expect. 8. Run `git rev-parse HEAD` and save the commit ID it outputs. 9. Switch back to the broken version of the branch: `git checkout avxcheck`. 10. Run `git reset --hard commit_id_from_step_8`. This will force the branch to point to the repaired commit we created in step 6. 11. Run `git push -f origin avxcheck:avxcheck` to force-push the repaired version of the branch into your fork. Then check that it looks ok on github. For avoiding this sort of thing in the future, here's a few tips:. * Never run `git merge` or `git pull`. Always update your branch with changes from the latest gatk master branch via the command: `git fetch upstream && git rebase -i upstream/master`, followed by `git push -f` to push the rebased branch into your fork. * If you've never run `git rebase` before, read a tutorial on it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437415495:266,authenticat,authentication,266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437415495,1,['authenticat'],['authentication']
Security,"@Emmalynchen I wouldn't worry about the `log4j:WARN` messages discussed in this thread---they're just harmless annoyances that pop up because we haven't gotten around to making sure the HDF5Library dependency uses the same logger as the rest of the GATK. Looking at your initial post (before you edited it), it looks like DenoiseReadCounts is failing because the panel of normals contains different intervals than those in the read-count collection you are trying to denoise:. ```; 22:50:58.635 INFO SVDDenoisingUtils - Validating sample intervals against original intervals used to build panel of normals...; 22:50:59.487 INFO DenoiseReadCounts - Shutting down engine; [May 7, 2019 10:50:59 PM UTC] org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=894959616; java.lang.IllegalArgumentException: Sample intervals must be identical to the original intervals used to build the panel of normals.; ```. You might try asking for more pointers over in the GATK Forums (https://gatkforums.broadinstitute.org/gatk), if you need them. Good luck!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-491473550:520,Validat,Validating,520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-491473550,1,['Validat'],['Validating']
Security,"@Horneth Ideally we'd just check up-front whether the bucket has requester pays enabled, and specify the user's default project as the billing project if it is. . It would also be good, I think, if we included a toggle that allows the client to tell the library to throw and refuse to proceed if an attempt is made to access requester-pays data, so that users who don't want to incur GCS access charges can get a hard guarantee that they won't.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-394839598:318,access,access,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-394839598,2,['access'],['access']
Security,"@J-Moravec GATK and picard should both handle the same reference files. It typically requires not a gzipped reference, but a bgzipped reference to enable random access ( as I think samtools does as well.). You will need several auxiliary files with the reference. You need the .fai index as well as the .gzi index. . Could you post the stack trace you're receiving as well as additional information about your reference file to help debug the problem you're seeing?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6590#issuecomment-625875092:161,access,access,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6590#issuecomment-625875092,1,['access'],['access']
Security,"@LeeTL1220 @droazen This is ready for review. It modestly improves all of our validations except Dream challenge 4, which I suspect is because the synthetic data doesn't respect mate pairing. To account for that I added an advanced option to turn off mate-awareness. @kachulis Thanks for catching the error in finding fragments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-490599827:78,validat,validations,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-490599827,1,['validat'],['validations']
Security,"@LeeTL1220 @katevoss @ruchim I started exposing all optional task-level parameters in the somatic workflows so that they could be specified via json when the workflows are used as subworkflows. E.g., `CNVSomaticPanelWorkflow.PreprocessIntervals.bin_length` is an optional task-level parameter that can be specified properly via json when `CNVSomaticPanelWorkflow` is the top-level workflow, but not when `CNVSomaticPanelWorkflow` is used as a subworkflow. This is because `MetaWorkflow.CNVSomaticPanelWorkflow.PreprocessIntervals.bin_length` cannot be set, correct?. However, things quickly became very messy. For example, alongside parameters like `bin_length` which are unique to the PreprocessIntervals task, we also have a lot of optional runtime parameters that are named generic things like `mem` which are not. So to expose these, we'd have to have workflow-level parameters with names like `preprocess_intervals_mem`, etc. It seems like this is exactly the problem the expected functionality would solve, if only it worked past the subworkflow level and the namespace is propagated as one would expect. Requiring that these be exposed also partially obviates the reason for having optional task-level arguments in the first place---what's the point of having them be optional if I have to add lines of code to expose all of them at the workflow level?. So again, I'm strongly against exposing all inputs for a particular workflow on the off-chance that that workflow might be used as a subworkflow. This adds a lot of unnecessary boilerplate that quickly gets very messy. I think that this problem should instead be solved by dynamically bubbling up all inputs, optional or required, at all levels. Anyway, I'm not going to try to tackle this before release, which I think was OK with @LeeTL1220. However, after release, I'd be happy to sit down and discuss how we want to do this sort of thing going forward.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3980#issuecomment-355830670:824,expose,expose,824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3980#issuecomment-355830670,3,['expose'],"['expose', 'exposed']"
Security,"@LeeTL1220 Fixed PathSeq test BAMs so that all reads have read groups with an SM tag. This will make them pass the WellFormedReadFilter. To be thorough, I made sure they also check out with ValidateSameFile. The BAMs are now properly sorted, and also I made a small fix so that unmapped mate flags are set properly in the filter tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3206:190,Validat,ValidateSameFile,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3206,1,['Validat'],['ValidateSameFile']
Security,"@LeeTL1220 Having started to implement this. I have a number of design questions that would be informed by your usecases. . Firstly, is there a reason to preserve symbolic alleles? It seems as though spanning deletions could/should be dropped as in most cases there is another variant context representing that deletion elsewhere in your file? Should there be validation around dropping spanning deletion symbolic alleles to ensure we aren't dropping a spanning deletion that isn't represented anywhere else? What about nocalls? . Your example suggests that we rely on the header line counts for subsetting annotations, if there is a disagreement in the header do you want any more sophisticated behavior than just throwing? My understanding is that we are lenient with splitting in htsjdk and there have been some mislabeled header lines in the past that would make this an expected state. Furthermore, most allele specific annotators are of type string because there is no standard for ""|"" delimiters which makes them hard to handle properly. @ldgauthier do you have any suggestions as to how to detect and handle allele specific annotations?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4976#issuecomment-404949363:360,validat,validation,360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4976#issuecomment-404949363,1,['validat'],['validation']
Security,"@LeeTL1220 I have a fast python implementation of the above. It'll take a little bit of additional code to make it output segment files. I can add that and start running some validation data, or I can just go ahead and start coding up the Java implementation, depending on how long you think it'll take to put together some validation runs up through DenoiseReadCounts. Do we want to improve the ReCapSegCaller behind CallSegments while we're at it? @davidbenjamin perhaps you can briefly remind me of the idea behind your initial caller and of the issues it had.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324128827:175,validat,validation,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324128827,2,['validat'],['validation']
Security,"@LeeTL1220 I went ahead and exposed more mem_gb parameters, which is convenient when we want to go below 250bp and the pair WDL is used as a subworkflow. Please review carefully!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4364#issuecomment-363787268:28,expose,exposed,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4364#issuecomment-363787268,1,['expose'],['exposed']
Security,"@LeeTL1220 Latest commit includes the rollback. I will create a separate branch for you that is rebased on sl_preprocess. Looking at it again, I initially described the change to you incorrectly. I thought it was ""similar CR || similar AF -> merge"" to ""similar CR && similar AF -> merge"", but that's not actually the case; it's instead ""similar according to credible interval 1 || similar according to credible interval 2 -> merge"" to ""similar according to credible interval 1 && similar according to credible interval 2 -> merge"". Probably the `&&` behavior is way too conservative, so I think rolling back to the `||` behavior would be fine for release. Let's double check with the validation just to be sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989:684,validat,validation,684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989,1,['validat'],['validation']
Security,"@LeeTL1220 Not sure if you will absolutely need this for HCC1143 WES validation, but just be aware that this change is coming soon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3981#issuecomment-352128732:69,validat,validation,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3981#issuecomment-352128732,1,['validat'],['validation']
Security,"@LeeTL1220 Note that I've validated with womtool, but as we've seen (#4281), changes of this sort (which deal with optional parameters, etc.) may slip through even if tests pass. You should take a careful look to make sure everything is in order!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361293506:26,validat,validated,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361293506,1,['validat'],['validated']
Security,"@LeeTL1220 OK, see the sl_change_model_segments_defaults_rebased branch. For validation, I'd say that sweeping the following should suffice:. Array[Float] kernel_variance_allele_fractions = [0.025, 0.05, 0.25]; Array[Float] smoothing_thresholds_allele_fraction = [2.0, 10.0, 50.0]; Array[Float] smoothing_thresholds_copy_ratio = [2.0, 10.0, 50.0]",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355468401:77,validat,validation,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355468401,1,['validat'],['validation']
Security,"@LeeTL1220 OK, tweaked the message a bit. I think I'm OK with this going in for the next point release. This is the sort of thing for which it will be nice to have the automatic validations, as a sanity check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979:178,validat,validations,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979,1,['validat'],['validations']
Security,@LeeTL1220 The criteria in my opinion are being the best Mutect and being stable. Were you suggesting waiting for some validation like MC3?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365660852:119,validat,validation,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365660852,1,['validat'],['validation']
Security,"@LeeTL1220 This will make it easy to basically re-do the MC3 analysis as if M2 had been there from the beginning. The idea is:. * run M2; * merge M2 variants into MC3; * validate all variants (M2 *and* MC3); * compare all callers on equal footing. It would be nice if there were a barclay annotation for an unsupported feature, but I'm not aware of one. . .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5007:170,validat,validate,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5007,1,['validat'],['validate']
Security,"@LeeTL1220 commented on [Mon Feb 01 2016](https://github.com/broadinstitute/gatk-protected/issues/343). In `CreatePanelOfNormals` make anonymize a flag that defaults to `false`. (i.e. `--anonymize`) In other words, by default, we do _not_ produce an anonymized PoN. We could also use a separate tool that takes a pre-existing PoN and anonymizes it. . To anonymize a PoN:; - [ ] Determine which fields are private. At the very least: `fnt_control_matrix`, `log_normals`, and `log_normals_pinv`. _There may be others -- please investigate as part of this issue_; - [ ] Have `CreatePanelOfNormals` delete the fields as the last step.; - [ ] Make sure that `HDF5PoN` produces reasonable error messages if one of these fields is accessed in an anonymized PoN.; - [ ] Create CLI that can take existing PoN and delete the fields. ---. @LeeTL1220 commented on [Mon Feb 01 2016](https://github.com/broadinstitute/gatk-protected/issues/343#issuecomment-178022285). This is necessary since we may want to share PoNs and the PoN files cannot have any private data. ---. @LeeTL1220 commented on [Wed Mar 02 2016](https://github.com/broadinstitute/gatk-protected/issues/343#issuecomment-191420153). Moving this to later milestone, unless it becomes more urgent.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2835:724,access,accessed,724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2835,1,['access'],['accessed']
Security,"@Ning-310 The error you're getting here (""Did not inflate expected amount"") implies that your input file is likely corrupt. Can you try running the tool `PrintBGZFBlockInformation` to validate the compressed blocks in your `.vcf.gz`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7114#issuecomment-793015796:184,validat,validate,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7114#issuecomment-793015796,1,['validat'],['validate']
Security,@SHuang-Broad what is PipelineOptions needed for ... does one need it to access the reference if it stored in something that is not a ordinary file? (e.g. GS bucket?),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025607:73,access,access,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025607,1,['access'],['access']
Security,"@Sun-shan Hi, could you try running with the `--disable-sequence-dictionary-validation` command?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112#issuecomment-357043845:76,validat,validation,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112#issuecomment-357043845,1,['validat'],['validation']
Security,"@Tintest Sorry for the slow reply. I'm not sure exactly what the issue is. I've never seen this exact error before. . I have two guesses, one is that there's something really weird going on in spark that's causing that null pointer exception which is killing the heartbeat. I'm not sure how to debug that without your access to your input data . The other theory which I think is more likely, is that you're running out of memory and it's causing weird errors to occur. How much memory is available to your job? You can set the java -Xmx value with `--java-options ""-Xmx120g""` as a GATK option. I would check that you're not running out of memory on your machine, or giving the job too little. I think for BaseRecalibratorSpark you want at least 2-4g per core, but haven't tested it in a long time so I might be wrong about that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134:318,access,access,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134,1,['access'],['access']
Security,"@WanessaMGoes It looks like most/all of your reads are getting filtered out by GATK's `WellformedReadFilter`:. ```; 17:07:23.141 INFO DepthOfCoverage - 1031666 read(s) filtered by: WellformedReadFilter; ```. Could you try running `ValidateSamFile` on your bam, and paste the result here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7332#issuecomment-882767886:231,Validat,ValidateSamFile,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7332#issuecomment-882767886,1,['Validat'],['ValidateSamFile']
Security,@Zepeng-Mu There seems to be an unsupported character in your reference fasta. Can you verify the integrity hash of your reference? Could you also try re-generating the fasta index using `samtools faidx`?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911#issuecomment-716737017:98,integrity,integrity,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911#issuecomment-716737017,2,"['hash', 'integrity']","['hash', 'integrity']"
Security,"@ahaessly Could you please take a look at this? We had a request to change this argument which wasn't previously possible since it was hardcoded into the WDL task. Ideally I'd like to expose all of the arguments but even wiring this one through the imported WDL was annoying. I tried making it an input to the task with a value like this:. ```; task M2 {; input {; Int max_reads_arg = 75; }; ...; ```; which looks a lot cleaner (don't have to make sure you wire it through from the main inputs), but when I looked in Terra it didn't actually expose the argument (I'm assuming because the M2 task is in a sub-workflow). Any thoughts on how to make this better so I can expose everything? Or is this the best way to do that at the moment?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6739:184,expose,expose,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6739,3,['expose'],['expose']
Security,"@akiezun @pgrosu I'd be very hesitant to make such a radical change to the internals of the tool at the same instant we're trying to validate BQSR for production use (https://github.com/broadinstitute/gatk/issues/1413). BAQ doesn't use `NestedIntegerArray`, anyway -- `NestedIntegerArray` is used for the recal tables themselves.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-180664239:133,validat,validate,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-180664239,1,['validat'],['validate']
Security,@akiezun Done. Could you give the user **coveralls** pull access to the repo so it can write into the pull requests?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/79#issuecomment-68935893:58,access,access,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/79#issuecomment-68935893,1,['access'],['access']
Security,"@akiezun In the settings I think you can give individual users access to the repo. I don't it ever got ticked for recapseg, so it's _not_ making comments on the pull requests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/79#issuecomment-69066246:63,access,access,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/79#issuecomment-69066246,1,['access'],['access']
Security,"@akiezun back to you with a comment. <!-- Reviewable comment -K2OCrEDRCLfJof_Cdgp:-1160907455 -->. ---. Reviewed 2 of 2 files at r1.; Review status: all files reviewed at latest revision, 2 unresolved discussions. ---. <sup>**[src/main/java/org/broadinstitute/hellbender/engine/datasources/ReferenceAPISource.java, line 155 [r1]](https://reviewable.io:443/reviews/broadinstitute/gatk/1058#-K2OAVk5uR5BT7DB8ujU)** ([raw file](https://github.com/broadinstitute/gatk/blob/a5c03b9e93125bf1acd9e9969a81f236a128ee6d/src/main/java/org/broadinstitute/hellbender/engine/datasources/ReferenceAPISource.java#L155)):</sup>; Should this be a `UserException`? It seems like it's probably a bug in the calling code if it's going off the end of a contig, unless you think the likely path is that they've specified the wrong reference. In either case, I think the message should mention that fewer bases were retrieved than requested in addtion to displaying the interval. It might be worth making this a more specific exception subclass too, I can imagine potential situations where people would want to catch and handle this differently. . <!-- Reviewable comment -K2OAVk5uR5BT7DB8ujV:-2111080668 -->. ---. <sup>**[src/test/java/org/broadinstitute/hellbender/engine/datasources/ReferenceAPISourceUnitTest.java, line 170 [r1]](https://reviewable.io:443/reviews/broadinstitute/gatk/1058#-K2OCQKoj0hZv86WbYXu)** ([raw file](https://github.com/broadinstitute/gatk/blob/a5c03b9e93125bf1acd9e9969a81f236a128ee6d/src/test/java/org/broadinstitute/hellbender/engine/datasources/ReferenceAPISourceUnitTest.java#L170)):</sup>; It would be nice if this were more specific so we can be sure the test isn't passing accidentally due to a failed authentication or downed webserver. <!-- Reviewable comment -K2OCQKpe3Ja-0PPUKjV:775526476 -->. ---. Comments from the [review on Reviewable.io](https://reviewable.io:443/reviews/broadinstitute/gatk/1058). <!-- Sent from Reviewable.io -->",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1058#issuecomment-154172680:1715,authenticat,authentication,1715,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1058#issuecomment-154172680,1,['authenticat'],['authentication']
Security,"@akiezun so my approach here is to stream through to build a histogram on bins 0, ..., 250. I can spin my own median function on a histogram, but it seems that Tim has already written a histogram class below in htsjdk.samtools.util that computes percentiles, mean, etc... I think it'd make sense to use something like this in general rather than locally replicating methods for common statistics on histograms. How to proceed? His class expects the histogram as a sortedMap (I was just using an array from 0 to 250). package htsjdk.samtools.util;. import htsjdk.samtools.util.Histogram.Bin;. /**; - Class for computing and accessing histogram type data. Stored internally in; - a sorted Map so that keys can be iterated in order.; *; - @author Tim Fennell; */; public class Histogram",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/540#issuecomment-115278716:623,access,accessing,623,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/540#issuecomment-115278716,1,['access'],['accessing']
Security,@akiezun this will sound dumb because you'd assume i have access to the internal infrastructure but i've been All Cloud since I got here. Are these files at these locations on the Isilon or do they reside elsewhere?. ```; bamIn=/dsde/working/akiezun/data/CEUTrio.HiSeq.WEx.b37.NA12892.bam; vcfIn=/dsde/working/akiezun/data/dbsnp_138.b37.excluding_sites_after_129.vcf; refIn=/dsde/working/akiezun/data/human_g1k_v37.fasta; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-227226948:58,access,access,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-227226948,1,['access'],['access']
Security,@alanhoyle Can you tell us whether the 400 Bad Request error is repeatable -- did you see it more than once? Oftentimes when accessing cloud data we encounter transient errors like this that go away on their own.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-724225557:125,access,accessing,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-724225557,1,['access'],['accessing']
Security,"@ashwini06 . This bam appears to be malformed and it fails Picard ValidateSamFile. I think you'll need to examine the earlier stages of your pipeline that produce your bam to ensure you get a correctly formed bam. I'm going to close this ticket now since this doesn't appear to be an issue with Mutect2. (base) wm462-624:Downloads fleharty$ java -jar $PICARD ValidateSamFile I=concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam ; INFO	2020-07-14 11:25:52	ValidateSamFile	. ********** NOTE: Picard's command line syntax is changing.; **********; ********** For more information, please see:; ********** https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition); **********; ********** The command line looks like this in the new syntax:; **********; ********** ValidateSamFile -I concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam; **********. 11:25:52.673 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/fleharty/resources/picard.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Jul 14 11:25:52 EDT 2020] ValidateSamFile INPUT=concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam MODE=VERBOSE MAX_OUTPUT=100 IGNORE_WARNINGS=false VALIDATE_INDEX=true INDEX_VALIDATION_STRINGENCY=EXHAUSTIVE IS_BISULFITE_SEQUENCED=false MAX_OPEN_TEMP_FILES=8000 SKIP_MATE_VALIDATION=false VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Jul 14 11:25:52 EDT 2020] Executing as fleharty@wm462-624 on Mac OS X 10.15.5 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_191-b12; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.20.4-SNAPSHOT; WARNING	2020-07-14 11:25:52	ValidateSamFile	NM validation cannot be performed without the reference. All other validations will still occur.; ERROR: Record 18321, Read name U",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:66,Validat,ValidateSamFile,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,4,['Validat'],['ValidateSamFile']
Security,"@asmirnov239 commented on [Fri Apr 21 2017](https://github.com/broadinstitute/gatk-protected/issues/1000). Right now if a user disables MAPPED filter, which is a default filter for CalculateTargetCoverage tool, it will fail with the following uninformative exception (unless somehow all reads are mapped):; ```; java.lang.IllegalArgumentException: the input location cannot be null; 	at org.broadinstitute.hellbender.utils.Utils.nonNull(Utils.java:549); 	at org.broadinstitute.hellbender.tools.exome.HashedListTargetCollection.indexRange(HashedListTargetCollection.java:152); 	at org.broadinstitute.hellbender.tools.exome.CalculateTargetCoverage.apply(CalculateTargetCoverage.java:298); ```; We should guard against it and throw an exception before the traversal starts if MAPPED filter is disabled. ---. @asmirnov239 commented on [Fri Apr 21 2017](https://github.com/broadinstitute/gatk-protected/issues/1000#issuecomment-296295294). Since there is no direct API call to access the list of resolved filters(after command line parsing) this bug fix will have to wait until [broadinstitute/barclay#38](https://github.com/broadinstitute/barclay/pull/38) is merged",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2976:500,Hash,HashedListTargetCollection,500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2976,3,"['Hash', 'access']","['HashedListTargetCollection', 'access']"
Security,@asmirnov239 commented on [Thu Sep 29 2016](https://github.com/broadinstitute/gatk-protected/issues/727). Here is the stack trace:. ```; java.lang.IllegalArgumentException: the 'to' index must be between 'from' and the length of the data/position sequence; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:609); at org.broadinstitute.hellbender.utils.param.ParamUtils.inRange(ParamUtils.java:80); at org.broadinstitute.hellbender.utils.hmm.ForwardBackwardAlgorithm$Result.logProbability(ForwardBackwardAlgorithm.java:141); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.lambda$calculateLog10GP$6(GenotypeCopyNumberTriStateSegments.java:197); at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:506); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.calculateLog10GP(GenotypeCopyNumberTriStateSegments.java:198); at org.broadinstitute.hellbender.tools.exome.germlinehmm.GenotypeCopyNumberTriStateSegments.lambda$composeVariantContext$0(GenotypeCopyNumberTriStateSegments.java:125); at java.util.stream.IntPipeline$4$1.accept(IntPipeline.java:250); at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110); at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSeq,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2898:302,validat,validateArg,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2898,1,['validat'],['validateArg']
Security,"@asmirnov239 looks like you are getting an NPE---remember that intervals are resolved after argument validation, so you need to do the check later. Also, good point, I think you can get a singleton after scattering if you get unlucky with your shards. ; Perhaps change the check to a filtering step in GermlineCNVCaller?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6559#issuecomment-617310137:101,validat,validation,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6559#issuecomment-617310137,1,['validat'],['validation']
Security,"@bbimber - here some answers:. * The `LocusWalker` in the GATK4 framework provides the traversal over each locus, and provides the information for the reference (`ReferenceContext`) and the pileup (`AlignmentContext`). I guess that this is similar to a rod-walker in the previous framework if a `FeatureInput` is present (accessed by the `FeatureContext`); * The apply function params are never null, but they may be empty. The reference context could be tested if it is empty by using `hasBackingDataSource()`. Other contexts can be tested with other methods to check if they are empty.; * For auto-discovery of feature inputs, mark the field with `FeatureInput<>` for the type of feature that you want; if you require more than one, a list of `FeatureInput` can be provided. Then, the features for the feature class can be retrieved from the `FeatureContext` on the apply function.; * For argument exceptions, use the ones in `UserException` or `CommandLineProgramException`, depending on which one fits better on your use case... If you wanna check an example of a locus walker with features, see [`ExampleLocusWalker`](https://github.com/broadinstitute/gatk/blob/4ef87ca10c3b57af76d829995e532c279b17cff2/src/main/java/org/broadinstitute/hellbender/tools/examples/ExampleLocusWalker.java). I hope that it helps!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-337598527:322,access,accessed,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-337598527,1,['access'],['accessed']
Security,"@bbimber Hmn, yeah, think it needs someone who has direct write access. I'll get a thumb from a teammate. Thanks for looking at it and for the pr!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8752#issuecomment-2023092567:64,access,access,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8752#issuecomment-2023092567,1,['access'],['access']
Security,"@bbimber I was hoping this could be reduced to a single new `File, PedigreeValidationType` constructor overload, and the new `File` getter (and without any changes to the existing subclasses). Its also not a perfect solution, but I'd prefer to minimize addition of any new methods that expose founderIDs or SampleDB, since we aspire to factor out the existing code that uses those from this class completely. As for the failed test, it looks like the tests timed out for some reason, hopefully transient, but it I'm guessing its unrelated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-855914785:286,expose,expose,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-855914785,1,['expose'],['expose']
Security,"@bbimber Thanks -- I think we'll upload the files to a public Google storage bucket instead, to avoid the need for sharing passwords out in the open like this. We should be able to get to this after the GATK point release goes out tomorrow. I'll make a post here once they're uploaded.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-360580547:123,password,passwords,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-360580547,1,['password'],['passwords']
Security,"@bbimber We just added full versions of the B37 and HG38 references to the repo a couple of days ago. You'll have to rebase this branch on current master to access them, but it might make it easier to port some of the GATK3 tests that use b37.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-430743842:157,access,access,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-430743842,1,['access'],['access']
Security,@beginner984 Could you explain what is happening in greater detail. I assume you mean that the .bam file was totally empty without even a header? Are you sure the task ran to completion? Do you have to command line output from the tool anywhere? What version of gatk are you running off of? Are you sure that the input file involved passes validation? . I would suggest that you direct this and other questions of this nature to the [gatk forums](https://gatkforums.broadinstitute.org/gatk/categories/gatk-support-forum). There are people on there who can help you get your tools up an running with the gatk and its tools and might have answers to your problem. Thank You.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1394#issuecomment-474026929:340,validat,validation,340,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1394#issuecomment-474026929,1,['validat'],['validation']
Security,"@bensprung So I thought this would be a trivial change. It turns out that encoding the Genotype as something like `1/1` is done way down in the depths of the VCF encoder and isn't exposed in an accessible way. It's going to need a (hopefully simple) change to the underlying htsjdk library to expose that machinery. It shouldn't be hard, it just means it will take a bit longer to get to than I expected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8160#issuecomment-1397695685:180,expose,exposed,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8160#issuecomment-1397695685,3,"['access', 'expose']","['accessible', 'expose', 'exposed']"
Security,"@bhanugandham To get around this issue, the user can run `ValidateVariants` with the `--validation-type-to-exclude ALLELES` argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630#issuecomment-640713793:58,Validat,ValidateVariants,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630#issuecomment-640713793,2,"['Validat', 'validat']","['ValidateVariants', 'validation-type-to-exclude']"
Security,"@bshifaw related to what Sam was saying - we also have a few standard resources needed to run the workflows that we would like to share with users. What is the standard procedure for doing so? Ideally they would be bundled with featured workspaces, but also accessible from outside of Terra",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-506504159:258,access,accessible,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-506504159,1,['access'],['accessible']
Security,"@byoo The easiest thing would be if you can upload it to google cloud and make it publicly visible. Then we can copy it over and you can delete it. Or if you can share your google account name I can grant you upload permission on a bucket we own. (If you want to not publish it to the world you can email it to me louisb@broadinstitute.org ) . Alternatively, if you can't use google cloud, you could upload it to the gatk ftp site. See this article here about how to connect to upload: https://gatkforums.broadinstitute.org/gatk/discussion/1215/how-can-i-access-the-gsa-public-ftp-server.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465237693:555,access,access-the-gsa-public-ftp-server,555,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465237693,1,['access'],['access-the-gsa-public-ftp-server']
Security,"@chandrans I don't have access to dsde-docs so I can't see the ticket/test files (we asked @vdauwera to give me access last week for a different issue, but I don't have it yet).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4525#issuecomment-377963524:24,access,access,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4525#issuecomment-377963524,2,['access'],['access']
Security,"@chapmanb We were able to reproduce a failure with your command line. This looks like an issue related to JNI and garbage collection that is exposed by setting `-Xmx46965m` and `-XX:+UseSerialGC`, but it needs further debugging. To confirm, can you please try running without specifying these javaOptions? Something like this:; ```; ./gatk-launch --javaOptions '-Djava.io.tmpdir=$TEMP_DIR' \; ApplyBQSRSpark \; --sparkMaster local[16] \; --input $BAM_IN \; --output $BAM_OUT \; --bqsr_recal_file $BQSR_RECAL \; -- \; --conf spark.local.dir=$SPARK_LOCAL_DIR; ```. FYI, we see better performance from Spark when using an SSD for spark.local.dir. The `--conf ` option above shows how to set the spark.local.dir.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-332370070:141,expose,exposed,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-332370070,1,['expose'],['exposed']
Security,"@cmnbroad : first - would it be possible to kick off travis tests? i refactored this and dont seem to be able to do that. Second, yes, I was trying to reorder and condense the commits but clearly didnt work. I think the problem was trying to put your GATK3 commit first (which would seem to make sense). in any case, I just recreated this, putting a pristine GATK3 first, following a consolidated set of my commits with 1) the limited core changes, 2) the meat of the VariantEval port, and 3) A separate commit with a port of GATK3 VariantEvalIntegrationTest which is useful for validation but should not be merged. To your points:. 1) I substantially cut down the incoming large files, mostly by limiting the intervals of new large VCFs. 2) On the plugin: this was discussed above, and I initially also pointed out this should ultimately go into Barclay. You are actually the one who proposed staging it in GATK. I am not entirely sure I understand the reticence on plugins; however, my goal is to get VariantEval ported by touching as little of it as possible. This is already sucking up a ton of time. I flipped VariantEvalUtils to gather a list of classes from the appropriate package instead of a full-on plugin. That should satisfy that concern?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431913735:579,validat,validation,579,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431913735,1,['validat'],['validation']
Security,@cmnbroad @SHuang-Broad . The cluster uses Kerberos for authentication. This style of pathname works for reading the cram file which is on the hdfs file system. . Using the hadoop shell works fine.... ; hadoop fs -ls hdfs:///project/casa/gcad/adsp.cc; Found 2 items; drwxrwxr-x - zhucc casa 0 2018-04-27 14:59 hdfs:///project/casa/gcad/adsp.cc/cram; drwxrwxr-x - farrell casa 0 2018-05-08 15:21 hdfs:///project/casa/gcad/adsp.cc/sv. When I change this to a local file a similar error occurs. The program runs for 40 plus minutes and then gets the following error. . ```; 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 92.0 in stage 13.0 (TID 68093) in 1108 ms on scc-q01.scc.bu.edu (executor 24) (101/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 101.0 in stage 13.0 (TID 68102) in 1061 ms on scc-q01.scc.bu.edu (executor 6) (102/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 34.0 in stage 13.0 (TID 68035) in 1653 ms on scc-q01.scc.bu.edu (executor 24) (103/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 44.0 in stage 13.0 (TID 68045) in 1553 ms on scc-q07.scc.bu.edu (executor 7) (104/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 63.0 in stage 13.0 (TID 68064) in 1362 ms on scc-q01.scc.bu.edu (executor 24) (105/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 102.0 in stage 13.0 (TID 68103) in 1057 ms on scc-q07.scc.bu.edu (executor 7) (106/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 39.0 in stage 13.0 (TID 68040) in 1604 ms on scc-q06.scc.bu.edu (executor 23) (107/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 5.0 in stage 13.0 (TID 68006) in 2015 ms on scc-q01.scc.bu.edu (executor 24) (108/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 10.0 in stage 13.0 (TID 68011) in 1928 ms on scc-q06.scc.bu.edu (executor 23) (109/116); 2019-05-19 19:09:41 INFO TaskSetManager:54 - Finished task 15.0 in stage 13.0 (TID 68016) in 1865 ms,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590:56,authenticat,authentication,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590,1,['authenticat'],['authentication']
Security,"@cmnbroad @lbergelson The cram index looks like it has all the info required to generate the splits without using the CramContainerIterator to look at the cram file directly. . Could using the crai index for splits be a potential solution to the glacially slow cram split generation? ; ; CRAM index. A CRAM index is a gzipped tab delimited file containing the following columns:; 1. Sequence id; 2. Alignment start; 3. Alignment span; 4. **Container start byte offset in the file**; 5. Slice start byte offset in the container data (‘blocks’); 6. Slice bytes; Each line represents a slice in the CRAM file. Please note that all slices must be listed in index file. In Hadoop-bam this code could read the crai instead of the cram to find the container boundaries. public List<InputSplit> getSplits(List<InputSplit> splits, Configuration conf); throws IOException {; // update splits to align with CRAM container boundaries; List<InputSplit> newSplits = new ArrayList<InputSplit>();; Map<Path, List<Long>> fileToOffsets = new HashMap<Path, List<Long>>();; for (InputSplit split : splits) {; FileSplit fileSplit = (FileSplit) split;; Path path = fileSplit.getPath();; List<Long> containerOffsets = fileToOffsets.get(path);; if (containerOffsets == null) {; containerOffsets = getContainerOffsets(conf, path);; fileToOffsets.put(path, containerOffsets);; }; long newStart = nextContainerOffset(containerOffsets, fileSplit.getStart());; long newEnd = nextContainerOffset(containerOffsets, fileSplit.getStart() +; fileSplit.getLength());; long newLength = newEnd - newStart;; if (newLength == 0) { // split is wholly within a container; continue;; }; FileSplit newSplit = new FileSplit(fileSplit.getPath(), newStart, newLength,; fileSplit.getLocations());; newSplits.add(newSplit);; }; return newSplits;; }",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699:1024,Hash,HashMap,1024,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699,1,['Hash'],['HashMap']
Security,"@cmnbroad After thinking about this I went ahead and created VariantEvalEngine. Doing this in one PR will simplify some of the sticking points around what is a final change vs. what it expected to be fixed later. With this change, the goal is to strip most logic from VariantEval into the engine. This engine can be constructed with a VariantEvalArgumentCollection, and any kind of GATKTool as the owner. I tried to minimize the amount of context the VariantEvalEngine needed to hang on to. This means all the child classes have visibility on the VariantEvalEngine, but are no longer directly exposed to either the walker class or the argument collection. . All the logic around gathering the arguments to form DrivingVariants is moved to a static method in VariantEvalEngine. . I also rebased and fixed conflicts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-750428516:593,expose,exposed,593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-750428516,1,['expose'],['exposed']
Security,"@cmnbroad Could you take a quick look at this again when you get a chance? I changed a few things in the untested methods to respond to @magicDGS's comments, but since they're so important and basically untested I think it would be good for someone to scan them. I change the behavior of failing customCommandLineValidation to always throw, so it's consistent failing regular command line validation as well. I also fixed some comment formatting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2340#issuecomment-275150232:389,validat,validation,389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2340#issuecomment-275150232,1,['validat'],['validation']
Security,"@cmnbroad I cleaned up some of the hashes and was able to create the conda environment locally. Can you try on your mac? We'll see if tests pass on Travis as well, then merge if all is good.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355647907:35,hash,hashes,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355647907,1,['hash'],['hashes']
Security,@cmnbroad I have added a validation/warning step to the pedigree annotations. It suffers from the issue where specifying both possibleDenovo and one of the other ped annotations will not affect warning between annotations. Since I'm choosing to only spit out warnings to the user this should probably be acceptable.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-466118658:25,validat,validation,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-466118658,1,['validat'],['validation']
Security,"@cmnbroad I saw your comment in https://github.com/broadinstitute/gatk/pull/7822. I'm trying to add WDL validation here, using the infrastructure in gradle. I was interested here in just validating the WDLs in the scripts directory.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7826#issuecomment-1116666702:104,validat,validation,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7826#issuecomment-1116666702,2,['validat'],"['validating', 'validation']"
Security,"@cmnbroad I started down this road. i wanted to make sure i follow your reasoning on some of this. I think you propose to change the tool arguments such that each input VCF is tagged by name (like -V:eval vcf1.vcf.gz -V:comp vcf2.vcf.gz), instead of different argument names. This is paired with a change to set the 'source' on each VariantContext to match the name of the source feature context. Unless I'm missing something, this basically makes everything identified by strings, with no direct FeatureInput <-> VariantContext reference, right? . Presumably, MultiVariantWalkerGroupedOnStart could implement something like:. protected Map<FeatureInput<VariantContext>, List<VariantContext>> groupVariantsByFeatureInput(List<VariantContext> variants) {; Map<String, FeatureInput<VariantContext>> sourceMap = new HashMap<>();; getDrivingVariantsFeatureInputs().forEach(x -> sourceMap.put(x.getName(), x));; ; Map<FeatureInput<VariantContext>, List<VariantContext>> ret = new HashMap<>();; variants.forEach(vc -> {; FeatureInput<VariantContext> fi = sourceMap.get(vc.getSource());; if (fi == null) {; //possibly throw? ; }; ; List<VariantContext> l = ret.getOrDefault(fi, new ArrayList<>());; l.add(vc);; ret.put(fi, l);; }); ; ; return ret;; }",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5439#issuecomment-730532600:813,Hash,HashMap,813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5439#issuecomment-730532600,2,['Hash'],['HashMap']
Security,"@cmnbroad I updated VariantQC and identified one minor difference in behavior associated with VariantEvalEngine. Contig stratification assigns level based on all the contigs. If user-supplied contigs are given, it should defer to these. This PR addresses this, and adds a test case. Note: I put the getContigNames() method into VariantEvalEngine, but it would also be possible to keep this in Config, but expose a getter for userSuppliedIntervals. It seemed marginally better to keep that private.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7238:405,expose,expose,405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7238,1,['expose'],['expose']
Security,@cmnbroad I would harmonize the `PicardCommandLineProgram` option name with the `GATKTool` name. Possibly it should be extracted into a Validation stringency argument collection that can be used in both places.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1439#issuecomment-175158837:136,Validat,Validation,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1439#issuecomment-175158837,1,['Validat'],['Validation']
Security,"@cmnbroad OK - what about this proposal? I just added a protected getter and fixed the typo in 'annotation'? We could expose a constructor based way to set PedigreeValidationType, but if you dont really want to expose more of the guts of PedigreeAnnotation to subclasses prior to splitting apart founderIds and pedigree, what about keeping this as simple and minimal as possible?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-855970929:118,expose,expose,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-855970929,2,['expose'],['expose']
Security,"@cmnbroad OK, considerable progress here. I was able to adjust behavior such that only two tests have changed behavior from GATK4/master. I think this is now correct. One instance of changed behavior is the Snpeff/overlap one we discussed above. The second is the one where we now provide the full genome as REF, not the truncated genome. I think this difference is justified since the tool now requires a reference, and the prior version was arguably too lenient on validation of contigs. Anyway, this branch now also removes by debugging code and comments. I think it is ready for a review. To some other questions you had above:. 1) The HashMap<FeatureInput<VariantContext>, HashMap<String, Collection<VariantContext>>> can be wrapped in a class with just a couple of methods, so we don't have to manifest that long type all over the place. I realize that's non-optimal, but this isnt anything I introduced here. I would really like to keep this PR as limited as we can, and address some larger refactoring in a different PR, once we've migrated to MultiVariantWalkerGroupedOnStart. 2) I know this PR still in an interim state, but passing the VariantWalker in as an argument to the comp methods doesn't seem like a step forward to me. If we can't solve that problem completely in this PR (which is fine, I'm all for trying to contain this), are those changes necessary ? Perhaps that part should just wait for the next round. As noted above, I'd like to propose this as iterative, with a second PR coming soon. I did this b/c it moved us toward not needing to pass around the walker. It minimizes the code that has access to the walker (as opposed to setting it after creating the instance of the Evaluator, etc. Yes, it exposes it for two methods, but those classes no longer hang on to it. I would like to ultimately remove this entirely. 3) To re-iterate testEvalTrackWithoutGenotypesWithSampleFields: the input file, noGenotypes.vcf, has a header dictionary with the full set of contigs, and a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747619130:467,validat,validation,467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747619130,3,"['Hash', 'validat']","['HashMap', 'validation']"
Security,"@cmnbroad Sorry to bug here, but I am wondering if it would be possible for someone to review. This is a limited change that basically consolidates some internal code in PedigreeAnnotation and exposes a couple protected getters. Tests are passing. Thanks in advance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-853234849:193,expose,exposes,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-853234849,1,['expose'],['exposes']
Security,"@cmnbroad Thank you for pointing out those build failures and even digging down to the apparent cause! I investigated and the issue wasn't inability to decompress gzip files (or at least wasn't only that), but XReadLines trims the lines by default and my code doesn't. The ""expected"" files have an extra tab at the end of some lines (the CHROM line for example) that this was picking up. What I've done is updated XReadLines so it can take Paths as input, so we get good matching behavior without having to duplicate code. While I was at it I also exposed XReadLines' ability to strip out comments, so assertEqualTextFiles didn't need to re-implement it anymore. Assuming Travis passes, this should be ready to review. I have the feeling we're getting close!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456919065:548,expose,exposed,548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456919065,1,['expose'],['exposed']
Security,"@cmnbroad Thank you so much for the reply. I don't have a small test case for you, but I can provide some other information.; It is RNA seq data and passes validation check (`java -jar picard.jar ValidateSamFile I=S3_2.unmapped.split.bam MODE=SUMMARY`).; BaseRecalibrator cmd:; `gatk BaseRecalibrator -R Homo_sapiens_assembly38.fasta -I S3_2.unmapped.split.bam --use-original-qualities -O S3_2.unmapped.recal_data.csv -known-sites Homo_sapiens_assembly38.dbsnp138.vcf -known-sites Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --known-sites Homo_sapiens_assembly38.known_indels.vcf.gz`; ApplyBQSR cmd:; `gatk ApplyBQSR -R Homo_sapiens_assembly38.fasta -I S3_2.unmapped.split.bam -O S3_2.unmapped.aligned.duplicates_marked.recalibrated.bam -bqsr S3_2.unmapped.recal_data.csv --add-output-sam-program-record --use-original-qualities`; RecalTables in S3_2.unmapped.recal_data.csv are empty. Here is the screen dump of BaseRecalibrator and ApplyBQSR.; BaseRecalibrator; ```; Using GATK jar <XXX>/gatk-4.1.4.1-83-g031c407-SNAPSHOT/gatk-package-4.1.4.1-83-g031c407-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar <XXX>/gatk-4.1.4.1-83-g031c407-SNAPSHOT/gatk-package-4.1.4.1-83-g031c407-SNAPSHOT-local.jar BaseRecalibrator -R Homo_sapiens_assembly38.fasta -I S3_2.unmapped.split.bam --use-original-qualities -O S3_2.unmapped.recal_data.csv -known-sites Homo_sapiens_assembly38.dbsnp138.vcf -known-sites Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --known-sites Homo_sapiens_assembly38.known_indels.vcf.gz; 23:39:34.668 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:<XXX>/gatk-4.1.4.1-83-g031c407-SNAPSHOT/gatk-package-4.1.4.1-83-g031c407-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 26, 2020 11:39:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6242#issuecomment-592005237:156,validat,validation,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6242#issuecomment-592005237,2,"['Validat', 'validat']","['ValidateSamFile', 'validation']"
Security,"@cmnbroad rebasing is done. To summarize changes since your last review:. - I backed out the earlier changes to FeatureInput/FeatureDataSource in favor of those from #7219 ; - I dont entirely know why this didnt hit before, but I made an update to VariantStratifiers to make tests pass. See: https://github.com/broadinstitute/gatk/pull/6973/commits/1569a909d3dc2301337e46441cc0cd969843c8d1. The gist is that we now instantiate those classes and pass VariantEvalEngine. Two of these classes had validation in their constructors, and could throw a CommandLineException if the tool was executed with bad arguments. This exception was getting caught and re-thrown as GATKException with the misleading message ""Problem making an instance of ...."". This proposal is to make a separate VariantStratifier.validateArgs() method, with a default no-op validation, and to call this only after instantiation. This was already exercised under the tests, such as testMultipleEvalTracksAlleleCountWithoutMerge(). VariantEval tests pass locally for me. With luck, tests will pass here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827805993:494,validat,validation,494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827805993,3,['validat'],"['validateArgs', 'validation']"
Security,"@cmnbroad 👍 to adding an advanced command line option for it. . @magicDGS Our goal is to make it unnecessary for normal users to ever need to see a stacktrace. We're definitely not at the point yet where every UserException produces either a) the complete information necessary to debug, or even b) the correct information. We're trying to fix all those cases, but there's a lot of possible failure modes between cloud access, spark, filesystem plugins, etc, so it's going to be an issue for a while. . I don't think it will hurt the user experience to have an extra commandline argument for it. Printing the stacktrace when debug is on isn't a bad idea, but I think it's better to have finer grained control over it. . The other issue is that it's easier to explain to an unsophisticated user how to set an extra commmand line argument rather than trying to get them to set the environment variable which well be helpful for our support team when they're trying to debug someone's problem. (especially since setting the environment variables may be different on a spark cluster than on a local run).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285390394:419,access,access,419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285390394,1,['access'],['access']
Security,"@cmnbroad, I'm thinking about a use case for no filters allowed for the user of the tool. Imagine that you want to pull down some evidence for discordant read pairs (for instance, for SV), and the user provides a read filter which removes this kind of signatures. Could it be possible to generate an interface for the `ReadFilterArgumentCollection` and implementations for no-exposed/exposed to the final user?. This will be similar to the optional/required arguments for reads, reference and so on...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225941325:376,expose,exposed,376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225941325,2,['expose'],['exposed']
Security,"@cmnbroad, sorry for the delayed response. I was in Taiwan giving a workshop last week and then I fell ill (run of the mill cold virus). The Comms team has been migrating issue tracking to a new system on Monday.com, which I am just now familiarizing myself to as I have been occupied with Taiwan workshop preparation. Forum questions are tracked in a separate system, Zendesk. The SOPs towards handling work for the two different systems are still under development so the best way to ensure you are up to date with the progress of work is to contact Robert @rcmajovski. The previous GitHub board that we used at https://github.com/broadinstitute/dsde-docs is still up and I still have my issue tickets here as I haven't had a chance to migrate these. . I do not know if you have access, but here is the link to track the issue ticket on Monday.com:; https://dsp-comms.monday.com/boards/145112271/. Just to orient you, if you click on the issue, a sideboard slides out from the right and you can comment on the work:; ![screenshot 2018-12-13 22 51 00](https://user-images.githubusercontent.com/11543866/49982483-c0040b80-ff2a-11e8-99a5-b6aae33d0311.png). It seems I've been assigned to update these documents. I'm unfamiliar with JEXL itself. I will survey the work that needs to be done and let you know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5422#issuecomment-447206700:781,access,access,781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5422#issuecomment-447206700,1,['access'],['access']
Security,"@cwhelan I was actually debating with myself about whether to include the initialization script here, as it was living in the bucket referred to in the creation script.; So we could do this:; always store the initialization script locally with the creation script instead of referring to a script living remotely, and makes that a required argument. The good: this makes it easier to track changes; The bad: initialization script must be removed from the bucket to avoid tracking possible different versions. A non-technical issue: we are ""delivering"" SGA in the initialization script, if that comes in to this repo, legal might have a problem with it. On the other hand, if the initialization script lives in a place only we can access, we are ""installing SGA for our own use"", which is not a problem with the GPL license.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2435#issuecomment-285093289:730,access,access,730,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2435#issuecomment-285093289,1,['access'],['access']
Security,"@cwhelan I've having problems with the non-Spark JAR though:. ``` bash; $ gradle clean installDist; $ java -jar build/libs/gatk-4.pre-alpha-*-SNAPSHOT.jar; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/logging/log4j/LogManager; at org.broadinstitute.hellbender.cmdline.ClassFinder.<clinit>(ClassFinder.java:29); at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:108); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:86); Caused by: java.lang.ClassNotFoundException: org.apache.logging.log4j.LogManager; at java.net.URLClassLoader$1.run(URLClassLoader.java:372); at java.net.URLClassLoader$1.run(URLClassLoader.java:361); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:360); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 4 more; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1213#issuecomment-162013287:748,secur,security,748,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1213#issuecomment-162013287,2,"['Access', 'secur']","['AccessController', 'security']"
Security,@cwhelan could you give andrei and sam access to the FC dsde-methods-sv-dev workspace can investigate the bug. I and Steve had tried without success.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5217#issuecomment-424435081:39,access,access,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5217#issuecomment-424435081,1,['access'],['access']
Security,"@davidadamsphd Is this still an issue? Will it be resolved as part of your validation efforts, or do we have to address it separately?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1042#issuecomment-157482285:75,validat,validation,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1042#issuecomment-157482285,1,['validat'],['validation']
Security,"@davidbenjamin @ldgauthier: in #6263 you added --force-output-intervals to GenotypeGVCFs, which forces the tool to output variants based on a whitelist of sites. I believe this exposed a pre-existing, not related bug. GenotypeGVCFsEngine.removeNonRefAlleles() currently assumes the input has only one alternate allele. If the gVCF has a site with 3 or more alleles, GenotypeGVCFsEngine.removeNonRefAlleles() isnt going to work as intended. If any NON_REF is found, it *should* remove ALT allele header lines and return the new VC with NON_REF removed. It currently only does this if ""newAlleles.size() == 1"", which I assume is a proxy for not having alternates. That assumes the input had only 2 alleles, which isnt safe. This PR includes a fix for this. When I started investigating this I made a repro case (the attached VCF) and test case in GenotypeGVCFsIntegration test that uses --force-output-intervals to illustrate this. Now that the actual problem is clearer, I could understand if you dont want to add more test data to GATK. . I tried to write a unit test for removeNonRefAlleles(), but it didnt seem like it was going to be easy to make a new instance of GenotypeGVCFsEngine.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406:177,expose,exposed,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406,1,['expose'],['exposed']
Security,"@davidbenjamin How's the patch coming? Did the M2 validation tests pass on your branch? We'll definitely try to expedite the code review, but I'll think we'll want some additional heavy-duty testing prior to release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-610995045:50,validat,validation,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-610995045,1,['validat'],['validation']
Security,@davidbenjamin I have asked the user that reported this issue to share their file and will let you know as soon as I can get access.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098#issuecomment-530197163:125,access,access,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098#issuecomment-530197163,1,['access'],['access']
Security,"@davidbenjamin I made the requested changes and submitted novaseq validation jobs. They haven't failed yet, but I'll monitor the jobs and make changes to the wdl as needed. Will let you know when they finish.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4895#issuecomment-408528614:66,validat,validation,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4895#issuecomment-408528614,1,['validat'],['validation']
Security,"@davidbenjamin I've been looking at this with @nh13 and I think what's going on here is a little different that @nh13 described. Specifically when I try to reproduce this I get results very similar to those shown above, but with the MNP calling turned on I also get a second variant at `chr2:241815307`. I don't have access to the original calls @nh13 was looking at, but I suspect they may contain this call too. So I get the following with MNP support on (I'm not sure why I'm not getting them phased):. ```; chr2 241815307 . CA TG 962.73 . GT:AD:DP:GQ:PL 0/1:26,34:60:99:1000,0,758; chr2 241815308 . A G 2214.77 . GT:AD:DP:GQ:PL 1/1:1,60:61:99:1243,136,0; ```. This makes it look a lot like the issue described in #5523. I'm attaching ; ![an IGV screenshot of the region](https://user-images.githubusercontent.com/1609210/53673861-55b85880-3c47-11e9-9338-43c5ba40b5b6.png) and a SAM file, [NA24694.chr2.241815307.sam.gz](https://github.com/broadinstitute/gatk/files/2921535/NA24694.chr2.241815307.sam.gz), for the region shown that reproduces this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5696#issuecomment-468859167:317,access,access,317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5696#issuecomment-468859167,1,['access'],['access']
Security,"@davidbenjamin I've got a munrosa_bams_bugreport.tar.gz (2.1 MB) ready for you -- I'm trying to upload to the ftp side via the instructions [here](https://gatkforums.broadinstitute.org/gatk/discussion/1894/how-do-i-submit-a-detailed-bug-report), but I haven't been able to get access this morning due to the 20 user limit. Is there any other way I can send it over to you? I'd prefer not to post here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402257370:277,access,access,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402257370,1,['access'],['access']
Security,"@davidbenjamin I've significantly refactored the production code, see the last commit. Most of this refactoring was to done make the code for the accounting of different modes (SNP/INDEL/both x BGMM/python x non/allele-specific) more minimal and straightforward. I've also combined the score/apply steps using the TwoPassVariantWalker. There's still lots of documentation, cleanup, and hardening/validation to be done, but most of the key methods and design choices have been documented, so I think it could be worth a quick review at this stage. Again, no need to nitpick code-style details, etc. (unless you really want to!) In the meantime, I'm going to do some more testing/tieout to make sure the refactor didn't break anything. This covers ~1800 LOC, which is roughly 50% of the equivalent VQSR code. Even modulo the remaining work just mentioned, which may add a few hundred LOC, I think this is a decent improvement---additional functionality, stability, etc. notwithstanding!. There's stubs for adding the truth-sensitivity conversion you proposed---should be pretty straightforward. I think it should also still be pretty easy for future pushes to add features like extraction/downsampling of unlabeled data, etc., but please do keep an eye out for design choices that may ultimately be constraining.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1044836946:396,validat,validation,396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7659#issuecomment-1044836946,1,['validat'],['validation']
Security,"@davidbenjamin Note that this is not exposed in CollectAllelicCounts either and is set to 30 by default. Our default set of read filters is also less stringent. However, we do expose a threshold on minimum base quality. Just a few more things to consider when we unify the two tools!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4011#issuecomment-354334621:37,expose,exposed,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4011#issuecomment-354334621,2,['expose'],"['expose', 'exposed']"
Security,"@davidbenjamin again, sorry to keep bugging on this thread, but it's been a while and we're really hoping to push these changes through since they're blocking a project. I believe I addressed everything in your review. I did identify another (arguably pre-existing) issue in GenotypGVCFs that would be exposed whenever it runs in all-sites mode or in force-output mode - the lack of allele trimming. This PR addresses that, including test cases, though I havent heard back about this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-581418093:302,expose,exposed,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-581418093,1,['expose'],['exposed']
Security,"@davidbenjamin at long last, back to you. I updated the nio wdl too, and it passes the Firecloud M2 wdl validation with the HCC sample, but not with the cram. But that's because that cram file is aligned to hg38, whereas the workspace uses hg19. I didn't touch anything related to the CramToBam task in the nio wdl so I think we're OK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-474900012:104,validat,validation,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-474900012,1,['validat'],['validation']
Security,"@davidbenjamin commented on [Mon Mar 27 2017](https://github.com/broadinstitute/gatk-protected/issues/958). We currently have an ICE exome normal-normal analysis set up i.e. you can `cd` into `/dsde/working/davidben/mutect/validations/normalNormal` and `/Users/home/davidben/cromwell/run_sge.sh normal_normal.wdl normal_normal.json` is all you need to get the analysis. Let's set this up for a few other replicate sets, which we can grab from the Palantir wiki.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2961:223,validat,validations,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2961,1,['validat'],['validations']
Security,"@davidbenjamin commented on [Sat May 27 2017](https://github.com/broadinstitute/gatk-protected/issues/1112). In `SomaticGenotypingEngine::callMutations` and `HaplotypeCallerGenotypingEngine::assignGenotypeLikelihoods` there is a line of code after the call is made but before the variant is annotated:; ```java; ReadLikelihoods annotationLikelihoods = prepareReadAlleleLikelihoodsForAnnotation(likelihoods...); ```; Is this really necessary? It seems quite defensible to annotate using the same likelihoods from which the variant call is derived. As far as Mutect is concerned, the standard will be whether our validations are better or at least no worse without it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3022:611,validat,validations,611,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3022,1,['validat'],['validations']
Security,"@davidbenjamin commented on [Sun May 28 2017](https://github.com/broadinstitute/gatk-protected/issues/1114). HaplotypeCaller and Mutect by default assemble reads with kmer sizes of 10 and 25. 10 seems extremely small given the low error rates of Illumina sequencing. It's worth investigating how the Mutect validations are affected by increasing these values. ---. @ldgauthier commented on [Tue May 30 2017](https://github.com/broadinstitute/gatk-protected/issues/1114#issuecomment-305032024). Investigate away, but keep in mind bigger kmers introduce more ""dangling tails"", which may end up dropping evidence at the ends of reads. If you end up diving into the assembly graphs, I'm happy to consult. It's a deep, dark rabbit hole, but I've been there before and I know the way. ;)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3024:307,validat,validations,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3024,1,['validat'],['validations']
Security,"@davidbenjamin commented on [Wed Feb 15 2017](https://github.com/broadinstitute/gatk-protected/issues/903). Since most of the work is in setting up the necessary tools and pipelines to evaluate, I will lump the actual act of evaluating on specific data into this single ticket. We need to:. * CRSP specificity: apply Takuto's `mutect2-replicate-validation.wdl` on the CRSP NA12878 replicates.; * CRSP sensitivity: apply the (currently in-progress) hapmap sensitivity pipeline to CRSP data.; * cfDNA: run cfDNA samples and matched solid tumor samples (which we already have from Viktor) and run the concordance tool.; * FFPE: run FFPE and matched non-FFPE samples and run the concordance tool.; * tumor-only: run some TCGA samples with and without their matched normal and run the concordance tool. ---. @davidbenjamin commented on [Wed Mar 15 2017](https://github.com/broadinstitute/gatk-protected/issues/903#issuecomment-286795503). Update: CRSP sensitivity and specificity have been run several times, cfDNA is currently running for the first time. FFPE and tumor-only will use the same wdl as cfDNA, so we'll run those once cfDNA finishes. ---. @davidbenjamin commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gatk-protected/issues/903#issuecomment-287675783). Update: everything done except FFPE and tumor-only. FFPE will use the same wdl as cfDNA.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2942:345,validat,validation,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2942,1,['validat'],['validation']
Security,"@davidbenjamin mutect2_pon.wdl and mutect2.wdl worked great without docker installed. Thanks!. @samuelklee @sooheelee As a user, I found a json template useful for two reasons, though it may be up to how a wdl is written.; 1) womtool generates inputs from all the dependent wdls including unnecessary ones for the workflow. (e.g. mutect2_pon.wdl); 2) womtool didn't provide default values. Looking at mutect_resources.wdl, I wondered what the good value for minimum_allele_frequency is (or what GATK team used for creating the resource bundle). In addition, I thought a test to validate every wdl would be helpful. (womtool validate [a wdl])",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256:578,validat,validate,578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256,2,['validat'],['validate']
Security,"@davidbenjamin, et al. I have two recommendations:. 1) Though I prefer to work symbolically and through proofs, it might be nice to first expand on the validation by proof in the JavaDoc - including for the specific function's header - and anywhere else where necessary across the GATK code, just for sanity's sake, and for tying things together neatly and properly. This process of always going through the mathematical steps alerts me when I code that I have not missed anything. . 2) When dealing with multiple levels of transformations, it probably would be good to formulate a collection of complete set of simple tests. Since like you mentioned {phased} is a subset (⊂) of {unphased}, then the paths of phased genotypes one works with would also be ideal to test on. Does this function have any validation tests confirming the correct likelihoods, which would be performed for both phased and unphased genotypes? These can be generated tests, if original files do not exists. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2019#issuecomment-236759221:152,validat,validation,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2019#issuecomment-236759221,2,['validat'],['validation']
Security,"@davidbernick thanks!. I noticed that the existing jobs are now failing with a GCS error (see https://gatk-jenkins.broadinstitute.org/job/gatk-perf-test-spark-markeddupe/436/console):. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```. There has been a change to the GCS library (https://github.com/broadinstitute/gatk/commit/b47838c9a5fa172ed6669ed4872b04d91c962a85), but when I ran a GCS pipeline manually on my machine it worked fine, even with this change. Any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325:219,secur,security,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325,2,"['access', 'secur']","['access', 'security']"
Security,"@doazen I need to re-review this myself, and see what more validation I can do. I hate to miss the release, but I won't be able to do that today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7402#issuecomment-952203649:59,validat,validation,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7402#issuecomment-952203649,1,['validat'],['validation']
Security,"@droazen +1 for being affected by this issue in production. As this is in production (same as @schelhorn , with big pharma which have very strict security requirements), and as 4.1.8.0 contains critical security vulnerabilities that were mitigated in subsequent releases, we are in a serious pickle here. @jhl667 how did you conclude that 4.1.8.0 performs better than newer versions? What we see is that it emits more variants, but after filtering and intersecting with other callers (i.e. Strelka), we get more variants and a ""better"" result (we can't really define ""better"" - it's merely an observation) with 4.2.4.1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1407439000:146,secur,security,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1407439000,2,['secur'],['security']
Security,"@droazen , I was able to reproduce your result. I tried to isolate what made it work or not. I tried with two kinds of inputs:; - on the hellbender bucket, or; - on my own bucket. I tried with two choices for `GOOGLE_APPLICATION_CREDENTIALS`:; - default credentials, or; - my own. I tried with two different clusters:; - one created in the Broad project, or; - one created in my own project. With every one of those eight combinations, I got the same result: the dreaded ""Error code 404 trying to get security access token from Compute Engine metadata for the default service account."". ```; ./gatk-launch CountReadsSpark -I gs://hellbender/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -- --sparkRunner GCS --cluster jp-test-cluster --executor-cores 2 --num-executors 2; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-352147413:501,secur,security,501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-352147413,4,"['access', 'secur']","['access', 'security']"
Security,"@droazen - That won't be solved by the current #3447, because there is no way of fine-tune the codecs: I require to being able to add/remove concrete classes, and exclude codecs from a concrete package. An example is a custom codec implementation for some feature, to provide extra-validation for the downstream toolkit. This would be even more useful if HTSJDK is moving to an interface-based library...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-337622596:282,validat,validation,282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-337622596,1,['validat'],['validation']
Security,@droazen : Thanks a lot for prioritizing and attending to this. The security posture has greatly improved from where we started. Community greatly benefits from your effort. I have migrated to using the 4.5 release after some regression testing. Below is a list of critical and high findings with 4.5 release. There are links to snyk version update recommendations. I know sometimes its not easy just to upgrade the library version as we could end up with run time errors. I am adding this here so that its handy when ever you look at this further. Thanks again. . packageName | version | severity | language | module_id; -- | -- | -- | -- | --; com.google.protobuf:protobuf-java | 3.7.1 | high | java | [SNYK-JAVA-COMGOOGLEPROTOBUF-2331703 ](https://security.snyk.io/vuln/SNYK-JAVA-COMGOOGLEPROTOBUF-2331703 ); com.google.protobuf:protobuf-java | 3.7.1 | high | java | [SNYK-JAVA-COMGOOGLEPROTOBUF-3167772](https://security.snyk.io/vuln/SNYK-JAVA-COMGOOGLEPROTOBUF-3167772); io.netty:netty-codec-http2 | 4.1.96.Final | high | java | [SNYK-JAVA-IONETTY-5953332](https://security.snyk.io/vuln/SNYK-JAVA-IONETTY-5953332); log4j:log4j | 1.2.17 | high | java | [SNYK-JAVA-LOG4J-2342645](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-2342645); log4j:log4j | 1.2.17 | high | java | [SNYK-JAVA-LOG4J-2342646](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-2342646); log4j:log4j | 1.2.17 | high | java | [SNYK-JAVA-LOG4J-2342647](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-2342647); log4j:log4j | 1.2.17 | critical | java | [SNYK-JAVA-LOG4J-572732](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-572732); net.minidev:json-smart | 1.3.2 | high | java | [SNYK-JAVA-NETMINIDEV-3369748](https://security.snyk.io/vuln/SNYK-JAVA-NETMINIDEV-3369748); org.apache.zookeeper:zookeeper | 3.6.3 | high | java | [SNYK-JAVA-ORGAPACHEZOOKEEPER-5961102](https://security.snyk.io/vuln/SNYK-JAVA-ORGAPACHEZOOKEEPER-5961102); org.codehaus.jettison:jettison | 1.1 | high | java | [SNYK-JAVA-ORGCODEHAUSJETTISON-3168085](https://,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1890593067:68,secur,security,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1890593067,3,['secur'],['security']
Security,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:215,validat,validate,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364,1,['validat'],['validate']
Security,"@droazen @davidbenjamin any thoughts regarding the last bullet above in https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471 on possible integration tests? Started looking at this today and was wondering if you might have any suggestions. Ideally, we'd want to test that the exposure was done correctly through the 3 affected tools: HaplotypeCaller, Mutect2, and FilterAlignmentArtifacts. I can certainly take the approach outlined above and 1) on master, pick one or more integration tests for each tool, then generate results by changing the original unexposed constants and running on the relevant test data, 2) on this branch, commit those new results, then add corresponding versions of the integration tests that change the exposed inputs and check against the results. However, not sure if we'll want to clutter the repo with more test files just for this sort of exposing of constants, and such tests don't really feel complete anyway. So alternatively, I could probably write a script to do essentially the same thing and just check consistency between the branches for a bunch of randomly generated SW parameter values, perhaps also running on more substantial test files for each tool. I can document this process and then we can move on without committing any new tests or test files once we're satisfied that the exposure was done correctly. Or if you guys have additional suggestions, would be glad to hear them!. Finally, it looks like FilterAlignmentArtifacts doesn't have any integration tests for correctness---let me know if there are auxiliary tests we'd want to run there. Anyway, probably overthinking things, but the exposure was enough of a headache that I want to make sure I did it right. But would also rather fully hash out what to do beforehand, so I don't end up having to redo things after review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896314077:749,expose,exposed,749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896314077,2,"['expose', 'hash']","['exposed', 'hash']"
Security,@droazen @lbergelson -- this is blocking the JG run. I can get you access to the underlying data if necessary but hoping the stack trace will point to something obvious,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301329590:67,access,access,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2713#issuecomment-301329590,1,['access'],['access']
Security,"@droazen @lbergelson I'm not really sure how to do this. It's easy in SVN, but not in git. We would need to insert the version info in the labels of the dockerfile when we cut a release -- the release version (e.g. 4.beta.4) not the git hash. How is GotC doing it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3645#issuecomment-333543566:237,hash,hash,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3645#issuecomment-333543566,1,['hash'],['hash']
Security,"@droazen Applied your steps, I hope correctly - the pull request looks clean now. Your steps were a huge help. . The travis build looks like failing now, for reasons not obviously connected with our commit:. `Error: (converted from warning) unable to access index for repository http://cran.mtu.edu/src/contrib; Execution halted; The command ""if [[ $TEST_DOCKER != true ]]; then sudo mkdir -p /usr/local/lib/R/; sudo mkdir -p site-library; sudo ln -sFv ~/site-library /usr/local/lib/R/site-library; sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9; sudo add-apt-repository ""deb http://cran.rstudio.com/bin/linux/ubuntu trusty/""; sudo apt-get update; sudo apt-get install -y --force-yes r-base-dev=3.1.3-1trusty; sudo apt-get install -y --force-yes r-base-core=3.1.3-1trusty; sudo Rscript scripts/docker/gatkbase/install_R_packages.R; fi;"" failed and exited with 1 during .`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437922888:251,access,access,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437922888,1,['access'],['access']
Security,@droazen Didn't she validate the input bam though?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317047601:20,validat,validate,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317047601,1,['validat'],['validate']
Security,@droazen Hadoop-BAM has been released now so this is ready for review now whenever you can get to it. There are two other changes included that are unrelated to the tickets listed above:; - ValidateSAMFile has a change because the setValidateIndex API has been deprecated in htsjdk; - Includes a centralized DEFAULT_READ_VALIDATION_STRINGENCY value per our discussion.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1469#issuecomment-184224336:190,Validat,ValidateSAMFile,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1469#issuecomment-184224336,1,['Validat'],['ValidateSAMFile']
Security,"@droazen I am more confident that this method was not ported (or deleted, I suppose). It is used only once in gsa-unstable. The GATK 3 method `HaplotypeCallerGenotypingEngine::prepareReadAlleleLikelihoodsForAnnotation` is identical to the GATK 4 method `AssemblyBasedCallerGenotypingEngine::prepareReadAlleleLikelihoodsForAnnotation` except for the following lines that are missing in GATK 4:. ```java; if (call.getAlleles().size() != readAlleleLikelihoodsForAnnotations.alleleCount()) {; readAlleleLikelihoodsForAnnotations.updateNonRefAlleleLikelihoods(new IndexedAlleleList<>(new HashSet<>(call.getAlleles())));; }; ```. I can't think of a reason for this code to be removed, so why don't we restore those lines to `prepareReadAlleleLikelihoodsForAnnotation` and copy the GATK 3 code for `ReadLikelihoods. updateNonRefAlleleLikelihoods()`, which doesn't seem to exist or have any equivalent in GATK 4?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1950#issuecomment-300901327:583,Hash,HashSet,583,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1950#issuecomment-300901327,1,['Hash'],['HashSet']
Security,"@droazen I have a PR for gatk-bwa-mem that adds a footer to the image file so that we can test integrity. I also added code to test every (I think) call that returns an error indication, and pass this info up the chain. Could you review the PR or delegate, please?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079:95,integrity,integrity,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079,1,['integrity'],['integrity']
Security,"@droazen I have forward that question to GP and will get back to you once I get their answer. (At least, to my knowledge, I can't determine this without their help since I only have access to the output but not the pipeline.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099616963:182,access,access,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099616963,1,['access'],['access']
Security,@droazen I just looked and it seems that the only other big one I added was `--disable-artificial-haplotype-recovery` and that one is very esoteric indeed and doesn't need to be exposed I don't think.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6737#issuecomment-668197410:178,expose,exposed,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6737#issuecomment-668197410,1,['expose'],['exposed']
Security,@droazen I realized I should probably have exposed these methods for protected since we'd need to duplicated them in order to do broadinstitute/gatk-protected#1013. this includes the changes in #2630,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2631:43,expose,exposed,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2631,1,['expose'],['exposed']
Security,"@droazen I thought I had updated this months ago saying that I was finished validating, and that it was ready for review, but it appears that I didn't. But anyway its ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7402#issuecomment-1108948701:76,validat,validating,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7402#issuecomment-1108948701,1,['validat'],['validating']
Security,@droazen I would rather not get into why exactly the CNV tests are relying on bogus intervals that don't pass validation and what to do about it on this branch. I would rather get this version of things in now to help in at least the -L interval file use case,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7295#issuecomment-860948476:110,validat,validation,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7295#issuecomment-860948476,1,['validat'],['validation']
Security,@droazen I'm not authorized either.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306542782:17,authoriz,authorized,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306542782,1,['authoriz'],['authorized']
Security,@droazen No objection here. It may be that my changing the db access to read only fixed the issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4413#issuecomment-413247125:62,access,access,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413#issuecomment-413247125,1,['access'],['access']
Security,"@droazen Per our discussion about whether the default stringency should be SILENT or STRICT, I re-ran the BaseRecalibrator integration tests (remember these were the only tests that failed with STRINGENCY=STRICT, at least non-Spark tests which is all that are affected by this PR) to see why they failed. There are about 15 tests, totalling about 10 bams used there that fail validation. Based on Picard validation, some have >100 errors, some have a handful; the most common errors are:. -Mate not found for paired read; -Mate Alignment start should be 0 because reference name = *; -Mapped mate should have mate reference name. There are also a handful of missing NM tags. I have the file-by-file breakdown if you want to see it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1439#issuecomment-174663312:376,validat,validation,376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1439#issuecomment-174663312,2,['validat'],['validation']
Security,@droazen The PR is #6544. James has reviewed and requested a few more tests. It's working fine on validations including ~30 exomes and ~15 genomes.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-611223334:98,validat,validations,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-611223334,1,['validat'],['validations']
Security,"@droazen We could probably force it too, but it's easier to just have it build with an incomplete version number which is what the new commit does. If there's no tag it just uses the short-hash, and if there is no git describe --always --long (which is true with jgit for instance..) then it will build with ""version-unknown"".",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/196#issuecomment-77919740:189,hash,hash,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196#issuecomment-77919740,1,['hash'],['hash']
Security,"@droazen Yes, please. Sorry for not catching this! Turns out that unpaired reads that pass all the M2 read filters and show evidence of a SNV are rare enough that they don't show up in any of the M2 validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5121#issuecomment-413611150:199,validat,validations,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5121#issuecomment-413611150,1,['validat'],['validations']
Security,"@droazen any thoughts how we should proceed here, if at all? @ldgauthier reminded me that this story was unfinished and is getting a little stale. @fleharty take note if we want to report progress on this front to our MalariaGEN collaborators. On my end, there are a couple of things to do:; - [x] rebase and resolve conflicts; - [x] change TSV input as discussed above; - [x] add doc strings for new arguments; - [x] add integration tests to make absolutely sure exposure was done correctly, perhaps? I'm open to discussion about how this should be done. Complete coverage here will be difficult and perhaps not worth the effort, but I can probably put in a few tests that make sure changing the hard-coded values in master and doing the same via the exposed parameters in this branch have the same effect on a few existing test cases. However, while I'm doing the last three, I wonder if we could run whatever canonical evaluations/optimizations we have to see whether it's worth consolidating some of the parameter sets at this stage? I think there's an argument for having at least two sets (haplotype-to-reference + read-to-haplotype), but I'm not sure how to justify having a separate set for dangling heads/tails. But also not sure which set the latter should be consolidated with---@jamesemery thoughts? Again, let me reiterate that it seems that many of these parameter values were chosen arbitrarily (or, if not, that the procedure for choosing them has been lost). As a start, you can see the results of some optimizations I did on the CHM mix on slide 15 at https://docs.google.com/presentation/d/1zGuquAZWSUQ-wNxp8D6HhGNjIaFcV0_X9WAS4LODbEo/edit?usp=sharing Here, I optimized over haplotype-to-reference + read-to-haplotype SW parameters on various metrics after variant normalization using vcfeval. These optimizations were done using the Bayesian optimization framework I prototyped long ago (see https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer and http",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471:752,expose,exposed,752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471,1,['expose'],['exposed']
Security,@droazen can you run it on GSC or maybe ask @jean-philippe-martin ? I put the bam file in the hellbender-validation/test-input/NA12878 bucket,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/995#issuecomment-170034661:105,validat,validation,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/995#issuecomment-170034661,1,['validat'],['validation']
Security,"@droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473). This capability would be useful if it turns out that the CNV tools (for example) need to be released much more frequently than the GATK as a whole. We don't want a release of the CNV tools to be blocked for a long time because something else in the toolkit (like the `HaplotypeCaller`) is not ready for release. . There could be a `properties` file in the jar that controls which tools are exposed via the command-line -- this way we could publish a jar that exposes only the CNV tools, for example. An alternative approach would be to use branching and cherry-picking to do this kind of selective release, or split the GATK into even more repositories, but I'm not sure those approaches would be preferable. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215491991). This came out of a discussion between myself and @LeeTL1220 . ---. @lbergelson commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215493945). So a gatk release would contain different sets of tools sometimes? Wouldn't that be confusing? It seems like it would be better to always release different jars, or version sets of tools independently and release jars with the latest good release of each individual set of tools. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215494432). @lbergelson Well, we definitely still want there to be releases of the GATK toolkit in its entirety. If the CNV tools need to be released more frequently than this, they could be versioned/released separately and periodically incorporated into the toolkit-wide releases. ---. @droazen commented on [Thu Apr 28 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215495326). To be clear, though, this is very much still in the ""t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:492,expose,exposed,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,2,['expose'],"['exposed', 'exposes']"
Security,"@droazen it looked like it was going to work but then—. ```java; @Override; final protected ReferenceDataSource directlyAccessEngineReferenceDataSource() {; throw new GATKException(""Should never directly access the engine ReferenceDataSource in walker tool classes "" +; ""outside of the engine package. Walker tools should get their data via apply() instead."");; }; ```. Also, this is really not the responsibility of the tool class—it should be handled as part of the walker.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6512#issuecomment-618429411:204,access,access,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6512#issuecomment-618429411,1,['access'],['access']
Security,"@droazen looking into the ripping out a bit more, I think it's too disruptive for alpha. The recalibration table will change and it will require a more thorough validation. As this is a potentially results-changing change, I vote to move this past alpha. I have removed the indel calculations from the ApplyBQSR because that does not change any semantics. ; (i propose instead to nominate https://github.com/broadinstitute/gatk/issues/1078 for alpha - I can put that in very quickly)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1056#issuecomment-157051241:161,validat,validation,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1056#issuecomment-157051241,1,['validat'],['validation']
Security,@droazen sorry for a late response. I agree moving to java 17 would help. I do see that GATK itself is using the newer version of log4j but then its the transitive dependencies for the libraries used that bring in the older version of log4j. . this creates situations that the final compiled jar has both version of the log4j and this could create problems. . Gatk being a very useful tool gets integrated in multiple other tools and pipelines so in a way affecting the security posture of where its being used. The risk might be low being a standalone cli tool but its a very hard conversation with info security :) . May I ask for a ballpark ETA for the new version? Appreciate the work thats gone into this tool.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1448897264:470,secur,security,470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1448897264,2,['secur'],['security']
Security,@droazen still giving error:. com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132:102,secur,security,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132,2,"['access', 'secur']","['access', 'security']"
Security,"@droazen thanks for the quick response! Just to be clear, my concerns were about testing that I didn't somehow screw up the original behavior through the exposure, not just testing that *some* behavior was exposed. But message received---will keep things on the simple side!. Also, please see the plots in #5564 to get an idea of the effect on outputs, if you haven't already. Would appreciate any thoughts you might have on that thread!. Will try to get this done in the next day or two, thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896328697:206,expose,exposed,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896328697,1,['expose'],['exposed']
Security,"@droazen yes, at least to a point we have this worked out. we really needed something besides CombineGVCFs in order to scale, but GenomicsDB definitely is a new format and I hope the tool keeps getting fleshed out. One final question: is there a way to check the integrity of a GenomicsDB instance? With a VCF one could at least iterate it, or check that it's a valid (non-truncated) gzip file. . Thanks for the help - we can close the issue as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-684864223:263,integrity,integrity,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-684864223,1,['integrity'],['integrity']
Security,"@droazen, I think I have pushed most of the changes requested -. * Moved out `appendPathToDir` from BucketUtils to IOUtils; * `appendPathToDir` now uses Path.resolve() to append a given path to dir; * If a workspace already exists and `overExistingWorkspace` is false, a `UnableToCreateGenomicsDBWorkspace` exception is thrown while creating a GenomicsDB workspace.; * Made sure all paths passed to GenomicsDB are absolute.; * Introduced `gendb.hdfs:` and `gendb.gs:` URI schemes in addition to the existing `gendb:` scheme for identifying Cloud paths in GenomicsDB with unit testing for these new schemes.; * Added unit tests to test writing to GenomicsDB workspace/arrays to GCS and then reading/querying from the same GenomicsDB instance from GCS with validation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5017#issuecomment-415611303:755,validat,validation,755,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5017#issuecomment-415611303,1,['validat'],['validation']
Security,"@droazen, the SAMRecord interface exposes getReferenceIndex and getMateReferenceIndex, so there is no question that the index has to be there. . What I was talking about what the optimization where when serializing, the [BAMRecordCodec only saves the index](https://github.com/samtools/htsjdk/blob/master/src/java/htsjdk/samtools/BAMRecordCodec.java#L131), and not the name. That is because if we have the header then we can go from the index to the name. If there is no header, then we can't do that optimization anymore and instead have to save those two fields for every read.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141251365:34,expose,exposes,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141251365,1,['expose'],['exposes']
Security,"@droazen, we have a free GCS account, so it is possible that Hadoop requires extra configuration for authenticating/connecting with the HELLBENDER travis service account. Can anyone help here? This the code we have for connecting to GCS via Hadoop. ```; hdfsFS gcs_connect(struct hdfsBuilder *builder, const std::string& working_dir) {; char *gcs_creds = getenv(""GOOGLE_APPLICATION_CREDENTIALS"");; if (gcs_creds) {; value = parse_json(gcs_creds, ""project_id""); // free value after hdfsBuilderConnect as it is shallow copied.; if (value) {; hdfsBuilderConfSetStr(builder, ""google.cloud.auth.service.account.enable"", ""true"");; hdfsBuilderConfSetStr(builder, ""google.cloud.auth.service.account.json.keyfile"", gcs_creds);; hdfsBuilderConfSetStr(builder, ""fs.gs.project.id"", value);; }; }. if (working_dir.empty()) {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", ""/"");; } else {; hdfsBuilderConfSetStr(builder, ""fs.gs.working.dir"", working_dir.c_str());; }. // Default buffer sizes are huge in the GCS connector. GenomicsDB reads/writes in smaller chunks,; // so the buffer size can be made a little smaller.; hdfsBuilderConfSetStr(builder, ""fs.gs.io.buffersize.write"", ""262144"");. hdfsFS hdfs_handle = hdfsBuilderConnect(builder);; free(value);; return hdfs_handle;; }; ```. This is the error from Travis logs-; ```; Running Test: Test method testWriteToAndQueryFromGCS(org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest); hdfsBuilderConnect(forceNewInstance=1, nn=gs://hellbender-test-logs, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:210); at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:75); at com.google.cloud.hadoop.fs.gcs.GoogleHadoo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888:101,authenticat,authenticating,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422915888,1,['authenticat'],['authenticating']
Security,"@droazen, will put some debug print statements in the two tests that are failing while authenticating with GCS and issue another pull request to _nalinigans_genomicsdb_uri_support_ branch. Hope that is OK. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422843915:87,authenticat,authenticating,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5197#issuecomment-422843915,1,['authenticat'],['authenticating']
Security,"@droazen,. Apologies for the delay in getting back to you. Given the nature of our work, it's essential that we address and remove any high and critical vulnerabilities, regardless of their real-world threat level. Ensuring our system remains secure is our top priority. Here is the pull request with the modifications to address the high and critical vulnerabilities: [#8950](https://github.com/broadinstitute/gatk/pull/8950). Please review and let me know if you have any feedback.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2285999993:201,threat,threat,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2285999993,2,"['secur', 'threat']","['secure', 'threat']"
Security,"@eddiebroad commented on [Thu Dec 01 2016](https://github.com/broadinstitute/gatk-protected/issues/806). An issue encountered with gatk-protected ""SparkGenomeReadCounts"" tool is a non-helpful ""null"" error message. A non-helpful error ""null"" message was printed by gatk-protected with the command-line below; during the course of trying to use it on/in FireCloud:. ```; + java -Xmx48g -jar fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar SparkGenomeReadCounts --outputFile this.entity_id.coverage.tsv --reference fc-e2421839-93d5-4ed5-8861-593f00364e54/Homo_sapiens_assembly19.fasta --input firecloud-tcga-open-access/tutorial/bams/C835.HCC1143_BL.4.bam --binsize 5000; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; .....; ......; ......; proceeding with flushing remote transports.; ***********************************************************************. null. ***********************************************************************; ```. To try to make a more helpful error message appear I added a ""catch"" block after a call to runTool in instanceMainPostParseArgs in file CommandLineProgram.java and got a more helpful message about a missing dictionary file: . try {; return runTool();; } ; catch(Exception e) {; e.getStackTrace();; }. java.lang.RuntimeException: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:204); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:95); 	at org.broadinstitute.hellbender.Main.instanceMain(Main.java:103); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:115); 	at org.broadinstitute.hellbender.Main.main(Main.java:152); Caused by: org.broadinstitute.hellbender.exceptions.UserException$MissingReferenceDictFile; 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:612,access,access,612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,1,['access'],['access']
Security,"@fleharty @avalind ; Sorry, something happened with my previous message.; But what I wrote previously was that I couldn't reproduce the same error message using Picard ValidateSamFile. I tried validating my bam file and I don't see any errors. Even the samtools flagstat option works fine on my bam file.; Please find the attached screenshots,. <img width=""704"" alt=""picard"" src=""https://user-images.githubusercontent.com/6302819/88064375-8023f200-cb6b-11ea-960e-bab93f79ff22.png"">. <img width=""289"" alt=""flagstst"" src=""https://user-images.githubusercontent.com/6302819/88064447-9631b280-cb6b-11ea-86ee-6c49f9111507.png"">. Do you still think my bam file is malformatted?. PS: @fleharty used Picard version (2.20.4-SNAPSHOT), whereas I used v.2.23.2; for running Picard ValidateSamFile.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-661884614:168,Validat,ValidateSamFile,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-661884614,3,"['Validat', 'validat']","['ValidateSamFile', 'validating']"
Security,"@fleharty It's line 810 in that class (https://github.com/samtools/htsjdk/blob/f15bc9d2c0297a1bde6b89aa95cf2dc45dfc567f/src/main/java/htsjdk/variant/vcf/AbstractVCFCodec.java#L810). We need to switch from calling `decodeInts()` to calling a method that tolerates and preserves missing values. A decision will need to be made about whether, for AD specifically, missing values should be replaced with 0 (which @ldgauthier said she'd be ok with), or passed through to the caller as '.' or null. If we choose to propagate the missing values back to the caller, we may need to do downstream work in GATK/Picard to modify tools to handle them, and also modify the HTSJDK accessor for the AD field to return list of `Integer` instead of array of `int`. If we replace the missing values with 0, we likely wouldn't have to patch any downstream code at all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-682016997:666,access,accessor,666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-682016997,1,['access'],['accessor']
Security,"@frank-y-liu Thanks for the pull request! Looks good to me except for a very minor nitpick about tabs. In general we always use spaces. You should be able to set your IDE to autoconvert them. . I'm happy to merge without the cloud tests. It's a security hazard to let pull request from forks have access to those tokens, so they don't get passed to builds from forks. We separate the clouds tests explicitly so they can be skipped without breaking the rest of the tests when this happens. Your code should not effect any of the cloud functionality so I'm not worried if those tests didn't run. We can give you direct push access as well if that's more convenient for you. Then the tests will all run.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1761#issuecomment-213575978:245,secur,security,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1761#issuecomment-213575978,3,"['access', 'secur']","['access', 'security']"
Security,@gbrandt6 @bhanugandham do we have access to gvcfs that reproduce this problem? just want something real to test a fix with.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-689720463:35,access,access,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-689720463,1,['access'],['access']
Security,@gmagoon I agree that it does look a lot like an off-by-one error. The genotype validator is complaining about seeing a reference allele that just happens to be the same as the previous VC. . @cwhelan can you take a look when you get a chance?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336#issuecomment-431855929:80,validat,validator,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336#issuecomment-431855929,1,['validat'],['validator']
Security,"@gokalpcelik I see that the bug exists in the updated code too. We can fix it, but would be good to have some dataset that can be used to validate. Any chance to ask the user to generate a small example?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8788#issuecomment-2073371655:138,validat,validate,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8788#issuecomment-2073371655,1,['validat'],['validate']
Security,"@gspowley I have neglected this for a while, to say the least. Here is a command line using publicly available data with paths on the Broad servers. Everyone at the Broad has read access to these files, FWIW. What should I do with the data?. ```bash; wgs_intervals=/seq/references/Homo_sapiens_assembly19/v1/variant_calling/wgs_calling_regions.v1.interval_list; hg19=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta; tumor_bam=/dsde/working/davidben/dream/synthetic/original_bams_symlinks/tumor_4.bam; tumor_sample=synthetic.challenge.set4.tumour; normal_bam=/dsde/working/davidben/dream/synthetic/original_bams_symlinks/normal_4.bam; normal_sample=synthetic.challenge.set4.normal; java -jar $gatk Mutect2 \; -R $hg19 \; -L $wgs_intervals \; -I $tumor_bam -tumor $tumor_sample \; -I $normal_bam -normal $normal_sample \; -O output.vcf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2562#issuecomment-307436212:180,access,access,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2562#issuecomment-307436212,1,['access'],['access']
Security,"@gudeqing Thanks for reporting. `GatherBamFiles` is a bit of a tricky tool and it's easy to do the wrong thing with it accidentally. It's possible that there's an error in either how it was run or the input files but you definitely also could have discovered a bug. Samtools indexing it correctly would be point towards a bug, but I'd like you to check a few things first to be sure. . GatherBamFiles is dumb and just concatenates bam files so it's very picky about inputs. If the bam files in the input are not disjoint or they are specified out of order than `GatherBamFiles` will produce an invalid output which might manifest in indexing errors. It's also possible that the header specified didn't include all the contigs present in the collection of bams which could have a similar error result. Could you run ValidateSamFile on the result and report back what it says? If the file is out of order in some way or the header doesn't match it should report that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6379#issuecomment-575680528:815,Validat,ValidateSamFile,815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6379#issuecomment-575680528,1,['Validat'],['ValidateSamFile']
Security,"@ilyasoifer Is there any way I can access the original cram (or better yet, a small subset thereof consisting of just MT) that illustrates this issue) and the reference ? It might be hard to debug without that. If thats not possible, a few suggestions: can you try using PrintReads to write the original cram (I would try just MT) first to a cram, then to a sam, and also the original cram to a sam, and see how those compare? It would also be useful to see what that read looks like if you use samtools view on the ORIGINAL cram. Do you know what software/version was used to write the original cram ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8768#issuecomment-2045130095:35,access,access,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8768#issuecomment-2045130095,1,['access'],['access']
Security,@ilyasoifer cnorman@broadinstitute.org. And don't worry about doing the PrintReads conversions I requested - if I have access to the original file and the reference I can debug this directly.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8768#issuecomment-2045185628:119,access,access,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8768#issuecomment-2045185628,1,['access'],['access']
Security,"@jamesemery - i will also look into whether this file is somehow created by subsetting another during tests. in the meantime, would it be possible to also get these? i'm pretty confident this is the final list:. gsa-hpprojects\GATK\data\Comparisons\Validated\HapMap\3.3\genotypes_r27_nr.b37_fwd.vcf. and the following are in privateTestDir:. overlapTest.bed; PhaseByTransmission/PhaseByTransmission.IntegrationTest.goodFamilies.ped; PhaseByTransmission/PhaseByTransmission.IntegrationTest.TP.vcf; NA12878.HiSeq.WGS.b37_decoy.indel.recalibrated.vcf; yri.trio.gatk.ug.head.vcf; NA12878.HiSeq.WGS.b37_decoy.indel.recalibrated.vcf; Mills_and_1000G_gold_standard.indels.b37.sites.vcf; validationReportComp.vcf; validationReportComp.noGenotypes.vcf",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-366799537:249,Validat,Validated,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-366799537,3,"['Validat', 'validat']","['Validated', 'validationReportComp']"
Security,"@jamesemery : i have run all integration tests, and I think this is a complete list of the remaining files I can hopefully get:. /private/gatk-tools-private/src/test/resources/withSymbolic.b37.vcf; /private/gatk-tools-private/src/test/resources/PhaseByTransmission/PhaseByTransmission.IntegrationTest.TP.vcf ; /private/gatk-tools-private/src/test/resources/yri.trio.gatk_glftrio.intersection.annotated.filtered.chr1.vcf ; /private/gatk-tools-private/src/test/resources/NA12878.HiSeq.WGS.b37_decoy.indel.recalibrated.vcf ; /private/gatk-tools-private/src/test/resources/validationReportEval.noGenotypes.vcf ; /private/gatk-tools-private/src/test/resources/validationReportEval.vcf ; /private/gatk-tools-private/src/test/resources/ac0.vcf ; /humgen/gsa-hpprojects/GATK/data/Comparisons/Validated/HapMap/3.3/genotypes_r27_nr.b37_fwd.vcf; /humgen/gsa-hpprojects/GATK/data/Validation_Data/snpEff2.0.5.AFR.unfiltered.VariantAnnotator.output.vcf. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-366146129:569,validat,validationReportEval,569,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-366146129,3,"['Validat', 'validat']","['Validated', 'validationReportEval']"
Security,"@jamesemery @droazen I've updated this branch to ensure all read and write paths to shared state in `GenotypeLikelihoodCalculators` is synchronized. I then wrote a little [test](https://github.com/broadinstitute/gatk/commit/3bb178746b1dd286f55ba77e6939e2104ced98d0) using `AlleleSubsettingUtils` to access `GenotypeLikelihoodCalculators` 10^6 times to see the effect of adding synchronization. R session (times are in millis):; ```; > without_sync = c(10166, 10049, 10306, 10059, 10165); > with_sync = c(10700, 10384, 9923, 10097, 10190); > t.test(without_sync, with_sync, paired=TRUE). 	Paired t-test. data: without_sync and with_sync; t = -0.70447, df = 4, p-value = 0.52; alternative hypothesis: true difference in means is not equal to 0; 95 percent confidence interval:; -542.5421 322.9421; sample estimates:; mean of the differences ; -109.8 ; ```. The p-value is not less than 0.05, so we can't reject the null hypothesis (that the mean times are the same). So adding synchronization doesn't seem to make any difference in this test. BTW, I noticed that `GenotypeLikelihoods` has synchronization, so there is some precedent for thread-safety using this means.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-426338479:299,access,access,299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-426338479,1,['access'],['access']
Security,"@jamesemery Back to you, at long last. I adopted your suggestion of a proper search that doesn't revisit already-seen vertices and came up with a better way of seeding the ""good"" subgraph that is safe from your STR concern. As far as code is concerned it's a total rewrite — you can pretend the first PR commit doesn't exist. The new criterion for seeding the search is chains with good log odds on both ends and which are incident on a vertex with multiple good out-edges or multiple good in-edges. The rationale is that the adjacency of two bad edges may have good log odds (Suppose a bad edge comes in and two bad edges come out. One is a new error on top of the original error and one is the continuation of the original error) but two have two outgoing edges with good log odds requires an actual real variant. On our M2 validations this essentially no effect on sensitivity and a mild reduction in false positives. I will leave it to you (or to me when I don't have to work like a vampire) to investigate how well it interacts with junction trees. As a first step I wrote a basic unit test for the basic pathology of the old method.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6520#issuecomment-624265441:826,validat,validations,826,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6520#issuecomment-624265441,1,['validat'],['validations']
Security,"@jamesemery Can you rebase this branch onto latest master to resolve the conflicts? Recommend doing a local squash first given the number of commits here to make it less painful (by ""local squash"" I mean first `rebase -i` onto the hash of the first commit in the `git log` history that's not your own, and then rebase onto `origin/master`).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3803#issuecomment-359036049:231,hash,hash,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3803#issuecomment-359036049,1,['hash'],['hash']
Security,@jamesemery Could I get a 👍 on this from you. Anders reviewed it but it's not counting him since he doesn't have write access.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6668#issuecomment-646861071:119,access,access,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6668#issuecomment-646861071,1,['access'],['access']
Security,"@jamesemery I agree - all access (read and write) to `GenotypeLikelihoodCalculators` instance variables needs to be synchronized to make it safe. I think it would be sufficient to make `getInstance()` and `calculateGenotypeCountUsingTables()` synchronized. @droazen, are you concerned about performance for the Spark case? For the walker version, presumably the access is single-threaded, and hence [uncontended, which is very cheap](https://books.google.co.uk/books?id=mzgFCAAAQBAJ&pg=PA230&lpg=PA230&dq=java+uncontended+synchronization+goetz&source=bl&ots=7W4J807faW&sig=YALE1qdWoAUELPqLRhIedz-bZ20&hl=en&sa=X&ved=2ahUKEwj4jJeko8zdAhXVFsAKHazkBrcQ6AEwB3oECAIQAQ#v=onepage&q=java%20uncontended%20synchronization%20goetz&f=false). Another option would be to maintain a separate instance of `GenotypeLikelihoodCalculators` per genotyping engine. The size of the table is ploidy * alleles, so not too large?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-423546586:26,access,access,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-423546586,2,['access'],['access']
Security,@jamesemery Still some test failures https://storage.googleapis.com/hellbender-test-logs/build_reports/master_19811.2/tests/test/classes/org.broadinstitute.hellbender.tools.spark.validation.CompareDuplicatesSparkIntegrationTest.html#testOutputFile,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4894#issuecomment-397343622:179,validat,validation,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4894#issuecomment-397343622,1,['validat'],['validation']
Security,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7041:151,validat,validation,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041,2,"['inject', 'validat']","['inject', 'validation']"
Security,"@jamesemery What about supporting an initialize() method on VariantAnnotation? This is GATK3-like, and would be non-disruptive to existing code, since the interfaces could have a default no-op implementation? . /**; * Provides an opportunity to set up context; */; public void initialize(VariantAnnotatorEngine engine) {. }. Then we could address whether any context is appropriate to expose via methods on VariantAnnotatorEngine?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754274008:385,expose,expose,385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754274008,1,['expose'],['expose']
Security,"@jamesemery and now the overview of the more complex changes:. - `AssemblyResultSet`: the code for adding and removing haplotypes based on pileup alleles has become a `void` method of this class, where it belongs. Here and elsewhere I introduce snappy variable and function named referring to ""good"" and ""bad"" alleles, which I find visually much clearer. The code is basically the same as before but somewhat streamified. I extracted a `makeHaplotypeWithInsertedEvent` method to eliminate some code duplication between GGA and pileup force-calling.; - `HaplotypeCallerEngine` and `Mutect2Engine`: Force-calling alleles are split into biallelic `Events`. Duplicated code for finding all pileup events, then sifting them into good event to force-call and bad events to remove is extracted as `PileupBasedAlleles.goodAndBadPileupEvents`. Computing `allVariationEvents` is much simpler because 1) it now uses `Event` instead of `VariantContext` and 2) `Event` overrides `equals` and `hashCode`.; - `PileupBasedAlleles`: `getPileupVariantContexts` and sorting into good and bad pileup variants has been unified into `goodAndBadPileupEvents()`. It has additionally been somewhat rewritten for conciseness. Also, instead of the somewhat kludgy method of making `VariantContext` with four temporary attributes, then filtering based on those attributes, it calculates the filtering status immediately and uses `Events`. Also fixed the somewhat-misleading use of the word `alt` to mean `SNP`.; - `AssemblyBasedCallerUtils`: `applyPileupEventsAsForcedAlleles`, along with several helper methods that it calls, has been moved into `AssemblyResultResult`, where it is now a void member method.; - `GATKVariantContextUtils` mainly just using `Event` instead of `VariantContext`, which simplifies the code for splitting a `VariantContext` into biallelics. After going through this exercise I realize that it's not actually so much. The diff's bark is worse than its bite. The overwhelming majority of changes are eit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574175702:980,hash,hashCode,980,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574175702,1,['hash'],['hashCode']
Security,"@jamesemery sorry to bug on this topic, but I'm hoping to make a push early this year to fully migrate my lab off GATK3 . I looked more closely at the specific annotations we need to migrate. I decided that I will implement our walker, 'DiscvrVariantAnnotator', which is basically a light wrapper around VariantAnnotation. This will make it easier to spike in custom annotations. In that walker, I will override makeVariantAnnotations(). I will make a new marker interface for EngineAwareAnnotation, and test that on all the Annotation classes, and use this to inject FeatureManager. So no core GATK changes needed. I did find one thing I'd like to propose. You probably know PedigreeAnnotation is special-cased in GATK. Annotations that use it have automatic argument validation and have the SampleDB injected. Currently, PedigreeAnnotation is a subclass of InfoFieldAnnotation, so isnt available to GenotypeAnnotations. There doesnt appear to be a solid reason why. I tried to fix that and my best idea is the proposal here: #7041 . The core idea is to convert InfoFieldAnnotation and GenotypeAnnotation to interfaces. This is generally a trivial switch in existing code. With that, it becomes possible for classes that currently extend PedigreeAnnotation (which I switched to no longer extend InfoFieldAnnotation) to simply PedigreeAnnotation and implement InfoFieldAnnotation. This makes it possible for future classes to extend PedigreeAnnotation and implement GenotypeAnnotation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063:561,inject,inject,561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063,3,"['inject', 'validat']","['inject', 'injected', 'validation']"
Security,"@jamesemery, researcher has uploaded data to </humgen/gsa-scr1/pub/incoming/Exception_in_SplitNCigarReads.tgz> and has clarified a few other details within the forum thread, e.g. running ValidateSamFile `IGNORE=MISSING_TAG_NM IGNORE=MATE_NOT_FOUND` allows for validation. Thanks for looking into this. ---. Hello,. I am getting the following exception when running SplitNCigarReads on RNA-Seq data using GATK 4.0.8.1:; ```; java.lang.ArrayIndexOutOfBoundsException: 100; 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.overhangingBasesMismatch(OverhangFixingManager.java:313); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.fixSplit(OverhangFixingManager.java:252); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.addReadGroup(OverhangFixingManager.java:209); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.splitNCigarRead(SplitNCigarReads.java:270); 	at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.firstPassApply(SplitNCigarReads.java:180); 	at org.broadinstitute.hellbender.engine.TwoPassReadWalker.lambda$traverseReads$0(TwoPassReadWalker.java:62); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5230:187,Validat,ValidateSamFile,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5230,2,"['Validat', 'validat']","['ValidateSamFile', 'validation']"
Security,"@jamesemery: thank you. however, I am probably missing something obvious here. i tried to access this using 'gsutil cp'; however, i get an AccessDeniedException: bbimber@gmail.com does not have storage.objects.list access to variant-eval-test-data. Should I, and/or is there another way to access this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-363220456:90,access,access,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-363220456,4,"['Access', 'access']","['AccessDeniedException', 'access']"
Security,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:48,access,accessing,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016,1,['access'],['accessing']
Security,"@jean-philippe-martin ; Thanks for the input. I've checked both `gs://broad-dsde-methods-shuang/pb/bams/NA12892/` and `gs://broad-dsde-methods-sv/samples/G94797_CHM_MIX/WGS1/tmp`, they return something like this. ```; gs://broad-dsde-methods-shuang/pb/bams/NA12892/:; Creation time: Mon, 22 Apr 2019 16:14:50 GMT; Update time: Mon, 22 Apr 2019 16:14:50 GMT; Storage class: STANDARD; Content-Length: 11; Content-Type: text/plain; Hash (crc32c): XkI+Dw==; Hash (md5): apnFdauH+MfR7R5S5+NJzg==; ETag: CJekwKSM5OECEAE=; Generation: 1555949690032663; Metageneration: 1; ACL: [; {; ""entity"": ""project-owners-222581509023"",; ""projectTeam"": {; ""projectNumber"": ""222581509023"",; ""team"": ""owners""; },; ""role"": ""OWNER""; },; {; ""entity"": ""project-editors-222581509023"",; ""projectTeam"": {; ""projectNumber"": ""222581509023"",; ""team"": ""editors""; },; ""role"": ""OWNER""; },; {; ""entity"": ""project-viewers-222581509023"",; ""projectTeam"": {; ""projectNumber"": ""222581509023"",; ""team"": ""viewers""; },; ""role"": ""READER""; },; {; ""email"": ""shuang@broadinstitute.org"",; ""entity"": ""user-shuang@broadinstitute.org"",; ""role"": ""OWNER""; }; ]; ......; ......; ```. The line the `Content-Length: 11` seems to suggest you are right.; And if I run `gsutil ls -lh gs://broad-dsde-methods-shuang/pb/bams/NA12892/`, I get; ```; 11 B 2019-04-22T16:14:50Z gs://broad-dsde-methods-shuang/pb/bams/NA12892/; ......; ......; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-492762131:429,Hash,Hash,429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-492762131,2,['Hash'],['Hash']
Security,"@jean-philippe-martin Can you comment on this error with your thoughts? Despite now doing a channel reopen on `UnknownHostException` in our fork of the NIO library, all reopens are failing, which implies that this error can't be recovered from via a simple retry. Could there be something wrong in our authentication setup?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412906931:302,authenticat,authentication,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412906931,1,['authenticat'],['authentication']
Security,"@jean-philippe-martin Can you comment on this one? It looks like `google-cloud-java` recently bumped their `google-auth-library-credentials` and `google-auth-library-oauth2-http` dependencies to `0.8.0` -- was there some change that would require us to modify our authentication-related code in GATK, and/or the permissions setup in our Google Cloud project, that could explain the error:. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001:264,authenticat,authentication-related,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001,3,"['access', 'authenticat', 'secur']","['access', 'authentication-related', 'security']"
Security,"@jean-philippe-martin I like your counter proposal in general for testing path integration. I think writing to GCS over NIO is an important enough feature that we should have at least 1 test in gatk that actually writes to a real GCS bucket in case there's ever an issue specifically with GCS (authentication issues are one potential problem I can imagine). . It seems like we should be able to design in a way that avoids collisions. What does `Files.createTempFile()` do with gcs? My guess is that it probably doesn't do the right thing, but maybe we could fix it so it would? Or use some sort of scheme with random UUID's like the methods in BucketUtils that we have already.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332235140:294,authenticat,authentication,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332235140,1,['authenticat'],['authentication']
Security,@jean-philippe-martin I think we can set up a repro by creating a new github project with a simple travis build that just does an NIO access. I don't think we can reproduce it locally since I'm pretty sure it's a bad interaction with the environment.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516890466:134,access,access,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516890466,1,['access'],['access']
Security,"@jean-philippe-martin Review complete. Looks good modulo the ReadSource stuff. I'm concerned about the reinvention of ReadsSource, so I think we should probably patch the validation stringency issue before pulling this into main. I see that you have a patch for it already, so that means we should probably review that quickly.. It does seem like you're doing a bunch of work which is very close to the existing `DataflowReadsPipeline`. It would be good to be able to unify those in the future so that future tools wont have to deal with getting reads and headers and the like. Have you considered filtering out unconvertible Reads with a filter applied before the ReadTransform step? It would decouple the issue of ""our conversion is broken"" from the implementation of BQSR at some cost in speed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/556#issuecomment-110877031:171,validat,validation,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/556#issuecomment-110877031,1,['validat'],['validation']
Security,"@jean-philippe-martin Thank you for putting this together, but performing authentication and reading the first byte might be too small a test for running on the Cloud. Could you run a profile test using `gcloud-java-nio` with 100 GB, 500 GB, 1 TB, 10 TB of data and process it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2013#issuecomment-233417619:74,authenticat,authentication,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2013#issuecomment-233417619,1,['authenticat'],['authentication']
Security,"@jean-philippe-martin The bug is in a piece of code that ISN'T using NIO, but is using some old code from the dataflow days to access the bam. I think that we can replace that code now that NIO is working and we should no longer need these special cases for GCS files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277832993:127,access,access,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277832993,1,['access'],['access']
Security,@jean-philippe-martin What happens if someone tries to read a `gs:` path but they don't have the correct/any authentication?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2013#issuecomment-233445289:109,authenticat,authentication,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2013#issuecomment-233445289,1,['authenticat'],['authentication']
Security,"@jean-philippe-martin When you patch this one, could you also audit the rest of `CloudStorageReadChannel` for any other methods that could trigger a GCS access and require retries?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314549425:62,audit,audit,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314549425,2,"['access', 'audit']","['access', 'audit']"
Security,@jean-philippe-martin since you have push access to this repo you should be able to force travis to rerun a branch if you're logged in,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1662#issuecomment-207072471:42,access,access,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1662#issuecomment-207072471,1,['access'],['access']
Security,"@jean-philippe-martin, we want to expose a walker-like interface, but we also care about the general ease of writing programs using the tools we and the user wrote (in native Dataflow/Spark). This is a point that @droazen, has emphasized to me several times. I'll let him add more detail on this if needed. I agree that the static approach won't work for Dataflow when workers are added, but I think I have a solution for Spark that works even when workers are added.; We'd create a new class (like I suggested above), but this would have a `Broadcast<SAMFileHeader>`, which is basically a lazy-loader for headers. We'd only load the header when needed.; I think this may be the best of all solution as it could also support several headers.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141177047:34,expose,expose,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141177047,1,['expose'],['expose']
Security,"@jhl667 I'm looking into this. It looks like I neglected to set the sqlite connection to read only mode when connecting to the db file. I'm going to update it to do so. I'm not sure this applies when a read-only connection is created, but it looks like sqlite has some issues with NFS / distributed file systems:; - https://stackoverflow.com/questions/9907429/locking-sqlite-file-on-nfs-filesystem-possible ; - https://github.com/CGATOxford/CGATPipelines/issues/. One post in the github thread above mentions using `-o flock` when mounting Lustre partitions so that they all have concurrent locks. This _may_ be a workaround in the meantime. . I'll try to look at it on our NFS mounts - I don't have access to a Lustre fs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4413#issuecomment-366009015:700,access,access,700,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413#issuecomment-366009015,1,['access'],['access']
Security,"@jhl667, yep, I understand. Still, this issue is too big to be left alone. I think the Broad has to act here, since patient's lives are at stake and we didn't receive any actionable response for half a year. Mutect2 has a good reputation, and the Broad profits from that, but it is also medical software and it should be treated as such. Mutect2 will continue to be used for some time, and this has to be fixed. @droazen, is there anything else you people can do? Is the wider GATK dev team aware of the issue? Is this something I should escalate to someone else so that you get support from your management to fix it? We have pharma collabs with the Broad in place, I could try doing it that way, or via the genomics/pharma community. I'm not trying to be threatening or anything, just thinking out loud how we can help you to get the resources to solve this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1404845998:757,threat,threatening,757,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1404845998,1,['threat'],['threatening']
Security,"@jkobject Actually, we just noticed that your error is triggered by the file `gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/5c2db926-3b1c-479c-9ed3-a99ce518de91/omics_mutect2/60955825-7723-4bc9-8202-bdd9975bb5c0/call-mutect2/Mutect2/7d737efc-c8be-4a6d-8803-4f786129521a/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list`, not the bam. Could you attempt the `gsutil` test on that file instead, and let us know what happens? Eg.,. ```; gsutil -u broad-firecloud-ccle cp gs://fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/5c2db926-3b1c-479c-9ed3-a99ce518de91/omics_mutect2/60955825-7723-4bc9-8202-bdd9975bb5c0/call-mutect2/Mutect2/7d737efc-c8be-4a6d-8803-4f786129521a/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list .; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064482965:86,secur,secure-,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064482965,2,['secur'],['secure-']
Security,"@jkobject Our testing of the nightly image with our own service account and billing project suggests that the requester pays access issue is resolved, so we're not sure what's causing it to continue to fail for you. As an experiment, could you try this: within the gatk-nightly image, try to access your requester pays file `gs://cclebams/wgs_hg38/CDS-0b4jFH.wgs_ccle.bam` using the `gsutil` command with the `-u` option. Eg., `gsutil -u broad-firecloud-ccle cp gs://cclebams/wgs_hg38/CDS-0b4jFH.wgs_ccle.bam .`, and report whether that succeeds. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064477058:125,access,access,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064477058,2,['access'],['access']
Security,"@jkobject That appears to be a different error: ""User project specified in the request is invalid"" instead of ""Bucket is a requester pays bucket but no user project provided"", which was the error this patch fixed. Can you confirm that the `broad-firecloud-ccle` project exists and is authorized under your service account? . @lbergelson Can you comment further on this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064417440:284,authoriz,authorized,284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064417440,1,['authoriz'],['authorized']
Security,"@john-alexander Just to be sure, you've checked that file is accessible to singularity?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-685813946:61,access,accessible,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6446#issuecomment-685813946,1,['access'],['accessible']
Security,"@jonn-smith I have sucessfully built GATK by these commands. git clone https://github.com/broadinstitute/gatk; gradlew bundle. I've got this zip file in folder ""build"".; gatk-4.0.4.0-34-g2cc7abd-SNAPSHOT.zip. So I unzipped and used this to replace GATK-4.0.4.0 that I downloaded from https://github.com/broadinstitute/gatk/releases/download/4.0.4.0/gatk-4.0.4.0.zip. I still found errors. 21:09:33.811 INFO ProgressMeter - Starting traversal; 21:09:33.811 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 21:09:46.267 INFO ProgressMeter - chr1:24929636 0.2 3000 14453.2; 21:09:59.072 INFO ProgressMeter - chr1:64681324 0.4 6000 14251.2; 21:10:09.456 INFO ProgressMeter - chr1:156245393 0.6 9000 15149.8; 21:10:21.510 INFO ProgressMeter - chr1:206965947 0.8 12000 15094.7; 21:10:26.132 INFO Funcotator - Shutting down engine; [May 23, 2018 9:10:26 PM ICT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 1.36 minutes.; Runtime.totalMemory()=11500781568; java.lang.IllegalArgumentException: Genomic positions must be > 0.; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:722). What should I do? Can you send me one that is ready-to-use? Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391371859:1134,validat,validateArg,1134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391371859,1,['validat'],['validateArg']
Security,"@jonn-smith Is there a forum post (or other docs) on how to setup a datasource for remote, NIO access? Do we make it clear that this only supports what the GATK supports?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5425#issuecomment-439976455:95,access,access,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5425#issuecomment-439976455,1,['access'],['access']
Security,"@kachulis Thanks for the report. The fix will be slightly complicated by the fact that there is also a (GATK-tool) level arg called `masterSequenceDictionary`. So in the override, we'll want to validate/resolve that argument against the others as well. If you need a short term workaround, you can try disabling on-they-fly indexing (`--create-output-variant-index false`, and then index the output separately using `IndexFeatureFile`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5087#issuecomment-411051092:194,validat,validate,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5087#issuecomment-411051092,1,['validat'],['validate']
Security,"@kcibul Does @jean-philippe-martin's suggestion above work for you, or are you still having authentication issues when running using a service account?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-284507997:92,authenticat,authentication,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-284507997,1,['authenticat'],['authentication']
Security,"@kcibul My reasoning for doing it in WDL is to better integrate with the process that creates the VAT table, and therefore make sure that the person running it has access (and knows the location of) not only to the VAT table but also the intermediary steps (e.g. the annotation JSON files that are output from NIRVANA). Not all of the validation steps need to be all bash; the first one was because it's literally just a call to make sure a table exists and has rows with `vid` values in it. Other rules (e.g. [rule #2](https://github.com/broadinstitute/dsp-spec-ops/issues/365)) will most likely need either python or jq to run.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883457790:164,access,access,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883457790,2,"['access', 'validat']","['access', 'validation']"
Security,"@kcibul reports that if the CNNScoreVariants python code throws an exception during async batch processing, the GATK tool hangs (specifically, it was happening when GATK was sending a . for a missing annotation, and the python code was trying to interpret that as a number and blowing up). It looks like this happens because `StreamingPythonScriptExecutor::waitForPreviousBatchCompletion` waits for the async write thread `Future` to complete first, before checking the fifo for an `ACK`/`NCK` (which is when the exception would be propagated). If the async write thread is blocked because the fifo is full because the python code isn't retrieving data because an exception was thrown, the java side will hang waiting for the `Future` complete. The solution is to reverse the order of the `waitForPreviousBatchCompletion` checking (ack first, then validate that the async write `Future` completes). There is a [branch]( https://github.com/broadinstitute/gatk/tree/cn_async_python_exception) with a test and a fix for the StreamingPythonExecutor, and a [separate branch](https://github.com/broadinstitute/gatk/tree/cn_cnn_exception) with a test for CNNScoreVariants that also has the executor fix. I need to verify that the CNNSCoreVariants test actually fails without the fix, and then this can be turned into a PR, which I'll do when I return from vacation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7401:848,validat,validate,848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7401,1,['validat'],['validate']
Security,"@kdatta @kgururaj It seems like we're losing rsID's in the input gvcf when we load them into genomics db. Is this deliberate to save space? Is it a bug? Is it a configuration option that isn't exposed by `GenomicsDBImport`? . I don't think it's important for production because they pass in a dbSNP at genotyping time so that can be recomputed, but it's causing issues in some of my tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2636:193,expose,exposed,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2636,1,['expose'],['exposed']
Security,@kdatta Why not use some kind of globally-unique identifier for the arrays if name collision is an issue (such as a hash or UUID)? Would that solve the problem?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320325990:116,hash,hash,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320325990,1,['hash'],['hash']
Security,"@kgururaj . So I found out that there are other fields that are also throwing a similar error with `vcf-validator`:. Below you will find this: `INFO tag [an_adj_exac_oth=16,16] expected different number of values (1)`. ```; # from the vcf-validator; INFO field at 4:2044128 .. INFO tag [af_exac_all=0] expected different number of values (expected 3, found 1),INFO tag [af_adj_exac_fin=0] expected different number of values (expected 3, found 1),INFO tag [an_adj_exac_oth=16,16] expected different number of values (1),INFO tag [an_adj_exac_nfe=202,202] expected different number of values (1),INFO tag [an_adj_exac_afr=20,20] expected different number of values (1),INFO tag [af_adj_exac_amr=0] expected different number of values (expected 3, found 1),INFO tag [an_exac_all=1246,1246] expected different number of values (1),INFO tag [an_adj_exac_amr=10,10] expected different number of values (1),INFO tag [af_adj_exac_oth=0] expected different number of values (expected 3, found 1),INFO tag [an_adj_exac_eas=30,30] expected different number of values (1),INFO tag [an_adj_exac_fin=2,2] expected different number of values (1),INFO tag [an_adj_exac_sas=966,966] expected different number of values (1),INFO tag [af_adj_exac_sas=0] expected different number of values (expected 3, found 1),INFO tag [af_adj_exac_afr=0] expected different number of values (expected 3, found 1),INFO tag [af_adj_exac_nfe=0] expected different number of values (expected 3, found 1),INFO tag [max_aaf_all=1] expected different number of values (expected 3, found 1),INFO tag [af_adj_exac_eas=0] expected different number of values (expected 3, found 1); ```. In this case, `an_adj_exac_oth` has > 1 values and only 1 is allowed:. ```; grep ; ##INFO=<ID=an_adj_exac_oth,Number=1,Type=Integer,Description=""Other Chromosome Count (from /mnt/isilon/cbmi/variome/bin/bcbio-nextgen/bcbio/gemini_data/ExAC.r0.3.sites.vep.tidy.vcf.gz)"">. # the corresponding variant in the vcf ; 4	2044128	.	C	T,CGCT,<NON_REF>	3476.7	.	DP=97",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407497476:104,validat,validator,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407497476,2,['validat'],['validator']
Security,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:1615,access,access,1615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071,1,['access'],['access']
Security,@knight2015 I'm sorry to say we don't support spark 3.0.0 a the moment. If you have access to a spark 2.4.x cluster I would try that.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6644#issuecomment-640701152:84,access,access,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644#issuecomment-640701152,1,['access'],['access']
Security,@ksw9 can you run the vcf validator tool suggested by @komalsrathi in #5045 [here](https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407476343)? The issue is primarily caused by mismatch in the field description in the VCF header and the data lines. @droazen can you comment on the [sanity check that I suggested here](https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407501684)?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413282882:26,validat,validator,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413282882,1,['validat'],['validator']
Security,"@lbergelson @droazen Both of you committed changes to the Dockerfile recently, but as far as I can tell they are not security related. Should I keep this PR at [4.2.4.1](https://hub.docker.com/layers/broadinstitute/gatk/4.2.4.1/images/sha256-421d2fb2cc869249cef3f4d7a77289256d295b04ba623096228e0e5fd42939e9?context=explore)?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7611#issuecomment-1048281865:117,secur,security,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7611#issuecomment-1048281865,1,['secur'],['security']
Security,@lbergelson @gokalpcelik any chance of giving me access to the workspace for the 330 whole exomes?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2433346908:49,access,access,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2433346908,1,['access'],['access']
Security,"@lbergelson For the `isinf` error, let's try this change in common_data_structure.h. ```; - if (isinf(small) == -1 || isinf(big) == -1); + if (std::isinf(small) == -1 || std::isinf(big) == -1); ```. The gettime related errors are because mac doesn't support clock_gettime ([discussion here](http://stackoverflow.com/questions/5167269/clock-gettime-alternative-in-mac-os-x)). The code in util.cc is part of some unused sandbox code, which can be removed. Try this command to check for AVX support on mac. ```; sysctl -a | grep machdep.cpu.features; ```. I'll try to get access to a mac to help the build debug go faster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187840330:569,access,access,569,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-187840330,1,['access'],['access']
Security,"@lbergelson Hi, thank you for your kind reply. Following is the report of ValidateSamFile:; Tool returned: 3; ERROR::RECORD_OUT_OF_ORDER:Record 86076959, Read name A00583:183:HLCWVDMXX:1:1114:30897:16579, The record is out of [coordinate] order, prior read name [ST-E00159:680:H57NGCCX2:6:2201:21765:57301], prior coodinates [22:51244173]; ERROR::MATE_NOT_FOUND:Read name ST-E00159:680:H57NGCCX2:6:2208:30289:5300, Mate not found for paired read; ERROR::MATE_NOT_FOUND:Read name A00583:183:HLCWVDMXX:1:1236:31611:36793, Mate not found for paired read; ...... The Result really supprised me! However, mutect2 and haplotypecaller are ok with the input of the resulted bam indexed with samtools. I also found that the conclusion of ""Mate not found for paired read"" is True. The bam was generated by: fastq ->mergeBam( bwabam + (fastq->ubam) ) -> markdup+sortAndFixTags -> applyBQSR -> gatherBam. Steps of Bwa and BQSR were paralleled with Intervals. And, I am sure that all my inputs are in consistent order. Example of interval specified: ""-L chr21:1+ -L chr22:1+"". Looking foward to your reply.; Best Regards!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6379#issuecomment-575985383:74,Validat,ValidateSamFile,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6379#issuecomment-575985383,1,['Validat'],['ValidateSamFile']
Security,@lbergelson I added a second argument per your request. I still disagree that this is the right argument to expose because it is very dangerous.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5974#issuecomment-497383571:108,expose,expose,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5974#issuecomment-497383571,1,['expose'],['expose']
Security,"@lbergelson I added an integration test that writes to GCS... it doesn't work for me (""com.google.cloud.storage.StorageException (...) does not have storage.objects.get access to (...)""). This may be due to a misconfiguration on my end. I wonder if it'll work with Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-334877523:169,access,access,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-334877523,1,['access'],['access']
Security,"@lbergelson I agree with you about moving tests up, though I would make the point that there were many tests that got pushed down in the first place because they would involve fixing bugs in MarkDuplicatesGATK that were already fixed in MarkDuplicatesSpark, I will audit the ones I did and didn't push up so i'm more confident there is a reason to have tests pushed down or not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5166#issuecomment-419550902:265,audit,audit,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5166#issuecomment-419550902,1,['audit'],['audit']
Security,"@lbergelson I disagree -- it's very clear to me that those tests will trigger Google authentication, just by tracing through the code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2706#issuecomment-300806909:85,authenticat,authentication,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2706#issuecomment-300806909,1,['authenticat'],['authentication']
Security,"@lbergelson I updated to the latest 2.x Mockito and that fixed the problem. The only failing test now is FuncotatorIntegrationTest#nonTrivialLargeDataValidationTest. The output VCF differs in the `FUNCOTATION` annotation, and it’s to do with ordering of the fields. E.g. it will be. ```; 1_%7C_1|false_%7C_false|false_%7C_false; ```; not; ```; false_%7C_false|1_%7C_1|false_%7C_false; ``` . It looks like it could be a case of using HashSet not LinkedHashSet, or HashMap not LinkedHashMap - but a quick replace throughout the GATK and HTSJDK codebase didn’t fix the problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532593427:433,Hash,HashSet,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532593427,2,['Hash'],"['HashMap', 'HashSet']"
Security,"@lbergelson I was referring more to the middle part of the StackOverflow by Daniel Chapman - specifically the [4.1 The ObjectStreamClass Class](http://docs.oracle.com/javase/8/docs/platform/serialization/spec/class.html#a5082) and [4.6 Stream Unique Identifiers](http://docs.oracle.com/javase/8/docs/platform/serialization/spec/class.html#a4100):. _If not specified by the class, the value returned is a hash computed from the class's name, interfaces, methods, and fields using the Secure Hash Algorithm (SHA) as defined by the National Institute of Standards._. Now when I look at the `java.io.ObjectStreamClass.java` file for 64-bit JDK7 and JDK8 - from src.zip - both have the same code for the following parts after performing a `diff` - I didn't list all of the lines of code since they are quite long:. ```; public long getSerialVersionUID() {; // REMIND: synchronize instead of relying on volatile?; if (suid == null) {; suid = AccessController.doPrivileged(; new PrivilegedAction<Long>() {; public Long run() {; return computeDefaultSUID(cl);; }; }; );; }; return suid.longValue();; }; ... private static long computeDefaultSUID(Class<?> cl) {; ...very long code which can be inspected via the src.zip file...; }; ```. So looking at the code portions of `computeDefaultSUID()` and I notice in our instance `ReadFilter` is a interface, which gets defined later via [ReadFilterLibrary.java](https://github.com/broadinstitute/hellbender/blob/62ef76ba60951c562a0d4c39189aa3f01f27f8d3/src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilterLibrary.java) or via `new ReadsFilter(readFilter, header)`, in either of these instances the fields would be different, based on this portion of `computeDefaultSUID` when looking at declared fields:. ```; Field[] fields = cl.getDeclaredFields();; MemberSignature[] fieldSigs = new MemberSignature[fields.length];; for (int i = 0; i < fields.length; i++) {; fieldSigs[i] = new MemberSignature(fields[i]);; }; ```. Therefore the `SUID` would be ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499:404,hash,hash,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499,4,"['Access', 'Hash', 'Secur', 'hash']","['AccessController', 'Hash', 'Secure', 'hash']"
Security,"@lbergelson Louis, I run into the similar trouble when I enable GATK to access oss fs of Aliyun, our oss of hadoop-fs impl (org.apache.hadoop.fs.{FileSystem, Path}) work well with spark perfectly but oss provider (java.nio.file.spi.FileSystemProvider) is not available today. (Not included in gatk package gatk-4.beta.6. . After I researched on [SparkContext](; https://github.com/apache/spark/blob/1c9f95cb771ac78775a77edd1abfeb2d8ae2a124/core/src/main/scala/org/apache/spark/SparkContext.scala) impl and [GATK rg.seqdoop.hadoop_bam.AnySAMInputFormat](https://github.com/broadinstitute/gatk/search?utf8=%E2%9C%93&q=java.nio.file.FileSystem&type=Code) impl. [IOUtils](https://github.com/broadinstitute/gatk/blob/94ac626218e073b77156a3eff076003d26be318c/src/main/java/org/broadinstitute/hellbender/utils/io/IOUtils.java#L535). Today, org.apache.hadoop.fs.{FileSystem, Path} is much broadly used in the Big Data world, and most of vendors of distribution storage provider already provide impl of org.apache.hadoop.fs.{FileSystem, Path} include AWS, Google and Alibaba. There are huge customers of Hadoop already work on hadoop.fs for years, if GAKT on spark could rely on org.apache.hadoop.fs.{FileSystem, Path} , I guess GAKT could acquire more existing customers of Hadoop on Cloud much faster . . Maybe we could consider migrating java.nio.file.FileSystem impl to org.apache.hadoop.fs.{FileSystem, Path} impl in [SparkContextFacto]r(https://github.com/broadinstitute/gatk/blob/73f2a62bee52518b57a985717770ed3a64d83243/src/main/java/org/broadinstitute/hellbender/engine/spark/SparkContextFactory.java), otherwise we could support both nio and hadoop thru env variable, Let me know your thought!. ```; scala> stringRdd.saveAsTextFile(""oss://eric-new/testwrite10""). scala> val stringRdd = sc.parallelize(Seq(""Test String"")); stringRdd: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[4] at parallelize at <console>:24. scala> stringRdd.saveAsTextFile(""oss://eric-new/testwrite11""); ```. ``` oss",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-354989381:72,access,access,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-354989381,1,['access'],['access']
Security,"@lbergelson You may recall that we've encountered things like malformed block-compressed input that validates and can be read without error, and yet appears to have fewer records than it should.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317048503:100,validat,validates,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317048503,1,['validat'],['validates']
Security,@lbergelson changed it to `validate`. Anything else?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290780224:27,validat,validate,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290780224,1,['validat'],['validate']
Security,@lbergelson here is the new version of the tool with all of the integration tests hand-verified verses the old version of the tool. The output now consistently passes validation and there is now an option to turn on (it is off by default) the N-splitting of secondary alignments.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-239503282:167,validat,validation,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-239503282,1,['validat'],['validation']
Security,@lbergelson i didn't have you on the whitelist for that command. now i do. we want to explicitly authorize who can run that because it's essentially allowing pull-requests to run on our servers so we need a human thumbs-up.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1975#issuecomment-233026831:97,authoriz,authorize,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1975#issuecomment-233026831,1,['authoriz'],['authorize']
Security,@lbergelson thank you for the comment and sorry for my bit late response. I excluded the dependency to the jsr203-s3a and tested that both local- and spark-gatk can access s3a files by dynamically loading it. I also added a new directory `scripts/s3a` for documentation and simple tests for s3a demonstration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6698#issuecomment-665484597:165,access,access,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698#issuecomment-665484597,1,['access'],['access']
Security,"@lbergelson thanks for following up. To the first part:. ```; jar tvf GenomeAnalysisTK4.jar; echo $?; ```; returns 0. and this is:; ```; jar tvf ../bin/GenomeAnalysisTK4.jar | grep -i FileTruncatedException; 765 Wed Mar 17 12:09:12 PDT 2021 htsjdk/samtools/FileTruncatedException.class; ```; so seems ok. I will talk to the group that manages the cluster. one out there possibility is that this is based on a lustre filesystem, and there could be some cryptic cluster-specific access issue. i have no specific reason to believe this, but weird things have happened.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042022576:477,access,access,477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042022576,1,['access'],['access']
Security,"@lbergelson the NIO access would fail with a ""permission denied"" error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2013#issuecomment-233445717:20,access,access,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2013#issuecomment-233445717,1,['access'],['access']
Security,"@lbergelson, I don't think that this solution will help in this case, because another error when trying to use `CommandLineProgramTest`is that it extends `BaseTest`, which loads directly a `GenomeLocParser` for a reference that is not present and it blows up in every test. Regarding the `Main` class, because you point it out here, I would like to have some control over `Main` and how it manages things like errors or logging header. Basically all the things that I'm facing at the moment are, apart of this error using the testing framework, is that the framework have tons of mentions to the GATK itself (error messages pointing to the GATK manual page or bundle tools), and little control over which of them should be expose to the final user. Only as an example, I would like to output a line with the name and version of my software and a short notice about the usage of the GATK framework and which version I'm using (for easier maintenance, and contribution if a bug is found).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242802278:723,expose,expose,723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242802278,1,['expose'],['expose']
Security,"@lbergson's instructions above are good, but somehow they did not work for me. I was able to follow the [application default credentials](https://developers.google.com/identity/protocols/application-default-credentials) instructions, though. Here are the steps I took:. 1. create a new service account on the Google Cloud web page and download the JSON key file.; 2. gcloud auth activate-service-account --key-file ""$PATH_TO_THE_KEY_FILE""; 3. export GOOGLE_APPLICATION_CREDENTIALS=""$PATH_TO_THE_KEY_FILE"". I cleared my credentials first to make sure that the access worked because of the above steps, not because of other credentials. After those steps, gatk was able to run from my desktop and access files using the service account credentials. `gsutil ls` worked as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282900470:559,access,access,559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282900470,2,['access'],['access']
Security,"@ldgauthier Concordance with XHMM would definitely be useful for validating calls on clusters for which we do not have WGS data. ; We need to modify code for having a fixed common CNV regions, but that should be straightforward.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4738#issuecomment-387828741:65,validat,validating,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4738#issuecomment-387828741,1,['validat'],['validating']
Security,"@ldgauthier Feel free to open a ticket describing your dream sequence dictionary compatibility check -- we can make the existing check stricter if you think it's too permissive, since users are always free to run with `--disable-sequence-dictionary-validation`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3754#issuecomment-495336889:249,validat,validation,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3754#issuecomment-495336889,1,['validat'],['validation']
Security,"@ldgauthier If you feel that you need some validation, but less strict/expensive than the default, then I'd suggest turning off the default validation, writing your own scaled-down dictionary validation routine, and calling it from `onTraversalStart()` in your tool. Then if it seems like the scaled-down validation might be generally useful, we could hook it up to the `SequenceDictionaryValidationArgumentCollection` as a third engine-level option.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6589#issuecomment-625438251:43,validat,validation,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6589#issuecomment-625438251,4,['validat'],['validation']
Security,"@ldgauthier This is why the `--disable-sequence-dictionary-validation` argument exists in `GATKTool`. If you're confident in the compatibility of your inputs, and the checks are too expensive, you can run with that option and (optionally) perform some less strict validation of your own in your `onTraversalStart()` method.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6589#issuecomment-625366653:59,validat,validation,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6589#issuecomment-625366653,2,['validat'],['validation']
Security,"@ldgauthier and @jonn-smith . As discussed during the gatk office hours, this error traces back to ValidateVariants in GVCF mode being unable to handle variants with a lower start position than the previous contig.; Example:; Super-Scaffold_1 9238114 . T <NON_REF> . . END=9238123 GT:DP:GQ:MIN_DP:PL 0/0:12:0:11:0,0,0; Super-Scaffold_2 1 . G <NON_REF> . . END=4 GT:DP:GQ:MIN_DP:PL 0/0:31:93:31:0,93,1141",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6023#issuecomment-507376213:99,Validat,ValidateVariants,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6023#issuecomment-507376213,1,['Validat'],['ValidateVariants']
Security,@ldgauthier has volunteered to open a PR to expose this parameter -- should be part of the next GATK release,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1662611627:44,expose,expose,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1662611627,1,['expose'],['expose']
Security,"@ldgauthier this finishes what we started in #4858 and is necessary for the pileup-calls-on-bamouts MC3 validation. The cause is the same, in that Pair-HMM has a tiny bias in favor of shorter haplotypes and thus it prefers deletion haplotypes when reads end inside STRs. In #4858 we broke near-ties in favor of the reference; this PR fixes the case where two alt haplotypes share a SNV and one of them has a spurious deletion. One important sanity check was that when I set `cigarTerm` to zero in `AssemblyBasedCallerUtils.java` no tests broke. This means that the refactoring needed to set up the change didn't affect behavior. I looked at most of the sites where `PL`s and/or `DP`s changed in the integration test vcfs and in every case the difference was from a fake deletion that this PR fixed. I also went through the diff of the bamouts in IGV and found the same thing. Finally, the changes to test vcfs in `GenotypeGVCFsIntegrationTest` and `GenomicsDBImporterIntegrationTest` are a consequence of changes to the `HaplotypeCallerIntegrationTest` vcfs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5359:104,validat,validation,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5359,1,['validat'],['validation']
Security,"@lucidtronix Are the environment variables that you added to the Docker env essential to realize the speed 2x improvement ? I'm reluctant to just add them to the Docker env without understanding what they're doing and whether/how they impact other components. i.e., changing OPEN_MP thread affinity/pinning params etc. might impact the native Intel PairHMM implementation (also @samuelklee will these impact CNV) ? Another option is reduce the scope of them and set them only for the specific tool(s), possibly exposed as command line arguments. The ScriptExecutor has control over the python process' environment and could easily propagate them to the so they only affect the particular Python process. But the values would have to be provided somehow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475614790:511,expose,exposed,511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475614790,1,['expose'],['exposed']
Security,"@magiDGS My preference would be to do a single PR with all of the fixes for the enable/disable validation rules and allowed values changes, and only those changes. Then we can do a second one with the extensibility changes. You can decide if you want to close this PR, or use it as the basis for the second one - either way is fine with me. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-278328215:95,validat,validation,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-278328215,1,['validat'],['validation']
Security,"@magicDGS Args like the config file that are truly optional (have no default value at all) do not show up in the command line or headers unless they're populated with some value. It should be pretty easy for ReadTools (which I think already has a common base class for its tools), to ensure a config file is never accepted by just precluding it via custom command line validation, or arg preprocessing. BTW, all tools built with GATK already have numerous common args that may or may not apply in a given tool context. For example, all of the ReadWalkers have a `--lenientVCFProcessing` arg. So I'm not even sure we need to make this hidden, since it will hide it from gatk users. My 2 cents. Others may feel differently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371819413:369,validat,validation,369,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371819413,1,['validat'],['validation']
Security,"@magicDGS Good question! The main requirement is that the APIs need to allow you to *optionally* pass in URIs/Paths for all of the ""companion files"" for a particular input. For example, the `fai` and `dict` files for a fasta, or the `bai` file for a bam. When using signed URIs for authentication, these would all have separate signed URIs that would need to be provided explicitly. Of course, there should also be API methods that don't require you to pass in all of the companion files, and instead infer them automatically from the Path to the primary input, as htsjdk currently does. We would use these whenever possible (eg., when using account-level authentication rather than signed URIs, or when no authentication is necessary).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5269#issuecomment-429064032:282,authenticat,authentication,282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5269#issuecomment-429064032,3,['authenticat'],['authentication']
Security,"@magicDGS I glanced at the tests and it appears there may be a scientific validation component, which I am unfamiliar with (I'm in an intro to Java course currently). Is this the case? If scientific validation is needed, then it is best to involve someone familiar with validation, e.g. Laura or Yossi. If all you need is data that can be run through these commands, I can put this together. Let me know. I'm late to these efforts, but I'd like to check one thing. Because of the way GRCh38 contigs are parsed, e.g. the HLAs that contain colons in their names, I believe we now prefer Picard-style intervals lists that tab-separate values instead of the `10:96000399-96000421` format that RealignerTargetCreator produces. I'm not certain of the status of GATK-style intervals lists, but I do know that the CNV developers have swiched to Picard-style. Is this what is produced by the new RealignerTargetCreator?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371506127:74,validat,validation,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371506127,3,['validat'],['validation']
Security,"@magicDGS I'd strongly prefer not to introduce a read filter descriptor hierarchy if we can avoid it, as it will be tricky to get right, and add complexity. We definitely need to be able to extend the package list used by the descriptor to find plugins, but as you point out we'll be able to use the configuration mechanism for that. For before/after-analysis filters, I expect that we'll just add that directly to the existing plugin once we resolve https://github.com/broadinstitute/gatk/pull/2085 (which I hope to get to this week). I think the rest of the cases can be addressed by overriding makeReadFilter and providing custom behavior of filter merging. If this turns out to be something truly common, we could consider allowing the tool to inject an argument collection into the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-274970451:748,inject,inject,748,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-274970451,1,['inject'],['inject']
Security,"@magicDGS My apologies for the long delay on this. It looks like there are still quite a few standard porting issues that need to be addressed in this PR (brackets, finals, multiple top-level public classes, outdated GATK3 usage example, remove references to RODs, kebabify, etc., etc.). There is also the bigger issue of testing and validation - ideally at a minimum we'd reproduce the existing GATK3 tests, but since these are dependent on large, private files, those tests will have to be replaced with new tests, and validated/compared against GATK3. These same issues will come up with IndelRealigner. @vdauwera @sooheelee Even with @magicDGS graciously volunteering to do the work of porting the code, retaining the indel realignment tools will require internal review, helping with test development and validation, and support. Before we commit to that, I guess I want to make sure that this is indeed a high priority, and that you think porting this to GATK4 is a better option than relying on GATK3, or letting @magicDGS port it to ReadTools ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643:334,validat,validation,334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643,3,['validat'],"['validated', 'validation']"
Security,"@magicDGS Sorry for the delay on these AssemblyRegion-related PRs. There is an effort at the Broad right now to validate the GATK4 `HaplotypeCaller` against the GATK3 version. Until this is complete, we're not accepting even minor changes to code on the critical path for the `HaplotypeCaller`, except for bug fixes that arise from the validation work. It's still possible that as a result of this validation work `AssemblyRegionWalker` may get refactored/altered to address problems discovered, so until we have a final version that produces acceptable results for `HaplotypeCaller` (and we're not quite there yet) other changes to that part of the codebase will have to wait. Sorry for the inconvenience -- once GATK4's `HaplotypeCaller` gets the official stamp of approval we will certainly find a way to get all of your changes in. In the mean time we have to ask you to be patient a little longer!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2371#issuecomment-287447471:112,validat,validate,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2371#issuecomment-287447471,3,['validat'],"['validate', 'validation']"
Security,"@magicDGS The problem with exposing the datasources to walkers is that they would be able to invalidate the entire traversal. For example, a `ReadWalker` could alter the traversal intervals on the reads datasource mid-way through traversal from within `apply()`, or it could cause the reads iterator used by the engine to get closed by issuing a separate `iterator()` call on the datasource, which would cause the rest of the traversal to fail. This is why I feel strongly that the datasource objects should not be directly accessible to walker-based tools. Note that it's still possible for walkers to create their own, separate datasources without reaching into the ones used by the engine, or a tool author can extend `GATKTool` directly rather than one of the walker base classes and have the freedom to access everything (which was not possible before this PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4964#issuecomment-401423305:524,access,accessible,524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4964#issuecomment-401423305,2,['access'],"['access', 'accessible']"
Security,"@magicDGS There isn't a specific master branch, but each push to master gets it's own artifact with a name like 4.alpha.1-208-g702c9e3-SNAPSHOT. You can search for the short commit hash of the build you want and use that artifact. . you'll need to add the artifactory repository to your build file. ```; repositories {; maven {; url ""https://artifactory.broadinstitute.org/artifactory/libs-snapshot/"" ; }; ```. There seems to be some bug right now where it hasn't uploaded the last 2 commits to master, I'm not sure what's causing that, but in general there should always be the most recent commits to master available. (As well as a snapshot of every pull request branch). It wouldn't be a bad idea for us to have master-SNAPSHOT as well, maybe we should do that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1985#issuecomment-231406928:181,hash,hash,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1985#issuecomment-231406928,1,['hash'],['hash']
Security,"@magicDGS Yes, I think it would be much simpler if we had one PR with all of the fixes for the validation rules (and related help issues). The extensibility changes we've been discussing should be a separate PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278330318:95,validat,validation,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278330318,1,['validat'],['validation']
Security,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:957,Validat,ValidateSamFile,957,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600,2,"['Validat', 'validat']","['ValidateSamFile', 'validation']"
Security,"@marcopessoa, the fixes for this issue are not in master yet - here is the pending PR #6305. You could use the [genomicsdb_120_1](https://github.com/broadinstitute/gatk/tree/genomicsdb_120_1) branch to test out your scenario and post what you find to provide further validation for the changes in the PR. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-573447804:267,validat,validation,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-573447804,1,['validat'],['validation']
Security,@mbabadi Can you let me know about the validation tools today?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3887#issuecomment-348487741:39,validat,validation,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3887#issuecomment-348487741,1,['validat'],['validation']
Security,"@mbabadi I know for the hg38 runs you are using CalculateTargetCoverage, but in case you used SparkGenomeReadCounts for any other WGS runs you're looking at, here's another thing to be aware of when considering the duplicates issue. I'm also running into frequent errors when running SparkGenomeReadCounts for the WGS CNV validation that seem to be related to hadoop bam or binning errors. Let's move to @asmirnov239's new tool ASAP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3367#issuecomment-324935273:322,validat,validation,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3367#issuecomment-324935273,1,['validat'],['validation']
Security,"@mbabadi I've updated my PR to use miniconda3. @mbabadi @lucidtronix @samuelklee I think we should aim for tools that at least run out-of-box, without depending on any out-of-band configuration other than the conda env. On top of that we can provide guidance/configs for users on how to enable further optimizations, like g++. Does that sound like an achievable goal ?. As for the docker, we're going to have strike the right balance between image bloat and performance(including test performance). I think we're around 4+ gig now, and counting. Before the Python integration we were at 1.9G, and trying to find ways to reduce it. So lets see where we wind up but keep that in mind. Finally, we need to find a way to install the (GATK) python package(s) without depending on access to the GATK repo. Right now I think the gCNV branch has a ""pip install from source"" added to the conda env .yml. That will work on the docker at the moment (and thus on travis), but that won't work for non-docker users how don't have source/repo access. Also, one of the proposals to reduce the size of the docker is to remove the repo clone that is currently there. My proposal is that we change the gradle build to create an archive/zip of the python source (this would include the VQSR-CNN package code as well as gCNV kernel). We can then copy that on to the docker image, and pip-install it from the copy. That would retain the ability to always run travis tests based on the code in the repo, and also keep the nightly docker image in sync. We'll also have deliver the archive as an artifact somehow (perhaps including PyPi) for non-docker users.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350303277:775,access,access,775,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350303277,2,['access'],['access']
Security,"@mbabadi commented on [Thu Jan 05 2017](https://github.com/broadinstitute/gatk-protected/issues/842). - [ ] carefully document the exposed parameters of gCNV, mark the tricky ones as advanced and document use case",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2928:131,expose,exposed,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2928,1,['expose'],['exposed']
Security,"@mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1058). - [ ] good choice of default parameters; - [ ] double-check assertion coverage in `CoverageModelArgumentCollection.validate()`; - [ ] if a model is provided, ARD and number of PCs must be overridden (currently, an exception is thrown if there is a discrepancy between model parameters and arguments). Relevant discussion:; **Mehrtash**: We may be able to get rid of a number of these parameters. Though, generally speaking, I'd rather expose more than less, with good default values and bold advanced disclaimers w/ proper documentation as you suggested. This is the case with sophisticated tools like HaplotypeCaller, StarAligner, etc. Soon enough, we will get strange errors from various users many of which can be resolved by changing a certain advanced parameter. Without exposing them, we will have to create patches for them and/or build custom jars.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2995:218,validat,validate,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2995,2,"['expose', 'validat']","['expose', 'validate']"
Security,@mbabadi commented on [Tue May 02 2017](https://github.com/broadinstitute/gatk-protected/issues/1021). - [ ] factor I/O methods out of `CoverageModelEMWorkspace` and to a new class; - [ ] shrink the exposed API; - [ ] rename/refactor `CopyRatioCallingMetadata` appropriately; - [ ] rename/move `MathObjectAsserts` to test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2979:199,expose,exposed,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2979,1,['expose'],['exposed']
Security,@mcovarr @RoriCremer I have modified this now to fail outright if one of the validations fail. It now calls a GenerateFinalReport task as its last task and that will summarize the results in a way that (hopefully) makes it easier to understand the validation failure.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7850#issuecomment-1131987266:77,validat,validations,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7850#issuecomment-1131987266,2,['validat'],"['validation', 'validations']"
Security,"@mcovarr Hi Miguel - I just took a quick look at this branch, and it seems that it nicely addresses most of our needs for PGEN extract - specifically it would allow us to make an `ExtractCohortToPgen` that is just a slight variation of `ExtractCohortToVcf`. . There is one other thing we need though, which is a way to determine how many variants will be traversed *before* we traverse them. PGEN needs that up front, so we'd need it when we create the PGEN writer (currently it looks like that would be in the `ExtractCohortToPgen` `onStart` method). Is there any way to do that, and/or does it require access to the ExtractCohortEngine, which currently looks to private in the `ExtractTool` base class ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8344#issuecomment-1570383483:604,access,access,604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8344#issuecomment-1570383483,1,['access'],['access']
Security,"@meganshand Could you review this? It fixes most of the homoplasmic missed calls in broadinstitute/dsp-spec-ops#116. I reviewed all of the false positive that were introduced to our somatic validations when attempting to make this the default in non-mitochondria mode. Everything was due to mapping error, which I do not expect to be an issue in mitochondria, and not an inherent problem with recovering more dangling ends. You will still want to run this branch through some of your validations, however. In mitochondria mode it's the same as the dangling-1-29.jar that I shared earlier with you and Sarah.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5693:190,validat,validations,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5693,2,['validat'],['validations']
Security,"@meganshand Here's a quick example:. ![image](https://user-images.githubusercontent.com/11076296/158385742-20a3303b-d8ce-4335-b42f-622da9bfa8d3.png); ![image](https://user-images.githubusercontent.com/11076296/158385777-6174f8b8-7abb-4b31-92d1-11cc8064854b.png). Note that the malaria data used was pretty small: chr1-2 training (~20k positive training/truth variants, ~50k negative training variants; note also that the threshold for determining negative training was not tuned---a threshold corresponding to a 98% truth sensitivity was arbitrarily chosen), chr3 validation (~50k variants), and chr4-6 test (~150k variants). The LL score is calculated from a validation set held out from the training/truth positives used to train the model, while the F1 score is calculated using ""orthogonal truth"" positives/negatives determined using 3 families of ~30 trios each. However, there's some arbitrariness in how we define the boundary for the latter positives/negatives, and hence some arbitrariness in the F1 score itself. But I'd expect using gold-standard GIAB truth would be more straightforward. Not sure how much we can conclude, but that the validation and test F1s are similar and that the validation LL score isn't *too* far off are encouraging. That said, there is a pretty big drop in recall when optimizing LL. But we should also expect some discrepancy between LL and F1, according to one of the papers linked above. I would hope that with more variants or reliable training/truth (as in your data), things might stabilize or line up better. I'll try running with more malaria data, as well. The following trios x sites heatmap (top plot) for the validation set might better illustrate the arbitrariness in F1 (click to enlarge):. ![image](https://user-images.githubusercontent.com/11076296/158385585-1a0dfe8e-d4b7-4770-aed0-19ad81162c92.png). Here, yellow = het errors (since these are supposed to be clonal malaria samples), red = Mendelian errors, grey = no calls, green = Mendelian con",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1067396431:564,validat,validation,564,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1067396431,2,['validat'],['validation']
Security,"@meganshand I ran the ""Full Pipeline"" workflows in a clone of your FC workspace: https://portal.firecloud.org/#workspaces/broad-firecloud-dsde/copy-of-megans-m2-mito-validations. I did not run any of the things that generate graphs because they were harder for me to understand. To compare the new results to your previous ones, I took all variants that were either PASS or had only the contamination filter applied, extracted just the locus and alleles columns, then manually inspected the diff. For the 5% and 50% spike-ins there were usually no differences at all, while for the 1% spike-in the difference was usually 2-5 variants that straddled the LOD threshold.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5473#issuecomment-443745103:166,validat,validations,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5473#issuecomment-443745103,1,['validat'],['validations']
Security,"@meganshand There is a warning in the docs for `ReadCoordinateComparator` that it should not be used for bam file output that needs to match the ordering of `SAMRecordCoordinateComparator` exactly, since it sorts all unmapped reads after all mapped reads. `ReadCoordinateComparator` is a comparator for `GATKRead`, and that interface does not allow unmapped reads to have a position. Ie., even if an unmapped `SAMRecord` is assigned the position of its mapped mate, calling `getContig()`/`getStart()` on the unmapped read via the `GATKRead` interface will return null/0. This was done mainly for consistency reasons and to simplify client code. Whenever we need bam file order for reads in GATK4, we operate on SAMRecords directly and use either the `SAMRecordCoordinateComparator` from htsjdk or the `HeaderlessSAMRecordCoordinateComparator` (for headerless Spark reads) that produces the same ordering. I recommend addressing this for this tool via `presorted = false` for now, since the GATK3 version has it set to false as well with the comment: ""**we don't want to assume that reads will be written in order by the manager because in deep, deep pileups it won't work**"". This suggests that even if you were to change the comparator used by this tool to behave like `SAMRecordCoordinateComparator`, you'd still have ordering issues in deep coverage areas. It's worthwhile, though, to open a separate ticket to explore whether `ReadCoordinateComparator` could be changed to exactly match bam file order. Eg., perhaps we could add `getAssignedContig()`, `getAssignedStart()`, etc. methods to `GATKRead` to expose the positions that unmapped reads with mapped mates get assigned for sorting purposes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1853#issuecomment-224668518:1608,expose,expose,1608,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1853#issuecomment-224668518,1,['expose'],['expose']
Security,@mepowers Nice to meet you. . This issue isn't resolved. What was resolved was uploading a core dump that exhibits the problem. Is it possible for you to take a look into what's the causing the invalid pointer? Let us know what additional information we can provide. The core dump is located at `gs://hellbender/bugs/5690/core.tar.gz` and should be publicly accessible.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465272533:358,access,accessible,358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465272533,1,['access'],['accessible']
Security,"@michaelgatzen ; in the meantime, if you need a samtools docker that can read from the bucket, you can ; ```; docker pull us.gcr.io/broad-dsde-methods/samtoolscloud:bucket.access. docker run us.gcr.io/broad-dsde-methods/samtoolscloud:bucket.access \; /bin/bash -c \; ""export GCS_OAUTH_TOKEN=`gcloud auth application-default print-access-token`; samtools view -H gs://your_bucket""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6148#issuecomment-531017117:172,access,access,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6148#issuecomment-531017117,3,['access'],"['access', 'access-token']"
Security,"@micknudsen The splitting-bai is a different index from the bai. It's used to determine where spark should split the bam into shards when it's distributing work across the cluster. It doesn't provide random access support to the file, so it's a supplement to the bai instead of a replacement. Ideally we'd also output a normal bai as well, but due to the way the work is sharded it's not trivial to do so. . You can create the bai with `samtools index` if you use samtools, or `CreateHadoopBamSplittingIndex` has an option to output a bai. . The spark tools really should be creating it on the fly but we haven't gotten a chance to implement it yet. I opened a new ticket to track that since I didn't see one anywhere #4226",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359544765:207,access,access,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359544765,1,['access'],['access']
Security,"@mohitmathew Thanks for the report! We are currently in the process of updating GATK to Java 17, which necessarily involves updating many of our dependencies. We are also updating our docker image to be based off of the latest Ubuntu LTS release. This should greatly reduce the number of critical vulnerabilities in our release image. After the Java 17 switchover we can revisit this and see what security issues remain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1442245408:397,secur,security,397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1442245408,1,['secur'],['security']
Security,@mrizkypw I've reported these abusive PRs to github as well as the Broad's security team.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6194#issuecomment-537530173:75,secur,security,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6194#issuecomment-537530173,1,['secur'],['security']
Security,"@munrosa @ldgauthier Possible breakthrough. . First, what's definitely true about the het at 169510380 in 55_55003_F5region.bam when I reproduce the bug with `-L chr1:169510380 -ip 100`:. * The variant is considered active and triggers assembly, as it should.; * For every kmer size there are non-unique kmers in the reference, so it increases up to k = 85, the last attempt at which the engine relaxes the unique kmers requirement. (See `ReadThreadingAssembler` line 425).; * Once it reaches this kmer size, there are cycles in the graph and so no assembly is returned. (See `ReadThreadingAssembler` line 464). Thus no alt haplotype is discovered and the variant is missed. I believe there are two possible solutions.; * The assembly engine looks for cycles before pruning, but this order could be switched with no ill effects. In the case of this het there are no cycles after pruning because the apparent cycle was a poorly-supported path due to sequencing error. Here regular pruning works but the new `--adaptive-pruning` option would give a bit more security against false cycles.; * We don't actually have to check for cycles, especially in the last, desperate kmer attempt. Well, we do with the current recursive implementation of `KBestHaplotypeFinder`, but we *don't* in the Dijkstra's algorithm implementation currently under review: #5462. (Technical note: @ldgauthier I know I promised that this PR gives entirely equivalent results to the existing implementation, but technically this is only true if the existing implementation finishes in finite time. Due to the greedy -- but optimal -- nature of Dijkstra's algorithm, cycles do not cause issues). Personally, I am in favor of *both* solutions -- looking for cycles after pruning, and waiving the no-cycle requirement on the last attempt. They are complementary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-446465913:1056,secur,security,1056,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-446465913,1,['secur'],['security']
Security,"@mwalker174 Ok, I've asked our Google collaborator @jean-philippe-martin to comment on https://github.com/broadinstitute/gatk/issues/3591. It looks like there were some authentication-related changes in the newer gcloud releases that could explain the error. It may be that we just need to update our client code and/or project IAM settings.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330937174:169,authenticat,authentication-related,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330937174,1,['authenticat'],['authentication-related']
Security,"@mwalker174 This is just FYI... you do not need to do anything. You cannot assume that the user running the test doesn't have root access. Also, I cleaned up the test a bit to use standard TestNG conventions (note the ``@ Test``):; ```; @Test(expectedExceptions = UserException.CouldNotCreateOutputFile.class); @SuppressWarnings(""unchecked""); public void testWriteTwoKryo() throws Exception {; final File tempFile = createTempFile(""test"", "".dat"");; final Integer int_in = 29382;; final String str_in = ""test string"";; PSUtils.writeKryoTwo(tempFile.getPath(), int_in, str_in);. final Kryo kryo = new Kryo();; kryo.setReferences(false);; final Input input = new Input(BucketUtils.openFile(tempFile.getPath(), null));; final Integer int_out = (Integer) kryo.readClassAndObject(input);; final String str_out = (String) kryo.readClassAndObject(input);; input.close();. Assert.assertEquals(int_in, int_out);; Assert.assertEquals(str_in, str_out);. // Point to a subdir that does not exist, so that we get a FNF exception; PSUtils.writeKryoTwo(tempFile.getAbsolutePath() + ""/bad_dir/bad_subdir/"", int_out, str_out);; }; ```. Please note that this is not in ``master`` at the time of this writing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2708#issuecomment-300832489:131,access,access,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2708#issuecomment-300832489,1,['access'],['access']
Security,@nalinigans @mlathara Is there an integrity checker tool for GenomicsDB (or a programmatic way to check the integrity of a GenomicsDB instance)?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-684910131:34,integrity,integrity,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-684910131,2,['integrity'],['integrity']
Security,@nenewell I took a brief look yesterday and it looks like there are many bams that fail to validate due to errors with mate pairs. I'm not sure how concerned we are about those errors. It's the weirder ones like . ```; htsjdk.samtools.SAMException: SAMFormatException on record 01; at htsjdk.samtools.SamFileValidator.validateSamRecordsAndQualityFormat(SamFileValidator.java:308); at htsjdk.samtools.SamFileValidator.validateSamFile(SamFileValidator.java:199); at htsjdk.samtools.SamFileValidator.validateSamFileVerbose(SamFileValidator.java:159); at org.broadinstitute.hellbender.tools.picard.sam.ValidateSamFile.doWork(ValidateSamFile.java:129); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardCommandLineProgram.java:51); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.main(Main.java:86); Caused by: htsjdk.samtools.SAMFormatException: Error parsing text SAM file. Not enough fields; File src/test/resources/org/broadinstitute/hellbender/tools/picard/analysis/CompareMetrics/colqualyldmtcs.bam; Line 1; ```. That seem particularly concerning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-112826383:91,validat,validate,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-112826383,6,"['Validat', 'validat']","['ValidateSamFile', 'validate', 'validateSamFile', 'validateSamFileVerbose', 'validateSamRecordsAndQualityFormat']"
Security,"@nenewell If I understand what is going on correctly I think this may be a bug in the validator. Sam spec says . • If 0x1 is unset, no assumptions can be made about 0x2, 0x8, 0x20, 0x40 and 0x80. | Bit | Description |; | --- | --- |; | 1 0x1 | template having multiple segments in sequencing |; | 2 0x2 | each segment properly aligned according to the aligner |; | 4 0x4 | segment unmapped |; | 8 0x8 | next segment in the template unmapped |; | 16 0x10 | SEQ being reverse complemented |; | 32 0x20 | SEQ of the next segment in the template being reverse complemented |; | 64 0x40 | the first segment in the template |; | 128 0x80 | the last segment in the template |; | 256 0x100 | secondary alignment |; | 512 0x200 | not passing quality controls |; | 1024 0x400 | PCR or optical duplicate |; | 2048 0x800 | supplementary alignment |. So it shouldn't matter what google is setting the mate flags to if the read is a singleton. I know there are some other issues with things like this, I think `SAMRecord.equals()` isn't properly agnostic to certain flag combinations and will incorrectly evaluate as not equal even in some cases where the read is logically identical. Does that make sense or have I missed something?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114255696:86,validat,validator,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114255696,1,['validat'],['validator']
Security,"@nh13 Thank you for clarifying. As of today GKL does not auto-detect when there's a read that's ""too long,"" ie a read length we haven't validated with GKL. We should be able to build that into our pending release. I agree we should also make sure that if the GKL pairHMM fails, the JAVA version is called instead. @Kmannth @droazen let's discuss this in our next sync.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6733#issuecomment-674250782:136,validat,validated,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733#issuecomment-674250782,1,['validat'],['validated']
Security,@nh13 The tool as it currently stands does not appear to do any validation on the VCF header. Agree that this is something the tool ought to do. . @ldgauthier I heard that you had a branch that improves this tool -- did you by any chance add header validation in that branch?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6762#issuecomment-679294356:64,validat,validation,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6762#issuecomment-679294356,2,['validat'],['validation']
Security,"@niyomiw That's not a `NullPointerException` -- it's a `NumberFormatException`, and is different from the issue reported in this ticket. It's possible that one or more of your VCFs are malformed in some way. Could you try running `ValidateVariants` on the inputs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-716675461:231,Validat,ValidateVariants,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-716675461,1,['Validat'],['ValidateVariants']
Security,"@niyomiw That's not a `NullPointerException` -- it's a `NumberFormatException`, and is different from the issue resolved in https://github.com/broadinstitute/gatk/issues/6766. It's possible that one or more of your VCFs are malformed in some way. Could you try running `ValidateVariants` on the inputs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6913#issuecomment-716675049:270,Validat,ValidateVariants,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913#issuecomment-716675049,1,['Validat'],['ValidateVariants']
Security,"@pettyalex I don't think the Spark tools such as `MarkDuplicateSpark` are a likely candidate for stdin/stdout support. As you point out, they achieve parallelism by partitioning and then randomly accessing serialized input files. Even if it they could read from stdin, the benefits would be minimal, since they can't begin processing until they've seen the entire input stream, and they can't begin assembling the output until all of the worker nodes have finished processing their individual shards. So it would still require serializing the input, andI think the coarse grained process-parallelism you usually get from pipelining would be pretty minimal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6749#issuecomment-1096818715:196,access,accessing,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749#issuecomment-1096818715,1,['access'],['accessing']
Security,"@pgrosu I'm not sure that actually does explain what's happening. If I read it correctly it's saying that some objects were serialized, then the class was changed, and the old saved objects were no longer loadable. . Our current situation is that we serialized some objects, and deserializing them with the exact same class failed. The first situation is expected, the second one should not happen. . Is it possible that we are using different jvms on our local machine vs on the google cluster? So classes are serialized locally and then a jvm dependent hashcode is different at the other end?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107699331:555,hash,hashcode,555,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107699331,1,['hash'],['hashcode']
Security,"@rahulg603 This last time this was reported, we were unable to reproduce on our end, and the issue mysteriously ""went away"" on its own for @ldgauthier. Could you please report whether you're still getting the same error today? Are you able to access the same bucket using `gsutil` ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6179#issuecomment-1048012280:243,access,access,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6179#issuecomment-1048012280,1,['access'],['access']
Security,"@rdbremel for ""mystery 1"" see issue #5447. This should be an innocuous warning that it can't initialize the Google Cloud Storage code and shouldn't cause a failure unless you try to access paths that start with ""gs://"". Going through the Cloud initialization steps described in the README should remove the warning (though again, this isn't required if you don't need to read files from the cloud). Mystery 2: For what it's worth, ""GC overhead limit exceeded"" indicates that the VM was spending too much time in GC. Running low on memory is a possible cause but generating too many small objects or being stuck in an infinite loop of allocation/deallocation are others. In the past these have been caused by inputs that were malformed in some way. This isn't the place for this discussion though, please file a separate issue since it's a separate bug.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548955879:182,access,access,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548955879,1,['access'],['access']
Security,"@ronlevine commented on [Fri Jul 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438). ### Instructions. Follow up to #1432.; Remove the following code from `IntervalUtils. intervalFileToList()` when a new exome, correctly converted interval list (with no -1 length intervals) is released :. ```; if (interval.getStart() - interval.getEnd() == 1 ) { ; logger.warn(""Possible incorrectly converted length 1 interval : "" + interval);; }; ```. ---; ## Feature request; ### Tool(s) involved. Any tool using `IntervalUtils. intervalFileToList()` ; ### Description. Once this change is made, -1 length intervals will be validated and an exception will be thrown. ---. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260495927). From what I understand of the referenced thread, the ""incorrect"" interval list may always be around, so we may never be able to just blow up on it. Would it perhaps be more viable to add an option to toggle the level of stringency, ie choose in the command line whether to blow up or skip on these invalid intervals? . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260496001). @yfarjoun will want to opine on this, I think. . ---. @yfarjoun commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260513266). I hope that when we move exomes to hg38 we will correct this silly thing; and a few decades later we will no need this code (hehe). Y. On Mon, Nov 14, 2016 at 6:19 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > From what I understand of the referenced thread, the ""incorrect"" interval; > list may always be around, so we may never be able to just blow up on it.; > Would it perhaps be more viable to add an option to toggle the level of; > stringency, ie choose in the command line whether to blow up or skip on; > these invalid intervals?; > ; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2520:629,validat,validated,629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2520,1,['validat'],['validated']
Security,@ruchim would you be able to run the centaur tests on an arbitrary hash? That way we don't release bad WDL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362086043:67,hash,hash,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362086043,1,['hash'],['hash']
Security,"@samuelklee @asmirnov239 @mbabadi I tried to run a 30-sample cohort through gCNV on all canonical chromosomes with 250bp bins sharded in 10k-interval blocks, but PostprocessGermlineCNVCalls gave the following error:. ```...; 19:26:14.967 INFO PostprocessGermlineCNVCalls - Analyzing shard 223...; 19:26:15.107 INFO PostprocessGermlineCNVCalls - Analyzing shard 224...; 19:26:15.259 INFO PostprocessGermlineCNVCalls - Analyzing shard 225...; 19:26:15.260 INFO PostprocessGermlineCNVCalls - Shutting down engine; [May 29, 2018 7:26:15 PM UTC] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 3.34 minutes.; Runtime.totalMemory()=39753089024; ***********************************************************************. A USER ERROR has occurred: Bad input: Validation error occurred on line %d of the posterior file: Posterior probabilities for at at least one posterior record do not sum up to one.; ```. After inspecting the output from shard 225, it seems that the model starts producing nan values after ~1600 warmup iterations (looking at the ELBO log). This shard corresponds to a pericentromeric region chr3:91540501-94090250. . It would be nice to have the option to bypass this error in PostprocessGermlineCNVCalls. Here is the model config for the shard:. ```""p_alt"": 1e-06,; ""p_active"": 0.01,; ""cnv_coherence_length"": 10000.0,; ""class_coherence_length"": 10000.0,; ""max_copy_number"": 5,; ""num_calling_processes"": 1,; ""num_copy_number_states"": 6,; ""num_copy_number_classes"": 2; ""max_bias_factors"": 5,; ""mapping_error_rate"": 0.01,; ""psi_t_scale"": 0.001,; ""psi_s_scale"": 0.0001,; ""depth_correction_tau"": 10000.0,; ""log_mean_bias_std"": 0.1,; ""init_ard_rel_unexplained_variance"": 0.1,; ""num_gc_bins"": 20,; ""gc_curve_sd"": 1.0,; ""q_c_expectation_mode"": ""hybrid"",; ""active_class_padding_hybrid_mode"": 50000,; ""enable_bias_factors"": false,; ""enable_explicit_gc_bias_modeling"": false,; ""disable_bias_factors_in_active_class"": false; ""version"": ""0.7""; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4824:797,Validat,Validation,797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4824,1,['Validat'],['Validation']
Security,"@samuelklee @davidbenjamin I'm not authorized to merge PRs, so one of yous will have to.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306541526:35,authoriz,authorized,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306541526,1,['authoriz'],['authorized']
Security,@samuelklee Can we just expose `bin_length` since it determines what is WGS vs. Exome? Punt the rest?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3980#issuecomment-355997554:24,expose,expose,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3980#issuecomment-355997554,1,['expose'],['expose']
Security,@samuelklee Feel free to merge regardless of your decision. This PR is actually blocking a validation.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3550#issuecomment-331029649:91,validat,validation,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3550#issuecomment-331029649,1,['validat'],['validation']
Security,"@samuelklee I am inclined toward dropping all nd4j-related things. Given that we have access to tf, theano and numpy, I personally do not intend to do any heavy lifting in Java in the foreseeable future. Feel free to clean up and issue PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2929#issuecomment-358097583:86,access,access,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2929#issuecomment-358097583,1,['access'],['access']
Security,"@samuelklee I support exposing these parameters via the command line, but I'd be opposed to any consolidation of parameters that changes the HaplotypeCaller output prior to the initial DRAGEN-GATK release in November, as the evaluations in that project are difficult enough as it is. If you want to do an evaluation to find the best set of SW parameters now, that's fine of course -- but we wouldn't be able to actually merge any breaking HaplotypeCaller changes until after the November DRAGEN-GATK release, and we'd also have to check whether the proposed changes affect the functional equivalence of GATK and DRAGEN (we're developing tests now that can check this). If you want to expose the SW parameters on the CLI now, I think 12 arguments is fine. Just give each argument a clear prefix indicating what it applies to (eg., `--read-to-haplotype-mismatch-penalty`). If a user has gotten to the point where they feel the need to mess with the SW parameters, their command line is probably already long and complex as it is, so adding a few additional arguments won't ruin their day.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291:684,expose,expose,684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291,1,['expose'],['expose']
Security,"@samuelklee I wrote some benchmarks for the exact combinatorics and you were right, my optimization was pointless. Although the `CombinatoricsUtils` method does explicitly multiply out instead of using cached factorials 1) the number of multiplications is only min(ploidy, (allele count - 1)), and 2) it actually takes quite a while (much larger than reasonable ploidy and allele count) for multiplication to take longer than the memory access of stored factorials. . I have removed this error in judgment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1066873168:437,access,access,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1066873168,1,['access'],['access']
Security,"@samuelklee If there are CNV tools that can't comfortably extend `GATKTool` as things stand now, then I think that we should adjust `GATKTool` to be more flexible until they can do so. This would help with certain long-term goals that the engine team has (such as all tools supporting NIO for all inputs, consistent sequence dictionary validation, etc.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358040921:336,validat,validation,336,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358040921,1,['validat'],['validation']
Security,@samuelklee We can easily expose the `IntervalMergingRule` in `IntervalArgumentCollection` (which is where `-L` is defined) as an argument to prevent the merging of adjacent intervals. We could also add a way for individual tools to set a default value for `IntervalMergingRule` themselves.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3246#issuecomment-314496762:26,expose,expose,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3246#issuecomment-314496762,1,['expose'],['expose']
Security,"@samuelklee Yes, this looks similar to what happened in master yesterday. In that case it looked like a transient remote access issue during the docker build. Having said that, its strange that the two data points we have were both on M2 WDL build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356761950:121,access,access,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356761950,1,['access'],['access']
Security,@samuelklee the problem is that I need something pretty quickly here. I'm guessing that changing the GMM algorithm is going to require a ton of validation...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3230#issuecomment-313891523:144,validat,validation,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3230#issuecomment-313891523,1,['validat'],['validation']
Security,"@schaluva Could I get access to a bam for that chromosome or some smaller interval that exhibits the bug and the original, non-simplified germline resource VCF? I think the error in filtering has been fixed, so I'm focusing on the first error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098#issuecomment-530090255:22,access,access,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098#issuecomment-530090255,1,['access'],['access']
Security,"@schelhorn We have a large clinical ""truth"" set we utilize during workflow validations. We also utilize spike-in samples from SeraCare and perform dilutions using a couple of the common Coriell cell lines. We noticed the Mutect2 calling inconsistency while validating a small targeted panel.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1171672027:75,validat,validations,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1171672027,2,['validat'],"['validating', 'validations']"
Security,"@skwalker -- you've validated GATK 4 HaplotypeCaller pretty thoroughly, have you seen this issue? If not, let's close it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1858#issuecomment-443235374:20,validat,validated,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1858#issuecomment-443235374,1,['validat'],['validated']
Security,"@slzhao This is definitely a reasonable thing to do. Please feel free to issue a PR to do this. That said, I have to give you a warning. Some of the datasources rely on `sqlite3` and therefore have issues on some distributed filesystems (see this [post on Lustre/NFS errors](https://github.com/CGATOxford/CGATPipelines/issues/39)). There are a few posts in the GATK forums about this as well. So you may want to do some testing before using one centralized copy of the data sources. . As a heads-up - I do not have access to a Lustre filesystem so I am unable to do any debugging with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6731#issuecomment-671508424:515,access,access,515,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6731#issuecomment-671508424,1,['access'],['access']
Security,"@sooheelee I can't speak for CNV, but there isn't any general reason to prefer Picard interval lists in GATK. There was previously an issue with parsing interval queries that used contig names that contained "":"", but thats fixed now. The only time we prefer a Picard list is the theoretical case were you use a query interval against a sequence dictionary that contains contigs that make that query ambiguous (hg38 is not one of those). GATK will detect and reject such a query and suggest using a Picard interval file to disambiguate it. @magicDGS I'm not sure how/if writing tests against existing files in the repository will be useful. I want to restate that we don't want to take ports of these tools if they're marked `@Experimental `or `@Beta` because they haven't been validated, or don't have good test coverage. We need to find a way need to have valid tests so they'll be production ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161:777,validat,validated,777,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161,1,['validat'],['validated']
Security,"@sooheelee I'm not sure I understand this issue. Is someone running the gatk docker image and then having people use that as a shared server? If they are, then it seems like it's their responsibility to control ssh access to the server, set up permissions, etc. That's outside of the scope of what we can do. If someone is running docker and starting up their own instance of the gatk container, then they have root access to that container by definition. . Could you explain the exact use case you want to support? I read the thread you pointed at but I also didn't really follow EADG's reasoning.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-333650137:215,access,access,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-333650137,2,['access'],['access']
Security,"@t-ogasawara Thanks for pointing us to the OSU service -- that looks like just what we need! I'll see if I can obtain access for our project. If we can get access and set up automated continuous tests for PPC, then I think we can use a single repo for the two architectures as you propose. Without continuous testing, though, I'm not convinced that `if the files under common are changed, the changes should work on PPC if the tests don't fail on x86_64.` -- at least, we would not be comfortable making changes to common code without tests in place.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-215460975:118,access,access,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-215460975,2,['access'],['access']
Security,"@takeshi-yoshimura Native access to s3a::// seems useful. In order to include this though we need some tests to show that it works/ demonstrate how to use it. I'm a bit concerned that it's version 0.0.1 (although it looks like there is a [0.0.2](https://search.maven.org/artifact/net.fnothaft/jsr203-s3a) out, should that be the one incorporated instead?) and there doesn't seem to be any activity on the library's [github](https://github.com/fnothaft/jsr203-s3a) in the last two years-ish. I'm wondering how stable/supported it is. . Maybe @fnothaft can comment on it. What's the status of this library? Do you recommend incorporating it or is there a different solution you've moved on to?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6698#issuecomment-658863506:26,access,access,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698#issuecomment-658863506,1,['access'],['access']
Security,"@takutosato @LeeTL1220 As mentioned, this change scraps all the p values and replaces it with a simple and cheap probabilistic model. All our validations either improve or stay the same and speed is much better. * Spurious active regions are reduced by almost 50%.; * DREAM 4 goes from 40 hours total CPU time to 20 hours. All DREAM genomes now take less than a day.; * Hapmap sensitivity is the same.; * DREAM sensitivities for SNVs and indels all go up a bit.; * Upon manual review we no longer make any obviously bad inactive calls, except for very long deletions, which remain an issue. @takutosato This is a higher priority review than either of the documentation PRs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3304:142,validat,validations,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3304,1,['validat'],['validations']
Security,"@takutosato Based on all of our validations I added a commit to make this the default for M2. Because M2 shares a nested argument collection with HaplotypeCaller, this was pretty awkward. Louis told me this was the best among bad options.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5473#issuecomment-444360492:32,validat,validations,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5473#issuecomment-444360492,1,['validat'],['validations']
Security,@takutosato Can you review this PR?. This is a community request and a useful feature for our MC3 validation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4601:98,validat,validation,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4601,1,['validat'],['validation']
Security,"@takutosato I was checking the filter analysis outputs of every M2 validation and this filter hurts much, much more than it helps, probably because other developments have made it less necessary. Let's essentially turn it off by default.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5487:67,validat,validation,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5487,1,['validat'],['validation']
Security,"@takutosato If you look at the previous code for realignment to a read's best haplotype it assumes that the read start within the reference haplotype byte array is the same as its start within the best haplotype byte array (see the coordinate passed to leftAlignIndels). This means that left alignment would effectively be deactivated (since the bases didn't line up correctly) whenever the best haplotype contained indels before the read start. This also creates a rare but possible edge case bug where if a read cigar ends in an indel and we miscalculated the read's start in the reference we might get an array out of bounds exception within leftAlignIndels. The recent PR #6427, which fixed some bugs involving left alignment, actually exposed this bug, because the previous code simply skipped left alignment when it encountered an out of bounds index. The fix is in the line `final int readStartOnReferenceHaplotype = readStartOnReferenceHaplotype(rightPaddedHaplotypeVsRefCigar, readToHaplotypeSWAlignment.getAlignmentOffset());` The idea is that we know where the read starts on its best haplotype from the SW alignment. In order to find the corresponding reference base, we follow the haplotype-to-reference cigar up to the read start and count the number of reference bases consumed. For example, suppose the haplotype-to-reference cigar is 30M5D100M and the read starts at (0-indexed) position 50 on the haplotype. We want to know how many reference bases are consumed in order to consume 50 alt haplotype bases in this cigar. That is, we count the reference bases in the 30M5D20M leading sub-cigar, which is 55. Thus the reference start is 55. Conversely, if the haplotype-to-reference cigar were 30M5I100M the read would start after 30M5I15M, with 45 reference bases consumed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6461:740,expose,exposed,740,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6461,1,['expose'],['exposed']
Security,"@takutosato Since this is an unsupported script that I have already tested to make sure results are the same, don't spend much time on it. Here's the summary:. * Put sub-sampling of hapmap (the most expensive part and a one-time cost because the samples are the same every time) into its own wdl.; * Put the rest of generating the truth into the same wdl as the sensitivity validation. This will make things simpler for the TAG team.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3379:374,validat,validation,374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3379,1,['validat'],['validation']
Security,"@takutosato The extra strength of normal reads informing the ref allele's annotations improves results (very) slightly in all of our validations. The deeper reason for this change is in anticipation of multi-sample mode, where filtering based on a single INFO field will be simpler and probably statistically more powerful than filtering on a bunch of separate genotype fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5518:133,validat,validations,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5518,1,['validat'],['validations']
Security,@takutosato These are the changes I made for the most recent GP validation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3171:64,validat,validation,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3171,1,['validat'],['validation']
Security,@takutosato This change doesn't hurt sensitivity in our validations and made M2 25% faster. We were getting a lot of active regions based on single substitution errors in overlapping reads.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5078:56,validat,validations,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5078,1,['validat'],['validations']
Security,"@takutosato This dramatically improves `CalculateContamination` by giving more care to distinguishing hom alts from hets. It makes an especially big difference in our tumor-only HCC1143 validations, where the accuracy is now very good (and BTW, ContEst gets these all completely wrong even *with* a matched normal). It also makes the tool work better in targeted panels where there might not be enough hom alt sites by adding a backup hom ref mode that gets triggered automatically. This is based on a Broadie request. I will file a separate issue to update the docs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5413:186,validat,validations,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5413,1,['validat'],['validations']
Security,@takutosato This lets `ValidateBasicSomaticShortMutations` optionally annotate the `eval` vcf with validation `INFO` fields in addition to the standard output of a tsv. Having a vcf is more convenient for some things in MC3.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4999:23,Validat,ValidateBasicSomaticShortMutations,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4999,2,"['Validat', 'validat']","['ValidateBasicSomaticShortMutations', 'validation']"
Security,"@takutosato This uses minor allele fraction segmentation, which was already done internally in `CalculateContamination`, to improve tumor-only calling a lot. I also sw modest improvements in some tumor-normal validations. Also, @chandrans @sooheelee this hopefully does away with the problems with `af-of-alleles-not-in-resource` by deriving a defensible default that doesn't result in all calls in tumor-only mode getting filtered.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4509:209,validat,validations,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4509,1,['validat'],['validations']
Security,@takutosato Two quick edge cases and new unit tests. These were exposed when fixing other bugs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6518:64,expose,exposed,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6518,1,['expose'],['exposed']
Security,@takutosato We don't need to do this. The read orientation model is sufficiently well-validated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5654#issuecomment-572203804:86,validat,validated,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5654#issuecomment-572203804,1,['validat'],['validated']
Security,"@tedsharpe @cwhelan please review. - Adds MarkDuplicatesReadFilter (to replace MarkedOpticalDuplicateReadFilter). MarkedOpticalDuplicateReadFilter will be removed in a subsequent PR because the Filter tool currently uses it.; - Changed some types (short to int, float to double) in the DUST algorithm; - Adds HostAlignmentReadFilter for filtering sufficiently well-mapped host reads. The helper function is there to run the test on supplementary alignments. I chose not to expose this as a GATK filter because the definitions of coverage and identity used here could be different than what some users would expect. @lbergelson Addressed your comments from the other branch:; - Added docstring to AmbiguousBaseReadFilter argument; - Made filterOpticalOnly an argument; - Argument variables changed from uppercase to lowercase; - See above regarding the duplicates filters",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2665:473,expose,expose,473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2665,1,['expose'],['expose']
Security,"@tedsharpe This looks good to me. In general partition sizes can be much larger than 100kb without problems, so I suspect it's is something funny to do with the task serialization of ctx.paralellize(). . If this is a performance critical tool it would probably be better to rewrite it in a way that it can load the reference in parallel. Since I assume this is something you run essentially once per reference it may not be worth it. . If you're worried about small machines running out of memory, I would expose the parameter that lets you configure how much memory each partition gets. I would expect in any spark configuration each core will have no less than ~1gb to work with and likely 2 -4 on any machines used for biology work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1505#issuecomment-187387150:506,expose,expose,506,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1505#issuecomment-187387150,1,['expose'],['expose']
Security,"@tedsharpe please review. - SVKmerizer takes in an integer specifying the spacing between between kmers. This is is an effective way to reduce the kmer set size without affecting sensitivity much.; - SVKmerShort - added masking function that returns a copy of the current kmer after deleting bases at the specified positions; - Reworded some error messages about kmer length; - Moved and added some hashing functions to SVUtils, which will be used in another PR for the long-typed set classes and de-duplication filter.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2662:399,hash,hashing,399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2662,1,['hash'],['hashing']
Security,@thebkaufman1995 encountered the following warning when trying to use TSV count files in the gCNV pipeline:. ```; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5F.c line 604 in H5Fopen(): unable to open file; major: File accessibilty; minor: Unable to open file; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fint.c line 1085 in H5F_open(): unable to read superblock; major: File accessibilty; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fsuper.c line 277 in H5F_super_read(): file signature not found; major: File accessibilty; minor: Not an HDF5 file; ```. My guess is this is because we first try to open counts files as HDF5 and then fall back to TSV (catching the relevant exception). Perhaps slightly different versions of the HDF5 library result in these warnings being emitted.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4482:307,access,accessibilty,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4482,3,['access'],['accessibilty']
Security,"@theisaacwong Thanks for reporting this. it might be hard to debug this without access to the input file. It looks like the issue might be with the cram file itself - do you know how the file was created (GATK, etc. ?). Also, it would be interesting to know if GATK is able to consume the file without specifying query intervals (without -L).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6865#issuecomment-704956160:80,access,access,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865#issuecomment-704956160,1,['access'],['access']
Security,"@tomwhite After spending some time searching for this feature for my testing purposes, it would be helpful to expose the NIO adapter toggle directly from the command line in this branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5138#issuecomment-418494235:110,expose,expose,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5138#issuecomment-418494235,1,['expose'],['expose']
Security,@tomwhite I think this might have been from the first run of the jenkins tests since the disq change over - not sure though. You should have access to the `broad-gatk-test-jenkins-robust` bucket now if you need it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5545#issuecomment-449440744:141,access,access,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545#issuecomment-449440744,1,['access'],['access']
Security,"@tomwhite I'm told you've done some work in the past with variant stores. Since we're now moving into working on the variant part of the pipeline, we'd like to assess our options for storing/accessing variants efficiently. Perhaps you could present some of your past work, and/or prototype some technologies you think are promising? We're going to look at TileDB (https://github.com/broadinstitute/gatk/issues/1647), but we'd like to get your suggestions/thoughts on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1659#issuecomment-202576944:191,access,accessing,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1659#issuecomment-202576944,1,['access'],['accessing']
Security,"@tomwhite The problem is that `GATKRead` does not expose the ""positions"" of reads that are marked as unmapped (this was a conscious design choice so that client code doesn't have to check 5 different fields to determine whether a read is unmapped or not). So we could write a new comparator, but it would have to convert to `SAMRecord` internally and would only be used when writing -- this is why we initially preferred to patch `ReadsSparkSink` rather than write a new comparator. But it looks like we have no choice...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1249#issuecomment-162026651:50,expose,expose,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1249#issuecomment-162026651,1,['expose'],['expose']
Security,"@vdauwera @droazen @lbergelson @cmnbroad Hey, this pull request will fail as long as the docker hub repo for broadinstitute/gatk has restricted read access. Any objections to making reading of the gatk (not gatk-protected) dockerhub repo public?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2726#issuecomment-302212757:149,access,access,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2726#issuecomment-302212757,1,['access'],['access']
Security,"@vdauwera Currently it looks like many causes of failure in the existing MalformedReadFilter do explode with an exception instead of filtering.; - A read has a bad or undefined read group; - read.getReadLength() == read.getBaseQualities().length; - read.getReadBases() != SAMRecord.NULL_SEQUENCE; - containsNOperator(read). These cases all throw exceptions by default or in any case. Should these be changed to filter out criteria? Or should these be moved to a ReadValidator like @jmthibault79 suggests. Alternatively, are these checked for by the HTSJDK validation / should they be?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/193#issuecomment-75647767:556,validat,validation,556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/193#issuecomment-75647767,1,['validat'],['validation']
Security,"@vdauwera I think we're planning on keeping a distinction between a bug and a user error. What the actual messages say is up for debate though. . Are you going to be offering support for alpha hellbender? What website do you want to link to? There aren't any doc urls at the moment so there's no where to direct people to right now. . Doing complete validation is a bit tricky, since an invalid option will screw up parsing for subsequent options. We should output a list of all the missing required options though instead of bailing at the first one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/418#issuecomment-146240164:350,validat,validation,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/418#issuecomment-146240164,1,['validat'],['validation']
Security,"@vdauwera Yes, he needs to be added to the appropriate github team (one that gives him write access to the repo).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1382#issuecomment-169178877:93,access,access,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1382#issuecomment-169178877,1,['access'],['access']
Security,"@vdauwera reported this here #950 :. > Can't seem to do git clone https://github.com/broadinstitute/hellbender/. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. > Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/952:675,Password,Password,675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952,2,"['Password', 'access']","['Password', 'accessing']"
Security,"@vdauwera we should modify the M2 WDLs. ; @davidbenjamin this will improve your sensitivity. Currently Mutect2 uses the MateOnSameContigOrNoMappedMateReadFilter filter that filters out any paired read whose mate maps to a different contig. This filter, if I recall correctly, used to be the hidden filter in HaplotypeCaller code that could not be turned off. It necessitated that I remove 0x1 flags in the GRCh38 tutorial (see section 6.1 of <https://gatkforums.broadinstitute.org/gatk/discussion/8017/>) so as to be able to call variants associated with a sample with an alternative haplotype. This filter is now exposed so that users can disable it. In addition to disabling this filter for ALT-aware data, I recommend we turn it off by default for somatic analyses, for any reference. This allows us (i) to call on ALT-aware mappings if data is such and (ii) call on SNPs and indels generated by putative structural variants that go _across contigs_. I know that this filter is active in the GATK4.beta.3-Mutect2 (see last line):; ```; WMCF9-CB5:align shlee$ gatk-launch Mutect2 -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -I hcc1143_N_subset500.bam -tumor HCC1143_normal -O 1_normalforpon.vcf.gz; Using GATK jar /Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar Mutect2 -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -I hcc1143_N_subset500.bam -tumor HCC1143_normal -O 1_normalforpon.vcf.gz; 19:26:43.105 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.latest/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; [August 24, 2017 7:26:43 PM EDT] Mutect2 --tumorSampleNam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3514:614,expose,exposed,614,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3514,1,['expose'],['exposed']
Security,"@vdauwera, examples of long arguments from the `StandardArgumentDefinitions`:. * `--disable-tool-default-read-filters`; * `--disable-sequence-dictionary-validation`; * `--add-output-sam-program-record`; * `--add-output-vcf-command-line`. This arguments are long anyway, but from my point of view it is more readable in the camel-case format; in addition, for the two last I have a question: is the upper-case format extension (SAM/VCF) going to be in lower-case? If not, there is still a mixture of upper/lower-case that may be confusing (and difficult to enforce).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-324038691:153,validat,validation,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-324038691,1,['validat'],['validation']
Security,"@vidprijatelj , I can't reproduce the issue on `MacOS` and `Centos 7`. Can you provide us with more information with respect to the system you are on? What is the OS? Are there any [access control lists](https://man7.org/linux/man-pages/man5/acl.5.html) setup?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1470386063:182,access,access,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1470386063,1,['access'],['access']
Security,@vilay-nference Thank you for your pull request. I've incorporated your suggestions and closed out many vulnerabilities from our transitive dependencies. Hadoop/spark have finally stopped incorporating log4j1 so that one is closed out for good. . I've also rebuilt our base docker to incorporate recent patches from ubuntu. We've implemented some additional security scanning into our build process which will help keep us more up to date going forward.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2432287402:358,secur,security,358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2432287402,1,['secur'],['security']
Security,"@vilay-nference Were you able to get this configuration to pass tests on your end? I've attempted to incorporate your changes into https://github.com/broadinstitute/gatk/pull/8998, but I'm running into issues with hadoop and protobuf incompatibilities. I see the same problem with your branch when I try to run tests on it. (I also can't run tests without disabling -Werror on your branch since there are still some unresolved deprecation and other minor issues). Errors look like this:. ```; Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.security.proto.SecurityProtos [in thread ""IPC Server handler 1 on default port 64812""]; 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.<clinit>(ClientNamenodeProtocolProtos.java); ```. and you can easily trigger one by running `ParallelCopyGCSDirectoryIntoHDFSSparkIntegrationTest`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2412827680:630,secur,security,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2412827680,2,"['Secur', 'secur']","['SecurityProtos', 'security']"
Security,"@vilay-nference You are always very welcome to submit a pull request on github with any proposed changes to GATK!. Most of the remaining vulnerabilities are in dependencies-of-dependencies which can be difficult to update, but we are slowly chipping away at them. For example, log4j 1.x is a dependency of the latest release of Apache Spark 3.x, and 4.x is still in preview (and note again that the log4j 1.x vulnerabilities are not the same as the infamous and very serious vulnerability that affected log4j 2.x some years ago). We don't believe that any of the remaining library vulnerabilities pose a real-world threat to GATK in practice, but it would still be good to eliminate them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2223132298:615,threat,threat,615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2223132298,1,['threat'],['threat']
Security,"@vruano ; Tests are failing, could you resolve this?; It appears to be in:; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest > testAgainstMutect2 FAILED; java.lang.IllegalArgumentException: Dirichlet parameters may not be negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); at org.broadinstitute.hellbender.utils.Dirichlet.<init>(Dirichlet.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticLikelihoodsEngine.getEffectiveCounts(SomaticLikelihoodsEngine.java:56)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7303#issuecomment-859204971:314,validat,validateArg,314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7303#issuecomment-859204971,1,['validat'],['validateArg']
Security,@vruano Should `ExomeToolsTestUtils` be exposed? What about `ReadClipperTestUtils`?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/525#issuecomment-103626555:40,expose,exposed,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/525#issuecomment-103626555,1,['expose'],['exposed']
Security,"@yfarjoun @vdauwera I've refined the tool categorization based on feedback on the tentative categorization. Thank you @yfarjoun for the review and feedback. The refinement is reflected in the new tabbed sheet in the shared Google Spreadsheet:`1217Changes_categorization-and-assignments`. I've separated out GATK vs Picard tools for each of the categories. . Here is a summary of the changes. 1. New 11 to `Diagnostics and QC`:; AnalyzeCovariates (from Alignment, Duplicate flagging and BQSR); GatherBQSRReports (from Alignment, Duplicate flagging and BQSR); FlagStat (from Read Data Manipulation); FlagStatSpark (from Read Data Manipulation); GetSampleName (from Read Data Manipulation); Picard BamIndexStats (from Read Data Manipulation); Picard CalculateReadGroupChecksum (from Read Data Manipulation); Picard CheckTerminatorBlock (from Read Data Manipulation); Picard CompareSAMs (from Read Data Manipulation); Picard ValidateSamFile (from Read Data Manipulation); Picard ViewSam (from Read Data Manipulation). 2. Merge 14 tools remaining in `Alignment, Duplicate flagging and BQSR` with 37 tools in `Read Data Manipulation`. Keep latter name. 	51 tools. 3. Move these out of `Read Data Manipulation`:; CompareDuplicatesSpark (to DxQC); ConvertHeaderlessHadoopBamShardToBam (to Other); CreateHadoopBamSplittingIndex (to Other). 4. Move ValidateVariants into `Variant Evaluation`. Also:; `Variant Evaluation and Refinement` --> `Variant Evaluation`; `VCF Manipulation` --> `Variant Manipulation` . Let us know your thoughts. Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-352313248:921,Validat,ValidateSamFile,921,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-352313248,2,['Validat'],"['ValidateSamFile', 'ValidateVariants']"
Security,"@yfarjoun How do you want to proceed with this PR, given that there are downstream issues even after this fix? Is the strategy going to be to keep developing patches like this, or throw in the towel and sanitize the problematic bases early on in the pipeline?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-642045845:203,sanitiz,sanitize,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-642045845,1,['sanitiz'],['sanitize']
Security,"@yfarjoun I believe you always have opinions about validation, wdyt?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2129#issuecomment-243281529:51,validat,validation,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2129#issuecomment-243281529,1,['validat'],['validation']
Security,"@yfarjoun Right, the intention of this ticket was to implement the codec in htsjdk, then add a GATK integration test proving that we can now access interval_list files as tribble features.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997:141,access,access,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997,1,['access'],['access']
Security,"@yfarjoun Well, as I said in person I believe that there are benefits to running with asynchronous prefetching turned on even in the random-access case. @jean-philippe-martin can confirm.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482681722:140,access,access,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482681722,1,['access'],['access']
Security,"@yl-h I have created a new branch [genomicsdb_6744](https://github.com/broadinstitute/gatk/tree/genomicsdb_6744) that exposes GenomicsDBArgument Collection to CreateSomaticPanelOfNormals. Can you please run the following to help us narrow down the issues?. 1. The default for GenomicsDB exports/queries changed from BCFCodec streaming in 4.1.7.0 to VCFCodec in 4.1.8.0. Run `gatk CreateSomaticPanelOfNormal` with `--genomicsdb-use-bcf-codec true` to override this default. If the expected PoN records is still missing variants, can you also run (2)?; 2. Run `gatk SelectVariants -O out.vcf -V gendb://...` on a small region with this branch to verify the number of variants is the same as from 4.1.7.0. If not, would you be able to distill and post any line that is missing now?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-672322785:118,expose,exposes,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-672322785,1,['expose'],['exposes']
Security,"@zhanyinx Just merged a fix to this, which exposes a new CLI parameter. Tonight's nightly build will have the new option for you to try.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8276#issuecomment-1674597532:43,expose,exposes,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8276#issuecomment-1674597532,1,['expose'],['exposes']
Security,"A bit of a side note, but which reference do we want specifically?; On Apr 19, 2015 8:57 PM, ""Adam Kiezun"" notifications@github.com wrote:. > a requirement is that we need to store and access the human reference file; > (~3GB, uncompressed) and a few other files < 1 GB each. The files will have; > public access so no additional security is required.; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/issues/388#issuecomment-94330634; > .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/388#issuecomment-94349276:185,access,access,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/388#issuecomment-94349276,3,"['access', 'secur']","['access', 'security']"
Security,"A few recent bugs, which are all entirely my fault, came about because the liftover of gnomAD to hg38 (there is no official hg38 gnomAD yet) exposed some new edge cases, such as `AF=.` and `AF=0`, that caused errors. I suspect that you are seeing one that we hadn't found yet. Unfortunately, we do not have nearly validation on hg38. Here's what I will do: 1) correct our hg38 gnomAD to fix liftover artifacts and put this new resource in the GATK bucket. 2) Create a Firecloud workspace with a few hg38 samples in order to reproduce the error and to make sure future changes don't create new problems 3) try to fix the error because even if 1) works it's sloppy to rely on the fact that gnomAD won't have these edge cases. I hope 1) succeeds because it will be available immediately without waiting for the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154:141,expose,exposed,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154,2,"['expose', 'validat']","['exposed', 'validation']"
Security,A quick and dirty implementation. The on thing that needs extra scrutiny is going to be the various conditions/failure states in the validate method. I think i caught most of the cases but there might be a gap somewhere.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8724:133,validat,validate,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8724,1,['validat'],['validate']
Security,"A quick patch to help out the Variants team, which is struggling with a problematic callset. Note that a similar regularization to the effective number per component probably should have been applied to solve the issue in https://github.com/broadinstitute/gatk/pull/6425. I'm not sure if the lack of this regularization will still lead to convergence issues, but I would hope that the fix that was implemented instead (treating vanishing components as a special case and skipping computation) suffices. As discussed there, we may also want to eventually remove the idiosyncratic finalize step; it’s likely this is the source of issues here, since the correct Bayesian M step is already regularized by the prior. The covariance regularization term added here is standard (c.f. e.g. https://github.com/scikit-learn/scikit-learn/blob/7e1e6d09bcc2eaeba98f7e737aac2ac782f0e5f1/sklearn/mixture/_gaussian_mixture.py#L154), but it may result in non-negligible changes to VQSLODs. As just discussed with the Variants team, we can probably use the WARP validation to convince ourselves that results are functionally equivalent. I updated the exact-match tests without much close examination (by simply forcing IntegrationTestSpec.assertEqualTextFiles to overwrite the old expected files), so someone may want to sanity check them. There were also a few more interactions between the integration tests for different tools than I anticipated. Some tests use output generated by an upstream tool as input and break encapsulation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709:1043,validat,validation,1043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709,1,['validat'],['validation']
Security,"A seemingly large change PR, but most changes are trivial.; The non-trivial part:. * a new tool `StructuralVariantionDiscoveryPipelineSpark` to run the whole process of SV discovery, by delegating works to `FindBreakpointEvidenceSpark` and `DiscoverVariantsFromContigAlignmentsSAMSpark`, both of which are refactored to accommodate the new tool;; * class `AlignmentRegion` is effectively moved into a new class `AlignedAssembly` (named quite close to the existing class `AlignedAssemblyOrExcuse` but will be moved into a different sub-package in a sequential PR).; * integration tests (local mode and on MiniClusters/hdfs) for all 5 major tools `FindBreakpointEvidenceSpark`, `DiscoverVariantsFromContigAlignmentsSAMSpark`, `StructuralVariantionDiscoveryPipelineSpark`, `AlignAssembledContigsSpark` and `DiscoverVariantsFromContigAlignmentsSGASpark`; a draw back is these integration tests do not test correctness of results but simple tests if these tools run.; * various unit tests. The two paths involving use of Fermi-lite are tested to be running and generating compatible results. The path involves using SGA as the assembler is also running but generates significantly less variants. (see attached run logs).; [differentVersions.txt](https://github.com/broadinstitute/gatk/files/956271/differentVersions.txt). The access levels of the various classes and methods are not optimal now because a serial PR that simply repackaging these classes (hence access levels must be changed) is expected to be generated immediately after this PR is approved.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2621:1321,access,access,1321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2621,2,['access'],['access']
Security,"A user rightly [points out](http://gatkforums.broadinstitute.org/gatk/discussion/comment/32631#Comment_32631) that different versions of HaplotypeCaller may produce GVCFs that are not directly compatible, causing weirdness when you joint-genotype them with GenotypeGVCFs. . Obviously this is primarily a data management problem (user should control what's in their pipeline) -- but it would be good to provide an additional safety layer by having GenotypeGVCFs, CombineGVCFs or whatever demon is used to invoke TileDB at least emit a WARN message if they see GVCFs produced by different versions of HC within the same input cohort. . Note that the VCF version number is not directly useable for this purpose since changes in the contents of GVCFs can arise within the same version of VCF spec. Also, one could argue that the GVCFs really should all be produced using exactly the same command line arguments -- but validating the entire command line would probably be overkill...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2129:914,validat,validating,914,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2129,1,['validat'],['validating']
Security,"A12878_S1_md.bam --output hc_variants_7.vcf --bam-output realigned_slice_7.bam --max-reads-per-alignment-start 1000 --min-base-quality-score 0 --minimum-mapping-quality 0 --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityAvailableReadFilter --disable-read-filter NotSecondaryAlignmentReadFilter --disable-read-filter NotDuplicateReadFilter --disable-read-filter PassesVendorQualityCheckReadFilter --disable-read-filter NonZeroReferenceLengthAlignmentReadFilter --disable-read-filter GoodCigarReadFilter --disable-read-filter WellformedReadFilter`; [January 10, 2018 2:39:19 PM EST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 91.81 minutes.; Runtime.totalMemory()=7215251456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr5 start:71357769 end:71357768; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4120:1350,validat,validatePositions,1350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120,1,['validat'],['validatePositions']
Security,"ATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Sep 16, 2019 2:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Mon Sep 16 02:33:15 UTC 2019] Executing as user@server on Linux 3.10.0-693.21.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_192-b01; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.3.0; [Mon Sep 16 02:33:22 UTC 2019] picard.analysis.CollectWgsMetrics done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=6996099072; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; java.lang.IllegalArgumentException: The requested position is not covered by this StartEdgingRecordAndOffset object.; at htsjdk.samtools.util.AbstractRecordAndOffset.validateOffset(AbstractRecordAndOffset.java:109); at htsjdk.samtools.util.EdgingRecordAndOffset$StartEdgingRecordAndOffset.getBaseQuality(EdgingRecordAndOffset.java:112); at picard.analysis.FastWgsMetricsCollector.excludeByQuality(FastWgsMetricsCollector.java:189); at picard.analysis.FastWgsMetricsCollector.processRecord(FastWgsMetricsCollector.java:144); at picard.analysis.FastWgsMetricsCollector.addInfo(FastWgsMetricsCollector.java:105); at picard.analysis.WgsMetricsProcessorImpl.processFile(WgsMetricsProcessorImpl.java:93); at picard.analysis.CollectWgsMetrics.doWork(CollectWgsMetrics.java:231); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); Using",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6163:2502,validat,validateOffset,2502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6163,1,['validat'],['validateOffset']
Security,ATK. ### Affected version(s); 4.1.4.1; ### Description ; when trying to compile with .gradlew bundle get the error above. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/usr/bin/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:108); at org.gradle.api.internal.tasks.execution.ResolveBeforeExecutionOutputsTaskExecuter.execute(ResolveBeforeExecutionOutputsTaskExecuter.java:67); at org.gradle.api.internal.tasks.execution.ResolveAfterPreviousExecutionStateTaskExecuter.execute(ResolveAfterPreviousExecutionStateTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:94); at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:95); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57); at org.gradle.api.internal.tasks,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466:1093,Validat,ValidatingTaskExecuter,1093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466,1,['Validat'],['ValidatingTaskExecuter']
Security,AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:347); ... 17 more; Caused by:; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); at shaded.cloud-nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); at shaded.cloud-nio.com.google.api.client.http.HttpRequest,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:3795,secur,security,3795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,1,['secur'],['security']
Security,"According to @jean-philippe-martin, the following workaround is still necessary in `GoogleGenomicsReadToGATKReadAdapter`:. ```; @Override; public GATKRead copy() {; // workaround until https://github.com/google/google-http-java-client/issues/293 is released; genomicsRead.setAlignedQuality(new ArrayList<>(genomicsRead.getAlignedQuality()));; Map<String, List<String>> infoCopy = new HashMap<>();; for (Map.Entry<String, List<String>> entry : genomicsRead.getInfo().entrySet()) {; infoCopy.put(entry.getKey(), new ArrayList<>(entry.getValue()));; }; genomicsRead.setInfo(infoCopy);; genomicsRead.getAlignment().setCigar(new ArrayList<>(genomicsRead.getAlignment().getCigar()));; // end workaround. // clone() actually makes a deep copy of all fields here (via GenericData.clone()); return new GoogleGenomicsReadToGATKReadAdapter(genomicsRead.clone());; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/650#issuecomment-132634761:384,Hash,HashMap,384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/650#issuecomment-132634761,1,['Hash'],['HashMap']
Security,"Actually, I'm going to go ahead and add some exact match tests to guard against this sort of thing. Behavior for key somatic CNV tool modules (i.e., kernel segmentation and MCMC) is unit tested to within statistical noise (so, not exact match) on simulated data, but most integration tests just check for plumbing and not correctness. The idea was always that this sort of thing would be covered by what eventually became CARROT, since such tests would probably have to be long running and require more resources than are available in the repo to be useful. See the high priority but long dormant issues https://github.com/broadinstitute/gatk/issues/4122 and https://github.com/broadinstitute/gatk/issues/4123, as well as https://github.com/broadinstitute/gatk/issues/4630. In fact, I think the original idea was that Lee's validation would be the first to go into CARROT. Note also that I did some work to set up transition of all existing CNV tests (also including the somatic CNV validation against TCGA SNP calls that I put together on Terra) before going on leave and moving off CNVs, but during all that, we managed to 1) lose TCGA access, 2) delete the test files on which Lee based his validation after he left, and 3) reassign at least one of the people that was going to help with the transition. Again, the resulting differences here are minor and it's unlikely that future non-CNV code changes will have similar effects, since the CNV code is relatively well encapsulated, but the exact-match checks will hopefully give us some peace of mind until CARROT tests are ready. @jonn-smith @KevinCLydon looping you in just in case you're not aware of all of this history. Would love to chat about where CARROT is at and where you'd like it to go---feel free to ping me anytime!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7649#issuecomment-1023354175:824,validat,validation,824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7649#issuecomment-1023354175,4,"['access', 'validat']","['access', 'validation']"
Security,"Actually, I'm noticing that while using NIO for the BAM for read/allelic-count collection is usually much more efficient, using NIO for the reference in other tasks can be much slower. Perhaps the access patterns for the reference (hitting ~10^5 intervals for WES PreprocessIntervals/AnnotateIntervals and ~10^6 sites for WES/WGS CollectAllelicCounts, respectively) make localization a better strategy? @droazen does that sound right to you?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-392046938:197,access,access,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-392046938,1,['access'],['access']
Security,"Actually, Jessica Hekman just confirmed she ran into an issue when running the GATK SV WDLs on-prem with Singularity, namely being unable to access the GATK jar in the root directory.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6525#issuecomment-1006929885:141,access,access,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6525#issuecomment-1006929885,1,['access'],['access']
Security,Add CheckForNullColumns to and fixed ClinvarSignificance in VAT validation [VS-1156],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8669:64,validat,validation,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8669,1,['validat'],['validation']
Security,Add NIO test that accesses public GCS data while not being authenticated,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5340:18,access,accesses,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5340,2,"['access', 'authenticat']","['accesses', 'authenticated']"
Security,Add VAT Validation check that aa_change and exon_number are consistentally set.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7850:8,Validat,Validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7850,1,['Validat'],['Validation']
Security,Add VAT validation rule #2 [VS-19],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7374:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7374,1,['validat'],['validation']
Security,Add VAT validation rule #5 [VS-16],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7365:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7365,1,['validat'],['validation']
Security,Add VAT validation rule #6 [VS-15],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7373:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7373,1,['validat'],['validation']
Security,Add VAT validation rule #7 [VS-14] and validation rule #6 [VS-15],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7379:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7379,2,['validat'],['validation']
Security,Add VDS Validation to the hail integration split,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8343:8,Validat,Validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8343,1,['Validat'],['Validation']
Security,Add a github action to run womtool validation on all WDLs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7822:35,validat,validation,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7822,1,['validat'],['validation']
Security,Add a loop to the validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8732:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8732,1,['validat'],['validation']
Security,"Add a test that validates than an ambiguous interval query can be disambiguated by the user by providing the interval in a bed file; changes the error message to recommend this alternative; fixes an issue where the error message was displaying the entire interval query multiple times, rather than the specific contigs which make the query ambiguous.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4183:16,validat,validates,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4183,1,['validat'],['validates']
Security,Add a test to validate WDLs in the scripts directory.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7826:14,validat,validate,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7826,1,['validat'],['validate']
Security,"Add additional validation around duplicated rows in the VAT; <img width=""1418"" alt=""duplicate_AN_or_AC_values"" src=""https://user-images.githubusercontent.com/6863459/220667710-a416ab64-4f9b-475b-9268-ef7b86bfa81e.png"">. This has a successful run (except for one failure that is because it's being run on way less data); https://job-manager.dsde-prod.broadinstitute.org/jobs/07ddde58-ac0d-4229-9f96-d093f5c11682; The failed test is:; SpotCheckForAAChangeAndExonNumberConsistency. Perhaps we want to update this to not run this test if there are less than 10k samples?; Yes we do:; Here's the ticket for that:; https://broadworkbench.atlassian.net/browse/VS-878",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8175:15,validat,validation,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8175,1,['validat'],['validation']
Security,Add an argument to GATKTool and GATKSparkTool that allows sequence dictionary validation to be turned off,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1145:78,validat,validation,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1145,1,['validat'],['validation']
Security,Add annotation checks to ValidateVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6272:25,Validat,ValidateVariants,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6272,1,['Validat'],['ValidateVariants']
Security,"Add argument to disable sequence dictionary validation, off by default",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1136:44,validat,validation,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1136,1,['validat'],['validation']
Security,"Add large runtime resource directory to lfs, and expose it to the Docker build.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4530:49,expose,expose,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4530,1,['expose'],['expose']
Security,Add optional summary table output to ValidateBasicSomaticShortMutations,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4982:37,Validat,ValidateBasicSomaticShortMutations,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4982,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,Add task for VAT validation #3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7360:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7360,1,['validat'],['validation']
Security,Add task for VAT validation #4,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7363:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7363,1,['validat'],['validation']
Security,Add task for VAT validation #8 & 9,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7364:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7364,1,['validat'],['validation']
Security,"Add the gcs-connector as a GATK dependency, and write a test showing that GCS access with the Spark local runner works",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3125:78,access,access,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3125,1,['access'],['access']
Security,Add validation to SparkSharder to get better information about sequence dictionary errors,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2615:4,validat,validation,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2615,1,['validat'],['validation']
Security,"Addded abstract class MachineLearningUtils to provide an interface and; handle common tasks. These include loading data, splitting data into; training and test sets, cross-validation, and optimizing classifier; hyperparameters. Also added XGBoostUtils which provides a concrete implemention of; MachineLearningUtils (by wrapping xgboost4j) and serves as an example; of how to provide access to a 3rd-party machine learning library. Finally, added an example tool: ExampleTrainXGBoostClassifier. This; demonstrates a typical training use case of loading data, training a; classifier, assessing accuracy, and saving the classifier. It also; demonstrates a typical filtering use case of loading a saved classifer,; and using it to calculate probabilities or class labels. This is working towards issue 4922 by providing the tools necessary to; train classifiers in general, but does not provide tools to train a; BreakpointEvidence filter, so does not resolve it. Additionally, this; framework should eventually be extended to provide a bayesian; hyperparameter optimizer. One outstanding problem with these changes is that xgboost4j threading; does not appear to work on OSX, resulting in slower training. However,; it does work on linux.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5146:172,validat,validation,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5146,2,"['access', 'validat']","['access', 'validation']"
Security,Added `#` as a character to be sanitized by `VCFOutputRenderer`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5817:31,sanitiz,sanitized,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5817,1,['sanitiz'],['sanitized']
Security,"Added a `PrintReads` based test (`IntelInflaterIntegrationTest.testIntelInflaterDeflaterWithPrintReads`) to test integration of `IntelInflater` and `IntelDeflater`. Removed the previous `IntelInflater` and `IntelDeflater` integration tests, which were basically copies of GKL unit tests. . **Note:** ; The `PrintReads` test is using `CEUTrio.HiSeq.WGS.b37.NA12878.20.21.tiny.md.bam` for input. When using `CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam` for input, we see the exception below when comparing `PrintReads` input and output. **This is true when using `IntelInflater`/`IntelDeflater`, as well as JDK `Inflater`/`Deflater`.** Is this a problem?. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-284551832:695,validat,validation,695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-284551832,1,['validat'],['validation']
Security,"Added a few comments of my own -- requested that you refactor to check the index modification time in the `FeatureDataSource` constructors, rather than in the sequence dictionary validation routines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324:179,validat,validation,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324,1,['validat'],['validation']
Security,Added a github action to run womtool validation on all WDLs; Also fixed two wdls that were failing validation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7822:37,validat,validation,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7822,2,['validat'],['validation']
Security,Added a test to validate WDLs in the scripts directory. (#7826),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7829:16,validat,validate,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7829,1,['validat'],['validate']
Security,"Added a unit test. To do so I had to make `BaseRecalibrationEngine.calculateKnownSites()` static. This wasn't a problem because I don't think it accesses any instance attributes but if there's some reason it shouldn't be static, I can do an integration test instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6389#issuecomment-576898683:145,access,accesses,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6389#issuecomment-576898683,1,['access'],['accesses']
Security,"Added a workflow file for enabling the GitHub Action which processes PR comments to determine if they are meant to trigger and CARROT test, and then processes them if they are formatted in that way. BIG IMPORTANT NOTE: Before this is merged, we need to set two secrets for this repo:; - `CARROT_TOPIC_NAME`, which is the name of the Google Cloud PubSub topic that messages will be sent to if a comment should trigger a run, and; - `CARROT_SA_KEY`, which is the service account key JSON for the service account that has write access to the PubSub topic.; If this is merged before those are set, I'm fairly confident we're just gonna get an email saying the action failed each time someone posts a PR comment (CARROT or otherwise), which would be less than ideal. Closes #6916",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6917:525,access,access,525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6917,1,['access'],['access']
Security,Added experimental tool and exposed some of the AllelicCNV file extension constants. I am adding the tools as requested. Minor additional changes.; @gtiao and @sooheelee . Closes #3196,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3198:28,expose,exposed,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3198,1,['expose'],['exposed']
Security,Added in code to change how the best transcript is determined.; Added `#` as a character to be sanitized by `VCFOutputRenderer`. (#5817); Fixes #5822,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5834:95,sanitiz,sanitized,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5834,1,['sanitiz'],['sanitized']
Security,Added map-style accessors to all concrete Funcotation classes (Funcotation.`getField`). Fixes #3919,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4176:16,access,accessors,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4176,1,['access'],['accessors']
Security,Added requester pays option to Mutect2 tasks that access bams,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6879:50,access,access,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6879,1,['access'],['access']
Security,Added the following methods to `GATKTool`:. - `getReferenceDataSource()`; - `getReadsDataSource()`; - `getFeatureManager()`. `Walker` inherits directly from `GATKTool` and overrides these methods to throw an exception if they are called. No walker should need to directly access the data.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4964:272,access,access,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4964,1,['access'],['access']
Security,Added validateSampleNameMap command line parameter; Added a unit test; Updated genomicsdb version to 0.6.3,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2733:6,validat,validateSampleNameMap,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2733,1,['validat'],['validateSampleNameMap']
Security,"Adding a new method `getVariantCacheLookAheadBases` to `VariantWalkerBase` which allows subclasses to set how far to look ahead when caching variants. This may help reduce memory use in GenotypeGVCFs. This also changes the side inputs to use FeatureDataSource.DEFAULT_QUERY_LOOKAHEAD_BASES which is `1000`, this is the value used by the other tools. I'm not sure if that's the right thing to do, but it makes variant walkers more consistent with other tools. Alternatively we could add a separate configuration method that lets tools change the side input value. We could also expose an optional parameter in the feature input that lets you set that on a per input basis if we need it. . This doesn't seem to have any negative effect on performance for genotypegvcfs, but it's hard to tell from short runs. It's also hard to tell if it's improving memory usage. It doesn't seem to make an appreciable difference at random places in the genome, but I'm hoping it will make a difference in very bad locations that have a lot of variation. Ideally our caches would be based on size rather than number of variants, but that's a more complicated change. fixes #3471",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3480:577,expose,expose,577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480,1,['expose'],['expose']
Security,"Adding validation to the SimpleInterval(String) constructor; Making GenomeLoc implement Locatable; Replacing all instances of SimpleInterval( locatable.getContig(), locatable.getStart(), locatable.getEnd()) with the new constructor. fixes #438 and #436",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/441:7,validat,validation,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/441,1,['validat'],['validation']
Security,"Adds a new ReadWalker tool, `RealignSoftClippedReads`, that realigns soft-clipped fragments using BWA. This tool is motivated by a specific artifact produced by Illumina DRAGEN v3.7.8 in which reads containing small indels are erroneously soft-clipped, often within mobile element contexts (LINE, SINE, ALU, SVA, etc). This is particularly problematic for mobile element insertion callers such as [Scramble](https://github.com/GeneDx/scramble) that rely on soft-clips for identifying potential insertion sites but do not perform a local assembly. In some cases, these soft-clipped reads are aligned to the incorrect region (confirmed by BLAT query and comparison to BWA alignments). An example of a false positive site produced by Scramble is shown below. <img width=""1008"" alt=""Screenshot 2023-11-16 at 2 09 45 PM"" src=""https://github.com/broadinstitute/gatk/assets/5686877/9d2c1dfd-9673-49f0-9372-c4c9cf6ffd9f"">. This PR includes the new tool and unit/integration tests and some minor refactoring to expose non-Spark BWA read mapping. This tool should be considered experimental until thorough benchmarking and analysis can be performed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8588:1002,expose,expose,1002,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8588,1,['expose'],['expose']
Security,Adds a tool to sanitize reads. This tool will convert any bases that do not match the reference into bases that do match the reference using the CIGAR as a key for which bases to change. The qualities for bases that match the reference are preserved.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6653:15,sanitiz,sanitize,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6653,1,['sanitiz'],['sanitize']
Security,"Adds support for online documentation generation through Barclay (https://github.com/broadinstitute/gatk/issues/2211) via the gatkDoc gradle task. The first commit contains only annotation updates (to target selected classes as documentation targets). A more complete audit/update pass will need to be done; but we need some for now in order to be able to exercise the doc generation process. The second commit contains that actual code and templates for documentation, and the final one upgrades to a Barclay snapshot that has the necessary dependent classes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327:268,audit,audit,268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327,1,['audit'],['audit']
Security,"Adds updated tools for creating the host reference kmer set (PathSeqBuildKmers) and filtering reads that are low-quality, low-complexity, or come from the host (PathSeqFilterSpark). Sorry for the especially large size on this PR. **PathSeqBuildKmers tool**. Note this has been renamed from PathSeqKmerSpark. Input:; 1) Host reference FASTA; 2) False positive probability (0 create a hash set, >0 to create a Bloom filter); 3) Kmer length (1-31); 4) Kmer base indices to mask (optional). Output:; 1) Serialized kmer Hopscotch set (.hss) or Bloom filter (.bfi) file. For each reference record, the tool generates a list of long's containing the canonicalized/masked kmers. The result is a Collection<long[]> variable, which is then converted to either a PSKmerSet (Hopscotch set) or PSKmerBloomFilter, depending on the desired false positive probability. . The PSKmerSet/BloomFilter classes are basically wrappers for LargeLongHopscotchSet and LongBloomFilter, respectively. They both inherit PSKmerCollection, which provides a contains() function for querying new kmers for set membership and makes loading the kmers for filtering more convenient. These classes also store the kmer size, mask, and false positive probability. They also handle canonicalization/masking on queried kmers. **PathSeqFilterSpark tool**. Input:; 1) Input BAM; 2) Host kmer set file (optional); 3) Host reference bwa image (optional). Output:; 1) BAM containing paired reads that still have mates; 2) BAM containing unpaired reads / reads whose mates were filtered out; 3) Metrics file containing read counts and elapsed wall time at each step (optional). Filtering steps performed on each read:; - If the user sets the --isHostAligned, the read will first be filtered if it is aligned sufficiently well ; - Alignment info is stripped; - A series of quality filters (same as in the previous version of this tool); - Kmerized and filtered out if at least a threshold number of kmers are in the host set (default 1); - Aligned t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3115:383,hash,hash,383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3115,1,['hash'],['hash']
Security,"Adressed all comments, @cmnbroad. Still the question on how to allow the user to provide custom validation. Back to you and thanks for reviewing!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-289361595:96,validat,validation,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-289361595,1,['validat'],['validation']
Security,"After #5887 goes in. PreprocessIntervals should still allow the use of IntervalMergingRule.OVERLAPPING_ONLY, and we should validate early that intervals are non-overlapping elsewhere.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5891:123,validat,validate,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5891,1,['validat'],['validate']
Security,"Agree that a separate README for the binary distribution is a good idea, but the document linked to above lacks basic instructions on things like running on a cluster and setting up GCS authentication. I think the doc should be based on the repo README instead with some sections omitted. It would actually be best if it could be generated automatically somehow from the repo README, so that we don't have to edit two documents whenever we make a change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3199#issuecomment-311986024:186,authenticat,authentication,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3199#issuecomment-311986024,1,['authenticat'],['authentication']
Security,Ah no we should just give them direct access to our dev repo. Will do now. Thanks though @ronlevine,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2308#issuecomment-291033418:38,access,access,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2308#issuecomment-291033418,1,['access'],['access']
Security,"Ah, that's a good reason not to use it. How about just plain old `validate`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290773651:66,validat,validate,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290773651,1,['validat'],['validate']
Security,"All that needs to be done here is prove that GenomicsDBImport can run on an 11k sample callset over a single interval without exploding or running out of memory. We don't need to hyper-optimize memory usage, or optimize the instance types for cost, etc. We should also probably pair it with GenotypeGVCFs in a single WDL script, to make sure that tool doesn't blow up either. Once done, we should share the settings we used with red team. Details on how to access the 11k sample set are in a Google doc that has been shared privately.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2633:457,access,access,457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2633,1,['access'],['access']
Security,"All walkers now have comprehensive sequence dictionary validation performed on their inputs (via the `GATKTool` base class, which is aware of all primary tool inputs and so is able to perform this check automatically -- see `GATKTool.validateSequenceDictionaries()`). At present, we need to do this validation manually in dataflow tools, but it would be nice if we could get it to happen automatically in a base class as it does on the walker side of things.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/669:55,validat,validation,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/669,3,['validat'],"['validateSequenceDictionaries', 'validation']"
Security,"Alright, I think I am in agreement with you @lbergelson about this behavior. Furthermore, all I needed out of this branch was an exposed mechanism for getting back the un-merged intervals so that I can track them myself in subtools. To that end I think I'm going to keep this branch and its tests and get rid of the merging rule argument in favor of leaving the logic for merging in place to be accessed by tools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567666730:129,expose,exposed,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567666730,2,"['access', 'expose']","['accessed', 'exposed']"
Security,"Also it seems that one can access the type arguments of fields thru reflection, thus the default behavior could constrain to try the codecs whose declared feature type is compatible with the FeatureInput parameter type. This would require less effort from the programmers perspective.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163297024:27,access,access,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163297024,1,['access'],['access']
Security,"Also just realized there’s *yet another* implementation in htsjdk, HardyWeinbergCalculation at https://github.com/samtools/htsjdk/blob/master/src/main/java/htsjdk/tribble/util/popgen/HardyWeinbergCalculation.java, so just a reminder to myself to check against that. Looks like a two-sided p-value of sorts is calculated there—I think this is P_{2\alpha} from Wigginton, although I need to double check. EDIT: Yup, it is, and furthermore the implementation appears to be correct. Phew! Added one more test to guard against a possible overflow issue that came up with that implementation, although it doesn't appear we have the same issue here. Will also note that 1) tests for the htsjdk implementation are pretty slim and don't actually cover very much, and 2) I don't see why we need to have two copies of this implementation, when all that essentially differs is the choice of p-value returned---we could certainly consolidate and expose the option of which p-value to return. Finally, I will also note that there is an implementation in bcftools. I have not checked it for correctness, but it appears to allow the calculation of both the one-sided p-value intended by ExcessHet, as well as what Wigginton calls P_{HWE}. So with that, the aforementioned implementations have covered every p-value discussed by that paper—and then one!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892893837:933,expose,expose,933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-892893837,1,['expose'],['expose']
Security,"Also note that I decided to append `_for_oncotator` to `additional_args`, since this is sufficiently vague without the suffix. However, analogous suffixes were not appended to exposed optional arguments for other tasks, since their names were less ambiguous. This is the sort of grossness we can do away with once Cromwell handles this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4324#issuecomment-362128625:176,expose,exposed,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4324#issuecomment-362128625,1,['expose'],['exposed']
Security,Also refactored the `VcfOutputRenderer` sanitization code. Fixes #5671,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5817:40,sanitiz,sanitization,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5817,1,['sanitiz'],['sanitization']
Security,Also when I validated the bam I got no errors. . I'll try rerunning this BQSR step a bunch of times to see if I can get the error again and see if it happens on the same shard.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317000181:12,validat,validated,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317000181,1,['validat'],['validated']
Security,"Also, MQ filtering results in stochastic coverage dropout. It is likely that low MQ regions significantly overlap across samples, in which case, downstream CNV can learn such biases and correct the coverage. Will test this in validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179:226,validat,validations,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179,1,['validat'],['validations']
Security,"Also, do you want to run the ""GATK protected test suite"" against ""GATK Public""? Explain the workflow you envision. . 1. A PR comes in on GATK Public. ; 2. Job runs with the HEAD of GATK Public PR. (The commit hash); 3. Job grabs GATK Protected and...? that's where Im not sure what you want. ""against a snapshot of GATK public built from the current branch"". Is GATK Protected regularly taken from a GATK snapshot? Do you have a scripted mechanism for that or just using GIT tools?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1758#issuecomment-287539278:209,hash,hash,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1758#issuecomment-287539278,1,['hash'],['hash']
Security,"Also, it may be prudent for me to run the data through the commands the tests use, as the data I will make comes from an external source and may not validate in its current state, depending on the tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500028:149,validat,validate,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500028,1,['validat'],['validate']
Security,"Also, the sooner Cromwell handles exposure of subworkflow task-level parameters, the better. I had to make these changes to bubble up and expose all optional parameters for all subworkflows, a process which adds an enormous amount of boilerplate and is (obviously) prone to errors. I plan to revert the changes when Cromwell is ready (#4287), so let me know!. I did not file an issue yet. @LeeTL1220 may have?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362072883:138,expose,expose,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362072883,1,['expose'],['expose']
Security,"Also, update code to use Hellbender's IOUtils instead of htsjdk's IOUtil; for these checks. We have both, presumably there's a reason Hellbender has their own and we should use them (for example, we can only add the hinting in our own). Sample error now:. A USER ERROR has occurred: Couldn't read file gs://foo/sam/m54113_160913_184949.scraps.beginning.sam. Error was: Error 403: jp-testing@redacted.iam.gserviceaccount.com does not have storage.objects.get access to foo/sam/m54113_160913_184949.scraps.beginning.sam. Potential cause: incorrect Google Cloud configuration; see instructions in the README. Fixes: #5468",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5477:458,access,access,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5477,1,['access'],['access']
Security,Also:; - Cleaned up headers in some test resources.; - Made sequence-dictionary checking more uniform across all CNV tools.; - Fixed an NPE bug in PlotModeledSegments input validation.; - Improved documentation regarding sex chromosomes in the ModelSegments pipeline.; - Miscellaneous boy-scout activities. Closes #3916.; Closes #3951.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4268:173,validat,validation,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4268,1,['validat'],['validation']
Security,"Although there is a workaround, ideally we'd remove the assumption from our docker that it can access the root user's home dir.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-434049374:95,access,access,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-434049374,1,['access'],['access']
Security,Always have git hash in Docker tags to avoid collisions [VS-1086],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8549:16,hash,hash,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8549,1,['hash'],['hash']
Security,"An optimization introduced in https://github.com/broadinstitute/gatk/pull/5466 was removed in https://github.com/broadinstitute/gatk/pull/6885. The latter exposed Smith-Waterman parameters, allowing them to be changed from their default values and thus to possibly violate conditions assumed by the former. We could restore the optimization if we added explicit checks of these conditions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7441:155,expose,exposed,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7441,1,['expose'],['exposed']
Security,"And for cosmic:. /home/robby/Tools/NGS/gatk-4.2.6.1-src/scripts/funcotator/data_sources/cosmic/; getCosmicDataSources.sh; This script creates the cosmic data sources for the Funcotator GATK tool. For usage information run with the '-h' option. To retrieve the COSMIC data sources you must have a COSMIC account.; Please enter your COSMIC account credentials:; Enter your email address: ***@***.***; Enter your password: ; Creating folders: ...; mkdir: created directory 'cosmic'; mkdir: created directory 'cosmic/hg19'; mkdir: created directory 'cosmic/hg38'; mkdir: created directory 'cosmic_fusion'; mkdir: created directory 'cosmic_fusion/hg19'; mkdir: created directory 'cosmic_fusion/hg38'; mkdir: created directory 'cosmic_tissue'; mkdir: created directory 'cosmic_tissue/hg19'; mkdir: created directory 'cosmic_tissue/hg38'; Getting files ... ; get: cosmic/grch37/cosmic/v84/; CosmicCompleteTargetedScreensMutantExport.tsv.gz: ssh: Could not resolve ; hostname sftp-cancer.sanger.ac.uk: Name or service not known; get: cosmic/grch37/cosmic/v84/CosmicFusionExport.tsv.gz: ssh: Could not ; resolve hostname sftp-cancer.sanger.ac.uk: Name or service not known; get: cosmic/grch38/cosmic/v84/; CosmicCompleteTargetedScreensMutantExport.tsv.gz: ssh: Could not resolve ; hostname sftp-cancer.sanger.ac.uk: Name or service not known; get: cosmic/grch38/cosmic/v84/CosmicFusionExport.tsv.gz: ssh: Could not ; resolve hostname sftp-cancer.sanger.ac.uk: Name or service not known; ***@***.***:~/Tools/NGS> . -- ; ; r-engelmann.de - Ihre Seite für die Auswertung und Visualisierung von Daten ; aus den Bereichen Biomedizin, Finanzen, Sozioökonomie und weitere. On Dienstag, 30. August 2022 16:36:24 CEST Jonn Smith wrote:; > @robby81 Which scripts are you running and what are the errors you see? The ; data sources scripts; > are unsupported, but should work out of the box (they did last time I tried ; them).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1274207002:410,password,password,410,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1274207002,1,['password'],['password']
Security,"Annotations in VCF are a nightmare due to format requirements. I'd recommend against using VCF to store annotations unless it's absolutely necessary. The mechanism to do so is too unwieldy - either you add annotations by name per allele as real annotations (i.e. accounted for in the header and then added to the INFO field as applicable with per-allele annotations separated by commas), or you add them to the INFO field as a pipe-delimited single annotation field, with commas separating this long annotation for each allele (this is currently what Funcotator does). Both are kind of gross, with the former taking a LOT of extra space and the latter being basically unreadable by eye. You also need to make sure annotations are sanitized for illegal characters (such as commas). Funcotator has an open issue for this. A tabular format for annotations makes more sense, and, as much as it pains me to suggest it, MAF may be a quick answer here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386121869:730,sanitiz,sanitized,730,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386121869,1,['sanitiz'],['sanitized']
Security,Another argument against this: the map function of a tool should clearly articulate its inputs in its signature. A map() that takes no parameters and relies on reflection/injection into members for its inputs would be supremely bad design.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76739266:171,inject,injection,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76739266,1,['inject'],['injection']
Security,Another option would be to add back the constructor that doesn't have ValidationStringency in CRAMIterator. (It looks like https://github.com/samtools/htsjdk/commit/efb11267ceea800d221a36d4cb9756dde4c7a984 introduced the incompatible change.) ValidationStringency can still be set using the setValidationStringency method. This would mean that no Hadoop-BAM JDK change or release is needed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1247#issuecomment-161945126:70,Validat,ValidationStringency,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1247#issuecomment-161945126,2,['Validat'],['ValidationStringency']
Security,"Another question: is there a way to get the test data used for GATK3 and VariantEval? Even if they're not small enough to reasonably check in, it would be at least useful to use that integration test as a way to validate it's working as expected in GATK4.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-337340876:212,validat,validate,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-337340876,1,['validat'],['validate']
Security,"Any chance we could break off legacy CNV tools into their own group? There are *many* more of them than there will be in the new pipelines---and many of them are experimental, deprecated, unsupported, or for validation only---that I think it makes sense to hide them and perhaps be less stringent about their documentation requirements. Anything we can do to reduce the support burden before release would be great.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346125341:208,validat,validation,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346125341,1,['validat'],['validation']
Security,"Any objections to exposing SW parameters to the command line? This looks like something we will want to explore for malaria. I'm also not convinced that our current parameters have been justified and/or optimized in any documented way. A few questions:. 1) There are 3 sets of parameters used in various ways, a) haplotype-to-reference alignment, b) read-to-haplotype alignment, and c) dangling ends. Any chance we can evaluate the effect of consolidating at least c), if not all sets? @emeryj I was told that you might be the one to ask about c) in particular; @davidbenjamin speculated that these might effectively yield STR-specific parameters. In general, if there are any quick and readily available evaluations (which ideally include variant normalization), I'd appreciate pointers to them. 2) Any suggestions on what the resulting command line should look like? I don't want to add 12 parameters, in the worst case. I also think that using integer arrays might be clunky. Perhaps I can suggest the use of args files in the doc string---although I don't think that those are expanded in the `##GATKCommandLine`, right?. 3) Should I touch `SWOverhangStrategy` at all? See e.g. https://github.com/broadinstitute/gatk/issues/6576. It looks like we thread both this and the `SWParameters` through many methods and classes, so the code could stand quite a bit of refactoring, but for now I will stick to the minimal changes required to expose. @droazen @ldgauthier any thoughts?. In some simple experiments of changing the a) parameters (from the somewhat questionable `NEW_SW_PARAMETERS = new SWParameters(200, -150, -260, -11)` back to `STANDARD_NGS = new SWParameters(25, -50, -110, -6)`), I've seen that there are non-negligible differences in the calls (beyond representation) at the few percent level, as well as changes in annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863:1437,expose,expose,1437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863,1,['expose'],['expose']
Security,Any test that tries to access a bucket seems to stall indefinitely. I think this has to do with gcloud not accepting our credentials file on travis. I suspect it's trying to open a web browser. I suspect it may need to be reconfigured with a service account key and an explicit authorization step before the build.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/444:23,access,access,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/444,2,"['access', 'authoriz']","['access', 'authorization']"
Security,"Apologies for re-opening, this is becoming an increasing issue for those looking to run GATK via Docker or singularity in a multi-tenant environment. Currently:; Docker creation and images provided run with a default user root within the container. Dropping privileges within the instance to a gatk user, would reduce the risk of inadvertent data access or harm when run in a multi-user environment. A possible solution:; Add something like the following within the Dockerfile:; RUN useradd -ms /bin/bash dev; WORKDIR /home/dev; USER dev. Providing:; Making changes like the above would bring the GATK docker container into line with best practice and greatly assist sites which are also looking to apply minimum standards enforcable through 3rd party applications, i.e. Aqua etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5959:347,access,access,347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5959,1,['access'],['access']
Security,"Apple is going to turn on Software Signing with OSX Catalina very soon (sometime this fall or so). While signing GATK will be fine, theoretically we have to sign all of the dynamic libraries that we leverage. OpenJDK did a release a while ago with these security features on and it was a major fiasco. We need to research what the signing requirements are and how they will affect the GATK release process.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6756:254,secur,security,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6756,1,['secur'],['security']
Security,"Are the errors below part of this, when starting BwaSpark with spark-submit?; I activated ""--disable-sequence-dictionary-validation true"", but that doesn't help. It is very unclear, why a BAM is not recognized as a BAM file. I have tried all kinds of ways to make sure that it is a BAM and not a SAM file.; The documentation for BwaSpark also says ""BAM/SAM/CRAM file containing reads"", so if SAM files are really not possible, that should probably be changed.; ...; Even on verbosity DEBUG, the comments are not at all helpful to get at the problem.; E.g. ""Cannot retrieve file pointers within SAM text files.""; Is that a general statement about SAM files? Or does it only say, that in this specific SAM file (which is actually a BAM file), file pointers cannot be found?; What pointers are meant exactly?; How could this be fixed?. ```; ""SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.""; Which URL?; Which stream?; Why would this happen? What could be the error?; The SAM/BAM distinction seems very unclear. It would be more helpful, if some specific missing aspect (e.g. not queryname sorted) would be clearly declared as the culprit.; ...; 00:29 DEBUG: [kryo] Write: SAMFileHeader{VN=1.5, SO=queryname}; ...; WARNING	2018-01-16 02:11:25	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; ...; java.lang.UnsupportedOperationException: Cannot retrieve file pointers within SAM text files.; 	at htsjdk.samtools.SAMTextReader.getFilePointerSpanningReads(SAMTextReader.java:185); ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062:121,validat,validation,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062,1,['validat'],['validation']
Security,Are these functions exposed to jexl?. https://github.com/samtools/htsjdk/blob/335f2c1d70fe922c1bedfcb2d7d7751d5adb723c/src/main/java/htsjdk/variant/variantcontext/VariantContext.java#L737,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5916#issuecomment-489349581:20,expose,exposed,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5916#issuecomment-489349581,1,['expose'],['exposed']
Security,ArrayIndexOutOfBoundsException: -87 in ValidateVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:39,Validat,ValidateVariants,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"As @cmnbroad pointed out, moving the function would need to expose the map, :+1: to just making it package protected and keeping it in place.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/787#issuecomment-128727780:60,expose,expose,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/787#issuecomment-128727780,1,['expose'],['expose']
Security,"As @droazen and I have been investigating, providing the `--gcs-project-for-requester-pays` argument when accessing buckets where the user does not have storage.bucket.get permission will cause failures. This clarifies the argument usage.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6594:106,access,accessing,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6594,1,['access'],['accessing']
Security,As I discovered when making the fix in PR #2021 bam files will fail validation if overhang clipping is used when running SplitNCigarRead because the mate reference start position might be changed. The tool can be refactored to perform a second walker pass over the reads in order to identify locations where this will be a problem by checking for sites where the primary read gets clipped by OverhangClippingManager.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2075:68,validat,validation,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2075,1,['validat'],['validation']
Security,"As a compromise fix, I have added a check to the validation code that asserts the dictionaries actually exist to save ourselves the potential null-pointer exceptions. @droazen . Fixes #6142",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6147:49,validat,validation,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6147,1,['validat'],['validation']
Security,"As a stopgap solution to allow `gs://` access on Spark with the local runner, let's add the `gcs-connector` as a project dependency, and craft a test case the runs a simple Spark tool like `PrintReadsSpark` using the local runner with GCS inputs and outputs. I've already started this in the branch https://github.com/broadinstitute/gatk/compare/dr_fix_gcs_spark_writing, but it's not working yet since the gcs-connector requires some extra authentication-related setup.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3125:39,access,access,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3125,2,"['access', 'authenticat']","['access', 'authentication-related']"
Security,"As an addendum to this task, we would also want to improve the test coverage to the underlying methods by hitting the newly exposed API.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5910#issuecomment-499224455:124,expose,exposed,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5910#issuecomment-499224455,1,['expose'],['exposed']
Security,"As discussed during GATK office hrs, we need to improve ValidateVariants message to say this is not a invalid vcf. ; **Solution**: separate validation argument that goes beyond vcf specs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630#issuecomment-637245840:56,Validat,ValidateVariants,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630#issuecomment-637245840,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,"As discussed in https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358040921, we need to refactor `GATKTool` so that all non-Spark tools can comfortably extend it rather than extending `CommandLineProgram` directly, as some tools currently do. In particular, we need to:. * Provide a mechanism for subclasses to selectively disable engine-wide arguments such as `-I` completely (and also the ability to override with their own version of an argument). * Access necessary datasources outside of the engine package. * Add the ability to register input metadata such as sequence dictionaries, so that standard validation rules can be enforced across the toolkit. * Add the ability for each tool to change the defaults for engine arguments such as `--interval-merging-rule`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4341:467,Access,Access,467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341,2,"['Access', 'validat']","['Access', 'validation']"
Security,As it turns out some of the `createGenomeLoc()` instances are being used by the GermlineCNVPipeline tests (evidently in ValidateVariants) and will fail if genome validation is enabled. This should be investigated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7300#issuecomment-861713884:120,Validat,ValidateVariants,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7300#issuecomment-861713884,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,"As part of #8083 we are drastically rewriting the entire Pileup-Caller infrastructure for DRAGEN-GATK. In doing so we have largely neglected its original functionality in Mutect2 and some of the changes (namely the re-factoring of that code to now happen after trimming like in with the GGA code) are going to impact the overall results for pileupcalling. It seems that we never added a real test of this functionality and its unclear to me currently what the meterics are that we want to assure ourselves that its working as intended. In #8083 I have checked that the code is hooked up manually, but its not clear to me what a proper test looks like for mutect without re-hashing the test samples that were being used in the bacterial project. I'm a little skeptical about adding a test that just asserts ""these results were different somehow"" and yet thats essentially the sort of test i would like and that would have saved me here. I would really like to have something better in place, especially if we are going to keep sharing the pileup-calling code between HC and M2 going forward.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8242:673,hash,hashing,673,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8242,1,['hash'],['hashing']
Security,"As part of my work in the Pipeline Dev team, I created 2 GATK images to address issue discussed [here](https://github.com/broadinstitute/gatk/issues/8684) (ie. having too many docker layers, we hit ACR limits very quickly). The images are in terrapublic, a premium-tier ACR and is publicly accessible. I made two images, one is squashed to just 1 layer, the other is reduced to just 12 layers (from the original 45). With these changes and the fact that terrapublic is on [premium](https://learn.microsoft.com/en-us/azure/container-registry/container-registry-skus#registry-throughput-and-throttling) tier, the maximum docker pulls per minute becomes 833 (ie. 10k readOps / 12 layers) for the reduced-layers image and 10,000 for the squashed one. We have yet to test these in our pipelines but I anticipate the squashed version to be slower since it won’t be able to take advantage of any parallel pulls or caching, hence the two versions to allow pipeline devs to decide which one is better for their use-case.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8808:290,access,accessible,290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8808,1,['access'],['accessible']
Security,"As per the discussion in https://github.com/broadinstitute/gatk/issues/3246, we need to expose the `IntervalArgumentCollection.IntervalMergingRule` setting as a command-line argument in `IntervalArgumentCollection`. This was exposed in GATK3 as `--interval_merging`/`-im` (see GATK3's `IntervalArgumentCollection`)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3251:88,expose,expose,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3251,2,['expose'],"['expose', 'exposed']"
Security,"As per the linked discussion, we are going to try to get access to a hosted PPC service that we can run automated tests on. If we're successful in setting up PPC automated tests, then the two native PairHmm implementations could live in the same repo -- if not, then we might prefer two separate repos.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-215710485:57,access,access,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-215710485,1,['access'],['access']
Security,"As reported by @jkobject testing our latest gatk-nightly image, certain non-requester-pays accesses fail with the latest google-cloud-nio version (0.123.23) when `--gcs-project-for-requester-pays` is specified. . The specific issue appears to be checks for the existence of non-existent files in non-requester-pays buckets when `--gcs-project-for-requester-pays` is set, resulting in a ""User project specified in the request is invalid"" error:. ```; code: 400; message: User project specified in the request is invalid.; reason: invalid; location: null; retryable: false; com.google.cloud.storage.StorageException: User project specified in the request is invalid.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:233); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.list(HttpStorageRpc.java:376); 	at com.google.cloud.storage.StorageImpl.lambda$listBlobs$11(StorageImpl.java:391); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.Retrying.run(Retrying.java:51); 	at com.google.cloud.storage.StorageImpl.listBlobs(StorageImpl.java:388); 	at com.google.cloud.storage.StorageImpl.list(StorageImpl.java:359); 	at com.google.cloud.storage.contrib.nio.CloudStoragePath.seemsLikeADirectoryAndUsePseudoDirectories(CloudStoragePath.java:118); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:743); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:418); 	at htsjdk.tribble.TribbleIndexedFeatureReader.loadIndex(TribbleIndexedFeatureReader.java:162); 	at htsjdk.tribble.TribbleIndexedFeatureReader.hasIndex(TribbleIndexedFeatureReader.java:228); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSourc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716:91,access,accesses,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716,1,['access'],['accesses']
Security,"At the Helsinki workshop someone explained to me they couldn't use Dockers on the server because folks don't typically have root access. I cannot say I understand the details, but I can get you in touch with someone who does if this is something you want to follow up on.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-333936510:129,access,access,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-333936510,1,['access'],['access']
Security,"At the moment, ReadTools only documents and use `ReadFilters` but I am planning to probably add pack a couple of tools from the GATK/Picard tools at some point. In addition, I am working on another toolkit based on the GATK code, and it will include also annotations for variants (and probably some VCF tools). I just thought that it will be useful to been able to pull out the super-category map to re-use the GATK docgen code. If a downstream project with extra-categories wants to use the GATK templates and DocGen code might get into troubles without being able to access that. I am still working on how to document better my toolkits, but it is not a problem yet. Anyway, I don't really have any strong feeling about this; I just wanted to reduce a bit the complexity of the GATK code and do the same with my downstream projects. If it is something that you anticipate that it is going to change the contract often, feel free to close (the RNA Strings can be removed in other PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661:569,access,access,569,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661,1,['access'],['access']
Security,Audit CRAM code in htsjdk for Path/NIO support,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5209:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5209,1,['Audit'],['Audit']
Security,Audit Funcotator FeatureCache access patterns,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5143:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5143,2,"['Audit', 'access']","['Audit', 'access']"
Security,Audit GenomeLocParser overloads for validation arguments.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7300:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7300,2,"['Audit', 'validat']","['Audit', 'validation']"
Security,Audit MuTect2 headers to describe fragment vs read annotations,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7904:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7904,1,['Audit'],['Audit']
Security,Audit Mutect2/HC FeatureCache access patterns,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5148:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5148,2,"['Audit', 'access']","['Audit', 'access']"
Security,Audit R package dependencies,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3047:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3047,1,['Audit'],['Audit']
Security,Audit ReadClipper code (and clients) to make sure that it can handle empty reads,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4204:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4204,1,['Audit'],['Audit']
Security,Audit ReadsDataSource for bugs related to header merging and contig indices,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1674:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1674,1,['Audit'],['Audit']
Security,"Audit results, there are two (very related issues).; Issue (1); `setPosition` from `SAMRecordToGATKReadAdapter` calls `setReferenceName` from `SAMRecord`. ```; public void setReferenceName(final String value) {; /* String.intern() is surprisingly expensive, so avoid it by looking up in sequence dictionary if possible */; if (NO_ALIGNMENT_REFERENCE_NAME.equals(value)) {; mReferenceName = NO_ALIGNMENT_REFERENCE_NAME;; mReferenceIndex = NO_ALIGNMENT_REFERENCE_INDEX;; return;; } else if (mHeader != null) {; final int referenceIndex = mHeader.getSequenceIndex(value);; if (referenceIndex != -1) {; setReferenceIndex(referenceIndex);; return;; }; }; // Drop through from above if nothing done.; mReferenceName = value.intern();; mReferenceIndex = null;; }; ```. Issue (2); `setMatePosition` from `SAMRecordToGATKReadAdapter` calls `setMateReferenceName` from `SAMRecord`. ```; public void setMateReferenceName(final String mateReferenceName) {; /* String.intern() is surprisingly expensive, so avoid it by looking up in sequence dictionary if possible */; if (NO_ALIGNMENT_REFERENCE_NAME.equals(mateReferenceName)) {; mMateReferenceName = NO_ALIGNMENT_REFERENCE_NAME;; mMateReferenceIndex = NO_ALIGNMENT_REFERENCE_INDEX;; return;; } else if (mHeader != null) {; final int referenceIndex = mHeader.getSequenceIndex(mateReferenceName);; if (referenceIndex != -1) {; setMateReferenceIndex(referenceIndex);; return;; }; }; // Drop through from above if nothing done.; this.mMateReferenceName = mateReferenceName.intern();; mMateReferenceIndex = null;; }; ```. @lbergelson, what's the fix?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141122913:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141122913,1,['Audit'],['Audit']
Security,Audit tools with tests with suspicious FeatureCache misses,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5895:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5895,1,['Audit'],['Audit']
Security,Audit use of Utils random generators and refactor if necessary.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6112:0,Audit,Audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6112,1,['Audit'],['Audit']
Security,Authenticate with dockerhub when running tests on travis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7102:0,Authenticat,Authenticate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7102,1,['Authenticat'],['Authenticate']
Security,Authenticate with github from Travis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3179:0,Authenticat,Authenticate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179,1,['Authenticat'],['Authenticate']
Security,Authenticating to dockerhub in travis build,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7204:0,Authenticat,Authenticating,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7204,1,['Authenticat'],['Authenticating']
Security,Authentication to access private GCS buckets,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394:0,Authenticat,Authentication,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394,2,"['Authenticat', 'access']","['Authentication', 'access']"
Security,"Authorization settings for the connector are described here: https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/gcs/conf/gcs-core-default.xml#L50. @jamesemery have you been able to get the connector working?. @droazen what configuration improvements did you have in mind?. Also, I'm not sure what the difference between `google.cloud.auth.service.account.json.keyfile` and `fs.gs.auth.service.account.json.keyfile` is (if any).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500755373:0,Authoriz,Authorization,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500755373,1,['Authoriz'],['Authorization']
Security,Automatic sequence dictionary validation for spark tools,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/669:30,validat,validation,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/669,1,['validat'],['validation']
Security,"Back to @droazen. Also in the last round, I didn't actually add the code in PositionalDownSampler to reject `submit` after `signalEndOfInput` was called (I added the state to keep track of it, but left out the actual validate call in submit). Letting tests run then, back to you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457759988:217,validat,validate,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457759988,1,['validat'],['validate']
Security,"Back to @meganshand. I put in a simple mitochondrial integration test. Given that our MC3 validation already covers this particular bug I actually don't think it needs a new test for mitochondria. Also, for later, are any of your spike-in bams public (or rather, public + public)? I noticed that the NA12878 truth doesn't have very low AFs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5057#issuecomment-408649991:90,validat,validation,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5057#issuecomment-408649991,1,['validat'],['validation']
Security,Back to you @cmnbroad. Your commit and some minor changes are included. There are still two questions:. * Why not using a `LinkedHashMap` instead of a `HashMap`/`ArrayList` for the default filters?; * Maybe it is better to make the fields final to do not override them in future changes or being aware of the change of state.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-283311142:152,Hash,HashMap,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-283311142,1,['Hash'],['HashMap']
Security,"Back to you @takutosato. You caught a couple of whoppers. Fortunately, the validations still look good after fixing them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4832#issuecomment-394917958:75,validat,validations,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4832#issuecomment-394917958,1,['validat'],['validations']
Security,"Barclay now has implementations for min/max and minRecommended/maxRecommended values for integer/float args (and these are integrated with the help doclet). Once GATK is upgraded to the next Barclay version, we can start using them. i.e., ApplyBQSRArgumentCollection. Also, there are a ton of places in gatk-protected where there is custom validation code that could be replaced with annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/143#issuecomment-273214207:340,validat,validation,340,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143#issuecomment-273214207,1,['validat'],['validation']
Security,"Based on the TODO that was in ReadsDataSource.java, I exposed a SamReaderFactory parameter for ReadsDataSource rather than limit it to just validation stringency. Whats the right protocol for adding a test that uses a test file from another package (I'm reaching into the picard test data for a data file for an engine test). Alternatively, is there a better way to test this change ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/565:54,expose,exposed,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565,2,"['expose', 'validat']","['exposed', 'validation']"
Security,Basic Validator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3755:6,Validat,Validator,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3755,1,['Validat'],['Validator']
Security,Basic testing of mutect2-replicate-validation.wdl still incomplete,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2948:35,validat,validation,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2948,1,['validat'],['validation']
Security,"Before our cromwell/WDL tests even start to build the docker image, we could run womtool to validate the WDL. This will catch some obvious errors in much less time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4802:92,validat,validate,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4802,1,['validat'],['validate']
Security,"Better sample name validation is done on the java side of plotting in #2858, but otherwise I don't really see a way around hardcoding column names in the R code that isn't more trouble than it's worth.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2862#issuecomment-335623002:19,validat,validation,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2862#issuecomment-335623002,1,['validat'],['validation']
Security,Btw the GATK3 version of SNCR doesn't generate a valid bam file according to ValidateSAMFile. Would be lovely to fix that here (and backport the fix if possible). v4 issue is here: https://github.com/broadinstitute/gatk/issues/1394,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1864#issuecomment-222232015:77,Validat,ValidateSAMFile,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1864#issuecomment-222232015,1,['Validat'],['ValidateSAMFile']
Security,"Bumping this since I ran into the same error as I was helping QC a colleagues data, running GATK 4.1.8.1 produces the following:. https://www.dropbox.com/s/2uleabl53dmg9y3/Screenshot%202020-07-28%2000.35.45.png. And this is on targeted capture data (Twist custom capture) ran through our core facility's sentieon pipeline, using the 'consensus' reads mapped to 1kg_grch37, using the raw reads works fine. Im not very familiar with sentieons pipelines but the steps to generate the UMI consensus reads are described at https://support.sentieon.com/appnotes/umi/. At first I though that discrepancy between @fleharty's ValidateSam and yours @ashwini06, could be that in the the newer version of Picard uses an updated version of htsjdk (v 2.23.0), but it's the same version of htsjdk that's included in GATK 4.1.8.1, so it seems unlikely. Walking through the commits between Picard 2.22.8 (the one bundled with GATK 4.1.8.1) and 2.23.2 doesn't (at least at first glance for me) show any commits changing code that could explain the differences in behaviour.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-664683562:617,Validat,ValidateSam,617,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-664683562,1,['Validat'],['ValidateSam']
Security,"Bumps commons-io:commons-io from 2.7 to 2.14.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=commons-io:commons-io&package-manager=gradle&previous-version=2.7&new-version=2.14.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You ca",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9003:296,secur,security-vulnerabilities,296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9003,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,BwaSpark does inappropriate validation of bam sequence dictionary against reference,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2121:28,validat,validation,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2121,1,['validat'],['validation']
Security,"BwaSpark is using WELLFORMED as it's read filter. This includes a number of checks that the reads validate against the header. However, most unaligned sam files are likely to have no or incomplete headers. This causes many reads to be unexpectedly filtered. We should define a better filter criteria BwaSpark.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2120:98,validat,validate,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2120,1,['validat'],['validate']
Security,"By ""currently"" you mean in classic GATK or in Hellbender? In classic GATK; I'm pretty sure none of these causes an exit. On Mon, Feb 23, 2015 at 5:08 PM, Louis Bergelson notifications@github.com; wrote:. > @vdauwera https://github.com/vdauwera Currently it looks like many; > causes of failure in the existing MalformedReadFilter do explode with an; > exception instead of filtering.; > - A read has a bad or undefined read group; > - read.getReadLength() == read.getBaseQualities().length; > - read.getReadBases() != SAMRecord.NULL_SEQUENCE; > - containsNOperator(read); > ; > These cases all throw exceptions by default or in any case. Should these; > be changed to filter out criteria? Or should these be moved to a; > ReadValidator like @jmthibault79 https://github.com/jmthibault79; > suggests. Alternatively, are these checked for by the HTSJDK validation /; > should they be?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/issues/193#issuecomment-75647767; > . ## . Geraldine A. Van der Auwera, Ph.D.; Bioinformatics Scientist II; GATK Support & Outreach; Broad Institute",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/193#issuecomment-75648317:851,validat,validation,851,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/193#issuecomment-75648317,1,['validat'],['validation']
Security,"By the way, I thought @vdauwera was opposed to using optional inputs in this way at some point (see #3657). Was that question ever decided? (I'm still of the opinion that they *should* be used in this way, but this is one of the reasons I didn't for this iteration of the WDL.). To be clear, the pair WDL right now does not allow all of the workflow paths (tumor-only, no PoN, etc.) that the new tools make possible. It only allows the one that we will most likely run in production (matched-normal + PoN). We should probably make the WDL a little more flexible to cover the most common use cases, but I'm fine if it doesn't completely expose all of the possible workflow paths---this would probably just make the WDL harder to maintain. Users can write their own WDLs in this case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362696132:636,expose,expose,636,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362696132,1,['expose'],['expose']
Security,C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970696E67456E67696E652E6A617661) |; | 0% | [...nstitute/hellbender/engine/AssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F417373656D626C79526567696F6E57616C6B65722E6A617661) |; | 0% | [...titute/hellbender/engine/spark/LocusWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4C6F63757357616C6B6572537061726B2E6A617661) |; | 0% | [...broadinstitute/hellbender/utils/GenomeLocParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F47656E6F6D654C6F635061727365722E6A617661) |; | 0% | [...ellbender/tools/validation/CompareBaseQualities.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F76616C69646174696F6E2F436F6D70617265426173655175616C69746965732E6A617661) |; | 0% | [...hellbender/tools/walkers/bqsr/AnalyzeCovariates.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F627173722F416E616C797A65436F76617269617465732E6A617661) |; | 0% | [...lections/RequiredVariantInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F617267756D656E74636F6C6C656374696F6E732F526571756972656456617269616E74496E707574417267756D656E74436F6C6C656374696F6E2E6A617661) |; > [Review all 203 files changed](https://codecov.io/gh/bro,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2293#issuecomment-265198632:2834,validat,validation,2834,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2293#issuecomment-265198632,1,['validat'],['validation']
Security,"CAL_DIRS in YARN).; 10:33:06.427 INFO ResourceUtils - ==============================================================; 10:33:06.427 INFO ResourceUtils - No custom resources configured for spark.driver.; 10:33:06.428 INFO ResourceUtils - ==============================================================; 10:33:06.428 INFO SparkContext - Submitted application: SortSamSpark; 10:33:06.446 INFO ResourceProfile - Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 600, script: , vendor: , cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0); 10:33:06.454 INFO ResourceProfile - Limiting resource is cpu; 10:33:06.455 INFO ResourceProfileManager - Added ResourceProfile id: 0; 10:33:06.500 INFO SecurityManager - Changing view acls to: root; 10:33:06.501 INFO SecurityManager - Changing modify acls to: root; 10:33:06.501 INFO SecurityManager - Changing view acls groups to:; 10:33:06.502 INFO SecurityManager - Changing modify acls groups to:; 10:33:06.502 INFO SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 10:33:06.755 INFO Utils - Successfully started service 'sparkDriver' on port 34861.; 10:33:06.784 INFO SparkEnv - Registering MapOutputTracker; 10:33:06.815 INFO SparkEnv - Registering BlockManagerMaster; 10:33:06.827 INFO BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 10:33:06.828 INFO BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up; 10:33:06.831 INFO SparkEnv - Registering BlockManagerMasterHeartbeat; 10:33:06.846 INFO DiskBlockManager - Created local directory at /raid/tmp/d6/c66ba827e22dbc38625af1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:41845,Secur,SecurityManager,41845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['Secur'],['SecurityManager']
Security,CNNPipelineIntegration tests needs expected results validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4537:52,validat,validation,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4537,1,['validat'],['validation']
Security,"CNNVariant Update models, validate scores, cleanup training",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5175:26,validat,validate,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5175,1,['validat'],['validate']
Security,CNV OncotateSegments does not expose bootDiskInGb runtime parameter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3566:30,expose,expose,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3566,1,['expose'],['expose']
Security,COMPRESSION_LEVEL : 1; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:19:10.290 INFO PrintReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:19:10.290 INFO PrintReadsSpark - Deflater: IntelDeflater; 14:19:10.290 INFO PrintReadsSpark - Inflater: IntelInflater; 14:19:10.290 INFO PrintReadsSpark - GCS max retries/reopens: 20; 14:19:10.290 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:19:10.290 INFO PrintReadsSpark - Initializing engine; 14:19:10.290 INFO PrintReadsSpark - Done initializing engine; 17/10/11 14:19:10 INFO spark.SparkContext: Running Spark version 1.6.0; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:10 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 43567.; 17/10/11 14:19:11 INFO slf4j.Slf4jLogger: Slf4jLogger started; 17/10/11 14:19:11 INFO Remoting: Starting remoting; 17/10/11 14:19:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.131.101.159:45501]; 17/10/11 14:19:11 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 45501.; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/11 14:19:11 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/11 14:19:11 INFO storage.DiskBlockManager: Created local directory at /tmp/hdfs/bloc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:3378,Secur,SecurityManager,3378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['Secur'],['SecurityManager']
Security,CREDENTIALS`). Here's an example test case: https://github.com/broadinstitute/gatk/commit/8b217f82352ceb55d21d7a5236e879818910d9c9. and the stacktrace:. ```; java.util.ServiceConfigurationError: java.nio.file.spi.FileSystemProvider: Provider com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider could not be instantiated; at java.util.ServiceLoader.fail(ServiceLoader.java:232); at java.util.ServiceLoader.access$100(ServiceLoader.java:185); at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384); at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404); at java.util.ServiceLoader$1.next(ServiceLoader.java:480); at java.nio.file.spi.FileSystemProvider.loadInstalledProviders(FileSystemProvider.java:119); at java.nio.file.spi.FileSystemProvider.access$000(FileSystemProvider.java:77); at java.nio.file.spi.FileSystemProvider$1.run(FileSystemProvider.java:169); at java.nio.file.spi.FileSystemProvider$1.run(FileSystemProvider.java:166); at java.security.AccessController.doPrivileged(Native Method); at java.nio.file.spi.FileSystemProvider.installedProviders(FileSystemProvider.java:166); at java.nio.file.Paths.get(Paths.java:141); at org.broadinstitute.hellbender.engine.spark.datasources.NioProviderExceptionUnitTest.test(NioProviderExceptionUnitTest.java:12). Caused by:; java.lang.IllegalArgumentException: A project ID is required for this service but could not be determined from the builder or the environment. Please set a project ID using the builder.; at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:122); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:208); at com.google.cloud.HttpServiceOptions.<init>(HttpServiceOptions.java:153); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:69); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:27); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:64); at com.google.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2110:1164,secur,security,1164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2110,1,['secur'],['security']
Security,"CS max retries/reopens: 20; 04:59:43.046 INFO ApplyBQSR - Requester pays: disabled; 04:59:43.047 INFO ApplyBQSR - Initializing engine; WARNING: BAM index file /scratch/ddo/markedsam/C18-436P.sort.rmdup.bam.bai is older than BAM /scratch/ddo/markedsam/C18-436P.sort.rmdup.bam; 04:59:43.556 INFO ApplyBQSR - Done initializing engine; 04:59:43.592 WARN ApplyBQSR - This tool has only been well tested on ILLUMINA-based sequencing data. For other data use at your own risk.; 04:59:43.592 INFO ProgressMeter - Starting traversal; 04:59:43.592 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 04:59:45.014 INFO ApplyBQSR - Shutting down engine; [November 8, 2021 at 4:59:45 a.m. PST] org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSR done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=557842432; java.lang.IllegalStateException: **The covariates table is missing ReadGroup V300019285_L2_ in RecalTable0**; 	at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:750); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.keyForReadGroup(ReadGroupCovariate.java:81); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.recordValues(ReadGroupCovariate.java:53); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.StandardCovariateList.recordAllValuesInStorage(StandardCovariateList.java:133); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527); 	at org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:145); 	at org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:27); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipelin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7549:3519,validat,validate,3519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7549,1,['validat'],['validate']
Security,"Calling `hashCode` directly on an instance of a Java enum produces a value that depends on the object's memory location and is therefore not stable across machines in a distributed environment. This causes issues when using these objects (or objects that contain them) as keys in Spark RDDs, which by default use `HashPartitioner` to parition by hash code. See this blog post for a summary:. http://dev.bizo.com/2014/02/beware-enums-in-spark.html. This PR modifies all places within the sv tools where we call `hashCode` on an enum, instead computing the hash of the ordinal of the enum value. For @SHuang-Broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4621:9,hash,hashCode,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4621,5,"['Hash', 'hash']","['HashPartitioner', 'hash', 'hashCode']"
Security,"Can someone here take inventory of the various Picard tools that you want to consider moving over? These are NOT represented in the GATK best practices document, for example `MergeBamAlignment` or `ValidateSamFile`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1#issuecomment-66663056:198,Validat,ValidateSamFile,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1#issuecomment-66663056,1,['Validat'],['ValidateSamFile']
Security,Can you gain access to the original gvcfs for those samples? if not I don't think there is a standard way to do such a thing in GATK following best practices. Perhaps there is some general VCF merging tool that would do the trick sort-of but it won't be the same as if you had run that sample with the rest thru the single sample + joint-genotyping pipeline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7292#issuecomment-855333445:13,access,access,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7292#issuecomment-855333445,1,['access'],['access']
Security,"Can you point out where in the log you see that? I'm looking at it but I don't see anything about memory in the log you provided. (Except the Runtime.totalMemory()=4523032576 which is just standard output spam from gatk when it shutsdown) Sequence dictionary validation usually happens first, it's strange that a failure in the middle of a run would be effected by it. I'm no very curious what weird thing is happening that's causing this...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548114772:259,validat,validation,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548114772,1,['validat'],['validation']
Security,"Can you run the GATK tool `ValidateSamFile` on `CEUTrio.HiSeq.WGS.b37.NA12878.20.21.tiny.md.bam`, and see if you get the same validation error as you do after roundtripping through the inflater/deflater, @gspowley?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285104828:27,Validat,ValidateSamFile,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285104828,2,"['Validat', 'validat']","['ValidateSamFile', 'validation']"
Security,Can you setup your temporary folder to a location where you have read and write access? Slurm might interfere with temporary files. ; [How to setup and use temporary folder for GATK local execution](https://gatk.broadinstitute.org/hc/en-us/articles/18965297287067-How-to-setup-and-use-temporary-folder-for-GATK-local-execution),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8873#issuecomment-2168101103:80,access,access,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8873#issuecomment-2168101103,1,['access'],['access']
Security,"Can you try a few more cache sizes like 200000 and 500000? Also, when you do the PR, could you create `VariantWalker.FEATURE_CACHE_SIZE = 100000` (or whatever the final value is) and pass it into the `FeatureManager` in `initializeFeatures()`? `FeatureDataSource.DEFAULT_QUERY_LOOKAHEAD_BASES` should stay at 1000 (for ReadWalkers, which have a lot more overlap in their query access patterns)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1092#issuecomment-155505129:377,access,access,377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1092#issuecomment-155505129,1,['access'],['access']
Security,"Can't seem to do git clone https://github.com/broadinstitute/hellbender/. This is my console output:. ```; wmd16-c9e:codespace vdauwera$ git clone http://github.com/broadinstitute/hellbender/; Cloning into 'hellbender'...; remote: Counting objects: 22221, done.; remote: Compressing objects: 100% (142/142), done.; remote: Total 22221 (delta 47), reused 4 (delta 4), pack-reused 22046; Receiving objects: 100% (22221/22221), 36.63 MiB | 3.58 MiB/s, done.; Resolving deltas: 100% (9903/9903), done.; Checking connectivity... done.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (76.16 MB); Username for 'http://github.com': vdauwera; Password for 'http://vdauwera@github.com': ; Error accessing media: src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam (6b1304800e60c0ac0358df137bdad48b7857a36465b04fef3fbbb09380f04746). Errors logged to /Users/vdauwera/codespace/hellbender/.git/lfs/objects/logs/20151005T220016.510795175.log.; Use `git lfs logs last` to view the log.; Downloading src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam.bai (11.25 KB); Username for 'http://github.com': ; ```. Looks like I'm failing to download large test files. Do I need to be on VPN for this to work? Or is it expected and I should ignore it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/950#issuecomment-145722061:664,Password,Password,664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/950#issuecomment-145722061,2,"['Password', 'access']","['Password', 'accessing']"
Security,Cannot access pull request for Owner configuration,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3945:7,access,access,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3945,1,['access'],['access']
Security,Change CompareSAMs to obey validation stringency; re-enable two integ…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/604:27,validat,validation,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/604,1,['validat'],['validation']
Security,Changed ValidateVariants Doc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2759:8,Validat,ValidateVariants,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2759,1,['Validat'],['ValidateVariants']
Security,Check UUID in read adapter equals() and hashCode() methods,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/653:40,hash,hashCode,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/653,1,['hash'],['hashCode']
Security,Clean up the fail fast validation a little.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7821:23,validat,validation,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7821,1,['validat'],['validation']
Security,"Closes #4893. Closes #5086. Closes #5684. Closes #4500. Makes #4933, #4958, and #5085 possible. @takutosato Failing tests are superficial. You can begin reviewing. . This is a big PR:. * Refactor of all M2 filtering. Each filter has its own class, and the filtering engine ties it all together.; * Learn allele fraction clustering and somatic SNV and indel priors.; * More probabilistic filters.; * All filters have a common probabilistic threshold.; * M2 determines threshold automatically.; * Rewrite of all M2 documentation.; * Several filters, including strand bias and normal artifact, learn their own parameters. @LeeTL1220 M2 validations look really, really good. @meganshand Once this goes in mitochondria best practices will need to be tweaked again. We can merge the dangling tails homoplasmic fix before merging this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5688:633,validat,validations,633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5688,1,['validat'],['validations']
Security,"Closes #5085. This improves validations a bit immediately but more importantly will enable more intelligent filtering on the level of haplotypes, which I think is critical to some of the messy data we have seen. This will also benefit HaplotypeCaller some day. @LeeTL1220 Could you review as far as changes to Mutect2 are concerned?. @droazen Could you review the refactoring of `ReadLikelihoods` / extracting `MoleculeLikelihoods`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5831:28,validat,validations,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831,1,['validat'],['validations']
Security,"Closes #6235 . This PR allows users to more easily clobber individual theano flags. This can be used to change the location of the theano compilation directory (see the above issue and #4782 for context). These flags are set upon import of the theano module; see http://deeplearning.net/software/theano/library/config.html for details. This solution is a little hacky, hence the code duplication. Ideally, we'd be able to specify this directory (and potentially other flags) as a parameter to the tools. As discussed with @cmnbroad, probably the cleanest solution would be to modify the PythonScriptExecutor to allow environment variables to be specified, e.g. via ProcessSettings. This solution would also cover the initial import of the `gcnvkernel` package for validation purposes, rather than only the imports in the resource scripts modified in this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6244:764,validat,validation,764,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6244,1,['validat'],['validation']
Security,Closes #6829; @mwalker174 Could you please review? . I only added `gcs_project_for_requester_pays` input to tasks that need access to BAMs. Do we also need it for the ones that require reference such as `PreprocessIntervals`?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6870:124,access,access,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6870,1,['access'],['access']
Security,Closes #7672. @ldgauthier This is the bug fix for Sarah Calvo. The allele was lost when trimming caused its haplotype to start with a deletion. The solution is to inject force-calling alleles after trimming. Are you able to review?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7679:163,inject,inject,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7679,1,['inject'],['inject']
Security,"Closes https://github.com/broadinstitute/dsp-spec-ops/issues/366 by putting into SQL what is in English in that ticket:; > All variants in the region, chr19:35,740,407-35,740,469, overlap transcripts with multiple genes and those genes are always IGFLR1 and AD000671.2. Do not consider rows that include a consequence of downstream_gene_variant or upstream_gene_variant in this validation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7360:378,validat,validation,378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7360,1,['validat'],['validation']
Security,"Closing this ancient PR -- this is hard to test/would take a lot of work to get in, and it's a somewhat exotic use case. We do already have tests covering access to private files with default credentials, which seems sufficient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2879#issuecomment-453564368:155,access,access,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2879#issuecomment-453564368,1,['access'],['access']
Security,"Coming from https://gatkforums.broadinstitute.org/gatk/discussion/9358/gatk-runtime-error-read-max-length-must-be-0-but-got-0-with-1000g-bam#latest. There seems to be a bug somewhere in the implementation of pair hmm, which multiple users have run into. The most recent user reported running Mutect2 on two different machines with the same inputs, and same versions of GATK. One run was successful, while the other failed with ; ``` ; java.lang.IllegalArgumentException: readMaxLength must be > 0 but got 0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:152); 	at org.broadinstitute.hellbender.utils.pairhmm.N2MemoryPairHMM.initialize(N2MemoryPairHMM.java:28); 	at org.broadinstitute.hellbender.utils.pairhmm.LoglessPairHMM.initialize(LoglessPairHMM.java:7); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:177); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.initializePairHMM(PairHMMLikelihoodCalculationEngine.java:242); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:177); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:207); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:212); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:979); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:182); 	at org.broadins",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543:554,validat,validateArg,554,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543,1,['validat'],['validateArg']
Security,Command line validation stringency argument for GATKTool.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1439:13,validat,validation,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1439,1,['validat'],['validation']
Security,CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:736); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:137); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:3649,secur,security,3649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,2,"['access', 'secur']","['access', 'security']"
Security,CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:137); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:158); 	at org.broadinstitute.hellbender.Main.main(Main.java:239); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.refreshAccessToken(ComputeEngineCredentials.java:152); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:175); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:161); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:157); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:9215,secur,security,9215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,2,"['access', 'secur']","['access', 'security']"
Security,CommandLinePrograms should not be instantiated until arguments are parsed and injected,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/107:78,inject,injected,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/107,1,['inject'],['injected']
Security,CompareSAMs ignores validation stringency,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419:20,validat,validation,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419,1,['validat'],['validation']
Security,"CompareSAMs ignores validation stringency. Running this. ```; build/install/hellbender/bin/hellbender CompareSAMs src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam src/test/resources/org/broadinstitute/hellbender/tools/BQSR/NA12878.chr17_69k_70k.dictFix.bam --VALIDATION_STRINGENCY SILENT; ```. results in this. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 130, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.; at htsjdk.samtools.SAMUtils.processValidationErrors(SAMUtils.java:439); at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:643); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:628); at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:598); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:544); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:518); at htsjdk.samtools.util.PeekIterator.peek(PeekIterator.java:67); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.skipAnyNotprimary(SecondaryOrSupplementarySkippingIterator.java:36); at htsjdk.samtools.SecondaryOrSupplementarySkippingIterator.advance(SecondaryOrSupplementarySkippingIterator.java:31); at org.broadinstitute.hellbender.utils.read.SamComparison.compareCoordinateSortedAlignments(SamComparison.java:111); at org.broadinstitute.hellbender.utils.read.SamComparison.compareAlignments(SamComparison.java:68); at org.broadinstitute.hellbender.utils.read.SamComparison.<init>(SamComparison.java:44); at org.broadinstitute.hellbender.tools.picard.sam.CompareSAMs.doWork(CompareSAMs.java:34); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:94); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:144); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgram.instanceMain(PicardComm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419:20,validat,validation,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419,2,['validat'],['validation']
Security,"Completing https://github.com/broadinstitute/hellbender/issues/673 will take care of the case of ""missing reference for CRAM"", but we also need to make sure we're handling the case of ""wrong reference"" elegantly (where elegantly means ""throw a `UserException` with a descriptive error message). We want a test case with a reference that is the wrong reference for a CRAM, but has a compatible sequence dictionary (so that it won't be caught by the sequence dictionary validation). Both the wrong and missing reference cases should have a simple integration test that runs, eg., `PrintReads` with `expectedExceptions = UserException.class`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/677#issuecomment-126031374:468,validat,validation,468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/677#issuecomment-126031374,1,['validat'],['validation']
Security,"Comprises the last ~~6 commits~~ 7 commits. (Had to fix a test file dependency. From now on, I'd like to request more encapsulation of test resources. Certainly we should have a common pool of general, rarely changed resources, but sharing of specific resources across packages breaks encapsulation.). @lbergelson I removed a few R dependencies. We should update the base Docker image accordingly and make sure I didn't break anything.; @davidbenjamin I had to change one use of HashedListTargetCollection in CalculateContamination. Also note that FilterByOrientationBias is the sole survivor in the exome package, so you may want to move it somewhere else.; @LeeTL1220 @vruano This removes a lot of your code. Please speak up if there are any utility classes, etc. that you'd like to keep. (For example, I kept the HMM code.) I removed the Target codec and associated classes.; @sooheelee I will update the list of tools for doc updates accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3935:479,Hash,HashedListTargetCollection,479,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3935,1,['Hash'],['HashedListTargetCollection']
Security,"Could it be possible to read the file from a `java.nio.Path` in the [gatk-bwamem-jni](https://github.com/broadinstitute/gatk-bwamem-jni), @SHuang-Broad? It looks that it's a constraint of the native code, but it will be nice to be able to have just one index image in HDFS accessible for all the nodes...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311908959:273,access,accessible,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311908959,1,['access'],['accessible']
Security,"Could this be related to having sliced objects in the gsutils buckets but not using a code path that goes through a native CRC implementation? I ask because I noticed that when I try to download the file. ```; gs://hellbender/test/resources/benchmark/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam; ```. with gsutil, I get this error:. ```; CommandException: ; Downloading this composite object requires integrity checking with CRC32c,; but your crcmod installation isn't using the module's C extension, so the; hash computation will likely throttle download performance. For help; installing the extension, please see:. $ gsutil help crcmod. To download regardless of crcmod performance or to skip slow integrity; checks, see the ""check_hashes"" option in your boto config file.; ```. Could the GATK command path be computing all of the CRC hashes in Java code, slowing it down?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-223982882:404,integrity,integrity,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-223982882,4,"['hash', 'integrity']","['hash', 'hashes', 'integrity']"
Security,Could you also run `docker images --digests` and paste the sha256 hash value for the image you're running? For `broadinstitute/gatk:4.4.0.0` it should be `044112d3d70603732d4a654ecaee33919cf9d45332d47268f5f1697b6ed558ed`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8402#issuecomment-1648498439:66,hash,hash,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8402#issuecomment-1648498439,1,['hash'],['hash']
Security,CountVariants in Spark. exposed Loading VariantContexts in parallel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1496:24,expose,exposed,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1496,1,['expose'],['exposed']
Security,Create WDL to validate VAT and add first test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7352:14,validat,validate,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7352,1,['validat'],['validate']
Security,Create a checksum to validate individual data sources based on the size of the data source files and some other meta attributes. Calculate the checksum for each data source in each data source package (somatic/germline). Store these checksums in the GATK jar and validate the data sources at runtime. Default to an exception if the checksums do not match. Have a command-line option to reduce the exception to a warning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087:9,checksum,checksum,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087,6,"['checksum', 'validat']","['checksum', 'checksums', 'validate']"
Security,Create separate ValidateVariants validation that go beyond vcf specs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:16,Validat,ValidateVariants,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,CreateSequenceDictionary needs to expose a utility method to create a sequence dictionary programmatically.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7628:34,expose,expose,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7628,1,['expose'],['expose']
Security,Created NioFileCopier that copies files using nio paths (includes; optional progress indicator and integrity validation).; Updated an error message in funcotator to make it more descriptive. Fixes #4549,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5150:99,integrity,integrity,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5150,2,"['integrity', 'validat']","['integrity', 'validation']"
Security,Created VAT here: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/b5c03ce6-cc74-462a-b81d-8ea102be314e; Validated VAT here: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/e6511960-8340-4e74-8f06-6c1a69d848bd (confirming with Rori that the failures are not surprising given it's only 10 samples),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8665:145,Validat,Validated,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8665,1,['Validat'],['Validated']
Security,Creating tools and simple command-line for validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1240:43,validat,validation,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1240,1,['validat'],['validation']
Security,"Cromwell switched to Java 11 starting with version 60 so the Java 8 sub-builds are probably going to error like. ```; Caused by: java.lang.UnsupportedClassVersionError: wdl/draft3/parser/WdlParser$Ast has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0; 	at java.lang.ClassLoader.defineClass1(Native Method); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:756); 	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); 	at java.net.URLClassLoader.defineClass(URLClassLoader.java:473); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7824#issuecomment-1116073144:497,secur,security,497,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7824#issuecomment-1116073144,3,"['Secur', 'secur']","['SecureClassLoader', 'security']"
Security,"CrosscheckFingerprints cannot access to ""Requester Pays"" buckets, can it be changed to support the ""--gcs-project-for-requester-pays"" option as in the GenomicsDBImport tool?. ```; code: 400; message: Bucket is requester pays bucket but no user project provided.; reason: required; location: null; retryable: false; com.google.cloud.storage.StorageException: Bucket is requester pays bucket but no user project provided.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:242); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:239); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); at shaded.cloud_nio.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:238); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:736); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:497); at htsjdk.samtools.util.IOUtil.assertPathsAreReadable(IOUtil.java:525); at picard.fingerprint.CrosscheckFingerprints.doWork(CrosscheckFingerprints.java:449); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7489:30,access,access,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7489,1,['access'],['access']
Security,"Currently `GATKRead.copy()` is unable to guarantee a deep copy, since we only have a deep copy method for Google `Read`s (`GenericData.clone()`, which it inherits), not `SAMRecord`s. We should write a deep copy method for `SAMRecord`, hook it up to the `GATKRead.copy()` implementation in `SAMRecordToGATKReadAdapter`, and change the method contract to guarantee that a deep copy will be performed. This is not a huge priority, since `GATKRead` already guarantees that defensive copies will be made of all mutable reference types returned from accessor methods (which means that shallow copies should be safe to use freely), but would be nice for consistency and peace of mind.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/623:544,access,accessor,544,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/623,1,['access'],['accessor']
Security,"Currently `SamAssertionUtils.assertSamsEqual` fails with `""SAM file output differs from expected output""`. It uses `SamComparison`, which prints a lot of helpful information about how the files differ to stdout. This output is often hidden when running it in a test suite though. It's also a bit strange to print error messages to stdout. `SamComparison` should capture this information and provide an accessor to retrieve it instead of dumping it to stdout.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/375:402,access,accessor,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/375,1,['access'],['accessor']
Security,"Currently `ValidateSamFile` has a limited list of platforms which does not include `BGI`. We should add `BGI` to the list of valid platforms, and we should review our list of supported platforms to make sure there are no others we are missing.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5517:11,Validat,ValidateSamFile,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5517,1,['Validat'],['ValidateSamFile']
Security,Currently build_docker will run for a long time and then fail at the end if you are not authenticated to gcloud. We should have an upfront test for it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5353:88,authenticat,authenticated,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5353,1,['authenticat'],['authenticated']
Security,"Currently in master, intervals from the IAC that have been modified by the engine are further padded, overlapping intervals are merged, and bins are created. WES should be run by specifying bin_length = 0, and the total number of intervals (targets, in this case) should remain fixed. However, current behavior does not prevent intervals that overlap after padding from being merged. Note also that in sl_gcnv_ploidy_cli, bins that contain only Ns are also dropped. We should add validation of the IAC to check for minimal modification by the engine (as is done by other CNV CLIs), and then pad without introducing overlaps or merging if bin_length = 0. If bin length != 0, then the current behavior is fine (since it is conceivable that one might want to bin when running WES).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3981:480,validat,validation,480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3981,1,['validat'],['validation']
Security,Currently it seems like the pull request build on travis is running the wrong commit's tests in docker. The docker build script takes a commit hash as part of it's inputs and then performs a checkout of that when building the docker. This is failing for the PR builds because the .travis.yml is currently getting the hash from calling rev-parse on the current branch which gives the commit number of master. It should be using $TRAVIS_COMMIT as the hash.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3216:143,hash,hash,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3216,3,['hash'],['hash']
Security,"Currently one can indicate if a program argument is optional by setting the Attribute annotation property `optional` to `true`. . Then, it is up to the programmer to indicate a default value for the parameter explicitly initializing the corresponding field with such a default value. It seems to me that we would gain versatility/expressibility if we use java.util.Optional as the type of the field:; - The code can then know wether the user actually gave a value to the parameter using `isPresent()`; currently there is no way to do so as the value provided by the user happens to be the default value.; - The default value may be defined dynamically based on other argument values or input data using `orElse(dynamicDefault)` or `orElseGet(dynamicDefaultLamda)`.; - The current solution prompts to use arbitrary marker constant value to deactivate the functionality; behind the user argument. eg.`maximumDepth = -1`. This constant may in fact be outside the valid ; range for the argument which makes validating it a bit more difficult.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1445:1003,validat,validating,1003,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1445,1,['validat'],['validating']
Security,"Currently our default reads validation stringency as defined in `GATKTool` is SILENT -- should it be STRICT, or is STRICT too impractical/annoying for read-world data?. Prompted by a discussion in https://github.com/broadinstitute/gatk/pull/1439",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1457:28,validat,validation,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1457,1,['validat'],['validation']
Security,Currently the only way to create a sequence dictionary from within a GATK tool is to call into the CreateSequenceDictionary tool as if it was being executed from the command-line. This is a hack. We need to expose a method that other tools can call into that will create a sequence dictionary for files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7628:207,expose,expose,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7628,1,['expose'],['expose']
Security,"Currently the script fails when configured to run tests, since it doesn't have access to the large files in the docker image. These need to be downloaded and mounted for the tests to pass, as we do in the docker tests on travis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3191:79,access,access,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3191,1,['access'],['access']
Security,"Currently we have a dependency on having gcloud and gsutil installed and configured in a certain way, but we don't have any documentation about it. . We're getting authentication partially from gcloud auth login, which is being propagated in a way I don't fully understand through the dataflow pipeline options. . We need to understand exactly what's happening and then write an explanation of what a user needs to do to have it work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1051:164,authenticat,authentication,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1051,1,['authenticat'],['authentication']
Security,"Currently, `IntervalArgumentCollection` still uses `GenomeLocs` internally during parsing, despite the rest of the engine using `SimpleIntervals`. This forces us to provide a sequence dictionary when interval arguments are present even if the only input is an interval list (eg., an `IntervalWalker` that purely processes/transforms intervals). We should provide a mode in `IntervalArgumentCollection` in which intervals can be parsed into `SimpleIntervals` without a sequence dictionary. This will require us to fill in a special value such as `Integer.MAX_VALUE` for the stop position of intervals that don't contain a stop position (eg., ""chr1"" or ""chr1:1+""), since we won't know the true contig lengths, but our future query interfaces should all be robust to requests for locations outside of contig boundaries (and not blow up given such requests). This will also require adding some way of determining whether or not an interval has been validated against a sequence dictionary -- perhaps `ValidatedInterval` could be a subclass of `SimpleInterval`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/298:945,validat,validated,945,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/298,2,"['Validat', 'validat']","['ValidatedInterval', 'validated']"
Security,"Currently, if the GATK doesn't have permission to check whether a GCS bucket is Requester Pays (which is a separate permission from access to the bucket itself!), we get a cryptic error message along the lines of:. ```; User does not have storage.buckets.get access to bucket_name; ```. This is the same error the gsutil client gives in the same situation:. ```; $ gsutil requesterpays get gs://gatk-best-practices; AccessDeniedException: 403 droazen@broadinstitute.org does not have storage.buckets.get access to gatk-best-practices.; ```. Ideally we should detect this situation upfront in the GATK and emit a more informative error message.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6349:132,access,access,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6349,4,"['Access', 'access']","['AccessDeniedException', 'access']"
Security,"Currently, in order to create a GenomeLoc, you need to create a GenomeLocParser, which requires either a reference fasta or a sequence dictionary for validation. Sometimes, however, you don't want this level of validation (perhaps you have already checked that the interval is within bounds, making the extra validation wasteful -- this happens in a few places in the new engine). There should be a way to instantiate a GenomeLoc directly, without the need to pass around a GenomeLocParser.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/100:150,validat,validation,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100,3,['validat'],['validation']
Security,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6698:125,access,access,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698,3,['access'],"['access', 'accesses']"
Security,"Currently, we're instantiating our CommandLineProgram before we've parsed its arguments and injected them into the appropriate member variables. This means that the constructors for our tools (eg., the ReadWalker constructor) cannot use argument values during initialization, which is a big problem. We need to delay instantiation until after arguments are parsed and injected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/107:92,inject,injected,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/107,2,['inject'],['injected']
Security,"DATA_SOURCES/data_source_8/hg38/dnaRepairGenes.20180524T145835.csv; 16:01:43.979 INFO Funcotator - Initializing Funcotator Engine...; 16:01:43.983 INFO Funcotator - Creating a VCF file for output: file:/home/deepak/software_library/gatk-4.1.7.0/variants.funcotated.vcf; 16:01:44.020 INFO ProgressMeter - Starting traversal; 16:01:44.020 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 16:01:44.068 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr1:1-10454 due to alternate allele: <NON_REF>; 16:01:44.116 INFO VcfFuncotationFactory - dbSNP 9606_b150 cache hits/total: 0/0; 16:01:44.121 INFO Funcotator - Shutting down engine; [12 May, 2020 4:01:44 PM IST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.14 minutes.; Runtime.totalMemory()=2889875456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:-9 end:10464; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:733); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createReferenceSnippet(FuncotatorUtils.java:1439); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getBasesInWindowAroundReferenceAllele(FuncotatorUtils.java:1468); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationForSymbolicAltAllele(GencodeFuncotationFactory.java:2560); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFlankFuncotation(GencodeFuncotationFactory.java:2465); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:953); at org.broadinstitute.hellbender.tools.func",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:6401,validat,validateArg,6401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['validat'],['validateArg']
Security,"DBImport - Callset Map JSON file will be written to /home/test/Software/gatk-4.4.0.0/test/./02/callset.json; 10:19:39.951 INFO GenomicsDBImport - Complete VCF Header will be written to /home/test/Software/gatk-4.4.0.0/test/./02/vcfheader.vcf; 10:19:39.951 INFO GenomicsDBImport - Importing to workspace - /home/test/Software/gatk-4.4.0.0/test/./02; 10:19:40.060 INFO GenomicsDBImport - Importing batch 1 with 2 samples; 10:19:40.075 INFO GenomicsDBImport - Shutting down engine; org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=285212672; java.lang.NumberFormatException: For input string: ""G""; 	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67); 	at java.base/java.lang.Integer.parseInt(Integer.java:668); 	at java.base/java.lang.Integer.parseInt(Integer.java:786); 	at htsjdk.tribble.readers.TabixReader.getIntv(TabixReader.java:337); 	at htsjdk.tribble.readers.TabixReader.access$500(TabixReader.java:48); 	at htsjdk.tribble.readers.TabixReader$IteratorImpl.next(TabixReader.java:438); 	at htsjdk.tribble.readers.TabixIteratorLineReader.readLine(TabixIteratorLineReader.java:46); 	at htsjdk.tribble.TabixFeatureReader$FeatureIterator.readNextRecord(TabixFeatureReader.java:170); 	at htsjdk.tribble.TabixFeatureReader$FeatureIterator.<init>(TabixFeatureReader.java:159); 	at htsjdk.tribble.TabixFeatureReader.query(TabixFeatureReader.java:133); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport$1.query(GenomicsDBImport.java:971); 	at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:167); 	at org.genomicsdb.importer.GenomicsDBImporter.lambda$null$4(GenomicsDBImporter.java:732); 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Thr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8517:3552,access,access,3552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8517,1,['access'],['access']
Security,"DP=1399;ECNT=1;MBQ=36,36;MFRL=209,211;MMQ=60,60;MPOS=34;POPAF=7.3;TLOD=42.57	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1327,27:0.019:1354:672,12:655,15:0.02,0.02,0.02:0.0007239,0.005058,0.994; 11	108175462	.	G	A	.	.	DP=972;ECNT=1;MBQ=36,36;MFRL=209,206;MMQ=60,60;MPOS=37;POPAF=7.3;TLOD=15.55	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:898,12:0.013:910:446,6:452,6:0.01,0.01,0.013:0.002966,0.0009292,0.996; 12	12037318	.	C	G	.	.	DP=975;ECNT=1;MBQ=36,36;MFRL=205,218;MMQ=60,60;MPOS=48;POPAF=7.3;TLOD=15.41	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:893,12:0.013:905:438,4:455,8:0.01,0.01,0.013:0.004146,0.0007942,0.995; 15	66679819	.	G	C	.	.	DP=870;ECNT=1;MBQ=36,36;MFRL=215,211;MMQ=60,60;MPOS=52;POPAF=7.3;TLOD=25.62	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:797,17:0.022:814:384,11:413,6:0.02,0.02,0.021:0.004622,0.001165,0.994; 18	42532923	.	T	C	.	.	DP=1402;ECNT=1;MBQ=36,36;MFRL=197,222;MMQ=60,60;MPOS=51;POPAF=7.3;TLOD=41.21	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1312,25:0.019:1337:681,13:631,12:0.02,0.01,0.019:0.0009167,0.002842,0.996; 20	31019360	.	AT	A	.	.	DP=1530;ECNT=1;MBQ=36,36;MFRL=198,199;MMQ=60,60;MPOS=44;POPAF=7.3;RPA=7,6;RU=T;STR;TLOD=30.65	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1424,34:0.022:1458:673,20:751,14:0.02,0.02,0.023:0.003063,0.0009654,0.996; ```. #### Steps to reproduce; ```; # Call without --alleles option does not produce the variants.; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_noalleles.vcf.gz; # Call with --alleles option produces the variants with presumably high quality scores; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_alleles.vcf.gz --alleles truth_small_variants_NA12878-NA24385-mix_sorted.vcf.gz; ```; The BAM, BED and output VCF files are available for download [here](https://gatk-validation.s3-eu-west-1.amazonaws.com/mutect2-4.1.9.0.zip).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7015:5837,validat,validation-stringency,5837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7015,3,['validat'],"['validation', 'validation-stringency']"
Security,Data is sensitive and bug is recapitulated in https://github.com/broadinstitute/dsde-docs/issues/3026. CombineGVCFs gives the following error message:; ```; java.lang.IllegalArgumentException: Invalid interval. Contig:HLA-DRB1*15:03:01:02 start:11569 end:11005; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.onTraversalSuccess(CombineGVCFs.java:415); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:895); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadinstitute.hellbender.Main.main(Main.java:288); ```; Here are the dictionary lines for two consecutive HLA-DRB1 contigs:; ```; @SQ SN:HLA-DRB1*15:03:01:02 LN:11569 M5:4e0d459b9bd15bff8645de84334e3d25 AS:38 UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta SP:Homo sapiens; @SQ SN:HLA-DRB1*16:02:01 LN:11005 M5:4a972df76bd3ee2857b87bd5be5ea00a AS:38 UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta SP:Homo sapiens; ```; Notice the `LN` lengths match up. It appears that our tool is mistaking contig information.; Note that `HLA-DRB1*16:02:01` is the very last contig in GRCh38.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4572:308,validat,validateArg,308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4572,2,['validat'],"['validateArg', 'validatePositions']"
Security,"Dear @davidbenjamin and @droazen,. please find [here](https://github.com/broadinstitute/gatk/files/12196051/2023-06-21.ISMB.Poster.on.XOP.Variant.Calling.Workflow.and.Mutect2.SES.v3.pdf) the poster that we presented this Monday at ISMB 2023 in Lyon. It sheds some additional light on this issue and explains why we believe that fine-tuning of the error model introduced in Mutect2 4.1.9.0 led to overcalling of variants in samples with increased (but not pathologic) DNA degradation. Presentation of the poster led to several interesting discussions with other users of Mutect2 at the conference. Given these results, I would propose that you could expose the parameter you newly set in commit [a304725](https://github.com/broadinstitute/gatk/commit/a304725a60f5000ec6381040137043a557fc3dc1) `private static final int ONE_THIRD_QUAL_CORRECTION = 5;` as a user-facing command line parameter. In this manner, you could leave the parameter at `5` by default but allow users who work on clinical (especially FFPE) samples to change it to `0` instead, thus effectively restoring the behaviour shown (and benchmarked) prior to 4.1.9.0. Would that be an acceptable compromise?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1655902557:649,expose,expose,649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1655902557,1,['expose'],['expose']
Security,Dear GATK staff. We are now forbidden access to any webpages starting with the address https://gatkforums.broadinstitute.org/gatk/discussion/ by cloudflare. We can still access pages starting with https://gatk.broadinstitute.org/hc/en-us/ . We are connecting from various computers and netwrk in France using Firefox but it seems that it is the server itself that is blocked by Cloudflare. Have you already been notified of this problem and do you think you can solve it with cloudflare?. Thanks for your help. Best regards. Thierry Grange,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-577016491:38,access,access,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-577016491,2,['access'],['access']
Security,"Dear all, thank you for the quick reply! Yes, I tried this on the latest release (4.0.8.0), and it is still an issue. vcf-validator validates the input VCFs, however, in the output VCF, I get errors associated with the field descriptions for the VAF annotation (which I believe may be specific to DeepVariant), a few of which are pasted below:. The header tag 'reference' not present. (Not required but highly recommended.). column CDC1551_clean_mutated_9.fasta_1_1 at NC_000962.3:580772; \ .. FORMAT tag [VAF] expected different number of values (expected 1, found 2); column CDC1551_clean_mutated_2.fasta_1_1 at NC_000962.3:580772 .. FORMAT tag [VAF] expected different number of values (expected 1, found 2). I tried the above after changing the VAF field description label from Number=R to Number=A in my unmerged gVCF files. This did not solve the problem. I'm attaching two example VCF files which I am attempting to merge. My commands are below: . ```. # Create GenomicsDBImport; gatk GenomicsDBImport \; -R ${REF_DIR}${ref} \; -V CDC1551_clean_mutated_1.fasta_1_1.bwa_deep.g.vcf.gz \; -V CDC1551_clean_mutated_2.fasta_1_1.bwa_deep.g.vcf.gz \; --reader-threads 8 \; --genomicsdb-workspace-path ${mapper}_${caller}_comb \; --intervals 'NC_000962.3' \; --java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true' \; --overwrite-existing-genomicsdb-workspace true . ## Joint Genotype VCF; gatk GenotypeGVCFs \; -R ${REF_DIR}${ref} \; -V gendb://${mapper}_${caller}_comb \; -O ${mapper}_${caller}_joint.vcf; ```. [test_vcfs.zip](https://github.com/broadinstitute/gatk/files/2295977/test_vcfs.zip). Thank you for your support on this problem!; Best,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413755772:122,validat,validator,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413755772,2,['validat'],"['validates', 'validator']"
Security,"Default changed from 250 -> 20 in #5699 and exposed in #7450. Unfortunately, I don't recall if we did any benchmarking to spot check runtime/output changes, but I would expect 20 samples to be sufficient for estimating posterior means and standard deviations to the level needed for most downstream use cases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-910220751:44,expose,exposed,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-910220751,1,['expose'],['exposed']
Security,"Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants don",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:3329,Validat,ValidateVariants,3329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,2,"['Validat', 'validat']","['ValidateVariants', 'validationExampleGood']"
Security,"Did you clone the GATK repo ?; **Yes**; What JDK/version are you using ?; **openjdk version ""11.0.6""**. Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/usr/bin/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:108); at org.gradle.api.internal.tasks.execution.ResolveBeforeExecutionOutputsTaskExecuter.execute(ResolveBeforeExecutionOutputsTaskExecuter.java:67); at org.gradle.api.internal.tasks.execution.ResolveAfterPreviousExecutionStateTaskExecuter.execute(ResolveAfterPreviousExecutionStateTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:94); at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:95); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57); at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.exec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-590387973:951,Validat,ValidatingTaskExecuter,951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-590387973,2,['Validat'],['ValidatingTaskExecuter']
Security,"Discussed with @kcibul (and others) offline. Conclusion: the majority of the validation code might end up being non-WDL with just one or two WDL tasks that call pthyon....etc., but it will be divided up into separate WDL tasks for now for development, and once it's done (or mostly) done, it can always be restructured to have the code in whatever place/structure makes the most sense going forward.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883526280:77,validat,validation,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883526280,1,['validat'],['validation']
Security,Disk space variables inconsistently exposed in gCNV WDLs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6995:36,expose,exposed,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6995,1,['expose'],['exposed']
Security,"Disq uses different code for finding container offsets compared to Hadoop-BAM, so that might be where the problem is coming from. However, I need access to the file that it's failing with to diagnose the issue. @jjfarrell how can I get a copy?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451880631:146,access,access,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451880631,1,['access'],['access']
Security,Do all those BAMs pass ValidateSamFile?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/541#issuecomment-112965444:23,Validat,ValidateSamFile,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/541#issuecomment-112965444,1,['Validat'],['ValidateSamFile']
Security,"Docker instance running as root, possible security issue for local data access. REVISITED",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5959:42,secur,security,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5959,2,"['access', 'secur']","['access', 'security']"
Security,Document how to access spark master page when running hellbender on GCE/dataproc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/975:16,access,access,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/975,1,['access'],['access']
Security,Document how to authenticate to Google Cloud Storage,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2495:16,authenticat,authenticate,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2495,1,['authenticat'],['authenticate']
Security,Does the bam pass `ValidateSamFile`?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6065#issuecomment-516480503:19,Validat,ValidateSamFile,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6065#issuecomment-516480503,1,['Validat'],['ValidateSamFile']
Security,"Does the problem go away if you use an output path with the 'hdfs://' scheme? E.g. _hdfs://namenode:8020/user/yaron/output.bam_ (where _namenode_ is the hostname of the namenode). There are two libraries being used internally for accessing the filesystem - the Hadoop filesystem API, and the NIO API - and they have slightly different behaviour if no scheme is provided. So to avoid problems it's best to give full paths with URI schemes for all input and output paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3066#issuecomment-407791242:230,access,accessing,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066#issuecomment-407791242,1,['access'],['accessing']
Security,Don't check contig ordering during sequence dictionary validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1178:55,validat,validation,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1178,1,['validat'],['validation']
Security,Don't check contig ordering in sequence dictionary validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1176:51,validat,validation,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1176,1,['validat'],['validation']
Security,Don't forget to expose the file in the WDL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5114#issuecomment-413203475:16,expose,expose,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5114#issuecomment-413203475,1,['expose'],['expose']
Security,"Done. Full results are on the internal presentation slides. The summary table follows:. | speedup vs async on a 1-core machine | slice | whole | intervals |; |-------------|----------|---------|----------|; | vcf | 0.91| 1.40| 0.57|; | bam (exome)| 40.42| 1.06| 1.02|; | bam (wgs)| 111.18| 1.21| 0.99|. This table compares the execution time of a single machine running PrintReads or SelectVariants, getting its input either directly from the Google bucket (NIO), or by first copying it with gsutil and then running off the local disk (with the async option turned on, allowing eager decompression of the stream - a feature the NIO code does not have). Each experiment is run four times, and each number here represents the ratio of two such experiments. Numbers larger than 1 indicate that NIO was faster. Each row is a different input file: vcf, small bam (exome), large bam (whole genome). Each column is a selection of what to read from the file (via the `-L` argument): a megabase slice, the whole file, or a long list of intervals. The NIO code relies heavily on prefetching, so it doesn't perform well with the many disjoint accesses of the right column. When processing only a small part of the (already small) vcf file, NIO loses out to copy + local processing. Everywhere else the direct-to-bucket ""NIO"" code performs quite well, up to 111x faster than the ""copy then process"" approach. I also ran the full set with async disabled. It makes a difference but NIO still wins and loses at the same places by similar margins (in particular the 111x win remains).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-284056956:1132,access,accesses,1132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-284056956,1,['access'],['accesses']
Security,Double-check validation test,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/557:13,validat,validation,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/557,1,['validat'],['validation']
Security,"Dsamjdk.compression_level=2 -jar /Applications/genomicstools/gatk/gatk-4.0.11.0/gatk-package-4.0.11.0-local.jar LearnReadOrientationModel -alt-table 13_tumor-alt.tsv -ref-hist 13_tumor-ref.metrics -alt-hist 13_tumor-alt-depth1.metrics -O 13_tumor-artifact-prior-table.tsv; 12:16:19.960 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.0.11.0/gatk-package-4.0.11.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; Nov 26, 2018 12:16:20 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:16:20.176 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 12:16:20.177 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:1500,authenticat,authentication,1500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['authenticat'],['authentication']
Security,DuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - GCS max retries/reopens: 20; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; 18/01/09 18:30:54 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 18/01/09 18:30:54 INFO spark.SparkContext: Submitted application: BwaAndMarkDuplicatesPipelineSpark; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'sparkDriver' on port 38793.; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering MapOutputTracker; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering BlockManagerMaster; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/01/09 18:30:55 INFO storage.DiskBlockManager: Created local directory at /tmp/sun/blockmgr-b03058d,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:5443,Secur,SecurityManager,5443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,During alpha we should work out the process of releasing builds to maven central. This may require coordinating with ops in order to handle signing keys and passwords.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1188:157,password,passwords,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1188,1,['password'],['passwords']
Security,"EDIT: Parameters are now exposed as individual arguments, so the following quoted text is outdated; see below for more details. > Adds the parameters `--dangling-end-smith-waterman-parameters-table <GATKPath>`, `--haplotype-to-reference-smith-waterman-parameters-table <GATKPath>`, and `--read-to-haplotype-smith-waterman-parameters-table <GATKPath>` to HaplotypeCaller and Mutect2. This allows for input via a TSV containing the column headers `MATCH_VALUE\tMISMATCH_PENALTY\tGAP_OPEN_PENALTY\tGAP_EXTEND_PENALTY` and one row of integers. Enables investigation of #2498 and #5564. Closes #6863 . Just opening this in case anyone wants to play around with it. I'll do some further testing on human and malaria data, but we have already found some cases in the latter for which changing some of the quizzical values to more reasonable ones yields immediate benefits. If anyone has any suggestions for possible evaluations, I'm all ears!. A few notes:. - I still need to add doc strings for the new arguments.; - Per https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291, we can wait until after the DRAGEN-GATK dust settles to review/reevaluate/merge.; - At that time, I'll add a few simple integration tests to check that I've properly bubbled up each set of parameters.; - The reviewer might find the diagram at https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816 useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885:25,expose,exposed,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885,1,['expose'],['exposed']
Security,"EDT] Executing as louisb@wm1b0-8ab on Mac OS X 10.9.5 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_45-b14; Version: Version:GATK.4.alpha-556-g73c02ea-SNAPSHOT JdkDeflater; 17:44:44.990 [main] INFO org.broadinstitute.hellbender.tools.PrintReads - Initializing engine; 17:44:45.124 [main] INFO org.broadinstitute.hellbender.tools.PrintReads - Done initializing engine; 17:44:45.151 [main] INFO org.broadinstitute.hellbender.engine.ReadsDataSource - Preparing readers for traversal; 17:44:45.153 [main] INFO org.broadinstitute.hellbender.engine.ReadsDataSource - Done preparing readers for traversal; 17:44:45.178 [main] INFO org.broadinstitute.hellbender.tools.PrintReads - Shutting down engine; [August 17, 2015 5:44:45 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=257425408; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$25(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$43/308889081.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/828#issuecomment-131972247:1424,validat,validatePositions,1424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828#issuecomment-131972247,1,['validat'],['validatePositions']
Security,ERROR] [system.err] [bwt_restore_sa] SA-BWT inconsistency: seq_len is not the same. Abort!; ... 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':test'.; 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:98); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:68); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:62); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAt,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:1180,Validat,ValidatingTaskExecuter,1180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['Validat'],['ValidatingTaskExecuter']
Security,"EXHAUSTIVE --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --SKIP_MATE_VALIDATION false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrowser.bed.bgz --known-sites snp151flagged_tablebrowser.bed.bgz`; ```; ERROR: return code 3; STDERR:; 15:46:35.795 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:46:42.808 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:42.810 INFO BaseR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:2078,Validat,Validated,2078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['Validat'],['Validated']
Security,"E_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrowser.bed.bgz --known-sites snp151flagged_tablebrowser.bed.bgz`; ```; ERROR: return code 3; STDERR:; 15:46:35.795 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:46:42.808 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:42.810 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.0.0; 15:46:42.810 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:46:42.813 INFO BaseRecalibrator - Execut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:2262,Validat,ValidateSamFile,2262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['Validat'],['ValidateSamFile']
Security,Early Subset VDS during validation for validation check,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8728:24,validat,validation,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8728,2,['validat'],['validation']
Security,"Empirical testing has shown that this tool performs best at scale with cloud buffering; disabled. With cloud buffering on and thousands of concurrent GenomicsDBImport tasks,; we do too many simultaneous GCS accesses (since the prefetcher spawns a new thread for each; reader upon a query) and start seeing intermittent failures, even with aggressive retries.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3110:207,access,accesses,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3110,1,['access'],['accesses']
Security,Enable direct s3a:// file accesses,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6698:26,access,accesses,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698,1,['access'],['accesses']
Security,Enable setting validation stringency in ReadsDataSource.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/565:15,validat,validation,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565,1,['validat'],['validation']
Security,Error getting access token for service account,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:14,access,access,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,1,['access'],['access']
Security,Error running gatk seq-format-validation workflow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:30,validat,validation,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['validat'],['validation']
Security,"Error: A JNI error has occurred, please check your installation and try again; Exception in thread ""main"" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes; 	at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:314); 	at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:268); 	at java.util.jar.JarVerifier.processEntry(JarVerifier.java:316); 	at java.util.jar.JarVerifier.update(JarVerifier.java:228); 	at java.util.jar.JarFile.initializeVerifier(JarFile.java:383); 	at java.util.jar.JarFile.getInputStream(JarFile.java:450); 	at sun.misc.JarIndex.getJarIndex(JarIndex.java:137); 	at sun.misc.URLClassPath$JarLoader$1.run(URLClassPath.java:839); 	at sun.misc.URLClassPath$JarLoader$1.run(URLClassPath.java:831); 	at java.security.AccessController.doPrivileged(Native Method); 	at sun.misc.URLClassPath$JarLoader.ensureOpen(URLClassPath.java:830); 	at sun.misc.URLClassPath$JarLoader.<init>(URLClassPath.java:803); 	at sun.misc.URLClassPath$3.run(URLClassPath.java:530); 	at sun.misc.URLClassPath$3.run(URLClassPath.java:520). This error seems to be resulting from signed jars and there are recommendations on the web such as exclude 'META-INF/*.RSA', 'META-INF/*.SF','META-INF/*.DSA'; I will greatly appreciate if someone could tell me where to add the aforementioned line in 'build.gradle' file.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2676:116,Secur,SecurityException,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2676,5,"['Access', 'Secur', 'secur']","['AccessController', 'SecurityException', 'security']"
Security,Errors in VariantFiltration - possibly due to (or exposed by) async tribble reading,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1638:50,expose,exposed,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1638,1,['expose'],['exposed']
Security,Escape table names properly in ValidateVat WDL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8116:31,Validat,ValidateVat,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8116,1,['Validat'],['ValidateVat']
Security,"Evaluation of THCA/STAD/LUAD TCGA WGS/WES CR concordance with SNP arrays was implemented on FC last summer and showed good performance. For WES, comparisons against GATK CNV and CODEX showed comparable to highly improved performance, respectively, with minimal parameter tuning. WGS comparisons were unavailable due to limitations of competing tools. This evaluation will be expanded to include CR/MAF concordance against PanCanAtlas ABSOLUTE results. Some curation of the samples could be performed; some batch effects were observed in some LC WGS LUAD samples. Comparisons to other tools will probably be removed for ease of maintenance. Will be adapted to fit into whatever framework arises from #4630; same goes for HCC1143 and CRSP validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697:737,validat,validations,737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697,1,['validat'],['validations']
Security,"Even if you know that only some tools are enabled for Spark, its not obvious how to find them. And the tool list has more than one Spark program group, which I didn't notice at first:. Spark Validation tools: Tools written in Spark to compare aspects of two different files; Spark pipelines: Pipelines that combine tools and use Apache Spark for scaling out (experimental); Spark tools: Tools that use Apache Spark for scaling out (experimental)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1291:191,Validat,Validation,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1291,1,['Validat'],['Validation']
Security,Every travis build will upload it's test results to gs://hellbender/test/build_reports/<somepath>. The end of the build log shows the publicly accessible url for the test results.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/704:143,access,accessible,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/704,1,['access'],['accessible']
Security,"Evidently docker is changing their policy around anonymous users pulling from all docker repos (regardless of the tier for the owner of the repository being pulled from). This might or might not affect us since it looks like travis is pulling from our GCR repo for builds but we should be mindful of workflows that might rely on pulling hundreds of docker images from docker-hub through anonymous web VMs:; ```; On Monday, November 2, 2020 at 9am Pacific Standard Time, Docker will begin enforcing rate limits on container pulls for Anonymous and Free users. Anonymous (unauthenticated) users will be limited to 100 container image pulls every six hours, and Free (authenticated) users will be limited to 200 container image pulls every six hours, when enforcement is fully implemented. Docker Pro and Team subscribers can pull container images from Docker Hub without restriction, as long as the quantities are not excessive or abusive.; In addition, we are pausing enforcement of the changes to our image-retention policies until mid-2021, when we anticipate incorporating them into usage-based pricing. Two months ago, we announced an update to Docker image-retention policies. As originally stated, this change, which was set to take effect on November 1, 2020, would result in the deletion of images for free Docker account users after six months of inactivity. Today's announcement means Docker will not enforce image expiration on November 1, 2020.; ```; This is farther clarified on their FAQ https://www.docker.com/pricing/resource-consumption-updates:; ```; Rate limits for Docker image pulls are based on the account type of the user requesting the image - not the account type of the image’s owner. These are defined on the pricing page.; The highest entitlement a user has, based on their personal account and any orgs they belong to, will be used. Unauthenticated pull requests are “anonymous” and will be rate limited based on IP address rather than user ID. For more information on aut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6922:665,authenticat,authenticated,665,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6922,1,['authenticat'],['authenticated']
Security,Example Run (AoU) [here](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20Echo%20RD/job_history/f4e85f7d-d8bf-45e1-a564-0dd2ae9f3761); New output file here: gs://fc-secure-4c3976f3-d84d-4243-876f-baa9f9a4256f/submissions/f4e85f7d-d8bf-45e1-a564-0dd2ae9f3761/GvsCalculatePrecisionAndSensitivity/85938f82-4731-437e-96a1-140a8ba7fcb7/call-CollateReports/stdout,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8633:182,secur,secure-,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8633,1,['secur'],['secure-']
Security,Expose BucketUtils.NIO_MAX_REOPENS as an engine-level argument,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3315:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3315,1,['Expose'],['Expose']
Security,"Expose Feature headers, and provide convenient VCFHeader access in VariantWalker",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/308:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/308,2,"['Expose', 'access']","['Expose', 'access']"
Security,Expose GenomicsDBArgumentCollection with CreateSomaticPanelOfNormals,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6746:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6746,1,['Expose'],['Expose']
Security,Expose HaplotypeCaller `READ_QUALITY_FILTER_THRESHOLD` on the command line,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7034:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7034,1,['Expose'],['Expose']
Security,Expose IntervalArgumentCollection.IntervalMergingRule as a command-line argument,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3251:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3251,1,['Expose'],['Expose']
Security,Expose `splitting-index-granularity` to all Spark tools outputting BAMs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6418:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6418,1,['Expose'],['Expose']
Security,Expose mapred.max.split.size as a parameter to GATKSparkTool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1064:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1064,1,['Expose'],['Expose']
Security,Expose max-alt-alleles constant as user parameter before we don't emit PLs in GenotypeGVCFs and CombineGVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2956:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2956,1,['Expose'],['Expose']
Security,Expose maximum-training-variants VQSR parameter [VS-634],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8029:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8029,1,['Expose'],['Expose']
Security,Expose more CNN training parameters to the command line,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8483:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8483,1,['Expose'],['Expose']
Security,Expose more optional parameters for CreatePanelOfNormals in CNV WDL.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3356:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3356,1,['Expose'],['Expose']
Security,Expose number of samples for emitting denoised copy ratios in gCNV.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5754:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754,1,['Expose'],['Expose']
Security,Expose or decrease CHUNK_DIVISOR in HDF5SVDReadCountPanelOfNormals.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4365:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4365,1,['Expose'],['Expose']
Security,Expose or hide all task-level parameters in CNV WDLs consistently.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3980:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3980,1,['Expose'],['Expose']
Security,Expose point size in somatic CNV plotting tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5748:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5748,1,['Expose'],['Expose']
Security,Expose spark attributes so they can be set by users,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1107:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1107,1,['Expose'],['Expose']
Security,Expose the attributes we set automatically in `SparkContextFactory` so they can be overridden by the user if necessary.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1107:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1107,1,['Expose'],['Expose']
Security,Expose the maximum-training-variants parameter for both INDEL and SNP model creation in the `GvsCreateFilterSet` WDL. Closes https://broadworkbench.atlassian.net/browse/VS-634,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8029:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8029,1,['Expose'],['Expose']
Security,Expose timeout arg in StreamingPythonScriptExecutor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4221:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4221,1,['Expose'],['Expose']
Security,Expose vid_mapping_file JSON in GenomicsDB,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3689:0,Expose,Expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3689,1,['Expose'],['Expose']
Security,Exposed Linked-Debrujin-Graph arguments to the help options,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6737:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6737,1,['Expose'],['Exposed']
Security,"Exposed Smith-Waterman parameters in HaplotypeCaller, Mutect2, and FilterAlignmentArtifacts.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885,1,['Expose'],['Exposed']
Security,Exposed ability to blacklist intervals in CNV WDLs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5027:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5027,1,['Expose'],['Exposed']
Security,Exposed bounds for copy-neutral segments in CallCopyRatioSegments.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4263:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4263,1,['Expose'],['Exposed']
Security,Exposed maximum chunk size in CNV panel of normals.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4528:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4528,1,['Expose'],['Exposed']
Security,Exposed maximum copy ratio and point size for CNV plotting tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6482:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6482,1,['Expose'],['Exposed']
Security,Exposed more mem_gb parameters and fixed mem_gb_for_model_segments.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4364:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4364,1,['Expose'],['Exposed']
Security,Exposed number of samples used for estimating denoised copy ratios in gCNV,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7450:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7450,1,['Expose'],['Exposed']
Security,Exposed optional task-level parameters and standardized runtime parameters in CNV WDLs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4288:0,Expose,Exposed,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288,1,['Expose'],['Exposed']
Security,Exposes an argument in the mitochondria WDL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6739:0,Expose,Exposes,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6739,1,['Expose'],['Exposes']
Security,Extract GenotypeGVCFs engine into publicly accessible class/function,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5910:43,access,accessible,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5910,1,['access'],['accessible']
Security,FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkTabComplete'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/vsc-hard-mounts/leuven-data/304/vsc30484/git/gatk/build/tmp/gatkTabComplete/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkTabComplete'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53); at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:233); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:74); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPla,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:1505,Validat,ValidatingTaskExecuter,1505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,1,['Validat'],['ValidatingTaskExecuter']
Security,FILTER_READS_WITH_N_CIGAR_ARGUMENT_FULL_NAME; ValidationExclusion.TYPE.ALLOW_N_CIGAR_READS. See TODO in MalformedReadFilter::checkCigarIsSupported,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/186:46,Validat,ValidationExclusion,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/186,1,['Validat'],['ValidationExclusion']
Security,"FO DenoiseReadCounts - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 20:08:45.223 INFO DenoiseReadCounts - Initializing engine; 20:08:45.223 INFO DenoiseReadCounts - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 20:08:45.300 INFO DenoiseReadCounts - Reading read-counts file (BT1813.counts.hdf5)...; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5F.c line 604 in H5Fopen(): unable to open file; major: File accessibilty; minor: Unable to open file; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fint.c line 1085 in H5F_open(): unable to read superblock; major: File accessibilty; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fsuper.c line 277 in H5F_super_read(): file signature not found; major: File accessibilty; minor: Not an HDF5 file; 20:08:49.800 INFO DenoiseReadCounts - Shutting down engine; [May 18, 2021 8:08:49 PM EDT] org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=1789919232; org.broadinstitute.hdf5.HDF5LibException: exception when opening '/hpf/largeprojects/tabori/projects/bmmrd/CNA_project/gatk_cna/gatk/analysis/lgg/cnvponC2.pon.hdf5' with READ_ONLY mode: Not an HDF5 file; at org.broadinstitute.hdf5.HDF5File.open(HDF5File.java:490); at org.broadinstitute.hdf5.HDF5File.<init>(HDF5File.java:82); at org.broadinstitute.hdf5.HDF5File.<init>(HDF5File.java:66); at org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts.doWork(DenoiseReadCounts.java:188); at org.broadinstitute.hellbender.cmdline.CommandLineProgram",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7258:4296,access,accessibilty,4296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7258,1,['access'],['accessibilty']
Security,"FO IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 00:17:06.850 INFO IndexFeatureFile - Deflater: IntelDeflater; 00:17:06.855 INFO IndexFeatureFile - Inflater: IntelInflater; 00:17:06.856 INFO IndexFeatureFile - GCS max retries/reopens: 20; 00:17:06.858 INFO IndexFeatureFile - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 00:17:06.859 INFO IndexFeatureFile - Initializing engine; 00:17:06.860 INFO IndexFeatureFile - Done initializing engine; 00:17:07.292 INFO FeatureManager - Using codec VCFCodec to read file file://bad.vcf; 00:17:07.310 INFO IndexFeatureFile - Shutting down engine; [January 26, 2018 12:17:07 AM GMT] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=512229376; java.lang.IllegalStateException: the progress meter has not been started yet; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:697); at org.broadinstitute.hellbender.engine.ProgressMeter.stop(ProgressMeter.java:230); at org.broadinstitute.hellbender.utils.codecs.ProgressReportingDelegatingCodec.isDone(ProgressReportingDelegatingCodec.java:104); at htsjdk.tribble.index.IndexFactory$FeatureIterator.readNextFeature(IndexFactory.java:522); at htsjdk.tribble.index.IndexFactory$FeatureIterator.<init>(IndexFactory.java:440); at htsjdk.tribble.index.IndexFactory.createDynamicIndex(IndexFactory.java:326); at org.broadinstitute.hellbender.tools.IndexFeatureFile.createAppropriateIndexInMemory(IndexFeatureFile.java:122); at org.broadinstitute.hellbender.tools.IndexFeatureFile.doWork(IndexFeatureFile.java:71); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4269:2968,validat,validate,2968,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4269,1,['validat'],['validate']
Security,FO PathSeqPipelineSpark - GCS max retries/reopens: 20; 17:39:19.246 INFO PathSeqPipelineSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 17:39:19.246 INFO PathSeqPipelineSpark - Initializing engine; 17:39:19.246 INFO PathSeqPipelineSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 18/04/24 17:39:19 INFO SparkContext: Running Spark version 2.2.0; 18/04/24 17:39:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/04/24 17:39:19 INFO SparkContext: Submitted application: PathSeqPipelineSpark; 18/04/24 17:39:20 INFO SecurityManager: Changing view acls to: username; 18/04/24 17:39:20 INFO SecurityManager: Changing modify acls to: username; 18/04/24 17:39:20 INFO SecurityManager: Changing view acls groups to:; 18/04/24 17:39:20 INFO SecurityManager: Changing modify acls groups to:; 18/04/24 17:39:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(username); groups with view permissions: Set(); users with modify permissions: Set(username); groups with modify permissions: Set(); 18/04/24 17:39:20 INFO Utils: Successfully started service 'sparkDriver' on port 46576.; 18/04/24 17:39:20 INFO SparkEnv: Registering MapOutputTracker; 18/04/24 17:39:20 INFO SparkEnv: Registering BlockManagerMaster; 18/04/24 17:39:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/04/24 17:39:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/04/24 17:39:20 INFO DiskBlockManager: Created local directory at /tmp/username/blockmgr-24b23f43-effa-45a6-8539-b9de234fa346; 18/04/24 17:39:20 INFO MemoryStore: MemoryStore started with capacity 366.3 MB; 18/04/24 17:39:20 INFO SparkEnv: Registering OutputComm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:7276,Secur,SecurityManager,7276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,FO PathSeqPipelineSpark - Inflater: IntelInflater** ; **09:27:44.735 INFO PathSeqPipelineSpark - GCS max retries/reopens: 20** ; **09:27:44.735 INFO PathSeqPipelineSpark - Requester pays: disabled** ; **09:27:44.735 INFO PathSeqPipelineSpark - Initializing engine** ; **09:27:44.736 INFO PathSeqPipelineSpark - Done initializing engine** ; **Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties** ; **20/03/05 09:27:46 INFO SparkContext: Running Spark version 2.4.3** ; **09:27:47.141 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable** ; **20/03/05 09:27:47 INFO SparkContext: Submitted application: PathSeqPipelineSpark** ; **20/03/05 09:27:47 INFO SecurityManager: Changing view acls to: phenomata** ; **20/03/05 09:27:47 INFO SecurityManager: Changing modify acls to: phenomata** ; **20/03/05 09:27:47 INFO SecurityManager: Changing view acls groups to: ** ; **20/03/05 09:27:47 INFO SecurityManager: Changing modify acls groups to: ** ; **20/03/05 09:27:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(phenomata); groups with view permissions: Set(); users with modify permissions: Set(phenomata); groups with modify permissions: Set()** ; **20/03/05 09:27:48 INFO Utils: Successfully started service 'sparkDriver' on port 49119.** ; **20/03/05 09:27:49 INFO SparkEnv: Registering MapOutputTracker** ; **20/03/05 09:27:49 INFO SparkEnv: Registering BlockManagerMaster** ; **20/03/05 09:27:49 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information** ; **20/03/05 09:27:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up** ; **20/03/05 09:27:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-990bc09b-b5cf-4d67-8fec-87bfa4a6fa94** ; **20/03/05 09:27:49 INFO MemoryStore: MemoryStore started with capacity 106.5 GB** ; **20/03/05,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:4482,Secur,SecurityManager,4482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,FeatureManager is an internal engine class that should not be exposed to the tool -- that is why FeatureContext exists as a wrapper. It is to prevent the client from doing bad things like closing important engine resources. See the comments at the top of the FeatureContext class:. ```; * Wrapper around FeatureManager that presents Feature data from a particular interval to a client tool; * without improperly exposing engine internals.; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76763857:62,expose,exposed,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76763857,1,['expose'],['exposed']
Security,FeatureManager provide access to a feature iterator without querying for a particular interval. This must work without the need for an index file present.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/647:23,access,access,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/647,1,['access'],['access']
Security,FeatureManager provide access to a feature iterator.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/647:23,access,access,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/647,1,['access'],['access']
Security,Figure out azure authentication in tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8612:17,authenticat,authentication,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8612,1,['authenticat'],['authentication']
Security,"FilterMutectCalls failed with ; ```; java.lang.IllegalArgumentException: beta must be greater than 0 but got -87566.7500301585; ```; ""this error only comes after the first pass of filtermutectCalls completed."". ValidateVarinats shows no errors when run on VCF.; ""The stats file was created by mutect2 for each shard and then joined with MergeMutectStats. Similar the read orientation model was built with the f1r2 files from all shards."". @davidbenjamin. --------------; Hi there,. I have a simulated dataset of related samples and currently running Mutect2 on it (10 tumor samples WGS with 130x); I managed to run everything through and now FilterMutectCalls crashes after the first pass through the variants with. ```; [October 1, 2019 12:16:16 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 370.68 minutes.; Runtime.totalMemory()=20597702656; java.lang.IllegalArgumentException: beta must be greater than 0 but got -87566.7500301585; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:14); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:42); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.learn(BinomialCluster.java:33); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$learnAndClearAccumulatedData$7(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.utils.IndexRange.forEach(IndexRange.java:116); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); at org.broadinstitute.hellbender.tools.wa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202:211,Validat,ValidateVarinats,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202,1,['Validat'],['ValidateVarinats']
Security,"Finished refactoring the production code as detailed above, just need to add some tests. Results are exactly the same as before in single-sample mode---except for allele-fraction-only mode. This is because I refactored all existing segmenters (there were separate ones for copy-ratio-only, allele-fraction-only, and copy-ratio + allele-fraction) as special cases of a single multisample segmenter; however, the Gaussian kernel in the old allele-fraction-only segmenter was missing a normalization factor that is now present in the new multisample segmenter. Thus, users who previously ran in allele-fraction-only mode will have to retune parameters to achieve the same level of sensitivity. I expect that this will be a very small number of users (if any---note that allele-fraction-only mode isn't even exposed in the WDL), but we can probably mention it in the release notes. Might need to update a figure, etc. as well in the tutorial.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611833344:804,expose,exposed,804,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611833344,1,['expose'],['exposed']
Security,Finished up the import of sequence dictionary validation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/629:46,validat,validation,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/629,1,['validat'],['validation']
Security,"Finished, [2D CNN inference](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/vqsr/CNNScoreVariants.java) and training merged, many new issues spawned.:; - [X] A cool(?) name CNNScoreVariants; - [x] Model training script (in Python, eventually in Java); - [x] Pretrained model for WGS; - [x] Pretrained model for WEx (still being validated and was only trained on NA12878); - [x] Model inference and VCF annotation (in Java); - [x] Solution for applying filters based on CNN score cutoff (tranches.py script); - [x] Currently just re-filtering. Still no joint calling solution...; - [x] Hyperparameters optimized for small 2d model similar performance but .25 params.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-377623706:390,validat,validated,390,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-377623706,1,['validat'],['validated']
Security,First cut at a python notebook to validate inputs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7845:34,validat,validate,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7845,1,['validat'],['validate']
Security,Fix BQSR Dataflow test that was failing due to lack of sequence dictionary validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/668:75,validat,validation,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/668,1,['validat'],['validation']
Security,Fix Input Validation python notebook,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7853:10,Validat,Validation,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7853,1,['Validat'],['Validation']
Security,Fix requester pays access by updating the google-cloud-nio library to the latest release,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700:19,access,access,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700,1,['access'],['access']
Security,Fix requester pays access harder. #7716,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7730:19,access,access,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7730,1,['access'],['access']
Security,Fix tests in ValidateVariantsIntegrationTest,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/659:13,Validat,ValidateVariantsIntegrationTest,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/659,1,['Validat'],['ValidateVariantsIntegrationTest']
Security,Fixed a bug where force calling alleles were lost upon trimming by placing allele injection after trimming,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7679:82,inject,injection,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7679,1,['inject'],['injection']
Security,"Fixes #7068 . - When adding AC, AF, AN, DP header lines, SelectVariants now checks if these lines are in the original header already and if so, overwrites these lines with the respective standard lines; - Without this check, an issue in htsjdk causes duplicate header lines with the same ID if the description differs. This should be fixed there but this fix provides a downstream workaround; - Modified the integration test validation files, which have been invalid VCF files with duplicate header lines; - Removed addition of AC, AF, AN if `--set-filtered-gt-to-nocall` is set, because these lines will be added later anyway",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7069:425,validat,validation,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7069,1,['validat'],['validation']
Security,"Fixes a bug that was exposed in https://gatk.broadinstitute.org/hc/en-us/community/posts/360075631171-BQSR-no-output-table-found. The issue is that bytes are signed in java, and yet we were treating them as unsigned and directly indexing an array with them.....this works as long as you don't have weird characters in your bam/reference...but if you do you get an access error that is non-informative.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7010:21,expose,exposed,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7010,2,"['access', 'expose']","['access', 'exposed']"
Security,"Fixes https://github.com/broadinstitute/gatk/issues/611. Uses ""validationStringency"" as the argument; PicardCommandLineProgram currently uses ""VALIDATION_STRINGENCY""; should we align all of these to use the same name?. I've done the same work for ReadSparkSource and GATKSparkTool but it requires a Hadoop-BAM upgrade so its in a separate PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1439:63,validat,validationStringency,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1439,1,['validat'],['validationStringency']
Security,"Fixes https://github.com/broadinstitute/gatk/issues/6173. I added a single line test that shows the problem, and regenerated the other test files. I didn't write a specific unit test that proves it's solved. Feel free to do so if you think it's necessary.; I validated the output by adding the field name to the output value and checking it by eye against the header lines. This could fairly simply made into a unit test if desired. I'm not sure if there are other large files that need to be regenerated. I had initially said this bug only affects vcf but I think it happens to Maf output as well. I removed a weakly typed method that allowed this bug to occur.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6178:259,validat,validated,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6178,1,['validat'],['validated']
Security,"Fixes issue identified by @kgururaj when investigating GenomicsDB; dropping calls (https://github.com/broadinstitute/gatk/issues/3429#issuecomment-324188028); which is due to incorrect VCF header length descriptions. It looks like this mismatch was reported early by @LeeTL1220; in #3296 when validating VCFs. @davidbenjamin provided a partial fix in #3351, generalizing the output; to include the option of specifying R instead of A using; `includeRefAllele`, fixing MFRL and removing MCL. This fixes the 3 remaining cases, MMQ (which breaks the GenomicsDB; example), MPOS and MBQ. Fixes #3296; Fixes #3429",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3490:293,validat,validating,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3490,1,['validat'],['validating']
Security,Fixing hash collision issue when adding filter value to the variant context,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3305:7,hash,hash,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3305,1,['hash'],['hash']
Security,"For @davidadamsphd when you get tired of validation tickets (if you don't have the bandwidth for this one, feel free to re-assign).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1047#issuecomment-150586732:41,validat,validation,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1047#issuecomment-150586732,1,['validat'],['validation']
Security,For @lbergelson. The general plan for HaplotypeCaller work in Q2 is:. -I will work on validation/testing of the walker version; -Louis will take the Spark version; -Adam will work on further HC performance optimizations (potentially for both walker and spark),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1639#issuecomment-202447009:86,validat,validation,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1639#issuecomment-202447009,1,['validat'],['validation']
Security,"For GVS Feature Extract, ~Cohort Extract~ and Prepare Callset we should add a bq labels to indicate the query and tool being. gvs_tool_name (e.g. feature-extract); gvs_query_name (e.g. read-sample-table). Python Prepare Callset:. <img width=""334"" alt=""Screen Shot 2021-05-19 at 9 31 04 AM"" src=""https://user-images.githubusercontent.com/6863459/118821262-1193eb80-b885-11eb-8456-71225b40192b.png"">. Java GVS Feature Extract:; <img width=""346"" alt=""Screen Shot 2021-05-19 at 9 31 25 AM"" src=""https://user-images.githubusercontent.com/6863459/118821247-0e006480-b885-11eb-9d95-99441c6dbebd.png"">. for Feature Extract; update the wdl to take in a query_labels optional string; update the GATK tool to take in a query_labels param; update the GATK tool to validate labels; update the GATK tool to add constant kv labels: ""gvs_tool_name"", ""extract-features"" and ""gvs_query_name"", ""extract-features"" (is there a way to get more explicit in the queries? isn't it just one query?); test that this works with and without a label param passed in. for Prepare Callset; update the wdl to take in a query_labels optional string; update the python script to take in a query_labels param; update the python scrip to validate passed in labels; update the python script to add constant kv labels for ever single query individually and as a default; test that this works with and without a label param passed in. <img width=""717"" alt=""Screen Shot 2021-05-05 at 2 40 30 PM"" src=""https://user-images.githubusercontent.com/6863459/117192554-dd61fa80-adaf-11eb-8996-be1dc266dcc2.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7233:752,validat,validate,752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7233,2,['validat'],['validate']
Security,"For Travis, the best way might be to put the test input files in a publicly-accessible location and use the API key.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/529#issuecomment-106015822:76,access,accessible,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/529#issuecomment-106015822,1,['access'],['accessible']
Security,"For `byte[]` attributes, the `GATKSAMRecordToGATKReadAdapter.getAttributesAsString()` uses the default `Object.toString()` (className@hashCode). This is something unexpected for my point of view, because the following code may fail:. ```java; public void testGATKReadGetAttributeAsString(final GATKRead read) {; read.setAttribute(""BC"", new byte[]{'A', 'C', 'T', 'G'});; // this will fail with the current implementation; Assert.assertEquals(read.getAttributesAsString(""BC"").getBytes(Charset.forName(""UTF-8"")),; read.getAttributeAsByteArray(""BC""));; }; ```. This PR fixes the issue by identifying `byte[]` attributes and converting them to Strings by using the default GATKRead charset (UTF-8).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3223:134,hash,hashCode,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3223,1,['hash'],['hashCode']
Security,"For a PrintReads command that requires accessing the index, e.g. when specifying `-L` intervals, running locally works but running on `gs://` CRAM fails even if index is explicitly specified. ## Local run (server); A command that accesses a local CRAM runs fine. ```; /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads \; -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam \; -L chr17; ...; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam -L chr17; 14:52:10.763 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 5, 2017 2:52:10 PM EDT] PrintReads --output /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam --intervals chr17 --input /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --interval_merging_rule ALL --readValidat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3669:39,access,accessing,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669,2,['access'],"['accesses', 'accessing']"
Security,"For example, contig-ploidy disk space is exposed only in case mode. Variable names are somewhat inconsistent, too (`disk_space_*` vs. `disk_space_gb_*`).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6995:41,expose,exposed,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6995,1,['expose'],['exposed']
Security,"For germline CNV:; It would be interesting to know which details (e.g. read group tags such as platform, model or also average insert size) are important for choosing additional Fastq/BAM files for creating a Panel of Normals (PON), when one does not have access to a batch. Which results from the GATK quality metrics would be most useful for choosing such datasets?. I'm thinking especially about e.g. choosing other Fastq/BAM files from the Personal Genomes Project. It would also be interesting to know if something like a ""Panel of Unnormals"" could be created, e.g. by choosing datasets from similar patients according to participant survey results from the Personal Genomes Project (https://my.pgp-hms.org/google_surveys). If a Panel of Normals can be used to reject spurious read counts, then a Panel of Unnormals could help to not reject rare read counts. (Hypermobile) Ehlers-Danlos-Syndrome as an unsolved and probably multi-gene case might be a perfect example, because it is already known that many genes exist with similar effects on connective tissue, i.e. hypermobility.; There are 115 hits grepping the above surveys for Ehlers-Danlos and at least a few of these might offer full fastq/bam files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2881#issuecomment-358092692:256,access,access,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2881#issuecomment-358092692,1,['access'],['access']
Security,"For ingesting into the aou security boundary, use the optional service account json argument.; This also needs to localize some files manually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7164:27,secur,security,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7164,1,['secur'],['security']
Security,"For now, the tool will just supply the count and not make any decision as to whether the variant validated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5059#issuecomment-408433167:97,validat,validated,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5059#issuecomment-408433167,1,['validat'],['validated']
Security,"For repeated operators (whether xIyI or xMyM), I think GATK3 has/had a function to simplify cigars to ""sanitize"" that situation. In terms of desired behavior, we don't want to filter out the reads, we want to transform them to be processable without difficulty. I think xIyD should be considered valid.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/428#issuecomment-95056320:103,sanitiz,sanitize,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/428#issuecomment-95056320,1,['sanitiz'],['sanitize']
Security,"For testing #3069, creating a Java test that shows that the GKL messages are controlled by the [log4j logLevel](https://www.tutorialspoint.com/log4j/log4j_logging_levels.htm).; Also, this branch should be rebased. A fix for the test failures, due to an issue with 2 factor authentication for [GIt Large File Storage](https://git-lfs.github.com/) of test data was recently merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141:273,authenticat,authentication,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141,1,['authenticat'],['authentication']
Security,"For the record, without this validation step in place this test fails with the following out of memory error (which we don't fully understand yet, but it's basically GroupByKey going crazy). @jean-philippe-martin do you think this deserves a separate ticket to investigate further? . java.lang.OutOfMemoryError: Java heap space; at java.util.Arrays.copyOf(Arrays.java:3236); at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:113); at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93); at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:140); at com.google.cloud.dataflow.sdk.util.ExposedByteArrayOutputStream.write(ExposedByteArrayOutputStream.java:82); at java.io.DataOutputStream.write(DataOutputStream.java:107); at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877); at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786); at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189); at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); at com.google.cloud.dataflow.sdk.coders.SerializableCoder.encode(SerializableCoder.java:113); at org.broadinstitute.hellbender.engine.dataflow.coders.GATKReadCoder.encode(GATKReadCoder.java:38); at org.broadinstitute.hellbender.engine.dataflow.coders.GATKReadCoder.encode(GATKReadCoder.java:27); at com.google.cloud.dataflow.sdk.transforms.join.UnionCoder.encode(UnionCoder.java:82); at com.google.cloud.dataflow.sdk.transforms.join.UnionCoder.encode(UnionCoder.java:37); at com.google.cloud.dataflow.sdk.util.WindowedValue$FullWindowedValueCoder.encode(WindowedValue.java:528); at com.google.cloud.dataflow.sdk.util.WindowedValue$FullWindowedValueCoder.encode(WindowedValue.java:472); at com.google.cloud.dataflow.sdk.coders.IterableLikeCoder.encode(IterableLikeCoder.java:96); at com.google.cloud.dataflow.sdk.coders.IterableLikeCoder.encode(IterableLikeCoder.java:42); at com.google.cloud.da",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/668#issuecomment-122949556:29,validat,validation,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/668#issuecomment-122949556,3,"['Expose', 'validat']","['ExposedByteArrayOutputStream', 'validation']"
Security,"For what it's worth, this works but I should improve the error message. If you don't have the right permissions, currently you get an error that's something like this:. ```; htsjdk.samtools.util.RuntimeIOException: Error opening file: file:///home/jpmartin//gatk/gs:/bobs-bucket-you-cant-write-to/test-output/printtogcs.bam; ```. This is both; - confusing: it makes it look like the path is wrong even though the code actually tried the correct path; - improvable: it'd be nice if we gave the reason there was an error (403 Forbidden: user jpmartin doesn't have write access)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2422#issuecomment-342255531:568,access,access,568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2422#issuecomment-342255531,1,['access'],['access']
Security,"From @tomwhite . ""Isilon exposes a Hadoop filesystem interface which makes it possible; to use it as a source or sink for Spark. (There are some notes here:; http://www.cloudera.com/documentation/enterprise/latest/topics/cm_mc_isilon_service.html). Note however that you lose the benefits of locality, so it won't be as; fast as HDFS. Definitely worth a try. Also, for a pipeline with; multiple steps, you could use HDFS to store intermediate data, only; reading from Isilon for the source files and writing to Isilon with; the final result.""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1508:25,expose,exposes,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1508,1,['expose'],['exposes']
Security,"From our normal-normal validation. Some irrelevant annotations removed. ```; 3	124464215	.	ATTT	A,ATTTT	.	PASS	N_ART_LOD=-1.573e+00,7.21;RPA=15,12,16;RU=T;STR;TLOD=5.65,4.81	GT:AD:AF 0/1/2:91,12,6:0.183,0.174 0/0:100,13,8:0.166,0.179; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4689:23,validat,validation,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4689,1,['validat'],['validation']
Security,Full scientific validation via end to end comparison of filtered results between WARP and BQ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7179:16,validat,validation,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7179,1,['validat'],['validation']
Security,Fully validate HaplotypeCaller walker for production (with help of palantir and/or short variants team),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1640:6,validat,validate,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1640,1,['validat'],['validate']
Security,Funcotator - Added map-style accessor for fields.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4176:29,access,accessor,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4176,1,['access'],['accessor']
Security,Funcotator - Need a validation tool for data sources,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4380:20,validat,validation,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380,1,['validat'],['validation']
Security,Funcotator - Refactor Funcotation class to use a HashMap for each field,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3919:49,Hash,HashMap,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3919,1,['Hash'],['HashMap']
Security,Funcotator should validate datasource version at startup.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5660:18,validat,validate,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5660,1,['validat'],['validate']
Security,"G: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Read: WrappedArray([]); 02:25 DEBUG: [kryo] Write: scala.Tuple3[]; ...; 02:42 DEBUG: [kryo] Write object reference 1941: HLA-A*24:152; 02:42 DEBUG: [kryo] Write object reference 1945: chrUn_JTFH01001224v1_decoy; 02:42 DEBUG: [kryo] Write object reference 1949: HLA-B*14:01:01; 02:42 DEBUG: [kryo] Write object reference 1953: chr5_GL949742v1_alt; ...; 02:42 DEBUG: [kryo] Write object reference 1942: SAMSequenceRecord(name=HLA-A*24:152,length=3176,dict_index=2919,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1946: SAMSequenceRecord(name=chrUn_JTFH01001224v1_decoy,length=1051,dict_index=2066,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1950: SAMSequenceRecord(name=HLA-B*14:01:01,length=3312,dict_index=2999,assembly=null,alternate_names=[]); 02:42 DEBUG: [kryo] Write object reference 1954: SAMSequenceRecord(name=chr5_GL949742v1_alt,length=226852,dict_index=241,assembly=null,alternate_names=[]); ...; 02:42 DEBUG: [kryo] Write: Array[java.lang.Object]; 02:42 DEBUG: [kryo] Write: Object[]; 02:42 DEBUG: [kryo] Write: byte[]; 02:42 DEBUG: [kryo] Write: WrappedArray([]); ...; 03:20 DEBUG: [kryo] Read: CompressedMapStatus; 03:20 DEBUG: [kryo] Write: Array[java.lang.Object]; 03:20 DEBUG: [kryo] Write: Object[]; 03:20 DEBUG: [kryo] Write: byte[]; 03:20 DEBUG: [kryo] Read: Array[java.lang.Object]; 03:20 DEBUG: [kryo] Read: Object[]; 03:21 DEBUG: [kryo] Write: TaskCommitMessage; 03:21 DEBUG: [kryo] Read: TaskCommitMessage; ```. #### Steps to reproduce; **Command:**; ```; gatk --java-options ""-Djava.io.tmpdir=/scratch"" MarkDuplicatesSpark --input C19CUACXX.1.1-1.sorted.bam --output /scratch/C19CUACXX.1.1.sorted.Spark.Strigency-strict.bam --conf 'spark.local.dir=/scratch' --tmp-dir /scratch --read-validation-stringency STRICT; ```. #### Expected behavior; Finish MarkDuplicatesSpark successfully and output a valid bam file. #### Actual behavior; The bam file is empty.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8134:2892,validat,validation-stringency,2892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8134,1,['validat'],['validation-stringency']
Security,"GATK consumes hdf5, but doesn't expose an API for it. https://github.com/broadinstitute/hdf5-java-bindings/issues/15 is a more appropriate place for that question.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5953#issuecomment-494358138:32,expose,expose,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5953#issuecomment-494358138,1,['expose'],['expose']
Security,GATK exposes Picard tools thru its command line interface. The usage syntax is different between these two tool kits and so picard code examples in javadocs don't make that much sense when displayed in GATK's own docs. For now code examples embeded in the Picard repo should stick to picard syntax as a matter of principle. So the solution is to transform those snippets on-the-fly when we generate the gatk-docs. . The is a good opportunity to do so in ```GATKHelpDocWorkUnitHandler``` by overloading the ```getDescription(DocWorkUnit)``` so that any occurrence of a picard.jar example is translated into gatk's version:; ```. <pre>java -jar picard.jar toolName \; ARG1=VAL1 \; ARG2=VAL2 ; </pre>; ```. to this:. ```; <pre>gatk toolName \; -ARG1 VAL1 \; --ARG2 VAL2; </pre>; ```. The difficult part is to find-out the mapping of picard argument names and gatk's exposed picard argument names and whether these need single or double dash. To this end we can use some reflection.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3932:5,expose,exposes,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3932,2,['expose'],"['exposed', 'exposes']"
Security,GATK4 ValidateVariants Doc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2759:6,Validat,ValidateVariants,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2759,1,['Validat'],['ValidateVariants']
Security,GATKSparkTool should use stricter validation for CRAMs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1179:34,validat,validation,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179,1,['validat'],['validation']
Security,"GATKVariantContextUtils.createVCFWriter attempts to determine the output vcf type based on the file extension provided by the user, and defaults to vcf if the extension isn't a recognized type. There is code in VariantContextWriterBuilder (determineOutputTypeFromFile) in htsjdk that attempts to do the same mapping, but isn't public. We should expose that in htsjdk and use it in GATKVariantConextUtils so we can get rid of the redundant code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2128:345,expose,expose,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2128,1,['expose'],['expose']
Security,"GCS NIO provider is public already, accessible at:; https://github.com/GoogleCloudPlatform/gcloud-java/tree/gcs-nio. I'm working on getting the [integration tests](https://github.com/jean-philippe-martin/gcloud-java/blob/integration-tests/gcloud-java-contrib/gcloud-java-nio/src/test/java/com/google/gcloud/storage/contrib/nio/ITGcsNio.java) and examples ready, and later on getting the NIO provider onto the main branch so it's part of the default SDK download. The integration tests pass, showing it's now possible to read/write GCS files via the NIO interface. So technically you could start using it now, though it's probably easier to wait until those tests and the examples have passed the pull request gauntlet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1547#issuecomment-191974649:36,access,accessible,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1547#issuecomment-191974649,1,['access'],['accessible']
Security,"GRCh37, and this will be fine in the vast majority of cases.  There MAY be some errors (e.g. in the Y chromosome, but possibly in other places as well) due to changes between the two references. ; ; 12:37:55.679 INFO  ProgressMeter - Starting traversal ; ; 12:37:55.679 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Features Processed  Features/Minute ; ; 12:37:56.198 WARN  FuncotatorUtils - Reference allele is different than the reference coding sequence (strand: -, alt = G, ref G != T reference coding seq) @\[chr1:13839497\]!  Substituting given allele for sequence code (TTC->GTC) ; ; 12:37:56.213 INFO  FuncotateSegments - Shutting down engine ; ; \[February 9, 2022 12:37:56 PM EST\] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.24 minutes. ; ; Runtime.totalMemory()=3139436544 ; ; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:29534 end:14501 ; ;     at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2938) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7676:2393,validat,validateArg,2393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7676,1,['validat'],['validateArg']
Security,GVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `49.123% <0%> (-0.442%)` | `45 <0> (+1)` | |; | [...ute/hellbender/utils/variant/GATKVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2655?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWQ0ZDb25zdGFudHMuamF2YQ==) | `50% <0%> (-16.667%)` | `3 <2> (+2)` | |; | [...itute/hellbender/tools/walkers/vqsr/ApplyVQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/2655?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQXBwbHlWUVNSLmphdmE=) | `75% <100%> (ø)` | `55 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2655?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `93.75% <0%> (-1.563%)` | `21% <0%> (-1%)` | |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2655?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `81.081% <0%> (+0.484%)` | `24% <0%> (+6%)` | :arrow_up: |; | [...org/broadinstitute/hellbender/utils/MathUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2655?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYXRoVXRpbHMuamF2YQ==) | `81.009% <0%> (+1.711%)` | `170% <0%> (+30%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2655?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `74.026% <0%> (+1.948%)` | `35% <0%> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2655?src=pr&el=tree#diff-c3JjL21,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2655#issuecomment-299088185:2403,Validat,ValidateVariants,2403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2655#issuecomment-299088185,1,['Validat'],['ValidateVariants']
Security,Gatk validate variants doesn't report an error on non-spec-compliant headers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6762:5,validat,validate,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6762,1,['validat'],['validate']
Security,Gave SortSam lenient validation in M2 wdl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4844:21,validat,validation,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4844,1,['validat'],['validation']
Security,Generate Avro Files run: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/577e77f2-4174-46c0-9d8a-9fdbbd2a27ed. Generate VDS run: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/27299041-7779-49d7-b7d3-6c0349f5ffc3. Generate VAT run: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/ad1b2687-7df0-4e92-b4e2-b61fcb77cd19. Validate VAT run: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/dae4874f-a619-40d4-84b4-066295b76cb2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8702:442,Validat,Validate,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8702,1,['Validat'],['Validate']
Security,"GenomicsDBImport currently doesn't support multi-sample input vcfs. We've had a number of usesr request the ability to import precombined multi-sample vcfs. . People may have old call-sets which they would like to combine with new data, and do not have access to the original single sample gvcfs needed to recombine them in GenomicsDBImport. . It would be good if we could import these directly into GenomicsDB.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6530:253,access,access,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6530,1,['access'],['access']
Security,"Glad to hear you were able to make progress. We're open to suggestions around improving the tooling for this. For instance, you mentioned wanting to redo samples -- we already have support in GenomicsDB for querying by sample. We should be able to expose that at the GATK level. As long as you're okay with renaming the sample when you re-generate the gVCFs that should work. . Technically we could expose support to modify existing samples, but that get's a bit hairy because of the way data is retrieved. . I'm not sure why the queries for intact chromosomes take so much longer. Since you were able to replicate with a single sample, ~7m interval is there any chance you can share just that bit (workspace, or even better that portion of the gvcf) and we can take a deeper look?. To your question about whether GenomicsDBImport includes variants that span the specified import interval: it will definitely include variants that start in those intervals, but it won't always store variants that start before the import interval. For deletions, we have some special handling for variants that start before the interval - they should show up represented by the star allele, but I don't think this is the case for insertions starting before the import interval.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221066848:248,expose,expose,248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221066848,2,['expose'],['expose']
Security,"Go the following:. ```; Current git hash does not match GATK git hash. Run anyway?yes; error: malformed object name 1; usage: git branch [<options>] [-r | -a] [--merged | --no-merged]; or: git branch [<options>] [-l] [-f] <branch-name> [<start-point>]; or: git branch [<options>] [-r] (-d | -D) <branch-name>...; or: git branch [<options>] (-m | -M) [<old-branch>] <new-branch>; or: git branch [<options>] [-r | -a] [--points-at]; ...; ```; Not sure the first error message about the ""hashes"" means perhaps that is the cause though. Assigned to @TedBrookings because I think this is you beast.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3593:36,hash,hash,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593,3,['hash'],"['hash', 'hashes']"
Security,"Goal was to get WGS coverage collection at 100bp at ~15 cents per sample. Since this is I/O bound (takes ~2 hours to stream or localize a BAM, or about the same to decompress a CRAM), cost reduction can be most easily achieved by reducing the memory requirements and moving down to a cheaper VM. . Memory requirements at 100bp are dominated by manipulations of the list of ~30M intervals. There were a few easy fixes to reduce requirements that did not require changing the collection method (which can be easily modified for future investigations, see #4551):. -removed WellformedReadFilter. See #5233. EDIT: We decided after PR review to retain this filter by default and disable it at the WDL level when Best Practices is released. Leaving the issue open.; -initialized HashMultiSet capacity; -removed unnecessary call to OverlapDetector.getAll; -avoided a redundant defensive copy in SimpleCountCollection; -used per-contig OverlapDetectors, rather than a global one. This brought the cost down to ~9 cents per sample using n1-standard-2's with 7.5GB of memory when collecting on BAMs with NIO. Note that I didn't optimize disk size, which accounts for ~50% of the total cost and is unused when running with NIO, so we are closer to ~5 cents per sample. It is possible that using CRAMs with or without NIO and with or without SSDs might be cheaper. Note that OverlapDetectors may be overkill for our case, since bins are guaranteed to be sorted and non-overlapping and queries are also sorted. We could probably roll something that is O(1) in memory. However, since we are I/O bound, as long as we are satisfied with the current cost, I am willing to sacrifice memory for implementation and maintenance costs, as well as the option to change strategies easily. In any case, @lbergelson found some easy wins in OverlapDetector that may further bring the memory usage down, and will issue a fix in htsjdk soon.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5715:773,Hash,HashMultiSet,773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5715,1,['Hash'],['HashMultiSet']
Security,"Good catch @EdwardDixon. From @cmnbroad 's Oct 12 post:; >We may need to provide a fallback environment for those (I'll try to get resolution on that). If it turns out we do, I'm actually not suggesting the fallback be automatic (3 in your list), just that we have a **graceful failure mode and an instructive error message.**. We have this now, right? Just want to be sure. If there's more work to be done, let's hash it out on another PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-438735712:414,hash,hash,414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-438735712,1,['hash'],['hash']
Security,"Good catch. I think hc7b2577_8 might be specific for linux64. We can try removing that hash, but I don't have a mac, so I can't test this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355645250:87,hash,hash,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355645250,1,['hash'],['hash']
Security,"Google is deprecating and removing their implementation of the old style GA4GH read and reference API's. . > ; > Reads API functionality is now replaced by the htsget protocol ; > ; > This year, the GA4GH team introduced the htsget protocol to allow users to download read data for subsections of the genome in which they are interested. This is a richer and more flexible approach to working with reads data. It allows you to keep your genomics data in a common BAM file format on Google Cloud Storage and work with it efficiently from your computation pipelines, using standard bioinformatics tools. We have already launched our own open source implementation of this protocol, which you can use to access your reads data. Many popular tools such as samtools and htslib have been updated by the community to support htsget. Documentation is provided here. The Reads API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month by those receiving this notice, whichever comes first. ; > ; > Variants API is now replaced by htsget and Variant Transforms ; > ; > The GA4GH team also plans to extend the htsget protocol to cover variant data, and we will extend our implementation of htsget to cover this use case. ; > ; > After analyzing usage of the Variants API, we found that users primarily used it to import variant data and then export it to BigQuery. To save time and effort, we created Variant Transforms, an open source tool for directly importing VCF data into BigQuery. Variant Transforms and its documentation are published here. Variant Transforms is more scalable than the legacy Variants API, and it has a robust roadmap with a dedicated team. We also welcome collaborators on this project as it advances. ; > ; > The Variants API is now deprecated, and will be decommissioned after one year, or after there has been no API activity for one month, whichever comes first. ; > ; > We are excited to move in step with the global ge",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4166:701,access,access,701,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166,1,['access'],['access']
Security,Got the go-ahead and the access has been changed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2726#issuecomment-302518914:25,access,access,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2726#issuecomment-302518914,1,['access'],['access']
Security,"Great addition to the list. [`htsjdk.samtools.metrics.MetricsFile`](https://github.com/samtools/htsjdk/tree/master/src/java/htsjdk/samtools/metrics) are a nice way of generating summary outputs, and later generating summary reports. For those without access to the above repo, among other features, `ComparePipelineTestOutput` generates HTML reports on directories of metrics files. Still, I believe one of the biggest complaints by comp-bios was that after improving an algorithm (ex: PairHMM), one is penalized by having to update lines of expected output spread across dozens of files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/69#issuecomment-67238583:251,access,access,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/69#issuecomment-67238583,1,['access'],['access']
Security,"Great! And yes, LL will be optimized separately for SNPs and INDELs. How about this for a first workflow to target?. 1) Run ExtractVariantAnnotations on a training set of chromosomes. You can keep training/truth labels as in Best Practices, for now.; 2) Run TrainVariantAnnotationsModel on that. We'll use the truth scores generated here for any sensitivity conversions---i.e., we'll be calibrating scores only to the truth sites that are contained in the training set of chromosomes.; 3) Use the trained model to run a single shard of ScoreVariantAnnotations on a validation set of chromosomes.; 4) Run some variation of the above script on the resulting outputs to determine SNP and INDEL score thresholds for optimizing the corresponding LL scores. We can also add some code to the script to use the truth scores from step 2 to convert these score thresholds into truth-sensitivity thresholds.; 5) Provide these truth-sensitivity thresholds to ScoreVariantAnnotations and use them to hard filter. Evaluate on a test set of chromosomes. If all looks good, we can later move steps 3-4 into the train tool and automate the passing of sensitivities in 5 via outputs in the model directory. This will let us keep the basic interface of ScoreVariantAnnotations the same, but we'll have to add a few basic parameters to TrainVariantAnnotationsModel to control the train/validation split. So I think all this branch is missing is step 5---we'll simply need to add command-line parameters for the SNP/INDEL sensitivity thresholds and then do the hard filtering in the VCF writing method highlighted above. Do you think you can handle implementing that in this branch, and then the rest at the WDL level? I can help with the python script for the LL stuff (or anything else), if needed. Not sure if you got a chance to check out what your collaborators are doing in the methods you're looking to compare against, but it would be good to understand if this basic scheme for train/validation/test splitting can",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068345084:565,validat,validation,565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068345084,1,['validat'],['validation']
Security,"Great! Now that we know it works, it can wait to be reviewed. It's a small change but this feature had stayed untested for too long. In fact an even better way of doing this, if we have the energy & desire, would be to set up a separate bucket with a separate project. I *think* if we do it right we may then be able to have a fully automated test of the explicit credentials, as the default credentials would have access to the ""normal"" test data but we'd make sure the default user is not authorized to access the separate bucket (so we have to use the explicit credentials).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2879#issuecomment-306295687:415,access,access,415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2879#issuecomment-306295687,3,"['access', 'authoriz']","['access', 'authorized']"
Security,"Great, thanks!. On Mon, Dec 3, 2018 at 10:15 AM David Benjamin <notifications@github.com>; wrote:. > @meganshand <https://github.com/meganshand> I ran the ""Full Pipeline""; > workflows in a clone of your FC workspace:; > https://portal.firecloud.org/#workspaces/broad-firecloud-dsde/copy-of-megans-m2-mito-validations.; > I did not run any of the things that generate graphs because they were; > harder for me to understand. To compare the new results to your previous; > ones, I took all variants that were either PASS or had only the; > contamination filter applied, extracted just the locus and alleles columns,; > then manually inspected the diff. For the 5% and 50% spike-ins there were; > usually no differences at all, while for the 1% spike-in the difference was; > usually 2-5 variants that straddled the LOD threshold.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5473#issuecomment-443745103>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMwCcuQyzMweZjxWrXBODTCBaOSIks5u1T_-gaJpZM4Y9STI>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5473#issuecomment-443751026:305,validat,validations,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5473#issuecomment-443751026,1,['validat'],['validations']
Security,"Grr, looks like this slipped by us in #4288. See my comments there---why does this validate in womtool? We got bit by a similar issue in #4281.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362071370:83,validat,validate,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362071370,1,['validat'],['validate']
Security,"HG00731 fails with a similar error:. ```; 18/04/11 16:08:40 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 98.0 in stage 42.0 (TID 49620, cwhelan-hg00731-cram-samtools-bam-feature-w-4.c.broad-dsde-methods.internal, executor 43): java.lang.IllegalArgumentException: Invalid interval. Contig:chr6 start:34662153 end:34662143; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.ContigAlignmentsModifier.computeNewRefSpanAndCigar(ContigAlignmentsModifier.java:163); at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.ContigAlignmentsModifier.clipAlignmentInterval(ContigAlignmentsModifier.java:42); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.removeOverlap(CpxVariantInterpreter.java:179); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.deOverlapAlignments(CpxVariantInterpreter.java:122); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.furtherPreprocess(CpxVariantInterpreter.java:79); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.lambda$inferCpxVariant$bdd686a3$1(CpxVariantInterpreter.java:51); at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4648#issuecomment-380510575:380,validat,validateArg,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4648#issuecomment-380510575,2,['validat'],"['validateArg', 'validatePositions']"
Security,HI @droazen I see you were on this issue and generated a PR but could not merge because test case failures. I wanted to check if you were able to make progress on this. Within my organization infosec independently reviewed and have denied use of GATK :( . Let me know if you have an ETA for security fix update. Thank you!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1678986791:291,secur,security,291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1678986791,1,['secur'],['security']
Security,"HI @jonn-smith ; Creating this issue ticket as discussed. ; Issue: The header of that particular file has a hash mark # before it, because of that the parser wont work properly. A bug seems to have been introduced in the tribble indexing code for TSV files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223#issuecomment-545117559:108,hash,hash,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223#issuecomment-545117559,1,['hash'],['hash']
Security,"HI, ; the following commands were included at my bash script .; after I ran them, I got a log file with ""Tool returned:; 6785087"", I am not sure why the return code is 6785087 , not 0 ???. Anything wrong with my commands ?; Thanks ! . gatk-4.1.2.0/gatk BaseRecalibrator -R $fasta -I $tumor_bam --known-sites a.vcf --known-sites b.vcf ; --intervals t.bed --interval-padding 50 --read-validation-stringency SILENT -O recal_data.table . gatk-4.1.2.0/gatk ApplyBQSR -R $fasta -I $tumor_bam --bqsr-recal-file recal_data.table ; --intervals t.bed --interval-padding 50 --read-validation-stringency SILENT -O recal_data.bam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6056:383,validat,validation-stringency,383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6056,2,['validat'],['validation-stringency']
Security,Hand HaplotypeCaller snapshot with first-pass validation issues addressed off to palantir for second-pass validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3233:46,validat,validation,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3233,2,['validat'],['validation']
Security,HashedListTargetCollection has unnatural contig order,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1754:0,Hash,HashedListTargetCollection,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1754,1,['Hash'],['HashedListTargetCollection']
Security,"Hello @dagsbio and thank you for your question. It sounds like there was an issue with your bam file, possibly with the header version line. We support up through bam v1.6. You can also try running ValidateSamFile on the bam. I would recommend however that you direct your questions/troubleshooting requests to the new gatk support forum here: https://gatk.broadinstitute.org/hc/en-us/community/topics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6350#issuecomment-571636329:198,Validat,ValidateSamFile,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6350#issuecomment-571636329,1,['Validat'],['ValidateSamFile']
Security,"Hello @jackycsie. I would request that you direct this sort of question to the GATK Support forums https://gatkforums.broadinstitute.org/gatk/categories/gatk-support-forum. Regarding the BAM size there are a number of reasons the file could have shrunk, the most likely answer is that the GATK applied a different level of compression to the output bam than was applied to your inputs. I would recommend you run CountReads and calling ValidateSamFile on the outputs for your run and if there appears to be an issue with the output you post a question about it on the Support Forums.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6236#issuecomment-547452764:435,Validat,ValidateSamFile,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6236#issuecomment-547452764,1,['Validat'],['ValidateSamFile']
Security,"Hello @liuyihhha, I'm sorry to hear that. We should probably include a more prominent warning that something like this could happen if you disable all of the readfilters for the tool some of them are there just to make sure everything is formatted correctly and doesn't crash. If you `--disable-tool-default-read-filters` it disables all of them including the basic ""can the GATK even parse this read"" style readfilters. I would recommend adding back in some of the more basic read filters and seeing if you still get this error. Specifically I would recommend trying with the following arguments:; ```; --disable-tool-default-read-filters true; -RF WellformedReadFilter; -RF GoodCigarReadFilter; ```; As for what about SplitNCigarReads could be causing the reads to be invalid I would like to have some idea of what the issue is. You could try running `ValidateSamFile` on your input to Mutect2 and hopefully that will spit back some readnames that are invalid which should make it easier to diagnose. Given the operations in SplitNCigarReads and the nature of your stacktrace it wouldn't surprise me if there is something wrong/messy about the cigars output by that tool in some cases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8224#issuecomment-1450266657:854,Validat,ValidateSamFile,854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8224#issuecomment-1450266657,1,['Validat'],['ValidateSamFile']
Security,"Hello, Could you tell me the exact source websites of funcotator_dataSources.v1.7.20200521g? I did not find it in your Google Cloud (genomics-public-data).; Besides, I used this code to download`./gatk-4.1.9.0/gatk FuncotatorDataSourceDownloader --germline --validate-integrity --extract-after-download; `, but the error appeared as following:`Nov 18, 2023 1:15:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:15:05.202 INFO FuncotatorDataSourceDownloader - ------------------------------------------------------------; 13:15:05.203 INFO FuncotatorDataSourceDownloader - The Genome Analysis Toolkit (GATK) v4.1.9.0; 13:15:05.203 INFO FuncotatorDataSourceDownloader - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:15:05.203 INFO FuncotatorDataSourceDownloader - Executing as yaoxq@mu01 on Linux v3.10.0-693.el7.x86_64 amd64; 13:15:05.203 INFO FuncotatorDataSourceDownloader - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_151-b12; 13:15:05.203 INFO FuncotatorDataSourceDownloader - Start Date/Time: November 18, 2023 1:15:04 PM CST; 13:15:05.203 INFO FuncotatorDataSourceDownloader - ------------------------------------------------------------; 13:15:05.203 INFO FuncotatorDataSourceDownloader - ------------------------------------------------------------; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Version: 2.23.0; 13:15:05.204 INFO FuncotatorDataSourceDownloader - Picard Version: 2.23.3; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:15:05.204 INFO FuncotatorDataSourceDownloader - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:15:05.204 I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:259,validat,validate-integrity,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['validat'],['validate-integrity']
Security,"Hello, more information on the parameters and runtime can be found here: #7492 . the stacktrace is now:; ```; ...; 22:14:59.985 INFO ProgressMeter - chrUn_JTFH01001653v1_decoy:301 116.6 2161460 18530.7; 22:15:11.142 INFO ProgressMeter - chrUn_JTFH01001673v1_decoy:301 116.8 2161540 18501.9; Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15500m -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://cclebams/hg38_wes/CDS-02waxZ.hg38.bam -tumor TUHR14TKB --germline-resource gs://depmapomicsdata/gnomad.genomes.r3.0.sites.vcf.bgz -pon gs://depmapomicsdata/1000g_pon.hg38.vcf.gz -L gs://fc-secure-d2a2d895-a7af-4117-bdc7-652d7d268324/cec2a1a6-ffc3-4f1b-ba94-27ae918c56e9/Mutect2/b389d86b-8b0b-4d77-8224-a5a3e3a0b4e5/call-SplitIntervals/cacheCopy/glob-0fc990c5ca95eebc97c4c204e3e303e1/0004-scattered.interval_list -O output.vcf.gz --f1r2-tar-gz f1r2.tar.gz --gcs-project-for-requester-pays broad-firecloud-ccle; ln: failed to access '/cromwell_root/*normal-pileups.table': No such file or directory; ln: failed to access '/cromwell_root/*tumor-pileups.table': No such file or directory; 2021/10/05 22:15:24 Starting delocalization.; ...; ```. I run mutect2 in tumor only mode. ; Interestingly, this error always only happen at the last shard only (every other shard runs to completion). Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7494:858,secur,secure-,858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7494,3,"['access', 'secur']","['access', 'secure-']"
Security,"Hello,. I think we're pretty close on porting this. However, i wanted to ask again if I could get access to the test data used in GATK3 VariantEvalWalkerUnitTest and VariantEvalIntegrationTest. We dont need to port those files to GATK4 unless some of them already exist; however, having these files would help confirm the ported tool is behaving exactly as GATK3. Second, I am hoping to confirm a behavior for FeaureContext: many GATK3 stratifiers follow roughly this pattern (VariantEval / knownCNVsFile being an example). The pattern is: 1) some VCF/BED file provided as an argument, 2) in initialize(), the walker reads this file in memory into a List<GenomeLoc> or IntervalTree<GenomeLoc>. This is so each locus can quickly find overlapping intervals. In GATK4, there is no longer a point in loading the whole file into memory, right? If I define an argument as FeatureInput<Feature>, it will automatically be initialized. FeatureContext.getValues() seems to give me overlapping intervals (including partial overlaps). Therefore there is no reason to try to replicate that GATK3 pattern of reading intervals into memory. Can someone confirm this is correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-343563884:98,access,access,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-343563884,1,['access'],['access']
Security,"Hello,. There was at least one prior conversation about migrating or not migrating GATK3 CombineVariants to GATK4. My understanding is that there was a decision in GATK not to migrate CombineVariants, and instead push people to use Picard MergeVcfs. As you know, Picard MergeVcfs is somewhat similar; however, it doesnt merge genotypes. That is a pretty big difference in function. . CombineVariants is one of the few GATK3 tools my lab is still using. I'd like to move us off GATK3 in the coming months. Given GATK has already decided not to migrate it, I would first like to propose that we could port and take it over in my lab's DISCVRseq project (https://github.com/bimberlab/discvrseq). I'm happy to give attribution to GATK, etc. I would likely rename it MergeVcfsAndGenotypes (this is more intuitive to me), but I would otherwise not change functionality much. I'd prefer to do this instead of porting to GATK4 because porting to GATK is going to throw up a lot more obstacles and probably require that I modernize/update a good amount of that tool's code. I appreciate why this is required, but it takes a lot more work from us. If you did not like this, I'm open to considering porting to GATK4. In my initial review, it looked like CombineVariants was fairly self-contained and that most of the accessory code (merging genotypes is the most complex thing) was already migrated to GATK4. Some of you may have already done a more thorough review of it. . What do you think?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7038:1306,access,accessory,1306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7038,1,['access'],['accessory']
Security,"Here is a recap of what we discussed today during the CNV meeting:. For the first round of evaluations we decided to run Germline CNV pipeline on TCGA exomes using a range of key hyperparameters (namely psi-t-scale and p-alt) and establish the base level performance metrics using output of GenomeSTRiP on matched WGS samples as ground truth. . @mbabadi could you come up with a good range of hyperparameter values that you think should be cross-validated?. In particular we need to:. - Dockerize tools we will be evaluating against (XHMM, CODEX2, CLAMMS, GenomeSTRiP); - Write a WDL that runs Germline CNV that scatters across range of key hyperparameters and outputs array of VCFs; - Write VCF processors for output of CLAMMS and CODEX2 ; - Write WDLs for running XHMM, CODEX2, CLAMMS and GenomeSTRiP that output VCFs; - Write WDL that takes results of the above and uses @mbabadi 's gCNV evaluation python modules(located here /dsde/working/mehrtash/gCNV_theano_eval) to output performance metrics; - Decide on an automatic evaluation framework. For the next round of evaluations we need to:. - Decide on appropriate metrics for evaluating performance on trios and write scripts that implement them; - Expand the range of hyperparameters in search space (possibly include different bin sizes, GC vs no GC correction, and fragment mid point coverage collection vs largest fragment overlap coverage collection); - Use gnomAD subset of matched WES/WGS pairs for validation",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071:446,validat,validated,446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071,2,['validat'],"['validated', 'validation']"
Security,"Here it is. An overview of what's been added:; - metrics package; - a few general metrics classes (e.g. MultiLevelMetrics); - may want to push these down into HTSJDK later; - added some utils; - utils.gene: gene annotation; - utils.illumina: general Illumina-related utils (adapters, etc); - utils.text.parsers: text parsing; - utils.variant: added dbSNP stuff; - MathUtils: added a few basic things (mean, stddev, etc) with unit tests; - tools; - three major packages:; - analysis: metrics + analyses (including necessary Rscripts); - illumina: Illumina parsing + validation; - vcf: VCF manipulation + GenotypeConcordance; - also two smaller packages, fastq and intervals, containing a few tools each; - tests; - all existing tests were ported; still, overall test coverage goes down by ~6%; - all CLP integration tests have been ported to the new argument system; - test data has also been carried over, and is neatly organized; - there are no huge files, and very few above 100KB (just a few VCFs I think); - however, the Illumina test data is pretty big - ~6MB spread over ~1700 files",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/347:565,validat,validation,565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/347,1,['validat'],['validation']
Security,"Here's an idea. It may be too much work, for now, and I'm fine with this code as it stands, but perhaps others are not. Anyway, the idea is this:. The constructor gets one extra argument: A lambda that serves as a validation function of the form; ```; void validate( int contig, int start, int end );; ```; It either throws an exception or returns silently.; Every client of SVInterval thus documents its intended conventions, and makes certain that those conventions are being adhered to.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5157#issuecomment-418868380:214,validat,validation,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5157#issuecomment-418868380,2,['validat'],"['validate', 'validation']"
Security,"Here's how these scripts are organized and why they take the form it is now:. How to run; * `manage/project.sh` is the ""executable""; * paths for VCF files (zipped or not) from PacBio callsets on CHM haploids, and Manta's VCF on the mixture should be provided to `manage/project.sh`, and; * paths for two versions of GATK-SV callsets; one is fine, but scripts in the sub-directory `manage` must be modified. Two GATK-SV vcf files are requested because this would allow one to compare if a supposedly improvement would make our raw sensitivity/specificity better or worse, that was the use case [here](https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest), and; * paths to where results are to be stored, one for each GATK-SV callset must be given and ; * path to where to store the results of comparing the two callsets; * several GNU bash utilities are expected, `guniq` and `gsort`, when run on a Mac, as well as `bedtools`. and what to expect; * the scripts checks the VCF files, prints to screen a slew of information that one can pipe, or simplely browse through.; * the scripts also outputs the ID's of variants from each of the two GATK callsets that are ""validated"" by PacBio haploid calls. Misc points:; * watch out for ""duplicated"" records, as sometimes different assembly contigs mapped to the same locations have slightly different alleles (SNP, for example) hence both would be output, but there aren't many such records based on experience; * there are also some variants that we output to the VCFs having size <50 or >50K, both of which are filtered upfront and saved separately.; * The scripts started when we first call insertions, deletions, inversions and small duplications, and back then PacBio call sets on the CHM haploids were not available, so Manta's calls were used as ""reference"", that explains why they are referred to throughout the project",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030:1172,validat,validated,1172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030,1,['validat'],['validated']
Security,"Here's some old code that uses SamLocusIterator (from tfennel) that AllelicCapseg can adapt for now. From Tim:; ""They key to making this nice and simple is the SamLocusIterator class, which given a BAM file and a list of intervals, will give you pileups at each position in the intervals, filtered how you want them, and even provide convenience methods to access the exact base per read that is piled up at the site etc. The really nice things about doing it this way is that the constructor to SamLocusIterator takes a simple parameter to tell it whether to use an index/query mechanism (similar to what you're doing now) or to just read the BAM serially up until the last interval is reached and output the loci of interest. Running the below with ~100k sites on a standard exome (15GB or so) without using the index took only about 15 minutes."". ```; public void pileup(final File bam, final IntervalList intervals, final int minQ, final File outputFile) {; final int MAX_INTERVALS_FOR_INDEX = 25000; // just a guess, not sure what the right number is. final SamLocusIterator iterator = new SamLocusIterator(new SAMFileReader(bam), intervals, intervals.size() < MAX_INTERVALS_FOR_INDEX);; iterator.setEmitUncoveredLoci(false);; iterator.setQualityScoreCutoff(minQ);. final BufferedWriter out = IoUtil.openFileForBufferedWriting(outputFile); // will automatically gzip if filename ends with .gz; try {; while (iterator.hasNext()) {; final SamLocusIterator.LocusInfo locus = iterator.next();; int a=0, c=0, g=0, t=0;. for (final SamLocusIterator.RecordAndOffset rec : locus.getRecordAndPositions()) {; switch (rec.getReadBase()) {; case 'A' : ++a; break;; case 'C' : ++c; break;; case 'G' : ++g; break;; case 'T' : ++t; break;; }; }. out.append(locus.getSequenceName() + ""\t"" + locus.getPosition() + ""\t"" + a + ""\t"" + c + ""\t"" + g + ""\t"" + t + ""\t"");; }. out.close(); ; }; catch (IOException ioe) { throw new RuntimeIOException(ioe); }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/335#issuecomment-88102420:357,access,access,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/335#issuecomment-88102420,1,['access'],['access']
Security,Hey @droazen can you please give me authorization to merge PRs? Or can you please merge this PR? Thanks.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2812#issuecomment-306374281:36,authoriz,authorization,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2812#issuecomment-306374281,1,['authoriz'],['authorization']
Security,"Hey @lbergelson, @droazen or @jamesemery: I'm hoping we could finalize this issue. I am unable to commit directly to this branch. To respond to the suggestions from @droazen I made this PR which i am hoping someone can merge into this feature branch (https://github.com/broadinstitute/gatk/pull/8871). . To recap:; - This PR is driven by a request from some of DISCVRseq's users to restore a GATK3 behavior where all source IDs are saved for variants when multiple VCFs are merged.; - This PR would expose this as an opt-in feature, and should not change any default GATK4 behavior. Therefore existing variant merge code should be unchanged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8752#issuecomment-2206804137:499,expose,expose,499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8752#issuecomment-2206804137,1,['expose'],['expose']
Security,"Hey @rsasch -- Just thinking out loud here… but does WDL seem like the right ""language"" to implement these sort of checks? It just feels like there is a ton of boilerplate, the WDL/bash constructs are a bit hard to follow, and I'm sure the development cycles were pretty slow waiting for cromwell to spin up all those VMs, etc. An alternative would be to write all these validations as a python script, which could make better use of structure (ie authenticating once, etc) and I bet would be quite a bit more readable. You could also run it locally if needed for development, debugging and then ultimately wrap it into a single-task WDL so it could be run easily from Terra. Happy to chat more",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883435010:371,validat,validations,371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883435010,2,"['authenticat', 'validat']","['authenticating', 'validations']"
Security,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6733:1703,checksum,checksum,1703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733,1,['checksum'],['checksum']
Security,"Hi ; I am using GATK 4.1.7.0, and have faced an issue running the seq-format-validation workflow. basically the process is ran but ends in failed state and the main output does not appear. I have attached here the exact command, stderr,validate-bam-inputs.json and validate-bam.wdl. The stdout just says 230. ; I would be grateful for any help on how to solve the issue. ; Best ; zara. <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 12 AM"" src=""https://user-images.githubusercontent.com/61913000/87845900-e6491480-c8e0-11ea-8dc0-ec5b3fbc15a8.png"">; <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 19 AM"" src=""https://user-images.githubusercontent.com/61913000/87845901-e77a4180-c8e0-11ea-8c6a-fb5783949ba3.png"">; <img width=""353"" alt=""Screen Shot 2020-07-16 at 12 00 30 AM"" src=""https://user-images.githubusercontent.com/61913000/87845902-ea753200-c8e0-11ea-96bc-caecee2ccb39.png"">; <img width=""1249"" alt=""stderr1"" src=""https://user-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:77,validat,validation,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,3,['validat'],"['validate-bam', 'validate-bam-inputs', 'validation']"
Security,Hi ; We have a forum post asking help for getting GATK 4.1.0.0 conda environment installed using the yml file. ; [https://gatk.broadinstitute.org/hc/en-us/community/posts/18332470602523-Install-GATK-version-4-1-0-0-using-Conda-](url). Looks like restructuring of the default repository under conda took out some of these packages and they are no longer directly accessible. They can be accessed from the forge repo with certain flags. This issue seems to deprecate some of the older but still usable versions of GATK (due to various reasons). Directing people to use the docker version or upgrading to the latest GATK version seems to be the only solution left for now. Any other ideas of how we should pursue this issue? @lbergelson @droazen ?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8504:362,access,accessible,362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8504,2,['access'],"['accessed', 'accessible']"
Security,"Hi @aderzelle. Thanks for your interest in NeuralNetInference. The tool currently has pre-beta`Experimental` status, so for now it should be used for evaluation purposes only. We expect to release another version of GATK, probably within the next week, that will include an updated version of the tool that will include a default architecture file, along with some additional tools for things like training. The tools will still be `Experimental`, but should be a bit easier to use. In the meantime, there is a bit more information about how to access the existing hd5 file [here](https://github.com/broadinstitute/gatk/issues/4511). Note that in the next release, the name of the tool will have changed to CNNScoreVariants. @lucidtronix anything else to add here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411:545,access,access,545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411,1,['access'],['access']
Security,Hi @cmnbroad - I removed a space in the path and re-ran ValidateVariants. It went through throwing no errors. Many thanks.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4657#issuecomment-380989518:56,Validat,ValidateVariants,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4657#issuecomment-380989518,1,['Validat'],['ValidateVariants']
Security,"Hi @dislek, this type of question might be more appropriate for the GATK forum (and has actually been previously asked there, see https://gatkforums.broadinstitute.org/gatk/discussion/12543/determinegermlinecontigploidy and the thread linked in the answer). The priors file is a TSV file that is described in the tool documentation for DetermineGermlineContigPloidy. You should manually construct this TSV file, with contig names appropriate to the reference being used and prior probabilities appropriate for the quality of your data set---probably the suggestions in the example in the tool documentation are a reasonable place to start. However, you may want to validate the ploidy calls output by DetermineGermlineContigPloidy using samples where the truth is known to ensure that the model is trained correctly using your choice of priors and other model parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5719#issuecomment-467252385:665,validat,validate,665,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5719#issuecomment-467252385,1,['validat'],['validate']
Security,Hi @icemduru ; Looks like your slurm workload manager was configured to have a limit of 48GBs of maximum process memory size per execution. Your java instance is set with -Xmx45G which will cover most of this limit and leaves only a handful of memory space for the native GenomicsDB library. Native libraries work above the heapsize so it is better for you to set your -Xmx to a more sensible size of 8~12GB and leave rest of the memory space to the native library to use. . Keep in mind that this memory limit on slurm could be set per user not per task therefore you may need to run a single contig at a time or maybe 2 of them simultaneously. Otherwise slurm may interefere with all the tasks and cancel all your jobs. . One final reminder. We strongly recommend users to set the temporary directory to somewhere else other than /tmp. Slurm workload manager interferes with this preference and sometimes results in premature termination of the gatk processes due to deletion of extracted native library and accessory files. . I hope this helps.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2283694332:1010,access,accessory,1010,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2283694332,1,['access'],['accessory']
Security,Hi @jonn-smith I had some success getting outputs with this. However ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/ is no longer accessible. The most recent version of I accessed on 3/19/2018 still contained at least one error. I'm trying to correct them myself as I go using a more recent build of GATK but it would be helpful if the data files required by this program were available. The one I found is in `gencode_xrefseq.config` where it references a source that doesn't exist and I fixed that. After that I was able to get outputs with hg38. Thanks for your work on this!. I'd also point out there are a lot of fields in the MAF with `__UNKNOWN__` as the entry,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645:150,access,accessible,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645,2,['access'],"['accessed', 'accessible']"
Security,"Hi @praneetha92 ,. Where did this file come from? GATK doesn't produce GLs anymore. It looks like there are the wrong number of likelihoods for one of your genotypes. Unfortunately our validation tool doesn't check this, but can you try vcf-validator? You can find it here: https://vcftools.github.io/perl_module.html#vcf-validator",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6897#issuecomment-710135263:185,validat,validation,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897#issuecomment-710135263,3,['validat'],"['validation', 'validator']"
Security,"Hi @tushu1232. The index image is a new feature that's not fully exposed in a friendly. It's the 5 indexes that bwa requires baked into a single file for easy distribution. ( .amb, .ann, .bwt, .pac, .sa ) We're going to add an official tool to generate it in the near future, but at present the only way to do so is to write a tool yourself that calls into org.broadinstitute.hellbender.utils.bwa.BwaMemIndex.createIndexImage();",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2414#issuecomment-282128828:65,expose,exposed,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2414#issuecomment-282128828,1,['expose'],['exposed']
Security,"Hi Adam,. Maybe I'm thinking naively here - and I don't have access to a complete and proper Spark cluster for rigorous testing - but just as a simple test of loading a VCF via Spark, I took [PrintReadsSpark.java](https://github.com/broadinstitute/gatk/blob/030858bc08328200b9df287db2571b907189ec66/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSpark.java) and performed following updates:; - Copied `./src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test.vcf` into the local directory.; - Renamed the copy of `PrintReadsSpark.java` as `PrintVCFSpark.java`; - Added `import org.broadinstitute.hellbender.utils.variant.Variant;`; - Added `import org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSource;`; - As a test, I changed to the `runTool` method with the following to print the information in the first element in the RDD:. ``` Java; JavaRDD<Variant> rddParallelVariants =; variantsSparkSource.getParallelVariants(output);. System.out.println( rddParallelVariants.first().toString() );; ```. And after re-compiling GATK and running `PrintVCFSpark`, I got the following to print the first element of the RDD:. ``` Bash; $ ./gatk-launch PrintVCFSpark --input test.vcf --output test.vcf. Running:; /home/pgrosu/me/hellbender_broad_institute/gatk/build/install/gatk/bin/gatk PrintVCFSpark --input test.vcf --output test.vcf; [February 14, 2016 7:04:16 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVCFSpark --output test.vcf --input test.vcf --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false; [February 14, 2016 7:04:16 PM EST] Executing as pgrosu on Linux 2.6.32-358.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_05-b13; Version: Version:4.alpha-86-g154d0a8-SNAPSHOT JdkD",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857:61,access,access,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857,1,['access'],['access']
Security,"Hi Adam,. Thank you for this amazing work, and would like to suggest something small without disturbing the test-flow. So unless I'm not mistaken, the class that is consuming the memory is [NestedIntegerArray.java](https://github.com/broadgsa/gatk/blob/master/public/gatk-utils/src/main/java/org/broadinstitute/gatk/utils/collections/NestedIntegerArray.java). Why not try an experiment where you implement something similar to [Google's SSTable](https://www.igvita.com/2012/02/06/sstable-and-log-structured-storage-leveldb/) that got release as [leveldb](https://github.com/google/leveldb). For instance the key-index lookup for you can be hash or a hash+offset. Basically these structures borrow from the concept of a [Log-Structured Merge-Tree (LSM-Tree) - link is a PDF paper](http://paperhub.s3.amazonaws.com/18e91eb4db2114a06ea614f0384f2784.pdf). You can push most of these to disk instead of memory, and they can be compressed as well. The indices can remain in memory for fast-lookup with the data staying on disk. So for instance, you can generate an key-index digest of specific values via `hash_function(numReadGroups.id, qualDimension.index, eventDimension.type)`, whose result you then use to quickly lookup the value for that key - which would reside on disk. That can be further improved with a priority queue cache for the most accessed values. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-180626838:640,hash,hash,640,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-180626838,3,"['access', 'hash']","['accessed', 'hash']"
Security,"Hi Chris,. Would you please review this?; And @tedsharpe, feel free to look at the getters in `InsertSizeMetricsCollectorSpark.java` and see if you need more access functions. Thank you.; Steve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1566:158,access,access,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1566,1,['access'],['access']
Security,"Hi James, that definitely shouldn't be happening. Any chance I could get access to that cram file or a 10 kB chunk around chr1:1914706 for debugging?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-593049062:73,access,access,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6473#issuecomment-593049062,1,['access'],['access']
Security,"Hi Jose,; Your system ulimit setting is too low. Please do this with root at; /etc/security/limits.conf; * soft memlock unlimited; * hard memlock unlimited; * hard nofile 20480; * soft nofile 20480; * hard nproc 40960; * soft nproc 40960; * soft stack unlimited; * hard stack unlimited. Ruzhu; -------------------------------------------; Ruzhu Chen, PhD (845) 433-8426(T/L 293-8426); Email: ruzhuchen@us.ibm.com, Mobile: (845) 337-7238; Sr. Technical Solution Architect, HPC / Genomics & Life Sciences; IBM Systems, 2455 South Road, Poughkeepsie, NY 12601. From:	Jose Sergio Hleap <notifications@github.com>; To:	broadinstitute/gatk <gatk@noreply.github.com>; Cc:	ruzhuchen <ruzhuchen@us.ibm.com>, Mention; <mention@noreply.github.com>; Date:	03/12/2020 11:37 AM; Subject:	[EXTERNAL] Re: [broadinstitute/gatk] Got ""Too many open files""; when use BaseRecalibratorSpark (#5316). Apologies on the poor report. There are no other users in these compute; nodes (I am the tester) and for all intents and purposes the ulimit is; pretty high (hard limit of 8192 max files). I am using GATK version; 4.1.4.1, although it might be the one that has been optimised for IBM; power9 systems by @ruzhuchen. Currently I am waiting for the sys admin to; increase the max files further, but I believe that this is far from ideal.; Here is the (simplified) command:. gatk --java-options ""-Xmx40g; -Djava.library.path=/bio/apps/gatk_4.1.4/gatk-4.1.4.1/libs; -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" Mutect2 -R; Homo_sapiens_assembly38.fa -I illuminaN_hg38.br.recal.bam; --max-mnp-distance 0 -O illuminaN.vcf.gz. May be I am running it wrong?. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or unsubscribe.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-598269062:83,secur,security,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-598269062,1,['secur'],['security']
Security,"Hi Paul, that means you don't have access to our internal repositories. Let me see if I can get you access.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-183014915:35,access,access,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-183014915,2,['access'],['access']
Security,"Hi all,. Below error occurs trying to access Funcotator data source directory installed on lustre file system. We have a non-lustre mounted fs for cases like this, but I thought it was worth bringing up. ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to query the database for geneName: null; 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.cosmic.CosmicFuncotationFactory.createFuncotations(CosmicFuncotationFactory.java:244); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:404); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:316); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4413:38,access,access,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413,1,['access'],['access']
Security,"Hi all;; When validation runs on the GATK 4.0.0 release (congrats!) we're running into segfault issues on some `GenomicsDBImport` runs which look to be due to the length of the database path:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f99a7642c5b, pid=7446, tid=0x00007f99fbfa0700; #; # JRE version: OpenJDK Runtime Environment (8.0_121-b15) (build 1.8.0_121-b15); # Java VM: OpenJDK 64-Bit Server VM (25.121-b15 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libtiledbgenomicsdb8843204539247232071.so+0x4fdc5b] std::string::compare(char const*) const+0x1b; ```; Here is a self-contained test case that reproduces the issue:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_genomicsdb_length.tar.gz. A standard small name and longer name of 105 characters work fine:; ```; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path short_genomicsdb -L chr22:15069-15500 --variant Test1.vcf.gz --variant Test2.vcf.gz; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path long_aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_genomicsdb/works_aaaaaaaaaaaaaaaaaaaaaaaaaa -L chr22:15069-15500 --variant Test1.vcf.gz --variant Test2.vcf.gz; ```; But when you add an additional character, you trigger the segfault:; ```; gatk-launch --java-options '-Xms1g -Xmx2g' GenomicsDBImport --reader-threads 1 --genomicsdb-workspace-path long_aaaaaa; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_genomicsdb/fails_aaaaaaaaaaaaaaaaaaaaaaaaaaa -L chr22:15069-15500 -; -variant Test1.vcf.gz --variant Test2.vcf.gz; ```; Thank you for looking at this and please let me know if I can provide any other information to help debug.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4160:14,validat,validation,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4160,1,['validat'],['validation']
Security,"Hi everyone,. I'm facing a similar issue with GATK v4.1.0.0 (HTSJDK v2.18.2 and Picard v2.18.25). I'm using GATK Docker image broadinstitute/gatk:4.1.0.0. Following what I read here, I checked the bam file and everything seems fine:; `gatk ValidateSamFile --INPUT sorted.bam --MODE SUMMARY`; ```; Using GATK jar /gatk/gatk-package-4.1.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.1.0.0-local.jar ValidateSamFile --INPUT CQ-NEQAS-2018.ILLUMINA.library.000000000-BCFDC.1.1.sorted.bam --MODE SUMMARY; 16:08:17.382 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Thu Mar 07 16:08:17 UTC 2019] ValidateSamFile --INPUT CQ-NEQAS-2018.ILLUMINA.library.000000000-BCFDC.1.1.sorted.bam --MODE SUMMARY --MAX_OUTPUT 100 --IGNORE_WARNINGS false --VALIDATE_INDEX true --INDEX_VALIDATION_STRINGENCY EXHAUSTIVE --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --SKIP_MATE_VALIDATION false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. La",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:240,Validat,ValidateSamFile,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,3,['Validat'],['ValidateSamFile']
Security,"Hi folks. @chandrans and I have laid out some plans towards updating GATK4 docs for the January 9 release. Our approach is to prioritize documentation around stable Best Practice Workflows. On the docket currently is the single stable workflow--germline SNP and indel calling from DNA data. We will of course update tool docs (excluding Spark and BWA tools) and supporting tutorials. Even for tools we are unfamiliar with, we aim to have at the least a basic description and an example command. Thanks for the documentation you have already done and the help you give us in updating these. If you are certain your workflow will be ready for the release, then please let us know immediately so we can plan accordingly. If your workflow will be ready later, then can you still give us an estimate for your release so we can plan ahead? Thanks. - @davidbenjamin, did I hear you correctly that you think somatic SNV and indel calling will be ready for the Jan 9 release?; - @samuelklee, I know major changes are currently afoot for somatic CNV. Will you make the Jan 9 release for the targeted exomes use-case? What about WGS?; - @mbabadi, is March, 2018 still the plan?; - @jonn-smith, what is the status on the Tool-That-Must-Not-Be-Named?; - @cwhelan @tedsharpe @SHuang-Broad, is SV on for next year or thereafter?. It would be most helpful to users if we also have validation of our workflows as applied to real data. Are there plans to make benchmarking stats available for each of your workflows?. Sheila and I have 30-man days we can give between us towards updating documentation by December 14. Besides Geraldine, we will rely on some of you to review further refinements to documentation from now to December 14. Thanks again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769:1365,validat,validation,1365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769,1,['validat'],['validation']
Security,"Hi guys,. In case it helps, here's an upload site that could be used for these GATK3 test data, either uploading through the browser:. https://prime-seq.ohsu.edu/project/Internal/Bimber/GATK/begin.view?. or command line (-T for file name(s)), note the user/password:. curl --basic -T foo.txt -u ""gatk_upload@gatk.com:genomes"" https://prime-seq.ohsu.edu/_webdav/Internal/Bimber/GATK/@files/. I'll delete that temporary user and dropbox once finished, so i'm not that worried about posting credential in this public forum. I'm also happy to download from somewhere if that's an option. The post above summarizes the files we're hoping to get. Thanks again for the help,; Ben",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-360578779:257,password,password,257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-360578779,1,['password'],['password']
Security,"Hi, ; for those looking to run containers within a multi-user HPC environment, running a container with default root privileges presents a potential data security risk. Adding something like :. RUN useradd -ms /bin/bash gatk; WORKDIR /home/gatk; USER gatk. to the Docker file would greatly reduce the risk and bring the current containers in line with general best practice, e.g https://medium.com/@mccode/processes-in-containers-should-not-run-as-root-2feae3f0df3b. There should be no downsides to running in this manner. Singularity could help but the current configuration will be picked up and prevented from running by any site using a container security scanner, e.g. Aqua.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-494457377:154,secur,security,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3644#issuecomment-494457377,2,['secur'],['security']
Security,"Hi, I encountered the following error while running GATK.; It is hard for me to say what exactly is wrong, and extensive searching has not been helpul. Thanks in advance!. ```; gatk ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVarian",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:182,Validat,ValidateVariants,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,2,['Validat'],['ValidateVariants']
Security,"Hi, since there is DOS (Denial of Service) threat for log4j 2.16.0(https://logging.apache.org/log4j/2.x/security.html),; is that possible to update GATK with log4j_2.17.0? Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7603#issuecomment-998102555:43,threat,threat,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7603#issuecomment-998102555,2,"['secur', 'threat']","['security', 'threat']"
Security,"Hi,. @gbrandt6 can you let me know how to access the bug report files that the user pushed to [ftp](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072797951/comments/360012763332)? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6793#issuecomment-686806185:42,access,access,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793#issuecomment-686806185,1,['access'],['access']
Security,"Hi,. I had used ""ASEReadCounter"" with the GRCh37 Genome on my samples and I got results even when I had this warning:; ""IndexDictionaryUtils - Track sitesVCFFile doesn't have a sequence dictionary built in, skipping dictionary validation "". The problem is that now I'm using just the canonical chromosomes as a reference and I'm getting the same warning but the output file is empty. Could someone help me? . Thanks,; Cristian",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6540:227,validat,validation,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6540,1,['validat'],['validation']
Security,"Hi,. I'm trying to validate the performance of BwaSpark (I'm running it locally). The input ubam file size is 5.1 GB. It takes 65 minutes for GATK's BwaSpark to complete which is exactly same as bwa-mem. Below is the command that I used to run BwaSpark. Is there any way to make BwaSpark run faster while running it locally or will the performance increase only while running on spark cluster? Please let me know if I had to modify or add any parameter. . Also, please let me know where can I find the complete list of --conf parameters for BwaSpark? (I couldn't find these options in gatk BwaSpark --help). `time gatk BwaSpark --bwa-mem-index-image GRCh37.fasta.img --spark-master local[*] --bam-partition-size 4000000 --conf 'spark.executor.num=5' --conf 'spark.executor.cores=16' --conf 'spark.executor.memory=15G' --conf 'spark.driver.memory=30G' --conf 'spark.dynamicAllocation.enabled=true' -I unmapped_input.bam -O output.bam -R GRCh37.fasta 2> Log_file.log`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8897:19,validat,validate,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8897,1,['validat'],['validate']
Security,"Hi,. Not sure if it is applicable but I just ran vcf-validator on the input gvcf file (also not sure if you can run vcf-validator on a gvcf): . ```; vcf-validator Sample_1__CDL-164-04P-gatk-haplotype-annotated-rnaedit-annotated-gemini.vcf.gz; ```. Here are the first few lines from the logs:. ```; The header tag 'reference' not present. (Not required but highly recommended.); INFO field at 1:14599 .. INFO tag [max_aaf_all=0.2096] expected different number of values (expected 2, found 1); INFO field at 1:14604 .. INFO tag [max_aaf_all=0.2096] expected different number of values (expected 2, found 1); INFO field at 1:14930 .. INFO tag [max_aaf_all=0.5231] expected different number of values (expected 2, found 1); INFO field at 1:15211 .. INFO tag [max_aaf_all=0.7316] expected different number of values (expected 2, found 1); INFO field at 1:15274 .. INFO tag [max_aaf_all=0.7205] expected different number of values (expected 3, found 1); INFO field at 1:16949 .. INFO tag [max_aaf_all=0.0227] expected different number of values (expected 2, found 1); INFO field at 1:17365 .. INFO tag [max_aaf_all=0.3841] expected different number of values (expected 2, found 1),INFO tag [af_adj_exac_afr=; 0.1603] expected different number of values (expected 2, found 1),INFO tag [af_exac_all=0.2553] expected different number of values (expect; ed 2, found 1),INFO tag [af_adj_exac_nfe=0.2715] expected different number of values (expected 2, found 1),INFO tag [af_adj_exac_sas=0.2883; ] expected different number of values (expected 2, found 1),INFO tag [af_adj_exac_oth=0.2581] expected different number of values (expected; 2, found 1),INFO tag [af_adj_exac_eas=0.3841] expected different number of values (expected 2, found 1),INFO tag [af_adj_exac_amr=0.221] e; xpected different number of values (expected 2, found 1),INFO tag [af_adj_exac_fin=0.2245] expected different number of values (expected 2,; found 1); INFO field at 1:17373 .. INFO tag [af_adj_exac_amr=0.028] expected different number ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407476343:53,validat,validator,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-407476343,3,['validat'],['validator']
Security,"Hi,. Using GATK mutect2's wdl file on Terra (version 21 on agora) I keep getting the same error:; ""pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket"" . Here is part of the stacktrace : ; ```; 20:59:48.744 INFO Mutect2 - Inflater: IntelInflater; 20:59:48.744 INFO Mutect2 - GCS max retries/reopens: 20; 20:59:48.744 INFO Mutect2 - Requester pays: enabled. Billed to: broad-firecloud-ccle; 20:59:48.744 INFO Mutect2 - Initializing engine; 20:59:54.630 INFO FeatureManager - Using codec VCFCodec to read file gs://depmapomicsdata/1000g_pon.hg38.vcf.gz; 20:59:55.629 INFO Mutect2 - Shutting down engine; [October 4, 2021 8:59:55 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=876609536; code: 403; message: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; reason: forbidden; location: null; retryable: false; com.google.cloud.storage.StorageException: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:406); at com.google.cloud.storage.StorageImpl$4.call(StorageImpl.java:217); ...; ```. This happens while it runs the command:. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15500m\ ; -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\ ; -I gs://cclebams/hg38_wes/CDS-00rz9N.hg38.bam -tumor BC1_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE --germline-resource gs://gcp-public-data--gnomad/release/3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492:204,access,access,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492,1,['access'],['access']
Security,"Hi,; I update GATK today.; After 158 minutes variant calling on the same bam files, I have another issue :. ```; [3 décembre 2019 13:57:42 CET] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 158.34 minutes.; Runtime.totalMemory()=28647096320; Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded; 	at java.util.LinkedHashMap$LinkedKeySet.iterator(LinkedHashMap.java:543); 	at java.util.HashSet.iterator(HashSet.java:173); 	at java.util.AbstractCollection.toArray(AbstractCollection.java:137); 	at java.util.LinkedList.addAll(LinkedList.java:408); 	at java.util.LinkedList.addAll(LinkedList.java:387); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.graphs.BaseGraph$BaseGraphIterator.next(BaseGraph.java:774); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.graphs.BaseGraph$BaseGraphIterator.next(BaseGraph.java:723); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.graphs.BaseGraph.removePathsNotConnectedToRef(BaseGraph.java:505); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.getAssemblyResult(ReadThreadingAssembler.java:514); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.createGraph(ReadThreadingAssembler.java:492); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.assemble(ReadThreadingAssembler.java:401); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.runLocalAssembly(ReadThreadingAssembler.java:148); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:290); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:224); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); 	at org.broadinstitute.hellben",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-561188674:447,Hash,HashSet,447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-561188674,2,['Hash'],['HashSet']
Security,Hm - I don't think we can take that last change. Theres not much use in validating args after they've been used by the constructors. Let me see if there is an alternative.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827854652:72,validat,validating,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827854652,1,['validat'],['validating']
Security,"Hmm, I don't have access to dsde-docs. I thought by default haplotypeCaller doesn't use supplementary reads in GATK3? If I'm wrong about that assumption, then I don't see any reason why it would be different in GATK4.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2043#issuecomment-235071588:18,access,access,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2043#issuecomment-235071588,1,['access'],['access']
Security,"Hmm, I started taking a stab at the LL score implementation, but I think it's going to complicate the code quite a bit and add some branching options to the tool interfaces. Compounding this with a change in the use of ""truth"" and ""validation"" terminology, I fear that the resulting differences from the legacy strategy might be a bit much for users to digest!. So I'd want to better understand the cost/benefit before we proceed. How critical is automatic tuning of the hard threshold? And what's the relative importance to method changes that increase AUC (i.e., as opposed to figuring out where on the curve to hard threshold)? Is there a clear path forward for evaluating such a tuning process? @meganshand would be glad to chat more!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065524909:232,validat,validation,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065524909,1,['validat'],['validation']
Security,"Hmm, as we discussed, I'm not sure this will be so straightforward, given that we only have easy access to scores for positive truth---and hence, no false positives, which precludes calculation of precision and F1. I *think* we could pass a VCF for a sample with gold-standard positives and negatives and use the existing code for extracting labels, but this will require a bit of engineering and be more trouble than it's worth. There are other options---see https://ir.cwi.nl/pub/30479, for example. We might want to experiment with the LL score discussed there (see https://www.aaai.org/Papers/ICML/2003/ICML03-060.pdf for the original paper---although note that despite the paper's high citation count, I'm not sure what the canonical name for this metric actually is, but it doesn't appear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:97,access,access,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,1,['access'],['access']
Security,"Hmmm, rather than making assumptions, the aligner could expose its SW parameters and then it comes down to a line of arithmetic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5466#issuecomment-443324822:56,expose,expose,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5466#issuecomment-443324822,1,['expose'],['expose']
Security,Hmn. This is failing with 403 unauthorized errors. Seems like something about authentication changed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-511979513:78,authenticat,authentication,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-511979513,1,['authenticat'],['authentication']
Security,"How about doing this everywhere except in Picard, instead of abandoning it completely? Non-linked hash sets/maps have caused MANY problems in GATK over the years.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1844#issuecomment-220622306:98,hash,hash,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1844#issuecomment-220622306,1,['hash'],['hash']
Security,How do I access that? I thought that the GATK resources were located here: https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0/. Is there a reason this is not in the GATK resource bundle?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481902753:9,access,access,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481902753,1,['access'],['access']
Security,"How to reproduce:. Modify the code in ```AlignmentIntervalUnitTest.testConstructionFromSAMRecord``` to perform a validation of the read returned by ```applyAlignment```:. ```; final SAMRecord samRecord = BwaMemAlignmentUtils.applyAlignment(""whatever"", SVDiscoveryTestDataProvider.makeDummySequence(expectedContigLength, (byte)'A'), null, null, bwaMemAlignment, refNames, hg19Header, false, false);; if (samRecord.isValid() != null) {; throw new IllegalStateException(samRecord.isValid().stream().map(s -> s.getMessage()).collect(Collectors.joining("", "")));; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3459#issuecomment-323218384:113,validat,validation,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459#issuecomment-323218384,1,['validat'],['validation']
Security,"Huh, I wonder why gradle doesn't like a lustre system. I didn't now that was an issue. Git-lfs is an annoyance to install if you don't have access to a package manager. I *think* it can be installed without sudo but I get why that's a pain. I've spent a non-zero amount of time fighting with git-lfs installation before. Thank you for elaborating!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042057009:140,access,access,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042057009,1,['access'],['access']
Security,"I added a test according to #4642 , but can't reproduce the error. The user also noted that the error message was badly formed, which is true because it ended with a colon. Now it looks like:; ""Input src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf fails strict validation of type CHR_COUNTS: the Allele Count (AC) tag is incorrect for the record at position 1:985447, 1 vs. 2""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6076:263,Validat,ValidateVariants,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6076,3,"['Validat', 'validat']","['ValidateVariants', 'validation', 'validationExampleBad']"
Security,"I added one unrelated bugfix. FuncotatorUtils.createReferenceSnippet tries to expand the reference window. When doing this, it should never allow a start less than 1. The last commit addresses that. . Note: I did not see an easy way for createReferenceSnippet() to identify the length of the contig (such as access to the SequenceDictionary), but it would in theory be useful to also check contig size and not exceed it. @droazen or @jonn-smith: it would be helpful if you could approve the test run. ```; 22 Jun 2023 14:54:27,152 DEBUG: 	java.lang.IllegalArgumentException: Invalid interval. Contig:MT start:0 end:20; 22 Jun 2023 14:54:27,154 DEBUG: 		at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804); 22 Jun 2023 14:54:27,155 DEBUG: 		at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); 22 Jun 2023 14:54:27,156 DEBUG: 		at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35); 22 Jun 2023 14:54:27,158 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createReferenceSnippet(FuncotatorUtils.java:1461); 22 Jun 2023 14:54:27,159 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createIgrFuncotation(GencodeFuncotationFactory.java:2481); 22 Jun 2023 14:54:27,160 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createIgrFuncotations(GencodeFuncotationFactory.java:2407); 22 Jun 2023 14:54:27,162 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createDefaultFuncotationsOnVariant(GencodeFuncotationFactory.java:499); 22 Jun 2023 14:54:27,163 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:217); 22 Jun 2023 14:54:27,164 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.create",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226:308,access,access,308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226,3,"['access', 'validat']","['access', 'validateArg', 'validatePositions']"
Security,"I added you as collaborator, you should have access now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-183027964:45,access,access,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-183027964,1,['access'],['access']
Security,"I addressed partially your comments (and fixed a compilation error due to the tests using the previous arguments). One of the major points of discussion are the following:. * `Collection` instead of `List`: I think that the first is more flexible, because a client maybe wants to have a `LinkedHashSet` as the argument to avoid repetition of the same filter. I agree that the abstract class should discourage not honoring the user order.; * Access to methods/fields: I think that the plugin could be used outside GATK in a different way by extending it. I explained some of my usage cases in one of the comments in the code, but just by overriding a simple method the whole plugin could be used very nicely in some of them. I would prefer to do that than copy your code and re-implement the bits that I would like to change. Back to you for your ideas on this, @cmnbroad!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275359208:441,Access,Access,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275359208,1,['Access'],['Access']
Security,I agree that it is a good security measure to use fixed signed dependencies for repeatable builds. GATK depends on gradle 3.1.: [download](https://services.gradle.org/distributions/gradle-3.1-bin.zip) [shaw256](https://services.gradle.org/distributions/gradle-3.1-bin.zip.sha256),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444208372:26,secur,security,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444208372,1,['secur'],['security']
Security,"I agree with everything @magicDGS said. In general, the native GATK tool benefits from all of the automatic framework management and I/O support (like honoring md5, lenient args, etc.). #2234 also has the validation checking mentioned, and has more tests. (It is true that when #2223 goes in, we'll have to override the default sequence dictionary validation behavior, maybe via disableSequenceDictionaryValidation). So I think we should take the native one, but if we do choose to keep this one for any reason, then I'll still want to do a line-by-line CR before we merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-257306629:205,validat,validation,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-257306629,2,['validat'],['validation']
Security,I also can't access those files. Who can grant access to them?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2658#issuecomment-299493615:13,access,access,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2658#issuecomment-299493615,2,['access'],['access']
Security,"I am aware that those methods should be definetively implemented in the abstract class - but it could be recommended *NOT TO OVERRIDE* unless you know what you are doing. I know the problems of having them exposed, but also I can see some potential to be accessible from an implemented walker when the user knows what is doing...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4964#issuecomment-404134765:206,expose,exposed,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4964#issuecomment-404134765,2,"['access', 'expose']","['accessible', 'exposed']"
Security,I am getting the following exception when I set `--minimum-mapping-quality` to 60 (but not 50). . ```console; $ gatk --version; ...; The Genome Analysis Toolkit (GATK) v4.2.0.0; HTSJDK Version: 2.24.0; Picard Version: 2.25.0; ```. ```console; $ gatk HaplotypeCaller \; -I in.bam \; -L chr7:145945238-145945238 \; -stand-call-conf 0 \; --disable-optimizations \; --force-active -O out.vcf \; --reference /path/to/ucsc.hg19.fasta \; --minimum-mapping-quality 60;; ...; java.lang.IllegalStateException: There is no variation present.; 	at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyRegionTrimmer$Result.getVariantRegion(AssemblyRegionTrimmer.java:108); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:595); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:273); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. <details>; <summary>test.sam</summary>. ```; @HD	VN:1.6	SO:coordinate; @SQ	SN:chr1	LN:249250621; @SQ	SN:chr2	LN:243199373; @SQ	SN:chr3	LN:198022430; @SQ	SN:chr4	LN:191154276; @SQ	SN:chr5	LN:18,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7123:578,validat,validate,578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7123,1,['validat'],['validate']
Security,"I am going to be able to identify samples for a new panel of normals this week, after which generating and validating the panel will take another few days.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1289162161:107,validat,validating,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1289162161,1,['validat'],['validating']
Security,"I am having a similar issue with GATK `4.1.4.1` that persists after updating to `4.2.0.0`:; ```; 00:33:06.768 INFO BaseRecalibrationEngine - The covariates being used here:; 00:33:06.768 INFO BaseRecalibrationEngine - ReadGroupCovariate; 00:33:06.768 INFO BaseRecalibrationEngine - QualityScoreCovariate; 00:33:06.768 INFO BaseRecalibrationEngine - ContextCovariate; 00:33:06.768 INFO BaseRecalibrationEngine - CycleCovariate; 21/03/28 00:33:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on fend04.cluster:42128 in memory (size: 35.5 KB, free: 5.2 GB); 21/03/28 00:33:14 ERROR Executor: Exception in task 1.0 in stage 0.0 (TID 1); java.lang.IllegalArgumentException: Table1 1,3 not equal to 2,3; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.combineTables(RecalUtils.java:560); at org.broadinstitute.hellbender.utils.recalibration.RecalibrationTables.combine(RecalibrationTables.java:144); at org.broadinstitute.hellbender.utils.recalibration.RecalibrationTables.inPlaceCombine(RecalibrationTables.java:178); at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724:748,validat,validateArg,748,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724,1,['validat'],['validateArg']
Security,"I am looking at using GATK and first checked at the docker image using **_docker pull broadinstitute/gatk_**. this container image has 1460 vulnerabilities and a lot of them are critical. ; <img width=""1737"" alt=""Screenshot 2023-02-21 212830"" src=""https://user-images.githubusercontent.com/4427764/220508376-aeead13b-999b-4cfd-a7d6-295241df532a.png"">. Then I decided not to use this image and instead create my own image and just deploy the released version 4.2.6.1 from here (https://github.com/broadinstitute/gatk/releases/download/4.2.6.1/gatk-4.2.6.1.zip). Even this has many vulnerabilities include things stemming from log4j 1.2.17. These have been fixed by log4j team years back in version 2.17.1 onwards. I am really stunned that a popular library like gatk is not keeping up with basic security fixes. <img width=""854"" alt=""Screenshot 2023-02-21 212751"" src=""https://user-images.githubusercontent.com/4427764/220508300-7bfe331d-8286-4950-a6dc-e1f5f97c65d0.png"">. the latest version of docker desktop has integrated image scanning and can very easily highlight the issues listed above. Can we start addressing these issues sooner than later.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215:795,secur,security,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215,1,['secur'],['security']
Security,"I am running GenotypeGVCFs using a single, combine GVCF produced from CombineGVCFs in GATK4. The file contains 44 individuals yet I am receiving the warning 'InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples'. Should I be concerned by this? I can validate that my input file contains more than 10 samples by the headers it contains. . This is the code I am running, . java -jar ../../programs/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar GenotypeGVCFs -R revisedAssemblyUnmasked.fa --variant subset_of_pop.vcf -O genotype_subset.vcf. Thank you, . ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6238:283,validat,validate,283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6238,1,['validat'],['validate']
Security,"I am still receiving security warnings about GATK 4.4.0.0:. Detected by File Paths: gatk-4.4.0.0/gatk-package-4.4.0.0-local.jar; Detected by Library: pkg:java/log4j:log4j; CPE: cpe:/a:apache:log4j:1.2.17; Version End of Life Date: August 4th, 2015 at 7:00 PM",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1513816621:21,secur,security,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1513816621,1,['secur'],['security']
Security,"I appreciate the desire for minimal changes, but I would point out that tying the VariantContext to the source FeatureInput is likely to be a somewhat common need for MultiVariantWalkers. I realize you have a lot of existing example that dont need this capability. While I started this using VariantEval/VariantQC, I more recently tried to port CombineVariants to GATK4 and hit a similar roadblock. I have one or two other lab-specific walkers that would benefit from using the iteration pattern of MultiVariantWalkerGroupedOnStart, but also need some ability to retain the FeatureInput->VariantContext link. I believe GATK3 retained this. It would be nice to at least make this a capability available to all MultiVariantWalkerGroupedOnStart walkers. My suggestion above about making a FeatureInputAwareVariantContext wasnt necessarily meant to be introduced into every class. Would something conceptually like this pass GATK if I could introduce it more surgically, perhaps injected into MultiVariantDataSource alone?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823594870:975,inject,injected,975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823594870,1,['inject'],['injected']
Security,"I can access the artefactory web site. I tried again, and the build worked! Must have been a transient issue. Thanks for checking!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2579#issuecomment-292596069:6,access,access,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2579#issuecomment-292596069,1,['access'],['access']
Security,"I can confirm it was due to ""gs://gcp-public-data--gnomad"" not giving the correct authorization.. I had to copy the file in my own workspace. . It seems pretty problematic as it is the recommended file to run the workflow with...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492#issuecomment-934925641:82,authoriz,authorization,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492#issuecomment-934925641,1,['authoriz'],['authorization']
Security,"I can expose validation stringency, but there is a TODO in this file that says ""allow SamReader settings to be customized by client"". So my question is similar to the question in issue 419: should I allow the caller to optionally provide their own SamReaderFactory so they can customize all of the options, or do we really want to just limit it to validation stringency ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/181#issuecomment-111532924:6,expose,expose,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/181#issuecomment-111532924,3,"['expose', 'validat']","['expose', 'validation']"
Security,"I checked only the tools that are marked `no` in the `correct category in gatk --list` in the 0107Check_category_&_doc tab of https://docs.google.com/spreadsheets/d/19SvP6DHyXewm8Cd47WsM3NUku_czP2rkh4L_6fd-Nac/edit?usp=sharing. ## The following eight tools need fixing:. tool | category philosophically ok? | 2nd check, correct category in gatkDoc? | categorization fixed by https://github.com/broadinstitute/gatk/pull/4094?; -- | -- | -- | --; IndexFeatureFile | NO | y | no; still in Variant Manipulation but should be in Other.; CreateHadoopBamSplittingIndex | NO | y | no; still in Other but no longer with ConvertHeaderlessHadoopBamShardToBam; VariantAnnotator | y | DOES NOT SHOW UP | no; does not show up; FixCallsetSampleOrdering | MISSING | no | no; does not show up; DepthOfCoverage | y | DOES NOT SHOW UP | no; DiagnoseTargets | y | DOES NOT SHOW UP | no; GatherTranches | y | y | DOES NOT SHOW UP IN GATKDOC; shows up in correct category in gatk --list; ValidateBasicSomaticShortMutations | MISSING | no | DOES NOT SHOW UP IN GATKDOC; shows up in correct category in gatk --list. ## The following tools appear fixed by this PR:. tool | category philosophically ok? | 2nd check, correct category in gatkDoc? | categorization fixed by https://github.com/broadinstitute/gatk/pull/4094?; -- | -- | -- | --; CollectBaseDistributionByCycleSpark | y | y | y; ASEReadCounter | y | y | y; CountBases | y | y | y; CountBasesSpark | y | y | y; CountReads | y | y | y; CountReadsSpark | y | y | y; PileupSpark | y | y | y; CollectInsertSizeMetricsSpark | y | y | y; CollectMultipleMetricsSpark | y | y | y; CollectQualityYieldMetricsSpark | y | y | y; CompareBaseQualities | y | y | y; EstimateLibraryComplexityGATK | y | y | y; FilterLongReadAlignmentsSAMSpark | y | y | y; FlagStat | y | y | y; FlagStatSpark | y | y | y; MeanQualityByCycleSpark | y | y | y; QualityScoreDistributionSpark | y | y | y; GatherBQSRReports | y | y | y; ApplyBQSR | y | y | y; ApplyBQSRSpark | y | y | y; BaseRecalibrato",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356110640:966,Validat,ValidateBasicSomaticShortMutations,966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356110640,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,I checked that it runs now with picard 2.0.1 and GATK3.5 (validation fails though),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1921:58,validat,validation,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1921,1,['validat'],['validation']
Security,"I cleaned up the class a bit - removed all specialized filtering methods in favor of generic predicate-based access. If we find repeated uses in client code, we can move those here. . Regarding tests, can you list the conditions that you think are inadequately tested?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/661#issuecomment-128042589:109,access,access,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/661#issuecomment-128042589,1,['access'],['access']
Security,I cleaned up the mutect2 wdl and added multi-sample support. I also optimized resource usage and exposed the memory parameters: https://github.com/phylyc/gatk4-somatic-snvs-indels,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7532#issuecomment-1125321665:97,expose,exposed,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7532#issuecomment-1125321665,1,['expose'],['exposed']
Security,"I created a branch in gatk-protected to address this issue. @lbergelson, @droazen -- could I get push access to the gatk-protected repo so I can push and submit a PR? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2717#issuecomment-302442385:102,access,access,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2717#issuecomment-302442385,1,['access'],['access']
Security,"I created a minimal branch to clean up the way we were passing around credentials. We create a GCSOptions class instead of a DataflowPipelineOptions when we create the pipeline and pass in secrets in at the point instead at the ReadSources level. ReadSources now takes a pipeline instead of the secrets file location. This isn't a long term solution. We should switch the code to get rid of the GenomicsSecret and instead use the more general secret. I think much of the secets factory junk can go away now (they dated from a time when the Dataflow API wasn't built out much. All tests passed locally. Oddly, I now am sometimes getting a dialog about DSDE needing access to basic information about my Google account, not sure source of the issue (maybe the secret I grabbed?), if it's repeatable, or blocking. I recommend the reviewer patch my branch and test locally.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/513:664,access,access,664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/513,1,['access'],['access']
Security,I currently have a feature driven walker in gatk-protected that is slower than a read-walker equivalent due to the repetitive Read iterator re-instantiation when accessing overlapping reads using the ReadContext. . Ideally the engine (FeatureManager?) would try to reuse open read iterators instead of creating them for each feature/interval.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1246:162,access,accessing,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1246,1,['access'],['accessing']
Security,"I did this yesterday but didn't look into all the output. ```; find src/test/resources -name ""*.bam"" > bams. for x in $(cat bams):; do build/install/hellbender/bin/hellbender ValidateSamFile -I $x >> validateBamOutput 2>&1; done; ```. output is here:; https://gist.github.com/lbergelson/002289ce94b0eace183c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-112827447:175,Validat,ValidateSamFile,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-112827447,2,"['Validat', 'validat']","['ValidateSamFile', 'validateBamOutput']"
Security,"I did, but then I rethought it and decided that I think it's too fragile to do it that way: You have to guarantee that all classes that might want to be registered are loaded and initialized before you instantiate the SparkConf. The problem is that it varies among JVM implementations exactly when that (class loading and initialization) happens. Some JVMs do the whole mess, chasing all references down from main recursively at the beginning, others are as lazy as possible and initialize only when actually traversing a reference for the first time. We could use that technique to ""inject"" a set of registrations into the GATKRegistrator from each main class. But since it's unreliable to do it in arbitrary classes, it seemed more straightforward to just let the normal object oriented method of overrides handle the problem, since it will need to be done only by direct subclasses, anyway. But I'm certainly open to other solutions, so long as we provide the functionality.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1767#issuecomment-214473964:584,inject,inject,584,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1767#issuecomment-214473964,1,['inject'],['inject']
Security,"I didn't expect Hellbender to crash for this command:. `$ ./hb PrintReads -I CEUTrio.HiSeq.WGS.b37.NA12878.bam -O 4m.bam -L 20:1000000-4000000`; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/828:439,validat,validatePositions,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828,1,['validat'],['validatePositions']
Security,"I didn't realize before that there is no ""include"" (opt-in) validation type arg, only ""exclude"". So I'm not sure what the purpose of having ""ALL"" is in the first place, if the only thing you can usefully do with it is exclude it. I think the best longer term fix would be to add an ""--validation-type-to-include"" arg, and have it default to the everything except for IDs, and then construct the actual types based on merging include/exclude args. But thats a bigger change then just fixing the current (silent do-nothing) default behavior, and requires more error checking for conflicting args. Lets start with changing it so that in the default (no args) case, we log a warning message saying that IDs will be left out since no IDS were provided, and proceed with the remaining validations. Then if we want to get more ambitious we can talk about making the bigger change. Also, as part of the initial fix, it might be a good idea to change `calculateValidationTypesToApply` so that it doesn't modify the `excludeTypes` list directly, since this is the list provided by the user, and instead uses it's own temporary list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279:60,validat,validation,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279,3,['validat'],"['validation', 'validation-type-to-include', 'validations']"
Security,"I discovered that it actually is possible to load unmapped reads with the existing google code code. I had thought it didn't include the ability to do so, but after further digging, there's a way to do it that we just haven't exposed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/560#issuecomment-114228839:226,expose,exposed,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/560#issuecomment-114228839,1,['expose'],['exposed']
Security,"I discovered that one of the 345 input gvcfs failed VCF validation. When I removed that file and reran with no other changes, I did not get the ""terminate called without an active exception"" error. However, ImportGvcfs still fails; the failure seems to occur immediately after GenomicsDBImport logs success in importing all batches, in each shard. From all the Cromwell logs it looks like everything is working, but the top level workflow execution fails. I've been trying various configurations of memory, scatter count, and #nodes, so I don't have those log files around still. I can rerun with -DGATK_STACKTRACE_ON_USER_EXCEPTION=true and see if I get anything useful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1295310651:56,validat,validation,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1295310651,1,['validat'],['validation']
Security,I don't know if it's the same issue but we have recently started seeing random 403 errors running dataproc jobs that appear to be internal to GCS dataproc services:. ```; ERROR: (gcloud.dataproc.jobs.submit.spark) HTTPError 403: cwhelan@broadinstitute.org does not have storage.objects.get access to dataproc-ed605f51-8ceb-44f7-b48c-a87bc588c1a6-us/google-cloud-dataproc-metainfo/dbfb2df5-060a-425e-ac31-77484354f264/jobs/0a5c53e9-f935-48f8-a39e-8a46d20b5ec9/driveroutput.000000010.; ```. For us the job keeps running on the dataproc cluster but the error crashes the client program that submitted the job.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735#issuecomment-339034362:290,access,access,290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735#issuecomment-339034362,1,['access'],['access']
Security,I don't think so -- using the API key introduces all sorts of security issues with sanitizing command lines. I think we just want to rely on the default Google credentials.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2402#issuecomment-288549958:62,secur,security,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2402#issuecomment-288549958,2,"['sanitiz', 'secur']","['sanitizing', 'security']"
Security,"I don't think that hiding/disable arguments would work in every case: sometimes, an argument shouldn't be exposed but still available to set programmatically, or maybe just reduce visibility making it `@Hidden` and/or `@Advance`. What is the problem of making an interface for the top-level argument to the GATK? Changing the interface or the `CommadnLineProgram` has the same effect, but the API user can still behave the same as before. It is much more extensible and downstream-friendly. What's about making the `CLPConfigurationArgumentCollection` an interface always returning defaults to be able to change it in a proper way? The cycle of development of a new argument will be: 1) add a new method to the interface with a default returning what will be expected from the previous behaviour, 2) add and return by the argument in the GATK implementation, 3) use the getter in the CLP for perform the operation. This only adds the first point, and operating in 3 classes instead of 3. For API user it is really easy to maintain the previous behavior when upgrading the dependency by just using their own implementation of the class, or include the top-level new arguments by using the GATK implementation. It is much more flexible and extensible (I always think about GATK also as a library). In addition, I think that this approach is also important for evolving GATK. For example, if a new top-level argument is tagged as experimental (still not supported but requested in Barclay), removing it would allow to keep the interface (no version bump) the same and final users can still operate with the experimental argument. The same applies to the `GATKTool` base class (https://github.com/broadinstitute/gatk/issues/4341), and for downstream projects the aim should be to be able to extend safely the `CommandLineProgram` directly to implement their own toolkit using the powerful GATK framework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-366185003:106,expose,exposed,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-366185003,1,['expose'],['exposed']
Security,"I don't think that's the elusive bug we're looking for, but a bit more argument validation certainly cannot hurt. The gradle files look like they're auto-generated, I certainly didn't change them myself. Let me know if you think we should delete them instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-298450921:80,validat,validation,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-298450921,1,['validat'],['validation']
Security,"I don't think we've made any guarantees about the thread safety of Funcotator or the associated datasource classes. . Also, this account seems to be a bot and I can't access its listed home page…. I can audit the class at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7376#issuecomment-891860172:167,access,access,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7376#issuecomment-891860172,2,"['access', 'audit']","['access', 'audit']"
Security,"I found they were incompatible. It seems that the interface isn't match. The error log looks like below. Exception in thread ""main"" java.lang.NoSuchMethodError: scala.collection.Seq.aggregate(Ljava/lang/Object;Lscala/Function2;Lscala/Function2;)Ljava/lang/Object;; at org.bdgenomics.adam.models.NonoverlappingRegions.mergeRegions(NonoverlappingRegions.scala:75); at org.bdgenomics.adam.models.NonoverlappingRegions.<init>(NonoverlappingRegions.scala:55); at org.bdgenomics.adam.models.NonoverlappingRegions$.apply(NonoverlappingRegions.scala:169); at org.bdgenomics.adam.util.TwoBitRecord$.apply(TwoBitFile.scala:193); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.bdgenomics.adam.util.TwoBitFile.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:311); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:1089,Hash,HashMap,1089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,1,['Hash'],['HashMap']
Security,"I get tarballs from github, and then download dependencies and generate the intermediate tarball internally. We never clone git repositories as you might think due to security issues.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584408522:167,secur,security,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584408522,1,['secur'],['security']
Security,I got another report of something similar in the non-spark HaplotypeCaller; stack trace below. ````; java.lang.IllegalStateException: Duplicate key [B@42515a2f; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculationEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:520); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:239); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:244); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:217); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(Com,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018#issuecomment-310805959:251,Hash,HashMap,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018#issuecomment-310805959,2,['Hash'],['HashMap']
Security,"I got it to work by using the runtime switch --disable-sequence-dictionary-validation . . If that is not used it crashes. . . Docker commandline. . /gatk Funcotator --disable-sequence-dictionary-validation \. -R mydata/refs/Homo_sapiens_assembly19.fasta \. -V mydata/P50513_mutect2_filtered.vcf \. -O mydata/P50513_mutect2_funcotator.maf \. --output-file-format MAF \. --data-sources-path mydata/dataSourcesFolder/funcotator_dataSources.v1.6.20190124s/ --ref-version hg19. . . . From: Louis Bergelson <notifications@github.com> ; Sent: Wednesday, October 30, 2019 10:26 AM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: rdbremel <rdbremel017@gmail.com>; Mention <mention@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Funcotator shuts down (#6182). . @rdbremel <https://github.com/rdbremel> This got missed in the churn of issues. Does this happen repeatedly or is it a 1 time occurrence? We've seen similar issues in the past and tried to wrap them all in layers of retries, but sometimes things slip through. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub <https://github.com/broadinstitute/gatk/issues/6182?email_source=notifications&email_token=ANCR2VB4ZCHMAJUHBKE2SP3QRGRQFA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECUTZZI#issuecomment-547962085> , or unsubscribe <https://github.com/notifications/unsubscribe-auth/ANCR2VHRV5JESZYAYX55YHTQRGRQFANCNFSM4I2MRFQA> . <https://github.com/notifications/beacon/ANCR2VAS2WE5TDCUC6G5LETQRGRQFA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECUTZZI.gif>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548102382:75,validat,validation,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548102382,2,['validat'],['validation']
Security,"I guess we need to do some work on the doclet code, abstract out example code and use templates to transform it into the appropriate format/syntax depending what project is generating the documentation. Alternatively and only if documentation html is well formed (xhtml like) then in theory we could use XSLT transformation style sheets to convert embedded code example encoded with xml/xhtml into the concrete syntax. Most major browsers support XSLT. EDIT: The XSLT solution won't probably work since even if we try to change the output from html to xhtml, the fact that we are injecting the javadoc's html would probably break the xhtml.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349724551:580,inject,injecting,580,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349724551,1,['inject'],['injecting']
Security,"I have a run going now. On Jan 4, 2018 15:32, ""samuelklee"" <notifications@github.com> wrote:. > Placeholders for now. We can tweak the actual values once @LeeTL1220; > <https://github.com/leetl1220> checks effect on validation.; >; > Closes #4032 <https://github.com/broadinstitute/gatk/issues/4032>.; > ------------------------------; > You can view, comment on, or merge this pull request online at:; >; > https://github.com/broadinstitute/gatk/pull/4046; > Commit Summary; >; > - Changed default values for ModelSegments segmentation parameters.; >; > File Changes; >; > - *M* src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > ModelSegments.java; > <https://github.com/broadinstitute/gatk/pull/4046/files#diff-0> (6); >; > Patch Links:; >; > - https://github.com/broadinstitute/gatk/pull/4046.patch; > - https://github.com/broadinstitute/gatk/pull/4046.diff; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4046>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk8coObtbYN125S1_BMBx1VnnmbF4ks5tHTVzgaJpZM4RTh_B>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355405908:216,validat,validation,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355405908,1,['validat'],['validation']
Security,"I have been able to get the connector working on GCP VMs where I have manually authenticated locally with my own account. I have not successfully gotten it working on a cromwell VM or ortherwise using manually supplied keyfiles. Anecdotal evidence, but its worth mentioning that both: `fs.gs.impl`; `fs.AbstractFileSystem.gs.impl`; seem to be optional for getting a run to work. It seems to have defaulted to the right things in the trials I've tested (though thats not to say the default will always work). I have put in a question on the issue tracker asking about available authentication inside a pipelines API VM.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500846568:79,authenticat,authenticated,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5996#issuecomment-500846568,2,['authenticat'],"['authenticated', 'authentication']"
Security,"I have four phased variants in close proximity that have the following pattern:. ```; chrA 10 ... GT:PS 0|1:1; chrA 20 ... GT:PS 0|1:2; chrA 30 ... GT:PS 0|1:1; chrA 40 ... GT:PS 0|1:2; ```. These four variants are wholly contained in a single set of reads. There are of course other reads that partially span them. The first variant is a deletion, while the remaining three are SNVs.; Examining the reads, there are two haplotypes since:; 1. Alternate for the 1st and 3rd read; 2. Alternate for the 2nd and 4th read. I would have expected them all to have the same phase set (`PS`) value. I have a test case I can share privately (let me know a good email to send it to confidentially).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6845:671,confidential,confidentially,671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6845,1,['confidential'],['confidentially']
Security,"I have just experienced the same problem of stack overflow with my first attempt to use gatk HaplotypeCallerSpark with the option --spark-master local[*]. My GATK version is 4.1.2.0,that was installed via bioconda. ; Should I wait for the corrected version or is there a way to circumvent the problem with extra install or by using options like --java-options '-XssOptimalValue'?; When is the corrected version expected? Is Q2 (end of June?) still an option? Will it be readily on bioconda then?; Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-499414227:362,Xss,XssOptimalValue,362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-499414227,1,['Xss'],['XssOptimalValue']
Security,"I have noticed that when running spark tools (e.g. CountReadsSpark or MarkDuplicatesSpark) that running with an input in the form ""CountReadsSpark -I gs://my-bucket-dir/my-file.bam."" The tool crashes with the following unhelpful stacktraces:. ```; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:208); 	at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:70); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1825); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1012); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:975); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2687); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2669); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:500); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:469); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1084); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1072); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.SparkContext.withScope(SparkContext.scala:679); 	at org.ap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:283,access,access,283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['access'],['access']
Security,"I have tested this with a fresh `gcloud` client and have not been able to reproduce the error. I did find an article from someone else who got the `400: invalid_grant` error: https://blog.timekit.io/google-oauth-invalid-grant-nightmare-and-how-to-fix-it-9f4efaf1da35. The long and short of it is that it's an authentication issue. Can you verify that the authentication you're using on the terminal is valid? That is, can you get at other public resources on gcloud?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-725097056:309,authenticat,authentication,309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-725097056,2,['authenticat'],['authentication']
Security,"I have three main reasons to propose to move the arguments in CLP to an argument collection that is configurable by downstream tools/projects:. 1. Support hiding some arguments for downstream projects. For example, I do not want to support a config file by the user, but rather decide the settings for the framework and expose only some configuration.; 1. Set custom defaults for some downstream tools (including GATK). For example, a concrete tool might want to force the temp directory to be specified to avoid failures due to no space (and specify that in the documentation).; 1. Support old-style arguments (not kebab-case) for downstream projects that rely on the current argument definitions. I am specially affected by this one, because updating GATK to the 4.0.0 release of January will be a breaking change that will cause some nightmares for my users - and I don't want to do a major version bump yet (I have to re-work a bit my own framework before it). Thus, the first commit of this PR holds the proposal for the new argument collection. As I know that the team is also trying to normalize arguments and documentation, I included two more commits to help with the task (they can be removed if you think that it is better after the argument collection):; * Use `java.nio.Path` for temp directories (to support temp directories in HDFS, for example); * Change arguments moved to the collection to kebab-case (to help with #3853)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998:320,expose,expose,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998,1,['expose'],['expose']
Security,"I have to deal with this component recently and I found the design rather awkward.... In general between GATK and htsjdk we don't seem to have a proper support for managing and querying Supplementary alignment information from read alignment records:. 1. Querying: implemented in htsjdk consists in forging artificial SAMRecords that contain only the alignment info in the SA tag element... It seems to me that it makes more sense to create class to hold this information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder already has defined a private inner class with that in mind ""SARead"" so why not flesh it out and make it public. 2. Writing: currently SATagBuilder gets attached to a read, parsing its current SA attribute content into SARead instances. It provides the possibility adding additional SAM record one by one or clearing the list. ... then it actually updates the SA attribute on the original read when a method (setTag) is explicitly called.; I don't see the need to attach the SATag Builder to a read... it could perfectly be free standing; the same builder could be re-apply to several reads for that matter and I don't see any gain in hiding the read SA tag setting process,... even if typically this builder output would go to the ""SA"" tag, perhaps at some point we would like to also write SA coordinate list somewhere else, some other tag name or perhaps an error message... why impose this single purpose limitation?; I suggest to drop the notion of a builder for a more general custom ReadAlignmentInfo (or whatever name) list. Such list could be making reference to a dictionary to validate its elements, prevent duplicates, keep the primary SA in the first position... etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3324:1622,validat,validate,1622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324,1,['validat'],['validate']
Security,"I haven't been able to reproduce @vdauwera error, but there are issues with the https checkout at the moment. ; There's one annoying issue witwhere it will prompt for a password before every individual file download. This will be fixed in https://github.com/github/git-lfs/issues/755. It can be worked around by using `git config credential.helper cache` but the easiest thing to do at the moment is just using the ssh checkout. . I need to investigate what happens with ssh checkout if you don't have a key set up.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/952#issuecomment-150376513:169,password,password,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/952#issuecomment-150376513,1,['password'],['password']
Security,"I implemented @lbergelson's suggestion with a new method: `validateArg(final boolean condition, final Supplier<String> msg)` invoked as eg `Utils.validateArg(n > 0, () -> String.format(""You have chosen the worst value ever, name %d,"", n))`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1979#issuecomment-232122503:59,validat,validateArg,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1979#issuecomment-232122503,2,['validat'],['validateArg']
Security,I just added you so you should have access now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2043#issuecomment-235077255:36,access,access,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2043#issuecomment-235077255,1,['access'],['access']
Security,I noticed some classes that were unused in hellbender.; This exposed some others that were only referenced by unused classes. Made slight cosmetic modification to OpticalDuplicateFinder as well,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/780:61,expose,exposed,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/780,1,['expose'],['exposed']
Security,"I noticed that `VcfUtils.getSortedSampleSet` takes a `GenotypeMergeType`. The only case it looks at is `UNIQIFY`. You would expect that calling `getSortedSampleSet(someHeaderWithDuplicateSamples, GenotypeMergeType.REQUIRE_UNIQUE)` should throw, but instead it silently continues. . ex, the following test passes just fine:; ```; @Test; public void testGetSortedSampleSet(){; final HashMap<String, VCFHeader> headers = new HashMap<>();; headers.put(""track1"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));; headers.put(""track2"", new VCFHeader(Collections.emptySet(), Sets.newSet(""sample1"")));. final SortedSet<String> sortedSampleSet = VcfUtils.getSortedSampleSet(headers, GATKVariantContextUtils.GenotypeMergeType.REQUIRE_UNIQUE);; }; ```. The method is also lacking any tests or javadoc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3744:381,Hash,HashMap,381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3744,2,['Hash'],['HashMap']
Security,"I noticed that the PairHMM implementation argument is hidden in `LikelihoodEngineArgumentCollection` for some reason. Shouldn't it be exposed as an advanced argument people can choose what pair hmm they want?. It's also present in the `UnifiedArgumentCollection`, but it's never used from there. ```; /**; * The PairHMM implementation to use for genotype likelihood calculations. The various implementations balance a tradeoff of accuracy and runtime.; */; @Hidden; @Argument(fullName = ""pair_hmm_implementation"", shortName = ""pairHMM"", doc = ""The PairHMM implementation to use for genotype likelihood calculations"", optional = true); public PairHMM.Implementation pairHMM = PairHMM.Implementation.FASTEST_AVAILABLE;; ```. It seems like we should remove it from the `UnifiedArgumentCollection` and make it either a normal argument or an advanced argument in the `LikelihoodEngineArgumentCollection`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3553:134,expose,exposed,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3553,1,['expose'],['exposed']
Security,"I prepared a clean Bam file following GATK Best Practice and used GATK4 HaplotypeCaller to create a gvcf with ploidy1 option:. '''; gatk-4.0.2.1/gatk HaplotypeCaller --native-pair-hmm-threads 24 -I KU_filtered_sorted_mdup.bam -O HC.KU.raw.snps.indels.g.vcf -R ref.fasta -ploidy 1 --emit-ref-confidence GVCF; '''. When I validated the gvcf, ValidateVariants threw errors at the end:. '''; <br />11:27:55.681 INFO ProgressMeter - Traversal complete. Processed 124689522 total variants in 3.8 minutes.; 11:27:55.681 INFO ValidateVariants - Shutting down engine; [April 10, 2018 11:27:55 AM JST] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 3.82 minutes.; Runtime.totalMemory()=4682940416; java.lang.IllegalArgumentException: Illegal character in path at index 15:HC.KU.raw.snps.indels.g.vcf; at java.net.URI.create(URI.java:852); at org.broadinstitute.hellbender.engine.FeatureInput.makeIntoAbsolutePath(FeatureInput.java:242); at org.broadinstitute.hellbender.engine.FeatureInput.toString(FeatureInput.java:314); at java.util.Formatter$FormatSpecifier.printString(Formatter.java:2886); at java.util.Formatter$FormatSpecifier.print(Formatter.java:2763); at java.util.Formatter.format(Formatter.java:2520); at java.util.Formatter.format(Formatter.java:2455); at java.lang.String.format(String.java:2940); at org.broadinstitute.hellbender.engine.FeatureDataSource.close(FeatureDataSource.java:589); at org.broadinstitute.hellbender.engine.FeatureManager.lambda$close$9(FeatureManager.java:505); at java.util.LinkedHashMap$LinkedValues.forEach(LinkedHashMap.java:608); at org.broadinstitute.hellbender.engine.FeatureManager.close(FeatureManager.java:505); at org.broadinstitute.hellbender.engine.GATKTool.onShutdown(GATKTool.java:857); at org.broadinstitute.hellbender.engine.VariantWalker.onShutdown(VariantWalker.java:95); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4657:320,validat,validated,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4657,4,"['Validat', 'validat']","['ValidateVariants', 'validated']"
Security,"I ran GATK 4.1.0.0 Mutect2 on a small (~1Mb) targeted panel. I am using a normal control that is not the same individual (basically to exclude technical artifacts), so I do expect to see more variants than with a proper matched normal. I was getting around 100-300 variants per sample with GATK 4.0.6.0. I am still roughly in the same range for some samples GATK 4.1.0.0, but I am getting 0 for some. The problem seems to be at the FilterMutectCalls stage where I am seeing the following error:; ```; [March 19, 2019 10:43:17 PM EDT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=8851030016; java.lang.IllegalArgumentException: errorRate must be good probability but got NaN; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:227); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:211); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyContaminationFilter(Mutect2FilteringEngine.java:79); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:518); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$For",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821:801,validat,validateArg,801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821,1,['validat'],['validateArg']
Security,"I ran across a weird case the other day that I wanted to document here.; ` final Set<VCFHeaderLine> headerInfo = new HashSet<>();; headerInfo.addAll(getHeaderForVariants().getMetaDataInInputOrder());; headerInfo.add(GATKVCFHeaderLines.getFilterLine(GATKVCFConstants.LOW_HET_FILTER_NAME));; vcfWriter = createVCFWriter(new File(outputVcf));; vcfWriter.writeHeader(new VCFHeader(headerInfo));; `; Setting up the header this way end up with no genotypes in the output vcf. This is because the sample line is not included in the headerInfo, it is maintained as a separate field in the VCFHeader object. To resolve this issue the last line needed to be:; ` vcfWriter.writeHeader(new VCFHeader(headerInfo, getHeaderForVariants().getSampleNamesInOrder()));; `",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6048#issuecomment-582452360:117,Hash,HashSet,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6048#issuecomment-582452360,1,['Hash'],['HashSet']
Security,"I ran the full test suite using a [branch](https://github.com/broadinstitute/gatk/tree/cn_check_cache_thrash) that throws if a tool ever tries to query the FeatureCache using a query interval that is earlier than, but on the same contig as, the one currently cached. Several tests [failed](https://travis-ci.org/broadinstitute/gatk/builds/422089722), including a few of the Funcotator ones:. FuncotatorIntegrationTest.exhaustiveArgumentTest; FuncotatorIntegrationTest.testFuncotatorWithoutValidatingResults; FuncotatorIntegrationTest.testVcfDatasourceAccountsForAltAlleles; FuncotatorIntegrationTest.testVcfMafConcordance. These may be test artifacts, but we should audit the Funcotator cache access patterns and see if this is actually causing thrashing that affects performance. Since the FeatureCache caching strategy assumes queries will be forward-only, it might be an indication that Funcotator performance could be improved by either turning off caching or using an alternative cache strategy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5143:666,audit,audit,666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5143,2,"['access', 'audit']","['access', 'audit']"
Security,I recommend we error out when provided with `--validation-type-to-exclude ALL`. It doesn't make sense - why call the validator if you're not going to validate?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-485714312:47,validat,validation-type-to-exclude,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-485714312,3,['validat'],"['validate', 'validation-type-to-exclude', 'validator']"
Security,"I reproduced various out of memory errors in a Linux VM with 4G of RAM, both with the `IntelInflaterDeflaterIntegrationTest` enabled and disabled. Most resulted in the kernel killing the Java process, like this one (from `dmesg`):; ```; [38425.759992] Out of memory: Kill process 10295 (java) score 747 or sacrifice child; [38425.759998] Killed process 10295 (java) total-vm:7885212kB, anon-rss:3250892kB, file-rss:0kB; ```. Some were caught by the JVM, like this one:; ```; #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 90177536 bytes for committing reserved memory.; # Possible reasons:; # The system is out of physical RAM or swap space; # In 32 bit mode, the process size limit was hit; # Possible solutions:; # Reduce memory load on the system; # Increase physical memory or swap space; # Check if swap backing store is full; # Use 64 bit Java on a 64 bit OS; # Decrease Java heap size (-Xmx/-Xms); # Decrease number of Java threads; # Decrease Java thread stack sizes (-Xss); # Set larger code cache with -XX:ReservedCodeCacheSize=; # This output file may be truncated or incomplete.; #; # Out of Memory Error (os_linux.cpp:2627), pid=20484, tid=139679452493568; #; # JRE version: Java(TM) SE Runtime Environment (8.0_72-b15) (build 1.8.0_72-b15); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.72-b15 mixed mode linux-amd64 compressed oops); # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; ```. Here's my theory of what's happening. The `maxHeapSize` for test JVMs is set to 4G in `build.gradle`:; ```; maxHeapSize = ""4G""; ```. A 4G max heap size is too high for systems with 4G of RAM, because the Java heap grows until the system runs out of memory. If we decrease `maxHeapSize`, the GC should prevent the Java heap from growing too large, with the trade-off of more GC calls. I changed the `maxHeapSize` to `2G` a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288423316:1059,Xss,Xss,1059,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288423316,1,['Xss'],['Xss']
Security,"I reran the workflow, this time allocating 200GB RAM to tmp in the slurm job, everything else exactly the same, and got the ""terminate called without an active exception"" failure again, so that error was not due to the gvcf that failed VCF validation as it was not included. This time, shard 9 succeeded in ImportGvcfs and also successfully completed GenotypeGVCFs. I have attached the top level stdout and stderr logs for the slurm job, and the stdout.background and stderr.background logs from shard 3 of ImportGvcfs. No java error log was present on any of the ImportGvcfs shards' execution directories, and all except shard 9 had rc=250.; [ImportGvcfsWithTmpError.tar.gz](https://github.com/broadinstitute/gatk/files/9911311/ImportGvcfsWithTmpError.tar.gz)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1298661994:240,validat,validation,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1298661994,1,['validat'],['validation']
Security,I run like this:. ```; ./src/main/java/org/broadinstitute/hellbender/tools/validation/validate-reads-spark-pipeline.sh src/test/resources/org/broadinstitute/hellbender/tools/validation/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam src/test/resources/large/human_g1k_v37.20.21.fasta src/test/resources/large/human_g1k_v37.20.21.2bit src/test/resources/large/dbsnp_138.b37.20.21.vcf throwOnDiff saveIntermediateFiles; ```. And it fails like this:. ```; -----------CompareMatrix summary------------; diff count %total; -24 101 0.0662; -23 39 0.0256; -22 10 0.0066; 0 152210 99.8033; 22 10 0.0066; 23 39 0.0256; 24 101 0.0662. ---------CompareMatrix full matrix (non-zero entries) ----------; QRead1 QRead2 diff count; 2 2 0 15922; 2 24 -22 10; 2 25 -23 39; 2 26 -24 101; 4 4 0 41; 5 5 0 35; 21 21 0 16; 22 22 0 7443; 23 23 0 7881; 24 2 22 10; 24 24 0 37073; 25 2 23 39; 25 25 0 20772; 26 2 24 101; 26 26 0 43841; 27 27 0 16358; 28 28 0 2828; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1922#issuecomment-226819228:75,validat,validation,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1922#issuecomment-226819228,3,['validat'],"['validate-reads-spark-pipeline', 'validation']"
Security,"I see that this is occurring in the mitochondrial chromosome. The model was trained mostly with the autosomes and so scores on the mitochondrial DNA have not been extensively validated. That said, this looks like a bug and we hope to have a fix in soon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4727#issuecomment-387737569:175,validat,validated,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4727#issuecomment-387737569,1,['validat'],['validated']
Security,"I see the exception on most chromosomes, here's the one for chr1:. java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:79293873 end:79293872; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095:207,validat,validateArg,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095,2,['validat'],"['validateArg', 'validatePositions']"
Security,"I see, thanks for pointing this out. We need to run; ```; git archive --format tar.gz --prefix gatk-{hash} -o gatk-{hash}.tar.gz {hash}; ```; to retrieve and archive the files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584477699:101,hash,hash,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584477699,3,['hash'],['hash']
Security,"I set TEST_TYPE to ""all"" and was able to run this test without failure. The command I used is:; ```; ./gradlew test --tests org.broadinstitute.hellbender.utils.nio.GcsNioIntegrationTest.openPublicFile; ```; I ran it 10 times and got the same result every time:; `BUILD SUCCESSFUL`. It looks like this was a transient problem: either the internet connection was stalled or the authentication server was down temporarily. As this happens at the very beginning of the execution, it's probably not a very big deal: the user can just retry. Incidentally, PR #2506 that is under review lengthens the connection timeouts, if I am not mistaken. This will probably make the problem less likely to reoccur.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514#issuecomment-288852260:376,authenticat,authentication,376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514#issuecomment-288852260,1,['authenticat'],['authentication']
Security,"I spoke too soon. No matter how I define the type, whether String or File, when I run womtools validate I get the error:. ```; ERROR: Value for this attribute is expected to be a string:. bam: {; ```. I added the following parameter_meta field to the task:. ![screenshot 2018-11-08 18 02 03](https://user-images.githubusercontent.com/11543866/48232693-7569ff00-e380-11e8-9dad-2eed3ca68118.png). How to correct this @cjllanwarne? Here's the relevant WDL: https://github.com/broadinstitute/gatk/blob/4.0.11.0/scripts/cnv_wdl/cnv_common_tasks.wdl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-437188313:95,validat,validate,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-437188313,1,['validat'],['validate']
Security,"I suggest copying the test file. Shared test files can lead to trouble. On Sunday, June 14, 2015, cmnbroad notifications@github.com wrote:. > Based on the TODO that was in ReadsDataSource.java, I exposed a; > SamReaderFactory parameter for ReadsDataSource rather than limit it to just; > validation stringency.; > ; > Whats the right protocol for adding a test that uses a test file from; > another package (I'm reaching into the picard test data for a data file for; > ; > ## an engine test). Alternatively, is there a better way to test this change ?; > ; > You can view, comment on, or merge this pull request online at:; > ; > https://github.com/broadinstitute/hellbender/pull/565; > Commit Summary; > - Enable setting validation stringency in ReadsDataSource.; > ; > File Changes; > - _M_; > src/main/java/org/broadinstitute/hellbender/engine/ReadsDataSource.java; > https://github.com/broadinstitute/hellbender/pull/565/files#diff-0; > (38); > - _M_; > src/test/java/org/broadinstitute/hellbender/engine/ReadsDataSourceUnitTest.java; > https://github.com/broadinstitute/hellbender/pull/565/files#diff-1; > (25); > ; > Patch Links:; > - https://github.com/broadinstitute/hellbender/pull/565.patch; > - https://github.com/broadinstitute/hellbender/pull/565.diff; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/pull/565. ## . Sent from Gmail Mobile",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/565#issuecomment-111864608:196,expose,exposed,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/565#issuecomment-111864608,3,"['expose', 'validat']","['exposed', 'validation']"
Security,"I suppose that you are going to try to set up the automated tests on PPC. If the test environment is set up, the native libraries can live in the same repo.; @droazen @akiezun Did you not get access a PPC service?. It is useful to keep the source files under a single tree (with the common and cpu-specific parts as I explained) from the view point of maintenance and another porting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-217069817:192,access,access,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-217069817,1,['access'],['access']
Security,"I suppressed the warnings we were getting. If we can't fix them lets at least not see them.; It seemed like it was ok to suppress the serialization warnings rather than provide a UUID, since java will fill one in for us. We can add a hash value instead if that's better.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/84:234,hash,hash,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/84,1,['hash'],['hash']
Security,"I terms of comparing implementations in this particular instance, the entire BAM file is also being scanned, so there is no additional limitation in using Parquet. In general, though, there are some additional complications for typical Hadoop data sets due to their distributed nature. There are multiple methods for accelerating lookups, depending on the particular application and what kind of latency you need. A few of them:; - Data set partitioning in the style of Hive, where you split your data set into a directory hierarchy that's based on the values of one of the columns. This is like building an index, and should be done on cols that feature in lot of predicates. In the quince repo that we're using for ingest, we are partitioning the data based on genome locus. This makes it easy to access the data only from the locus of interest.; - Parquet supports predicate pushdown and column stats on its row chunks, so the more you homogenize the data (e.g., by sorting), the more likely it is you can skip large blocks of data.; - The parquet file format supports the concept of indexing (though I don't think it is implemented yet in any of the packages that read/write it); - For particular applications, you can also use a different storage backend like HBase or Kudu that allow very rapid point/range queries at scale. I believe GEL is planning on trying out HBase for some of their applications; - The Hammerbacher lab and the ADAM folks are also working on tools for BAM file indexing and visualization that scales on Hadoop. I think the projects are cycledash/pileup.js and mango, respectively.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1067#issuecomment-152446541:799,access,access,799,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1067#issuecomment-152446541,1,['access'],['access']
Security,"I think all of our dataflow / spark code is at least almost entirely using `GATKRead`. GATKRead is designed to not provide access to the header because it's not available from a google `Read` backed `GATKRead`. It sounds like there is some information that `Read` includes that is missing from a headerless `SAMRecord`. I think we could audit the `SAMRecordToGATKReadAdaptor` to find any places it touches the header and then cache that information in the adaptor before stripping the header. We don't need to add back in the headers at any point, because we provide library functions to perform any header related operation with a provided header.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141107659:123,access,access,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141107659,2,"['access', 'audit']","['access', 'audit']"
Security,"I think even more important is that they share the reference genome that they are using. Get Outlook for Android<https://aka.ms/AAb9ysg>; ________________________________; From: Gökalp Çelik ***@***.***>; Sent: Wednesday, April 24, 2024 12:28:39 AM; To: broadinstitute/gatk ***@***.***>; Cc: Ilya Soifer ***@***.***>; Assign ***@***.***>; Subject: Re: [broadinstitute/gatk] Prevent users enabling annotations with mismatching data type (flow etc) (Issue #8788). Assigned #8788<https://github.com/broadinstitute/gatk/issues/8788> to @ilyasoifer<https://github.com/ilyasoifer>. —; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/8788#event-12581899218>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AGDPRCP66IKPOBF2GPENP6LY63HAPAVCNFSM6AAAAABGTGMBPWVHI2DSMVQWIX3LMV45UABCJFZXG5LFIV3GK3TUJZXXI2LGNFRWC5DJN5XDWMJSGU4DCOBZHEZDCOA>.; You are receiving this because you were assigned.Message ID: ***@***.***>. ________________________________. CONFIDENTIALITY NOTICE: This message (including any attachments) should be presumed to contain confidential, proprietary, privileged and/or private information. Information contained in this message is intended only for the recipient(s) named above. Any disclosure, reproduction, distribution or other use of this message or any attachments by any unauthorized individual or entity is strictly prohibited. If you have received this message in error, please notify the sender immediately, and delete the message and any attachments. Learn more about Ultima Genomics’ Privacy Policy<https://www.ultimagenomics.com/privacy-policy>.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8788#issuecomment-2074020625:1003,CONFIDENTIAL,CONFIDENTIALITY,1003,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8788#issuecomment-2074020625,2,"['CONFIDENTIAL', 'confidential']","['CONFIDENTIALITY', 'confidential']"
Security,"I think for SQ you could limit the lines you write out to the contigs that are covered in your intervals list, ignore the rest. So you can access that info as soon as you've parsed the command line. Or if you're running without an intervals list you could supply a seq dict file through a separate arg. But the former seems safer. . For other modes: EXTREME would hardcode what we consider required. Then you could potentially do ARBITRARY to allow passing strings for specific attributes that you want to drop. . None of these would have to depend on what's in the calls, I think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2233#issuecomment-266059687:139,access,access,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2233#issuecomment-266059687,1,['access'],['access']
Security,"I think it still needs to be run through an QA process independent from the dev team . There may be options, details etc that we don't do exactly how production does. Things coming to mind (there's surely much more):; - test splitting input in in many ways (the same exact way as production does); - generation of md5 (we're not doing it yet); - the PG tag in the header (we're not writing one yet); - validate that the original qualities are preserved exactly (i;ve not done it as part of this validation); - testing memory consumption and resource consumption - that's something that only someone close to production can measure/answer in the same environment in which production runs. I'm running on very different env. etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1413#issuecomment-188597920:402,validat,validate,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1413#issuecomment-188597920,2,['validat'],"['validate', 'validation']"
Security,"I think it triggers in certain situations where a firewall is blocking the connection. If the internet is simply unreachable it doesn't happen, so I don't know what the exact error case is. It happened consistently for people inside Intel's firewall or vpn. . An option to disable gcs support isn't a bad idea, it's kind of a hack though, it would be better if we could understand and avoid triggering the problem. If we could only initialize GCS support when we are sure that we actually are accessing files from google that could be a useful, but it doesn't seem like there's any single point we can plug into to detect that, it would have to be spread over everything that uses paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141:50,firewall,firewall,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141,3,"['access', 'firewall']","['accessing', 'firewall']"
Security,"I think that `DIRECT` should only give access to walker impls. Anything Spark should use spark-submit or gcs. So if you're running a local Spark tool, you would use `--runner SPARK --master local[3]`. Then you never need the additional sparkMaster option.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1329#issuecomment-164065760:39,access,access,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1329#issuecomment-164065760,1,['access'],['access']
Security,"I think that each tool should either emit proper error messages, or deal with the data it's given. currently BQSR emits a cryptic error message so I think that this PR is an improvement regardless of whether the pipeline is sanitized. . That said, I think that it might be a good idea to make ValidateSamFile break on non-ACGTN bases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-642719900:224,sanitiz,sanitized,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-642719900,2,"['Validat', 'sanitiz']","['ValidateSamFile', 'sanitized']"
Security,"I think that it is necessary to have a way for downstream projects to override some of the top-level arguments in the base CLP class. For example, the config file is for documentation purposes, but I don't want to expose users to that argument because I will set the defaults programmatically. Another example is the GCS retries, which might not be useful for a software that is not planning to support GCS even if it is already implemented (or does not want to expose). As a downstream developer, for me it is important to being able to configure arguments and expose/hide them to my final users; with the current implementation, my main issue is to have an argument that are irrelevant for the toolkit user and that I get questions about why and how to use them (the most clear example, the config file). If the main problem is to change an interface, a default value for new methods can be added to keep the same behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361876183:214,expose,expose,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361876183,3,['expose'],['expose']
Security,"I think that it would be fine to have both legacy and modern styles in the; examples, but I think having gatk in the picard docs will not pass review. On Tue, Dec 5, 2017 at 10:41 PM, sooheelee <notifications@github.com> wrote:. > It would be nice to have a few Picard tools that we feature in BPWs (e.g.; > MarkDuplicates) show both syntaxes:; >; > 1. java -jar picard.jar ValidateSamFile I=reads.bam MODE=SUMMARY; > 2. gatk ValidateSamFile -I reads.bam -MODE=SUMMARY; >; > I assume MODE gets one dash and not two, but really I don't know. So; > having such examples scattered throughout the tool chest for most often; > used tools would be great.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349522774>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0ht41UsGHu_2TgrbKKNJwDepEdMZks5s9gz4gaJpZM4QitCF>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349642831:374,Validat,ValidateSamFile,374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349642831,2,['Validat'],['ValidateSamFile']
Security,"I think that this is a nice feature (at least for me) and not a bug. For example, if in GATK someone runs a tool with `-RF read_filters.args`, then the pipeline cannot be reproduced in a different dataset unless the file is accessible. I can understand that it could be also nice to preserve the `-RF read_filters.args` to be able to modify the file an re-run the tool with different parameters, but for me the purpose of storing the command line in the header or other places is keep track of the exact params that I used: if a file is modified, then it is impossible to trace the params. For input files, this is expected (if the input has changed, it is expected that the result change), but for arguments it shouldn't be the case (independently of the file changing, the tool was running with exactly that parameters). I vote for solve this in Barclay in a configurable way, to allow users to decide which kind of verbosity of the command line they want (I definitely prefer to expand as currently).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3797#issuecomment-342798092:224,access,accessible,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3797#issuecomment-342798092,1,['access'],['accessible']
Security,"I think that this is part of wider need to for dependency-injection in tools; often the initialize() method might be loaded with instantiation of components that themselves require some user argument inputs.. can this be done in a more declarative fashion? . For example... HC, UG or GenotypeGVCFs the have annotationEngine or genotypingEngine components that are explicitly initialized in initialize() what if the engine is responsible to instantiate them and add the appropriate arguments to the command line which are declared in the corresponding classes rather than in the tool (or a synthetic argument collection class)?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/96#issuecomment-69810912:58,inject,injection,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/96#issuecomment-69810912,1,['inject'],['injection']
Security,"I think the `Optimized` version deals with avoiding replicating reads in a more nuanced manner, but if I understand correctly, it doesn't seem to me to avoid the shuffle. It looks like it essentially ignores the concept of data locality entirely, and potentially transfers a lot of data over the network. (Equivalent to performing a shuffle on a sorted file in HDFS.). IMO, the current ""shuffle"" implementation is already a ""Spark-y"" way to do it, but with multiple inefficiencies:; - Reads/variants are keyed to their corresponding shards, replicating reads if they cross over shard boundaries. This necessitates an `aggregateByKey` operation that potentially reshuffles the entire data set at the end to deal with neighboring shards that could be hashed to different machines.; - The impl uses `cogroup` and `groupByKey`, which require materializing all values for a key in memory (which could be large). Best to avoid these if possible.; - And related to the previous issue, the join strategy for reads and variants is basically a cross-product-and-filter, which is not very efficient, especially considering that the data can be ordered. I think the best implementation here would steal JP's method of sharding the reads/variants, but make use of `repartitionAndSortWithinPartition`, which lets you specify what partition to use and also sorts all the values within a given partition. This means that we could employ a sort-merge on each partition, and only scan through the datasets once after shuffling them. Do you already have an impl for doing a sort-merge of `Locatable`s? These can be a bit tricky. I wrote one for the `ShuffleRegionJoin` impl in ADAM, but there are semantic differences that would make it less efficient to use. (Specifically, it would require the `aggregateByKey` operation and also creating `SimpleInterval`-style objects from a separate model.). Finally, I would also add the ability to specify which join strategy to use separately for the reference bases and the vari",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1007#issuecomment-151721602:749,hash,hashed,749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1007#issuecomment-151721602,1,['hash'],['hashed']
Security,"I think the issue might be that you need a ` -- ` between the gatk options on the left, and the spark specific options on the right. This is a confusing artifact of how our arg parsing works and the fact that the gatk-launch script needs a way of finding the spark options but doesn't have access to our java parser. (we're planning on fixing that in the near future, but no good time line) . Could you try:; ```; /home/axverdier/Tools/GATK4/gatk-4.beta.6/gatk-launch CountReadsSpark --programName gatk4-testing --input hdfs://spark01:7222/user/axverdier/data/710-PE-G1.bam --output hdfs://spark01:7222/user/axverdier/testOutGATK_CountReadsSpark --javaOptions -Dmapr.library.flatclass -- --sparkRunner SPARK --sparkMaster yarn --deploy-mode cluster; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350064538:290,access,access,290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350064538,1,['access'],['access']
Security,"I think the piece we need is just the parser, though -- we can keep the Picard code that injects values into instance variables & parses the annotations, etc., we just need something to go from the raw args array into a parsed set of names + values.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/72#issuecomment-69632895:89,inject,injects,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/72#issuecomment-69632895,1,['inject'],['injects']
Security,"I think there are two points to this issue: 1. validation or no-validation and 2. need to pass GenomeLocParser around... . Is 1. about performance? otherwise we prefer to have validated locations, right? and If it is about performance I think it should be shown that it really makes a difference to remove those checks. About, 2., can be solved by being able to recover the sequence-dictonary/reference object (called Reference from this point on) from a genome loc and then you can ask it for a new genome-loc if the appropriate methods are added instead of depending on that annoying middle man called GenomeLocParser. I would say that is unlikely to be in the situation where you want to create a GenomeLoc out of the blur without having already a reference to another GenomeLoc or Reference object available. It is an issue if GenomeLoc holds on to a reference to the Reference object? (or the instantiating class is a inner class of the Reference?)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69802695:47,validat,validation,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69802695,3,['validat'],"['validated', 'validation']"
Security,I think we need someone with admin access to do this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/740:35,access,access,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/740,1,['access'],['access']
Security,I took over #5367 but since I don't have access to your fork @magicDGS I have created a second branch with my changes. Closes #4860,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5655:41,access,access,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5655,2,['access'],['access']
Security,"I tried clearing my caches and rebuilding, but I resolve everything. I noticed that our artifactory website looks much different today than it did yesterday. I wonder if it was down temporarily for an update. Maybe try again now? Unless they put it behind the firewall which would be a disaster... can you access https://artifactory.broadinstitute.org/?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2579#issuecomment-292587641:260,firewall,firewall,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2579#issuecomment-292587641,2,"['access', 'firewall']","['access', 'firewall']"
Security,"I tried this branch out and got the dreaded 404 error, unfortunately:. ```; $ ./gatk-launch CountReadsSpark -I gs://hellbender/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam -- --sparkRunner GCS --cluster droazen-test-cluster --executor-cores 2 --num-executors 2; Using GATK jar /Users/droazen/src/hellbender/build/libs/gatk-package-4.beta.6-54-g0ee99da-SNAPSHOT-spark.jar; jar caching is disabled because GATK_GCS_STAGING is not set. please set GATK_GCS_STAGING to a bucket you have write access too in order to enable jar caching; add the following line to you .bashrc or equivalent startup script. export GATK_GCS_STAGING=gs://<my_bucket>/. Replacing spark-submit style args with dataproc style args. --cluster droazen-test-cluster --executor-cores 2 --num-executors 2 -> --cluster droazen-test-cluster --properties spark.driver.userClassPathFirst=true,spark.io.compression.codec=lzf,spark.driver.maxResultSize=0,spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.kryoserializer.buffer.max=512m,spark.yarn.executor.memoryOverhead=600,spark.executor.cores=2,spark.executor.instances=2. Running:; gcloud dataproc jobs submit spark --cluster droazen-test-cluster --properties spark.driver.userClassPathFirst=true,spark.io.compression.codec=lzf,spark.driver.maxResultSize=0,spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 ,spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:504,access,access,504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['access'],['access']
Security,"I was able to download the gnomAD VCFs with a gsutil cp command within a; couple hours of the remote funcotator failures. --; Alan Hoyle - alan@alanhoyle.com - alanhoyle.com; ------------------------------; *From:* Jonn Smith <notifications@github.com>; *Sent:* Tuesday, November 10, 2020 9:59:06 PM; *To:* broadinstitute/gatk <gatk@noreply.github.com>; *Cc:* Alan Hoyle <alan@alanhoyle.com>; Mention <mention@noreply.github.com>; *Subject:* Re: [broadinstitute/gatk] Funcotator with gnomAD enabled crashes; with Bad Request (#6926). I have tested this with a fresh gcloud client and have not been able to; reproduce the error. I did find an article from someone else who got the 400: invalid_grant; error:; https://blog.timekit.io/google-oauth-invalid-grant-nightmare-and-how-to-fix-it-9f4efaf1da35; <https://www.google.com/url?q=https://blog.timekit.io/google-oauth-invalid-grant-nightmare-and-how-to-fix-it-9f4efaf1da35&source=gmail-imap&ust=1605668351000000&usg=AOvVaw03ZXI9QiPy1AFI5zfsFIjB>. The long and short of it is that it's an authentication issue. Can you; verify that the authentication you're using on the terminal is valid? That; is, can you get at other public resources on gcloud?. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub; <https://www.google.com/url?q=https://github.com/broadinstitute/gatk/issues/6926%23issuecomment-725097056&source=gmail-imap&ust=1605668351000000&usg=AOvVaw0sZboplCCqclv3xBdQk3Fb>,; or unsubscribe; <https://www.google.com/url?q=https://github.com/notifications/unsubscribe-auth/AACGX433BU42UPHZTKQLTBTSPH4XVANCNFSM4TD2FDGA&source=gmail-imap&ust=1605668351000000&usg=AOvVaw0n415Vb2d-0gOnEk9wramu>; .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-728261716:1038,authenticat,authentication,1038,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-728261716,2,['authenticat'],['authentication']
Security,I wasn't able to reproduce this exact issue. However at least I can make the error message a bit more user-friendly (submitting #2417 for review). Crucially this will now give the name of the file we're having issues with (thus removing the uncertainty about whether it's the data or the index file we cannot access).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281515286:309,access,access,309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281515286,1,['access'],['access']
Security,"I would like to keep in some of my tools the read group arguments in sync with the `AddOrReplaceReadGroup` in picard, but currently there is no way of access them. This is a very simple and trivial patch to extract the short/long names to a static String variable to be able to use them. In addition, I refactored the variable names to the camel-case java convention.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2260:151,access,access,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2260,1,['access'],['access']
Security,"I would like to specify what passing a `ReadFilter` to some of my tools means, so maybe passing an `ArgumentCollection` will be simpler than this one, I agree. Although #2085 may solve the issue regarding the `ReadTransformer`/`ReadFilter` ordering, I would like to have in the plugin a way to specify different parameters (maybe some of then hidden before expose to users or advanced in the case of disabling). I will open a new PR for that change, but I will really appreciate if I can get something like that in this and other plugins (if implemented).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-275082983:357,expose,expose,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-275082983,1,['expose'],['expose']
Security,"I'd also be hesitant to break the previous expectation that IntervalArgumentCollection contains a non-empty list of intervals. If I understand correctly (and apologies if not, I'm glancing at the repo between paternity-leave duties and am quite sleep deprived!), all calling code would have to add an explicit check that the new option isn't enabled or risk failing ungracefully downstream. For CNV code, this might be as simple as changing the validation method `CopyNumberArgumentValidationUtils.validateIntervalArgumentCollection`, but I wouldn't generally expect it to be so straightforward to add such checks throughout the codebase. I also agree with @lbergelson that the expected behavior might not be immediately clear and that perhaps this could be addressed in the scattering step---seems like shards could just be limited to regions that cover the resource at the outset. Consider also an older comment at https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435588845 about whether or not we should just use the equivalent Picard tool (horrible glob aside).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6209#issuecomment-540740687:445,validat,validation,445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6209#issuecomment-540740687,2,['validat'],"['validateIntervalArgumentCollection', 'validation']"
Security,I'll add: I suspect that this could get done pretty quickly/painlessly if @lbergelson (our travis expert) and yourself (who has set up tests like this before many times) got together in a room and hashed it out. Recommend setting up a meeting with @lbergelson at a time that's convenient in the next week or two. I'll post command lines here by early next week.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287478818:197,hash,hashed,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287478818,1,['hash'],['hashed']
Security,I'm actually a little surprised that it's not emitting a 1/* at the second location (despite that perhaps not being compatible with the spec; I agree with @bhandsaker 's view of what `*` should mean) given the changes I made in https://github.com/broadinstitute/gatk/pull/4963 to support spanning deletions. Those changes were not made with MNPs in mind but reading the code I'm surprised the `*` allele is not injected into the variant context. What version of HaplotypeCaller are you using @tfenne?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447369490:411,inject,injected,411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447369490,1,['inject'],['injected']
Security,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:521,secur,security,521,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,2,['secur'],['security']
Security,"I'm getting the same issue on GATK 4.1.9.0 FilterAlignmentArtifacts. This bug has been present for 1 year. Has this been fixed?; Note: There is no work-around because FilterAlignmentArtifacts does not have a --smith-waterman option. Here is my error:; ```; 20:12:42.724 WARN FilterAlignmentArtifacts - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:682,secur,secure-,682,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098,1,['secur'],['secure-']
Security,"I'm glad it's working now, but a PS since you asked about `-independent-mates`: several months ago we made Mutect2 force paired reads to share the latent random variable indicating which haplotype they are derived from in the somatic genotyping model. This is correct because paired reads come from the same molecule of DNA. `-independent-mates` disables this and tells Mutect2 to forget about pairing. We only created the option because some synthetic validation data is generated by spiking in variation without regard to pairing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-596165833:453,validat,validation,453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-596165833,1,['validat'],['validation']
Security,"I'm going to abandon this - Picard tests depend on the order in contrived ways, eg:. ```; private DetailPair getWorstMetrics(final List<DetailPair> metrics) {; PreAdapterDetailMetrics worstPreAdapterMetrics = null;; BaitBiasDetailMetrics worstBaitBiasMetrics = null;; for (final DetailPair m : metrics) {; if (worstPreAdapterMetrics == null || m.preAdapterMetrics.QSCORE < worstPreAdapterMetrics.QSCORE) worstPreAdapterMetrics = m.preAdapterMetrics;; if (worstBaitBiasMetrics == null || m.baitBiasMetrics.QSCORE < worstBaitBiasMetrics.QSCORE) worstBaitBiasMetrics = m.baitBiasMetrics;; }; return new DetailPair(worstPreAdapterMetrics, worstBaitBiasMetrics);; }; ```. if all `QSCORE` are the same this arbitrarily pick the first one. That backfires when I switch to linked hashmaps and linkedhashsets. Specifically `CollectSequencingArtifactMetricsTest` fails. Given that #1210 (fate of Picard) is unresolved I'm going to not put time into it yet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1844#issuecomment-220611498:772,hash,hashmaps,772,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1844#issuecomment-220611498,1,['hash'],['hashmaps']
Security,I'm informed that I have access to the broad-firecloud-dsde billing account and it appears whatever error we encountered the other day was something transient.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-437409513:25,access,access,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-437409513,1,['access'],['access']
Security,I'm kind of glad that 4.1 exposed this because previously unmatched pairs were silently giving wildly-inflated contamination estimates.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083398:26,expose,exposed,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083398,1,['expose'],['exposed']
Security,"I'm looking into migrating custom GATK3 variant Info/GenotypeAnnotations to GATK4. The annotate() method in GATK3 was passed a sizable amount of context. This is greatly reduced in GATK4. I understand a desire to simplify, such as not passing the Walker. FeatureContext in particular would be helpful, is there another way to access that from VariantAnnotations?. Stepping back: the one scenario I want to support is to annotate genotype concordance between the input VCF and a reference VCF. In our GATK3 implementation, the user supplied that VCF on the command line when executing VariantAnnotator. This plugin used GATK3's walker.getResourceRodBindings(), which seems analogous to GATK4 FeatureContext, to find that binding. It then queries that VCF to find any VariantContext from the current site. . I realize this is raising a couple issues: a) access FeatureContext from within annotate(), , b) efficiently query VariantContext from another resource, and c) plugin that would ideally provide its own command-line argument. . Are there any existing GATK annotations or other plugins that deal with these issues?. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930:326,access,access,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930,2,['access'],['access']
Security,"I'm new at this, so I may be missing something, but it looks to me like there is an issue with the conversion code in GenomicsConverter.makeSAMRecord() in com.google.cloud.genomics.gatk.common. I've been working on this bam file issue, correcting errors in the files used for tests. Many of the errors involve reads with FLAGs that indicate that they are in pairs, but the mate is not extant in the file, causing the error. A way to fix this without deleting the offending reads is to set the FLAG to zero and also modify the RNEXT, PNEXT, and TLEN fields, if necessary, so that the read becomes single (provided that the values of all of these fields are not important for the tests). However, when I do this, I find that tests that write and then read bam files fail, because when the just-written file is read back, SAM validation complains that the mate unmapped FLAG is set for an unpaired read. It turns out that the copy of the file written by the test substitutes the value '8' for '0' as the FLAG for the modified reads. The relevant code in GenomicsConvertermakeSamRecord() (line 170) is:. flags += ((read.getNextMatePosition() == null || read.getNextMatePosition.getPosition() == null)) ? 8 : 0;. The effect of this line is that all reads which have null mate positions, even those which the FLAG specifies as unpaired, get the mate unmapped FLAG set, causing the validation errors that i'm seeing. The reason the tests have not failed before is apparently that the existing test files do not contain any reads with FLAGs that specify them as unpaired. A simple fix for this would be to convert the line above to:. flags += ( paired && (read.getNextMatePosition() == null || read.getNextMatePosition.getPosition() == null)) ? 8 : 0;. The redundant parens in the original code suggest that something like this may have been intended,but the google genomics documentation at http://google-genomics.readthedocs.org/en/latest/migrating_tips.html gives the following pseudocode:. flags += read.n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114101033:823,validat,validation,823,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114101033,1,['validat'],['validation']
Security,"I'm not able to access a cluster to test this on right now, however I wonder if it's something to do with the sort order declared in the BAM header. MarkDuplicatesSpark uses the same header for the output as the input, and doesn't change the sort order attribute, unlike SortBamSpark. Does setting it to unsorted help?. Have you been able to reproduce this on smaller inputs? I noticed that we don't have an integration test for MD.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1005#issuecomment-148753478:16,access,access,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1005#issuecomment-148753478,1,['access'],['access']
Security,I'm not sure I have access to that bucket -- which project is it associated with?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2658#issuecomment-299480244:20,access,access,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2658#issuecomment-299480244,1,['access'],['access']
Security,"I'm not sure at this point. ; Is it possible the issue would also occur if the bam passes ValidateSamFile, and the intervals file is sorted, but the 2 have different contig orderings?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6065#issuecomment-591651451:90,Validat,ValidateSamFile,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6065#issuecomment-591651451,1,['Validat'],['ValidateSamFile']
Security,"I'm not sure exactly what's happening but I suspect it has something to do with the way the files are mounted. My guess is that there is some sort of transient interruption happening in the connection between the EC2 instance and the file server, and it's causing an error in gatk. When reading from a local file GATK does not expect any errors since errors in local files are usually fatal problems caused by a broken disk. Its probably some sort of bug in amazon's fuse implementation which isn't properly hiding network problems from the software. . I expect that your output is truncated at the point the error occured, and you probably need to rerun those shards. Instead of mounting them with amazon's fuse, you could try to either copy the files to a local disc, or access them using an NIO filesystem plugins like this plugin https://github.com/awslabs/aws-java-nio-spi-for-s3 or as signed URLs using https://github.com/broadinstitute/http-nio/ (included in gatk 4.6).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8735#issuecomment-2214915942:773,access,access,773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8735#issuecomment-2214915942,1,['access'],['access']
Security,"I'm not sure what went wrong exactly, I might have messed up something when I did the travis encrypt command. I've deleted the previous one, regenerated a new-new key, and reencrypted it. Hopefully this time it will work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5308#issuecomment-430319851:93,encrypt,encrypt,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5308#issuecomment-430319851,1,['encrypt'],['encrypt']
Security,"I'm pretty sure this is a hadoop-bam issue, but I'm finding that any BAM produced by bwa (VN 0.7.16a-r1181) will not load in Spark. The BAM loads successfully in ValidateSamFile (although it throws errors because there are no RGs). Running it through AddOrReplaceReadGroups makes the error go away. Attempting to load from local disk gives the following error:. `htsjdk.samtools.SAMFormatException: Does not seem like a BAM file; 	at org.seqdoop.hadoop_bam.BAMSplitGuesser.<init>(BAMSplitGuesser.java:88); 	at org.seqdoop.hadoop_bam.BAMInputFormat.addProbabilisticSplits(BAMInputFormat.java:228); 	at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:155); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAMInputFormat.java:252); 	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:121); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3488:162,Validat,ValidateSamFile,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488,1,['Validat'],['ValidateSamFile']
Security,"I'm trying to run Mutect2 in tumor-only mode, for a small panel, and I get this errors at the FilterMutectCalls step. ```bash; [July 26, 2019 9:34:50 AM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2129657856; java.lang.IllegalArgumentException: errorRate must be good probability but got NaN; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:225); at org.broadinstitute.hellbender.utils.QualityUtils.errorProbToQual(QualityUtils.java:209); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.lambda$applyFiltersAndAccumulateOutputStats$13(Mutect2FilteringEngine.java:176); at java.util.Optional.ifPresent(Optional.java:159); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.applyFiltersAndAccumulateOutputStats(Mutect2FilteringEngine.java:174); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:142); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6058:435,validat,validateArg,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6058,1,['validat'],['validateArg']
Security,"I'm using GATK 4.2.1.0-0 tool `Mutect2` to call mutations in a mitochondrion genome, and later processing the VCFs with `FilterMutectCalls` enabling as well the mitochondria mode (`--mitochondria-mode true`). For some reason, this results in **some** of the VCFs to return the following error:. > java.lang.IllegalArgumentException: log10p: Log10-probability must be 0 or less; > 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); > 	at org.broadinstitute.hellbender.utils.MathUtils.log10BinomialProbability(MathUtils.java:646); > 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:639); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$calculateQuantileBackgroundResponsibilities$10(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.utils.MathUtils.applyToArray(MathUtils.java:1035); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.calculateQuantileBackgroundResponsibilities(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:165); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165); > 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); > 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8455:426,validat,validateArg,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8455,1,['validat'],['validateArg']
Security,"I'm working on an imputation pipeline right now, and the contigs in the returned VCF header don't contain lengths. This fix to UpdateVCFSequenceDictionary allows me to force an update to the VCF's sequence dictionary so I have a valid VCF I can use with the rest of our tools when both --replace and --disable-sequence-dictionary-validation are set to true.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6140:330,validat,validation,330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6140,1,['validat'],['validation']
Security,"I've gotten this to work with an internal GCE project (I haven't successfully tested with broad-dsde-dev because of firewall rules). However, it should look like this using bdutil. ```; ./bdutil -P cluster-1 -z us-central1-a -p broad-dsde-dev -b dataproc-8cbe9d51-94fb-4ad4-9c34-a283212c2ae6-us -e hadoop2 socksproxy 12340; ```. which is just a wrapper around. ```; gcloud --project=broad-dsde-dev --quiet --verbosity=info compute ssh cluster-1-m --command= --ssh-flag=-N --ssh-flag=-D12340 --ssh-flag=-oServerAliveInterval=60 --ssh-flag=-oServerAliveCountMax=3 --ssh-flag=-oConnectTimeout=30 --zone=us-central1-a; ```. and a few other commands. After the proxy has started, you need to open up Chrome with the proxy:. ```; /Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --proxy-server='socks5://localhost:12340' --host-resolver-rules='MAP * 0.0.0.0, EXCLUDE localhost' --user-data-dir=/tmp/bdutil-socksproxy/cluster-1-m http://cluster-1-m:8088 http://cluster-1-m:50070; ```. That'll open up the master page. If you have any funky IP address/proxy extensions (like I do), you'll need to turn those off. @droazen and @lbergelson, where do you want this documented?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/975#issuecomment-148457456:116,firewall,firewall,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/975#issuecomment-148457456,1,['firewall'],['firewall']
Security,"I've removed some in #2786. The rest are all related to the `ReferenceAPISource` (so not part of GCS authentication, part of Genomics authentication). So one may argue that after this change lands, we can close this bug. Or we can push further and try to use `authHolder` instead of the `PipelineOptions` everywhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/963#issuecomment-305275228:101,authenticat,authentication,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/963#issuecomment-305275228,2,['authenticat'],['authentication']
Security,"IET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resour",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2664,Validat,ValidateVariants,2664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"INDEL informative reads based on the reference confidence model"">; ##FORMAT=<ID=MB,Number=4,Type=Integer,Description=""Per-sample component statistics to detect mate bias"">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=PRI,Number=G,Type=Float,Description=""Phred-scaled prior probabilities for genotypes"">; ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=SB,Number=4,Type=Integer,Description=""Per-sample component statistics which comprise the Fisher's Exact Test to detect strand bias"">; ##FORMAT=<ID=SPL,Number=.,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for SNPs based on the reference confidence model"">; ##FORMAT=<ID=SQ,Number=A,Type=Float,Description=""Somatic quality"">; ##DRAGENCommandLine=<ID=HashTableBuild,Version=""SW: 01.003.044.3.8.4, HashTableVersion: 8"",CommandLineOptions=""/opt/edico/bin/dragen --build-hash-table true --enable-cnv true --ht-alt-aware-validate true; ##DRAGENCommandLine=<ID=dragen,Version=""SW: 05.021.609.3.9.5, HW: 05.021.609"",Date=""Wed Feb 09 21:30:31 UTC 2022"",CommandLineOptions=""--bam-input s3://cromwell-dragen-us-east-1/samples/validacaoDRAGEN/ba; ```. About chrM, yeah... all of them have this info... like below. ```; grep ""^chrM"" <name>.hard-filtered.gvcf | head ; chrM	1	.	G	<NON_REF>	.	weak_evidence	END=1	GT:AD:DP:SQ:MIN_DP	0/0:112,1579:1691:0:1691; chrM	2	.	A	<NON_REF>	.	PASS	END=72	GT:AD:DP:SQ:MIN_DP	0/0:2504,2:2506:99:1712; chrM	73	.	A	G,<NON_REF>	.	PASS	DP=2017;MQ=208.10;FractionInformativeReads=0.948	GT:SQ:AD:AF:F1R2:F2R1:DP:SB:MB	1/1:98.13,0.00:0,1912,0:1.000,0.000:0,980,0:0,932,0:1912:0,0,756,1156:0,0,932,980; ```. As I replied to you, in another section,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7797#issuecomment-1112612397:2359,Hash,HashTableBuild,2359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7797#issuecomment-1112612397,1,['Hash'],['HashTableBuild']
Security,"INDEX false --CREATE_MD5_FILE false --help false --version false --verbosity INFO --QUIET false; [March 9, 2017 7:03:42 PM EST] Executing as gspowley@dna on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Version: Version:4.alpha.2-170-g8d06823-SNAPSHOT; 19:03:42.998 INFO ValidateSamFile - Defaults.BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.COMPRESSION_LEVEL : 1; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_INDEX : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_MD5 : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CUSTOM_READER_FACTORY : ; 19:03:42.999 INFO ValidateSamFile - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 19:03:42.999 INFO ValidateSamFile - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.REFERENCE_FASTA : null; 19:03:43.000 INFO ValidateSamFile - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.000 INFO ValidateSamFile - Initializing engine; 19:03:43.000 INFO ValidateSamFile - Done initializing engine; ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 24466, Read name 20FUKAAXX100202:7:46:13035:77621, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97940, Read name 20FUKAAXX100202:5:7:21464:86",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:1561,Validat,ValidateSamFile,1561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,1,['Validat'],['ValidateSamFile']
Security,"Ideally we'd minimize changes to core engine classes, and instead create new specialized subclasses (like a subclass of MultiVariantWalkerGroupedOnStart) that implement the desired behavior. The main thing is that we need something that only affects `VariantEval` - anything that affects other tools would run into the same issues as #4571 - specifically that tests that use VariantContext equality to validate results will start to fail because of the presence of source name in the actual values.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823578133:402,validat,validate,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823578133,1,['validat'],['validate']
Security,"If --gcs-project-for-requester-pays is not specified, gatk should use the current billing project to access requester pays buckets.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6669:101,access,access,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6669,1,['access'],['access']
Security,"If I clone GATK with the ssh URL (`git@github.com:broadinstitute/gatk.git`), and then run a `docker build` command from the root of that clone, I get ssh authentication errors at the `git lfs pull` step:. ```; Step 9/36 : RUN git lfs pull; ---> Running in 1f415556efd2; Git LFS: (0 of 104 files) 0 B / 1.28 GB ; batch request: Host key verification failed.: exit status 255; batch request: Host key verification failed.: exit status 255; error: failed to fetch some objects from 'https://github.com/broadinstitute/gatk.git/info/lfs'; The command '/bin/sh -c git lfs pull' returned a non-zero code: 2; ```. If I do the same thing from a GATK clone created using the https URL (`https://github.com/broadinstitute/gatk.git`), I get no lfs error. This also raises the larger question of whether we are authenticating with github before doing `git lfs pull` during the docker build, as I believe that the quotas for unauthenticated `git lfs` operations are much smaller than for authenticated operations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7077:154,authenticat,authentication,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7077,3,['authenticat'],"['authenticated', 'authenticating', 'authentication']"
Security,"If I understand what you're proposing, the tool code would have to use `instanceof` checks and typecasts to take advantage of this feature (unless `FeatureInputAwareVariantContext` was exposed in the `apply` method). Other reviewers may feel differently, but using the source field (which I don't view as ""repurposing"" since I think its aligned with the intent of that field) seems cleaner. Up to you if you want to submit a PR with your proposed change to see if its viable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-824047890:185,expose,exposed,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-824047890,1,['expose'],['exposed']
Security,"If a tool exists and is runnable, but is not documented, it should be accessible via tab-completion. Otherwise people can't depend on tab-completion to give a complete list of all tools that can be run.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330936329:70,access,accessible,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330936329,1,['access'],['accessible']
Security,"If one of the block compressed VCFs in the list is empty (i.e. it does have proper header lines but there are no variant records, which is perfectly valid) then the tool fails with an IllegalStateException:. java.lang.IllegalStateException: Could not read available bytes from BlockCompressedInputStream.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:697); at org.broadinstitute.hellbender.tools.GatherVcfs.gatherWithBlockCopying(GatherVcfs.java:354)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3218:351,validat,validate,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3218,1,['validat'],['validate']
Security,"If only some of the accesses failed, then it's likely what we're seeing here is GCS refusing to serve requests because it feels it's getting too many. How many machines are trying to access the file? How many threads per machine? What storage class is the bucket?. The lower storage classes support fewer parallel accesses, and NIO's prefetching (if enabled) results in two threads per reader.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459842021:20,access,accesses,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459842021,3,['access'],"['access', 'accesses']"
Security,"If the sample file is created by extracting a table from BQ, the file might be in a bucket that only the service account can access. Add an option for using the service account to pull the file.; Also, expose the service account input at the workflow (not the task) level",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7299:125,access,access,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7299,2,"['access', 'expose']","['access', 'expose']"
Security,"If we find one that does everything we need, sure -- but if there isn't such a beast, I'd advocate a hybrid approach of a NIH library to parse the args according to POSIX conventions, and an ""IH"" solution (which already exists, of course) to handle the annotation parsing and value injection.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/72#issuecomment-69635412:282,inject,injection,282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/72#issuecomment-69635412,1,['inject'],['injection']
Security,"If we like this -- we also need to . - [x] build a jar; - [x] update the WDL to use this tool (and the Jar); - [ ] Put the BED files someplace public/widely accessible (likely just the 1kb version); - [x] Run an E2E on QuickStart, merge the VCFs and compare (and see no differences); - [x] If we want to validate evenness we need to run with a lot of shards and enough data that they are interesting. Maybe Stroke 10k; - [x] In parallel if we could turn some of the above script into integration tests that would be awesome",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7643#issuecomment-1017113500:157,access,accessible,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7643#issuecomment-1017113500,2,"['access', 'validat']","['accessible', 'validate']"
Security,"If you ask HaplotypeCallerSpark for a gvcf.gz it outputs a base pair resolution GVCF with no blocking. This is due to confusion in hadoop-bam / VariantSparkSink. It works fine if you write an uncompressed g.vcf. This is due to a conditional statement in `KeyIgnoringVCFOutputFormat.getRecordWriter(askAttemptContext ctx)`. ```; 		if (!isCompressed) {; 			return getRecordWriter(ctx, file);; 		} else {; 			FileSystem fs = file.getFileSystem(conf);; 			return getRecordWriter(ctx, codec.createOutputStream(fs.create(file)));; 		}; ```. The two branches call two different overloads of `getRecordWriter`. ```; getRecordWriter(TaskAttemptContext ctx, Path out). getRecordWriter(TaskAttemptContext ctx, OutputStream outputStream); ```. The first is public, and overriden to provide GVCF writers in our code, the second is private and doesn't know about our GVCF writer. We could override `getRecordWriter(ctx)` but we need access to a constructor for `VCFRecordWriter` that takes a stream and propagates the ctx which doesn't exist.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4274:919,access,access,919,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4274,1,['access'],['access']
Security,"If you need files that will pass, we have validation passing versions of many of our test files in https://github.com/broadinstitute/gatk/pull/809. It's possible you could pull some of those in. We haven't figured out a scheme for evaluating if they are equivalent for testing purposes, but if you wanted to look at the specific failing files it might be a good place to start. . I'm not sure STRICT is the right default validation since traditionally gatk ran it's own orthogonal validation from picard, and many GATK valid bams will not pass picard validation. I wasn't involved in the talk with @droazen though, so I assume you've already discussed this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1439#issuecomment-175160857:42,validat,validation,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1439#issuecomment-175160857,4,['validat'],['validation']
Security,"If you would like the GenomicsDB for chromosome `CM031199.1` (which, by the way, was created with GATK 4.2.4.1) that I used in the above two examples, for your own debugging purposes, you can download it as a .tar archive from:. [https://drive.google.com/file/d/1LzZCkWfmNb8IcZpdreaNIxtJ8GQQ-b7g/view?usp=sharing](https://drive.google.com/file/d/1LzZCkWfmNb8IcZpdreaNIxtJ8GQQ-b7g/view?usp=sharing). It is 385 Mb, and it has an SHA1 hash (from the Unix `shasum` utility) of `d330a28120713fb05c95d1bf54342944f5d741c9`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1014196799:432,hash,hash,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1014196799,1,['hash'],['hash']
Security,"Implement -L system, enable access to it for tools that request it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4:28,access,access,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4,1,['access'],['access']
Security,"Implement -L system, enable access to it for tools that request it (define how they 'request it' - maybe by implementing an interface or calling a function or overriding some generic hook - part of this issue is to design it).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4:28,access,access,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4,1,['access'],['access']
Security,"Implements allele collapsing for ""breakend replacement"" BND alleles, as described in section 5.4 of the [VCFv4.2 spec](https://samtools.github.io/hts-specs/VCFv4.2.pdf). Also:; - Validates symbolic alt allele for non-BND SV classes when attempting to collapse multiple alt alleles.; - Greatly improves unit test coverage for `CanonicalSVCollapser`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8408:179,Validat,Validates,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8408,1,['Validat'],['Validates']
Security,"Implements tool for clustering SVs, built on top of the clustering engine code refined recently in #7243. In addition to a few bug fixes, updates also include:. - `PloidyTable` class, which ingests and serves as a simple data class for a tsv of per-sample contig ploidies. This was necessary for inferring genotypes when input vcfs contain non-matching sample and variant records.; - Modified `SVClusterEngine` to render sorted output.; - Improved code for SV record collapsing (see the `CanonicalSVCollapser`), particularly for CNVs. Genotype collapsing now infers allele phasing in certain unambiguous cases, in particular for DUPs and multi-allelic CNVs. Testing for this has been cleaned up and augmented with further cases to validate this functionality.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7541:731,validat,validate,731,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7541,1,['validat'],['validate']
Security,Improve error message for no-access and disabled-account cases,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417:29,access,access,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417,1,['access'],['access']
Security,Improve error message in spark tools when trying to access a local file from other nodes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1417:52,access,access,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1417,1,['access'],['access']
Security,"In ADAM, we have well maintained Hadoop InputFormats for both normal and interleaved FASTQ. Additionally, we wrap these InputFormats in Spark-friendly APIs (exposed in Scala, Java, Python, and R) that add validation and standard transformations. GATK already has a dependency on ADAM, so...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4612#issuecomment-405114805:157,expose,exposed,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4612#issuecomment-405114805,2,"['expose', 'validat']","['exposed', 'validation']"
Security,"In IntervalUtils, when Picard intervals are parsed and checked for validity, (line 359 `glParser.isValidGenomeLoc(interval.getContig(), interval.getStart(), interval.getEnd(), true)`), if the contig doesn't match the supplied reference (via -R) then the error produced is `has an invalid interval`. The interval is perfectly valid, especially since the Picard interval_list has a corresponding sequence dictionary. I'm not sure if the preferred behavior here is to validate against the interval_list seqdict and then note that the -R reference doesn't match or to error because the -R ref doesn't match. Maybe if the tool requiresReference() and the -R doesn't match throw an error?. I encountered this in the context of a tool similar to SplitIntervals, which requires a reference even if a Picard interval_list is provided. I see that this is a TODO in GATKTool::getBestAvailableSequenceDictionary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5410:465,validat,validate,465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5410,1,['validat'],['validate']
Security,"In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them into the ref haplotype, then threading these constructed haplotypes into the assembly graph with a large edge weight. There are several drawbacks to this approach:. * The strange edge weights interfere with the `AdaptiveChainPruner`.; * The large edge weights may not be large enough to avoid pruning when depth is extremely high.; * The alleles may be lost if assembly fails.; * If the alleles actually exist but are in phase with another variant we end up putting an enormous amount of weight on a false haplotype. We can get around these issue with the following method:. * assemble haplotypes without regard to the force-called alleles.; * if an allele is present in these haplotypes, do nothing further.; * otherwise, add a haplotype in which the allele is injected into the reference haplotype. @LeeTL1220 I prototyped this and it seems to resolve the missed forced alleles that Ziao found. @ldgauthier Can you think of any objections to making this change in HaplotypeCaller?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857:57,inject,injecting,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857,2,['inject'],"['injected', 'injecting']"
Security,"In PathSeqPipelineSpark, the reads are repartitioned to ~5k per partition (by default) just prior to the pathogen BWA alignment step (to ensure an even distribution of work). Currently, some samples with a lot of non-host reads cause 10,000's of sharded BAMs to be written at the end of the pipeline. This PR reduces the number of partitions in the read RDD just before writing to disk in the PathSeqPipelineSpark tool. It exposes a command-line option for the number of reads per partition, with a default value that results in a much more reasonable number of sharded BAMs in even the worst cases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3545:423,expose,exposes,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3545,1,['expose'],['exposes']
Security,"In doing continued profiling of the HaplotypeCaller GVCF mode I have observed that somewhere in the range of 12% of our overall runtime (after i've made my other optimizations) is spent in `VariantContextBuilder.make()` upon further investigation I have noticed that we are currently building a VariantContext object for each pileup in `ReferenceConfidenceModel.calculateReferenceConfidence()`. This means that we are building a unique VariantContext object for essentially every spot on the genome. VariantContext object building represents a significant overhead in terms of validation and construction and memory usage. I suspect that if we were to create some reduced object without as much overhead we could save ourselves a lot of trouble time and memory merging these things. Unfortunately I think the merging of these context objects happens in the GVCF writer which means it won't be a trivial change to make to the engine. Perhaps it is worth investigating what can be done to this code, as it represents another size-able chunk of speedup if we can squash it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5618:577,validat,validation,577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5618,1,['validat'],['validation']
Security,"In fact, setting the deploy-mode works with manual jobs as we get logs in our Hadoop monitor ( the tool to monitor the jobs on the spark cluster ) and directly on our console if deploy-mode is not set / set to client. Both `--deploy-mode` and `--conf 'spark.submit.deployMode=cluster'`. But with GATK, logs appear directly on my console and not in the Hadoop monitor even if we set with `--conf 'spark.submit.deployMode=cluster`. The other methods `--deploy-mode` and `-- --deploy-mode` having the said problems.; About the `-- --deploy-mode` and the JNI linkage error, I'm currently checking this.; All our Spark nodes have access to the mapr libraries from `/opt/mapr/...`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350676916:625,access,access,625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350676916,1,['access'],['access']
Security,"In gatk3 we had mechanism for multithreading in gatk, but they made the tools very complicated and didn't provide enough speed up to be worthwhile in most cases. In gatk 4 we made the decision to write the tools as single threaded. We have a separate implementation of some tools using spark which is a parallelization library. . If you want to parallelize the HaplotypeCaller you can shard the input and run multiple copies of the tool on different input shards. That's how we do it in production. Alternatively you can try out the beta tool HaplotypeCallerSpark which is natively parallel but is still being developed. It hasn't been validated and may not produce results that are as accurate as the regular HaplotypeCaller.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6117#issuecomment-524554040:636,validat,validated,636,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6117#issuecomment-524554040,1,['validat'],['validated']
Security,In light of the recent #7357 and #7358 it has become clear that we are blind changes that cause the logging outputs for GATK to become unusable because we are spitting endless warnings to stdout. I think we should change our integration tests to capture the log output for each of our tests and assert that none of them balloon beyond some reasonable threshold that would capture these problems (perhaps a megabyte but it would take a little bit of sleuthing to be sure). . I would think the best place would be to add a capture into `CommandLineProgramTest.runCommandLine()` that instead of using the current behavior `injectDefaultVerbosity()` we instead leave the logging output as the default and capture it somewhere explicit where we can make assertions about the size of the outputs. Possibly we could create a dummy logging level that just saves and counts the outputs so we can make assertions about the logs. Ideally this should apply to every tool simultaneously since it would be too patchwork to simply add logging output tests for enough of the tools to protect us manually.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7368:620,inject,injectDefaultVerbosity,620,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7368,1,['inject'],['injectDefaultVerbosity']
Security,"In looking at his further, the container header contains a stream offset, and each slice header also contains a global record counter. Both of these need to be updated. Its not clear if its possible to repair these without re-encoding the entire container stream, but if so that should probably be done in a method exposed by htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2201#issuecomment-324756574:315,expose,exposed,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2201#issuecomment-324756574,1,['expose'],['exposed']
Security,"In my case, as an API user, my main usage of GATK is for traverse `GATKRead` and `VariantContext`, so I would like to have in `GATKTool` a simpler way of access to the `FeatureInput<VariantContext>` instead of getting them from `FeatureManager features`. It will be useful in the `VariantWalker` as a step to issue #692, to get all the variants provided by the user in the same walker. My idea is modify the `GATKTool` to include:; - A `public abstract boolean requiresVariant()`, which will be used to determine if we should detach or not all the variants inputs from the `FeatureManager features`.; - A `private void initializeVariants()`, which will implement a way to extract the `FeatureInput<VariantContext>` from `features` and initialize a `FeatureManager variants` or a extended class which includes only `VariantContext` inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1710:154,access,access,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1710,1,['access'],['access']
Security,"In particular add output GATKTool.getDefaultToolVCFHeaderLines to the VCF header, and rewrite the integration test for GenerateVCFFromPosteriors so that it validates the equivalence of variant context records, instead of file equivalency",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4267:156,validat,validates,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4267,1,['validat'],['validates']
Security,"In particular, we are a little lax on sequence-dictionary validation in the CNV pipelines. However, it might be that this is a necessary evil---it seems sequence dictionaries are somewhat inconsistent even in datasets such as TCGA.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3864:58,validat,validation,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3864,1,['validat'],['validation']
Security,"In the VAT validation, give clearer error msg about which clinvar classification values are missing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7939:11,validat,validation,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7939,1,['validat'],['validation']
Security,"In the process of designing correctness tests for `MarkDuplicatesSpark`, @davidadamsphd has come up with a potential set of optimizations to `MarkDuplicatesSpark` that have the potential to improve performance by an order of magnitude. The task here is to meet with @davidadamsphd, get access to and understand his optimizations, and port them to the main `MarkDuplicatesSpark` tool (along with any other optimizations you feel are appropriate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1100:286,access,access,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1100,1,['access'],['access']
Security,In the work on #7295 it became clear that there are a lot of overlapping overloads of the `createGenomeLoc()` method that has already caused some confusion since some overloads will skip the reference validation step. Somebody should audit all of the uses of `GenomeLocParser` and evaluate where validation is and isn't appropriate (possibly if you want an unvalidated genomeLoc use a SimpleInterval?) and wire them accordingly.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7300:201,validat,validation,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7300,3,"['audit', 'validat']","['audit', 'validation']"
Security,"In this branch are a number of improvements and changes that form the baseline for the current ongoing evaluation of the DRAGEN/GATK pipeline. This represents the joint work of both msyelf and @vruano. The major improvements in this branch are as follows:; - `EstimateDragstrModelParameters` tool for estimating the per-sample/per-STRType errors for use in the HMM gap open/gap close penalties as well as the necessary changes to the PairHMM loading code in order to adjust the model appropriately.; - Support for using the DragstrParams and flat SNP priors to compute genotype posteriors and the support for using them in the selection of genotypes as well as for computing the QUAL score. ; - Base Quality Dropout (BQD) model which penalizes variants with low average base quality scores among genotyped reads and reads that were otherwise excluded from the genotyper. A number of additional arguments to expose internal behaviors in the readThreadingAssembler and HaplotypeCaller have been made in order to support threading more lowBQ reads through to the genotyper. ; - Foreign Read Detection (FRD) model which uses an adjusted mapping quality score as well as read strandedness information to penalize reads that are likely to have originated from somewhere else on the genome. A number of additional arguments and behaviors have been exposed in order to preserve lower mapping quality reads in the HaplotypeCaller in service.; - Dynamic Read Disqualification, allows for longer/lower base quality reads to be less likely to be rejected by eliminating the hard cap on quality scores and further adjusting the limit based on the average base quality for bases in the read. . Design decisions that I would direct the reviewers attention to as they correspond to potentially dangerous/controversial changes:; - Because FRD/BQD require low quality ends to be included in the models for genotyping, I have added the option to softclipLowQualityEnds (as opposed to their current treatment which involv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6634:907,expose,expose,907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6634,1,['expose'],['expose']
Security,"In validateVariants tool, made the default case behave so that it does the validations that can be done, and issues warning messages for the validations that cannot be done (ie, required external files)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5984:3,validat,validateVariants,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5984,3,['validat'],"['validateVariants', 'validations']"
Security,"In working with the SampleDBBuilder code I have noticed that there is an argument for validationStrictness which purports to assert that there is a >1:1 mach between the discovered samples in the pedigree file and those in the underlying variantDataSources according to the code on line 83. Unfortunately, as it stands there is no way to input `samplesFromDataSources` into the builder, so these assertions are skipped. There are tests for validation but these only apply to asserting that there are no name collisions between the samples added as pedigree files, which appears to be different.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3949:86,validat,validationStrictness,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3949,2,['validat'],"['validation', 'validationStrictness']"
Security,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6660:293,validat,validation,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660,2,"['hash', 'validat']","['hash', 'validation']"
Security,Index files should have an integrity check built-in,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5571:27,integrity,integrity,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5571,1,['integrity'],['integrity']
Security,Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/a795190c-dcc2-40a7-bfcc-84fa6a4ea0dc); Two failed on ValidateVDS (or rather something upstream). I *don't* think this is an effect of this PR.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8807:149,Validat,ValidateVDS,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8807,1,['Validat'],['ValidateVDS']
Security,"Interesting, it's definitely possible it's coming from one of the other buckets. I don't think we have fine grained control over WHICH bucket we attempt to read requester pays status from, so it's possible if it's enabled it's necessary to have that permission on every bucket. It's annoying that the error message doesn't say which reader is performing the access. Is there a longer stack trace available?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492#issuecomment-934908586:358,access,access,358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492#issuecomment-934908586,1,['access'],['access']
Security,"Interesting, when I run locally I get:. ```; Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.funcotator.FuncotatorIntegrationTest > nonTrivialLargeDataValidationTest[3](/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/funcotator/validationTestData/regressionTestHg19Large.vcf, /Users/louisb/Workspace/gatk/src/test/resources/large/Homo_sapiens_assembly19.fasta.gz, hg19, /Users/louisb/Workspace/gatk/src/test/resources/large/funcotator/funcotator_dataSources/, /Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/funcotator/validationTestData/regressionTestHg19Large_expected.vcf) FAILED; java.lang.UnsatisfiedLinkError: 'void org.sqlite.core.NativeDB._open_utf8(byte[], int)'; at org.sqlite.core.NativeDB._open_utf8(Native Method); at org.sqlite.core.NativeDB._open(NativeDB.java:71); at org.sqlite.core.DB.open(DB.java:174); at org.sqlite.core.CoreConnection.open(CoreConnection.java:220); at org.sqlite.core.CoreConnection.<init>(CoreConnection.java:76); at org.sqlite.jdbc3.JDBC3Connection.<init>(JDBC3Connection.java:25); at org.sqlite.jdbc4.JDBC4Connection.<init>(JDBC4Connection.java:24); at org.sqlite.SQLiteConnection.<init>(SQLiteConnection.java:45); at org.sqlite.JDBC.createConnection(JDBC.java:114); at org.sqlite.JDBC.connect(JDBC.java:88); at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:677); at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:189); at org.broadinstitute.hellbender.tools.funcotator.dataSources.cosmic.CosmicFuncotationFactory.<init>(CosmicFuncotationFactory.java:161); at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.createCosmicDataSource(DataSourceUtils.java:469); at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.createDataSourceFuncotationFactoriesForDataSources(DataSourceUtils.java:289); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.onTraversalStart(Funcotator.java",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532715444:281,validat,validationTestData,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532715444,2,['validat'],['validationTestData']
Security,"Introducing the IntervalLocusIterator which will traverse every locus in intervals, regardless of coverage. Minor changes. Removed imports. AlignmentContextLocusIterator first cut. Still needs unit tests. Putting in the walker. Still needs unit tests. Adding tests (and fixes) so that we can get AlignmentContexts. Adding tests (and fixes) so that we can get AlignmentContexts. Working tests. Beginning migration to a LocusWalker change rather than a separate walker. Merging the emit empty loci into locus walker. Still need warnings and validation of parameters. Next step is the LocusWalker testing. Simple test of the new LocusWalker when it emit empty loci. Addressing PR requests and added ShardedIntervalIterator to save RAM on big intervals. Addressing the rest of the PR comments. Rolling back to int from long. Addressing second round of PR comments. Wrapped LIBS in a factory so that we can encapsulate the retrieval of the best alignment context iterator. Spark empty loci traversal being supported. Rebasing based off of the other emit loci branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2731:539,validat,validation,539,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2731,1,['validat'],['validation']
Security,Investigate whether our default validation stringency for reads should be STRICT rather than SILENT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1457:32,validat,validation,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1457,1,['validat'],['validation']
Security,Is there any update for this issue? I'm asking as AWS moved to NIO v2 late 2018 and htslib supports direct S3 access.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3708#issuecomment-628392999:110,access,access,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3708#issuecomment-628392999,1,['access'],['access']
Security,"Is there some discussion about why this is necessary? This doesn't seem like the right place to expose this to me. Wouldn't this make more sense being set, for example, on the CLI with the `spark-submit` command?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1066#issuecomment-152359731:96,expose,expose,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1066#issuecomment-152359731,1,['expose'],['expose']
Security,"It happened multiple times over the course of a couple days. Since I; downloaded the full gnomad exome data locally, I haven't tested again. --; - Alan Hoyle - alan@alanhoyle.com - http://www.alanhoyle.com/ -. On Mon, Nov 9, 2020 at 2:23 PM droazen <notifications@github.com> wrote:. > @alanhoyle <https://github.com/alanhoyle> Can you tell us whether the 400; > Bad Request error is repeatable -- did you see it more than once?; > Oftentimes when accessing cloud data we encounter transient errors like; > this that go away on their own.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6926#issuecomment-724225557>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AACGX43OY2CFF5KFZXZOH4LSPA6T3ANCNFSM4TD2FDGA>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-724267156:448,access,accessing,448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926#issuecomment-724267156,1,['access'],['accessing']
Security,"It looks like picard metrics record at least one more field when the metrics get reported, namely the count of supplementary reads seen. The metrics code should be audited to ensure it matches with picard over the same files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4777:164,audit,audited,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4777,1,['audit'],['audited']
Security,"It looks like the noGenotypes.vcf in GATK3 was derived from the v37 ref with decoy. In GATK4, the sequence dictionary validation requirement is that the input and reference have a common subset of contigs, so given your description of the difference I would expect it to pass that test. Feel free to reopen if you think I've missed something.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4453#issuecomment-410724975:118,validat,validation,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4453#issuecomment-410724975,1,['validat'],['validation']
Security,It looks like we need to update mockito. ; https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27538.13/tests/test/index.html. ```. java.lang.IllegalArgumentException: Unknown Java version: 11; 	at net.bytebuddy.ClassFileVersion.ofJavaVersion(ClassFileVersion.java:135); 	at net.bytebuddy.ClassFileVersion$VersionLocator$ForJava9CapableVm.locate(ClassFileVersion.java:357); 	at net.bytebuddy.ClassFileVersion.ofThisVm(ClassFileVersion.java:147); 	at net.bytebuddy.dynamic.loading.ClassInjector$UsingReflection$Dispatcher$CreationAction.run(ClassInjector.java:301); 	at net.bytebuddy.dynamic.loading.ClassInjector$UsingReflection$Dispatcher$CreationAction.run(ClassInjector.java:290); 	at java.base/java.security.AccessController.doPrivileged(Native Method); 	at net.bytebuddy.dynamic.loading.ClassInjector$UsingReflection.<clinit>(ClassInjector.java:70); 	at net.bytebuddy.dynamic.loading.ClassLoadingStrategy$Default$InjectionDispatcher.load(ClassLoadingStrategy.java:184); 	at net.bytebuddy.dynamic.TypeResolutionStrategy$Passive.initialize(TypeResolutionStrategy.java:79); 	at net.bytebuddy.dynamic.DynamicType$Default$Unloaded.load(DynamicType.java:4456); 	at org.mockito.internal.creation.bytebuddy.SubclassBytecodeGenerator.mockClass(SubclassBytecodeGenerator.java:115); 	at org.mockito.internal.creation.bytebuddy.TypeCachingBytecodeGenerator$1.call(TypeCachingBytecodeGenerator.java:37); 	at org.mockito.internal.creation.bytebuddy.TypeCachingBytecodeGenerator$1.call(TypeCachingBytecodeGenerator.java:34); 	at net.bytebuddy.TypeCache.findOrInsert(TypeCache.java:138); 	at net.bytebuddy.TypeCache$WithInlineExpunction.findOrInsert(TypeCache.java:346); 	at net.bytebuddy.TypeCache.findOrInsert(TypeCache.java:161); 	at net.bytebuddy.TypeCache$WithInlineExpunction.findOrInsert(TypeCache.java:355); 	at org.mockito.internal.creation.bytebuddy.TypeCachingBytecodeGenerator.mockClass(TypeCachingBytecodeGenerator.java:32); 	at org.mockito.internal.creation.bytebuddy.SubclassB,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532377836:724,secur,security,724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532377836,3,"['Access', 'Inject', 'secur']","['AccessController', 'InjectionDispatcher', 'security']"
Security,"It seems a lot of users use bcftools on their VCFs, and it sometimes converts floats to integers. For example MQ=31.0 to MQ=31. This change causes GATK tools to error. Is it possible to relax this validation?. ----; User Report; ----. Hi,. Every time I had this message, this was due to bcftools which can change some float values to an integer representation : (e.g : before bcftools : MQ=31.0; after bcftools : MQ=31). . The fact that GATK is very strict on that subject (40.0 is considered as a float while 40 is not) have some advantages and some drawbacks. I hope this problem will be resolved in GATK4 because bcftools is really useful and widely used when dealing with vcf files. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43270#Comment_43270",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3734:197,validat,validation,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3734,1,['validat'],['validation']
Security,"It seems like travis isn't really testing this properly, it's hard to prove that it's not using the default credentials. Would it make sense to do the following?; 1. create a new gcloud project; 2. create a private file in a bucket only accessible by that account ; 3. add a service account json for that account to travis, and use it in this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2879#issuecomment-330339002:237,access,accessible,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2879#issuecomment-330339002,1,['access'],['accessible']
Security,"It shouldn't take any extra work to merge most external requests once things are setup properly. The issue is that certain dataflow operations a key/password to access our google account and we can't publish those as part of the repo, so we use travis.ci's encrypt mechanism to make them available to the build without making them public. On external pull requests, travis doesn't make the keys available, because it would possible to access them with a malicious pull request. . Currently the things that rely on authentication aren't running anyway in travis, but the key was still being decrypted and failing on external requests I've removed that step for now, and will be more careful to ensure that builds will continue even if the key is missing when we re-enable it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/478#issuecomment-98215051:149,password,password,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478#issuecomment-98215051,5,"['access', 'authenticat', 'encrypt', 'password']","['access', 'authentication', 'encrypt', 'password']"
Security,"It turns out we were wrong and there was already a knob exposed for this. I gave the user some directions on increasing the correct buffer size, and they have accepted that answer. . We can probably go ahead and close this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6150#issuecomment-532297743:56,expose,exposed,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6150#issuecomment-532297743,1,['expose'],['exposed']
Security,It was noticed while doing #8351 that the `GencodeFunctotation.equals()` method has the following line in it; ``` ; if (geneTranscriptType != that.geneTranscriptType) return false; ; ```. Unfortunately the geneTranscriptType is stored as a Sting and thus this should NOT be expected to succeed in almost any case. As it stands fixing this innocuous oversight seems to break several of the combinatorial funcotator tests and an integration test. Somebody should fix this behavior (easy) and validate that the test changes are within tolerable levels (hard).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8385:490,validat,validate,490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8385,1,['validat'],['validate']
Security,It would be better if in addition to / instead of the getter/setter scheme that exists with current `Funcotation` classes we used a `HashMap` to be able to directly get each field by name. This would allow for more programmatic manipulation of `Funcotation` objects.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3919:133,Hash,HashMap,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3919,1,['Hash'],['HashMap']
Security,"It would be great if the jbwa also exposes a `bwa index` option, as we might need to map reads back to the assembled contigs (there will be many of them) for the genotyping step in SV pipeline, which in turn requires the contigs themselves to be indexed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1857#issuecomment-227504606:35,expose,exposes,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1857#issuecomment-227504606,1,['expose'],['exposes']
Security,"It would be nice to have a StrandedInterval class, and then the distal targets could be stored as one of these in the various BreakpointEvidence subclasses that have distal targets, and the PairedStrandedIntervals class could just have two of them. This would also let you eliminate the methods hasDistalTargets and getDistalTargetsUpstreamOfBreakpoints -- getDistalTargets would do the job of all three.; I assume that PairedStrandedIntervals shouldn't ever have null intervals for source or target, so you could just validate in the constructor and then you wouldn't have to test nullness in equals and hashCode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328935711:519,validat,validate,519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328935711,2,"['hash', 'validat']","['hashCode', 'validate']"
Security,"It would be nice to have a few Picard tools that we feature in BPWs (e.g. MarkDuplicates) show both syntaxes:. 1. java -jar picard.jar ValidateSamFile I=reads.bam MODE=SUMMARY; 2. gatk ValidateSamFile -I reads.bam -MODE SUMMARY. I assume MODE gets one dash and not two, but really I don't know. So having such examples scattered throughout the tool chest for most often used tools would be great. The second example could be prefaced with, e.g.; > Picard tools are callable from GATK4. The equivalent command to the above invoked via the GATK launch script would be:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349522774:135,Validat,ValidateSamFile,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349522774,2,['Validat'],['ValidateSamFile']
Security,"It's a feature, we're so committed to open source that we don't allow it to be made private through encryption.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4718#issuecomment-385800585:100,encrypt,encryption,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4718#issuecomment-385800585,1,['encrypt'],['encryption']
Security,"It's hard to say what is going on here exactly...but a couple of clarifying questions here. You stated that importing to EBS was roughly 2x faster than Lustre (~1hr vs ~2hrs). Is that right? Are the vcfs on Lustre in both cases?. We're not sure exactly what is going on here...generally we do see some slowdown on shared filesystems compared to just private mounted disks. Do you have access to any CloudWatch metrics or the like? I'm not entirely sure what to look for there, but looking at IOPs over time, or transactions per second, read/write transaction size, etc might help show something interesting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7646#issuecomment-1044815768:385,access,access,385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7646#issuecomment-1044815768,1,['access'],['access']
Security,"It's not a surprise that a local disk is faster than a remote one, but the; magnitude of the difference is a lot more than I would expect. I remember; at the time using direct GCS access to get the best possible performance in; the bit I was working on, but I don't remember exactly how much of a; difference it made. From my desktop it takes 2m25s to download the whole file, so the ~6min; difference seems really excessive, something is broken. One thing to look; into is whether the sharding is working correctly (are we getting the; correct number of parallel downloads?). Presumably this code is using the HDFS adapter. It'll be interesting to; compare vs the NIO version (and then the optimized NIO version once I write; it).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-213094600:180,access,access,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-213094600,1,['access'],['access']
Security,"It's not clear to me that we want these tools in Gatk4. We deliberately didn't port them because we felt they were unnecessary going forward. . I understand that there are some legitimate use cases that require them: ex low coverage naive variant calling from high ploidy pools which haplotype caller would do poorly on. (Also, do we know that haplotype caller doesn't do well on those sorts of things? Maybe we should consider modifications there if it doesn't?) I'm not sure that supporting that use case is worth the added complexity of maintaining and supporting these tools. Especially since we don't provide a pileup based variant caller as part of gatk4... . @vdauwera Can you comment? . @sooheelee I'm not sure I agree with you that supporting this for mutect 1 is useful. ; A) We don't want to support the use of mutect 1 anymore and would like to encourage people to switch to mutect 2 which I think we now believe is a better variant caller for both snps and indels. ; B) Mutect 1 users are already using gatk3, so they have access to these tools already. Mutect 1 also requires co-cleaning which I believe is a different but related tool to indel realignment. . For the variant review issue, we have thoughts on implementing a much better solution for variant review by creating an assembly plugin for igv.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988:1036,access,access,1036,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988,1,['access'],['access']
Security,"It's true that our measurements have shown some improvement even in a random access case. Surely we should be able to fabricate a more extreme case where prefetching doesn't help, so it still makes sense to offer a choice.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482689496:77,access,access,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482689496,1,['access'],['access']
Security,It's weird that it worked before though if roles aren't set up right. It seems like security issues shouldn't be solved by asking people to upgrade their client software so that it can deny them permission.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940018:84,secur,security,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940018,1,['secur'],['security']
Security,Iterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); ```. I ran the same command again from my computer (not in the cloud) still using the NIO paths and it ran successfully. I've also seen it run successfully when running the same pipeline in the cloud. The only thing I think I've changed is the disk size I'm asking for. I'm in the process of validating the input bam right now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316:7467,validat,validating,7467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316,1,['validat'],['validating']
Security,Its use in `ValidateBasicSomaticShortMutations` seems limited to the integration test. Can I rewrite the test to do without `AnnotatedInterval` and call it a day?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526876913:12,Validat,ValidateBasicSomaticShortMutations,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526876913,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,"I’ll take a look at the somatic tests. They should be OK, probably just something related to kebab case changes. EDIT: Or hmm, maybe they weren't passing before. Something to do with annotated-interval validation, I think. I think the WDL tests should be using the Docker, which has g++. Travis machines might be slower?. Integration tests will need to be in the python test group. Take a look at the python tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350160424:202,validat,validation,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350160424,1,['validat'],['validation']
Security,"I’m sorry I wasn’t really keeping a good trail of the errors and it was a few weeks ago and I have been doing other stuff. . . I have a notation in my log about the run time switch and I seem to have gotten the notion about using it from reading stuff in one of the tutorials or on the forum. I gotta admit I am clueless about what the dictionary validation is actually doing so it wouldn’t have been anything that I conjured up on my own. . . From: Louis Bergelson <notifications@github.com> ; Sent: Wednesday, October 30, 2019 4:13 PM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: rdbremel <rdbremel017@gmail.com>; Mention <mention@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Funcotator shuts down (#6182). . Can you point out where in the log you see that? I'm looking at it but I don't see anything about memory in the log you provided. (Except the Runtime.totalMemory()=4523032576 which is just standard output spam from gatk when it shutsdown) Sequence dictionary validation usually happens first, it's strange that a failure in the middle of a run would be effected by it. I'm no very curious what weird thing is happening that's causing this... —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub <https://github.com/broadinstitute/gatk/issues/6182?email_source=notifications&email_token=ANCR2VFFO5775FSQO6EHFX3QRH2HHA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECVZCVA#issuecomment-548114772> , or unsubscribe <https://github.com/notifications/unsubscribe-auth/ANCR2VA3C2XW4BZEI5YNGITQRH2HHANCNFSM4I2MRFQA> . <https://github.com/notifications/beacon/ANCR2VFOYRDVUGP66IIIVHDQRH2HHA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECVZCVA.gif>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548119939:347,validat,validation,347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548119939,2,['validat'],['validation']
Security,Jc validate variants fixes issue5862,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5984:3,validat,validate,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5984,1,['validat'],['validate']
Security,JlbmRlci90b29scy9zcGFyay9BcHBseUJRU1JTcGFyay5qYXZh) | `50% <0%> (-50%)` | `3% <0%> (ø)` | |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `55% <0%> (-45%)` | `5% <0%> (-3%)` | |; | [...ute/hellbender/tools/walkers/UnmarkDuplicates.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1VubWFya0R1cGxpY2F0ZXMuamF2YQ==) | `45% <0%> (-45%)` | `5% <0%> (ø)` | |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `52.381% <0%> (-39.286%)` | `5% <0%> (-1%)` | |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ291bnRGYWxzZVBvc2l0aXZlcy5qYXZh) | `56.863% <0%> (-36.686%)` | `4% <0%> (-3%)` | |; | [...ender/engine/MultiVariantWalkerGroupedOnStart.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTXVsdGlWYXJpYW50V2Fsa2VyR3JvdXBlZE9uU3RhcnQuamF2YQ==) | `62% <0%> (-34.875%)` | `14% <0%> (-6%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `54.545% <0%> (-34.816%)` | `10% <0%> (-2%)` | |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pul,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662:2695,validat,validation,2695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662,1,['validat'],['validation']
Security,"Just it case, I want to add that ""origin/master)"" kind of outcome is just a possibility ... sometimes you may get a line like ```* (HEAD detached at 18ed19)``` and then it would be ```18ed19)```. So please refrain of trying to handle the detached ```origin/whatever``` case and rather provide a solution that works with any ""garbage"" that the ```git batch --contains HASH``` command may come out with. I would say that unless the output lines is a standard looking branch name (e.g perl regex: ```/\s*([a-zA-Z_0-9]*)\s*/```) then just omit this part of the name or fill it with something constant like a ""UNKNOWN"" or ""DETACHED"" or ""HEAD"" or ""SNAPSHOT""....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3642#issuecomment-333904259:367,HASH,HASH,367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3642#issuecomment-333904259,1,['HASH'],['HASH']
Security,"Just noting, as we discussed, this could allow us to condense coverage files, etc. We'd want to make sure that bins are always validated and that we don't introduce use cases that corrupt the bins (e.g., filtering bins). Also not really sure how hard indexing would be. Should be in conjunction with #4717. We are probably OK shuffling around relatively large interval and count files for the time being, but we can adjust priority when it makes sense (also depending on where htsjdk development is on these issues).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5702#issuecomment-466203330:127,validat,validated,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5702#issuecomment-466203330,1,['validat'],['validated']
Security,"Just some thoughts for @samuelklee. For example, CollectFragmentCounts produces the following hybrid-type `@RG` line:. ![screenshot 2018-02-22 15 05 48](https://user-images.githubusercontent.com/11543866/36908820-66b90938-1e0a-11e8-8830-793ff3f71e96.png). ```; @RG ID:GATKCopyNumber SM:HCC1143_tumor; ```; Official format specifications are at https://samtools.github.io/hts-specs/. Let me briefly describe the #choices. ---; If we are to follow conventions used in the alignment world (SAM specs, for interval lists), then... We note data transformations using `@PG` program groups. These can be added successively to the same data file, given unique `@PG ID` fields, and collectively these lines showcase the history of data transformations for a dataset. The `@RG` group is reserved for lane level data and yes, does unify based on the sample or library. ---; If we examine VCFs, the convention is to use `#` hashtags to denote header rows (VCF specs). Double hashtags `##` denote all metadata lines and a single hashtag `#` denotes the line with the column labels. Here are some select rows from an M2 VCF header:; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=artifact_in_normal,Description=""artifact_in_normal"">; ...; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ...; ##GATKCommandLine=<ID=FilterMutectCalls,CommandLine=""FilterMutectCalls...; ...; ##GATKCommandLine=<ID=Mutect2,CommandLine=""Mutect2 --tumor-sample HCC1143_tumor ...; ...; ##INFO=<ID=TLOD,Number=A,Type=Float,Description=""Tumor LOD score"">; ##Mutect Version=2.1-beta; ##command=FilterByOrientationBias --output hcc1143_T_clean-filtered.vcf...; ...; ##contig=<ID=chr1,length=248956422>; ##contig=<ID=chr2,length=242193529>; ...; ##contig=<ID=HLA-DRB1*16:02:01,length=11005>; ##filtering_status=These calls have been filtered by FilterMutectCalls to label false positives with a list of failed filters and true positives with PASS.; ##normal_sample=HCC1143_normal; #",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4481:912,hash,hashtags,912,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4481,1,['hash'],['hashtags']
Security,"Just the last commit. As requested by @LeeTL1220 to enable Intel to access task-level parameters for subworkflows. Note that this adds an unnecessary amount of boilerplate and will quickly become untenable if there are many identically named parameters. As discussed in #3980, this sort of thing really should be handled by Cromwell, otherwise there is not much benefit to using optional parameters. I've filed #4287 to revert when we can. Closes #3980.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4288:68,access,access,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288,1,['access'],['access']
Security,"Just to add - GenomicsDB relies on the filesystem for integrity checks just like any other file on the filesystem. We could add integrity checks at a micro chunk-level, but that would be at the expense of performance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-713055866:54,integrity,integrity,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-713055866,2,['integrity'],['integrity']
Security,"Just to make sure I understand the issue---will this cause technical problems in the Firecloud environment, or is it more of a style issue?. If the latter, one reason I prefer the use of optional file inputs to trigger tool-level ""modes"" when possible is that it propagates more naturally from the tool level. For example, let's consider a tool that can operate in either tumor-only or matched-pair mode. It is natural at the tool level to make the tumor a required input and the normal optional. The other options are quite awkward: 1) make both inputs required and switch between using the normal or not with a flag (in which case it is very easy for the user to shoot themselves in the foot if they forget to set the flag right, and we'd have to pass a dummy normal every time we want to run tumor only if we don't actually have a pair), 2) leave the normal as optional but add a flag anyway, which would be redundant and require an additional validation (i.e., if the flag is set to matched mode but we don't have a normal, we should fail early), or 3) write separate tools for each mode with the corresponding required inputs. If we accept that optional file input is the way to handle such a scenario at the tool level but not at the workflow level, then we will simply run into the same problems at the workflow level. I'm sure there are more complex scenarios when triggering on file presence/absence doesn't uniquely specify a workflow, in which case flags are a must. But for simple scenarios, I'm not sure why we shouldn't take advantage of the ability to specify optional file inputs in WDL (actually, I'm not sure how else we are supposed to use them?). However, if this is a problem for Firecloud, then I'd like to understand why---and what possible solutions there might be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334046444:947,validat,validation,947,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334046444,1,['validat'],['validation']
Security,"K Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:33:37.513 INFO Mutect2 - Deflater: IntelDeflater; 10:33:37.513 INFO Mutect2 - Inflater: IntelInflater; 10:33:37.514 INFO Mutect2 - GCS max retries/reopens: 20; 10:33:37.514 INFO Mutect2 - Requester pays: disabled; 10:33:37.514 INFO Mutect2 - Initializing engine; 10:33:37.874 INFO Mutect2 - Shutting down engine; [August 28, 2019 at 10:33:37 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=161480704; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:769); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:711); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:161); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291). This Issue was generated from your [forums] ; [forums",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6142:3382,validat,validateDictionaries,3382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6142,1,['validat'],['validateDictionaries']
Security,"KTool.java:525); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:728); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:79); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; GET https://storage.googleapis.com/storage/v1/b/fc-secure-bd7b8bc9-f665-4269-997e-5a402088a369/o?maxResults=1&prefix=5c2db926-3b1c-479c-9ed3-a99ce518de91/omics_mutect2/60955825-7723-4bc9-8202-bdd9975bb5c0/call-mutect2/Mutect2/7d737efc-c8be-4a6d-8803-4f786129521a/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list.idx/&projection=full&userProject; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""User project specified in the request is invalid."",; ""reason"" : ""invalid""; } ],; ""message"" : ""User project specified in the request is invalid.""; }; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:428); 	at com.google.api.client.http.HttpRequest.e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716:4064,secur,secure-,4064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716,1,['secur'],['secure-']
Security,"Keeping the dockstore as is for now because I may want to run this on a few shards from the 30k while it's still in review. This pr adds a fair amount of work to the bcftools task (ExtractAnAcAfFromVCF) and adds a significant number of columns to the schema: the sample count for all of the samples, as well as for each subpopulation. Note that AC_hemi will be added in a follow on pr; Note that additional validation tests will be added in a follow on pr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7456:407,validat,validation,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7456,1,['validat'],['validation']
Security,Kryo issue tracking this here is here https://github.com/EsotericSoftware/kryo/issues/382. Temporary fix is to run with the following set:. ```; spark.executor.extraJavaOptions –XX:hashCode=0; spark.driver.extraJavaOptions –XX:hashCode=0; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1524#issuecomment-189368808:181,hash,hashCode,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1524#issuecomment-189368808,2,['hash'],['hashCode']
Security,Leave validation cluster running at end [VS-901],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8729:6,validat,validation,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8729,1,['validat'],['validation']
Security,"Legacy pipeline (note, the following should only be done after final ModelSegments PR is in):; - [x] Delete prototype tools. (#3887) (SL, PR issued by 12/1); - ~~Add deprecated/legacy tag to legacy pipeline tools. (SL, PR issued by 12/1 EDIT: need further input from @vdauwera )~~; - ~~Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826:688,expose,exposed,688,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826,1,['expose'],['exposed']
Security,"Let me know if you want more methods exposed, or need any help in general.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2072#issuecomment-236905536:37,expose,exposed,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2072#issuecomment-236905536,1,['expose'],['exposed']
Security,"Let's create a mock up of a possible future configuration setup using the Owner library (https://github.com/lviggiano/owner). For the mock up, I recommend we have two configuration files, one containing system properties and the other containing a few general engine settings. . We can select a few system properties from `gatk-launch` for inclusion in the system properties config file (eg., `samjdk.compression_level`, `samjdk.use_async_io_read_samtools`, etc.). . For the engine settings file, I recommend including `codecPackages` (a `List<String>` currently hardcoded in `FeatureManager.CODEC_PACKAGES`), `cloudPrefetchBuffer`/`cloudIndexPrefetchBuffer` (int values) from `GATKTool`, and `createOutputBamIndex` (boolean), also from `GATKTool`. As part of this, we'll have to prove that we can inject the system properties sufficiently early on that libraries such as htsjdk will pick them up.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3126:798,inject,inject,798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126,1,['inject'],['inject']
Security,"Let's discuss further before you get too far along. The design of the Collections code was intended to ensure that very strict file formats are adhered to within the CNV pipeline. Making it more flexible to accommodate TSVs with arbitrary column headers, relax requirements for sequence dictionaries, etc. undermines that goal. There are also two other issues to consider:. 1) It looks like @jonn-smith has also been putting considerable effort into building a TSV framework for Funcotator. Perhaps CombineSegmentBreakpoints should consider using that framework instead, if it is more appropriate. We can also discuss bringing the CNV pipeline over into that framework, but this should definitely wait until after release. The end goal is for CNV team to spend as little time as possible writing or maintaining any code related to TSV parsing. 2) @mbabadi has put together some python evaluation code for the new gCNV, which makes use of the IntervalTree python package and PyVCF to accomplish some things that are very similar to what CombineSegmentBreakpoints is doing. Perhaps we could implement a similar approach purely in Java by making use of the IntervalTree implementation in htsjdk. I think for now we should treat CombineSegmentBreakpoints as a one-off tool to be used for internal validations. After release, we should design a more generic evaluation tool. This tool could take as input multiple collections of annotated locatables, with a few rigidly defined formats allowed (e.g., VCF, CNV Collection TSVs, perhaps some TSVs from other tools, etc.), with one designated as ground truth. The regions for evaluation could also be specified via -L (since it is possible this might not completely specified by the ground-truth collection). The appropriate intersections and lookups could then be performed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352860616:1293,validat,validations,1293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352860616,1,['validat'],['validations']
Security,"Let's talk about groupReadPairs, pairedReads, and unpairedReads. The groupBy method called by groupReadPairs is very expensive both in time and in memory. It's a full hash shuffle of GATKReads (time expensive), that results in a gazillion 1- and 2-element Lists (memory expensive). So you certainly don't want to do it twice. But the way pairedReads and unpairedReads is set up, you *will* do it twice if you want to process both paired and unpaired reads. (And even if you aren't, someone else might try to use this code to do so.). So my first suggestion is that you remove the call to groupReadPairs from pairedReads and unpairedReads, and let a user groupReadPairs once, and reuse the resulting JavaPairRDD to process paired and unpaired reads. My second suggestion is quite a bit more complicated, but I think it would result in far better performance. I'll sketch it out here, and then I can explain it further in person, if it's a direction you'd like to pursue. The first step is to create a JavaRDD<GATKRead> in which all pairs sharing a template name are in the same partition (but without grouping them). To do that, you temporarily boost the input JavaRDD into a JavaPairRDD<String,GATKRead> by extracting the read name as a key. Then you repartition (to do the shuffle). Then you map back to an ordinary JavaRDD<GATKRead> by keeping just the value. (Note: if the BAM has queryname sort order, you can just skip this step entirely.); Now you can do a mapPartition operation to filter for paired or unpaired reads: Iterate over the reads in the partition, and keep a hash map of [name -> read] of reads that have not yet found mates. To filter for paired reads, whenever you find the name of the current read already in the table, just emit the current read and the read in the map as a pair, and delete the read from the map (you're done with that name -- this keeps the table smaller). To filter for unpaired reads, just delete any map entry that you successfully look up, and insert any ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2664#issuecomment-299955039:167,hash,hash,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2664#issuecomment-299955039,1,['hash'],['hash']
Security,"Likely an analogous problem to #1417. ```; ./gatk-launch MarkDuplicatesSpark -I file:///home/unix/louisb/flag_stat.bam -O file:///home/unix/louisb/testoutput.bam -- --sparkRunner SPARK --sparkMaster yarn-client; ```. results in:. ```; java.lang.IllegalArgumentException: Wrong FS: file:/home/unix/louisb/testoutput.bam, expected: hdfs://dataflow01.broadinstitute.org:8020; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:654); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105); at org.apache.hadoop.hdfs.DistributedFileSystem$12.doCall(DistributedFileSystem.java:645); at org.apache.hadoop.hdfs.DistributedFileSystem$12.doCall(DistributedFileSystem.java:641); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:641); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.deleteHadoopFile(ReadsSparkSink.java:200); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:191); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:106); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.runTool(MarkDuplicatesSpark.java:94); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:257); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); at org.broadinstitute.h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1451:581,access,access,581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1451,1,['access'],['access']
Security,List data access patterns in Picard/GATK/Foghorn,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1:10,access,access,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1,1,['access'],['access']
Security,Long file names prevent cloning GATK on system with encrypted /home,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4718:52,encrypt,encrypted,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4718,1,['encrypt'],['encrypted']
Security,"Looks like the problem occurs when the cram dictionary is ""compatible"" with the reference dictionary according to our validation routines, but the reference dictionary does not contain all contigs from the cram dictionary. We are going to make our dictionary validation stricter to prevent this (https://github.com/broadinstitute/hellbender/issues/802). We should also patch htsjdk to throw a nicer error than `NullPointerException` in this case -- ie., insert a check after `CRAMIterator` line 158 that throws a `RuntimeException` with a nice ""contig from cram header not found in reference"" message if refs == null. Once the above patch goes into htsjdk we can close this ticket and focus on the validation issue in https://github.com/broadinstitute/hellbender/issues/802",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/793#issuecomment-130344138:118,validat,validation,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/793#issuecomment-130344138,3,['validat'],['validation']
Security,"Lots of the test input VCFs (and some expected test VCFs) are invalid: GQs that don't match their PLs (which should get fixed by the time I'm done with #3404 ), the wrong number of PLs for the alleles in the VC (src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/SelectVariants/vcfexample.loseAlleleInSelection.vcf) and probably more issues too. It's hard to be confident our output VCFs are correct when the expected behavior is sometimes wrong. Ideally we should run GATK ValidateVariants and/or vcftools validate on all the test VCFs (input and expected) and ensure files are valid where weren't not testing format/parsing issues.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3407:499,Validat,ValidateVariants,499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407,2,"['Validat', 'validat']","['ValidateVariants', 'validate']"
Security,"M 1.8.0_25-b17; Version: Version:4.pre-alpha-210-gd7179f7-SNAPSHOT JdkDeflater; 07:07:56.668 INFO PrintReads - Initializing engine; 07:07:56.815 INFO PrintReads - Shutting down engine; [December 5, 2015 7:07:56 AM EST] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=257425408; ***********************************************************************. A USER ERROR has occurred: Input files reference and reads have incompatible contigs: Found contigs with the same name but different lengths: ; contig reference = 1 / 1000000; contig reads = 1 / 249250621.; reference contigs = [1]; reads contigs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, X, Y, MT, GL000207.1, GL000226.1, GL000229.1, GL000231.1, GL000210.1, GL000239.1, GL000235.1, GL000201.1, GL000247.1, GL000245.1, GL000197.1, GL000203.1, GL000246.1, GL000249.1, GL000196.1, GL000248.1, GL000244.1, GL000238.1, GL000202.1, GL000234.1, GL000232.1, GL000206.1, GL000240.1, GL000236.1, GL000241.1, GL000243.1, GL000242.1, GL000230.1, GL000237.1, GL000233.1, GL000204.1, GL000198.1, GL000208.1, GL000191.1, GL000227.1, GL000228.1, GL000214.1, GL000221.1, GL000209.1, GL000218.1, GL000220.1, GL000213.1, GL000211.1, GL000199.1, GL000217.1, GL000216.1, GL000215.1, GL000205.1, GL000219.1, GL000224.1, GL000223.1, GL000195.1, GL000212.1, GL000222.1, GL000200.1, GL000193.1, GL000194.1, GL000225.1, GL000192.1, NC_007605]. ***********************************************************************; ```. I think you meant ""the Picard version of this metric does not complain"", which is expected given that Picard tools do not do the same automatic sequence dictionary validation as walkers and spark tools. If you think they should, you should create a different ticket ""Multi-input Picard tools and metrics should perform sequence dictionary validation on their inputs"" or file a specific bug against the Picard version of `CollectQualityYieldMetrics`. Closing",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1262#issuecomment-162176558:2773,validat,validation,2773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1262#issuecomment-162176558,2,['validat'],['validation']
Security,M2 VCFs do not validate,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3296:15,validat,validate,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3296,1,['validat'],['validate']
Security,"MIGRATED FROM GATK3. @ldgauthier commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053). Currently ValidateVariants relies on genotypes to transitively check that each alt allele occurs in at least one sample and that the AC adds up. However, this can fail on sites-only files because there are no genotypes. We should use the definition of the info annotations in the header to check how many entries each should have.; ### Outline; - Add a new validation type for info-field counts to enum and to switch statement; - Grab info headers from input VCF with something like GATKVCFUtils.getVCFHeadersFromRods(getToolkit(), variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; - In the map() function, for each info header line, call on each VCFInfoHeaderLine getCount(vc) to get the expected number of info annotation entries; - Compare the expected number with a count based on vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some additional parsing because it returns an Object; - (Bonus points if you use the isFixedCount() and getCount() functions on the VCF info header line to simplify annotations that aren't according to the number of alt alleles); ### Test data. /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; Should fail AC/AF validation at ; `1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120`; See results using:. ```; use VCFtools; vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; ```. which outputs:; `INFO field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:135,Validat,ValidateVariants,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,"MProxy: Connecting to ResourceManager at mg/10.131.101.159:8032; 17/10/13 18:11:36 INFO yarn.Client: Requesting a new application from cluster with 3 NodeManagers; 17/10/13 18:11:36 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per container); 17/10/13 18:11:36 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/13 18:11:36 INFO yarn.Client: Setting up container launch context for our AM; 17/10/13 18:11:36 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/13 18:11:36 INFO yarn.Client: Preparing resources for our AM container; 17/10/13 18:11:37 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-c7e5eece-205e-4bce-a69b-4168c9b79045/__spark_conf__2918234914787361986.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507856833944_0003/__spark_conf__.zip; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); groups with view permissions: Set(); users with modify permissions: Set(hdfs); groups with modify permissions: Set(); 17/10/13 18:11:37 INFO yarn.Client: Submitting application application_1507856833944_0003 to ResourceManager; 17/10/13 18:11:37 INFO impl.YarnClientImpl: Submitted application application_1507856833944_0003; 17/10/13 18:11:37 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1507856833944_0003 and attemptId None; 17/10/13 18:11:38 INFO yarn.Client: Application report for application_1507856833944_0003 (state: ACCEPTED); 17/10/13 18:11:38 INFO y",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:10558,Secur,SecurityManager,10558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['Secur'],['SecurityManager']
Security,Make GCS authentication work without using dataflow options classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/963:9,authenticat,authentication,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/963,1,['authenticat'],['authentication']
Security,Make PathSeq test BAMs pass ValidateSamFile,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3204:28,Validat,ValidateSamFile,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3204,2,['Validat'],['ValidateSamFile']
Security,Make a bunch of in silico contaminated samples and validate contamination tool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3256:51,validat,validate,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3256,1,['validat'],['validate']
Security,Make sequence dictionary validation a bit less strict,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/877:25,validat,validation,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/877,1,['validat'],['validation']
Security,Make sequence dictionary validation in BQSR dataflow work when the reference is in a bucket,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/737:25,validat,validation,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/737,1,['validat'],['validation']
Security,Make some noise when VDS validation succeeds,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8155:25,validat,validation,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8155,1,['validat'],['validation']
Security,"Makes CreateVariantIngestFiles robust to partially or fully loaded samples. Commit 21828af8f5a925cc331dce6093c0d510042d7b64 is what I actually propose to merge, while commit de673204183a4c45059dc9ea4e05868e2ea6ae59 randomly injects failures covering all the known failure modes. I tested these changes using both commits and was able to verify that partially loaded samples were handled correctly on subsequent attempts to load the sample (unfortunately we can't actually prevent these partial loadings from happening in the first place because preemptions, among other possible reasons).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7843:224,inject,injects,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7843,1,['inject'],['injects']
Security,"Makes `CreateVariantIngestFiles` robust to partially or fully loaded samples. Commit a8dc5ea89653a7f94588aa040b49d0264d17f72d is what I actually propose to merge, while commit 118a44604343e8f77d53bcc6545b2360fefbe1cc randomly injects failures covering all the known failure modes. I tested these changes using both commits and was able to verify that partially loaded samples were handled correctly on subsequent attempts to load the sample (unfortunately we can't actually prevent these partial loadings from happening in the first place because preemptions, among other possible reasons).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7831:226,inject,injects,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7831,1,['inject'],['injects']
Security,"Managers; 17/10/13 18:11:36 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per container); 17/10/13 18:11:36 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/13 18:11:36 INFO yarn.Client: Setting up container launch context for our AM; 17/10/13 18:11:36 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/13 18:11:36 INFO yarn.Client: Preparing resources for our AM container; 17/10/13 18:11:37 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-c7e5eece-205e-4bce-a69b-4168c9b79045/__spark_conf__2918234914787361986.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507856833944_0003/__spark_conf__.zip; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); groups with view permissions: Set(); users with modify permissions: Set(hdfs); groups with modify permissions: Set(); 17/10/13 18:11:37 INFO yarn.Client: Submitting application application_1507856833944_0003 to ResourceManager; 17/10/13 18:11:37 INFO impl.YarnClientImpl: Submitted application application_1507856833944_0003; 17/10/13 18:11:37 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1507856833944_0003 and attemptId None; 17/10/13 18:11:38 INFO yarn.Client: Application report for application_1507856833944_0003 (state: ACCEPTED); 17/10/13 18:11:38 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:10710,Secur,SecurityManager,10710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['Secur'],['SecurityManager']
Security,"MannWhitneyU was re-written from scratch in 2016 in GATK3,; but these changes never got ported to GATK4. This new version; produces significantly different results from the version; currently in GATK4, resulting in VERY different values for the; RankSumTest annotations in HaplotypeCaller output. @meganshand informs me that the updated GATK3 version has been; validated in R, and has much better tests than the old version. This is a straightforward port of that version with minimal changes:. -Merged ""MWUnitTest"" and ""RankSumUnitTest"" from GATK3 into a single; test class MannWhitneyUUnitTest; -Ported MathUtils.binomialCoefficient() and wrote new test for it; -Updated RankSumTest class and tests as appropriate. I've confirmed that with this change, the RankSum annotations produced; by the GATK4 HaplotypeCaller closely match those produced by the GATK3; HaplotypeCaller. Resolves #2604",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2605:361,validat,validated,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2605,1,['validat'],['validated']
Security,Many times the question comes up of whether variants are lost in HaplotypeCaller and Mutect2 because they are not assembled. It seems like an easy and scalable way to answer this would be to emit an optional sites-only vcf of all variants in the `EventMap` before genotyping. That way we could do internal validations about assembly much faster than currently. and user questions in this vein would not require the IDE or looking at bamouts in IGV. I envision something like this:; ```; gatk Mutect2 -I tumor.bam -O out.vcf --assembled-variants assembled.vcf; gatk SelectVariants truth.vcf --discordance assembled.vcf -O assembly-false-negatives.vcf; ```. @ldgauthier @yfarjoun what do you think about this?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5426:306,validat,validations,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5426,1,['validat'],['validations']
Security,"Maybe I misunderstand the underlying model, but if some Pedigree annotations only need to know which samples are founders (ExcessHet ?) , and some need to know the full relationships (PossibleDeNovo), then I'm suggesting we change the class hierarchy to reflect that:. PedigreeAnnotation; |--TrioAnnotation; |----PossibleDeNovo; |--ExcessHet (assuming ExcessHet only needs founders...); ... Then the plugin could deterministically validate whether the user has provided sufficient args for the set of requested annotations; and if so, propagate them accordingly. A TrioAnnotation could only be populated (from the command line at least) from a file, whereas the others could be populated from either a file or just a set of IDs. I think it would simplify the annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550:431,validat,validate,431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550,1,['validat'],['validate']
Security,Merge adjacent blocks when validating GVCFs so we use less memory and dont fail when not using an interval argument,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3445:27,validat,validating,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3445,1,['validat'],['validating']
Security,"Merging this according to discussion with @LeeTL1220. We still need to investigate some possible regressions in the CRSP validation, but we should be good for prerelease on the CNV somatic side. There is one last branch (#4061) on the germline side, but I think we didn't plan on having gCNV ready for prerelease.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355665197:121,validat,validation,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355665197,1,['validat'],['validation']
Security,"Meta-comments for reviewers: the new program groups in this PR are based on @sooheelee 's spreadsheet, including some that are placeholders for things that will soon live in Picard, but aren't accessible from there yet. I've left the old program groups intact because they're still being referenced by tools. As the doc PRs are merged in, eventually these will be left dangling with no references, and then we'll remove them. In the meantime we'll have some redundancies (ReadProgramGroup will be replaced by ReadDataProgramGroup, or whatever we settle on).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-349722389:193,access,accessible,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-349722389,1,['access'],['accessible']
Security,"Minimally, VariantWalkerSpark, but we should also audit the other classes included in https://github.com/broadinstitute/gatk/pull/2256/files to see if readFilters are properly propagated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2338:50,audit,audit,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2338,1,['audit'],['audit']
Security,"MisencodedBaseQualityReads Fix Illumina base quality scores in a SAM/BAM/CRAM file; FlagStat A reimplementation of the 'samtools flagstat' subcommand; GatherBQSRReports Gathers scattered BQSR recalibration reports into a single file; GatherBamFiles Concatenates one or more BAM files together as efficiently as possible; LeftAlignIndels Left-aligns indels from reads in a SAM/BAM/CRAM file; MarkDuplicates Examines aligned records in the supplied SAM/BAM/CRAM file to locate duplicate molecules.; MergeBamAlignment Merges alignment data from a SAM/BAM with data in an unmapped SAM/BAM/CRAM file; MergeSamFiles Merges multiple SAM/BAM files into one file; PrintReads Print reads in the SAM/BAM/CRAM file; ReorderSam Reorders reads in a SAM/BAM file to match ordering in reference; ReplaceSamHeader Replace the SAMFileHeader in a SAM/BAM file with the given header; RevertBaseQualityScores Revert Quality Scores in a SAM/BAM/CRAM file; RevertOriginalBaseQualitiesAndAddMateCigar Reverts the original base qualities and adds the mate cigar tag to read-group BAMs; RevertSam Reverts SAM/BAM files to a previous state; SamFormatConverter Convert a SAM/BAM/CRAM file to a SAM/BAM/CRAM file; SamToFastq Converts a SAM/BAM file into a FASTQ; SortSam Sorts a SAM/BAM/CRAM file; SplitNCigarReads Split Reads with N in Cigar; SplitReads Outputs reads from a SAM/BAM/CRAM by read group, sample and library name; UnmarkDuplicates Unmark duplicates in a SAM/BAM/CRAM file; ValidateSamFile Validates a SAM/BAM/CRAM file. --------------------------------------------------------------------------------------; Spark Validation tools: Tools written in Spark to compare aspects of two different files; CompareBaseQualitiesSpark Diff qs of the BAMs; CompareDuplicatesSpark Compares two BAMs for duplicates. --------------------------------------------------------------------------------------; Spark pipelines: Pipelines that combine tools and use Apache Spark for scaling out (experimental); BQSRPipelineSpark Both st",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1669:6290,Validat,ValidateSamFile,6290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1669,2,['Validat'],"['ValidateSamFile', 'Validates']"
Security,"Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Refactor main code block for model training; it's a bit monolithic and procedural now.; - [x] Decide on behavior for ill-behaved annotations. E.g., all missing, zero variance. Future work:. - [ ] We could allow subsetting of annotations here, which might allow for easier treatment of ill-behaved annotations. However, I'd say enabling workflows where the set of annotations is fixed is the priority.; - [ ] We could do positive-unlabeled training more rigorously or iteratively. Right now, we essentially do a single iteration to determine negative data. This could perhaps be preceded by a round of refactoring to clean up model training and make it less procedural.; - [ ] Automatic threshold tuning could be built into the tool, see #7711. We'd probably have to introduce a ""validation"" label. Perhaps it makes sense to keep this sort of thing at the workflow level?; - [ ] In the positive-negative framework enforced by the Java code in this tool, a ""model"" is anything that assigns a score, we fit two models to different subsets of the data, and then take the difference of the two scores. While the python backend does give some freedom to specify a model, future developers may want to go beyond the framework itself. For example, more traditional classification frameworks, etc. could be explored. As an intermediate step, one could perhaps use the positive/negative scores from the current framework in a more sophisticated way (e.g., using them as features), rather than just taking their difference. This sort of future work could be developed completely independently of the codebase associated with the current training tool (or done externally in python), but should still be able to make use of the extract and score tools, since the contracts should be",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369:1589,validat,validation,1589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369,1,['validat'],['validation']
Security,Moot because @samuelklee replaced uses of `HashedListTargetCollection` with `OverlapDetector`.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1754#issuecomment-357482326:43,Hash,HashedListTargetCollection,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1754#issuecomment-357482326,1,['Hash'],['HashedListTargetCollection']
Security,More fix enum hashCode,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4623:14,hash,hashCode,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4623,1,['hash'],['hashCode']
Security,"Most likely not. We've validated that we don't need it for DNA, it's hard to imagine that would be different for RNA.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1394#issuecomment-231498501:23,validat,validated,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1394#issuecomment-231498501,1,['validat'],['validated']
Security,"Most methods in `FuncotatorUtils` take a `SequenceComparison` object as input. This should be changed to either:. 1. Take the base fields as arguments (i.e. whatever is accessed in the `SequenceComparison` object). or . 2. For each method taking a `SequenceComparison`, create a `canCall` method that takes a `SequenceComparison` and returns a boolean - whether, based on the assigned fields in the `SequenceComparison` object, you can call the method itself.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3959:169,access,accessed,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3959,1,['access'],['accessed']
Security,"Most spark tools use the one in GATKSparkTool, but some have some special requirements that make it not work for them. They have to specify different sequence dictionaries or something like that in a way that isn't exposed. Maybe something could be refactored there, but they needed manually adjusting to match the new behavior because of their special handling of the writing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6458#issuecomment-594167389:215,expose,exposed,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6458#issuecomment-594167389,1,['expose'],['exposed']
Security,Moved validation test data out of large files area.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5381:6,validat,validation,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5381,1,['validat'],['validation']
Security,"Moving to [GenomicsDB 1.4.1 ](https://github.com/GenomicsDB/GenomicsDB/releases/tag/v1.4.1)release will allow for the direct use of the native GCS C++ client instead of the GCS Cloud Connector via HDFS. The GCS Cloud Connector can still be used with GenomicsDB via the `--genomicsdb-use-gcs-hdfs-connector` option. Using the native client with gcs allows for GenomicsDB to use the standard paradigms to help with authentication, retries with exponential backoff, configuring credentials, etc. The defaults are all hardcoded to match what is in gatk at present. It also helps with performance issues with gcs, see #7070. This version also contains fixes for #7089, although it will require additional support from gatk(will be part of a separate PR).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7224:413,authenticat,authentication,413,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7224,1,['authenticat'],['authentication']
Security,Multi-input Picard tools and metrics should perform sequence dictionary validation on their inputs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1272:72,validat,validation,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1272,1,['validat'],['validation']
Security,MultiVariantWalker sequence dictionary cross-validation is miserable,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6589:45,validat,validation,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6589,1,['validat'],['validation']
Security,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:362,access,accesses,362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716,2,['access'],['accesses']
Security,"Mutect2.wdl: ""pet-@.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492:74,access,access,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492,1,['access'],['access']
Security,My branch only validates the lengths of some annotations of type list -- I didn't add any checks with respect to the spec.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6762#issuecomment-705185296:15,validat,validates,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6762#issuecomment-705185296,1,['validat'],['validates']
Security,My hypothesis is that the many accesses exhausts something along the path and that something as a result rejects all connections. Perhaps to serve a client they need a file handle and there's a limit of < 1e6 handles? . If we really need to open this many perhaps we should try to put together a minimal program that reproduces the problem and then submit that to cloud support.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308586876:31,access,accesses,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308586876,1,['access'],['accesses']
Security,"My problem is fixed with the first commit, because if `customCommandLineValidation()` throws an `UserException.CommandLineException` it is catched and printed (otherwise, it is ignore in `Main`, except for the returning status). Anyway, I added a commit with the implementation of the void method for all the tools. I guess that it is not a good idea after all, because it could help to print several errors. My first commit deal with the two situations, printing one/several errors if the `String[]` is not null, and if the validation throws an error catching it and handle in the same way as the ones in `CommandLineProgram`. I will rather go for the first and changing the printing of the errors in the array to the same place as the catched exceptions, and decorate it in the same way for not confusing the software user. What do you thing, @lbergelson?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255856456:525,validat,validation,525,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255856456,1,['validat'],['validation']
Security,"My recollection is that this is a use case we never put any priority on so there's no test in the GATK suite for access to private files. There should be, of course. The feature is there and (at least locally) it worked when I tried it. NIO does not use the API_KEY, it uses default credentials. Those are environment variables that are set by the `gcloud` command or pre-set for you in the case of virtual machines on Google. There are two cases: local execution and Spark. . I just tested local execution and it worked fine for me:. ```; $ ./gatk-launch PrintReads -L Broad.human.exome.b37.small.interval_list -I gs://jpmartin-private/bench/WGS-G94982-NA12878.bam -O t_gcs.bam; ```. this command worked even though (unless I'm mistaken) neither the bucket nor the file are public. One challenge however is that the way to set default credentials has changed recently. Calling `gcloud auth login` used to be enough but now we have to call (IIRC) `gcloud auth application-default login`. For Spark, the default credentials are set as whoever owns the dataproc environment that's used to run the show. So it should be set so it has access to the buckets necessary. NIO has mechanisms for accessing buckets that belong to someone other than who is running the Spark job, but they are not hooked into GATK yet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277832658:113,access,access,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277832658,3,['access'],"['access', 'accessing']"
Security,"My suspicion was wrong. We also include a safety check which cause us to correctly reject most accidental matches. If we detect 2 chromosomes with the same name but different lengths we fail even if we detect otherwise matching chromosomes. I've run all the dictionaries I could find in the gatk bundle against each and only b37 and b37_decoy are compatible with each other which is the desired behavior I believe. | | hg18 | hg19 | b37 | b37_decoy | hg38 |; | -- |------|-----|------|-----------|-------|; | hg18 | ✅ | | | | |; | hg19 | | ✅ | | | |; | b37 | | | ✅ | ✅ | |; | b37_decoy | | | ✅ | ✅ | |; | hg38 | | | | | ✅ |. ```; @DataProvider; public Iterator<Object[]> getComparisons(){; final ArrayList<Object[]> comparisons = new ArrayList<>();; final List<String> dicts = Arrays.asList(""Homo_sapiens_assembly18.dict"",; ""ucsc.hg19.dict"",; ""human_b36_both.dict"",; ""human_g1k_v37.dict"",; ""human_g1k_v37_decoy.dict"",; ""Homo_sapiens_assembly38.dict"");; for( String left : dicts) {; for (String right: dicts){; Path leftDict =Paths.get(""/Users/louisb/Downloads/dicts"", left);; Path rightDict = Paths.get(""/Users/louisb/Downloads/dicts"", right);. comparisons.add( new Object[] {leftDict, rightDict});; }; }; return comparisons.iterator();; }. @Test(dataProvider = ""getComparisons""); public void testSequenceDictionariesAgainstEachother(Path left, Path right){; String leftName = left.getFileName().toString();; String rightName = right.getFileName().toString();; SequenceDictionaryUtils.validateDictionaries(leftName,; SAMSequenceDictionaryExtractor.extractDictionary(left),; rightName,; SAMSequenceDictionaryExtractor.extractDictionary(right));; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3754#issuecomment-494924193:1485,validat,validateDictionaries,1485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3754#issuecomment-494924193,1,['validat'],['validateDictionaries']
Security,"NFO: Registering coder for VariantAnnotation; Jul 14, 2015 1:14:51 PM com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds registerGenomicsCoders; INFO: Registering coder for SearchAnnotationSetsRequest; Jul 14, 2015 1:14:51 PM com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds registerGenomicsCoders; INFO: Registering coder for RangePosition; Jul 14, 2015 1:14:51 PM com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds registerGenomicsCoders; INFO: Registering coder for SearchJobsRequest; Jul 14, 2015 1:14:51 PM com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds registerGenomicsCoders; INFO: Registering coder for ExportVariantSetRequest; 15/07/14 13:14:51 INFO spark.SparkPipelineRunner: Executing pipeline using the SparkPipelineRunner.; 15/07/14 13:14:51 INFO spark.SparkContext: Running Spark version 1.3.1; 15/07/14 13:14:51 INFO spark.SecurityManager: Changing view acls to: louisb; 15/07/14 13:14:51 INFO spark.SecurityManager: Changing modify acls to: louisb; 15/07/14 13:14:51 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(louisb); users with modify permissions: Set(louisb); 15/07/14 13:14:52 INFO slf4j.Slf4jLogger: Slf4jLogger started; 15/07/14 13:14:52 INFO Remoting: Starting remoting; 15/07/14 13:14:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@wm1b0-8ab.broadinstitute.org:65238]; 15/07/14 13:14:52 INFO util.Utils: Successfully started service 'sparkDriver' on port 65238.; 15/07/14 13:14:52 INFO spark.SparkEnv: Registering MapOutputTracker; 15/07/14 13:14:52 INFO spark.SparkEnv: Registering BlockManagerMaster; 15/07/14 13:14:52 INFO storage.DiskBlockManager: Created local directory at /var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/louisb/spark-7b286138-5fde-4fcb-bc34-3c6a86da6c0c/blockmgr-46eb69b0-d3ca-4004-bf32-ab103c0787f2; 15/07/14 13:14:52 INFO storage.MemoryStore: MemoryStore started with capacity 265.1 MB; 15/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:16276,Secur,SecurityManager,16276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['Secur'],['SecurityManager']
Security,"NIO uses the gcloud system authentication, so we shouldn't need this anymore.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2402:27,authenticat,authentication,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2402,1,['authenticat'],['authentication']
Security,"Need some guidance here. The CompareSAMs tool was not propagating the validation stringency. I have a fix for that, but that alone doesn't fix the compareBAMFiles test in BaseRecalibrationIntegrationTest.java, since that uses SamAssertionUtils.assertSamsEqual, which also doesn't propagate (or accept) a validation stringency. Changing SamAssertionUtils to use either SILENT or LENIENT does fix the integration test, and all the other tests pass, but it seems like a relaxing of the stringency, and I'm not sure it should be necessary to the BQSR test. If relaxing the stringency for BQSR test _IS_ the right path, one possibility is to add a new method to SamAssertionUtils that accepts a validation stringency argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419#issuecomment-109796266:70,validat,validation,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419#issuecomment-109796266,3,['validat'],['validation']
Security,"New version allows restricting which users can trigger carrot jobs based on their access to the repository. In this case, I've set it to restrict to only users who have at least write access.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6986:82,access,access,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6986,2,['access'],['access']
Security,"No problem – I can see how this would be challenging to review – maybe it’s not even practical – if you decide it’s best just not to use it that’s OK - working on these issues has been a valuable learning experience for me. . I sent an archive with the new validations and the diffs between the old and new bams to akiezun. Although in many cases the files shared types of errors, I had to look at each file individually to take into account the particular errors in each file and how to fix them without (to the best of my knowledge) interfering with the purpose of the test. I did write a python script to use where necessary for converting multiple unpaired reads in a file to single reads, and I used bash scripts to call the picard tools to convert multiple files at a time from bam to sam for editing and then back again after they were modified. In some cases I had to modify the values in test output files to match the values produced by the test using the modified bams/sams, or just capture the new output files and use them to replace the old with the new. In two cases where file format errors appeared to be necessary but the filename did not indicate this, I renamed the files to make this clear. From: Louis Bergelson ; Sent: Thursday, August 20, 2015 2:13 PM; To: broadinstitute/hellbender ; Cc: nenewell ; Subject: Re: [hellbender] Issue 569 - bam and sam file cleanup. (#809). @nenewell Sorry this has been sitting. We've been trying to figure out how to review this one. Could you describe how you made the changes? Did you script it or go through by hand and modify them all?. —; Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/809#issuecomment-133123051:257,validat,validations,257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/809#issuecomment-133123051,1,['validat'],['validations']
Security,No validation here. I was satisfied with the validation from the Palantir report and using this as a robustness test to show that GATK4 HC isn't going to fall over. I have a matched list of GVCFs here: /humgen/gsa-hpprojects/dev/gauthier/scratch/newQualHC/check.list @skwalker could you adapt your analysis to run with this list? I'll need to give you a different jar for the GenotypeGVCFs step on my GVCFs since the annotation format is outdated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380822981:3,validat,validation,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380822981,2,['validat'],['validation']
Security,"Normally one provides passing workflow runs with a PR. For the integration run [that is here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ab86fb6d-c5d6-48b6-8322-923af691751c). There's also a ""real"" run taking place using this branch [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/db59d5b8-e2ac-4619-9563-aa5631bf053c). However for testing correctness of these changes with respect to the requester pays flag, my pet ""does not have serviceusage.services.use access to the Google Cloud project"". I therefore present instead a [run with my changes](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9e712055-f466-4929-b6eb-5306f3cde1a0) that fails in exactly the same way as a [run without my changes](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/185506f5-9dc1-4c02-997d-6fe3f5695259).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8552:500,access,access,500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8552,1,['access'],['access']
Security,"Not bad, but why can't the BAM be split as multiple objects in the same bucket where the directory is the name of the BAM. I was having this discussion with Dion at the following thread:. https://github.com/googlegenomics/utils-java/issues/62#issuecomment-220444203. You can have a folder in the GS location be the name of the BAM, and even sort them like a distributed B-tree. This way you can even simultaneously process reads as new data is streaming in from the GS location. Since the Google disk IOPS are as follows, based on the following link:. https://cloud.google.com/compute/docs/disks/performance#type_comparison. | Read | Write |; | --- | --- |; | 3000 IOPS | 0 IOPS |; | 2250 IOPS | 3750 IOPS |; | 1500 IOPS | 7500 IOPS |; | 750 IOPS | 11250 IOPS |; | 0 IOPS | 15000 IOPS |. So it all depends on perspective of what folks prefer, which in this case means that we can minimize the 6 min component. Then comes the 1.5 min portion of HDFS, which can occur in parallel and could also be memory-mapped and/or SSD accessed. So there are still ways to improve the access and processing time, but it depends on how fast - or instantaneous - folks want to have the results processed and returned back.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-235130868:1021,access,accessed,1021,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-235130868,2,['access'],"['access', 'accessed']"
Security,"Not in general, because prefetching isn't always desirable. By its nature it's designed for long sequential reads rather than random accesses. In GATK though there is prefetcher code in a FeatureDataSource constructor, so anyone who uses that one will get the prefetching.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482660586:133,access,accesses,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482660586,1,['access'],['accesses']
Security,"Not yet. I am curious about the mathematical details of it. How does it distinguish no dominant clone from contamination or too many infiltrating immune cells? In the meantime, I wrote a small R script. Example output below. This is a sun-exposed skin cancer, hence the enormous mutation burden in whole genome sequencing data. ![image](https://user-images.githubusercontent.com/631218/87098600-08acb380-c28b-11ea-8876-9d9817ab13d7.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6674#issuecomment-656391166:239,expose,exposed,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6674#issuecomment-656391166,1,['expose'],['exposed']
Security,"Note #4439, which concerns a Picard tool that might also need options for interval merging exposed. Just something to be aware of---I'm guessing that it's probably a bit ambitious to have identical options for all interval inputs to both Picard and GATK tools?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-367810395:91,expose,exposed,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-367810395,1,['expose'],['exposed']
Security,"Note that although all walkers now have comprehensive sequence dictionary validation performed on their inputs (via the GATKTool base class, which is aware of all primary tool inputs and so is able to perform this check automatically), at present we need to do this validation manually in dataflow tools (as I did with BQSR dataflow here) -- but it would be nice if we could get it to happen automatically in a base class as it does on the walker side of things. Created as ticket https://github.com/broadinstitute/hellbender/issues/669",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/668#issuecomment-122948454:74,validat,validation,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/668#issuecomment-122948454,2,['validat'],['validation']
Security,"Note: the test failures seem to have a lot of docker ""toomanyrequests: You have reached your pull rate limit. You may increase the limit by authenticating and upgrading"" and are probably not due to these changes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7219#issuecomment-824459892:140,authenticat,authenticating,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7219#issuecomment-824459892,1,['authenticat'],['authenticating']
Security,"Notes from @kvg :. Manuscript on LdBG details: https://academic.oup.com/bioinformatics/article/34/15/2556/4938484. Reference implementation of the assembler in C: https://github.com/mcveanlab/mccortex; mcveanlab/mccortex. My Java library for accessing and manipulating LdBGs and associated formats: https://github.com/mcveanlab/CortexJDK. A useful starting point is the tests I've written to produce Figure 1 (the one with the pentagram cycle) from the manuscript. Without links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L210. With links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L229. (Oh and FYI, there's one place where my implementation of the read threading currently doesn't match the McCortex C reference implementation - the handling of sequencing errors and replacing the errorful kmers with kmers from the graph. It's an easy thing to add; I just hadn't gotten around to it because I didn't have the need to do that alignment myself given that all my graphs and links were constructed with McCortex anyway.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843:242,access,accessing,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843,1,['access'],['accessing']
Security,Now can specify a master sequence dictionary that preempts all other; dictionaries that are found (in GATKTool.getBestAvailableSequenceDictionary). Added in associated validity checks with new dictionary in; GATKTool.validateSequenceDictionaries. Fixes #2410,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3058:217,validat,validateSequenceDictionaries,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3058,1,['validat'],['validateSequenceDictionaries']
Security,"Now that sequence dictionary validation is in, we can re-enable this test,; which was previously failing with a java.lang.OutOfMemoryError due to lack; of upfront validation of the reads vs. reference sequence dictionaries.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/668:29,validat,validation,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/668,2,['validat'],['validation']
Security,"Now that there's more rigorous sequence dictionary validation a bunch of dictionaries don't jive with the reference, especially files of the form src/test/resources/org/broadinstitute/hellbender/tools/copynumber/gcnv-postprocess/shard_0-calls/interval_list.tsv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6957:51,validat,validation,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6957,1,['validat'],['validation']
Security,Now the validation test data sets are in the normal git file repository.; This allows them to be visually inspected for differences when they have; changed (during a code review). Fixes #5379,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5381:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5381,1,['validat'],['validation']
Security,"O ""$i"".snp.vcf.gz; gatk VariantFiltration -R $reference -V $path_BQSR/bqsr1.snp.vcf.gz -filter ""QD < 2.0"" --filter-name ""QD2"" -filter ""FS > 60.0"" --filter-name ""FS60"" -filter ""MQ < 40.0"" --filter-name ""MQ40"" -filter ""MQRankSum < -12.5"" --filter-name ""MQRankSum-12.5"" -filter ""ReadPosRankSum < -8.0"" --filter-name ""ReadPosRankSum-8.0"" -O $""i"".filtered.snp.vcf.gz; gatk SelectVariants -R $reference -V $""i"".filtered.snp.vcf.gz --exclude-filtered -O ""$i"".select.filtered.snp.vcf.gz; #INDEL; gatk SelectVariants -R $reference -V ""$i"".vcf.gz -select-type INDEL -O ""$i"".indel.vcf.gz; gatk VariantFiltration -R $reference -V ""$i"".indel.vcf.gz -filter ""QD < 2.0"" --filter-name ""QD2"" -filter ""FS > 200.0"" --filter-name ""FS200"" -filter ""ReadPosRankSum < -20.0"" --filter-name ""ReadPosRankSum-20"" -O ""$i"".filtered.indel.vcf.gz; gatk SelectVariants -R $reference -V ""$i"".filtered.indel.vcf.gz --exclude-filtered -O ""$i"".selected.filtered.indel.vcf.gz. gatk BaseRecalibrator -R $reference -I $i_bam -O grp1 --use-original-qualities --known-sites ""$i"".select.filtered.snp.vcf.gz --known-sites ""$i"".selected.filtered.indel.vcf.gz; gatk ApplyBQSR -R $reference -I $i_bam -O ""$i"".sorted.dedup.BQSR1.bam -bqsr grp1 --static-quantized-quals 10 --static-quantized-quals 20 --static-quantized-quals 30 --add-output-sam-program-record --create-output-bam-md5 --use-original-qualities; gatk ValidateSamFile -I ""$i"".sorted.dedup.BQSR.bam -O ""$i""_validateSamFile_of_bqsr_bam_file.out; samtools index ""$i"".sorted.dedup.BQSR.bam; done; gatk --java-options ""-Xmx30G"" HaplotypeCaller -R $reference -I sample1.sorted.dedup.BQSR.bam sample2.sorted.dedup.BQSR.bam sample3.sorted.dedup.BQSR.bam -O sample1_sample2_sample4.g.vcf.gz --tmp-dir tmp -ERC GVCF; ```. Secondly, how do I set the ploidy parameter for different samples in the population-based snp-calling?; Finally, for each taxa, there are some samples with relatively high sequence depth (> 10x). Is there any better choices for the snp-calling pipeline ??. Sincerely.; Jing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8414:2613,Validat,ValidateSamFile,2613,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8414,1,['Validat'],['ValidateSamFile']
Security,"O field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very appropriate to validate in htsjdk. On Thu, Jul 16, 2015 at 4:05 PM, ldgauthier notifications@github.com; wrote:. > Currently ValidateVariants relies on genotypes to transitively check that; > each alt allele occurs in at least one sample and that the AC adds up.; > However, this can fail on sites-only files because there are no genotypes.; > We should use the definition of the info annotations in the header to check; > how many entries each should have.; > Outline; > - Add a new validation type for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() function, for each info header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some; > additional parsing because it returns an Object; > - (Bonus points if you use the isFixedCount() and getCount() functions; > on the VCF info header line to simplify annotations that aren't according; > to the number of alt alleles); > ; > Test data; > ; > /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > Should fail AC/AF validation at; > 1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120; > See results using:; > ; > use VCFtools; > vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:2484,validat,validation,2484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,"O yarn.Client: Preparing resources for our AM container; 20/10/22 12:02:26 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 20/10/22 12:02:29 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_libs__7655440475844189559.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start ti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6906:3249,Secur,SecurityManager,3249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906,1,['Secur'],['SecurityManager']
Security,"ODE VERBOSE --MAX_OUTPUT 100 --IGNORE_WARNINGS false --VALIDATE_INDEX true --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 1 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --verbosity INFO --QUIET false; [March 9, 2017 7:03:42 PM EST] Executing as gspowley@dna on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Version: Version:4.alpha.2-170-g8d06823-SNAPSHOT; 19:03:42.998 INFO ValidateSamFile - Defaults.BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.COMPRESSION_LEVEL : 1; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_INDEX : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_MD5 : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CUSTOM_READER_FACTORY : ; 19:03:42.999 INFO ValidateSamFile - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 19:03:42.999 INFO ValidateSamFile - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.REFERENCE_FASTA : null; 19:03:43.000 INFO ValidateSamFile - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.000 INFO ValidateSamFile - Initializing engine; 19:03:43.000 INFO ValidateSamFile - Done initializing engine; ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 24466, Read name 20FUKAA",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:1338,Validat,ValidateSamFile,1338,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,1,['Validat'],['ValidateSamFile']
Security,"OK - PedigreeValidationType is now set in the constructor and is final. This does not separate the two intertwined codepaths around PedigreeFile vs. FounderIds, but that was a pre-existing problem. It doesnt doesnt change the pre-existing weirdness around the timing of setting pedigreeFile and/or founderIds within GATKAnnotationPluginDescriptor, where PedigreeAnnotation gets special treatment. I dont think this makes that situation any worse. if you still have concerns on this proposal, I actually think I could make our code work if you simply exposed a protected getPedigreeFile() method on PedigreeAnnotation. I can make the SampleDB instance in my code without needed to share code here. It seemed useful to expose some of that code to avoid duplication, but if it's going to over-complicate we can remove it. Also: that one test failure seems potentially unrelated (https://travis-ci.com/github/broadinstitute/gatk/jobs/510624560)? A compile issue with javadoc?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-853986169:550,expose,exposed,550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-853986169,2,['expose'],"['expose', 'exposed']"
Security,"OK, thanks @droazen. I'll go ahead and expose all of them in a branch for now. For my own education, perhaps @jamesemery or @vruano can comment---does turning on DRAGEN sidestep all or some subset of the code paths where the above 3 sets of parameters come into play?. For what it's worth, now that I'm looking at short variants in malaria as a ""novice"" HC/M2 user, the command line options are quite daunting! Many of them are not well documented and it's not always clear which options might interact with each other. Perhaps once the evaluations are in place, it might be worth doing some model ablation to see if we can come up with a more minimal set of options (including the consolidation of the parameters under discussion, if possible).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705096593:39,expose,expose,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705096593,1,['expose'],['expose']
Security,"OK, that's reasonable. I'll dig into the other test changes. I can answer a few:. - Regarding passing the VariantWalker: I agree that's not an improvement by itself, but I would argue it's not that much different than it was. My plan is to pass a VariantEvalContext object, which would obscure any need to have knowledge of the walker. In an attempt to keep this PR simpler, I didnt complete that work. I do expect to make a second PR in relatively short order, once we get this resolved. - With respect to testEvalTrackWithoutGenotypesWithSampleFields and the different reference: I think the issue is that the old version (master GATK branch) didnt validate as strictly. When switching to MultiVariantWalkerGroupedOnStart, the reference is required, and the tool will error if the contigs dont match. VariantEval on the master branch didnt really need the reference for anything, and was apparently more permissive if it didnt line up. It probably preferentially grabbed the dictionary from the VCF header. I will look into those other questions",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744698072:651,validat,validate,651,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744698072,1,['validat'],['validate']
Security,"OK. Passes checks. @droazen One final look? I couldn't figure out how to use runCommandLine, because I needed access to my walker instance. Is this OK, or is there a better way to do it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7695#issuecomment-1089021503:110,access,access,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7695#issuecomment-1089021503,1,['access'],['access']
Security,"OK. StratManager is about 80% wired to do the merging this would require. It would require me to implement some existing methods, like VariantEvaluator.combine(), but the basic idea exists today in StratificationManager.combineStrats(). I'd probably propose to expose this via VariantEvalEngine by adding saveToDisk(File targetFile), and restore(List<File> serializedStratManagers) methods. I'd propose to keep interaction with this process protected and only expose the save/restore methods. Alternately, I could expose save, restore (single-object) and combine methods. Regarding actually saving the state of StratificationManager to disk: some form of Jackson-based serialization would probably be easiest. My initial thought would be to make a new class specifically for serializing: SerializedStratificationManager. This would cache the relevant information and be the object that is serialized/deserialized. I would add a new constructor to StratificationManager that accepts this object and restores the state within StratificationManager. I think this could be all be kept internal to GATK. Does that broad outline seem like a concept you might accept in GATK?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-755351932:261,expose,expose,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-755351932,3,['expose'],['expose']
Security,"Oh I'm so sorry about that. I ran ValidateVariants on a few samples (running the whole batch now). This is the error I get when I don't specify the --validate-GVCF or --validation-type-to-exclude ALLELES . > A USER ERROR has occurred: Input renamed_seq1trimq10_LHA_AS02_1.raw_variants.g.vcf fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position DS235882:56737 are not observed at all in the sample genotypes. The position in the gvcf. > DS235882 56737 . A T,<NON_REF> 0 . BaseQRankSum=-3.172;DP=29;ExcessHet=3.0103;MLEAC=0,0;MLEAF=0.00,0.00;MQRankSum=-1.507;RAW_MQandDP=97098,29;Re; adPosRankSum=-0.312 GT:AD:DP:GQ:PL:SB 0/0:27,2,0:29:67:0,67,1051,81,1056,1070:13,14,1,1. When I exclude the Alleles, I get no errors for the samples I checked thus far. This error cannot be causing the initial problem because I got the same error (in different position) on some gvcfs that are currently working fine with CombineGVCFs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6913#issuecomment-716710858:34,Validat,ValidateVariants,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913#issuecomment-716710858,4,"['Validat', 'validat']","['ValidateVariants', 'validate-GVCF', 'validation', 'validation-type-to-exclude']"
Security,"Oh, I hadn't noticed that there was a compilation warning causing the test to fail. ```; /gatk/src/test/java/org/broadinstitute/hellbender/MainTest.java:55: warning: [serial] serializable class ExitNotAllowedExcepion has no definition of serialVersionUID; private static final class ExitNotAllowedExcepion extends SecurityException {; ^; error: warnings found and -Werror specified; ```. Please fix that also :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772:314,Secur,SecurityException,314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772,1,['Secur'],['SecurityException']
Security,"Oh, good point. Maybe we should add a GATKRProtectedRegistrator that first applies the GATKRegistrator and then does additional gatk-protected specific registrations? We'll have to add a way to inject the right one though as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272483079:194,inject,inject,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2337#issuecomment-272483079,1,['inject'],['inject']
Security,"Oh, that's right, I'd forgotten about the SGA license issue. Since we're; about to move to fermi-lite (hopefully), let's just hold off on checking in; the initialization script until that's done, keeping it in the known bucket; location. On Wed, Mar 8, 2017 at 11:37 AM, Steve Huang <notifications@github.com>; wrote:. > @cwhelan <https://github.com/cwhelan> I was actually debating with myself; > about whether to include the initialization script here, as it was living; > in the bucket referred to in the creation script.; > So we could do this:; > always store the initialization script locally with the creation script; > instead of referring to a script living remotely, and makes that a required; > argument. The good: this makes it easier to track changes; The bad:; > initialization script must be removed from the bucket to avoid tracking; > possible different versions.; >; > A non-technical issue: we are ""delivering"" SGA in the initialization; > script, if that comes in to this repo, legal might have a problem with it.; > On the other hand, it the initialization script lives in a place only we; > can access, we are ""installing SGA for our own use"", which is not a problem; > with the GPL license.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/2435#issuecomment-285093289>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZZPv4WyEYz-yYaZZIIjH8LBMOhZ4ks5rjtlCgaJpZM4MTqFc>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2435#issuecomment-285105258:1117,access,access,1117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2435#issuecomment-285105258,1,['access'],['access']
Security,"Ok -- caveat for all -- objects in bucket that are accessed via simple API Key need to have: User:allUsers:reader ACL permissions. if you need more complex access control, we'll have to support the ""secretFile"" attribute in `gcloud dataproc` -- not just the apiKey.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-228425738:51,access,accessed,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-228425738,2,['access'],"['access', 'accessed']"
Security,"Ok @jean-philippe-martin, I have an updated patch that seems to resolve the 503 errors! It's here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. Will you have time before you leave on vacation to open a PR against google-cloud-java? If not, let me know and we'll try to sort out our CLA issues and PR it ourselves. I didn't have time to write unit tests, unfortunately, though we're running it now with 1000 concurrent jobs each accessing 11,000 files and not seeing any errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319:477,access,accessing,477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319,1,['access'],['accessing']
Security,"Ok, thanks for validating that. I'll make a PR for this change (the way those unit tests are written is a little sketchy so I may fix that at the same time). I forgot about the spark failures - can you post the log output for those failures as well ?. Also, to answer your original question, you should generally always be able to work directly from head of master and all tests should pass, though sometimes things like this can slip through. Also, to answer your original question",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064:15,validat,validating,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064,1,['validat'],['validating']
Security,"Okay, I have a new panel for hg38 here: gs://broad-dsde-methods-davidben/mutect2-2023-panel-of-normals/mutect2-hg38-pon.vcf.gz. It has all the variants of the old panel, plus more that arose in more recent versions of Mutect2. It is also generally somewhat more conservative, with a greater bias toward precision than the previous one. This panel is intended to be used at your own risk. I can vouch that it doesn't wreck the results of our own validations but I do not have time to vet it thoroughly enough to put it in the best practices google bucket. Likewise, I cannot promise that it will improve specificity in any particular set of samples. Within several months I hope we are all running the next version of Mutect and never need to see a panel of normals again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1430315034:445,validat,validations,445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1430315034,1,['validat'],['validations']
Security,"Okay, this PR has grown a little bit. Here's what we have now:; - Move CompareSAMs to picard package; - Move most of CompareSAMs logic into a separate util, SamComparison; - Move CompareSAMs unit tests to SamComparisonTest, since they do not fit into the CommandLineProgramTest framework. CompareSAMsTest is now a stub, to be expanded later.; - Added SamAssertionUtils, which contains basic assertions about SAM files (are they valid? are they roughly equal?) that are used by many unit tests, so that we don't have the exact same block of boilerplate validation code in multiple places. ; - Insert `--VERBOSITY ERROR` into CommandLineProgramTest, in a way that can handle immutable input lists",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/171#issuecomment-73972768:552,validat,validation,552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/171#issuecomment-73972768,1,['validat'],['validation']
Security,"Once again I've managed to convince David R. to let me merge with some tech debt as follows:; - [ ] Add to GnarlyGenotyper an integration test like testRawAndFinalizedAlleleSpecificAnnotationsThoroughly() for GGVCFs; - [ ] Add a direct unit test for makeReducedAnnotationString() if you exposed it as package-accessible; - [ ] ~Break out finalized key definition, promote getKeyNames and getRawKeyNames to default methods in ReducibleAnnotation interface~; - [ ] One last `ann.getRawKeyNames().get(0)` in GnarlyGenotyperEngine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6203:287,expose,exposed,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6203,2,"['access', 'expose']","['accessible', 'exposed']"
Security,"Once https://github.com/broadinstitute/gatk/pull/3620/ is in, we should be able to remove the download of picard.jar from .travis.yml, and change the M2 WDL to no longer depend having access to it. Workflow calls to picard tools can be replaced with calls to the same tools in GATK, although the argument syntax will have to change from picard style to Barclay style (""I=..."" to ""-I ..."").",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3625:184,access,access,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3625,1,['access'],['access']
Security,"Once https://github.com/samtools/htsjdk/pull/327 is merged into htsjdk and propagates to hellbender, let's audit our Spark tools to ensure that we are always serializing headerless SAMRecords",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1072:107,audit,audit,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1072,1,['audit'],['audit']
Security,"One consideration is that (unlike the GATK) we are supporting reference-less traversals, which makes the requirement to always provide a sequence dictionary for every interval a bit onerous... But if the consensus is that we should still always require validation against a sequence dictionary, but encapsulated within GenomeLoc (eliminating the need for GenomeLocParser), I would support that. I agree that the performance concerns are not worth addressing unless a profiler shows that they are an actual problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69813473:253,validat,validation,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69813473,1,['validat'],['validation']
Security,"One more thing: I'm also wondering if it would be possible to get a quick, preliminary evaluation of such a process without actually doing the work of adding it into the training tool. It's probably possible to do a slightly more ""manual"" validation split (say, using one or a few chromosomes), run the score tool on that validation set, use some external code to calculate the desired threshold from the resulting scores, and then use that threshold going forward. Actually, now that I've written it out, that sounds a lot cleaner and more flexible! Let me try to hack together the corresponding workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065543611:239,validat,validation,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065543611,2,['validat'],['validation']
Security,One of the issues:. [Utils] [ERROR] [Error] java.lang.IllegalArgumentException: Invalid interval. Contig:1 start:350001 end:300000; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.&lt;init&gt;(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.tools.copynumber.utils.annotatedinterval.AnnotatedIntervalUtilsUnitTest.provideMergeByAnnotation(AnnotatedIntervalUtilsUnitTest.java:215); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:55); 	at org.testng.internal.MethodInvocationHelper.invokeMethodNoCheckedException(MethodInvocationHelper.java:45); 	at org.testng.internal.MethodInvocationHelper.invokeDataProvider(MethodInvocationHelper.java:115); 	at org.testng.internal.Parameters.handleParameters(Parameters.java:509); 	at org.testng.internal.Invoker.handleParameters(Invoker.java:1308); 	at org.testng.internal.Invoker.createParameters(Invoker.java:1036); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1126); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5339#issuecomment-431874410:178,validat,validateArg,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5339#issuecomment-431874410,2,['validat'],"['validateArg', 'validatePositions']"
Security,"One part of this ticket is done: https://github.com/broadinstitute/gatk/pull/4964 added accessors that allow direct descendants of `GATKTool` to directly access engine datasources, while still forbidding direct access for tools that extend a Walker base class (except for Walker types living in the engine package, which still have access).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878:88,access,accessors,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878,4,['access'],"['access', 'accessors']"
Security,Or rather the sequence-dictionary would have a method to instantiate validated GenomeLocs?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69799988:69,validat,validated,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69799988,1,['validat'],['validated']
Security,"Or rather, what needs to happen is the arguments need to be parsed and injected in the constructor for the class at the top of the hierarchy, so that all subclass constructors can use the argument values during initialization.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/107#issuecomment-69779074:71,inject,injected,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/107#issuecomment-69779074,1,['inject'],['injected']
Security,"Otherwise, when json is refreshed, contents of the file are different, hash of the file is different, and call-caching will not register a match, despite the same ""account"" being used. - changed input type from `File` to `String`; - changed the name to make it more obvious/clear. Closes https://github.com/broadinstitute/dsp-spec-ops/issues/327",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7347:71,hash,hash,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7347,1,['hash'],['hash']
Security,"Our R dependency is primarily for producing plots. It could be possible to create plots using javascript instead. Javascript plots have several potential advantages but also several major downsides. The biggest and most obvious drawback is that we don't have any code to produce them yet, and they are likely harder to generate and experiment with than R scripts. . The advantage would be that we could avoid requiring an R installation to run hellbender scripts, we could potentially also include interactive plotting or other neat tricks to make the plots more useful. I see 2 possible routes to replacing Rscripts with javascript. The first would be for tools that require graphs to perform some html generation and produce html reports with embedded javascript. The user could then open these in their browser and view the plots ( much like how our test suite report and jacoco is done). . A different option would be to use javascript plotting libraries directly within the jvm to generate SVG. Java 8 has a new javascript engine which is supposed to be reasonably fast and offers access to java objects from within it. Unfortunately it doesn't offer a full DOM like a browser does, so most existing javascript libraries will fall over. It seems like it would take a lot of hacking to get something like d3 to run directly on the jvm. (someone has done something of the kind here: http://jazdw.net/content/server-side-svg-generation-using-d3js) . Other options would be to use the javafx web panes to display a browser directly, or to plot directly on a canvas. Either of these options seem like they would be painful and awful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/248:1086,access,access,1086,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/248,1,['access'],['access']
Security,"Out of 11 runs on exactly the same data, FilterByOrientationBias fails 6 times and succeeds 5 times. Assigning @LeeTL1220, given prior interaction with user. - User reports this error in: https://gatkforums.broadinstitute.org/gatk/discussion/comment/40412#Comment_40412; - My recapitulation is in: https://github.com/broadinstitute/dsde-docs/issues/2294. Data is at `/humgen/gsa-scr1/pub/incoming/byoo_FilterByOrientationBias.zip`. Command is:; ```; gatk-launch FilterByOrientationBias \; -A 'G/T' -A 'C/T' \; -V test2.vcf \; -P test2.pre_adapter_detail_metrics \; --output ob_filtered2.vcf; ```. Error message changes between:; ```; java.lang.IllegalStateException: Allele in genotype C* not in the variant context [G*, T]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.tools.exome.orientationbiasvariantfilter.OrientationBiasFilterer.annotateVariantContextsWithFilterResults(OrientationBiasFilterer.java:216); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:168); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:781); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3291:774,validat,validateGenotypes,774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3291,2,['validat'],"['validate', 'validateGenotypes']"
Security,"Overriding the defaults would get us most of the way there. Right now, we perform the following check on the IAC and fail if the defaults aren't changed to values that the CNV tools require, which is awkward:. ```; /**; * Validate that the interval-argument collection parameters minimally modify the input intervals.; */; public static void validateIntervalArgumentCollection(final IntervalArgumentCollection intervalArgumentCollection) {; Utils.validateArg(intervalArgumentCollection.getIntervalSetRule() == IntervalSetRule.UNION,; ""Interval set rule must be set to UNION."");; Utils.validateArg(intervalArgumentCollection.getIntervalExclusionPadding() == 0,; ""Interval exclusion padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalPadding() == 0,; ""Interval padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalMergingRule() == IntervalMergingRule.OVERLAPPING_ONLY,; ""Interval merging rule must be set to OVERLAPPING_ONLY."");; }; ```. If we override defaults, we'd still perform the check to make sure the user didn't muck with them, but it'd still be nicer than forcing the user to change the original defaults on their own. However, there are still two more awkward points: 1) there is no value for `-interval-set-rule` that does *nothing* to the incoming intervals (you must either union or intersect), and 2) we have to specify our own `padding` argument in `PreprocessIntervals` that is distinct from `-interval-padding`, since we want to implement our own padding. The first can be easily addressed by adding an option to do nothing to the intervals; I'm not so sure what the best way to handle the second would be, so we can punt on it if it'd be more work than it's worth---these are relatively minor pain points, in the end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857:222,Validat,Validate,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857,6,"['Validat', 'validat']","['Validate', 'validateArg', 'validateIntervalArgumentCollection']"
Security,"Passing Integration Test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ad05b4d1-7aed-4482-8b5c-ced7b87d2d37).; Verified that GQ0 dropped in 'hail_lite' run and not in 'hail_vcf' run; (queries of count by state from ref ranges table):. **Hail Lite (Hail path, drop state 0):; state count**; 2 2495387; 3 4773472  ; 4 5959290. **Lite VCF (VCF path, drop_state 40):; state count**; 0 2764630; 2 2495387; 3 4773472. Spun up a notebook and ran the vds_validation.py script on the VDS generated by 'hail_lite'. And it passed:. > 2023-10-04 19:08:01.278 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.; > To preserve matrix table column order, first unkey columns with 'key_cols_by()'; > checking that:; > * no reference blocks have GQ=0; > * all ref blocks have END after start; > * all ref blocks are max 1000 bases long; > running densify on 200kb region (0 + 1) / 1]; > took 10.9s to densify 0 rows after interval query; > Hail VDS validation successful======================================(1 + 0) / 1]",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8538:981,validat,validation,981,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8538,1,['validat'],['validation']
Security,Passing VAT from VDS run on Quickstart here: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/533017b9-2dfb-42ec-83ef-42dfda67f5c1; And a 'passing' (two expected failures) ValidateVat run here:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/e0af0c06-c724-4ae2-b821-6a04b558b21e,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8144#issuecomment-1371268610:208,Validat,ValidateVat,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8144#issuecomment-1371268610,1,['Validat'],['ValidateVat']
Security,PathSeqPipelineSpark validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8212:21,validat,validation,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8212,1,['validat'],['validation']
Security,"Per comments on the Slack channel, this can also be used as a component in germline tagging for matched tumor-normal pairs. For the same series above:. Here is the 100% normal run through ModelSegments, which yields 36 segments:; ![N modeled](https://user-images.githubusercontent.com/11076296/76631751-931d1a80-6518-11ea-8c18-2a8f41057ce3.png). Joint segmentation of the 100% normal and the 100% tumor yields 241 segments (up from 130 for the 100% tumor alone, as above). Using this joint segmentation for subsequent ModelSegments runs:. For the 100% normal, this yields 88 segments (up from 36):; ![N-SJS modeled](https://user-images.githubusercontent.com/11076296/76632024-ebecb300-6518-11ea-89ff-109c97970ef0.png). For the 100% tumor, this yields 166 segments (up from 130):; ![T-SJS modeled](https://user-images.githubusercontent.com/11076296/76632125-13dc1680-6519-11ea-9901-0c78809d08ba.png). I haven't performed detailed validations, but some spot checking suggests that this actually mitigate oversegmentation while still increasing sensitivity to shared events. For example, there is a small 13-bin deletion in chr19 that is found when running the 100% normal alone, but gets broken up into two adjacent deletions when running the 100% tumor alone (probably just due to statistical noise in the copy ratios). When running jointly, the deletion does not get broken up. However, as discussed over Slack, we should probably run some scenarios with simulated data to check behavior---for example, how robust is the joint segmentation to some of the samples being noisy/oversegmented?. There are lots of options for restructuring the workflow. We could potentially modify ModelSegments to take in the denoised copy ratios from the normal, when available, and add modeling of the normal and germline tagging to that tool. Or we could break things up into separate tools. @fleharty any opinions?. Note that another benefit of using this joint segmentation for germline tagging is that common breakp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598764477:929,validat,validations,929,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598764477,1,['validat'],['validations']
Security,"Per discussion with @kgururaj, the proposal is to have GenomicsDB expose/document the existing protocol buffers already used internally, along with protobuf-based constructors for both GenomicsDBImporter and GenomicsDBFeatureReader.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3689#issuecomment-336962583:66,expose,expose,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3689#issuecomment-336962583,1,['expose'],['expose']
Security,"Per discussions with @fleharty, we are looking to significantly revamp the automated somatic CNV evaluations in preparation for benchmarking the TH prototype. The existing evaluations use a few unsupported/experimental tools and idiosyncratic/redundant classes (e.g., the `src/main/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedinterval` class this issue concerns), the functionality of which we can hopefully move to python-based validation code. . The aforementioned code was purposefully decoupled from supported CNV code, but since then it has been incorporated into `Funcotator` tools and `ValidateBasicSomaticShortMutations`, at least. @jonn-smith @davidbenjamin can we discuss a plan for cleaning this code up? Would it be easy to use an existing TSV/XSV class to handle the functionality needed for these tools?. @jonn-smith perhaps we should also discuss the plan for future `FuncotateSegments` development/integration with @fleharty.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526226506:452,validat,validation,452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526226506,2,"['Validat', 'validat']","['ValidateBasicSomaticShortMutations', 'validation']"
Security,Performance issues when accessing Reads in Interval/Feature based walkers.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1246:24,access,accessing,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1246,1,['access'],['accessing']
Security,Picard docs must reflect Picards command line syntax or their syntax as how it gets exposed thru GATK? I.e. ```INPUT=XXX``` or ```-I|--INPUT XXX```?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349489906:84,expose,exposed,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349489906,1,['expose'],['exposed']
Security,Picard tools don't perform validation of the sequence dictionary which will occasionally lead to errors. They should implement the same checking as the rest of our tools,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1272:27,validat,validation,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1272,1,['validat'],['validation']
Security,PileupElement : save memory and time by accessing bases and quals directly without copying.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1794:40,access,accessing,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1794,1,['access'],['accessing']
Security,PileupElement: save memory and time by accessing bases and quals directly without copying. Showed up on profile in HC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1794:39,access,accessing,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1794,1,['access'],['accessing']
Security,Placeholders for now. We can tweak the actual values once @LeeTL1220 checks effect on validation. Closes #4032.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4046:86,validat,validation,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046,1,['validat'],['validation']
Security,Please make this option hidden if it's only being kept for testing purposes (and document clearly that that is the case). Users should not have access to options that are not expected to have value.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2231#issuecomment-316842338:144,access,access,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2231#issuecomment-316842338,1,['access'],['access']
Security,"Please update the GitHub description to use https://www.broadinstitute.org/gatk/ which saves one redirect, and is more secure with rogue DNS servers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3211:119,secur,secure,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3211,1,['secur'],['secure']
Security,Polishing hapmap M2 validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3171:20,validat,validation,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3171,1,['validat'],['validation']
Security,PoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:6133); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:505); 	... 12 more; ```. This service account does have access to these files because every shard accesses the same files and most of them succeed and when the same task is rerun it does succeed. @snovod should have any other information you may need.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735:6610,access,access,6610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735,2,['access'],"['access', 'accesses']"
Security,"PoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). I don't understand why if the command is the same:; ```; $GATK_PATH BwaAndMarkDuplicatesPipelineSpark --bam-partition-size 64000000 or 4000000 \; --input hdfs://namenode:8020/$dir_prepro$ubam \; --reference hdfs://namenode:8020/hg19-ucsc/ucsc.hg19.2bit \; --bwa-mem-index-image /reference_image/ucsc.hg19.fasta.img \; --disable-sequence-dictionary-validation true \; --output hdfs://namenode:8020/$dir_prepro$output -- \; --spark-runner SPARK --spark-master spark://$SPARK_MASTER_HOST:7077 \; --driver-memory 20g --executor-cores 4 --executor-memory 8g; ```. Furthermore I have this problem with this version v4.0.4.0-23-g6e1cc8c-SNAPSHOT. > mark duplicate records objects corresponding to read with name, this could be the result of readnames spanning more than one partition; 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$null$0(MarkDuplicatesSpark.java:109); 	at java.util.HashMap.merge(HashMap.java:1253); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark.lambda$mark$62928560$1(MarkDuplicatesSpark.java:109); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1.apply(JavaRDDLike.scala:319); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4820:7087,Hash,HashMap,7087,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4820,1,['Hash'],['HashMap']
Security,Populating the DB SNP validation status field properly,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5046:22,validat,validation,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5046,1,['validat'],['validation']
Security,Porting over gvcf validation option to ValidateVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3331:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3331,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6994:300,expose,exposed,300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994,3,['expose'],['exposed']
Security,Prefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetH,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180:6717,secur,security,6717,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180,1,['secur'],['security']
Security,"Previously, a temporary table is created as part of extract of the VQSR features, and it goes into a separate `temp_tables` dataset in the current project -- that is no longer true, and it now goes into the default dataset as a short living temp table with the task name and a hash. This pr should:. - default to the current dataset (with the VET etc tables) rather than a different dataset. - give a prefix to the temp tables so we know which one came from which step. - temp table TTL---not a changeable option, but default to 24 hours across the board. Still to discuss:; Parameterization of the location (dataset) to create the temp table in (default to the default dataset); manual clean up/TTL is a changeable option and TTL is parametrizable (currently the TTL is a parameter for the prepare step -- but then we set a default as 24 hrs in the WDL) . ![Screen Shot 2022-06-10 at 1 27 58 PM](https://user-images.githubusercontent.com/6863459/173121781-4486c1d1-ef7a-4ab8-aa62-fdc5018fd3b9.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7742:277,hash,hash,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7742,1,['hash'],['hash']
Security,Provide a mechanism for dataflow authentication information to be set once and stay set,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/701:33,authenticat,authentication,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/701,1,['authenticat'],['authentication']
Security,Provide a tool for outputting possible pathogen injection site on (human) host,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3458:48,inject,injection,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3458,1,['inject'],['injection']
Security,Providing counts for supporting alt reads in the validation normal.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5062:49,validat,validation,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5062,1,['validat'],['validation']
Security,Python tools need doc and validation that the conda environment is activated,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4127:26,validat,validation,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4127,1,['validat'],['validation']
Security,Qs of reads sharing kmers with putative SV breakpoints for local assembly; FlagStatSpark FlagStat on Spark; MarkDuplicatesSpark MarkDuplicates on Spark; MeanQualityByCycleSpark MeanQualityByCycle on Spark; PrintReadsSpark PrintReads on Spark; QualityScoreDistributionSpark QualityScoreDistribution on Spark; SortReadFileSpark SortSam on Spark (works on SAM/BAM/CRAM). --------------------------------------------------------------------------------------; Spark tools for structural variation analysis: Structural variation analysis tools that use Apache Spark for scaling out (experimental); CollectInsertSizeMetricsSpark Collect Insert Size Distribution on Spark. --------------------------------------------------------------------------------------; VCF: Tools for manipulating variants and associated metadata; CountVariants Count variants in a VCF file; ExampleVariantWalker Example tool that prints variants with optional contextual data; FilterVcf Hard-filters a VCF file; GatherVcfs Gathers multiple VCF files from a scatter operation into a single VCF file; GenotypeConcordance Calculates the concordance between genotype data for two samples in two different VCFs; IndexFeatureFile Creates indices for Feature-containing files (eg VCF and BED files); LiftOverVcf Lifts a VCF between genome builds; MakeSitesOnlyVcf Creates a VCF bereft of genotype information from an input VCF; MergeVcfs Merges multiple VCF files into one VCF file; RenameSampleInVcf Rename a sample within a VCF; SelectVariants Select a subset of variants from a larger callset in a VCF file; SortVcf Sorts one or more VCF files; SplitVcfs Splits an input VCF file into two VCF files; ValidateVariants Validate VCF; VariantFiltration Hard-filter variants VCF (mark them as FILTER); VariantsToTable Extract specific fields from a VCF file to a tab-delimited table; VcfToIntervalList Converts a VCF file to a Picard Interval List. --------------------------------------------------------------------------------------; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1669:9457,Validat,ValidateVariants,9457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1669,2,['Validat'],"['Validate', 'ValidateVariants']"
Security,"Questions from developers, mainly, about things like ""my IntelliJ project is broken"" and ""GCS authentication not working"" -- you get the picture :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3199#issuecomment-312054764:94,authenticat,authentication,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3199#issuecomment-312054764,1,['authenticat'],['authentication']
Security,R code does not have access to changes in column names/file formats,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2862:21,access,access,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2862,1,['access'],['access']
Security,"READ_PAIR_DUPLICATES READ_PAIR_OPTICAL_DUPLICATES PERCENT_DUPLICATION ESTIMATED_LIBRARY_SIZE; Unknown 0 9951 0 0 0 0 0 0. ## HISTOGRAM java.lang.Integer; duplication_group_count Unknown; 1 9951; ```. MarkDuplicatesSpark; ```; ## htsjdk.samtools.metrics.StringHeader; # MarkDuplicatesSpark --output temp/align/markduplicates/c_lib1.bam --metrics-file stats/align/markduplicates/c_lib1.metrics.txt --input temp/align/bwa_aln/c_lib1_L001.sorted.bam --read-validation-stringency LENIENT --spark-master local[8] --allow-multiple-sort-orders-in-input false --treat-unsorted-as-querygroup-ordered false --duplicate-scoring-strategy SUM_OF_BASE_QUALITIES --do-not-mark-unmapped-mates false --duplicate-tagging-policy DontTag --remove-all-duplicates false --remove-sequencing-duplicates false --read-name-regex <optimized capture of last three ':' separated fields as numeric values> --optical-duplicate-pixel-distance 100 --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --bam-partition-size 0 --use-nio false --disable-sequence-dictionary-validation false --add-output-vcf-command-line true --sharded-output false --num-reducers 0 --create-output-bam-index true --create-output-bam-splitting-index true --splitting-index-granularity 4096 --create-output-variant-index true --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays --disable-tool-default-read-filters false; ## htsjdk.samtools.metrics.StringHeader; # Started on: March 24, 2021 9:31:36 PM CET. ## METRICS CLASS org.broadinstitute.hellbender.utils.read.markduplicates.GATKDuplicationMetrics; LIBRARY UNPAIRED_READS_EXAMINED READ_PAIRS_EXAMINED SECONDARY_OR_SUPPLEMENTARY_RDS UNMAPPED_READS UNPAIRED_READ_DUPLICATES READ_PAIR_DUPLICATES READ_PAIR_OPTICAL_DUPLICATES PERCENT_DUPLICATION ESTIMATED_LIBRARY_SIZE; Unknown Library 0 9998 0 0 0 0 0 0; ```. MarkDuplica",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7161:2227,validat,validation-stringency,2227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7161,2,['validat'],"['validation', 'validation-stringency']"
Security,"RN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 20/10/22 12:02:29 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_libs__7655440475844189559.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:80",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6906:3325,Secur,SecurityManager,3325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906,1,['Secur'],['SecurityManager']
Security,ROC Curve Walker for validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2723:21,validat,validation,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2723,1,['validat'],['validation']
Security,"R_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.java:197); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:236); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at org.broadinstitute.h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:3238,Validat,ValidateVariants,3238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"Rather than delaying argument validation to a second pass, I changed the sequence so the tool instantiates the descriptor and gives it the tool defaults right from the start, (and then passes the descriptor instance(s) to the arg parser) so it has all the state it needs to validate at arg parsing time. Also, I reverted the removal of the package limitation for plugins, at least temporarily, since searching through all packages looked like it slowed down the integration tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1973#issuecomment-232046070:30,validat,validation,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1973#issuecomment-232046070,2,['validat'],"['validate', 'validation']"
Security,Rc vat validation typo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7366:7,validat,validation,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7366,1,['validat'],['validation']
Security,Re-enable BaseRecalibratorDataflowIntegrationTest.testBQSRFailWithIncompatibleReference once sequence dictionary validation is in,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/625:113,validat,validation,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/625,1,['validat'],['validation']
Security,"Read counts at different stages of the PathSeq pipeline are now logged using `MetricsFile`. The filter metrics contains the number of reads remaining and number of reads filtered at each step (after filtering pre-aligned reads, low quality/complexity reads, host reads, and duplicates). The score metrics give number of pathogen-mapped and unmapped reads. These metrics are now validated in the PathSeq integration tests, which have also been refactored to use DataProviders instead of separate functions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3611:378,validat,validated,378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611,1,['validat'],['validated']
Security,ReadSparkSink adds a crc checksum file even for local files,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1266:25,checksum,checksum,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1266,1,['checksum'],['checksum']
Security,ReadsDataSource: enable setting validation stringency,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/181:32,validat,validation,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/181,1,['validat'],['validation']
Security,ReadsDataSource: enable setting validation stringency.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/585:32,validat,validation,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/585,1,['validat'],['validation']
Security,ReadsDataSource: expose setting validation stringency at command line,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/611:17,expose,expose,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/611,2,"['expose', 'validat']","['expose', 'validation']"
Security,Recent refactoring seems to have introduced a bug in pileup mode that failed to enforce the limit on the number of haplotypes to be considered. With this patch:. - HaplotypeCaller once again respects the limit on haplotypes before genotyping.; - Changed some `HashSet`s to `LinkedHashSets` to preserve determinism.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8489:260,Hash,HashSet,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8489,1,['Hash'],['HashSet']
Security,Refactor MT wdl to make validations easier,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5708:24,validat,validations,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5708,1,['validat'],['validations']
Security,"Reference, Feature and whatever context fully by injection.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242:49,inject,injection,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242,1,['inject'],['injection']
Security,"Regarding writing the SAM file, I now remember why it was created instead of using existing ones: the SV pipeline needs to be able to write to HDFS, hence cannot rely on a `File` interface&mdash;which the `ReadUtils.createCommonSAMWriter(...)` exposes. ; So the current hand rolled version in `SVFileUtils.getSAMFileWriter()` calls into `BucketUtils.createFile(...)` for that HDFS compatibility, and then makes use of the `SAMFileWriterFactory.makeBAMWriter(final SAMFileHeader header, final boolean presorted, final OutputStream stream)`, unlike `ReadUtils.createCommonSAMWriter(...)` which calls into `SAMFileWriterFactory.makeSAMOrBAMWriter(final SAMFileHeader header, final boolean presorted, final Path outputPath)`. So in short: HDFS compatibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3674#issuecomment-339391912:244,expose,exposes,244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3674#issuecomment-339391912,1,['expose'],['exposes']
Security,Remove the <20 obfuscation for AC; This needs to be removed from the Python (which did the original obfuscation); And the VAT Validation WDL -- which checked on it,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7435:126,Validat,Validation,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7435,1,['Validat'],['Validation']
Security,Removes unnecessary and buggy validation check,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8580:30,validat,validation,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8580,1,['validat'],['validation']
Security,Rename ValidateBasicSomaticShortMutations to something more in-line with MutationValidator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5871:7,Validat,ValidateBasicSomaticShortMutations,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5871,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,Renamed existing test for validating generated WDLs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7829:26,validat,validating,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7829,1,['validat'],['validating']
Security,Reported by Intel. Should be a `UserException` instead. ```; ./gatk-launch BwaSpark -I hdfs://sn1:8020/user/$USER/gatk/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -R hdfs://sn1:8020/user/$USER/gatk/human_g1k_v37.fasta -O hdfs://sn1:8020/user/$USER/gatk/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -- --sparkRunner SPARK --sparkMaster spark://sn1:7077 --driver-memory 8G --num-executors 4 --executor-cores 9 --executor-memory 27g; ```. ```; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:464); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:458); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.validateToolInputs(GATKSparkTool.java:402); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:312); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:185); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAcce,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2020:893,validat,validateDictionaries,893,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2020,1,['validat'],['validateDictionaries']
Security,"Reposting from the Slack channel:. When I run ValidateVariants on an *invalid* VCF without providing a reference or any ""--validation-type-to-exclude"" arguments, I don't get any validation errors. However, if I add ""--validation-type-to-exclude REF"", then I get validation errors as expected. Even when I get validation errors in the second case, the error message seems to terminate abruptly: `A USER ERROR has occurred: Input output.vcf fails strict validation: the Allele Count (AC) tag is incorrect for the record at position 1:1262288, 2 vs. 1 of type:`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4642:46,Validat,ValidateVariants,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4642,7,"['Validat', 'validat']","['ValidateVariants', 'validation', 'validation-type-to-exclude']"
Security,Request: Easy access to FeatureInput<VariantContext> in GATKTool for walkers that traverse VariantContext,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1710:14,access,access,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1710,1,['access'],['access']
Security,Requester pays access isn't working,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6179:15,access,access,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6179,1,['access'],['access']
Security,"Requires a ""git lfs pull"" to access. File size is ~230 MB.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/927:29,access,access,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/927,1,['access'],['access']
Security,"Returning false instead of throwing when data is missing in the `GoogleGenomicsReadToGATKReadAdapter` is misleading -- we don't know the answer to the question the client is asking in such cases, so returning false is not correct behavior. If these fields are actually missing in the underlying reads we really do want to blow up with an exception on access, as it means the read object is not usable by us (and the query that produced these incomplete objects likely needs to be modified). Could you restore the previous versions of these methods (`isSecondaryAlignment()`, `isDuplicate()`, etc.) before I review?. As for the Google read converters, could you open a separate ticket with your description of the inconsistencies so we can decide whether to submit a patch?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/871#issuecomment-136771148:351,access,access,351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871#issuecomment-136771148,1,['access'],['access']
Security,"Revamping the existing somatic validation pipeline needs to be done before development of the TH prototype can continue. - [ ] Identify test bed of TCGA samples from various tumor types. We can mix tumor-normal samples (as I've done at the counts/allelic-counts level in preliminary evaluations of the TH prototype) to expand the effective number of samples.; - [ ] Determine minimal version of current CGA ABSOLUTE pipeline (to be used as a baseline for comparison).; - [ ] Generate and manually curate ABSOLUTE results and narrow samples down to those with relatively robust solutions.; - [ ] Construct ModelSegments/M2 -> ABSOLUTE pipeline (will at least require minor development/tuning of ModelSegments output -> ABSOLUTE input conversion script, may also require germline tagging, see related #5804) and evaluate.; - [ ] Construct ModelSegments/M2 -> TH pipeline and evaluate.; - [ ] Remove unsupported code/tools. See https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199 for a summary. We should make sure that any users that would be affected by this are notified and prepare accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699:31,validat,validation,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699,1,['validat'],['validation']
Security,Revert explicit GAR references in our Docker build scripts for now. Variants team members are not Methods team members and thus do not have the access required to make Variants GAR repos public in the `broad-dsde-methods` project. Note that Variants images are still ending up in GAR thanks to the magic of DevOps redirects. This PR also retains the Docker image ID-based referencing that was introduced at the same time as the explicit GAR references that are now being backed out. Successful (or at least non-instafailing) [integration run here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/2f00b836-0c2d-41e9-84b1-b8c6a2bea8f6).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8789:144,access,access,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8789,1,['access'],['access']
Security,"Reviving this. This will essentially be a major refactor/rewrite of CreatePanelOfNormals to make it scalable enough to handle WGS. - [x] CombineReadCounts is too cumbersome for large matrices. Change CreatePanelOfNormals to take in multiple -I instead.; - [x] Rename NormalizeSomaticReadCounts to DenoiseReadCounts and require integer read counts as input. These will still be backed by a ReadCountCollection until @asmirnov239's changes are in.; - [x] Remove optional outputs (factor-normalized and beta-hats) from DenoiseReadCounts. For now, TN and PTN output will remain in the same format (log2) to maintain compatibility with downstream tools.; - [x] Maximum number of eigensamples K to retain in the PoN is specified; the smaller of this or the number of samples remaining after filtering is used. The number actually used to denoise can be specified in DenoiseReadCounts. If we are going to spend energy computing K eigensamples, there is no reason we shouldn't expose all of them in the PoN, even if we don't want to use all of them for denoising. (Also, the current SVD utility methods do not allow for specification of K < N when performing SVD on an MxN matrix, even though the backend implementations that are called do allow for this; this is terrible. In any case, randomized SVD should be much faster than the currently available implementations, even when K = N).; - [x] Rename CreatePanelOfNormals to CreateReadCountPanelOfNormals; - [x] Refer to ""targets"" as intervals. See #3246.; - [x] Remove QC.; - [x] Refer to proportional coverage as fractional coverage.; - [x] Perform optional GC-bias correction internally if annotated intervals are passed as input.; - [x] Make standardization process for panel and case samples identical. Currently, a sample mean is taken at one point in the PoN standardization process, while a sample median is taken in the case standardization process.; - [x] HDF5 PoN will store version number, all integer read counts, all/panel intervals, all/panel ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-313921687:969,expose,expose,969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-313921687,1,['expose'],['expose']
Security,"Rightnow doing the manual docker build locally would fail. One needs to copy the line in `.travis.yml`. ```; sudo bash build_docker.sh -e ${HASH} -s -u -d $PWD/temp_staging/;; sudo docker run -v $(pwd)/src/test/resources:/testdata --rm -e ""TEST_VERBOSITY=minimal"" -e ""TEST_TYPE=${TEST_TYPE}"" -t broadinstitute/gatk:${HASH} bash /root/run_unit_tests.sh;; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3160:140,HASH,HASH,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3160,2,['HASH'],['HASH']
Security,Rlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `96.629% <0.000%> (+0.562%)` | :arrow_up: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/8048/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `79.570% <0.000%> (+1.075%)` | :arrow_up: |; | [...dinstitute/hellbender/tools/sv/SiteDepthtoBAF.java](https://codecov.io/gh/broadinstitute/gatk/pull/8048/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9TaXRlRGVwdGh0b0JBRi5qYXZh) | `82.418% <0.000%> (+1.099%)` | :arrow_up: |; | [...lkers/validation/EvaluateInfoFieldConcordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/8048/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vRXZhbHVhdGVJbmZvRmllbGRDb25jb3JkYW5jZS5qYXZh) | `72.581% <0.000%> (+1.613%)` | :arrow_up: |; | [...va/org/broadinstitute/hellbender/GATKBaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/8048/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9HQVRLQmFzZVRlc3QuamF2YQ==) | `98.333% <0.000%> (+1.667%)` | :arrow_up: |; | ... and [211 more](https://codecov.io/gh/broadinstitute/gatk/pull/8048/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | |. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8048#issuecomment-1272595315:4692,validat,validation,4692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8048#issuecomment-1272595315,1,['validat'],['validation']
Security,"Run validation tests continuously in jenkins: ReadsPipelineSpark, BQSR etc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1401:4,validat,validation,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1401,1,['validat'],['validation']
Security,"Running on the hg19/b37 NA12878 bam file, I'm getting the following exception in stage 0:. ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 589 in stage 0.0 failed 4 times, most recent failure: Lost task 589.3 in stage 0.0 (TID 757, cwhelan-na12878-pcr--30x-bam-w-6.c.broad-dsde-methods.internal): java.lang.IllegalArgumentException: observedValue must be non-negative; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); at org.broadinstitute.hellbender.tools.spark.utils.IntHistogram.addObservation(IntHistogram.java:50); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$LibraryRawStatistics.addRead(ReadMetadata.java:367); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata$PartitionStatistics.<init>(ReadMetadata.java:431); at org.broadinstitute.hellbender.tools.spark.sv.evidence.ReadMetadata.lambda$new$1dcab782$1(ReadMetadata.java:57); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGSchedul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3462:443,validat,validateArg,443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3462,1,['validat'],['validateArg']
Security,"Running something like this on the outputs of the score tool from a validation shard could help determine the threshold. (This was done hastily, so excuse any errors!). Below I show the results of running with a test VCF of 50 1000G WES samples. Note that ""training"" and ""truth"" are used in the VQSR meanings, and that we derive positive labels for the validation set from their union; but one could imagine variations on this. ```; import h5py; import numpy as np; import matplotlib.pyplot as plt. annot_file = 'test.all-unlabeled.annot.hdf5'; scores_file = 'test.all-unlabeled.scores.hdf5'. with h5py.File(annot_file, 'r') as f:; is_training_n = f['/labels/training'][()].astype(bool); is_truth_n = f['/labels/truth'][()].astype(bool); ; with h5py.File(scores_file, 'r') as f:; score_n = f['/data/scores'][()]. score_sort_order_n = score_n.argsort(); sorted_score_n = score_n[score_sort_order_n]; is_positive_n = is_training_n | is_truth_n. p_n = is_positive_n[score_sort_order_n]; m_n = ~p_n. tp_n = np.cumsum(p_n[::-1])[::-1]; fn_n = np.cumsum(p_n); mp_n = np.cumsum(m_n[::-1])[::-1]. recall_n = tp_n / (tp_n + fn_n); LL_score_n = recall_n**2 / (mp_n / sum(m_n)). argmax_idx = np.argmax(LL_score_n); LL_score_max = LL_score_n[argmax_idx]; LL_score_argmax = sorted_score_n[argmax_idx]; recall_at_LL_score_argmax = recall_n[argmax_idx]. plt.plot(sorted_score_n, LL_score_n, label=f'LL score, max = {LL_score_max:.2f}, argmax = {LL_score_argmax:.2f}'); plt.plot(sorted_score_n, recall_n, label=f'recall, at LL score argmax = {recall_at_LL_score_argmax:.2f}'); plt.axvline(LL_score_argmax, c='grey'); plt.xlabel('score'); plt.legend(); plt.show(); ```. ![image](https://user-images.githubusercontent.com/11076296/158000937-79dcfc26-45c6-400f-9101-37a96087492e.png). Would be interesting to also plot e.g. F1 vs. score, where F1 is determined on a orthogonal set of positive/negative gold-standard labels (e.g., GIAB), to see how close the LL score determined on the ""training/truth"" labels gets us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065794594:68,validat,validation,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065794594,2,['validat'],['validation']
Security,"SCAN\_WINDOW\_SIZE=1000. When it's set to default value 100, the error message is slightly different but ArrayIndexOutOfBoundsException persists. I have also experimented with different window sizes, all values >1000 give same error at the same read on chrX (details below). The reference fasta file is taken from UCSC: [https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz](https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz). Any feedback leading to resolving the issue is greatly appreciated. a) Picard version:. 2.21.6-SNAPSHOT. b) Command script:. java -jar picard.jar CollectGcBiasMetrics \\ ; ; I=sorted.sam \\ ; ; O=gc\_bias\_metrics.txt \\ ; ; CHART=gc\_bias\_metrics.pdf \\ ; ; S=summary\_metrics.txt \\ ; ; R=hg19.fa \\ ; ; SCAN\_WINDOW\_SIZE=1000. c) Error log:. MINIMUM\_GENOME\_FRACTION=1.0E-5 IS\_BISULFITE\_SEQUENCED=false METRIC\_ACCUMULATION\_LEVEL=\[ALL\_READS\] ALSO\_IGNORE\_DUPLICATES=false ASSUME\_SORTED=true STOP\_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION\_STRINGENCY=STRICT COMPRESSION\_LEVEL=5 MAX\_RECORDS\_IN\_RAM=500000 CREATE\_INDEX=false CREATE\_MD5\_FILE=false GA4GH\_CLIENT\_SECRETS=client\_secrets.json USE\_JDK\_DEFLATER=false USE\_JDK\_INFLATER=false ; ; \[Tue Jan 07 16:48:19 PST 2020\] Executing as [akoch@hpc5-0-3.local](mailto:akoch@hpc5-0-3.local) on Linux 2.6.32-431.11.2.el6.x86\_64 amd64; OpenJDK 64-Bit Server VM 1.8.0\_181-b13; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.21.6-SNAPSHOT ; ; INFO 2020-01-07 16:51:24 SinglePassSamProgram Processed 1,000,000 records. Elapsed time: 00:00:33s. Time for last 1,000,000: 27s. Last read position: chr5:92,832,908 ; ; INFO 2020-01-07 16:51:53 SinglePassSamProgram Processed 2,000,000 records. Elapsed time: 00:01:01s. Time for last 1,000,000: 28s. Last read position: chr11:121,228,669 ; ; \[Tue Jan 07 16:52:25 PST 2020\] picard.analysis.CollectGcBiasMetrics done. Elapsed time: 4.10 minutes. ; ; Runtime.totalMemory()=4236247040 ; ; To ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6372:1491,VALIDAT,VALIDATION,1491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6372,1,['VALIDAT'],['VALIDATION']
Security,"SSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Process",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:3060,Validat,ValidateVariants,3060,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(Fil,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:7852,secur,security,7852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['secur'],['security']
Security,SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(Fil,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:6146,secur,security,6146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['secur'],['security']
Security,SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(Fil,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9634,secur,security,9634,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['secur'],['security']
Security,"SamAssertionUtils.samsEqualStringent tries to short-circuit file validation by first doing an md5 compare. Most of the time when we run the test suite (in the current tests 171 out of 193), the short-circuiting fails we do the more expensive read by read test. All of these have one or more that fail md5 check (some are probably crams, which IIRC places the file name in the cram header):. MarkDuplicatesIntegrationTest; AddOrReplaceReadGroupsIntegrationTest; ApplyBQSRIntegrationTest; ApplyBQSRSparkIntegrationTest; BQSRPipelineSparkIntegrationTest; BwaSparkIntegrationTest; GatherBamFilesIntegrationTest; HaplotypeBAMWriterUnitTest; PrintReadsIntegrationTest; ReadsPipelineSparkIntegrationTest; SamAssertionUtilsUnitTest; SamFormatConverterIntegrationTest; SortReadFileSparkIntegrationTest; SortSamIntegrationTest; SplitNCigarReadsIntegrationTest; ClipReadsIntegrationTest",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2395:65,validat,validation,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2395,1,['validat'],['validation']
Security,"SamFile - Defaults.CREATE_INDEX : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_MD5 : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CUSTOM_READER_FACTORY : ; 19:03:42.999 INFO ValidateSamFile - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 19:03:42.999 INFO ValidateSamFile - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.REFERENCE_FASTA : null; 19:03:43.000 INFO ValidateSamFile - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.000 INFO ValidateSamFile - Initializing engine; 19:03:43.000 INFO ValidateSamFile - Done initializing engine; ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 24466, Read name 20FUKAAXX100202:7:46:13035:77621, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97940, Read name 20FUKAAXX100202:5:7:21464:86224, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97955, Read name 20GAVAAXX100126:5:7:1291:122571, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 112212, Read name 20GAVAAXX100126:8:1:1429:129840, bin field of BAM record does not equal value compu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:2008,Validat,ValidateSamFile,2008,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,1,['Validat'],['ValidateSamFile']
Security,SampleDBBuilder validationStrictness argument doesn't do anything,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3949:16,validat,validationStrictness,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3949,1,['validat'],['validationStrictness']
Security,"Say hello to Azure SQL Database from `sqlcmd`, Python and Java (via Ammonite) running in a Cromwell on Azure deployment. Since the Azure Batch VMs spun up by Cromwell on Azure appear to have no identity associated with them the workflow currently takes a database access token as a parameter which it passes to the three tasks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8220:264,access,access,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8220,1,['access'],['access']
Security,"ScoreVariantAnnotations:. Scores variant calls in a VCF file based on site-level annotations using a previously trained model. TODOs:. - [x] Integration tests. Exact-match tests for (non-exhaustive) configurations given by the Cartesian product of the following options:; * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); * non-allele-specific vs. allele-specific; * SNP-only vs. SNP+INDEL (for both of these options, we use trained models that contain both SNP and INDEL scorers as input) ; - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Double check or add behavior for handling previously filtered input, clearing present filters, etc. Future work:. - [ ] The `score_samples` method of the sklearn IsolationForest is single-threaded. See (possibly stalled) PR at https://github.com/scikit-learn/scikit-learn/pull/14001 and some workarounds using e.g. `multiprocessing` ibid.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563:686,validat,validation,686,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563,1,['validat'],['validation']
Security,"See #2488 for context. In short, the internal pathways for authentication changed, breaking some tests. We're pushing forward anyways but need to remember to re-enable the code & tests once we can (should be the next release).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2496:59,authenticat,authentication,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2496,1,['authenticat'],['authentication']
Security,"See Issue #7622 for more details. In addition to unit tests, here is how I validated:. ```; ##; # Split the WGS list; ##; rm -rf test_split. ./gatk --java-options ""-Xmx4g $DEBUG"" \; WeightedSplitIntervals \; --scatter-count 100 \; --weight-bed-file gvs_vet_weights_1kb.bed \; -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta \; --dont-mix-contigs true \; -L wgs_calling_regions.hg38.noCentromeres.noTelomeres.interval_list \; --output test_split. ##; # merge all the intervals lists back into one; ##; IL=""""; for f in test_split/*-scattered.interval_list; do; IL=""${IL} -I $f ""; done; ./gatk IntervalListTools --ACTION UNION $IL -O test_split/merged.interval_list. #; # compare it to the original; ##; ./gatk CompareIntervalLists \; -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta \; -L wgs_calling_regions.hg38.noCentromeres.noTelomeres.interval_list \; -L2 test_split/merged.interval_list. ##; # A visual check to see that the ordering is the same, and that the only splits; # are across file boundaries; ##; cat test_split/*-scattered.interval_list | grep -v ""@"" | cut -f1-3 > test_split/combined.txt; cat wgs_calling_regions.hg38.noCentromeres.noTelomeres.interval_list | grep -v ""@"" | cut -f1-3 > test_split/orig.txt; diff -y test_split/orig.txt test_split/combined.txt; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7643:75,validat,validated,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7643,1,['validat'],['validated']
Security,"See https://github.com/broadinstitute/gatk/issues/4125 (which I suspect is due to the conda env not being established). @mbabadi @samuelklee @vdauwera Unfortunately we didn't add anything to the doc for these tools saying that they require the conda env. Some suggestions:. - Ideally, we could do something along the lines of what @droazen suggested in #4125, where the script executor validates that the environment is established. In a previous discussion though, @vdauwera expressed some concerns around requiring miniconda (as opposed to enumerating the individual requirements and allowing users to install these themselves - which is harder to communicate, and even harder to validate). We should discuss this further.; - Either way, the tools themselves could catch PythonScriptExecutorException and re-throw it with a helpful message saying the conda env is required.; - Update the tool summaries saying that the conda env is required.; - Update the tool javadoc/gatkdoc with more detail.; - Other ? Blog entry/forum post ?. This shouldn't be an issue for Docker users. We did discover a last minute issue that will affect OSX users though, which has a couple of workarounds described in this [PR](https://github.com/broadinstitute/gatk/pull/4087).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4127:386,validat,validates,386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4127,2,['validat'],"['validate', 'validates']"
Security,Seeing a test failure due to errors with the service account access token. Possibly related to updating the NIO dependency. We've seen this multiple times today. ; ```; Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.nio.GcsNioIntegrationTest.openPublicFile FAILED; com.google.cloud.storage.StorageException: Error getting access token for service account: ; at com.google.cloud.storage.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:203); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:349); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:186); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:183); at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:183); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:197); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:194); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:72); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:62); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:268); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newByteChannel(CloudStorageFileSystemProvider.java:229); at java.nio.file.Files.newByteChannel(Files.java:361); at java.nio.file.Files.newByteChannel(Files.java:407); at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newInputStream(CloudStorageFileSystemProvider.java:348); at java.nio.file.Files.newInputStream(Files.java:152); at org.broadinstitute.hellbender.utils.nio.GcsNioIntegrationTest.openPublicFile(GcsNioIntegra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:61,access,access,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,2,['access'],['access']
Security,"Seems a shame to have every Spark application depend on GCS code, just to have access to HDFS. Maybe we could bust this into two pieces: separate out a spark.utils.HDFSUtils that knows nothing about GCS but can handle ""file:"" and ""hdfs:"" URLs, leaving the original gcs.BucketUtils that handles only ""gcs:"" URLs, and delegates non-gcs URLs to HDFSUtils.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1887:79,access,access,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1887,1,['access'],['access']
Security,"Sequence dictionary is not enough -- we actually need the reference because GenomicsDB uses that to fill in the reference base in some cases. For this reason, the reference is a required argument when reading from GenomicsDB, but as this issue outlines we probably should go one step further and validate that the intervals being queried are in the reference. We can add this to GenomicsDB but it's probably better to have a check done in GATK so that we fail fast. It is interesting though that the results seem valid...presumably having the reference base as 'N' in some cases doesn't affect it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7751#issuecomment-1095222041:296,validat,validate,296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7751#issuecomment-1095222041,1,['validat'],['validate']
Security,Serious Security Vulnerabilities in GATK,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215:8,Secur,Security,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215,1,['Secur'],['Security']
Security,"Several of our HGSV snapshot samples are failing with current master due to an exception in `CpxVariantInterpreter`. For example, sample HG00732 fails with this stacktrace:. ```; 18/04/11 14:30:28 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 2.0 in stage 42.0 (TID 60116, cwhelan-hg00732-cram-samtools-bam-feature-w-5.c.broad-dsde-methods.internal, executor 27): java.lang.IllegalArgumentException: Invalid interval. Contig:chr19 start:33757506 end:33757488; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.ContigAlignmentsModifier.computeNewRefSpanAndCigar(ContigAlignmentsModifier.java:159); at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.ContigAlignmentsModifier.clipAlignmentInterval(ContigAlignmentsModifier.java:42); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.removeOverlap(CpxVariantInterpreter.java:179); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.deOverlapAlignments(CpxVariantInterpreter.java:122); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.furtherPreprocess(CpxVariantInterpreter.java:79); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.lambda$inferCpxVariant$bdd686a3$1(CpxVariantInterpreter.java:51); at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4648:517,validat,validateArg,517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4648,2,['validat'],"['validateArg', 'validatePositions']"
Security,Should be validated to the point where production would be willing to use it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1640:10,validat,validated,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1640,1,['validat'],['validated']
Security,"Similar to how `GATKTool` requires a reference when there's at least one cram input, we need to do the same thing in spark. Right place to do this is probably in `GATKSparkTool.initializeReads()` or `GATKSparkTool.validateToolInputs()`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1181:214,validat,validateToolInputs,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1181,1,['validat'],['validateToolInputs']
Security,"SimpleInterval has a constructor that parses an interval String, but without access to a SequenceDictionary its not possible to correctly interpret intervals with contig names such as those used in hg38. It looks like the only non-test consumer of this method is TableCodec. For example:. - `HLA-A*01:01:01:01` is interpreted as `HLA-A*01:01:01:1-1`, but `HLA-A*01:01:01` doesn't exist; - `HLA-A*01:01:01:02N` its interpreted as position `02N` on contig `HLA-A*01:01:01`, which fails to parse, and the contig doesn't exist. GATK command line intervals resolve these by consulting the sequence dictionary. For hg38 at least, there can be no ambiguity and there is always only one correct interpretation. Its possible to construct a legal sequence dictionary that has ambiguities though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4597:77,access,access,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4597,1,['access'],['access']
Security,"Since @davidadamsphd has his hands full with getting the end-to-end large-scale validation tests for spark tools into a runnable state, I'm re-assigning this to @akiezun. @akiezun feel free to move this to beta if you don't think it's necessary for alpha -- if you have time, though, and run out of tickets, it might be a good use of your time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/591#issuecomment-157525053:80,validat,validation,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/591#issuecomment-157525053,1,['validat'],['validation']
Security,"Since GenomicsDB can be used with `CreateSomaticPanelOfNormals`, allow for the GenomicsDBArgumentCollection to be exposed with this tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6746:114,expose,exposed,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6746,1,['expose'],['exposed']
Security,"Since NIO reportedly now works from Spark clients, this bit of; authentication is unnecessary. Removing it greatly simplifies; BucketUtils, and also stops users having to worry about where; to get the AuthHolder from. This work is part of #2402",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2565:64,authenticat,authentication,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2565,1,['authenticat'],['authentication']
Security,"Since https://github.com/broadinstitute/gatk/pull/4711, we use a deletion hook to delete the temp directories created by the R executor, but the R executor also deletes these itself. https://github.com/samtools/htsjdk/pull/1315 seems to have exposed this by propagating the exception from the second attempt. See https://gatkforums.broadinstitute.org/gatk/discussion/comment/46733#Comment_46733.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5893:242,expose,exposed,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5893,1,['expose'],['exposed']
Security,"Since it's realigning the bam, it shouldn't validate that the file to be aligned already matches the header. This makes it impossible to realign to a different reference or align a headerless file. . This can currently be worked around using `--disableSequenceDictionaryValidation`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2121:44,validat,validate,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2121,1,['validat'],['validate']
Security,"Since the migration from travis-ci.org to travis-ci.com I've been unable to access our coveralls page. The coverage badge on the repo is broken as well. Others seem to be able to access the https://coveralls.io/r/broadinstitute/hellbender page, but I get an ""Access Denied"". It's still commenting on our posts, but it's not very useful without the actual coverage display. . I know @droazen can still see the page, @akiezun, can you? . I filed an issue with coveralls here: https://github.com/lemurheavy/coveralls-public/issues/497 but haven't heard anything back from them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/381:76,access,access,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/381,3,"['Access', 'access']","['Access', 'access']"
Security,"Since we are already injecting Arguments including FeatureInputs and referenceDictionaries... why we need to pass ReferenceContext or FeatureContext in the apply method? . If a tool requires some features, it could access it directly from the feature-input that is already declaring as a member field (of course, once the query api is provided there)... . What is the Optional<FeatureContext> giving us that could not be perfectly supported by an API-enriched FeatureInput object?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242:21,inject,injecting,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242,2,"['access', 'inject']","['access', 'injecting']"
Security,"Small PR containing fixes for various issues:; - Move CompareSAMs to picard package (fixes https://github.com/broadinstitute/hellbender/issues/139); - Move most of `CompareSAMs.doWork()` into a separate public method, to be used by external unit tests; - Use HTSJDK's SamFileValidator in assorted unit tests, rather than ValidateSamFile (which is just a CLP wrapper); - Insert `--VERBOSITY ERROR` into CommandLineProgramTest, which suppresses most logging output for CLPs that use HTSJDK-based logging (fixes https://github.com/broadinstitute/hellbender/issues/134)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/171:321,Validat,ValidateSamFile,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/171,1,['Validat'],['ValidateSamFile']
Security,"So should we expose it, or should we replace it and expose the replacement? :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1064#issuecomment-151894230:13,expose,expose,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1064#issuecomment-151894230,2,['expose'],['expose']
Security,"So this seems to only happen when trying to access a bucket from a job on dataproc. For example, the following throws the error:. ./gatk-launch PathSeqFilterSpark -I gs://bucket/in.bam -O gs://bucket/out.bam -- --sparkRunner GCS --cluster my-cluster. but the following does not:; ./gatk-launch PathSeqFilterSpark -I hdfs://bams/in.bam -O hdfs://bams/out.bam -- --sparkRunner GCS --cluster my-cluster. This happens even if I launch the cluster ""gcloud dataproc clusters create ... --scope cloud-platform"", which is supposed to grant full storage permissions. I believe this is equivalent to checking the ""Allow API access to all Google Cloud Services"" box if you launch a cluster through the web console. . Also explicitly adding the service account as a ""storage legacy bucket owner"" does not seem to help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331002437:44,access,access,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331002437,2,['access'],['access']
Security,"So we've had some debate over what the commands should be. Definitely still subject to change. . What's the right way to access the ; 1. help for gatk-launch itself; 2. tools list for gatk. currently `gatk-launch` displays it's own help, while `gatk-launch -help` passes through the help request to gatk which shows the tools list. I don't think `gatk-launch --help` should ONLY display the help for gatk-launch, but we could change it to display the gatk-help followed by it's own help message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1331#issuecomment-163662974:121,access,access,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1331#issuecomment-163662974,1,['access'],['access']
Security,"So, I have a question that I believe some discussions are necessary, regarding read filtering. The background that triggered this question is when I tried `PrintReads(Spark)` to filter out reads with `ReadFilterLibrary.GoodCigarReadFilter`. As it turns out, that one of the read (long read) have several alignment records, (unfortunately) the primary (i.e. 256 and 2048 flags not turned on) record is the one having a problematic CIGAR, hence filtered out. The alignment records left are&mdash;as expected&mdash;all records with either `not-primary` or `supplementary` flag turned on. . Should one consider such bam valid for analysis?; And more generally, should the collection of alignments after read filtering be checked with `ValidateBam` (assuming the tool checks for that error) as part of best practices?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6433:731,Validat,ValidateBam,731,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6433,1,['Validat'],['ValidateBam']
Security,"Somatic WDLs have them hidden, gCNV WDLs (in sl_gcnv_ploidy_cli) have them exposed. (EDIT: Actually, gCNV WDLs only have them exposed for gCNV-specific tasks. Common tasks such as PreprocessIntervals are also not exposed.). The former makes for cleaner `wdltool inputs` JSONs that contain only the bare minimum inputs, but it is unclear whether FC will allow for task-level parameters to be set. However, this can still be done via JSON, as long as the task is at the main workflow level (although this may change with a C30 hotfix?). The latter makes for messier JSONs and requires more upkeep to make sure everything stays exposed, but should work in FC (unless the workflow is used as a subworkflow?)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3980:75,expose,exposed,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3980,4,['expose'],['exposed']
Security,"Somatic WDLs should be up to date (they're passing on Travis, at least) and ready for running validations in the sl_wgs_segmentation branch @LeeTL1220.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-328536706:94,validat,validations,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-328536706,1,['validat'],['validations']
Security,"Some additional information I can add about this is that a potential solution to this problem is to remove altenate alleles and force the sites into being biallelic but this causes problems in other tools, like FastaAlternateReferenceMaker, so it's not a viable solution. . Since AD is 0-indexed and GT starts at 0, GT really seems like the best way to access the elements of the AD array. Perhaps a new feature could be added that automatically finds the called allele, like getAD().getCalledGT if giving the user access to GT is problematic for some reason. This would require getAD to accept something other than a pure number though and to my knowledge anything other than eg: getAD().1 or getAD().2 or 0, causes errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7448#issuecomment-909126111:353,access,access,353,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7448#issuecomment-909126111,2,['access'],['access']
Security,"Some comments/questions for the review:; - I'll add a separate ticket to rewrite the integration tests, all of which pass and most of which are disabled since they require access to large files on the broad file system. In the meantime I need to add a couple of small tests to get the coverage back up, and would like to get the CR process started.; - I ported a bunch of support files but need feedback on whether they're in the right location.; - Somewhere I saw something that said GATK no longer supports .ped files ? If not, what should the replacement be in the tests require pedigree input?; - Is it a requirement to support Ploidy > 2 ? The current GATK tool, and thus the HB tool, do not; - I did not port the WalkerTestSpec.disableShadowVCF? Is that needed in Hellbender ?; - Are there other headers I should be applying to the output variant file ?. Command Line Arguments:; - I didn't port the GATK command line argument ""-no_cmd_line_in_header"". Should I ? And if not, should the command line args automatically be propagated to the output vcf file ? I didn't see GATK do this anywhere.; - There was one test that used --variant:dbsnp on the command line but I couldn't find the code that processed that in GATK, not sure what the means on the command line.; - I replaced ""-U LENIENT_VCF_PROCESSING"" with ""--lenient"" (testFileWithoutInfoLineInHeaderWithOverride needs this to pass).; - I replaced ""-L"" with --interval since HB seems to use -L for ""lane"" ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027:172,access,access,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027,1,['access'],['access']
Security,"Some filters are implemented in the ModelSegments CreatePoN code (since these filters were directly ported from GATK CNV). Other filters were implemented as external python scripts by @mbabadi for GPC2 validation. We should extract and productionize if possible. Ideally, the tool would take several coverage files (collected over identical bins) and filtering parameters as input, and output a filtered list of bins. Downstream tools would subset the original coverage files to these bins accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2992#issuecomment-391682843:202,validat,validation,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2992#issuecomment-391682843,1,['validat'],['validation']
Security,"Some of the GTF files from ENSEMBL do not follow the format that the current `EnsemblGtfCodec` expects. This will cause Funcotator to fail on those files. A complete description (courtesy of ENSEMBL themselves) of their GTF format is as follows (and it differs from what is expected in the code):. ```; #### README ####. --------; GTF DUMP; --------. This directory includes a summary of the gene annotation information ; and GTF format. Ensembl provides an automatic gene annotation for Aedes aegypti.; For some species ( human, mouse, zebrafish, pig and rat), the; annotation provided through Ensembl also includes manual annotation; from HAVANA.; In the case of human and mouse, the GTF files found here are equivalent; to the GENCODE gene set. GTF provides access to all annotated transcripts which make; up an Ensembl gene set. Annotation is based on alignments of; biological evidence (eg. proteins, cDNAs, RNA-seq) to a genome assembly.; The annotation dumped here is transcribed and translated from the ; genome assembly and is not the original input sequence data that ; we used for alignment. Therefore, the sequences provided by Ensembl ; may differ from the original input sequence data where the genome ; assembly is different to the aligned sequence. . Additionally, we provide a GTF file containing the predicted gene set; as generated by Genscan and other abinitio prediction tools.; This file is identified by the abinitio extension. -----------; FILE NAMES; ------------; The files are consistently named following this pattern:; <species>.<assembly>.<version>.gtf.gz. <species>: The systematic name of the species.; <assembly>: The assembly build name.; <version>: The version of Ensembl from which the data was exported.; gtf : All files in these directories are in GTF format; gz : All files are compacted with GNU Zip for storage efficiency. e.g.; Homo_sapiens.GRCh38.81.gtf.gz. For the predicted gene set, an additional abinitio flag is added to the name file.; <species>.<assem",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6488:761,access,access,761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6488,1,['access'],['access']
Security,"Some tools have had usage examples ported from GATK3 that don't work in GATK4. We should fix ; these. . As well as fixing errors, it would be good to change the javadoc so it references parameters by the constant values instead of hardcoding them. (use `{@value StandardArgumentDefinitions#SOME_NAME}` ). These occur in at least the following tools, (found by `find in path -T`):; - [ ] ValidateVariants; - [ ] VariantFiltration; - [ ] AnalyzeCovariates; - [ ] BaseRecalibrator; - [ ] LeftAlignIndels",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1632:387,Validat,ValidateVariants,387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1632,1,['Validat'],['ValidateVariants']
Security,"Some tools need to dynamically resize the reference context window based upon other; input. This commit exposes a setWindow() method to allow tools to do this. -To change the reference context size, tools should invoke setWindow() on the; ReferenceContext provided by the engine before invoking getBases()/getBasesIterator(). -Hopefully eliminates the need for tools to create their own reference readers. -ReferenceContext still caches previous query results, but cache gets invalidated; every time the window size changes. Resolves #131",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/136:104,expose,exposes,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/136,1,['expose'],['exposes']
Security,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:909,validat,validation,909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774,5,['validat'],"['validate', 'validated', 'validation']"
Security,"Sorry, it's difficult for me to spot git notifications in my email. . > Maybe @bshifaw can chime in? Are the featured workspaces covered by tests elsewhere? What is the current SOP for taking workflows from this repo, turning them into featured workspaces, and populating their configurations?. Example JSONs with input test data are usually introduced in the gatk-workflows git repos and carried over to the featured workspaces. That isn't to say they are not welcomed from the gatk repo. > @bshifaw related to what Sam was saying - we also have a few standard resources needed to run the workflows that we would like to share with users. What is the standard procedure for doing so? Ideally they would be bundled with featured workspaces, but also accessible from outside of Terra. Workflow resources files that are not already in [broad-references](https://console.cloud.google.com/storage/browser/broad-references) would be saved in the [gatk-best-practices](https://console.cloud.google.com/storage/browser/gatk-best-practices) bucket. In the past i've separated the resources files per workflow directory (e.g. pathseq, cnn-hg38) but you can organize them a different way if the resources files would be shared by other workflows (e.g. somatic-hg38, somatic-b37).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-507703719:750,access,accessible,750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6017#issuecomment-507703719,1,['access'],['accessible']
Security,Spark large scale validation: allow tests to be run in push-button fashion using a script or similar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/695:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/695,1,['validat'],['validation']
Security,Spark large scale validation: requirements gathering and design,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1167:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1167,1,['validat'],['validation']
Security,"Spark large scale validation: tools to ingest GATK3 outputs, and prepare them as GATK4 inputs",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1169:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1169,1,['validat'],['validation']
Security,Spark large scale validation: tools to intelligently compare MarkDuplicates results,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1168:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1168,1,['validat'],['validation']
Security,"Spark tests in Jenkins are failing nightly. They've been failing since August 29th. This command:. ```; gcloud auth activate-service-account gatktestjenkins@broad-gatk-test.iam.gserviceaccount.com --key-file /scratch/testservice.json --project broad-gatk-test; ./gatk-launch MarkDuplicatesSpark \; --shardedOutput true \; -O /scratch/tmp.md.bam \; --numReducers 0 \; --apiKey $APIKEY \; -I $bamIn \; -- \; --sparkRunner GCS \; --driver-memory 8G \; --cluster $CLUSTERNAME \; --executor-cores 3 \; --executor-memory 25G \; --conf spark.yarn.executor.memoryOverhead=2500""; ```. Fails with:. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/spark/Logging; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at org.apache.spark.util.ChildFirstURLClassLoader.loadClass(MutableURLClassLoader.scala:52); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.bdgenomics.adam.serialization.ADAMKryoRegistrator.registerClasses(ADAMKryoRegistrator.scala:85); at org.broadinstitute.hellbender.engine.spark.GATKRegistrator.registerClasses(GATKRegistrator.java:74); at org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$6.apply(KryoSerializer.scala:125); at org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$6.apply(KryoSerializer.scala:125); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.sc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2183:801,secur,security,801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2183,4,"['Secur', 'access', 'secur']","['SecureClassLoader', 'access', 'security']"
Security,Spark version of ValidateSamFile,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5642:17,Validat,ValidateSamFile,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5642,1,['Validat'],['ValidateSamFile']
Security,"SparkGenomeReadCounts has some code to get rid of some of the non-autosomal chromosomes:. private static final Set<String> NONAUTOSOMALCONTIGS = new HashSet<>(Arrays.asList(""X"", ""Y"", ""MT"", ""M"", ""x"", ""y"",; ""m"", ""chrX"", ""chrY"", ""chrMT"", ""chrM"", ""chrm""));. protected static final String DROP_NON_AUTOSOMES_SHORT_NAME = ""keepxy"";; protected static final String DROP_NON_AUTOSOMES_LONG_NAME = ""keepXYMT"";. @Argument(doc = ""Keep X, Y, GL*, NC_*, and MT regions. If this option is not specified, these regions will be dropped, regardless of intervals specified. Use -L (or -XL) and enable this option for exact specification of intervals. This option may be removed in the future."",; fullName = DROP_NON_AUTOSOMES_LONG_NAME,; shortName = DROP_NON_AUTOSOMES_SHORT_NAME,; optional = true; ); protected boolean keepNonAutosomes = false;. This is a bit hacky, but we could expand the list to account for GRCh38 non-autosomes. (Also note that the choice of the short name for the parameter is not great...we should fix that.) @asmirnov239 the final version of your new tool should be able to handle this sort of thing more elegantly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317808987:149,Hash,HashSet,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317808987,1,['Hash'],['HashSet']
Security,SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.io.IOException: Error reading null at position 0; 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.openStream(SeekableGCSStream.java:126); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.seek(SeekableGCSStream.java:103); 	at com.google.cloud.genomics.dataflow.readers.bam.SeekableGCSStream.<init>(SeekableGCSStream.java:59); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAMFile(BAMIO.java:67); 	at com.google.cloud.genomics.dataflow.readers.bam.BAMIO.openBAM(BAMIO.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:178); 	... 20 more; Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized; Anonymous users does not have storage.objects.get access to object mw-pathseq-test/hs37d5cs.reads.sorted.bam.; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929:9835,access,access,9835,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929,1,['access'],['access']
Security,Spawn of VS-1214 which required the ability to run with a wheel. Hopefully we never need to use this but now we would have the ability if we ever need it. Full integration run [in progress](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/6d67fda8-1237-4cd8-bf49-fe582ae7fc13). Runs requiring PMI ops access exercising this new wheel functionality with a Delta-age 0.2.98 wheel:; - [Delta](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20Echo%20RD/job_history/7215bdc8-f951-4b84-b9bf-3aaa80eae0a1); - [Delcho](https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/GVS%20AoU%20Echo%20RD/job_history/a336972e-d9f4-4a74-92fe-6ed94d2b5fff),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8692:324,access,access,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8692,1,['access'],['access']
Security,"Spin up a public jenkins server for long-running validation tests (and other tests that can't or shouldn't run in travis), or switch from travis to a more flexible CI provider",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1400:49,validat,validation,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1400,1,['validat'],['validation']
Security,"Stacktrace is below. It looks like the default port (8020) is not being picked up.; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 5.0 failed 4 times, most recent failure: Lost task 8.3 in stage 5.0 (TID 82, tw-cluster-2-w-4.c.broad-gatk-collab.internal): java.lang.IllegalArgumentEx; ception: Wrong FS: hdfs://tw-cluster-2-m:-1/user/tom/small_spark_eval/dbsnp_138.b37.20.21.vcf, expected: hdfs://tw-cluster-2-m; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:648); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:194); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305); at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1301); at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1426); at hdfs.jsr203.HadoopFileSystem.checkAccess(HadoopFileSystem.java:937); at hdfs.jsr203.HadoopFileSystemProvider.checkAccess(HadoopFileSystemProvider.java:75); at java.nio.file.Files.exists(Files.java:2385); at org.broadinstitute.hellbender.utils.io.IOUtils.assertFileIsReadable(IOUtils.java:551); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:292); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:244); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:218); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:202); at org.broadinstitute.hellbender.engine.spark.KnownSitesCache.loadFromFeatureDataSource(KnownSitesCache.java:43); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3468:662,access,access,662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3468,1,['access'],['access']
Security,"Status update: the new qual is finished, backported, and validated in both GATK4 and the backport. In a validation of a subset of ExAC data (many samples) and 1kg data (low coverage) it finds all variants found with the old qual and saves many manifestly true multiallelics. I'm going to close this and open a new issue to delete the old qual.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1697#issuecomment-258151931:57,validat,validated,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1697#issuecomment-258151931,2,['validat'],"['validated', 'validation']"
Security,"Step #1: Port as much of `SequenceDictionaryUtils` as needed from the old GATK (remove garbage like validation exclusions, fix terrible things like non-canonical human order check if possible, if not create tickets). Port unit tests as well. Step #2: Hook up sequence dictionary validation to hellbender engine, and add integration tests to prove that dictionary incompatibilities are detected. Best place to hook this up is probably `GATKTool.onStartup()`, since it manages all the engine-level inputs for tools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/101#issuecomment-113275417:100,validat,validation,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/101#issuecomment-113275417,2,['validat'],['validation']
Security,Still got to test my Rc vs 923 add validation branch on the integration test now that it's fixed!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8592:35,validat,validation,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8592,1,['validat'],['validation']
Security,Stream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 15 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInput,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:8202,secur,security,8202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['secur'],['security']
Security,Stream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 50 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInput,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:6496,secur,security,6496,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['secur'],['security']
Security,Stream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInput,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9984,secur,security,9984,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['secur'],['security']
Security,"Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-Val",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:3951,Validat,ValidateBamsWf,3951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBamsWf']
Security,Subset VDS during validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8727:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8727,1,['validat'],['validation']
Security,"Successful run on the quickstart with the new python validation; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20cremer/job_history/475e425d-5be5-47a7-a2ed-ebbdcb3746d5. Successful run on the 3k callset with samples sets; https://app.terra.bio/#workspaces/allofus-drc-wgs-dev/NHGRI_AnVIL_3K%20Cremer/job_history/1db17d59-c221-4345-be15-7fed27358d6f. Sample set with 3202 samples; <img width=""435"" alt=""Screen Shot 2023-05-22 at 11 48 11 PM"" src=""https://github.com/broadinstitute/gatk/assets/6863459/de5683e3-b927-4fb3-bb06-ff4adc7b5435"">. <img width=""1078"" alt=""Screen Shot 2023-05-23 at 12 23 05 AM"" src=""https://github.com/broadinstitute/gatk/assets/6863459/976a382a-9953-42e7-a53a-0a7a4d15a9b8"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8325:53,validat,validation,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8325,1,['validat'],['validation']
Security,Support for GVCF validation with multiple contigs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6028:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6028,1,['validat'],['validation']
Security,"Suppose the reference haplotype is; TAAGC. . . . TAAGG. . . . and an alt haplotype (SNV at the last G shown) is; TAAGC. . . TAAG**C**. . . Suppose further that we have a read ending in the first TAAGC that has been hard-clipped (to fit the assembly region) to just a 5-base TAAGC stub. Pair-HMM is fully Bayesian and computes the total likelihood of *all* possible alignments of a read to each haplotype. This gives the alt haplotype a factor of 2 advantage because TAAGC matches it in two locations, so there are two perfectly matching alignments instead of one. In log 10 space this is log_10(2) = 0.301, which is greater than our 0.2 threshold for a likelihood to be considered informative. Therefore, by clipping the read and losing the information of its first 96 bases, we end up considering it informative for the wrong haplotype. This can lead to false positives. It *also* causes false negatives because sometimes a read stub from the normal sample get misaligned to the alt haplotype, triggering the normal artifact filter. It also causes problems in our bamout-based MC3 validation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5060:1082,validat,validation,1082,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5060,1,['validat'],['validation']
Security,"Sure, it's a fair point that we could write this genotype-compare operation as a standalone tool. It's convenient to make it work via VariantAnnotator so that we can do it concurrently with other annotation tasks, instead of needed two passes through the VCF. I primarily ask b/c this is a downgrade from GATK3, where the equivalent of FeatureContext was passed. . Would it be reasonable for the FeatureManager to somehow get exposed? In my example I am calling FeatureContext.getValues() without supplying an interval, but I certainly could (and maybe should). If one supplies a specific query interval, the Feautrecontext isnt doing much other than providing an abstraction between FeatureManager, and the boundaries set on Featurecontext (which i agree are tricky to figure out in some cases) dont really matter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754256795:426,expose,exposed,426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754256795,1,['expose'],['exposed']
Security,"TCGA SNP validation looks about the same on WES---perhaps a slight tradeoff of sensitivity for specificity at the 0.1% level, but nothing to write home about. WGS validations are still running due to the (intermittent?) NIO failures discussed elsewhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454570347:9,validat,validation,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454570347,2,['validat'],"['validation', 'validations']"
Security,Task.scala:96); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 ERROR Executor: Exception in task 518.0 in stage 0.0 (TID 518); java.io.FileNotFoundException: /home/data/WGS/F002/F002.sort.bam (Too many open files); 	at java.io.FileInputStream.open0(Native Method); 	at java.io.FileInputStream.open(FileInputStream.java:195); 	at java.io.FileInputStream.<init>(FileInputStream.java:138); 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:106); 	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:202); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:349); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:147); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:222); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:187); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:186); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:141); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:70); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:5299,Checksum,ChecksumFileSystem,5299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['Checksum'],['ChecksumFileSystem']
Security,Test to validate that CRAM MD5 slice calculation matches samtools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3430:8,validat,validate,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3430,1,['validat'],['validate']
Security,Test to verify that picard interval lists are handled properly by GATK tools. Validates the fix for https://github.com/broadinstitute/gatk/issues/3555.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3827:78,Validat,Validates,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3827,1,['Validat'],['Validates']
Security,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:1001,authenticat,authenticated,1001,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,1,['authenticat'],['authenticated']
Security,Tests that need to access data in a GCS bucket (but not run an actual pipeline); need a PipelineOptions object containing our API key. This new method makes; it for them.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/742:19,access,access,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/742,1,['access'],['access']
Security,Tests to prove that we can access and query bams in GCS from ReadWalkers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2407:27,access,access,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2407,1,['access'],['access']
Security,"Thank you @SHuang-Broad. The error was gone after I copied bwaindeximage file to lustre file system, which can be accessed by all worker nodes.; The new problem is: the program started but didn't give any informative message/progress (see log below). It was stopped (Ctl-C) after 16 hours. The sequence data is regular human exome, which could be mapped in 1-2 hours in our traditional pipeline. ```; ../gatk/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; -I hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam ; -O hdfs://ln16/user/myname/gatk4test/BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /TEST/hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=720 ; --executor-cores 20 ; --executor-memory 50g ; --conf spark.driver.memory=50g; Using GATK jar /home/myname/gatk4/gatk/build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar; Running:; /opt/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --master spark://ln16:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOption; s=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.di$able=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --conf spark.cores.max=720 --executor-cores 20 --executor-memory 50g --conf spark.driver.memory=50g /home/myname/gatk4/gatk$build/libs/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:114,access,accessed,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998,1,['access'],['accessed']
Security,Thank you @jamesemery! As a first pass at the integration tests we should make sure that the output files actually validate with Picard's ValidateSamFile tool. I can help with that if you have the files. Also we should look at some of the output manually. Can you point me to a location that has the new output files?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-233786535:115,validat,validate,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-233786535,2,"['Validat', 'validat']","['ValidateSamFile', 'validate']"
Security,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:659,authenticat,authentication,659,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504,1,['authenticat'],['authentication']
Security,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:1278,expose,expose,1278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160,1,['expose'],['expose']
Security,"Thank you for explaining this – I’m glad to hear it won’t take extra effort for my commits – I don’t want to cause extra work for you folks. I’ve re-based and pushed the changes. Please let me know if there are other commits on the trunk before you get to it and I’ll do it again. From: Louis Bergelson ; Sent: Friday, May 01, 2015 3:40 PM; To: broadinstitute/hellbender ; Cc: nenewell ; Subject: Re: [hellbender] #259 - replace calls to getChr() with getContig(). (#478). It shouldn't take any extra work to merge most external requests once things are setup properly. The issue is that certain dataflow operations a key/password to access our google account and we can't publish those as part of the repo, so we use travis.ci's encrypt mechanism to make them available to the build without making them public. On external pull requests, travis doesn't make the keys available, because it would possible to access them with a malicious pull request. . Currently the things that rely on authentication aren't running anyway in travis, but the key was still being decrypted and failing on external requests I've removed that step for now, and will be more careful to ensure that builds will continue even if the key is missing when we re-enable it. —; Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/478#issuecomment-98260330:622,password,password,622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478#issuecomment-98260330,5,"['access', 'authenticat', 'encrypt', 'password']","['access', 'authentication', 'encrypt', 'password']"
Security,Thanks @droazen! What data are you using to test the 2D model? And can we have access to your verification method?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1230344708:79,access,access,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1230344708,1,['access'],['access']
Security,Thanks @jamesemery . The issue seems to be solved on my end. Sorry but this was my misunderstanding of the improvements made to the tool itself. . https://gatk.broadinstitute.org/hc/en-us/community/posts/1260803956870-SplitNCigarReads-does-not-seem-to-split-reads-properly-as-it-was-before-3-8-1-?page=1#community_comment_4402553149467. BTW the bam file created after splitting by 4.2.0.0 is still not validated thoroughly by ValidateSamFile. Split Bam file needs its new NM MD and UQ tags regenerated by picard. . So I am closing the issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7323#issuecomment-865338591:402,validat,validated,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7323#issuecomment-865338591,2,"['Validat', 'validat']","['ValidateSamFile', 'validated']"
Security,"Thanks @ldgauthier! I think this is what you're asking for:. ```; # gVCF without --max-mnp-distance; chr4 5743509 . C T,<NON_REF> 5888.77 . DP=135;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;RAW_MQandDP=486000,135 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,135,0:135:99:0|1:5743509_C_T:5917,406,0,5917,406,5917:5743509:0,0,0,135; chr4 5743512 . T C,<NON_REF> 2745.77 . BaseQRankSum=-1.002;DP=131;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=0.000;RAW_MQandDP=471600,131;ReadPosRankSum=2.613 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 0|1:57,74,0:131:99:0|1:5743509_C_T:2774,0,2060,2945,2283,5228:5743509:0,57,0,74. # gVCF with --max-mnp-distance 5; chr4 5743509 . CTAT TTAC,TTAT,<NON_REF> 5485.73 . DP=136;ExcessHet=3.0103;MLEAC=1,1,0;MLEAF=0.500,0.500,0.00;RAW_MQandDP=489600,136 GT:AD:DP:GQ:PL:SB 1/2:0,74,56,0:130:99:5523,2213,2060,3016,0,2774,5388,2261,2994,5376:0,0,0,130; ```. I should also be able to share the BAM later today - I just need to sanitize it a little before sharing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466160716:937,sanitiz,sanitize,937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466160716,1,['sanitiz'],['sanitize']
Security,"Thanks @vidprijatelj. I see the [sticky bit](https://www.redhat.com/sysadmin/suid-sgid-sticky-bit) being used for groups for the workspace - `# flags: -s-`. That, by itself, seems to be OK, that is I am not able to reproduce the issue. But it looks like std::vector is not able to resize - `Caused by: java.io.IOException: GenomicsDB JNI Error: vector::_M_default_append`. What are the permissions to your tmp directory? Does it also have the sticky bit set? Even if the workspace only requires read permissions, GenomicsDB and probably the underlying standard C++ runtime may require write access to tmp and the sticky bit may be affecting the execution. . Also, can you please confirm that the user creating the workspace and the user reading from the workspace are the same?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1476526522:591,access,access,591,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1476526522,1,['access'],['access']
Security,"Thanks JP! We do have an argument to control the number of simultaneous GCS readers in the tool in question. However, even setting it to a low value is triggering the throttling, since we're running about 10,000 ways parallel, and each job is accessing the same set of files. We can currently only control the number of simultaneous readers within each of the 10,000 individual jobs, not across all jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307444524:243,access,accessing,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307444524,1,['access'],['accessing']
Security,"Thanks a lot @davidbenjamin! One of the questions that I have is how to add a new read to the `ReadLikelihoods` for a new allele that is found while iterating. A very simple example will be:. ``` java; public static PerReadAlleleLikelihoodMap flatPerReadAlleleLikelihoodsFromPileup(final ReadPileup pileup, final Allele refAllele) {; final PerReadAlleleLikelihoodMap pralm = new PerReadAlleleLikelihoodMap();; final byte ref = refAllele.getBases()[0];; for (final PileupElement e : pileup) {; final Allele current;; if (e.isDeletion()) {; current = Allele.SPAN_DEL;; } else if (e.getBase() == ref) {; current = refAllele;; } else {; current = Allele.create(e.getBase());; }; pralm.add(e, current, DEFAULT_FAKE_LIKELIHOOD);; }; return pralm;; }; ```. The solution that I found after looking at the class was this one, that it's very complicated:. ``` java; public static ReadLikelihoods<Allele> flatPerReadAlleleLikelihoodsFromPileup(final ReadPileup pileup, final Allele refAllele, final SAMFileHeader header) {; final Set<Allele> alleleSet = new TreeSet<Allele>();; final Map<String, List<GATKRead>> reads = new HashMap<>();; final byte ref = refAllele.getBases()[0];; alleleSet.add(refAllele);; for (final PileupElement e : pileup) {; if (e.isDeletion()) {; alleleSet.add(Allele.SPAN_DEL);; } else if (e.getBase() == ref) {; alleleSet.add(refAllele);; } else {; alleleSet.add(Allele.create(e.getBase()));; }; final String sample = ReadUtils.getSampleName(e.getRead(), header);; List<GATKRead> list = reads.getOrDefault(sample, null);; if(list == null) {; list = new ArrayList<>();; reads.put(sample, list);; }; list.add(e.getRead());; }; final ReadLikelihoods<Allele> likelihoods = new ReadLikelihoods<>(new IndexedSampleList(reads.keySet()), new IndexedAlleleList<Allele>(alleleSet), reads);; for(final PileupElement e: pileup) {; final String sample = ReadUtils.getSampleName(e.getRead(), header);; final LikelihoodMatrix<Allele> l = likelihoods.sampleMatrix(likelihoods.indexOfSample(sample));; f",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249930107:1113,Hash,HashMap,1113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249930107,1,['Hash'],['HashMap']
Security,"Thanks a lot for looking into this @sooheelee - I understand the pain of making the small data for the tests, so I really appreciate your work there. I have almost prepare a PR for the new port of `RealignerTargetCreator` that will have TODOs for the test data prepared by you, and with some tests using files already in the repository (for the target-creator, I guess that the validation for getting the regions to realign would be enough, because thanks to that tests I realized of a small bug due to not including all the loci in the `LocusWalker`). On the other hand, I will still fight for the `--nWayOut` not blocking the inclusion of `IndelRealigner` in the first place. My reasons are the following:; ; 1. Looking a bit into the code of GATK3, there is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:378,validat,validation,378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231,1,['validat'],['validation']
Security,"Thanks a lot, @ddrichel. Given that the current Mutect2 release is still broken on both tumor-normal and tumor-only WES data, and downgrade is not possible on production systems due to the log4j vulnerability: is there any path forward for users that care for both accuracy and security, @davidbenjamin and @droazen ?. I fear waiting for Mutect3 isn't an option since even when it is finished there won't be independent benchmarks available for it for quite a while. Also, I suspect (as any other software product) the new version will have bugs, too, until it has matured in production. Therefore I'd suggest that identifying, understanding and fixing the bug in the current Mutect2 release would be the wisest path forward - do you agree?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1534464682:278,secur,security,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1534464682,1,['secur'],['security']
Security,"Thanks for adding this! Let me discuss further with @mwalker174 to understand the need and typical use cases (e.g., combining fixed-grid bins) to make sure we don't run into any gotchas downstream. I'll try to review by EOD, but in the meantime, you might want to address a few issues I see at first glance:. 1) Correct the name of the tool (PreprocessIntervals) in the commit message and description.; 2) Add descriptions of the new parameters to the tool Javadoc.; 3) Amend the corresponding WDL task and expose the new parameters in all relevant germline and somatic WDLs.; 4) We should be sure to update the relevant documentation for all germline and somatic WDLs, which emphasizes how PreprocessIntervals should be run differently for WES and WGS, if we plan on changing the default behavior of the tool in the future.; 5) Tests are failing due to a compilation warning about a redundant cast to int.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387:507,expose,expose,507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387,1,['expose'],['expose']
Security,"Thanks for making this change! I might include more detail with the note (""Substantially improves results on FFPE samples""), for posterity---it's probably true, but we can't really say anything definitive with only N=1 and without the cross-validation procedure I mentioned on Slack. That is, the higher degree of denoising might just be an artifact of effectively removing more PCs with GC-bias correction (since I'm assuming the same number of PCs were explicitly removed in both cases), but it's possible that removing the optimal number of PCs without GC-bias correction could achieve a better result. Since our correction procedure is relatively naive, there may also be some dependence on bin size. However, I think it's probably not worth a detailed analysis, and that it's generally safe to enable correction by default.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5966#issuecomment-496933928:241,validat,validation,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5966#issuecomment-496933928,1,['validat'],['validation']
Security,"Thanks for the additional info! To clarify, though, was any validation done on the GVCF outputs themselves to check concordance vs. GATK3? If not, can I suggest that we do such a validation? Being able to say that we have 856 validated runs of the GATK4 HC on exome data would greatly bolster the case for including it in the new exome pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380785661:60,validat,validation,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380785661,3,['validat'],"['validated', 'validation']"
Security,"Thanks for the clarification @magicDGS. What I have are 1000 Genomes Project BAMs, which were preprocessed by the 1000 Genomes Project. The BAMs are aligned to GRCh38 and have undergone indel realignment (GATK3), so they represent a state of preprocessing against which we can validate the new indel realignment. If some representation of indels in such a BAM is sufficient as a truthset, then I can make this VCF. These samples, being from the 1000 Genomes Project, are well-analyzed and their indels will be represented in dbSNP and gnomAD resources. Of course, the test data will have been re-mapped with BWA and be without any trace of indel realignment. We should probably get someone familiar with the test suite to weigh in on the scope of the validation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371519632:277,validat,validate,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371519632,2,['validat'],"['validate', 'validation']"
Security,"Thanks for the heads up @lbergelson! I'm looking at this now; we'd added stricter validation of the strand argument in the `ReferenceRegion` constructor recently, so this should be a fairly straightforward fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356024413:82,validat,validation,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356024413,1,['validat'],['validation']
Security,"Thanks for the suggestion @fnothaft. Unfortunately, switching to Scala 2.11 didn't help as I still get a compile error due to the logging change in Spark 2:. ```; /Users/tom/workspace/gatk/src/main/java/org/broadinstitute/hellbender/utils/read/GATKReadToBDGAlignmentRecordConverter.java:38: error: cannot access Logging; return converter.convert(gatkRead.convertToSAMRecord(header), dict, readGroups);; ```. I get that with `org.bdgenomics.adam:adam-core_2.11:0.19.0` too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073#issuecomment-241995596:305,access,access,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073#issuecomment-241995596,1,['access'],['access']
Security,"Thanks for the suggestion @taytayp! We could also just go ahead and expose this in PlotDenoisedCopyRatios as well and only output a single plot there. I think it would be best to expose ylim parameters set to the current range by default (to preserve current behavior and so that comparison across samples remains easy), but perhaps we can consider a flag that plots the entire range. Perhaps we can also address things like #5748 at the same time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6391#issuecomment-576688903:68,expose,expose,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6391#issuecomment-576688903,2,['expose'],['expose']
Security,"Thanks for these suggestions, @sooheelee. Note that there's already an issue filed to add `@PG` tags at https://github.com/broadinstitute/gatk/issues/4117. As for the `@RG` tag, I was following the example of the SV team, which I saw introduced a custom RG ID (although this may only be used for tagging intermediate files---not sure?) Although not ideal, I think passing the sequence dictionary and sample name in this way allows us to reuse the relevant SAM header code and also prevents the possibility of users mixing up samples. (Recall that the old pipeline required the sample name to be passed in as a separate input to each tool and that no validation that each input came from the same sample was performed.). As for VCF output, we are also planning to add this to the ModelSegments pipeline (it is already in the gCNV pipeline). See https://github.com/broadinstitute/gatk/issues/4114. However, I think it makes sense for this to wait until the improved caller is in. I'll close this as a dupe for now, but we'll be able to reference your comments here from those issues in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160:650,validat,validation,650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160,1,['validat'],['validation']
Security,"Thanks for this pull request. It's failing at the moment because it's coming from an external pull request and travis doesn't decrypt secret keys for external pulls (for good security reasons.) It means I have to do a bit of work before this will successfully pass though. Looks good though :). The idea of removing `Feature` would correctly stop the warnings. `Feature` is actually used as a marker interface for identifying things that our input parsing system can read. So we can't just remove it and replace with `Locatable`. They're different conceptually even if they have basically the same methods. For now we can suppress those warnings, and we'll remove the methods once they are removed from htsjkd, or if that is difficult to pull of, we'll convert it to a default method once htsjdk switches to java 8.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/478#issuecomment-97956594:175,secur,security,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/478#issuecomment-97956594,1,['secur'],['security']
Security,"Thanks for your response @droazen -- just tried it and it still does not work for me. I am able to access the bucket fine via gsutil -u {project} as expected. I wonder if this is some GCP issue because I am also unable to get Cromwell to pull down files from requester pays (via Terra, so this should be handled in theory), an issue that a colleague also has once I asked her to run this command on a different r/p bucket using her billing project and account. Also, for a different project and bucket the usual workflow I have to get Hail to read from r/p buckets seems to not work with this same error. Very confused. EDIT: https://support.terra.bio/hc/en-us/articles/4447388269851 seems to provide the most parsimonious explanation:; ```; It was determined that Google tweaked an error message causing Cromwell not to recognize buckets as requestor pays.; ```. Wonder if something similar is going on with GATK?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6179#issuecomment-1048028114:99,access,access,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6179#issuecomment-1048028114,1,['access'],['access']
Security,"Thanks very much for your analysis. Job 4 does create a lot of garbage, but that appears to be inevitable whenever you are dealing with a PairRDD: You have to use a Tuple2 to represent key and value rather than using a more memory-conservative custom data object. You end up with a gazillion tiny objects that survive only during the shuffle. Too bad they didn't base PairRDD on an interface like Map.Entry. Also too bad that you cannot force a shuffle on a (plain old, non-Pair) RDD. Why not just treat it as a key-only structure and allow repartitioning? I mention this not merely to whine, but also in the faint hope that you've developed some helpful workarounds. I don't think we have enough memory to persist the reads, but we can revisit that later. Job 5 *is* doing a lot of computation. It's turning each read into kmers and testing each of those kmers to see if they exist in a large hash table. I don't think there's much opportunity for further optimization -- I knew this would be a bottleneck and tried my best to make the code efficient. The skew in task size is definitely a problem, and I'll be looking for opportunities to address that issue. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292230002:894,hash,hash,894,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292230002,1,['hash'],['hash']
Security,"Thanks very much, that is helpful. From: Louis Bergelson ; Sent: Wednesday, June 17, 2015 10:42 AM; To: broadinstitute/hellbender ; Cc: nenewell ; Subject: Re: [hellbender] Validate all existing test BAMs (#569). @nenewell If that's helpful feel free to make use of it, if it isn't feel free to discard it. —; Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-112855744:173,Validat,Validate,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-112855744,1,['Validat'],['Validate']
Security,"Thanks, @gokalpcelik! That's unfortunate that the packages are no longer accessible. However, this old version of the environment was also somewhat problematic in that it included build strings, installed many packages using pip instead of conda, and was otherwise overly restrictive, see e.g. https://gatk.broadinstitute.org/hc/en-us/community/posts/360061666671-Broken-conda-env-create-n-gatk-f-gatkcondaenv-yml. I would suggest, in the following order:. 1) Users upgrade to more recent versions of GATK; 2) Users use the 4.1.0.0 Docker; 3) Users edit the 4.1.0.0 environment to be less restrictive. For example, using Ubuntu 20.04.2 + conda 23.10.0, I was able to build something that is probably sufficiently close to the 4.1.0.0 conda environment by making the following changes:. ``` <- certifi=2016.2.28=py36_0; < - openssl=1.0.2l=0; < - pip=9.0.1=py36_1; < - python=3.6.2=0; < - readline=6.2=2; < - setuptools=36.4.0=py36_1; < - sqlite=3.13.0=0; < - tk=8.5.18=0; < - wheel=0.29.0=py36_0; < - xz=5.2.3=0; < - zlib=1.2.11=0; ---; > - openssl=1.0.2l; > - pip=9.0.1; > - python=3.6.2; > - setuptools=36.5.0; > - wheel=0.29.0; > - xz=5.2.3; > - zlib=1.2.11 ; ```. There is some clobbering that happens with the pip installs, but nothing major. Note that I cannot guarantee that this environment exactly reproduces results generated with the Docker (and it's possible that there might be a more minimal fix), but it's perhaps a starting point for those users that cannot go with the other (highly preferred) options.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8504#issuecomment-1852138745:73,access,accessible,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8504#issuecomment-1852138745,1,['access'],['accessible']
Security,"Thanks, @vruano, but I think you'll have to give me access to the FC workspace and bucket. I've opened a branch sl_revert_glob that I think will fix the issue. I'll test it out on FC and let you know how it goes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5217#issuecomment-424415630:52,access,access,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5217#issuecomment-424415630,1,['access'],['access']
Security,"Thanks, JP!; Yes, you understood right. I did not change anything. It was only different days. The probability that the same bucket could have been accessed by multiple jobs/projects totally makes sense. I will try lowering the number of scattered tasks and see if it works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526274700:148,access,accessed,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526274700,1,['access'],['accessed']
Security,"Thanks, this largely worked. However, would it be possible to also get the contents as validationDataLocation, which is . /humgen/gsa-hpprojects/GATK/data/Validation_Data/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-366140406:87,validat,validationDataLocation,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-366140406,1,['validat'],['validationDataLocation']
Security,"Thanks, we have access now. I'm pretty sure that sl_revert_glob will fix the error. I've rebased my dev branch sl_filter (which includes the filtering steps Jack mentioned in the BSV meeting today) onto sl_revert and am testing cohort mode on FC now. I'll try to test scattered-case mode as well later today if that succeeds. As @asmirnov239 pointed out to me, this revert leaves #4397 unresolved, so we should go back and clean up at some point. However, our priority now is to get a stable v1 of the SFARI evaluation on FC.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5217#issuecomment-424436535:16,access,access,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5217#issuecomment-424436535,1,['access'],['access']
Security,"Thanx for feedback. I obviously don’t know much if anything about the underlying logic but; have had enough experience to look in unusual places. Have a good weekend. RDB. On Fri, Nov 1, 2019 at 4:24 PM JP Martin <notifications@github.com> wrote:. > @rdbremel <https://github.com/rdbremel> for ""mystery 1"" see issue #5447; > <https://github.com/broadinstitute/gatk/issues/5447>. This should be an; > innocuous warning that it can't initialize the Google Cloud Storage code; > and shouldn't cause a failure unless you try to access paths that start; > with ""gs://"". Going through the Cloud initialization steps described in the; > README should remove the warning (though again, this isn't required if you; > don't need to read files from the cloud).; >; > Mystery 2: For what it's worth, ""GC overhead limit exceeded"" indicates; > that the VM was spending too much time in GC. Running low on memory is a; > possible cause but generating too many small objects or being stuck in an; > infinite loop of allocation/deallocation are others. In the past these have; > been caused by inputs that were malformed in some way. This isn't the place; > for this discussion though, please file a separate issue since it's a; > separate bug.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6182?email_source=notifications&email_token=ANCR2VHWQ6XDSUQ6KEGISFDQRSM7TA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEC4GNZY#issuecomment-548955879>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ANCR2VEC5ARUEQRTEDGJ3TDQRSM7TANCNFSM4I2MRFQA>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548989454:524,access,access,524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548989454,1,['access'],['access']
Security,"That should work for both my cases. It could be nice for SelectVariants to; be able to specify whether genotypes should be called or not too. Other; tools might want the sites-only option. On Mon, Mar 4, 2019 at 12:40 PM droazen <notifications@github.com> wrote:. > *@droazen* commented on this pull request.; > ------------------------------; >; > In; > src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBUtils.java; > <https://github.com/broadinstitute/gatk/pull/4947#discussion_r262167602>:; >; > > @@ -40,7 +40,7 @@; > */; > public static GenomicsDBExportConfiguration.ExportConfiguration createExportConfiguration(final File reference, final String workspace,; > final String callsetJson, final String vidmapJson,; > - final String vcfHeader) {; > + final String vcfHeader, final boolean doGnarlyGenotyping) {; >; > @lbergelson <https://github.com/lbergelson> @ldgauthier; > <https://github.com/ldgauthier> If tools had a way to inject custom GDB; > config (eg., via an overridable method in GATKTool), and the engine used; > this config when creating the Feature Manager on startup, would that solve; > the problem here?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4947#discussion_r262167602>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdOOjGpZBu39mqk7jekA7iOzWDTFrks5vTVqFgaJpZM4U4KK0>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-469412816:954,inject,inject,954,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-469412816,1,['inject'],['inject']
Security,"The BAM file is partitioned into chunks (called partitions) by Spark. The section of code that is failing is attempting to calculate the median number of bases covered in each partition. It calculates the number of bases covered for each partition, sorts the list, and grabs the middle entry. The code is not very defensive, and sadly, this number is 0 for your BAM. This could be because there are no partitions (I don't know why this might be), or because more than half of the partitions cover no bases (if, e.g., there are no mapped reads in the partition). Do you have a BAM that runs properly in the tool? You could try the Picard tool ValidateBAM or some tool that gathers mapping statistics (maybe samtools?) and compare the statistics on the good BAM as well as on the failing BAM. Maybe you'll spot some glaring distinction. The failing BAM is aligned and coordinate sorted, right? And the majority of the reads are mapped?. Is it a tiny BAM? Maybe we're creating too many partitions and most of them are empty?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7710#issuecomment-1065282915:642,Validat,ValidateBAM,642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7710#issuecomment-1065282915,1,['Validat'],['ValidateBAM']
Security,"The CNNPipelineIntegration tests for CNNVariantWriteTensors, CNNVariantTrain and FilterVariantTranches executes tool code, but does no expected results validation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4537:152,validat,validation,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4537,1,['validat'],['validation']
Security,"The Google Cloud web UI allows you to create ""directories"". When you press that button, it creates a file with a trailing slash, and the web UI interprets it as a directory even though it's a file. This causes no end of trouble because now every other program in the world that accesses cloud storage must be updated to adopt this ""convention"" or they'll see files where the user doesn't expect them. My guess would be that's what's going on here. That said, NIO *should* understand what these things are and ignore them. The [current workaround](https://github.com/googleapis/google-cloud-java/pull/4304) is to consider 0-byte files as potentially being fake directories. @cwhelan I cannot access the file `gs://broad-dsde-methods-shuang/pb/bams/NA12892/` but if you can, could you please check its size for me? I mean the file specifically. If it's nonzero that would explain the problem. If it's zero or nonexistent then we'll need to dig some more to understand what's going on.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-492450635:278,access,accesses,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-492450635,2,['access'],"['access', 'accesses']"
Security,"The PathSeq filter repartitioning the reads directly before the BWA host filtering step to even out the load on each partition. This is helpful for typical samples with low pathogen abundance, when ~90% of the reads are filtered before this step. . However, in some sample types such as stool, saliva, or environmental samples, one can have a large number of reads (i.e. ~10M) at this stage so the cost of the repartition shuffle outweighs the benefit of load balancing for the slow BWA step. . This PR exposes a tool argument to skip the repartitioning.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3405:503,expose,exposes,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3405,1,['expose'],['exposes']
Security,"The WGS validations that have completed so far look fine, though. Changes at the 0.1% level, mostly improvements, but nothing appears to be obviously broken. Should still run some of the other validations to be sure, but let's get this in for 4.1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454581846:8,validat,validations,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454581846,2,['validat'],['validations']
Security,"The [rules for requester pays](https://cloud.google.com/storage/docs/requester-pays#requirements) now specify two conditions under which the bucket may be accessed:. 1. userProject is specified (this is what `--gcs-project-for-requester-pays` does), or. 2. The requester has `resourcemanager.projects.createBillingAssignment` permission for the project that contains the bucket. . I suspect condition (2) is true here, so the access is granted. Note that if I remember correctly, condition (2) didn't exist when requester-pays was initially introduced.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6176#issuecomment-534288270:155,access,accessed,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6176#issuecomment-534288270,2,['access'],"['access', 'accessed']"
Security,"The `./gradlew clean install printVersion` command I mentioned publishes it to the local maven repo. Then you need to reference that version from your own build.gradle. Also beware when doing this iteratively that the local snapshot version # is based on the current head commit hash. In my experience, once gatk is published to local maven under a given version, if you want to make a change, you'll need to make a commit to force the version number to update, and then rerun the command above, and update your VariantQC to the new version. Otherwise the local repo won't be updated since it will appear up to date. Hope that makes sense.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759638068:279,hash,hash,279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759638068,1,['hash'],['hash']
Security,"The `MafOutputRenderer` changed how some funcotation fields are accessed. . Need to make VCF output consistent with the code in MAF output, and need to make sure it's consistent to the VCF format. Specifically, `VCFOutputRenderer` should use the funcotation map that is now created internally to go through and render the annotations. Specifically use `Funcotation::getFieldNames` and `Funcotation::getField`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4583:64,access,accessed,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4583,1,['access'],['accessed']
Security,"The access pattern I saw is that the queries start small and creep up to; tens or hundreds of thousands (Order of the queried numbers). With the; exponential cache expansion, the cache quickly catches up. So it's fine.; We'll revise when needed. On Wednesday, July 6, 2016, Louis Bergelson notifications@github.com; wrote:. > @akiezun https://github.com/akiezun My only concern now is that someone; > takes log10 of a very large number triggering a massive and slow cache; > expansion. This caching scheme is good for clustered queries of small; > values, but terrible for sparse large queries. Is that a case we need to; > consider?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gatk/pull/1957#issuecomment-230863916,; > or mute the thread; > https://github.com/notifications/unsubscribe/AB5rL32j0zFsPo1VQ4T6gxnEHvjpYZ02ks5qS_VhgaJpZM4JCXE9; > . ## . Sent from Gmail Mobile",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1957#issuecomment-230865040:4,access,access,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1957#issuecomment-230865040,1,['access'],['access']
Security,The addition of sequence dictionary validation functionality breaks two tests in ValidateVariantsIntegrationTest. These tests are testBadID and testBadID2_OKif_notInDBSNP.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/659:36,validat,validation,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/659,2,"['Validat', 'validat']","['ValidateVariantsIntegrationTest', 'validation']"
Security,"The code that composes the result output folder depends on ```git batch --contains HASH``` to pick up a line with a standard branch name (e.g. ``` joe_doe_bugfix```) . However this is not neceserely the case if the current checkout is not attach to a local branch... for example when one does ```git fetch; git checkout origin/master```. In that case a typical git-batch line that gets picked up is ```* (HEAD detached at origin/master)``` and in this case it will use ""origin/master)"" rather than ""joe_doe_bugfix"" to be part of the result output directory name. The problem is the ""/"" and "")"" which causes problems later at least when running copy_sv_results.sh as they are not escaped appropriately. Obvious ways to address this: ; 1. remove that component of the output name as is not needed to make it quite unique.; 2. change the sub-command to handle that situation. ; 3. or fail early (before spinning the cluster) if the GATK git checkout is detached.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3642:83,HASH,HASH,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3642,1,['HASH'],['HASH']
Security,"The code to automatically inject ""--VERBOSITY ERROR"" was included in [#171](https://github.com/broadinstitute/hellbender/pull/171/files), but without [#603](https://github.com/broadinstitute/hellbender/pull/603) or equivalent it doesn't affect log4j output. dding in #603 reduces the log output by about another 7000 lines. In addition, we could squeeze out another 5000 lines by automatically injecting ""--QUIET false"" the same way we inject --VERBOSITY.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/147#issuecomment-116737455:26,inject,inject,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/147#issuecomment-116737455,3,['inject'],"['inject', 'injecting']"
Security,"The constructors (some of them anyway) use the args during constructor execution, so validating them after the constructor is done executing is too late. Anyway, if you revert that commit so the validation happens as before, and instead add the following to the catch block in `VariantEvalEngine::createClass`, they will get propagated as expected:. ```; if (e.getCause() instanceof CommandLineException) {; // failures due to argument validation should be propagated; throw new CommandLineException(e.getCause().getMessage(), e.getCause());; }; throw new GATKException(""Problem making an instance of "" + clazz + "" Do check that the class has a constructor that accepts VariantEvalEngine"", e);; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827866803:85,validat,validating,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827866803,3,['validat'],"['validating', 'validation']"
Security,"The current `IsUsingCompressedReferences`; It does not pass project id that hosted dataset. ; When the project_id is missing in a BigQuery SQL query, the bq command will use the --project_id flag specified in the command as the default project for resolving dataset and table references.; Add additional parameter to allow passing dest project. . In our case; Error we saw in GCP console:; ```; Access Denied: Table terra-vpc-sc-dev-7ee328ad:1kg_wgs_2022q1.INFORMATION_SCHEMA.COLUMNS: User does not have permission to query table terra-vpc-sc-dev-7ee328ad:1kg_wgs_2022q1.INFORMATION_SCHEMA.COLUMNS, or perhaps it does not exist.; ```. `terra-vpc-sc-dev-7ee328ad:1kg_wgs_2022q1.INFORMATION_SCHEMA.COLUMNS` is wrong - `terra-vpc-sc-dev-7ee328ad` is the user workspace; It should be `fc-aou-cdr-synth-test-2.1kg_wgs_2022q1` - `fc-aou-cdr-synth-test-2` is the project that contains CDR data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9023:395,Access,Access,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9023,1,['Access'],['Access']
Security,"The current hardcoded limit restricts us to 16777215 bins, which we can hit as we go below 200bp bins. For a given matrix that needs to be broken into chunks, increasing the chunk size by decreasing CHUNK_DIVISOR will require more heap space. In practice, it's not too hard to build a PoN per contig to get around this limit at the moment. We might start having issues with doing SVD on the entire matrix anyway when we have this many bins. But it might be good to have the option exposed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4365:481,expose,exposed,481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4365,1,['expose'],['exposed']
Security,"The current implementation delegates to Hadoop-BAM SAMHeaderReader.readSAMHeaderFrom, which in turn delegates to htsjdk SAMFileReader (which is deprecated). This is fragile and in a couple of cases is succeeding now only because of some existing htsjdk quirks/bugs:. -It succeeds on ADAM files only because the htsjdk code [falls through](https://github.com/broadinstitute/gatk/issues/1280) to using a SAMTextReader on the ADAM stream, which surprisingly doesn't throw but returns a completely bogus header.; -It succeeds on CRAM files even though no reference is passed because the htsjdk code currently creates a default reference with nothing backing it in that case. Since we're never using this reader to access reads, this works now, but this will throw if we take [this htsjdk PR](https://github.com/samtools/htsjdk/pull/400) which enforces passing a valid reference to CRAMReaders. More generally, I think we need to reconcile the need to have a SAMFileHeader with the desire to have alternate read stores, and decide of delegating to Hadoop-BAM is sufficient here.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1346:710,access,access,710,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1346,1,['access'],['access']
Security,The default jar is taken to be the one bundled with the Docker in the CNV WDLs but is an exposed argument in the M2 WDLs.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4072:89,expose,exposed,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4072,1,['expose'],['exposed']
Security,"The fact that `ReadCoordinateComparator` does not exactly match the ordering of htsjdk's `SAMRecordCoordinateComparator` has been the cause of a few bugs. It sorts all unmapped reads after mapped reads, whereas `SAMRecordCoordinateComparator` sorts unmapped reads that are assigned the positions of their mapped mates with their mapped mates. The issue is that the `GATKRead` interface does not allow unmapped reads to have a position. Ie., even if an unmapped `SAMRecord` is assigned the position of its mapped mate, calling `getContig()`/`getStart()` on the unmapped read via the `GATKRead` interface will return `null`/`0`. This was done mainly for consistency reasons and to simplify client code. Perhaps we could add `getAssignedContig()`, `getAssignedStart()`, etc. methods to GATKRead to expose the positions that unmapped reads with mapped mates get assigned for sorting purposes, and use these in `ReadCoordinateComparator`. This should allow us to match `SAMRecordCoordinateComparator` exactly, and then `ReadCoordinateComparator` could be used even when sorting for the purpose of writing a bam.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1911:795,expose,expose,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1911,1,['expose'],['expose']
Security,"The failing test is unrelated to this branch, and I have secured permission to merge. Here we go. . .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1553213661:57,secur,secured,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1553213661,1,['secur'],['secured']
Security,"The git hash refers to the commit of GATK you have checked out in your branch as opposed to the commit of GATK that has been built in Java (and will be run on the cluster). I will clarify the error message: it means that you need to rebuild GATK to match your changes to the repository. The malformed object name is a different story, and seems like a bug. I will try to figure that out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394:8,hash,hash,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394,1,['hash'],['hash']
Security,"The idea is that this WDL will run all the checks for each release of the VAT table, one call for each validation. The first validation rule (""Validation Check confirms that data is put into the VAT table after completing without an error."") is included as a model for subsequent calls. - workflow should succeed if it's able to try all tests; - workflow output `validation_results` will contain details of each test result in an array of `{""testName"": ""result details""}`:; Example 1 — [fail](https://job-manager.dsde-prod.broadinstitute.org/jobs/2728b55b-5344-492a-951a-48fd416e9d0d); `{ ""EnsureVatTableHasVariants"": ""FAIL: The VAT table spec-ops-aou.rsa_gvs_quickstart.rsa_scratch has no variants in it."" }`; Example 2 — [pass](https://job-manager.dsde-prod.broadinstitute.org/jobs/83e3bd5a-9144-452e-93d9-9f273055177f); `{ ""EnsureVatTableHasVariants"": ""PASS: The VAT table spec-ops-aou.anvil_100_for_testing.aou_shard_223_vat has 294821 variants in it."" },`; Example 3 — [the test wasn't able to run](https://job-manager.dsde-prod.broadinstitute.org/jobs/7179d111-02aa-4bca-a0a0-f55e10e43791); `{ ""EnsureVatTableHasVariants"": ""Something went wrong. The attempt to count the variants returned: Error in query string: Error processing job 'spec-ops- aou:bqjob_r357c4b6fe6b0c6fb_0000017aac301de7_1': Unrecognized name: vid at [1:24]"" }`. Closes https://github.com/broadinstitute/dsp-spec-ops/issues/364",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7352:103,validat,validation,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7352,3,"['Validat', 'validat']","['Validation', 'validation']"
Security,"The idea of putting more help into the command line tools seems like a good one. We don't really have global ""man pages"" maybe we should have some that are accessible directly through the CLI describing important concepts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6639#issuecomment-656182276:156,access,accessible,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6639#issuecomment-656182276,1,['access'],['accessible']
Security,"The issue is that only the linked list version of hash sets/maps has a predictable iteration order. So, any algorithm that is order dependent may get different results between different Java versions. The only downside is the linked list will take up some additional storage.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1844#issuecomment-220625823:50,hash,hash,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1844#issuecomment-220625823,1,['hash'],['hash']
Security,"The issue with the tests is that this PR is from a fork so the tests don't have access to the permissions we need for BigQuery in the variantstore WDL tests. I need to fix this for the future (by making sure those tests don't run when the PR is from a fork), but I don't think that test failure should block this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6872#issuecomment-710041086:80,access,access,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6872#issuecomment-710041086,1,['access'],['access']
Security,The jenkins spark tests are failing with the following error:. This seems to have been introduced in https://github.com/broadinstitute/gatk/pull/3576. ```; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:339); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:91); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:194); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:346); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:162); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:118); 	at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:87); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:182); 	at org.broadinstitute.hellbender.engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591:203,secur,security,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591,4,"['access', 'secur']","['access', 'security']"
Security,"The latest code in htsjdk, which includes https://github.com/samtools/htsjdk/pull/1454 (changes the Allele class into an interface, and uses SimpleAllele as the concrete implementation) causes the `VariantAnnotatorEngineUnitTest.testCombineAnnotations` test to fail because the order of the list returned by `ReducibleAnnotationData.getAlleles` is different with that change than it is without it (presumably due to the different hashCode/equals implementations). `AS_RMSMappingQuality.parseRawData` seems to assume that the order of the Alleles in the list returned by ; `ReducibleAnnotationData.getAlleles` exactly matches the order of the raw data in the String returned by `ReducibleAnnotationData.getRawData`, since it uses indexed access to the list, but I don't see anything that states or ensures/enforces this. Changing the Map maintained by `ReducibleAnnotationData` into a LinkedHashMap fixes the issue for this test, but that just changes the order to be input order - the real issue is that the contract around how the order of the list and the order of the raw data is maintained isn't clear. This will need to be addressed before we can upgrade to the next release of htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7586:430,hash,hashCode,430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7586,2,"['access', 'hash']","['access', 'hashCode']"
Security,"The local assembly step currently in SV pipeline also uses RDD cacheing (`validateAndSaveResults` of `RunSGAViaProcessBuilderOnSpark.java`), so this would help.; Thanks, @akiezun and Lucy",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1811#issuecomment-223135473:74,validat,validateAndSaveResults,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1811#issuecomment-223135473,1,['validat'],['validateAndSaveResults']
Security,"The manifest file describes the files produced by the GvsExtractCallset task and is uploaded to GCS once all the shards have finished running. The existence of the manifest.txt file can be used to determine if the extraction is complete or not by just using `gsutil` command and not going through Cromwell/Terra. Here's a snippet of what that looks like. ```; interval_number, vcf_file_location, vcf_file_bytes, vcf_index_location, vcf_index_bytes; 0,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_0.vcf.gz,879403,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_0.vcf.gz.tbi,1682; 1,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_1.vcf.gz,871855,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_1.vcf.gz.tbi,1670; 2,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_2.vcf.gz,710617,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_2.vcf.gz.tbi,1629; 3,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_3.vcf.gz,715565,gs://fc-secure-765db3ba-3e2d-432e-89eb-9efda7430f93/genomic-extractions/66f225d3-35cf-4ff7-a4ec-3d887a86ea8b/vcfs/interval_3.vcf.gz.tbi,1645; ...; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7457:459,secur,secure-,459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7457,8,['secur'],['secure-']
Security,The name for the `variantContext` (as accessed by `getSource()`) is never populated properly. It needs to be populated in the codec. This field should be populated when the codec is created in `FeatureDataSource::getCodecForFeatureInput`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4570:38,access,accessed,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4570,1,['access'],['accessed']
Security,"The new pipeline is in a complete state. Nearly all tools and scripts were rewritten, many from scratch. I've tried to minimize interaction with old `tools/exome` code (notably, `ReadCountCollection` and `SegmentUtils`). There are still some improvements that can be made (especially in segment union and the subsequent modeling), but we should be ready to go for a first validation. Some notes:. WDL:; - I've moved the old pipeline to `somatic_old` folders.; - There is now just a matched-pair workflow and a panel workflow. We can add a single BAM case workflow or expand the matched-pair workflow to handle this, depending on the discussion at https://github.com/broadinstitute/gatk/issues/3657.; - WES/WGS is toggled by providing an optional target-file input.; - For all workflows, we always collect integer read counts; for WGS, these are output as both HDF5 and TSV and the HDF5 is used for subsequent input.; - For the case workflow, we always collect allelic counts at all sites and output as TSV.; - [x] We should output all data files as HDF5 by default and as TSV optionally. EDIT: This is done for `CollectFragmentCounts`.; - [x] We will need to update the workflows when @MartonKN and @asmirnov239 get `PreprocessIntervals` and `CollectReadCounts` merged, respectively. These tools will remove the awkwardness required by `PadTargets` and `CalculateTargetCoverage`/`SparkGenomeReadCounts`. Denoising:; - All parameters are exposed in the PoN creation tool (#3356).; - Without a PoN, standardization and optional GC correction are performed (#3570).; - Other than the minor point about sample mean/median being used inconsistently noted above, the denoising process is essentially exactly the same mathematically as before (""superficial"" differences include the vastly improved memory and I/O optimizations, the ability to adjust number of principal components used, the removal of redundant SVDs, the enforcement of consistent GC-bias correction).; - [ ] That said, I'll carry over this ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:372,validat,validation,372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['validat'],['validation']
Security,The new validation tests for `ReadsPipelineSpark` should be easily runnable in either a push-button fashion or on a set automatic schedule (nightly or weekly) via a jenkins server. Depends on https://github.com/broadinstitute/gatk/issues/1400,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1401:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1401,1,['validat'],['validation']
Security,"The only parallelism exposed by GenomicsDBImport is via `max-num-intervals-to-import-in-parallel` and that is at the granularity of threads in the same process. Not sure there is any parallelism in GenotypeGVCFs. ; The granularity of parallelism that @nickhsmith seems to want is at the level of a node and @mjohnsonngi is correct. Assuming GenotypeGVCFs processes each position independently, run GenomicsDBImport followed by GenotypeGVFs per node and then use GatherVcfs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7898#issuecomment-1175552901:21,expose,exposed,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7898#issuecomment-1175552901,1,['expose'],['exposed']
Security,"The output cram is malformed because because the cram writer code in htsjdk assumes it has a reference source for the output, but in this case it doesn't. It throws an NPE when it tries to access the reference bases. We need fixes and to tighten up code in several places in both htsjdk and HB. I'll add/update tickets accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/766#issuecomment-146315547:189,access,access,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/766#issuecomment-146315547,1,['access'],['access']
Security,"The possibility that this problem could be specific to the TCGA FC BAMs did arise in our previous discussions---not sure what storage class those are on?. However, in this workflow, at most one ReadWalker (CollectReadCounts) and one LocusWalker (CollectAllelicCounts) would try to access the same (tumor) BAM. There were several instances of (normal) BAMs which only had one LocusWalker (CollectAllelicCounts) accessing them that failed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459845523:281,access,access,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459845523,2,['access'],"['access', 'accessing']"
Security,The presence of gcloud-java-nio on the classpath prevents other providers being used if the GCS provider ID has not been specified (e.g. by setting `GOOGLE_APPLICATION_CREDENTIALS`). Here's an example test case: https://github.com/broadinstitute/gatk/commit/8b217f82352ceb55d21d7a5236e879818910d9c9. and the stacktrace:. ```; java.util.ServiceConfigurationError: java.nio.file.spi.FileSystemProvider: Provider com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider could not be instantiated; at java.util.ServiceLoader.fail(ServiceLoader.java:232); at java.util.ServiceLoader.access$100(ServiceLoader.java:185); at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384); at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404); at java.util.ServiceLoader$1.next(ServiceLoader.java:480); at java.nio.file.spi.FileSystemProvider.loadInstalledProviders(FileSystemProvider.java:119); at java.nio.file.spi.FileSystemProvider.access$000(FileSystemProvider.java:77); at java.nio.file.spi.FileSystemProvider$1.run(FileSystemProvider.java:169); at java.nio.file.spi.FileSystemProvider$1.run(FileSystemProvider.java:166); at java.security.AccessController.doPrivileged(Native Method); at java.nio.file.spi.FileSystemProvider.installedProviders(FileSystemProvider.java:166); at java.nio.file.Paths.get(Paths.java:141); at org.broadinstitute.hellbender.engine.spark.datasources.NioProviderExceptionUnitTest.test(NioProviderExceptionUnitTest.java:12). Caused by:; java.lang.IllegalArgumentException: A project ID is required for this service but could not be determined from the builder or the environment. Please set a project ID using the builder.; at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:122); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:208); at com.google.cloud.HttpServiceOptions.<init>(HttpServiceOptions.java:153); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:69); at c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2110:589,access,access,589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2110,2,['access'],['access']
Security,"The problem is that the package can't download any files during build due to security reasons. It has to use predefined, repeatable set of dependencies, and can't download random versions of gradle either. It has to use the ```devel/gradle``` port, and once this port has been upgraded to version 5.0 gatk became broken. ```devel/gradle4``` had to be created. Generally, indiscriminate downloads of files lead to security problems like the one that recently happened with a particular bitcoin-related node code, which was using a zillion node dependencies. One of them got infiltrated by a criminal who eventually stole bitcoins because he managed to inject his code into financial applications running on user's sites. To prevent such things from happening, all major packaging systems only use fingerprinted dependencies, and can't ""just download"" some alternative version of something during build, contrary to what devs might be expecting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444205059:77,secur,security,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444205059,3,"['inject', 'secur']","['inject', 'security']"
Security,"The problem with a static member is that then we can only have one header for every read, ever. This will probably break computations that handle more than one bam at a time. Another potential solution is to audit every Dataflow (and spark) code that can receive SAMRecords as input, and make sure they call some utility ""putHeadersBack"" function. There aren't so many of those so it would be possible, though not super-pleasant.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-140930109:208,audit,audit,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-140930109,1,['audit'],['audit']
Security,"The pull request addresses two issues:. 1. Improved and more robust parsing of FlowBasedReads. Specifically, the code now determines the minimal reportable quality; 2. New tool AddFlowSNVQuality that allows users to convert the flow-based quality format when every base quality reports probability of an insertion or deletion to a conventional format that gives base qualities (total probability of mismatch and probability of each mismatch in separate tags). . We believe that this tool is going to be important for users of the Ultima Genomics data that care about calling SNVs, especially in somatic setting, so the goal was to make documentation more accessible. . Happy to receive feedback about it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8697:655,access,accessible,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8697,1,['access'],['accessible']
Security,The recently-added sequence dictionary validation in `BaseRecalibratorDataflow` does not work when the reference is stored in a bucket -- we should patch it so that it does.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/683:39,validat,validation,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/683,1,['validat'],['validation']
Security,"The result of this bug is that if you produce a BAM with Spark, then produce a different BAM with the same name with the walker-framework, then try to read _that_ bam with Spark, it produces checksum (and other more misleading) errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1266:191,checksum,checksum,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1266,1,['checksum'],['checksum']
Security,"The same error was reported in other modules of GATK4. For eacmple, in GenomicsDBimport [Ref.1]. And I encountered it again when I check the bams with ValidateSamFile. [1] https://gatk.broadinstitute.org/hc/en-us/community/posts/360076477211-GenomicsDBimport-not-importing-all-the-batches?page=1#community_comment_4411519756827",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7582#issuecomment-991512945:151,Validat,ValidateSamFile,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7582#issuecomment-991512945,1,['Validat'],['ValidateSamFile']
Security,"The snapshot builds get published to an artifact repository, but I don't think those are accessible from outside of Broad. The build from this morning with your branch is [here](https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot-local/org/broadinstitute/gatk/4.0.11.0-30-g9c4a27b-SNAPSHOT/) if you can access it. Otherwise, for local development, you can do the following:. - pull gatk master from today so it includes your commit; - run `git fetch --tags` (this is optional but it will give your local build a more reasonable version tag); - run `./gradlew install printVersion` to install the locally built gatk into your local machine's maven repository; - change your VariantQC gradle project to include the `maven` gradle plugin if its not already there; - add `mavenLocal()` to your projects' `repositories `closure; - change your gatk dependency to the version number printed out by 'printVersion'; - rebuild VariantQC. Having said all that, what code are you dependent on ? I expect the command line interface to VariantEval, and the VariantUtils and StratificationManager and friends classes all to undergo some refactoring and evolve a bit before the tool has the beta tag removed and the interfaces are stabilized. See https://github.com/broadinstitute/gatk/issues/5439 and https://github.com/broadinstitute/gatk/issues/5440.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440782148:89,access,accessible,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440782148,2,['access'],"['access', 'accessible']"
Security,"The table names in GvsAssignId were not quoted with backticks, which is fine **except** if your dataset name starts with a number… which is a total valid identifier, but requires quoting. . Recently we had a customer (AoU) supply a dataset with the name `1kg_wgs` which exposed this problem",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7666:270,expose,exposed,270,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7666,1,['expose'],['exposed']
Security,"The task here is to simply move the code while changing as little as possible, and then validate that. Once that's done, we can do whatever refactoring/changes we want to VQSR, or replace it completely.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236014525:88,validat,validate,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236014525,1,['validat'],['validate']
Security,"The tool-specific WDLs we generate in https://github.com/broadinstitute/gatk-tool-wdls don't have the `localization_optional` parameter turned on for args that support cloud access (ie., arguments of type GATKPath), and so always localize.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7094:174,access,access,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7094,1,['access'],['access']
Security,"There are a number of GATK code paths that check to ensure that a reference is provided whenever a CRAM input is provided. Since htsjdk now accepts both embedded reference and reference-less (no reference compression) CRAMs, these checks should be removed once we update htsjdk. The CRAM code will defer accessing the reference until one is actually required, and will fail gracefully in the case where it is not provided.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6541:304,access,accessing,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6541,1,['access'],['accessing']
Security,"There are currently two failing tests, both of which need fixes in htsjdk.; * CountVariantsSparkIntegrationTest. This is a concurrency issue where VCFCodec (which isn't threadsafe) is being shared by multiple tasks in each Spark executor. The fix is for each task (partition) to have its own VCFCodec. This needs a couple of small changes in htsjdk to make it possible to access the codec's version and header fields so the codec can be recreated. See https://github.com/samtools/htsjdk/pull/1176.; * CpxVariantReInterpreterSparkIntegrationTest. I tracked this down to a problem with the buffer in htsjdk's SeekableBufferedStream. See https://github.com/samtools/htsjdk/pull/1175 for the fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5138#issuecomment-417241035:372,access,access,372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5138#issuecomment-417241035,1,['access'],['access']
Security,"There are params in Extract Cohort that can be tightened up. Extract Tool has two params that are not used by Extract Features and are _already_ in Extract Cohort. The filter_set_name is used in the BQ filtering tables and looks like we can set it to be completely required for any type of filtering. There are 3 BQ filter tables -- 2 are needed for filtering (no matter what?) and 1 (tranches) is needed for thresholding and sensitivity calculations?. Genotype level filtering is true by default, but this doesn't seem like it should effect things after this cleanup. Though technically it should only be true if a filter_set_name has been specified. I will add another comment in the body of the code, but I would like to add this safety gate explicitly. Disable gnarly doesn't need to be a passed in param---so we'll rip it out for now. SNP and INDEL truth sensitivity and SNP and INDEL Lod scores are cumbersome to have to worry about passing in, but I dont see a better alternative. Should there be additional validation on these (where if they are specified, but no filter_set_name is, then they throw an error?)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7293:1015,validat,validation,1015,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7293,1,['validat'],['validation']
Security,"There are quite a few v2.1 CRAM test files being used in GATK that should probably be regenerated and replaced with v3.0 files. There are also quite a few CRAM test files floating around in both htsjdk and GATK that have external blocks with content ID=0 (not valid per the spec) and some of those blocks have no actual content:. gatk/src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/expected.clippingReadsTestCRAM.QT_10.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/ClipReads/clippingReadsTestCRAM.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/print_reads.sorted.queryname.htsjdk-2.1.0.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.10m-10m100.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.bqsr.pipeline.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.noMD.noBQSR.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/expected.MultiSite.reads.pipeline.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.cram; gatk/src/test/resources/org/broadinstitute/hellbender/tools/validation/another.single.read.cram. These have external blocks with ID=0, but the blocks have no actual content:. gatk/src/test/resources/org/broadinstitute/hellbender/engine/cram_with_crai_index.cram (0 bytes); gatk/src/test/resources/org/broadinstitute/hellbender/engine/cram_with_bai_index.cram (0 bytes). We should regenerate and replace with v3.0 CRAM files.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6018:1234,validat,validation,1234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6018,2,['validat'],['validation']
Security,"There are several cases where ValidateVariants does no actual validation, and issues no warning message. This includes the default case, where the minimal set of required args is provided (these are examples from the doc, which should be updated when this is fixed): . `gatk ValidateVariants -V some.vcf`; `gatk ValidateVariants -V some.vcf -R some.fasta`. Either of these silently results in no validation and no warning message, despite the entire VCF being decoded and traversed, because the default validation type is ""ALL"", which includes validation type ""IDS"". But IDS requires a dbsnp arg, and none was provided, so the code short-circuits out. The default case should probably do whatever validation it can, but at a minimum a warning should be logged. Ironically, if you provide an exclusion on the command line via `--validation-type-to-exclude IDS`, then validation is done. Another no-op case is `--validation-type-to-exclude ALL` (also recommended in the doc), which also should probably be rejected, or at least logged, since it silently does no validation and reports no errors. This tripped up [this user](https://github.com/samtools/htsjdk/issues/1117), and resulted in a downstream BCF issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5862:30,Validat,ValidateVariants,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862,12,"['Validat', 'validat']","['ValidateVariants', 'validation', 'validation-type-to-exclude']"
Security,"There are two differences in GATK4 relative to GATK3 that are causing bugs in the read clipping code (see #3466 and #3845):. * `GATKRead` does not allow you to set mapped reads to a negative start position or a null contig, whereas the GATK3 clipping code allowed reads to enter such states. * We return a `ReadUtils.emptyRead()` when we completely clip away a read, as opposed to (eg.,) a read with a negative start position and no bases like we did in GATK3. We should audit all usages of the `ReadClipper` (as well as direct usages of `ReadUtils.emptyRead()` itself) to make sure that all client code can handle the return value of `ReadUtils.emptyRead()`, which returns an unmapped read with no bases. I've already audited the usages in `HaplotypeCaller`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4204:471,audit,audit,471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4204,2,['audit'],"['audit', 'audited']"
Security,"There are two issues with running this on Travis:; 1. Spinning up Dataproc requires access to a bunch of secrets -- namely API Keys and Google Service accounts (usually in the form of a JSON). Travis allows for encrypted Secrets, so I'm okay with them existing there, but they are ONLY available to PRs that originate from the repo (ie, no forked PRs have access to them). So doing this in Travis would only work from your local PR. Is that acceptable? If not, no Travis that I can think of. 2. We don't want ANYONE to just come in and launch these tests as they are $ expensive (spinning up clusters in Google). If this activates with any PR that comes in, then we can easily run up a bill by any malicious A-hole who feels like launching a bunch of PRs. I know that when I was 14 or so I would have probably done that if I discovered it. Jenkins has some mechnaisms to prevent run away PR tests. Does Travis? I didn't find any info on that... Happy to hash it out in a room (and sorry it took this long to get to. Pester Banks if you need my attention faster otherwise Workbench and Security get first dibs). But be aware of these issues with Travis and running dataproc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287539859:84,access,access,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287539859,5,"['Secur', 'access', 'encrypt', 'hash']","['Security', 'access', 'encrypted', 'hash']"
Security,"There currently is no way to access files in a GCS bucket that is not public. I will need this feature in the near future to analyze sensitive data. . Just discussed this with @lbergelson, and it sounds like this is something that is not a ton of work but has just been on the back-burner for a while.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394:29,access,access,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394,1,['access'],['access']
Security,"There is a pattern for abstracting these out, and even hiding them, but its intrusive and probably way overkill for this (see for example how `getSequenceDictionaryValidationArgumentCollection` is used). Also see `customCommandLineValidation` which can similarly be used for command line arg validation. Another option is to use a subclass constructor that resets the defaults, and logs a warning if you clobber a user value. The worst way is to do what AlleleFrequencyQC does in onTraversalStart, which just silently clobbers...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7287#issuecomment-853371556:292,validat,validation,292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7287#issuecomment-853371556,1,['validat'],['validation']
Security,"There is an [Apache2 version of BWA](https://github.com/lh3/bwa/tree/Apache2). The `bwa index` is slower than the GPL'd bwa, but the rest is the same. @lindenb For now, bwa-mem only exposes APIs for single-end mapping. That part of API stays the same (or almost the same). Your java binding should still work. There is a non-public version of bwa that also exposes paired-end mapping and more internals, but that version has duplicated code – that is why I have not made it public.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1517#issuecomment-198166846:182,expose,exposes,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1517#issuecomment-198166846,2,['expose'],['exposes']
Security,"There is currently a disabled test in `PrintReadsIntegrationTest` for which a query on a crai-indexed cram file returns the wrong result (we get the correct result with an equivalent bam):. ```; // The below test case is currently disabled due to an apparent bug in which the cram reader returns the unmapped read ""f""; // in this query, even though it has its mapped mate's position, and this position is outside the query intervals.; // This bug is being tracked here: https://github.com/broadinstitute/gatk/issues/1673; // { ceuSnippetCram, b37_reference_20_21, Arrays.asList(""20:10000009-10000011"", ""unmapped""), Arrays.asList(""a"", ""b"", ""c"", ""d"", ""e"", ""g"", ""h"", ""h"", ""i"", ""i"") },; ```. This appears to be a bug at the htsjdk level, as it can be reproduced by instantiating a `SamReader` directly:. ```; @Test; public void testBug() throws IOException {; final File ceuSnippetCram = new File(publicTestDir + ""org/broadinstitute/hellbender/engine/CEUTrio.HiSeq.WGS.b37.NA12878.snippet_with_unmapped.cram"");; final SimpleInterval interval = new SimpleInterval(""20"", 10000009, 10000011);; SamReaderFactory factory = SamReaderFactory.makeDefault().validationStringency(ValidationStringency.SILENT);; factory.referenceSequence(new File(b37_reference_20_21));. try ( final SamReader reader = factory.open(ceuSnippetCram) ) {; final Iterator<SAMRecord> iter = reader.queryOverlapping(new QueryInterval[]{IntervalUtils.convertSimpleIntervalToQueryInterval(interval, reader.getFileHeader().getSequenceDictionary())});; while ( iter.hasNext() ) {; final SAMRecord read = iter.next();; Assert.assertNotEquals(read.getReadName(), ""f"");; }; }; }; ```. Task is to look into this and get a sense of where the problem is, then file an htsjdk bug if appropriate. GATK 3.5 `PrintReads` does not have this problem with the same input, but it uses a completely different code path to query crams.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1673#issuecomment-203658956:1145,validat,validationStringency,1145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1673#issuecomment-203658956,2,"['Validat', 'validat']","['ValidationStringency', 'validationStringency']"
Security,There is one test in ValidateSamFileIntegrationTest that is commented out since it depends on a change to htsjdk.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1084:21,Validat,ValidateSamFileIntegrationTest,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1084,1,['Validat'],['ValidateSamFileIntegrationTest']
Security,"There is some confusing code in MarkDuplicatesSpark for comparison, some of which will cause inherent differences with picard Mark Duplicates. Some time should be set aside to ensure it is all performing correctly and that the differences are justified during validation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4707:260,validat,validation,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4707,1,['validat'],['validation']
Security,"There may be a general need to allow tools to request additional context around the current locus/interval. This currently is implemented for `ReferenceContext` via `setWindow()`, but could be expanded to the other *Context classes as well. . Note, however, that we should not encourage tools to perform arbitrary queries as a general rule, since it would be difficult or impossible to optimize a traversal in which the access pattern is random. If a tool needs to group disparate data items together (eg., mates on different contigs), there should be an initial grouping step to prepare the required data for the main analysis, instead of random queries within the main analysis.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/245:420,access,access,420,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/245,1,['access'],['access']
Security,There needs to be a validation tool for data sources to ensure that they conform to their formats properly. This tool is envisioned to be run just prior to data source release to fix any silent errors.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4380:20,validat,validation,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380,1,['validat'],['validation']
Security,"There should be a robust mechanism to check whether an index file is up-to-date with respect to the file it indexes (eg., UUIDs, hashes, etc.). Modification time alone is not sufficient, since files can get uploaded out-of-order in cloud environments.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5571:129,hash,hashes,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5571,1,['hash'],['hashes']
Security,"There should be an option to inform the user when reads do not pass the WellFormedReadFilter. This could be by logging the number of reads failing this filter or exploding (user-specified). Ideally, it would also report which part of the filter they failed. There are a lot of simple ""gotchas"" that can cause reads to fail, like not adding read groups with sample names. To a lay user, this could be very frustrating. In Spark tools that perform their own additional filtering, it can be impossible to tell even when a substantial subset of the input is silently lost this way (very scary stuff!). A tool to detect reads that are not Wellformed (akin to ValidateSamFile) would be helpful, although not for catching bugs like #3453. @lbergelson suggested creating a WellFormedOrExplodeReadFilter, which would allow tool developers to handle this issue at their discretion. I will work on something like this because PathSeq is especially susceptible to the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3454:654,Validat,ValidateSamFile,654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454,1,['Validat'],['ValidateSamFile']
Security,"There were a few issues with this case. First, the data source was not constructed 100% correctly. The config file is correct. . The index file is for the tar.gz version of the source data and not for the uncompressed version that they're using. The index should correspond to the source data in the file referenced by the config file itself (not a zipped or otherwise transformed version). Secondly, the source `tsv` data file has the header line for the table commented out. The Xsv codec is aware of leading hash marks as comments and will ignore any such lines. Because of this, the leading hash in the table header is ignored and the file cannot be properly parsed. The fix is simple - just remove the leading hash from the table header (the preceding line with the two hash marks is correctly interpreted as a file header because of the leading hashes acting as comments). Lastly, even if the user fixed the file they would still need to index it with`IndexFeatureFile`. At some point the code underlying this in `HTSJDK` was broken such that no Xsv files can currently be indexed. I have submitted a pull request in `HTSJDK` (https://github.com/samtools/htsjdk/pull/1429) for this and have another ready to go in GATK (#6224) that includes a test for this case so this reversion cannot happen again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223#issuecomment-545186183:511,hash,hash,511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223#issuecomment-545186183,5,['hash'],"['hash', 'hashes']"
Security,"There's a small set of tools that only outputs their results to stdout, making it difficult to use the output in a pipeline/script. This PR adds a way to output simple results from such tools to an (optional) output file. I Added this option to the following tools:; - CountBases; - CountBasesInReference; - CountReads; - CountVariants; - FlagStat. Other tools that might benefit from this (but it will require an API change, so I didn't do it):; - CompareIntervalLists; - ValidateVariants",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7072:473,Validat,ValidateVariants,473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7072,1,['Validat'],['ValidateVariants']
Security,There's an issue in `VcfFuncotationFactory.createFuncotationsOnVariant` where certain cites that need multiple functotations merged produce incorrect output. The cause is an accidental conversion of LinkedHashMap -> HashMap which scrambles the iteration order of the map. The order is used when writing the fields so the names of the fields end up on different values.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6173:216,Hash,HashMap,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6173,1,['Hash'],['HashMap']
Security,There's some bad input in the BQSR test; update the input validation test to make sure it can find reads that are malformed in that way.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/557:58,validat,validation,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/557,1,['validat'],['validation']
Security,"These are failing with:. ```; Error: (converted from warning) unable to access index for repository http://lib.stat.cmu.edu/R/CRAN/src/contrib; Execution halted; The command ""if [[ $TEST_DOCKER != true ]]; then sudo mkdir -p /usr/local/lib/R/; sudo mkdir -p site-library; sudo ln -sFv ~/site-library /usr/local/lib/R/site-library; sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9; sudo add-apt-repository ""deb http://cran.rstudio.com/bin/linux/ubuntu trusty/""; sudo apt-get update; sudo apt-get install -y --force-yes r-base-dev=3.1.3-1trusty; sudo apt-get install -y --force-yes r-base-core=3.1.3-1trusty; sudo Rscript scripts/docker/gatkbase/install_R_packages.R; fi;"" failed and exited with 1 during; ```; which has nothing to do with the PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203:72,access,access,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203,1,['access'],['access']
Security,"These can almost definitely go:; CalculatePulldownPhasePosteriors; PerformAlleleFractionSegmentation; PerformCopyRatioSegmentation; PerformJointSegmentation; XHMMSegmentCaller; XHMMSegmentGenotyper. @mbabadi will touch base with Monkol, but we think these can go:; TargetCoverageSexGenotyper; GermlineCNVCaller. Not sure about these germline validation tools, let me know:; ConvertGSVariantsToSegments; EvaluateCopyNumberTriStateCalls",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3887:342,validat,validation,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3887,1,['validat'],['validation']
Security,These changes pass all tests on my system but the Travis build fails in 30 seconds - security issue?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/809#issuecomment-130674475:85,secur,security,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/809#issuecomment-130674475,1,['secur'],['security']
Security,"These downstream protected tests only need to run on each merge into master, not when a PR is opened, so that should address the security issue. (I misspoke earlier, sorry -- only the tests in https://github.com/broadinstitute/gatk/issues/2298 need to run for each PR). The goal is just to have a badge on github that lets us know whether protected is working with the current build of public/master (and it often won't be in the course of development). Workflow would be:; 1. A merge goes into GATK public/master; 2. Job grabs the HEAD of public/master, and builds and installs a snapshot into the local maven repository using `./gradlew install printVersion`; 3. Job needs to save the last line of output from `./gradlew install printVersion` in a `gatkPublicVersion` variable -- this is the version of the snapshot of public that was installed to maven local.; 4. Job checks out latest GATK protected/master and executes the command to build it and run the full test suite, but as part of that command it overrides the GATK public version to point to the snapshot version installed locally and saved in the `gatkPublicVersion` variable above. It is trivial to patch protected's `build.gradle` to add the ability to override the GATK public version when running gradle commands (we can help with this part).; 5. New github badge for ""Downstream GATK protected tests"" on the front page of the GATK public github repo gets updated with the results of step 4, and can be clicked on to view the full test output.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1758#issuecomment-287543585:129,secur,security,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1758#issuecomment-287543585,1,['secur'],['security']
Security,"Think I'd prefer to just pass in a sequence dictionary to the GenomeLoc constructor when you want validation, instead of the subclass option. This would be compatible with the isValidated() idea.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69767411:98,validat,validation,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69767411,1,['validat'],['validation']
Security,This PR Creates and exposes the `is_wgs` parameter in the GvsJointVariantCalling wdl.; It follows the rules defined in the ticket VS-1020 as to how to set `is_wgs` and the `optional interval_list` and `interval_weights_bed` inputs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8515:20,expose,exposes,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8515,1,['expose'],['exposes']
Security,"This PR addresses required changes in order to use latest version of GenomicsDB which exposes new functionality such as:; - [Multi interval import and query support](https://github.com/broadinstitute/gatk/issues/3269):; - We create multiple arrays (directories) in a single workspace - one per interval. So, if you wish to import intervals (""chr1"", [ 1, 100M ]) and (""chr2"", [ 1, 100M ]), you end up with 2 directories/arrays in the workspace with names chr1$1$100M and chr2$1$100M. The array names depend on the partition bounds.; - During the read phase, the user only supplies the workspace. The array names are obtained by scanning the entries in the workspace and reading the right arrays. For example, if you wish to read (""chr2"", [ 50, 50M] ), then only the second array is queried.; - In the previous version of the tool, the array name was a constant - _genomicsdb_array_. The new version will be backward compatible with respect to reads. Hence, if a directory named _genomicsdb_array_ is found in the workspace directory, it's passed as the array for the _GenomicsDBFeatureReader_ otherwise the array names are generated from the directory entry names.; - Parallel import based on chromosome intervals. The number of threads to use can be specified as an integer argument to the [executeImport call](https://github.com/francares/gatk/blob/fmc_GenomicsDB_parallel_import/src/main/java/org/broadinstitute/hellbender/tools/genomicsdb/GenomicsDBImport.java#L535). If no argument is specified, the number of threads is determined by Java's ForkJoinPool (typically equal to the \#cores in the system). ; - The max number of intervals to import in parallel can be controlled by the command line argument --max-num-intervals-to-import-in-parallel (default 1); - Note that increasing parallelism increases the number of FeatureReaders opened to feed data to the importer. So, if you are using _N_ threads and your batch size is _B_, you will have _N*B_ feature readers open.; - Protobuf based API fo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645:86,expose,exposes,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645,1,['expose'],['exposes']
Security,"This PR adds segments VCF writing to `PostprocessGermlineCNVCalls`. Segmentation (Viterbi) and segment quality calculation are performed by `gcnvkernel`. This PR introduces the following additional features:; - Calls and model shards are not required to be provided in sorted order anymore; - The user can specify the ref copy-number state for autosomal contigs, as well as allosomal contigs; - For both intervals and segments VCF output: now we use either `<DUP>` or `<DEL>` alleles (in place of `CN_x` alleles), depending on whether the most likely copy-number call is below or above the ; contig baseline. The contig baseline state is whatever the user has specified for autosomal contigs, and the contig ploidy state on sex chromosomes (from the output of `DetermineGermlineContigPloidy`).; - Fail-fast validations and better test coverage; - Updated cohort and case WDL scripts and WDL tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4396:807,validat,validations,807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4396,1,['validat'],['validations']
Security,"This PR does most of the work for VS-565. It exposes the interval list and the sample list to whole way up the nested WDLs to GvsJointVariantCallng.wdl. Two minor things of note:; 1. sample_name_list is a File option and not a File because it's only computed inside of a branch of GvsExtractCallset where control_samples is false. If there is other behavior we want in the condition where it isn't computed, just let me know. This isn't an issue when it's run inside of GvsJointVariantCalling for the beta workflow though, and making it work there was the ultimate purpose of the ticket. 2. This PR does not fully complete the ticket. It will also require changes to the actual beta work space to add the necessary columns to the data table sample_set and change the outputs for the GvsJointVariantCalling workflow to map the new outputs to those columns. I have made these changes and test thems in my copy of the beta workflow, and can make the required changes in the one in gvs-prod once this PR is verified and merged.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8010:45,expose,exposes,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8010,1,['expose'],['exposes']
Security,"This PR is an attempt at improving SelectVariants by. - Rewriting unclear code;; - Adding documentation where needed; and; - Adding tests. The initial motivation for this code change (#7497) was to improve performance of SelectVariants by adding an option to do the ""INFO-level filtering"" before doing ""genotype filtering."" Our assumption was that this would improve performance because then we would avoid the expensive genotype ""fully-decode"" operation, which turns string format fields into appropriate object/types (int, array, etc.). This is (we think) done in `VariantContext.fullyDecode().`. This turned out not to be possible for the following reasons. First, there are roughly four types of genotype subsetting you could do:. a) By the sample names (`--sample-name NA12878`); b) JEXL (`--select GQ > 0`); c) JEXL by accessing the variant context object (`--select vc.getGenotype('NA12878').getGQ() > 1`); d) Others (e.g. `--remove-fraction-genotype`). a) does not need ""fully-decode."" It turns out b) was never supported (GATK currently removes all variants and succeed.) And from my experiments, c) does not seem to ever trigger calling `VariantContext.fullyDecode().` In fact the only code path I can see that calls fullyDecode() is by setting the `fully-decode` SelectVariants argument, which seems to just call fullyDecode at the beginning just for the sake of calling it (or so it appears to me. The utility of this command line argument is highly dubious.) . It's possible that apache code does something similar to fully decoding that could affect performance. All that is to say that we cannot achieve performance improvement with our original blueprint simply because this expensive ""fullyDecode"" operation seems to be a mythical operation that is never used in reality. So while I could not speed up SelectVariants, I cleaned up the code and added the following new arguments:. * `--select-genotype`: with this new genotype-specific JEXL argument, we support filtering by genotype f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8092:825,access,accessing,825,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8092,1,['access'],['accessing']
Security,"This PR only has a subset of the tools, but I wanted put something out there quickly to get comments and make sure I'm on the right track.; - Created tools.picard subpackage.; - Extend CommandLineProgram with PicardCommandLineProgram.; - Ported the following CLPs, with tests and small test files from Picard:; - AddCommentsToBam; - CleanSam; - CreateSequenceDictionary; - FastqToSam; - MergeBamAlignment; - RevertSam; - SamFormatConverter; - SamToFastq; - ValidateSamFile. Some notes:; - doWork() returns null for most CLPs. The exception is ValidateSam; in Picard, it returns a meaningful exit code (0 if input SAM is valid, 1 if not). Various unit tests were relying on this behavior. For now, I preserved it by returning a boolean.; - MergeBamAlignment actually involves a fair amount of logic, a la MarkDuplicates. It combines an aligned BAM with an unmapped BAM. Its helper classes have been placed in utils.sam.mergealignment. More information can be found there.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/124:457,Validat,ValidateSamFile,457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/124,2,['Validat'],"['ValidateSam', 'ValidateSamFile']"
Security,"This PR primarily fixes a bug in the hashCode method of BreakpointAllele that was causing Spark's groupByKey() method to not group identical inversion events together, resulting in duplicate variant calls in the output VCF. . All changes:; - Fix hashCode of BreakpointAllele to use the ordinal of the InversionType enum, which is consistent across executors; - Added Kryo Serializers to several SV classes; - Made the INSERTED_SEQUENCE_MAPPINGS VCF annotation include the assembly id and contig name for each mapping, which is necessary to read them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2168:37,hash,hashCode,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2168,2,['hash'],['hashCode']
Security,"This addresses issue 569 - the cleanup of format errors in bam and sam files in tests. I will send an archive with a README, validations for the post-modification bams and sams, and diffs for the bams to akiezun.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/809:125,validat,validations,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/809,1,['validat'],['validations']
Security,"This adds a new folder for large runtime resources to git-lfs. Unlike the large test resources, which are only accessed via a volume mount when tests are run on the Docker image, the runtime resources need to be accessible to the GATK build during the Docker build process, since they're included in the jar. AFAICT there is no `docker build` equivalent to `docker run -v`. So for now the runtime resources are git pulled into the Docker staging area, and thus onto the Docker image. We need this for @lucidtronix 's CNN branch (and possibly for @TedBrookings) if we're going to load models for resources, but longer term, we need a better solution.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4530:111,access,accessed,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4530,2,['access'],"['accessed', 'accessible']"
Security,This authenticates us to dockerhub on travis builds that require docker.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7204:5,authenticat,authenticates,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7204,1,['authenticat'],['authenticates']
Security,"This class was created to provided for a need to keep a sorted (by location) set of targets. However there is nothing in it that could not really be applied to any locatable in general. . As a matter of fact now I find myself in a situation in where I need the same functionality for a different subclass of Locatables, TargetCollection (and its implementations) have the functionality I need but using TargetCollection looks ugly due to its name and its methods names. The task is the to rename TargetCollection<T> to LocatableCollection<L> and accordingly replace 'target' in methods names for something else (either locatable or a generic name such 'elements'). . Also I recently noticed the existence of IntervalsSkipList which could be an additional implementation for TargetCollection (or rather the new LocatableCollection). So perhaps as part of this task we could unified the skip-list and the hash based solutions under a single common interface.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1538:903,hash,hash,903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1538,1,['hash'],['hash']
Security,"This code (building off of Louis' fixes) adds the following:; - AuthHolder, a replacement for the PipelineOptions. It stores the authentication info we need for GCS and supports both API_KEY and client-secrets.json. I adapted a few classes to accept an AuthHolder.; - BaseRecalibratorOptimizedSpark, a port of the ""shard"" approach I first did on the Dataflow side. Note that currently this code only performs reasonably for small inputs if you specify -L on the command line (for large inputs it doesn't matter).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/987:129,authenticat,authentication,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987,1,['authenticat'],['authentication']
Security,"This consists almost entirely of using `Utils.nonNull` and `Utils.validateArg` in code ported from GATK 3. There are less trivial but straightforward simplifications of code in `MathUtils` and `ReadLikelihoods`. @droazen and @lbergelson is one of you willing to review this mind-numbing PR, or suggest a victim? It should be quick.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1979:66,validat,validateArg,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1979,1,['validat'],['validateArg']
Security,"This constant controls both the maximum number of retries and the maximum number of reopens the GCS NIO library will perform in the face of transient errors. It's currently hardcoded, but should be exposed as an engine argument.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3315:198,expose,exposed,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3315,1,['expose'],['exposed']
Security,This epic is to track work on porting and validating VQSR for alpha-3. Feel free to add related tickets to the epic.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2062:42,validat,validating,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2062,1,['validat'],['validating']
Security,"This error does not occur with every VCF but at least with the one enclosed below. It passes vcf-validator with default arguments. . To reproduce: . ```; term1$ spark-shell # start you spark local cluster in another screen; ...; term2$ cd /dsde/working/valentin/bugs/gatk-var-walker-ser; term2$ git checkout 58cb99ec ; term2$ ./gradlew sparkJar; term2$ ./gatk-launch ExampleVariantWalkerSpark -V ./in.vcf.gz -- --sparkRunner SPARK --sparkMaster local. ```. ```; The stacktrace starts with:. 17/03/29 16:44:56 INFO SparkContext: Successfully stopped SparkContext; 16:44:56.000 INFO ExampleVariantWalkerSpark - Shutting down engine; [March 29, 2017 4:44:56 PM EDT] org.broadinstitute.hellbender.tools.examples.ExampleVariantWalkerSpark done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=576192512; java.lang.IllegalArgumentException: requirement failed: The partition coalescer passed in must be serializable.; 	at scala.Predef$.require(Predef.scala:224); 	at org.apache.spark.rdd.CoalescedRDD.<init>(CoalescedRDD.scala:84); 	at org.apache.spark.rdd.RDD$$anonfun$coalesce$1.apply(RDD.scala:466); 	at org.apache.spark.rdd.RDD$$anonfun$coalesce$1.apply(RDD.scala:445); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.coalesce(RDD.scala:445); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.coalesce(SparkSharder.java:321); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.joinOverlapping(SparkSharder.java:189); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.joinOverlapping(SparkSharder.java:126); 	at org.broadinstitute.hellbender.engine.spark.SparkSharder.shard(SparkSharder.java:99); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpark.getVariants(VariantWalkerSpark.java:129); 	at org.broadinstitute.hellbender.engine.spark.VariantWalkerSpa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545:97,validat,validator,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545,1,['validat'],['validator']
Security,"This happens whenever the start position of an interval for which intermediate bands must be created is less than the value `of break-bands-at-multiples-of`. For example, an input reference block record with a `start` position (say 1) that is less than the value of `of break-bands-at-multiples-of` (say 10000) would result in the invalid intermediate band interval:; ```; java.lang.IllegalArgumentException: Invalid interval. Contig:chr21 start:-1 end:-1. 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.createIntermediateVariants(CombineGVCFs.java:191); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.apply(CombineGVCFs.java:134). ```; This doesn't happen in GATK3.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4672:503,validat,validateArg,503,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4672,2,['validat'],"['validateArg', 'validatePositions']"
Security,This has exposed a dumb bug in our tests. It turns out we rely on the exact output of VariantContext.toString() Will fix. https://storage.googleapis.com/hellbender-test-logs/build_reports/lb_update_to_htsjdk_2.14.2_17106.2/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723:9,expose,exposed,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723,1,['expose'],['exposed']
Security,"This includes:; * the GQ0 --> no call conversion; * the setting of the max ref block size (already 1000, but need to let the VDS know). Bonus:; a validation script for the VDS itself. <img width=""851"" alt=""valid"" src=""https://user-images.githubusercontent.com/6863459/220472873-184c7c51-7b1b-41e7-abca-55d05293e590.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8205:146,validat,validation,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8205,1,['validat'],['validation']
Security,"This is a different sample/locus, but same issue:; `java -jar $GATKjar HaplotypeCaller --emit-ref-confidence GVCF --gvcf-gq-bands 10 --gvcf-gq-bands 20 --gvcf-gq-bands 30 --gvcf-gq-bands 40 --gvcf-gq-bands 50 --gvcf-gq-bands 60 --gvcf-gq-bands 70 --gvcf-gq-bands 80 --gvcf-gq-bands 90 --contamination-fraction-to-filter 0.011583226666666667 -L gs://broad-gotc-dev-cromwell-execution/ExomeGermlineSingleSample/873ad750-62ac-41a1-857a-a9388ad23392/call-BamToGvcf/BamToGvcf/c6c55d1d-7f26-4816-b268-10acfe409083/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/41scattered.interval_list -I gs://broad-gotc-dev-cromwell-execution/ExomeGermlineSingleSample/873ad750-62ac-41a1-857a-a9388ad23392/call-UnmappedBamToAlignedBam/UnmappedBamToAlignedBam/3945800d-4668-41b0-9eb0-602c2bf9b209/call-GatherBamFiles/NA12878.bam -G StandardAnnotation -G AS_StandardAnnotaiton -new-qual`; where GATKjar is 4.0.10.1 in my case. My problematic output is:; `chr6 149638730 . G GTTT,<NON_REF> 0.13 . AS_RAW_BaseQRankSum=||;AS_RAW_MQ=0.00|0.00|0.00;AS_RAW_MQRankSum=||;AS_RAW_ReadPosRankSum=||;AS_SB_TABLE=0,0|0,0|0,0;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.500,0.00 GT:AD:DP:GQ:PL:SB 1/1:0,0,0:0:3:19,3,0,19,3,19:0,0,0,0`; which is missing DP, QD, and RAW_MQandDP. Let me know if you don't have access to the gotc-dev bucket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-447350938:1280,access,access,1280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-447350938,1,['access'],['access']
Security,"This is a prototype of the basic infrastructure that must go in to make the junction tree based Haplotype finding work. I have pulled out a toggle for the HaplotypeCaller that that enables a separate ReadThreadingAssembler codepath for haplotype finding. Right now when this mode is enabled `ExperimentalReadThreadingAssembler` is used in conjunction with `JuncitonTreeKBestHalotypeFinder` to extract only haplotypes that show up in our junction trees with evidence of > 3 reads. This still poses problems with dangling end recovery as definitionally those branches never include complete junction tree data. . I will continue to work on this branch (as it is in a somewhat rough state still) but I would like to at least get some eyes on it before i get too deep in the weeds to at least validate the structural approach I have chosen. . Currently known issues in this branch: ; - Tests are failing due to resolution of non-unique reference sink vertexes, I would solicit help as to how best to resolve the case where junction trees point to both a reference stop allele and a continued path.; - There is at least one very degenerate edge case that might cause the code to hang, I would also ask after what is the best way to close out of looping assembly structures that never have reads to close them (i.e. a ""dangling end"" hom-var that happens to point to a non-unique reference base). ; - Probably after discussion the threshold for discarding junction trees will be changed to instead use paths from the discarded tree first. . Resolves #5925",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6034:789,validat,validate,789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6034,1,['validat'],['validate']
Security,"This is an implementation of a pileup validation tool. Additionally, some testing utilities for creating reads with variants have been added.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3755:38,validat,validation,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3755,1,['validat'],['validation']
Security,"This is done except for the remaining SortSamIntegration test issue exposed by the outputExtension fix, which is now covered by #1259.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1141#issuecomment-162520079:68,expose,exposed,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1141#issuecomment-162520079,1,['expose'],['exposed']
Security,This is exactly the sort of nightmare bug we get every java update. Just 1 isn't bad at all. I'm surprised replacing all the hashsets didn't work. It could come down to inadequate tiebreaking in a sort which falls back to identityHash. We saw that in a different bug recently. I'll take a look.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532701834:125,hash,hashsets,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532701834,1,['hash'],['hashsets']
Security,"This is meant as a group discussion that could happen several places, and here is as good as any. We know that shipping around the header is has a _huge_ cost. So, we need to find a way to effectively strip it from the `SAMRecord` without breaking it. I propose the following.; - Modify `SAMRecord` to use getter methods for the header; - Create a `HeaderSAMRecord` that extends `SAMRecord` and that has a static field for the header. This class would override `getHeader` to return the static; - Use `Broadcast` with `mapPartitions` to set the static on each worker. An alternative would be audit the field usage and do a combination of performing all necessary calls that require the header to when we load the reads and, if possible, making the still offending methods inaccessible. So, @tomwhite , @akiezun , @droazen , @lbergelson , @jean-philippe-martin , what do you all think?. I know @lbergelson previous expressed he didn't like the usage of statics for this purpose.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900:592,audit,audit,592,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900,1,['audit'],['audit']
Security,This is often needed since the docker image is big. Expose this parameter with a 20GB value,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3566:52,Expose,Expose,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3566,1,['Expose'],['Expose']
Security,This is ready for review. I'm creating/updating tickets for the remaining tools that have issues. There are also a couple of cases where there are tests commented out because they need fixes in htsjdk (GatherBamFiles and ValidateSAMFile at least - the fixes are all in PR https://github.com/samtools/htsjdk/pull/368) and I'll make tickets to reflect those as well.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1084#issuecomment-157490326:221,Validat,ValidateSAMFile,221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1084#issuecomment-157490326,1,['Validat'],['ValidateSAMFile']
Security,"This is rebased off of https://github.com/broadinstitute/gatk/pull/3716, since it depends on code there. Hence, only the second commit needs to be reviewed in this PR. The code and tests are quite similar to that for PlotSegmentedCopyRatio/PlotACNVResults. However, I've changed the R scripts to be more efficient (WGS plots no longer take several hours). Furthermore, PlotModeledSegments is more flexible than PlotACNVResults in that it plots CR, AF, or both on the fly depending on the available inputs. I've also added some more input validation, changed some terminology, and moved over to data.table for reading TSVs in R.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3729:538,validat,validation,538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3729,1,['validat'],['validation']
Security,This is required for some validation work we're currently doing.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1089:26,validat,validation,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1089,1,['validat'],['validation']
Security,"This is solved, since we now have the ability to disable sequence dictionary validation at the engine level!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/690#issuecomment-169136850:77,validat,validation,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/690#issuecomment-169136850,1,['validat'],['validation']
Security,"This is something we got to only in a rather basic way in GATK but is very useful to enable in order to save users from themselves. This would involve three components:. 1) Hard min/max values that correspond to limits beyond which values could cause errors/program failures; violation should throw a User Exception;. 2) Recommended min/max values that correspond to limits beyond which values do not make sense for a given analysis functionality for standard use cases; violation should log a WARN entry. 3) Behavior-disabling value if applicable. Let's say we have an argument that provides a threshold for filtering; and it takes min. 4, max. 20. We may want to set it up so that passing -1 disables the behavior controlled by the argument (so in the filtering case, ""-1"" means ""don't filter at all"") without tripping the min value check. . These should all be accessible to the GATKDoclet (or equivalent) for documentation purposes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/143:864,access,accessible,864,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143,1,['access'],['accessible']
Security,"This is the issue I was talking about the other day in our collaboration meeting. The file system is determined by the spark environment. In the direct runner it ends up being a `LocalFileSystem`. If you run using the SUBMIT runner on your own computer you'll likely also get a `LocalFileSystem`, if you run with SUBMIT on dataflow01 you'll be able to read hdfs, but unable to access `file://` and all paths will be silently translated to hdfs paths if file:// is specified..",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1324#issuecomment-163383360:377,access,access,377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1324#issuecomment-163383360,1,['access'],['access']
Security,This looks like a bug. I'm not sure if the issue is in the HaplotypeCaller output or in the way CombineGvcfs is merging things. Could you run ValidateVariants on each of the vcfs and let us know if they pass?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6368#issuecomment-574336680:142,Validat,ValidateVariants,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6368#issuecomment-574336680,1,['Validat'],['ValidateVariants']
Security,"This looks like a good start! I'm not quite sure how you are planning to handle dictionary validation, specifically, but you can take a look at the CNV plotting tools (PlotDenoisedCopyRatios and PlotModeledSegments) to see what level of validation we currently do. We can discuss further in person if you like. (Also, note that those tools take a sequence dictionary as an input to specify which contigs should be plotted; typically, this will be a subset of the full dictionary that excludes alt contigs, etc. Requiring this sequence-dictionary input is somewhat vestigial; previous versions of the pipeline did not include dictionaries in the headers of all CNV data files. Part of making these tools into GATKTools could include switching over to -L to specify regions for plotting.). Finally, are the changes to `-imr` mentioned in #2471 going to be addressed in a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363209925:91,validat,validation,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363209925,2,['validat'],['validation']
Security,"This looks like the auth service saw some transient error and instead of replying with a 503 (service temporarily unavailable), it replied with a 403 (forbidden). A workaround would be to retry on those. The side effect will be that if we genuinely do not have access, it'll take a bit longer to report it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735#issuecomment-338778985:261,access,access,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735#issuecomment-338778985,1,['access'],['access']
Security,"This may be an expensive validation since it necessarily involves parsing the cigar and MD tags. ; This is being done a `SamRecord` -> `Read` conversion since google's `CigarUnit` includes an optional referenceSequence field which may be filled in for SNPs and Deletions. It effectively replaces the sam MD tag. This is actually a major improvement over the MD tag, which is an incredibly confusing tag.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/557#issuecomment-111559387:25,validat,validation,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/557#issuecomment-111559387,1,['validat'],['validation']
Security,This method (validateSequenceDictionaries) in GATKTool needs to be modified so that the vcf file names associated with each sequence dictionary are passed into validateDictionaries() to make error messages more useful.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/660:13,validat,validateSequenceDictionaries,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/660,2,['validat'],"['validateDictionaries', 'validateSequenceDictionaries']"
Security,This needs to happen for MAF too. . We should add a method `OutputRenderer::sanitizeField` that we can plug into the annotation process that will automatically sanitize each field for illegal characters as they are added to the output. This will require refactoring the `OutputRenderer::write` method to be concrete with a call to another write method and this sanitizeField method to get the benefits automatically for all OutputRenderers.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4693#issuecomment-383709501:76,sanitiz,sanitizeField,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4693#issuecomment-383709501,3,['sanitiz'],"['sanitize', 'sanitizeField']"
Security,This only works for the conventional gather. adding useConventionalGather argument to force using conventional gather. adding --ignoreSafetyChecks to skip pre-validating the headers. continuing the tradition of having no tests for this tool,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2736:159,validat,validating,159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2736,1,['validat'],['validating']
Security,"This pr adds the subpopulation AC/AN/AF calculations.; It does this by taking in the ancestry table and making sublists of each---then passing that list of samples into the SelectVariants GATK tool. Updated Lucid chart here: https://lucid.app/lucidchart/fee376a4-4b72-481e-a239-a027f7f6ab1f/edit?page=CsG3hy3S1zEH#. Design Doc for this work:; https://docs.google.com/document/d/1FnPu_Jkz2O9rElApAQld0v6iBEFGe22dKarVWcwNxGI/edit. misc:; how should I add the VAT validation to the VAT pipeline? Should it run automatically?. Anvil data version of this table: spec-ops-aou:anvil_100_for_testing.vat_aug19. <img width=""1379"" alt=""Screen Shot 2021-08-11 at 5 38 22 PM"" src=""https://user-images.githubusercontent.com/6863459/129606564-bfc20a68-119a-4072-88b4-aeaf011cc965.png"">",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7399:461,validat,validation,461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7399,1,['validat'],['validation']
Security,"This produces a resource that will be used as input to an upcoming tool to filter intervals based on these annotations (as well as coverage statistics). Currently, we have an external python script performing this step in the gCNV pipeline. I also updated the AnnotateIntervals task and calls in WDL, but these changes are untested; the reviewer should check carefully for typos. Currently, all annotations are of double type, but I've added code that can support all types supported by the TSV code as well. Additional tracks can also be added relatively easily. Currently, allowed annotations and their corresponding types are hardcoded; we could possibly move this information to the SAM-style header in the future. For the Umap hg19 k100 single-read mappability track and the segmental-duplication track used by the Talkowski lab, annotation of 1kb bins on hg19 takes less than a minute with the default feature lookahead (which is exposed as a parameter). I tested using the Umap multi-read mappability track (which is orders of magnitude larger, but is actually what is used in the external script), but this is much slower (documentation indicates that the single-read track should be used to dissuade this). We should evaluate whether or not using the single-read track suffices for filtering.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5162:936,expose,exposed,936,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5162,1,['expose'],['exposed']
Security,"This pulls the bulk of the pipeline into a separate subworkflow so that the validations (with the mixture samples) can be run. The mixtures have already been subset and tagged, which is why the rest of the pipeline needed to be extracted.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5708:76,validat,validations,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5708,1,['validat'],['validations']
Security,"This replaces a secret that requires a pr to fix, and updates the name of one of the others.; Requires 1 more step after this.; * Switch travis variable name from DOCKER_SERVICE_PASS -> DOCKER_SERVICE_TOKEN for clarity; * Replace gcloud encrypted key",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7521:237,encrypt,encrypted,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7521,1,['encrypt'],['encrypted']
Security,"This request comes from the forum: . Mutect2 accepts multiple _different_ tumor samples (from the same individual) and calls on each sample at the same time, much like in a time-course experiment. Relatedly, if it's not too much to ask, I'd like to be able to provide multiple `--germline-resource` VCFs. ---; @Sheila and @shlee,; Thank you so much for referring me to the informative article and discussion!; I can't say I fully understand the technical difficulties. But I understood it is nontrivial to implement and joint somatic variant calling should be different from the joint calling of haplotypecaller. I still think it might be worthwhile for Mutect2 to be able to call somatic variants jointly on multiple tumor samples from **an** individual. It would help track somatic variants of a person over time. By the way, the article mentioned that Mutect2 would run without a matched normal. I wonder if Mutect2 now supports the tumor only mode. I remember no variant passed filters in tumor only mode for an older version. (One the other hand, I now think tumor only calling with high false positives would be a privacy threat..). ![](https://public.media.smithsonianmag.com/legacy_blog/snowflake-growth-2.gif """"); Image credit: [Libbrecht lab](https://smithsonianmag.com/science-nature/the-art-and-science-of-growing-snowflakes-in-a-lab-180949243/). This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/45571#Comment_45571",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4327:1128,threat,threat,1128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4327,1,['threat'],['threat']
Security,"This request was created from a contribution made by ABours on May 29, 2020 18:23 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360067695771-GenotypeGvcfs-has-formatting-issues-in-both-v4-1-6-0-as-v4-1-7-0. --. Hi,. I'm using v4.1.6.0 of GenotypeGvcfs to make a vcf, out of whole genome data from 19 samples (following your recommendations). When I run ValidateVariants to check the output of GenotypeGvcfs I get a error message, which states that one or more of the ALT allele are actually not in the samples provided. A previous user already found a similar error in ValidateVariants (https://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-), but then for Haplotypecaller, and you have opened a bugreport to add a feature to ValidateVariants: https://github.com/broadinstitute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: on",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:375,Validat,ValidateVariants,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,3,['Validat'],['ValidateVariants']
Security,"This request was created from a contribution made by Francesco Mazzarotto on March 23, 2022 14:16 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4892502642075-FilterMutectCalls-haplotype-filter-value-assigned-to-variants-with-different-PGT-tag](https://gatk.broadinstitute.org/hc/en-us/community/posts/4892502642075-FilterMutectCalls-haplotype-filter-value-assigned-to-variants-with-different-PGT-tag). \--. Hello,. I am using GATK v4.2.5.0 to process tumor-only samples sequenced with WES. In a sample, one variant that has been detected with Sanger sequencing (chr14-45137087-C-T) gets filtered out as non-PASS (also) because of the 'haplotype' filter value. As far as the 'haplotype' filter value is concerned, the 'guilty' variant seems to be another SNP 3bp upstream (chr14-45137084-C-T). There are no other variants called within 100bp of the Sanger-validated one (see below). chr14    45136964    .    C    T    .    haplotype;weak\_evidence    AS\_FilterStatus=weak\_evidence;AS\_SB\_TABLE=3,0|1,0;DP=4;ECNT=2;GERMQ=25;MBQ=41,37;MFRL=360,390;MMQ=60,60;MPOS=69;POPAF=7.30;ROQ=17;TLOD=3.20    GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB    0|1:3,1:0.333:4:1,0:1,1:0|1:45136962\_C\_T:45136962:3,0,1,0 ; ; chr14    45137084    .    C    T    .    germline;haplotype;panel\_of\_normals    AS\_FilterStatus=SITE;AS\_SB\_TABLE=9,1|12,5;DP=27;ECNT=2;GERMQ=1;MBQ=41,41;MFRL=297,326;MMQ=60,60;MPOS=45;PON;POPAF=0.830;ROQ=90;TLOD=59.93    GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB    0|1:10,17:0.615:27:4,13:4,4:0|1:45137084\_C\_T:45137084:9,1,12,5 ; ; chr14    45137087    .    C    T    .    germline;haplotype    AS\_FilterStatus=SITE;AS\_SB\_TABLE=12,5|9,1;DP=27;ECNT=2;GERMQ=1;MBQ=41,41;MFRL=326,297;MMQ=60,60;MPOS=44;POPAF=2.33;ROQ=93;TLOD=31.76    GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB    1|0:17,10:0.385:27:13,4:4,6:1|0:45137084\_C\_T:45137084:12,5,9,1 ; ; chr14    45149295    .    AC    A    .    haplotype;weak\_evidence    AS\_FilterStatus=weak\_evidence;AS\_SB\_TABLE=0,0|0,0;DP=1;ECNT",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7809:878,validat,validated,878,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7809,1,['validat'],['validated']
Security,"This request was created from a contribution made by Joyce Anon on April 25, 2022 06:30 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/5573282748699-Error-ShouldNeverReachHereException-FuncotationMap-in-FilterFuncotations](https://gatk.broadinstitute.org/hc/en-us/community/posts/5573282748699-Error-ShouldNeverReachHereException-FuncotationMap-in-FilterFuncotations). \--. FilterFuncotations stops with an error. The input file with the reference genome seems to pass ValidateVariants (no errors). It looks like ""FuncotationMap"" doesn't have enough values to go with the keys. I started with a .vcf file downloaded from Nebula Genomics, and sequentially used CNNScoreVariants, FilterVariantTranches (CNN\_1D), and Funcotator, with default settings. I am trying to find the most pathogenic variants. I considered using FilterVcf to remove synonymous and intron variants, but it doesn't look like it can do that. So then I tried FilterFuncotations, but it returns an error. What I want is some way to sort the variants by severity, to find the most pathogenic ones, but I don't know how to do that. GATK version: 4.2.6.1 ; ; Java runtime: OpenJDK 64-Bit Server VM v11.0.14.1+1-Ubuntu-0ubuntu1.20.04. Excerpt: ; ; \[April 25, 2022 at 2:00:35 AM EDT\] org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations done. Elapsed time: 0.03 minutes. ; ; Runtime.totalMemory()=319815680 ; ; org.broadinstitute.hellbender.exceptions.GATKException$ShouldNeverReachHereException: Cannot parse the funcotation attribute.  Num values: 31   Num keys: 53. Copied from the terminal: ; ; (gatk) aru@BioinformaticsVM:/mnt/sdb/gatk$ ./gatk FilterFuncotations --allele-frequency-data-source gnomad -O ./output/nebulaFilterFuncotations.vcf --ref-version hg38 -V ./output/nebulaFuncotatorAnnotated.vcf --java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true' ; ; Using GATK jar /mnt/sdb/gatk/gatk-package-4.2.6.1-local.jar ; ; Running: ; ;     java -Dsamjdk.use\_async\_io\_read\_samtools=f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7865:491,Validat,ValidateVariants,491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7865,1,['Validat'],['ValidateVariants']
Security,"This requires an upgrade to Hadoop-BAM the next time its released in order to pick up [this commit](https://github.com/HadoopGenomics/Hadoop-BAM/commit/85222f0d56f5a4294ff8fdff84c87b74b99413fc), plus changes in GATK to pass the validation stringency through. I have the necessary changes to GATK, but can't commit them as is because they're intertwined with other changes necessary for https://github.com/broadinstitute/gatk/issues/1346, which are in turn dependent on [other changes](https://github.com/cmnbroad/Hadoop-BAM/commit/07fc5560c2fabfab8c2d8344489efc47996cc597) that are not yet merged into Hadoop-BAM. They could be separated but hopefully will not have to be,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1261#issuecomment-172041451:228,validat,validation,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1261#issuecomment-172041451,1,['validat'],['validation']
Security,This retains the commit hash and commit number delta part in the version.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4118:24,hash,hash,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118,1,['hash'],['hash']
Security,"This set of optimizations brings the GATK4 HaplotypeCaller performance into line; with GATK3.x performance. Note that HaplotypeCallerSpark is not touched by this PR (that is for a future PR). Summary of changes:. * AssemblyRegionWalker: query all intervals on each contig simultaneously, rather than individually; * GATKRead: Cache adaptor boundary, soft start/end, and cigar length; * GATKRead: add getBasesNoCopy() / getBaseQualitiesNoCopy(); * ReadPileup: speed up stratified constructor; * LIBS.lazyLoadNextAlignmentContext(): don't keep pileup elements unnecessarily separated by sample during pileup creation; * Restore faster GATK3 version of ReferenceConfidenceModel.sumMismatchingQualities(); * RefVsAnyResult: nest within ReferenceConfidenceModel, and allow direct field access; * Remove redundant getBases() call in ReadThreadingGraph; * Fix BaseGraph Utils.validateArg() call; * ReadPileup: replace Collections.unmodifiableList(pileupElements).iterator() with direct return of an iterator that forbids removal; * Kill expensive bounds checking in GATKRead getBase()/getBaseQuality()/getCigarElement(); * Kill nonNull checks in PileupElement; * Kill expensive PileupElement and ReadPileup arg validation; * GATKRead adapter: clear cached values upon mutation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4031:781,access,access,781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4031,3,"['access', 'validat']","['access', 'validateArg', 'validation']"
Security,This should http access more seem less in a lot of places. . The way this handles query parameters is not ideal for signed url cases so we'll need to revisit that.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8626:17,access,access,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8626,1,['access'],['access']
Security,"This should resolve our git-lfs quota issues, since the quotas; for unauthenticated requests are much stingier than those for; authenticated requests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3179:127,authenticat,authenticated,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179,1,['authenticat'],['authenticated']
Security,This simplifies the code and didn't affect specificity in our validations. @takutosato can you review this?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3243:62,validat,validations,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3243,1,['validat'],['validations']
Security,This test exposed a bug in Spark Dataflow which is being fixed by https://github.com/cloudera/spark-dataflow/pull/57,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/599:10,expose,exposed,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/599,1,['expose'],['exposed']
Security,"This test input is malformed. When I try to read it with the Dataflow code, I get this error:. htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *. Here's the corresponding read:. 809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S \* 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?C<E@########## MD:Z:67 PG:Z:BWA RG:Z:809R9.5 AM:i:0 NM:i:0 SM:i:37 MQ:i:0 OQ:Z:DGEGGGGBFGGGGGDF8@@FGFBGGGBGCECCEEDFGGGFGFGGGBDGGF9DBFFGFBF;@>A4@@########## UQ:i:0. @droazen confirms that Picard's ValidateSAMFile utility reports that this bam has multiple errors. We should replace it with a clean input, and update the ""known good"" output accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/568:135,validat,validation,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/568,2,"['Validat', 'validat']","['ValidateSAMFile', 'validation']"
Security,"This ticket now represents the remaining work for the Spark large scale validation task: hooking up the existing pieces, and allowing them to be run using a script or similar. Most of its former story points have been redistributed to other tickets, making this now a 5 point ticket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/695#issuecomment-158403164:72,validat,validation,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/695#issuecomment-158403164,1,['validat'],['validation']
Security,"This tool creates a data file containing a map from reference accessions to NCBI taxonomic IDs, and the taxonomic tree, which includes parent/child relationships as well as other metadata like the reference length and scientific name of each node. . The input files are available from the NCBI FTP server. One is a ""catalog"" file that gives the mapping from reference contig accession to taxonomic ID. There are catalog files available for RefSeq and for Genbank - the tool can take in either. . There are two other files - a ""names"" and ""nodes"" file contained in a single tarball - that contain the scientific names of each node and parent/child relationships. For convenience, the tool takes in the path to the tarball and extracts the two files automatically. The resulting database size is minimized using the given reference. Once the full NCBI taxonomy tree is built, any organism node that is neither in the reference nor an ancestor of a reference organism is removed. The resulting datafile is read in by the ClassifyReads tool (coming in a future PR) to assign relative abundance scores to each taxonomic node. Also made some changed to the way the PSTree and PSTreeNode are serialized (using Kryo read/writeObject instead of read/writeClassAndObject) so that loading old files won't break if these classes change packages.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2730:62,access,accessions,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2730,2,['access'],"['accession', 'accessions']"
Security,"This update of genomicsDB includes the option to not validate the sampleMapFile against the actual headers. Choosing to not validate allows us to save time at the start by not having to open each file on the initial header construction when using --`sampleMapFile`. closes #2713, closes #2714, and closes #2715. It also includes an update to have GenomicsDB capture RSId's by default, (closes #2636) which should make diffs easier on our end at a slight cost of storage size. If that's an issue we may need to revisit the default.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2733#issuecomment-306254281:53,validat,validate,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2733#issuecomment-306254281,2,['validat'],['validate']
Security,"This user is receiving an empty output file when running GenomicsDBImport. The user ran ValidateVariants on the input files which was successful. . This request was created from a contribution made by Enrico Cocchi on July 14, 2021 10:31 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4403568031515-Mutect2-PoN-GenomicsDBImport-creates-empty-DB](https://gatk.broadinstitute.org/hc/en-us/community/posts/4403568031515-Mutect2-PoN-GenomicsDBImport-creates-empty-DB). \--. I am trying to follow GATK 4.2.0 best-practice guidelines for  \[Mutect2 PoN creation\](/hc/en-us/articles/360035531132--How-to-Call-somatic-mutations-using-GATK4-Mutect2). I called variants in my samples as recommended with:. gatk Mutect2 \\ ; ; \-R ${REF} \\ ; ; \-L ${EXOME\_INPUT\_INTERVALS} \\ ; ; \-I ${BAM} \\ ; ; \--sequence-dictionary ${DICT} \\ ; ; \--max-mnp-distance 0 \\ ; ; \-O ${SAMPLE\_NAME}.mutect2.vcf. but I see that the tool is unable to create a proper  `GenomicsDB`  through the  \[GenomicsDBImport\](/hc/en-us/articles/360057439331-GenomicsDBImport) command. Even focusing the analysis on a little interval in which I know I have variants in the Mutect2 generated VCFs, here the  `SelectVariants`  output from one of the VCF I'll use in the  `GenomicsDBImport`  command:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT XXX ; ; 1 883625 . A G . . AS\_SB\_TABLE=0,0|12,41;DP=54;ECNT=1;MBQ=0,33;MFRL=0,260;MMQ=60,60;MPOS=31;POPAF=7.30;TLOD=182.40 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:0,53:0.981:53:0,26:0,26:0,0,12,41. \`\`. and here the command to generate the DB:. gatk \ ; . \--java-options ""-Djava.io.tmpdir=/nfs/projects/CNV\_WGS/CHIP-PON-DB/TMP-DIR"" \\ ; ; GenomicsDBImport \\ ; ; \-R $REF \\ ; ; \-L 1:883600-883650 \\ ; ; \--genomicsdb-workspace-path $OUT \\ ; ; \--tmp-dir /nfs/projects/CNV\_WGS/CHIP-PON-DB/TMP-DIR \\ ; ; \-V /nfs/projects/CNV\_WGS/Mutetc2-PON-OUT/Roche-M/fetal0003D.Roche-M.mutect2.vcf -V /nfs/projects/CNV\_WGS/Mutetc2-PON-OUT/Roche-M/fetal0020D.Roche-M.mutect2.vcf -V ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7362:88,Validat,ValidateVariants,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7362,1,['Validat'],['ValidateVariants']
Security,"This user received an ArrayIndexOutofBoundsException error when running GenotypeGVCFs. The user confirmed that the headers of their vcf files and the their fasta files have matching IDs and contig lengths. The user also tried running ValidateVariants and received the following error: A USER ERROR has occurred: Input MA1.g.vcf fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position 1A:3456221 are not observed at all in the sample genotypes. This request was created from a contribution made by Alon Ziv on July 07, 2021 12:21 UTC. . Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4403256366107--java-lang-ArrayIndexOutOfBoundsException-32772-while-running-GenotypeGVCFs](https://gatk.broadinstitute.org/hc/en-us/community/posts/4403256366107--java-lang-ArrayIndexOutOfBoundsException-32772-while-running-GenotypeGVCFs). \--. i don't get an error but the massge  java.lang.ArrayIndexOutOfBoundsException: 32772 ; ; i use : GATK version used: 4.2.0 ; ; b) Exact command used  this line for Geomics DBImport. gatk GenomicsDBImport -V MA1.g.vcf -V MA2.g.vcf -V MA3.g.vcf -V MH1.g.vcf -V MH2.g.vcf -V MH3.g.vcf -V F4\_1.g.vcf -V F4\_2.g.vcf -V F4\_3.g.vcf --genomicsdb-workspace-path my\_database1AB -L 1A -L 1B -L 2A -L 2B -L 3A -L 3B -L 4A -L 4B -L 5A -L 5B -L 6A -L 6B -L 7A -L 7B. and this for GenotypeGVCFs. gatk --java-options ""-Xmx12g -Xms12g"" GenotypeGVCFs -R Triticum\_dicoccoides.WEWSeq\_v.1.0.dna.toplevel.fa -V gendb://my\_database -O output.vcf.gz --new-qual --tmp-dir temp/. c) Entire error log:. Using GATK jar /home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx12g -Xms12g -jar /home/alonzi/miniconda3/envs/rna-seq/share/gatk4-4.2.0.0-1/gatk-package-4.2.0.0-local.jar GenotypeGVCFs -R Triticum\_d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7348:234,Validat,ValidateVariants,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7348,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,"This was fixed by the addition of the following firewall rule:. <img width=""419"" alt=""screen shot 2016-03-29 at 3 00 11 pm"" src=""https://cloud.githubusercontent.com/assets/4700332/14122691/cda70254-f5ca-11e5-8342-afd119725d85.png"">",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1611#issuecomment-203085295:48,firewall,firewall,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1611#issuecomment-203085295,1,['firewall'],['firewall']
Security,"This was unearthed by #7542 and is plumbed correctly in this PR. Note that we need to still address the broader issue of hooking arguments to GenomicsDB - #6456 . GenomicsDB exposes a whole set of export arguments all added in response of gatk requests, some of them are hardcoded by certain tools(e.g GenotypeGVCFs uses --max-alternate-alleles while SelectVariants does not), many are unused.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7576:174,expose,exposes,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7576,1,['expose'],['exposes']
Security,This will currently fail all of the SplitNCigarReadsIntegrationTests.java tests because I have yet to validate that the approach is right for this problem and that the output is reasonable before I go about recreating the tests. @meganshand,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-233741188:102,validat,validate,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2021#issuecomment-233741188,1,['validat'],['validate']
Security,This will require porting `SequenceDictionaryUtils.validateDictionaries()` from the old GATK.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/101#issuecomment-113267458:51,validat,validateDictionaries,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/101#issuecomment-113267458,1,['validat'],['validateDictionaries']
Security,"To be clear, this will work perfectly fine as long as you have enough space in /dev/shm---which is typically true everywhere outside of our default Docker container. I'm loath to cripple a tool just because of limitations that are fundamentally elsewhere...let's just address those in the appropriate places. (Furthermore, I'm especially loath to write a plotting tool that takes ~5 minutes to generate a plot!) And yes, while it is not great that data.table forces us to use /dev/shm, I think `fread(""grep ..."")` is relatively standard. If `--shm-size` is indeed not exposed, why doesn't the Google backend scale /dev/shm or other tmpfs space with requested machine memory?. If there really is no other way around it, then all we're doing is filtering out the lines beginning with `@`. We could do this first by calling system commands within R to write to a temporary file, and then reading that back in with fread. This seems hacky to me, but I've confirmed that it works within the Docker. This will solve our immediate problem, but I still think it's worth taking a look at those other limitations elsewhere now as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827:568,expose,exposed,568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827,1,['expose'],['exposed']
Security,"To clarify what needs to be done here:. -Add a new `--javaOptions` argument to `gatk-launch`. -When running with a packaged local jar, the value of `--javaOptions` should be injected into the command line built by `formatLocalJarCommand()`. -When running with the ""wrapper script"" (as a result of building with `./gradlew installDist` instead of `./gradlew localJar`), propagate the value of `--javaOptions` to the `JAVA_OPTS` environment variable the wrapper script expects. You can inspect the wrapper script itself by running `./gradlew installDist` and then examining `build/install/gatk/bin/gatk`. -When running on Spark, you'll need to add the `--javaOptions` to `spark.driver.extraJavaOptions` and `spark.executor.extraJavaOptions`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2694#issuecomment-305007868:174,inject,injected,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2694#issuecomment-305007868,1,['inject'],['injected']
Security,"To the question on building it: I guess it isnt really a problem with your build per-se, but rather it seems to make a variety of assumptions or requirements on the environment that were difficult to replicate on our cluster (where i lack admin privs). Using your docker image was the faster way i could find to replicate the needed environment. Issues I hit included: 1) needed git lfs installed (on cluster i lack sudo/apt access), 2) gradle complained about building on the lustre filesystem, so i needed to move to other disks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042026487:425,access,access,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042026487,1,['access'],['access']
Security,"To update:. Chris and I just tested copying the bam and indices (3 files) from `gs://broad-dsde-methods-sv/samples/G94797_CHM_MIX/WGS1` (note that Chris reports it works on this bucket) to a just-created ""directory"" `gs://broad-dsde-methods-sv/samples/G94797_CHM_MIX/WGS1/tmp`, and it fails. Also an interested behavior we noticed, and a suspicion that is hard to test (due to lack of access to time machine), that this might be related when the ""directory"" is created: any directory freshly created after October 2018 might be susceptible to this, which is also the month when newer (>66) release of NIO became available.; In the mean time, if one does ; `gsutil ls -L gs://broad-dsde-methods-sv/samples/G94797_CHM_MIX/WGS1`; you'd get, at the last line, `TOTAL: 3 objects`, which is expected, whereas if one does; `gsutil ls -L gs://broad-dsde-methods-sv/samples/G94797_CHM_MIX/WGS1/tmp`; guess what: `TOTAL: 4 objects`!; It seems to list the ""directory"" itself as an object as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-491969032:385,access,access,385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-491969032,1,['access'],['access']
Security,"Totally get it now; with these changes, `assertEqualTextFiles` is getting `LinkedList`s from `XReadLines`, rather than `ArrayList`s, which it used to get from the trailing `stream.collect` calls. Since it then uses indexed access to iterate thorough the two lists zip style, the serial `get` calls are super slow on even moderately sized (100k) linked lists. Should be an easy fix. @jean-philippe-martin let me know if you want me to make this change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-462784167:223,access,access,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-462784167,1,['access'],['access']
Security,"Touch/Reference_data_b38/gnomad.genomes.v3.1.2.sites.chr3.vcf.bgz; 10:58:19.971 INFO FeatureManager - Using codec VCFCodec to read file file:///run/media/riadh/My%20Book_From%20Eiklid/Analysis/gatk-4.2.4.1/ensembl-vep/PE69_chr3.vcf; 10:58:20.063 INFO VariantAnnotator - Done initializing engine; 10:58:20.091 WARN VariantAnnotatorEngine - The requested expression attribute ""gnomad.ALT"" is missing from the header in its resource file gnomad; 10:58:20.140 INFO ProgressMeter - Starting traversal; 10:58:20.140 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 10:58:42.160 INFO VariantAnnotator - Shutting down engine; [March 17, 2022 at 10:58:42 AM CET] org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator done. Elapsed time: 0.37 minutes.; Runtime.totalMemory()=17158897664; java.lang.IllegalStateException: Allele in genotype C not in the variant context [C*, CT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.base/java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1464); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1420); 	at org.broadinstitute.hellben",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053:3972,validat,validateGenotypes,3972,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053,1,['validat'],['validateGenotypes']
Security,Trace:. ...; 11:54:40.426 [ERROR] [system.err] [bwt_restore_sa] SA-BWT inconsistency: seq_len is not the same. Abort!; ... 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':test'.; 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:98); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:68); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:62); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); 11:54:40.433 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54); 11:54:40.434 [ERROR] [org.gradle.internal.buildevents.BuildExceptionReporter] 	at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTas,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2802:1149,Validat,ValidatingTaskExecuter,1149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2802,1,['Validat'],['ValidatingTaskExecuter']
Security,"TrainVariantAnnotationsModel:. Trains a model for scoring variant calls based on site-level annotations. TODOs:. - [x] Integration tests. Exact-match tests for (non-exhaustive) configurations given by the Cartesian product of the following options:; * non-allele-specific vs. allele-specific; * SNP-only vs. SNP+INDEL (for both of these options, we use extracted annotations that contain both SNP and INDEL variants as input); * positive (training with *.annot.hdf5) vs. positive-unlabeled (training with *.annot.hdf5 and *.unlabeled.annot.hdf5); * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Refactor main code block for model training; it's a bit monolithic and procedural now.; - [x] Decide on behavior for ill-behaved annotations. E.g., all missing, zero variance. Future work:. - [ ] We could allow subsetting of annotations here, which might allow for easier treatment of ill-behaved annotations. However, I'd say enabling workflows where the set of annotations is fixed is the priority.; - [ ] We could do positive-unlabeled training more rigorously or iteratively. Right now, we essentially do a single iteration to determine negative data. This could perhaps be preceded by a round of refactoring to clean up model training and make it less procedural.; - [ ] Automatic threshold tuning could be built into the tool, see #7711. We'd probably have to introduce a ""validation"" label. Perhaps it makes sense to keep this sort of thing at the workflow level?; - [ ] In the positive-negative framework enforced by the Java code in this tool, a ""model"" is anything that assigns a score, we fit two models to different subsets of the data, and then take the difference of the two scores. While the python backend does give some freedom to specify a model, future developers may want",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369:791,validat,validation,791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948369,1,['validat'],['validation']
Security,"Travis is terminating our cron job because there is too much log output. ; It seems to be thousands of repetitions of:. ```; 21:44:23.077 WARN DefaultDocWorkUnitHandler - Could not access the field definition for backtrace while searching for SHOW_HIDDEN, presumably because the field is inaccessible; ```. Possibly related to our recent inclusion of picard in our doc output?. See: https://travis-ci.org/broadinstitute/gatk/jobs/289240692",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3710:181,access,access,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3710,1,['access'],['access']
Security,"Two .vcf.idx files used by the haplotype caller integration test had; file name lengths > 144. This is incompatible with ecryptfs, which is; commonly used for encrypted home directories on linux. Renaming the; .vcf and .vcf.idx files and updating references to them fixed the; problem. Fixes #4718.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4736:159,encrypt,encrypted,159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4736,1,['encrypt'],['encrypted']
Security,"Two documentation nitpicks. Looks good. It's good that you're fixing this, since i think the entire point of this class was to avoid copying the bases, and it ended up just copying the bases for the hashcode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1620#issuecomment-200883757:199,hash,hashcode,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1620#issuecomment-200883757,1,['hash'],['hashcode']
Security,"UFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.COMPRESSION_LEVEL : 1; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_INDEX : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_MD5 : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CUSTOM_READER_FACTORY : ; 19:03:42.999 INFO ValidateSamFile - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 19:03:42.999 INFO ValidateSamFile - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.REFERENCE_FASTA : null; 19:03:43.000 INFO ValidateSamFile - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.000 INFO ValidateSamFile - Initializing engine; 19:03:43.000 INFO ValidateSamFile - Done initializing engine; ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 24466, Read name 20FUKAAXX100202:7:46:13035:77621, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97940, Read name 20FUKAAXX100202:5:7:21464:86224, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97955, Read name 20GAVAAXX100126:5:7:1291:122571, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned;",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:1892,Validat,ValidateSamFile,1892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,1,['Validat'],['ValidateSamFile']
Security,"UIET false; [March 9, 2017 7:03:42 PM EST] Executing as gspowley@dna on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Version: Version:4.alpha.2-170-g8d06823-SNAPSHOT; 19:03:42.998 INFO ValidateSamFile - Defaults.BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.COMPRESSION_LEVEL : 1; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_INDEX : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_MD5 : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CUSTOM_READER_FACTORY : ; 19:03:42.999 INFO ValidateSamFile - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 19:03:42.999 INFO ValidateSamFile - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.REFERENCE_FASTA : null; 19:03:43.000 INFO ValidateSamFile - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.000 INFO ValidateSamFile - Initializing engine; 19:03:43.000 INFO ValidateSamFile - Done initializing engine; ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 24466, Read name 20FUKAAXX100202:7:46:13035:77621, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97940, Read name 20FUKAAXX100202:5:7:21464:86224, bin field of BAM record does not equal value computed based on alignment start a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:1646,Validat,ValidateSamFile,1646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,1,['Validat'],['ValidateSamFile']
Security,"UMINA.library.000000000-BCFDC.1.1.sorted.bam --MODE SUMMARY --MAX_OUTPUT 100 --IGNORE_WARNINGS false --VALIDATE_INDEX true --INDEX_VALIDATION_STRINGENCY EXHAUSTIVE --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --SKIP_MATE_VALIDATION false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; [Thu Mar 07 16:08:24 UTC 2019] Executing as mpmachado@lx-bioinfo02 on Linux 2.6.32-696.23.1.el6.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.0.0; WARNING 2019-03-07 16:08:24 ValidateSamFile NM validation cannot be performed without the reference. All other validations will still occur.; INFO 2019-03-07 16:10:25 SamFileValidator Validated Read 10,000,000 records. Elapsed time: 00:02:00s. Time for last 10,000,000: 120s. Last read position: chr9:32,633,613; INFO 2019-03-07 16:12:22 SamFileValidator Validated Read 20,000,000 records. Elapsed time: 00:03:58s. Time for last 10,000,000: 117s. Last read position: chrM:11,340; No errors found; [Thu Mar 07 16:13:05 UTC 2019] picard.sam.ValidateSamFile done. Elapsed time: 4.79 minutes.; Runtime.totalMemory()=2602041344; Tool returned:; 0; ```. But when run BaseRecalibrator got the _fromIndex toIndex_ error:; `gatk BaseRecalibrator --input sorted.bam --output sorted.baserecalibrator_report.txt --reference GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.fasta --use-original-qualities true --known-sites snp151common_tablebrowser.bed.bgz --known-sites snp151flagged_tablebrowser.bed.bgz`; ```; ERROR: return code 3; STDERR:; 15:46:35.795 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.0.0-local.jar!/com/intel/gkl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807:1907,Validat,Validated,1907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807,1,['Validat'],['Validated']
Security,Undisabling/fixing tests for ValidateVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/832:29,Validat,ValidateVariants,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/832,1,['Validat'],['ValidateVariants']
Security,Unexpected behavior for --validation-type-to-exclude argument in ValidateVariants.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4642:26,validat,validation-type-to-exclude,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4642,2,"['Validat', 'validat']","['ValidateVariants', 'validation-type-to-exclude']"
Security,"Unfortunately, projects like TCGA with BAMs from different sequencing centers do not use the exact same sequence dictionary across them. I've relaxed validation in cases where dictionaries are checked across different BAMs so that only a warning is thrown; however, cases where dictionaries should arise from the same BAM still throw an exception.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4758:150,validat,validation,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4758,1,['validat'],['validation']
Security,"Unit tests for tool X should not rely on the behavior of instanceMain or doWork in tool Y. . In particular, unit tests that involve comparing/validating outputs should not reference CLPs like CompareSAMs or ValidateSamFile directly. Instead, these CLPs should just be thin wrappers around other classes that have the actual logic. This is already the case for ValidateSamFile, which is just a wrapper for SamFileValidator in HTSJDK. CompareSAMs should be refactored to match this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/145:142,validat,validating,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/145,3,"['Validat', 'validat']","['ValidateSamFile', 'validating']"
Security,"Unless, that is, we want to use the API key to allow non-logged-in access to public data?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2402#issuecomment-288549673:67,access,access,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2402#issuecomment-288549673,1,['access'],['access']
Security,"Unlike the other validation rules, this does not test the validity of the VAT, but whether the pipeline completed as we expected it to--so I have added this as the singular test that runs during the pipeline. Validation Rule 2: The number of passing variants in GVS matches the number of variants in the VAT. Please note that we are counting the number of variants in GVS, not the number of sites, which may add a difficulty to this task. Another way to phrase it: ""If I were to make a sites only VCF of GVS and split each passing variant into it's own line, that number should equal the number of unique VIDs in the VAT."". Measure number of unique variants in sites only VCF that is generated. We don't want to count filtered variants so we can't count the GVS table. NOTE:. this pr also has some general cleanup as per discussion with Andrea. ; where would y'all suggest I put the template file for the custom annotations?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7374:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7374,2,"['Validat', 'validat']","['Validation', 'validation']"
Security,Update GATK dependencies to patch security vulnerabilities,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8352:34,secur,security,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8352,1,['secur'],['security']
Security,Update SV split-read strand validation and clustering,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8378:28,validat,validation,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8378,1,['validat'],['validation']
Security,Update ValidateSamFileIntegrationTest once htsjdk #369 CRAM bug fix is available,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1138:7,Validat,ValidateSamFileIntegrationTest,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1138,1,['Validat'],['ValidateSamFileIntegrationTest']
Security,"Update dependencies to address security vulnerabilities, and add a security scanner to build.gradle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8607:31,secur,security,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8607,2,['secur'],['security']
Security,"Update: I made a list of particularly bad intervals for the DREAM4 and 20-plex Hapmap bams by scattering 500 ways, choosing the 20 slowest jobs (weighting by an empirical 3x slowness factor for jobs on nodes that couldn't use AVX PairHMM acceleration), scattering again etc to obtain 100 or so intervals of roughly 200 bp that took long. Then I confirmed that the slowness had nothing to do with SGE or cromwell (it shouldn't, because I was getting runtime from the GATK output log, not the cromwell log, but just in case. . .) by re-running each interval on gsa5. In *every* case, the slow intervals had extremely deep coverage (2,000 - 30,000) due to mapping error. Even after filtering to MQ == 60, the high coverage usually remained, although it often decreased significantly. In addition to the extreme depth, the only other sign was a significant proportion of reads with multiple SNVs relative to the reference. Unfortunately, something cheap to compute, like CIGAR complexity, was often not a sign, because many CIGARs were eg 101M, with many of the M's coming from SNVs. One quick solution would be to completely skip calling on regions with extremely high depth. It's hard to imagine being able to trust any calls from them. Another option is MQ-based downsampling, for example downsampling to the 1000 reads with the best MQ. Some people might like the downsampling option for the secure feeling of not losing sensitivity, although realistically those regions are so terrible that this security is an illusion. The only real protection is a more complete reference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2975#issuecomment-309565338:1392,secur,secure,1392,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2975#issuecomment-309565338,2,['secur'],"['secure', 'security']"
Security,Update: the cfDNA validation is all set up.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2942#issuecomment-357065450:18,validat,validation,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2942#issuecomment-357065450,1,['validat'],['validation']
Security,"Update:; - [ ] A cool name! (Marduk, Clarendon, NeuroVar) ? maybe I'll do a slack poll of dsde methods?; - [x] Model training script (in Python, eventually in Java); - [x] Pretrained model for WGS; - [x] Pretrained model for WEx (still being validated and was only trained on NA12878); - [x] Model inference and VCF annotation (in Java); - [x] Solution for applying filters based on CNN score cutoff (tranches.py script); - [ ] Alternate joint calling WDL? Or for re-filtering? (ideally with a $$$ estimate); - [ ] Performance optimizations?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039:242,validat,validated,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039,1,['validat'],['validated']
Security,"Updates (EchoCallset Version):. Changes to scatter width of VCFs generated has changed the amount of data generated in tests, so need to update truth; Adding a new field to extracted VCF Header EXCESS_ALLLELES and that will break the tests.; And why not validate our VCFs for jollies.; Updates 'truth' path for data to match these changes. Integration tests failed due to different number of output VCFs now. So I cherry-picked Miguel's commit on ah_var_store that changed the scatter.; Integration tests *still* [failing](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/8f7b0cc9-4a31-404b-99b3-89e182707e8b) due to the change in VCF Header:. > 6,7d5; < ##FILTER=<ID=high_CALIBRATION_SENSITIVITY_INDEL,Description=""Site failed INDEL model calibration sensitivity cutoff (0.99)"">; < ##FILTER=<ID=high_CALIBRATION_SENSITIVITY_SNP,Description=""Site failed SNP model calibration sensitivity cutoff (0.997)"">; 9c7; < ##FORMAT=<ID=FT,Number=1,Type=String,Description=""Genotype Filter Field"">; ---; > ##FORMAT=<ID=FT,Number=1,Type=String,Description=""Sample Genotype Filter Field"">; 3388a3387,3388; > ##high_CALIBRATION_SENSITIVITY_INDEL=Sample Genotype FT filter value indicating that the genotyped allele failed INDEL model calibration sensitivity cutoff (0.99); > ##high_CALIBRATION_SENSITIVITY_SNP=Sample Genotype FT filter value indicating that the genotyped allele failed SNP model calibration sensitivity cutoff (0.997)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8848:254,validat,validate,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8848,1,['validat'],['validate']
Security,"Updates:; - Changes to scatter width of VCFs generated has changed the amount of data generated in tests, so need to update truth; - Adding a new field to extracted VCF Header `EXCESS_ALLLELES` and that will break the tests.; - And why not validate our VCFs for jollies.; - Updates 'truth' path for data to match these changes. Integration Tests:; Passing test against Chr20/X/Y [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/985fbc06-36ed-4006-9703-0b86577f704c); Passing test against All Chromosomes [Here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9d473c81-4742-4188-bc70-1e9371bfcc11)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8846:240,validat,validate,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8846,1,['validat'],['validate']
Security,"Upgrading htsjdk to 2.21.0. . This includes a change that relaxes restrictions on loading vcfs with sequence dictionaries that are missing lengths. This effected one of the tests which I changed a bit. We could also implement blanket ban on sequence dictionaries with missing lengths in our sequence dictionary validation code, but we currently allow them for sam/bam as far as I can tell and have tests that take them into account.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6250:311,validat,validation,311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6250,1,['validat'],['validation']
Security,Upgrading to Spark 3.3 (switches to log4j 2.x) when it's released would be ideal since it would solve the security issue mentioned [here](https://gatk.broadinstitute.org/hc/en-us/community/posts/4592331786651-vulnerability-issue-for-gatk-package-4-2-5-0-local-jar),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6671#issuecomment-1155747154:106,secur,security,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6671#issuecomment-1155747154,1,['secur'],['security']
Security,"Upon further investigating, the builds are indeed there. Dockerhub is deprecating their build security scan feature, and in the meantime it only allows one scan of an image a day. Because we tag each image with a different name they show up in the nightly build repository as being unscanned and thus get binned at the bottom of the page (after scrolling through everything since the beginning of time) to view the unscanned images.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4454#issuecomment-368648512:94,secur,security,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4454#issuecomment-368648512,1,['secur'],['security']
Security,"Use SampleLocatableMetadata if you want CombineSegmentBreakpoints to only operate on segment files from a single sample. It's conceivable that you want it to be more flexible, in which case I would use LocatableMetadata. Also, go ahead and move the collection class into the collection package, rather than expose the abstract classes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352762883:307,expose,expose,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352762883,1,['expose'],['expose']
Security,Use more secure HTTPS URL in GitHub description,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3211:9,secur,secure,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3211,1,['secur'],['secure']
Security,"Use setHeaderStrict, which validates the record's reference and mate reference against the new header. Requires disabling the ADAM test in MeanQualityByCycleSparkIntegrationTest due to https://github.com/broadinstitute/gatk/issues/1540.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1541:27,validat,validates,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1541,1,['validat'],['validates']
Security,"User Question: I'm trying to speed up the process of calling variants using SPARK. I have access to a slurm HPC cluster, so I guess it's not that straightforward to run GATK in a proper distributed master-slave architecture (if there is any tutorial on how to setup slurm jobs to use GATK Spark tools on multiple nodes I would appreciate it a lot). ; Therefore, I run GATK in local mode with some SPARK threads, eventually speeding up the process by parallelising the number of samples processed simultaneously with GNU parallel. But then, I'm having troubles because some samples crash due to SPARK errors. Perhaps you could send my logs to the developers ? I'm trying to run 8 parallel GATk jobs (8 samples) using 5 Spark cpus on each in a node with 40 cpus. . Best,; Pedro. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/56193#Comment_56193",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5717:90,access,access,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5717,1,['access'],['access']
Security,"User Report:. Hi,. I'm trying to run gatk MarkDuplicatesSpark (v 4.1.4.1) locally, so not on a spark cluster, and provided the option --conf 'spark.executor.cores=4' to tell MarkDuplicatesSpark to use only 4 cores on the machine. However when I check the system load with e.g. top I see that all 44 cores of the system are used by MarkDuplicatesSpark. What am I doing wrong?. command:; gatk MarkDuplicatesSpark \; --tmp-dir /local/scratch/tmp \; -I Control_aligned.bam \; -O Control_aligned_sort_mkdp.bam \ ; -M Control_aligned_sort_mkdp.txt \; --create-output-bam-index true \; --read-validation-stringency LENIENT \; --conf 'spark.executor.cores=4'. ------------------------------------------------------------------. **Solution** is to use this argument: `--spark-master local[2] -> ""Run on the local machine using two cores""`. More details in this doc: https://software.broadinstitute.org/gatk/documentation/article?id=11245. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24671/markduplicatesspark-not-respecting-conf-spark-executor-cores-4-option/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6324:586,validat,validation-stringency,586,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6324,1,['validat'],['validation-stringency']
Security,"User has tested GATK3.7 HaplotypeCaller and GATK4 HaplotypeCaller. GATK4 takes ~35 hours while GATK3.7 takes about 18 hours. Original report is here: https://github.com/broadinstitute/gatk/issues/3631 David, I assigned you just so you could take a look. User seems satisfied that GATK4 is faster, but I am just making sure this is expected. I asked for more details on what type of data they are using and whether Spark version is faster (assuming this is from non-Spark version). . ----; User Report; ----. @Sheila,. Hi Sheila,. I repeated the experiment with GATK4.0.0 version. The performance is much better than GATK4beta5 version. Here are the logs: . $ tail -400 NA12892.HaplotypeCaller.err; Using GATK jar /gpfs/software/genomics/GATK/4.0.0/gatk-package-4.0.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /gpfs/software/genomics/GATK/4.0.0/gatk-package-4.0.0.0-local.jar HaplotypeCaller --reference /gpfs/data_jrnas1/ref_data/Hsapiens/hs37d5/hs37d5.fa --input /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4.0.0/NA12892/bam/NA12892.recal.bam --dbsnp /gpfs/data_jrnas1/ref_data/Hsapiens/GRCh37/variation/dbsnp_138.vcf.gz --emit-ref-confidence GVCF --read-validation-stringency LENIENT --native-pair-hmm-threads 32 --output /gpfs/projects/NAGA/naga/NGS/pipeline/GATK_Best_Practices/GATK4.0.0/NA12892/vcf/NA12892.raw.snps.indels.g.vcf; [January 26, 2018 1:09:58 AM AST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: **2,133.48 minutes**.; Runtime.totalMemory()=2183659520; real 128010.56; user 436969.62; sys 3030.18. Thanks and Regards,; Naga. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/45634#Comment_45634",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4361:1320,validat,validation-stringency,1320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4361,1,['validat'],['validation-stringency']
Security,"User report:. ValidateVariants causes the error:; ```; java -Xms32G -Xmx32G -jar /data/biosoftware/GATK/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar ValidateVariants -R ~/reference/reference.fasta -V $i -gvcf; ```; And it causes the following error for all my files:; ```; ***********************************************************************. A USER ERROR has occurred: In a GVCF all records must ordered. Record: [VC Unknown @ Super-Scaffold_2:1-4 Q. of type=SYMBOLIC alleles=[G*, <NON_REF>] attr={END=4} filters= covers a position previously traversed. ***********************************************************************; ```. This doesn't cause the error:; ```; java -Xms32G -Xmx32G -jar /data/biosoftware/GATK/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar ValidateVariants -R ~/reference/reference.fasta -V $i; ```. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/59104#Comment_59104",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6023:14,Validat,ValidateVariants,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6023,3,['Validat'],['ValidateVariants']
Security,"Using GENOTYPE_GIVEN_ALLELES (""GGA"") mode with HaplotypeCaller, I've encountered a couple instances of crashes that I've traced to spanning deletions (of the type considered in #4963).; One case involved the following in the `--alleles` input:; ```; 22	16137300	rs567136176	TAG	T; 22	16137302	rs573978809	G	C; ```; and it crashed with:; ```; java.lang.IllegalStateException: Allele in genotype TAG* not in the variant context [G*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hell",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336:487,validat,validateGenotypes,487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336,2,['validat'],"['validate', 'validateGenotypes']"
Security,"Using HaplotypeCaller with `GENOTYPE_GIVEN_ALLELES` (""GGA"") mode, I came across a couple of cases that crashed, and I traced them to spanning deletions (of the type considered in #4963). The first case involved the following spanning deletion in the `--alleles` input:; ```; 22	16137300	rs567136176	TAG	T; 22	16137302	rs573978809	G	C; ```; and it crashed with:; ```; java.lang.IllegalStateException: Allele in genotype TAG* not in the variant context [G*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5337:512,validat,validateGenotypes,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5337,2,['validat'],"['validate', 'validateGenotypes']"
Security,"Using VCFTools to validate:; ```; vcf-validator SAMPLE7T-vs-SAMPLE7N-filtered.vcf; ```. I get a massive amount of messages:; ```; .....snip.......; column SAMPLE7N at 19:49136721 .. Could not validate the float [NaN],FORMAT tag [MPOS] expected different number of values (expected 1, found 2),FORMAT tag [MFRL] expected different number of values (expected 1, found 2),FORMAT tag [MMQ] expected different number of values (expected 1, found 2),FORMAT tag [MCL] expected different number of values (expected 1, found 2),FORMAT tag [MBQ] expected different number of values (expected 1, found 2); .....snip.......; column SAMPLE7T at 19:45901415 .. FORMAT tag [MBQ] expected different number of values (expected 1, found 2),FORMAT tag [MMQ] expected different number of values (expected 1, found 2),FORMAT tag [MCL] expected different number of values (expected 1, found 2),FORMAT tag [MFRL] expected different number of values (expected 1, found 2),FORMAT tag [MPOS] expected different number of values (expected 1, found 2); .....snip.......; ```. Sure enough, the header does not match the values for those fields (in the header number=""A""), so the validation errors are correct. Not sure what is the deal with FOXOG, but that may not be a big deal.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3296:18,validat,validate,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3296,4,['validat'],"['validate', 'validation', 'validator']"
Security,"Using the `--gcs-project-for-requester-pays` argument to access a requester-pays bucket, I tried `broad-dsde-methods`, `""broad-dsde-methods""`, and `222581509023`, but no dice. The log shows that the engine is reading the argument, but it doesn't seem to be passed to the cloud utils correctly.; ```; 14:23:16.753 INFO PrintReads - GCS max retries/reopens: 20; 14:23:16.753 INFO PrintReads - Requester pays: enabled. Billed to: broad-dsde-methods; 14:23:16.753 INFO PrintReads - Initializing engine; 14:23:18.501 INFO PrintReads - Shutting down engine; [September 23, 2019 2:23:18 PM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=375914496; code: 400; message: Bucket is requester pays bucket but no user project provided.; reason: required; location: null; retryable: false; com.google.cloud.storage.StorageException: Bucket is requester pays bucket but no user project provided.; ```. `gsutil -u 222581509023 stat gs://fc-secure-2011b97c-a9c9-4a13-8911-f3833be31253/CCDG_WashU_CVD_EOCAD_METSIM_WGS_all/2893803451.cram` works and `gsutil stat gs://fc-secure-2011b97c-a9c9-4a13-8911-f3833be31253/CCDG_WashU_CVD_EOCAD_METSIM_WGS_all/2893803451.cram` produces; ```; BadRequestException: 400 Bucket is requester pays bucket but no user project provided.; ```. I tried the above variations on `export GOOGLE_CLOUD_PROJECT=` in the shell, but that didn't change things. It's possible I missed some combination of the above, but at the very least our docs need clarification.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6179:57,access,access,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6179,3,"['access', 'secur']","['access', 'secure-']"
Security,"Using underlying functionality from GenomicsDB to validate/specify cloud url's for GenomicsDB workspaces. This allows for the specification of s3 and azure blob storage uri's in addition to gcs for GenomicsDB workspaces. Currently, there are no tests for s3/az uri's, this is just experimental functionality available if needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7271:50,validat,validate,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7271,1,['validat'],['validate']
Security,UvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NhbGxDb3B5UmF0aW9TZWdtZW50cy5qYXZh) | `100% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `75.51% <ø> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `69.231% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...tute/hellbender/tools/AnnotatePairOrientation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Bbm5vdGF0ZVBhaXJPcmllbnRhdGlvbi5qYXZh) | `96.429% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/tools/GatherVcfsCloud.java](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9HYXRoZXJWY2ZzQ2xvdWQuamF2YQ==) | `70.811% <ø> (ø)` | `40 <0> (ø)` | :arrow_down: |; | [...lbender/tools/spark/pathseq/PathSeqBuildKmers.java](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFCdWlsZEttZXJzLmphdmE=) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...tools/spark/validation/CompareDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay92YWxpZGF0aW9uL0NvbXBhcmVEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `82.927% <ø> (ø)` | `24 <0> (ø)` | :arrow_down: |; | ... and [92 more](https://codecov.io/gh/broadinstitute/gatk/pull/3880?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3880#issuecomment-347373155:3616,validat,validation,3616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3880#issuecomment-347373155,1,['validat'],['validation']
Security,VCF file names in validateSequenceDictionaries,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/660:18,validat,validateSequenceDictionaries,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/660,1,['validat'],['validateSequenceDictionaries']
Security,VCF row validation error on gCNV results,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8834:8,validat,validation,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8834,1,['validat'],['validation']
Security,VET Ingest Validation / Allow Ingest of non-VQSR'ed data,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7870:11,Validat,Validation,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7870,1,['Validat'],['Validation']
Security,VS 923 add validation to cluster creation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8581:11,validat,validation,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8581,1,['validat'],['validation']
Security,VS-1433 add vcf validator to tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8903:16,validat,validator,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8903,1,['validat'],['validator']
Security,VS-1433.; This PR adds the tool vcf-validator to our variants docker and uses it in our integration test.; It validates that the VCFs have no errors in the `AD` field (which were previously reported by AoU friends).; It also modifies the Beta integration test to only run on WGS samples (previously ran on all samples). Passing Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/0c9fb830-7831-4bee-a82c-d0146b250e59).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8903:36,validat,validator,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8903,2,['validat'],"['validates', 'validator']"
Security,VS-402. Add VAT Validation check that aa_change and exon_number are consistentally set.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7850:16,Validat,Validation,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7850,1,['Validat'],['Validation']
Security,VS-775 vat validation shards,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8175:11,validat,validation,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8175,1,['validat'],['validation']
Security,"Valentin & I discussed this in person just now, with the following results:. -The various *Context objects should probably be refactored to return empty lists upon lack of input, as Valentin suggested, instead of being `Optional`. -There may be a need to allow tools to request additional context around the current locus/interval, but tools should probably not be performing arbitrary queries as a general rule, since it would be difficult or impossible to optimize a traversal in which the access pattern is random. If a tool needs to group disparate data items together (eg., mates on different contigs), there should be an initial grouping step to prepare the required data for the main analysis, instead of random queries within the main analysis. -apply()/map() should take its inputs as parameters instead of directly accessing member variables into which input data has been injected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76805735:492,access,access,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76805735,3,"['access', 'inject']","['access', 'accessing', 'injected']"
Security,Validate GenotypeGVCFs walker for production use (with palantir and/or short variants team help),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2071:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2071,1,['Validat'],['Validate']
Security,Validate SVCallRecord coordinates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7714:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7714,1,['Validat'],['Validate']
Security,Validate all existing test BAMs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569,1,['Validat'],['Validate']
Security,Validate state utility method,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2543:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2543,1,['Validat'],['Validate']
Security,Validate the tiebreaking code for MarkDuplicatesSpark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4707:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4707,1,['Validat'],['Validate']
Security,Validate the walkers BaseRecalibrator/ApplyBQSR for production,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1413:0,Validat,Validate,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1413,1,['Validat'],['Validate']
Security,ValidateBasicSomaticShortMutations will validate variants with reads in the validation normal,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5059:0,Validat,ValidateBasicSomaticShortMutations,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5059,3,"['Validat', 'validat']","['ValidateBasicSomaticShortMutations', 'validate', 'validation']"
Security,ValidateSamFile shows no errors with the bam.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2113#issuecomment-242510056:0,Validat,ValidateSamFile,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2113#issuecomment-242510056,1,['Validat'],['ValidateSamFile']
Security,ValidateVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/314:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/314,1,['Validat'],['ValidateVariants']
Security,ValidateVariants + tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/314:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/314,1,['Validat'],['ValidateVariants']
Security,ValidateVariants exception message improvement,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6076:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6076,1,['Validat'],['ValidateVariants']
Security,"ValidateVariants gVCF mode error ""covers a position previously traversed""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6023:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6023,1,['Validat'],['ValidateVariants']
Security,"ValidateVariants give an `IllegalArgumentException` if a reference isn't provided. . It should be a `UserException`. I don't know but I think there may be modes that don't require the reference, so it may need to give a smart error message. ```; gatk-launch ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.119 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/louisb/Workspace/gatk/build/install/gatk/lib/gkl-0.4.1.jar!/com/intel/gkl/native/libgkl_compression.dylib; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf --doNotValidateFilteredRecords false --warnOnErrors false --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Def",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,7,"['Validat', 'validat']","['ValidateVariants', 'validationExampleGood']"
Security,ValidateVariants gvcf validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3445:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3445,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,ValidateVariants is smarter about when a reference is and is not required. Closes #2509.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2649:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2649,1,['Validat'],['ValidateVariants']
Security,ValidateVariants memory usage is high when using a gvcf as the interval list,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8608:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8608,1,['Validat'],['ValidateVariants']
Security,ValidateVariants should have a flag to validate based solely on VCF spec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6553:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6553,2,"['Validat', 'validat']","['ValidateVariants', 'validate']"
Security,ValidateVariants should validate counts of info-field annotation values,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,2,"['Validat', 'validat']","['ValidateVariants', 'validate']"
Security,ValidateVariants silently does no validation in use common cases,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5862:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,ValidateVariants throws IllegalArgumentException if a reference isn't provided,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,ValidateVariants: Error reports last (not first) overlapping interval,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103:0,Validat,ValidateVariants,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103,1,['Validat'],['ValidateVariants']
Security,Validation of sequence dictionaries from multiple BAMs now throws warning instead of exception in CNV workflows.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4758:0,Validat,Validation,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4758,1,['Validat'],['Validation']
Security,Validation stringency is ignored in LoadReadsFromFileFn,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/745:0,Validat,Validation,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/745,1,['Validat'],['Validation']
Security,Validation tests for on-the-fly .gz/.tbi creation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3056:0,Validat,Validation,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3056,1,['Validat'],['Validation']
Security,VariantWalker / VariantContext doesn't validate variants at parse-time,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5867:39,validat,validate,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5867,1,['validat'],['validate']
Security,"Variants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:2892,Validat,ValidateVariants,2892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,2,"['Validat', 'validat']","['ValidateVariants', 'validation']"
Security,Variants Processed Variants/Minute; 14:55:54.857 INFO FilterMutectCalls - Starting pass 0 through the variants; 14:56:05.368 INFO ProgressMeter - 1:2019484 0.2 16000 91332.9; 14:56:15.521 INFO ProgressMeter - 1:4008750 0.3 35000 101621.1; 14:56:26.027 INFO ProgressMeter - 1:5856032 0.5 55000 105867.6; ...; 19:37:05.295 INFO ProgressMeter - GL000209.1:48811 281.2 30739000 109323.8; 19:37:15.543 INFO ProgressMeter - GL000224.1:65537 281.3 30758000 109324.9; 19:37:25.847 INFO ProgressMeter - GL000248.1:21736 281.5 30768000 109293.8; 19:37:25.906 INFO FilterMutectCalls - Finished pass 0 through the variants; 19:50:04.590 INFO FilterMutectCalls - Shutting down engine; [9 January 2020 7:50:04 PM] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 294.19 minutes.; Runtime.totalMemory()=14966849536; java.lang.IllegalArgumentException: Values in probability array sum to a negative number NaN; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:731); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeSumToOne(MathUtils.java:731); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.performEMIteration(SomaticClusteringModel.java:336); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:306); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:158); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:159); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.Com,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-572799341:4269,validat,validateArg,4269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-572799341,1,['validat'],['validateArg']
Security,"Variants with the `-no-overlaps` option, a USER ERROR is outputted after the entire tool finishes running, as shown below:. ```; ***********************************************************************. A USER ERROR has occurred: This GVCF contained overlapping reference blocks. The first overlapping interval is [genomic coordinates here]. ***********************************************************************; ```. This error should be generally helpful, but it appears that the interval that is reported in the error message is the _last_ overlapping interval, not the _first_. I'm not super familiar with java, but I'm guessing that `firstOverlap` might be continuously replaced by `refInterval` if there are multiple overlaps, which is inconsistent with expected behavior. . Potentially relevant lines of code: ; - `-no-overlaps` argument description ([lines 192-201](; https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L192-L201)); - `firstOverlap = refInterval` ([line 275](https://github.com/broadinstitute/gatk/blob/ca33bc953abfa7050b791f049285f5262675cf84/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ValidateVariants.java#L275)). #### Steps to reproduce. Running ValidateVariants with the `-no-overlaps` flag on a .g.vcf with overlapping intervals will cause this error. More specifically, we're running this within WARP's Exome Germline Single Sample v.3.1.7 WDL release. Our command is as follows:. ```; gatk --java-options ""-Xms6000m -Xmx6500m"" \; ValidateVariants \; -V /path/to/our/.g.vcf.gz \; -R /path/to/our/.fa \; -L /path/to/our/.interval_list \; -gvcf \; --validation-type-to-exclude ALLELES \; --dbsnp /path/to/our/.vcf.gz \; --no-overlaps; ```. #### Expected behavior. The error message should report the _first_ overlapping interval. #### Actual behavior; The error message is reporting the _last_ overlapping interval.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103:1633,Validat,ValidateVariants,1633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103,4,"['Validat', 'validat']","['ValidateVariants', 'validation-type-to-exclude']"
Security,"Variants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 INFO LeftAlignAndTrimVariants - Start Date/Time",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:1059,authenticat,authenticated,1059,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494,1,['authenticat'],['authenticated']
Security,"Version:4.alpha.2-170-g8d06823-SNAPSHOT; 19:03:42.998 INFO ValidateSamFile - Defaults.BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.COMPRESSION_LEVEL : 1; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_INDEX : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_MD5 : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CUSTOM_READER_FACTORY : ; 19:03:42.999 INFO ValidateSamFile - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 19:03:42.999 INFO ValidateSamFile - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.REFERENCE_FASTA : null; 19:03:43.000 INFO ValidateSamFile - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.000 INFO ValidateSamFile - Initializing engine; 19:03:43.000 INFO ValidateSamFile - Done initializing engine; ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 24466, Read name 20FUKAAXX100202:7:46:13035:77621, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97940, Read name 20FUKAAXX100202:5:7:21464:86224, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97955, Read name 20GAVAAXX100126:5:7:1291:122571, bin field of BAM record does not equal value comp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:1816,Validat,ValidateSamFile,1816,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,1,['Validat'],['ValidateSamFile']
Security,VsdHMuamF2YQ==) | `84.615% <ø> (ø)` | `22 <0> (ø)` | :arrow_down: |; | [...adinstitute/hellbender/tools/exome/PadTargets.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9QYWRUYXJnZXRzLmphdmE=) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...hellbender/tools/genome/SparkGenomeReadCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWUvU3BhcmtHZW5vbWVSZWFkQ291bnRzLmphdmE=) | `91.089% <ø> (ø)` | `18 <0> (ø)` | :arrow_down: |; | [...egmentation/PerformAlleleFractionSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9zZWdtZW50YXRpb24vUGVyZm9ybUFsbGVsZUZyYWN0aW9uU2VnbWVudGF0aW9uLmphdmE=) | `88.889% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `88.542% <ø> (ø)` | `28 <0> (ø)` | :arrow_down: |; | [...ute/hellbender/tools/exome/ConvertACNVResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9Db252ZXJ0QUNOVlJlc3VsdHMuamF2YQ==) | `87.805% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...idation/AnnotateVcfWithExpectedAlleleFraction.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQW5ub3RhdGVWY2ZXaXRoRXhwZWN0ZWRBbGxlbGVGcmFjdGlvbi5qYXZh) | `96.429% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...tools/exome/convertbed/ConvertBedToTargetFile.java](https://codecov.io/gh/broadinstitute/gatk/pull,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3135#issuecomment-309876624:2684,validat,validation,2684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3135#issuecomment-309876624,1,['validat'],['validation']
Security,WDLs failing validation 😿,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8261#issuecomment-1483440501:13,validat,validation,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8261#issuecomment-1483440501,1,['validat'],['validation']
Security,"WGS validations are done and still look fine. @LeeTL1220 want to run your validations? 4.0.12.0 Docker + override jar should do the trick. In any case, I think the review can proceed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454765304:4,validat,validations,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454765304,2,['validat'],['validations']
Security,"WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.000 INFO ValidateSamFile - Initializing engine; 19:03:43.000 INFO ValidateSamFile - Done initializing engine; ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 24466, Read name 20FUKAAXX100202:7:46:13035:77621, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97940, Read name 20FUKAAXX100202:5:7:21464:86224, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97955, Read name 20GAVAAXX100126:5:7:1291:122571, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 112212, Read name 20GAVAAXX100126:8:1:1429:129840, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 126595, Read name 20FUKAAXX100202:6:46:9311:1219, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ...; ERROR: Read name 20FUKAAXX100202:3:66:14857:5877, Mate not found for paired read; ERROR: Read name 20GAVAAXX100126:3:42:3602:56427, Mate not found for paired read; ERROR: Read name 20FUKAAXX100202:3:43:9956:132423, Mate not found for paired read; ERROR: Read name 20GAVAAXX100126:5:28:11981:2516, Mate not found for paired read; ERROR: Read name 20FUKAAXX100202:6:24",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:2065,Validat,ValidateSamFile,2065,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,1,['Validat'],['ValidateSamFile']
Security,"We already added the functionality needed for the gCNV workflow to IntervalListTools in https://github.com/broadinstitute/picard/pull/1208. The issue is that the tool outputs each scattered interval list to a separate directory if the number of scatters is greater than 1, but it just outputs to a file (essentially a noop) if we don't need to scatter. Not sure the reason for this design, but it makes things difficult from the perspective of WDL. Would be easier if the expected output was always `Array[File]+`. I don't really see why IntervalListTools needs to create those intermediate directories (nor why the naming scheme is determined by `DecimalFormat(""0000"")`---don't think this is documented, either), but I am not sure if that behavior is expected by now or if it is safe to modify it. Pretty sure SplitIntervals is just calling the same backend class used by IntervalListTools. Perhaps that tool might've been spun off before we exposed the Picard tools? See e.g. https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435588845. I think we should try to avoid writing such custom/utility GATK tools unless really warranted.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6502#issuecomment-599639907:943,expose,exposed,943,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6502#issuecomment-599639907,1,['expose'],['exposed']
Security,"We also have to audit the data to identify private data, and replace or sanitize.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2063#issuecomment-235997161:16,audit,audit,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2063#issuecomment-235997161,2,"['audit', 'sanitiz']","['audit', 'sanitize']"
Security,"We can split the tests up into a bunch of build units, but we get rapidly diminishing returns since we spend minutes installing things and building the artifacts for every vm. Travis doesn't have any notion of a build pipeline, so we can't say ""build the artifact on 1 vm and then share it and run the tests on these 10 vms"". Since we have a hard limit of the number of VMs we can use at a time for DSDE ( currently 15) being less efficient is very bad news. ( We could of course pay for more... I recently asked travis support if we could switch to an unlimited pay for usage model and they said no. ) We could also try optimizing wasted vm time by prebuilding dockers to run in, but that's additional complication. (maybe not to much, might be worth it). We also would need a scheme for dividing tests evenly between VM's. I tried writing a testng test listener to distribute them between N nodes based on the hashcode of the test class, for use on circleci, but it fell over and exploded for some reason that I never debugged. We could either debug it, or possibly split the tests by splitting the list of test files and then passing those in specifically. (May run into character limits for command lines... ). Balancing it is going to be tricky though in any case since the tests are very unevenly expensive. (We could probably manually balance it since there are a small number of slow tests and the rest are so fast they don't really matter) . The easiest thing would be to set the test to run in parallel on their existing vm. I can try turning it on again. I remember it caused problems before though, which I assume we haven't addressed. Each vm has 2 cores, so we might see some speedup. I suspect we may be using both cores to some degree already, since performance nearly doubled when we switched from the 1 core to 2 core build machines. We could probably build a more efficient pipeline on jenkins if we wanted since it does have a notion of pipelines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1769#issuecomment-214492346:912,hash,hashcode,912,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1769#issuecomment-214492346,1,['hash'],['hashcode']
Security,"We found an issue with the way GKL was freeing an internal data structure. The issue was exposed by the `IntelInflaterIntegrationTest`, which uses the Inflater API in a different way than HTSJDK and GATK. We've fixed that issue and the GATK integration tests pass. We're releasing GKL 0.4.1 now and will update this PR when 0.4.1 is available in Maven Central.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282325096:89,expose,exposed,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282325096,1,['expose'],['exposed']
Security,"We found this trying to tie out the BQ version of the VQSR annotations with the Evoquer+Gnarly outputs, specifically in the RankSumTest annotations. This never got merged into master. The short story is... the implementation of median in the Histogram class is broken. Precisely, in this line it iterates through the bins of the histogram to find the midpoint index... however the keySet() it gets is from a HashMap and therefore not ordered. That code hasn't been touched in 2 years, so it's been this way for a while. It's tough to catch because of course there is a non-guaranteed ordering to the keys, and in the case of hashmap today when there are < 16 keys will be the hashcode of the keys modulo 16 until there is collision. The hashcode of integers is just the integer... so in our tests we have today it just happens to work because we have a small number of keys and they are close to each other so hash in the order we happen to want. I learned more about [HashMap internals](http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/687fd7c7986d/src/share/classes/java/util/HashMap.java) than I wanted to know in order to make a test case for it :/ . I. A test on data like this breaks:. 1,2,16. as it returns 1 instead of 2 as the median. I have a test for this, and have a fix (basically sort the keys, running through a TreeSet). Thanks to @mmorgantaylor and @schaluva for helping with this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7131:408,Hash,HashMap,408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7131,7,"['Hash', 'hash']","['HashMap', 'hash', 'hashcode', 'hashmap']"
Security,We had already planned to remove this limitation. The limitation comes from using an older version of TileDB in GenomicsDB. The latest version of TileDB has an API called array_move() to do this correctly which we will expose in GenomicsDB.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320304844:219,expose,expose,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320304844,1,['expose'],['expose']
Security,"We have a tool, VariantQC, that extends VariantEval. This PR is a minor refactor to expose the code that creates the list of VariantStratifier and VariantEvaluator objects as protected methods, so subclasses could modify them. This should have no functional difference on VariantEval itself. We're hoping to use these changes in order to adapt our tool in response to reviewers, so if there is any way to push these changes we would appreciate it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5998:84,expose,expose,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5998,1,['expose'],['expose']
Security,"We have access to data that should reproduce this issue, but can't post it here because it's not publicly shareable BAMs. Please let me know how I can share the data if someone decides to look at this issue. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5513#issuecomment-446315089:8,access,access,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5513#issuecomment-446315089,1,['access'],['access']
Security,We have run this tools successfully with a number of crams and bam at this point so we will need access to the data to reproduce the issue on our end. Would that be possible @jjfarrell?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182#issuecomment-819635502:97,access,access,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182#issuecomment-819635502,1,['access'],['access']
Security,"We have the basic DREAM somatic challenge, but there's also an RNA challenge, and perhaps others. If it's a similar format of bams, masks, and truth vcfs it would be really easy to set up a validation like the one we currently have on Firecloud.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5427:190,validat,validation,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5427,1,['validat'],['validation']
Security,"We have to keep on top of the times. These are changes we pushed for, so; we can access genomic positions through the same interface on features,; intervals, and samrecords.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/330#issuecomment-85740663:81,access,access,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/330#issuecomment-85740663,1,['access'],['access']
Security,"We just merged PR #5562, which addresses one of @munrosa's missed calls. I am investigating the harder fix of threading in both directions from the first unique kmer. It seems that there is nothing fundamentally wrong with this change, but it exposes mapping artifacts that we have never had to handle before. I think I know how to address these but it will take a while. Maybe two months, though it's hard to guess.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-468028441:243,expose,exposes,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-468028441,1,['expose'],['exposes']
Security,"We need a tool to compare multiple references and spit out a TSV (or similar) detailing what the differences are. Additionally it should be able to spit out a liftover file that will properly move a variant from one reference to another. We should first compare the sequence dictionaries in the references to see if they have equal lengths and checksums - the names may differ and we should track this so we can definitively say which contigs are equivalent. After this, we should walk the references and find out specifically which bases differ between contigs that have different checksums (with some limits on the number of differences between them so we don't get bogged down by `hg19` vs `hg38` comparisons). ; Then it should create a liftover file from those comparisons so the data can be easily converted between the references given. . Additionally, it should be able to take a variant file and a set of references and say:. - whether the variant file ""belongs"" to one of the given references; - if it isn't exactly from one of the given references, which reference is closest; - _optionally_: a lifted-over version of that VCF to the closest reference (with a bunch of warnings, if applicable). This will finally lay to rest the questions raised by [my blog post about ""HG19""](https://gatk.broadinstitute.org/hc/en-us/articles/360035890711). I believe Adam Phillipy had created a perl script that does something similar to this, but a brief view of his github page doesn't show anything like that anymore (maybe it was called `refdiff` or similar). I created a bash script that does something similar to this (see attached), but it only looks at the sequence dictionaries. It produces a table similar to that in the above blog post. For example:. |MD5 | HG38(Homo_sapiens_assembly38.dict) | HG38_WEIRD(genome.hg38rg.fa.dict)|; | --- | --- | --- |; |1e95e047b98ed92148dd84d6c037158c|chr1_KI270708v1_random|1_KI270708v1_random|; |42f7a452b8b769d051ad738ee9f00631|chr1_KI270714v1_random|1_KI270",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6837:344,checksum,checksums,344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6837,2,['checksum'],['checksums']
Security,"We need the ability to store command-line argument definitions in @ArgumentCollections like in the GATK, to avoid duplicate definitions, and to provide a standard way of accessing the argument values.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/96:170,access,accessing,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/96,1,['access'],['accessing']
Security,"We need to add a validation check to ensure that any read input file contains a header (since they're technically optional). There are code paths that assume that a header/sequence dictionary is always present (i.e., some of the SplitReads tests get NPEs if presented with one).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2334:17,validat,validation,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2334,1,['validat'],['validation']
Security,We need to look into Java 8 java.util.stream for accessing Read and Variant data,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9:49,access,accessing,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9,1,['access'],['accessing']
Security,We need to understand the data access patterns in the existing engines: Picard/GATK/Foghorn; @lbergelson and @kshakir already started doing it. Can you move the list here?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1:31,access,access,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1,1,['access'],['access']
Security,"We noticed today that there's no way in GATK4 to change the sigma of the band pass filter Gaussian kernel in `AssemblyRegionWalker`, even though `maxProbPropagationDistance` is settable. For consistency's sake, we should expose the band pass sigma via an arg as well.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5387:221,expose,expose,221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5387,1,['expose'],['expose']
Security,"We recently discovered that some of the tests we didn't think required google cloud authentication require that gcloud be initialized. Travis didn't catch this because we always initialize gcloud in order to do log uploading. We should change this so it's only initialized during the tests for the cloud tests. . The actual error we discovered didn't require that credentials be correct, only that a default project had been configured so simply logging out isn't enough to trigger it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2706:84,authenticat,authentication,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2706,1,['authenticat'],['authentication']
Security,"We should audit the plugin system (and add tests) to ensure that crazy combinations of enable/disable arguments (like `--readFilter` and `--disableReadFilter`) are disallowed, while useful combinations are permitted. Here's my attempt at an initial proposal:. `--enable X --disable X`: crazy, should be an error. `--enable X --enable X`: error. `--disable X --disable X`: error. `--enable X when X is already on by default in the tool`: warning, but should be allowed -- this is useful for pipeline authors to guarantee that a particular filter will be on, even if tool defaults change over time. We should make sure that the filter is only actually applied ONCE, however. `--disable X when X is not enabled by default in the tool`: warning, but should be allowed -- this is useful for pipeline authors to guarantee that a particular filter will be off, even if tool defaults change over time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2377:10,audit,audit,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2377,1,['audit'],['audit']
Security,We should currently be able to broadcast .2bit references stored in GCS buckets in the cloud. Whether it makes sense to do this vs. accessing the reference directly via GCS or the Google reference API is a topic for a future comparison.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1203#issuecomment-213150557:132,access,accessing,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1203#issuecomment-213150557,1,['access'],['accessing']
Security,"We should expose a `getSource()` method at the GATKRead level, and have GATK delegate to `samRecord.getFileSource()` in the `SAMRecord` case. We might need to do something extra to get HTSJDK to populate this field for us. Use case is a ReadsDataSource backed by multiple bam/cram inputs, with the reads merged into a single sorted stream, and the tool needing to be able to tell where each read came from. Can't always use read groups / sample names to accomplish this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8671#issuecomment-1919937519:10,expose,expose,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8671#issuecomment-1919937519,1,['expose'],['expose']
Security,"We use the GATKGCSOptions class to hold GCP authentication. It inherits from the Dataflow hierarchy and works well there, but since it doesn't implement Serializable it's cumbersome to work with in Spark. We've created AuthHolder as a replacement. It can do all the things GATKGCSOptions can do, and more (well, except for holding Dataflow debug options but we don't need that anymore). Once #978 is merged in, we need to migrate the code from GATKGCSOptions to AuthHolder. One benefit is that this will allow the Spark code to support client-secrets.json (for access to private GCS files, unlike the API key which only grants access to world-readable GCS files).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1002:44,authenticat,authentication,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1002,3,"['access', 'authenticat']","['access', 'authentication']"
Security,"We want something like a hosted jenkins server to run parts of the test suite that can't or shouldn't be run in travis. This includes:. -Long-running validation tests, like those designed by @davidadamsphd for the `ReadsPipelineSpark`; -Tests involving reading data from HDFS.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1400:150,validat,validation,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1400,1,['validat'],['validation']
Security,We were seeing failures on spark clusters that manifested as being; unable to find the Main class while running spark submit. The caused was the accidental introduction of a jar signature file; and key from the transitive gnu.getopt dependency. This was causing; signature validation failures since our uber jar did not match the; expected hashes. Fixed by excluding .SF and .RSA files from our jars.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618:273,validat,validation,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618,2,"['hash', 'validat']","['hashes', 'validation']"
Security,"We will commit this separately, but I don't want to do that until we validate that it actually solves the problem for the other branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7219#issuecomment-827765900:69,validat,validate,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7219#issuecomment-827765900,1,['validat'],['validate']
Security,We're having issues with all of our tests today. Github is refusing our git-lfs requests because they're over quota and we need to figure out how to either authenticate our requests in a safe way from travis or figure out why we're suddenly going over quota. It happened very suddenly and I suspect there might be an issue on github's end..,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-292005363:156,authenticat,authenticate,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-292005363,1,['authenticat'],['authenticate']
Security,"We're marking all of these as bucket for now @lbergelson to unblock our work (with the exception of the `PSUtilsUnitTest`). They require authentication now, so need to be properly marked. The underlying issue should ultimately be fixed by https://github.com/broadinstitute/gatk/issues/958",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2706#issuecomment-300815096:137,authenticat,authentication,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2706#issuecomment-300815096,1,['authenticat'],['authentication']
Security,"We're seeing a lot of failures of the form:. ```; com.google.cloud.storage.StorageException: 806222273987-uilktks3j6i7962rp0v7nusveer58497@developer.gserviceaccount.com does not have serviceusage.services.use access to project 685190392835.; Caused by:; shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""806222273987-uilktks3j6i7962rp0v7nusveer58497@developer.gserviceaccount.com does not have serviceusage.services.use access to project 685190392835."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""806222273987-uilktks3j6i7962rp0v7nusveer58497@developer.gserviceaccount.com does not have serviceusage.services.use access to project 685190392835.""; }; ```. It looks like it now requires some new permission for the service accounts but our existing service account doesn't have that permission.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-511986926:209,access,access,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-511986926,3,['access'],['access']
Security,We've been encountering transient 403 errors when using GCS NIO.; It seems that some GCS-related service is incorrectly returning 403 in; certain cases where we do actually have permission to access a resource.; This commit moves us to a google-cloud-java snapshot that retries upon; 403 errors:. https://github.com/droazen/google-cloud-java/commit/6d11bef1c81f885c26b2b56c8616b7a705171e4f. Resolves #3735,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3766:192,access,access,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3766,1,['access'],['access']
Security,We've been hit with a collective case of confusion. Of course this is going to fail. We're accessing a file on **local**. This is not visible to the executors on the other nodes. Thus the explosion.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1417#issuecomment-175758473:91,access,accessing,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1417#issuecomment-175758473,1,['access'],['accessing']
Security,"We've been using 4.beta.6 to generate new callsets because it has the GenomicsDBImport batching fix and it seems to have introduced transient Auth errors that production was not seeing before. This happens a maybe one shard at every task level and when rerun usually succeeds but as you can imagine is pretty annoying. This happens across multiple tools (GenomicsDBImport, GatherVcfs). Sometimes we get this as the only response from GATK when this happens. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't read file. Error was: Failure while waiting for FeatureReader to initialize with exception: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-gotc-prod-storage/pipeline/G101956/gvcfs/DDP_ATCP_42_1.4afb46bb-4009-47c4-9aa0-407e92de0db8.g.vcf.gz. ***********************************************************************; ```. and other times we get a nice stacktrace for this issue. ```; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.IOUtil.transferByStream(IOUtil.java:141); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.gatherWithBlockCopying(GatherVcfsCloud.java:394); 	at org.broadinstitute.hellbender.tools.GatherVcfsCloud.doWork(GatherVcfsCloud.java:143); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735:807,access,access,807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735,1,['access'],['access']
Security,"We've discovered a number of bam files being used in tests which are not valid BAM files. We should go through all the checked in BAMs, validate them, and replace broken ones. (Except ones that are intentionally broken for testing.) . (added later by @akiezun); In particular, copied from https://github.com/broadinstitute/hellbender/issues/568, NA12878.chr17_69k_70k.dictFix.bam has a problem:; whoever fixes this ticket needs to take care of this input. `htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 129, Read name 809R9ABXX101220:5:6:17918:145992, Mate Alignment start should be 0 because reference name = *.`. Here's the corresponding read:; `809R9ABXX101220:5:6:17918:145992 97 17 69400 37 67M9S * 71202348 0 ACTCCCCACCTTACCTGACTCCTTCCAGGGTTTGTCGCCTTTCCGGTCCCTGACCCCAGTGGATGGGAGTCTGTCC ?ABDDEEABEECBDBDAB=DEDCDEEBFADABCEAD?EEEDCFE?ABEEE@FCDEEEBF@F?CA4@@########## UQ:i:0`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569:136,validat,validate,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569,2,['validat'],"['validate', 'validation']"
Security,"We've had to do that in other places... On Fri, Jan 12, 2018 at 3:20 PM, samuelklee <notifications@github.com>; wrote:. > To be clear, this will work perfectly fine as long as you have enough; > space in /dev/shm---which is typically true everywhere outside of our; > default Docker container.; >; > I'm loath to cripple a tool just because of limitations that are; > fundamentally elsewhere...let's just address those in the appropriate; > places. (Furthermore, I'm especially loath to write a plotting tool that; > takes ~5 minutes to generate a plot!) And yes, while it is not great that; > data.table forces us to use /dev/shm, I think fread(""grep ..."") is; > relatively standard.; >; > If --shm-size is indeed not exposed, why doesn't the Google backend scale; > /dev/shm or other tmpfs space with requested machine memory?; >; > If there really is no other way around it, then all we're doing is; > filtering out the lines beginning with @. We could do this first by; > calling system commands within R to write to a temporary file, and then; > reading that back in with fread. This seems hacky to me, but I've confirmed; > that it works within the Docker. This will solve our immediate problem, but; > I still think it's worth taking a look at those other limitations elsewhere; > now as well.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkxNvcMcJfIhdlPhdU3vLHTiAVPPSks5tJ76mgaJpZM4RclpR>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357349198:719,expose,exposed,719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357349198,1,['expose'],['exposed']
Security,"Well, when the `clearItems` call is removed from the `consumeFinalizeItems` else branch, some `HaplotypeCallerSparkIntegrationTest`s [fail](https://api.travis-ci.com/v3/job/173147001/log.txt) because `PushToPullIterator` doesn't call clearItems to reset the state when `consumeFinalizeItems` returns no items, and the next submit is rejected because eoi hasn't been reset. So, since `consumeFinalizeItems` can't reset/mutate the state when there are no items, then we can't assert the precondition that `endOfInput==false` in `submit`. So I'm removing the validation of that from both `ReservoirDownsampler` and `PositionalDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723:556,validat,validation,556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723,1,['validat'],['validation']
Security,"Well, you're welcome to use gatk-launch as a launch script if you'd like (and feel free to rename to whatever you like...) A. There are a few reasons we have spark and non-spark versions of the tools. . 1. We wanted to port and validate certain tools as quickly as possible and doing a direct port from gatk3 -> gatk4 was easier than making them sparkified at the same time. 2. There's a tradeoff in using spark where you end up spending more total cpu hours in order to finish a job faster. Ideally this would be 1:1, double the number of cores and you halve the time to finish a job. It never scales perfectly though, there's always some overhead for being parallel. Our production pipelines are extremely sensitive to cost and not very sensitive to runtime, so they prefer we have a version that's optimized to use the least cpu hours even if that means a longer runtime. Other users prefer to be able to finish a job quickly and are willing to pay slightly more to do so, so we also have a spark version. . 3. Some tool are complicated to make work well spark. Spark works best when you can divide the input data into independent shards and then process them separately. This is complicated for things like the AssemblyRegion walker where you need context around each location of interest. We had to do things like add extra overlapping padding and things like that to avoid boundary issues where there are shard divisions. We don't yet fully understand spark performance and it's caveats, we're looking into that actively now. We hope that we'll be able to optimize our tools so that a spark pipeline of several tools in series is faster than running the individual non-spark versions, since it lets us avoid doing things like loading the bam file multiple times from disk. Whether or not we can achieve this is still and open question though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273318100:228,validat,validate,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273318100,1,['validat'],['validate']
Security,What about a light subclass ValidatedGenomeLoc? Looser tools can use GenomeLoc and stricter ones ValidatedGenomeLoc. Alternately: GenomeLoc.isValidated(),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69766896:28,Validat,ValidatedGenomeLoc,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100#issuecomment-69766896,2,['Validat'],['ValidatedGenomeLoc']
Security,"When I was trying to use user exceptions in a consistent way independently of the constructor (mostly related with files), I found very weird behaviour with the messages. Here I try to fix some of the things that I was struggling with:. * Support for path in constructors for `CouldNotReadInputFile`, `CouldNotCreateOutputFile`, `MalformedFile` and `MalformedBAM`, in addition to some missing constructors to have the same structure for all of them (with `File` and/or `String`).; * ~~Updated javadoc in `CommandLineException`, including extending classes to make clear that in the GATK framework is not printed out if it is thrown out of parameter validation.~~ __Edited__: this is not longer required, because `CommandLineException` is decoupled from `UserException` through barclay.; * Added a TODO into the `MalformedBAM` constructor that includes a `GATKRead` that is not used.; * __Edited__: added final to constructors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282:649,validat,validation,649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282,1,['validat'],['validation']
Security,"When `ReadPosRankSumTest.getReadPosition` encounters the second of two deletions with two bases in between it hits the following code:; ```; if ( AlignmentUtils.isInsideDeletion(read.getCigar(), offset) ) {; return OptionalDouble.of(INVALID_ELEMENT_FROM_READ);; }; ```; which returns negative infinity. Those with TCGA access can reproduce the issue by running on the TCGA exome pair ESCA-IG-A3YB-TP-NB at 15:34525804-34525810.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5492:319,access,access,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5492,1,['access'],['access']
Security,When accessing the help output for Picard tools (example MarkDuplicates) through the gatk launch script it seems that engine level Picard arguments are not showing up in the help output (example `--TMP_DIR`). The default behavior in picard itself is to hide those engine arguments from the help output behind a special help flag `--stdhelp` which adds all of those arguments back into the help output. We should reintroduce those arguments into the GATK help output for Picard tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6811:5,access,accessing,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6811,1,['access'],['accessing']
Security,"When running GATK with specific interval(s), the default behavior is to include any variant spanning those interval(s). When running scatter/gather jobs, this behavior is generally not what one wants, since this would result in variants spanning the job intervals getting included twice. In a handful of GATK tools, there is support for something like --ignore-variants-starting-outside-interval, which is probably designed to solve this problem. GenotypeGVCFs supports this. However, the implementation/support is generally tool-level and I dont believe all tools support this. For example, SelectVariants does not appear to. If one wants to run a scatter/gather task that doesnt start with a GATK tool that supports --ignore-variants-starting-outside-interval, you're out of luck. My questions are:. 1) Am I completely missing some existing capability?. 2) There is already some low-level support in the engine for control over intervals. Would you be receptive to a PR that pushes support for ""--ignore-variants-starting-outside-intervals"" lower into GATK? Perhaps into VariantWalkerBase? One possibility would be to create a StartsWithinIntervalsVariantFilter, and override makeVariantFilter() to inject it. I dont think this would be particularly invasive, and could be pretty useful across many tools. As part of this, MultiVariantWalkerGroupedOnStart's argument would get merged with this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8063:1201,inject,inject,1201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8063,1,['inject'],['inject']
Security,"When we make enhancements to the walker engine (eg., modify the `GATKTool` base class to support CRAM, or to validate the sequence dictionaries of the inputs), it would be good if Spark tools could also reap the benefits of these changes automatically. We may need to unify (or better integrate) the `GATKTool` and `SparkCommandLineProgram` base classes somehow to make this possible, as well as classes like `ReadsDataSource` (for walkers) and `ReadsSparkSource` (for Spark tools).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/680:109,validat,validate,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/680,1,['validat'],['validate']
Security,"While a minor issue, moving to `slf4j-api` as the logging API and `slf4j-log4jxx` as the implementation would help with interoperability. For example, I'm working on a proposal for a separate library for conversions between formats, and currently the API passes in a slf4j `Logger` and an enum similar to `ValidationStringency`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-261286474:306,Validat,ValidationStringency,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-261286474,1,['Validat'],['ValidationStringency']
Security,"While using a custom tool that validates arguments (e.g., certain range for an `Integer` parameter), a way of handling it is override `CommandLineProgram.customCommandLineValidation()` and return an String with the error found. Nevertheless, if parsing the arguments throws a `UserException.CommandLineException`, the error is printed with a concrete format (`printDecoratedUserExceptionMessage`) after the usage. This is different from the custom validation, which is printed without any decoration and before the usage. Although this behavior could be desirable, I expect that if my custom validation thrown an `UserException.CommandLineException` it is printed in the same way as other exceptions, and the exception is re-thrown in the same way (for testing purposes, for instance). But the current behaviour just exit without any error printed because the exception is catched in `Main`. A very minor change is include in the `try` block the custom validation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2225:31,validat,validates,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2225,4,['validat'],"['validates', 'validation']"
Security,"While working on validating #5607 I noticed that at the top of the method `isReadInformativeOfIndelOfSize()` that there is the following breakout condition:; ```; if( read.getLength() - readStart < maxIndelSize || refBases.length - refStart < maxIndelSize ) {; return false;; }; ```; This says that if the readStart is too close to the read.getLenght() then it will break out and not calculate the informativeness of a read. Unfortunately readStart isn't the readbase indexed readStart, its actually the ""IGV view"" offset for the read generated by the pileup for a particular reference position. The actual length that matters to us is: `AlignmentUtils.getBasesAlignedOneToOne(read).length` which is computed later when we realign the read bases to the reference. What this means is that if a read happens to have a long deletion in it then we will end up prematurely marking the read bases as being non-informative despite there being more than enough bases to work with when doing computations. Furthermore, since we realign the read bases later in the codepath, these bases in the gap between the realigned length and `read.getLength()` are still used to compute mismatch likelihood for bases before that point in the read. An example of this issue: I have a read with the cigar ""77M10D24M"", at position 92 of the read (the igv offset so in reality the 5th base into the last element of the cigar) the code returns false due to this condition. In reality `AlignmentUtils.getBasesAlignedOneToOne(read).length - readStart` value is 19, and thus comparable since there are >10 bases left in the read to test. . I have duplicated this behavior in #5607, perhaps it would be easiest to get that branch in first before tackling this issue just so validation for that refactor is easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5646:17,validat,validating,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5646,2,['validat'],"['validating', 'validation']"
Security,"Will include a top-level abstract Tool class, subclasses for each of the standard traversal types (ReadWalker, LocusWalker, etc.), and a class for each kind of data source (ReadDataSource, ReferenceDataSource, etc.). Initial framework will have placeholders/stub implementations for some functionality, but will support at least traversal by reads with the ability to access overlapping reference bases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/82:368,access,access,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/82,1,['access'],['access']
Security,"With `--genomicsdb-shared-posixfs-optimizations`, the storage system should only require read access. @droazen, will work towards a fix for this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1468563326:94,access,access,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1468563326,1,['access'],['access']
Security,"With a service account key set, it worked like a charm:. ```; $ ./gatk-launch PrintReadsSpark -I gs://jpmartin-testing-project/hellbender-test-inputs/CEUTrio.HiSeq.WGS.b37.ch20.1m-2m.NA12878.bam -O gs://jpmartin-testing-project/test-output/readcount --shardedOutput true -- --sparkRunner GCS --cluster jps-test-cluster; (...); [November 20, 2017 6:17:08 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.72 minutes.; Runtime.totalMemory()=670040064; Job [13c93a62-96d0-456e-91d1-ef7b20f1236b] finished successfully.; ```. Though I understand that [this is expected](https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894). So next I tried it without any `HELLBEND*` environment variable and it worked as well!. ```; Job [6e2f2c6b-921a-4fdf-a42e-0706216b2098] finished successfully.; (...); $ gsutil ls -lh gs://jpmartin-testing-project/test-output/readcount/; 0 B 2017-11-20T18:28:27Z gs://jpmartin-testing-project/test-output/readcount/; 0 B 2017-11-20T18:28:52Z gs://jpmartin-testing-project/test-output/readcount/_SUCCESS; 120.25 MiB 2017-11-20T18:28:51Z gs://jpmartin-testing-project/test-output/readcount/part-r-00000.bam; ```. This is with `GOOGLE_APPLICATION_CREDENTIALS` set, as I believe is part of the GATK README instructions. Next I went to my repro code and tried it again with v30. It failed (`StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account.`) I'm not sure why but the new version is certainly an improvement over the previous one since it fixes `PrintReadsSpark`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-345788205:1422,secur,security,1422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-345788205,2,"['access', 'secur']","['access', 'security']"
Security,"With some tweaks I see a good improvement. . First i tried it on our testing bam (on dr_runnable_haplotypecaller) and saw some speedup:. before, in GVCF mode. ```; real 6m6.430s; user 7m54.014s; sys 0m4.540s; ```. after. ```; real 5m58.246s; user 7m53.737s; sys 0m4.403s; ```. Then I rewrote it a bit by avoiding the `new String` calls and directly using the static `lastIndexOf` method from String that works on arrays (required copying code from the Java libraries because the right method is not accessible). The result was a 30s improvement over baseline (6%). ```; real 5m44.213s; user 7m26.240s; sys 0m3.916s; ```. So that would be a nice improvement but I'm not sure if copy/pasting code from the JDK is kosher license-wise. To be completely safe, @gspowley can you implement a clean-room version of `lastIndexOf(byte[] source, byte[] target)` so that we can replace `new String(reference).lastIndexOf(new String(alternate))` with `lastIndexOf(reference, alternate)`? Or let's find a library that we can use for this. I want to avoid `String` creation here because it's pretty expensive.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1677#issuecomment-204206963:499,access,accessible,499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1677#issuecomment-204206963,1,['access'],['accessible']
Security,"With the new GCS NIO reader, it may well be preferable to access large side inputs directly in GCS buckets rather than broadcasting them. This would reduce our memory usage dramatically relative to broadcast, and if the performance is the same or better it seems like the way to go.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2015:58,access,access,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2015,1,['access'],['access']
Security,"With this addition, summarizing the results of the MC3 validation will use more GATK, less scripting.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4982:55,validat,validation,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4982,1,['validat'],['validation']
Security,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:456,secur,security,456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156,4,['secur'],['security']
Security,"With walkers it's done like this (in `GATKTool`):. ```; if (hasReference()){; // pass in reference if available, because CRAM files need it; factory = SamReaderFactory.makeDefault().validationStringency(ValidationStringency.SILENT).referenceSequence(referenceArguments.getReferenceFile());; } else if (hasCramInput()) {; throw new UserException.MissingReference(""A reference file is required when using CRAM files."");; }; ```. Unsure how to do the same for Hadoop-BAM",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1180#issuecomment-158524395:182,validat,validationStringency,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1180#issuecomment-158524395,2,"['Validat', 'validat']","['ValidationStringency', 'validationStringency']"
Security,Work with palantir and/or short variants team to validate GATK4 version of VQSR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2065:49,validat,validate,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2065,1,['validat'],['validate']
Security,"Would also be good to annotate which annotator (curr M2, HC and VA) has access to each annotation module.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344760216:72,access,access,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344760216,1,['access'],['access']
Security,Would also be good to identify what changes we'd need to make to the `broad-dsde-dev` firewall config to make this work there so that we can file a request with IT.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/975#issuecomment-148461723:86,firewall,firewall,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/975#issuecomment-148461723,1,['firewall'],['firewall']
Security,"Would it be possible to expose the [`READ_QUALITY_FILTER_THRESHOLD`](https://github.com/broadinstitute/gatk/blob/9d5727df8db3a475b1ba5f9bff6bc92a322f5633/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerEngine.java#L729) on the command line for 4.9.0.1? I know on the latest branch we have [`--mapping-quality-threshold`](https://github.com/broadinstitute/gatk/blob/7e3d8a1e0c56206345128e3a6125ecc30427deda/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerArgumentCollection.java#L153). For data and regions where we get low mapping qualities (eg. PacBio), a hard-filter on mapq 20 is onerous. I'd also echo the comment in the latter TODO that the interplay between `----mapping-quality-threshold` (new) and ` --minimum-mapping-quality` (old) is confusing upon first inspection.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7034:24,expose,expose,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7034,1,['expose'],['expose']
Security,"Would that be like a way to run ValidateSamFile as a prelude to the actual; run, without doing it separately first?. On Mon, Feb 23, 2015 at 4:34 PM, jmthibault79 notifications@github.com; wrote:. > What about a ReadValidator which takes filters and errors out when any; > don't pass?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/issues/193#issuecomment-75638957; > . ## . Geraldine A. Van der Auwera, Ph.D.; Bioinformatics Scientist II; GATK Support & Outreach; Broad Institute",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/193#issuecomment-75645241:32,Validat,ValidateSamFile,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/193#issuecomment-75645241,1,['Validat'],['ValidateSamFile']
Security,Wrapper around VC object to access SVContext specific annotations.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3476:28,access,access,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476,1,['access'],['access']
Security,"Wrote a SimpleCopyRatioCaller that is still relatively naive, but I think a bit more sensible than ReCapSegCaller. It does the following:. 1) use the non-log2 mean copy ratio to determine copy-neutral segments (those within 1 +/- x, where x is an exposed parameter),; 2) weight segments by length for determining the mean and standard deviation of the non-log2 copy ratio in copy-neutral segments,; 3) filter outlier copy-neutral segments by non-log2 copy ratio z-score,; 4) use the filtered copy-neutral segments to determine a length-weighted mean and standard deviation,; 5) call remaining segments using z-score based on this mean and standard deviation. @MartonKN take note of these changes! I am sure that your caller will still do much better, especially given the allele-fraction data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3825#issuecomment-344590576:247,expose,exposed,247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3825#issuecomment-344590576,1,['expose'],['exposed']
Security,WxlY3RWYXJpYW50c1VuaXRUZXN0LmphdmE=) | `100% <ø> (ø)` | `12 <0> (?)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `87.037% <0%> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [...te/hellbender/engine/spark/VariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvVmFyaWFudFdhbGtlclNwYXJrLmphdmE=) | `72.34% <0%> (-2.128%)` | `14 <0> (ø)` | |; | [...itute/hellbender/engine/spark/ReadWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZFdhbGtlclNwYXJrLmphdmE=) | `77.419% <0%> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [...tools/spark/validation/CompareDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay92YWxpZGF0aW9uL0NvbXBhcmVEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `84.946% <0%> (ø)` | `24 <0> (ø)` | :arrow_down: |; | [...tute/hellbender/engine/spark/LocusWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvTG9jdXNXYWxrZXJTcGFyay5qYXZh) | `77.778% <0%> (ø)` | `12 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `84% <0%> (+23%)` | `30 <0> (+14)` | :arrow_up: |; | [...ava/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-370539956:2174,validat,validation,2174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-370539956,1,['validat'],['validation']
Security,XMuamF2YQ==) | `81.818% <0%> (-3.182%)` | `18% <0%> (+1%)` | |; | [...stitute/hellbender/utils/nio/PathLineIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vUGF0aExpbmVJdGVyYXRvci5qYXZh) | `61.111% <0%> (-3.175%)` | `4% <0%> (ø)` | |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `98% <0%> (-2%)` | `71% <0%> (ø)` | |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `87.179% <0%> (-1.417%)` | `41% <0%> (+2%)` | |; | [...walkers/validation/ConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `98.601% <0%> (-1.399%)` | `8% <0%> (+2%)` | |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `91.163% <0%> (-0.426%)` | `101% <0%> (+1%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `84.892% <0%> (-0.172%)` | `256% <0%> (-4%)` | |; | [...ls/walkers/mutect/CreateSomaticPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467092164:2435,validat,validation,2435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467092164,1,['validat'],['validation']
Security,XZh) | `60.57% <100%> (ø)` | `65 <0> (ø)` | :arrow_down: |; | [...nder/tools/walkers/vqsr/FilterVariantTranches.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvRmlsdGVyVmFyaWFudFRyYW5jaGVzLmphdmE=) | `92.241% <100%> (ø)` | `42 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/funcotator/FilterFuncotations.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0ZpbHRlckZ1bmNvdGF0aW9ucy5qYXZh) | `93.103% <100%> (ø)` | `18 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/vqsr/ApplyVQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQXBwbHlWUVNSLmphdmE=) | `75% <100%> (ø)` | `55 <0> (ø)` | :arrow_down: |; | [...r/tools/walkers/validation/RemoveNearbyIndels.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzLmphdmE=) | `90.476% <100%> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...dinstitute/hellbender/engine/GATKToolUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2xVbml0VGVzdC5qYXZh) | `91.017% <100%> (ø)` | `71 <0> (ø)` | :arrow_down: |; | [...idation/AnnotateVcfWithExpectedAlleleFraction.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQW5ub3RhdGVWY2ZXaXRoRXhwZWN0ZWRBbGxlbGVGcmFjdGlvbi5qYXZh) | `96.429% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | ... and [23 more](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5728#issuecomment-467660715:3055,validat,validation,3055,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5728#issuecomment-467660715,1,['validat'],['validation']
Security,"Y. On Mon, Nov 14, 2016 at 6:19 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > From what I understand of the referenced thread, the ""incorrect"" interval; > list may always be around, so we may never be able to just blow up on it.; > Would it perhaps be more viable to add an option to toggle the level of; > stringency, ie choose in the command line whether to blow up or skip on; > these invalid intervals?; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260495927,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0uvegvUmCq7_G7U2PSuTpvIYl0wQks5q-Ox0gaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118). So, would adding a toggle be acceptable? And more importantly, can we make stringent validation default, with the option to not blow up on silly exome files? Will production accept that?. ---. @yfarjoun commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260617185). let me talk with production to see if we can post-facto change the exome; file... On Mon, Nov 14, 2016 at 8:27 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > So, would adding a toggle be acceptable? And more importantly, can we make; > stringent validation default, with the option to not blow up on silly exome; > files? Will production accept that?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0tUTNAAyuk3m_2cJ8j_3KYroaqB1ks5q-QpsgaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2520:2559,validat,validation,2559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2520,1,['validat'],['validation']
Security,YNC_IO_WRITE_FOR_TRIBBLE : false; 17:28:28.782 INFO GermlineCNVCaller - Deflater: IntelDeflater; 17:28:28.782 INFO GermlineCNVCaller - Inflater: IntelInflater; 17:28:28.782 INFO GermlineCNVCaller - GCS max retries/reopens: 20; 17:28:28.782 INFO GermlineCNVCaller - Requester pays: disabled; 17:28:28.782 INFO GermlineCNVCaller - Initializing engine; 17:28:34.716 INFO GermlineCNVCaller - Done initializing engine; 17:28:34.723 INFO GermlineCNVCaller - Intervals specified...; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 17:28:35.689 INFO FeatureManager - Using codec IntervalListCodec to read file file:///media/Data/AnnotationDBs/CNV/Genom/hdf5/../Genom.filtered.interval_list; 17:28:42.892 INFO IntervalArgumentCollection - Processing 2741406000 bp from intervals; 17:28:43.237 INFO GermlineCNVCaller - Reading and validating annotated intervals...; 17:28:51.740 INFO GermlineCNVCaller - GC-content annotations for intervals found; explicit GC-bias correction will be performed...; 17:28:57.410 INFO GermlineCNVCaller - Running the tool in COHORT mode...; 17:28:57.410 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 17:28:57.940 INFO GermlineCNVCaller - Aggregating read-count file 0028-21.hdf5 (1 / 44); 17:29:00.837 INFO GermlineCNVCaller - Aggregating read-count file 0045-21.hdf5 (2 / 44); 17:29:03.690 INFO GermlineCNVCaller - Aggregating read-count file 0098-18.hdf5 (3 / 44); 17:29:06.658 INFO GermlineCNVCaller - Aggregating read-count file 0156-21.hdf5 (4 / 44); 17:29:09.435 INFO GermlineCNVCaller - Aggregating read-count file 0429-20.hdf5 (5 / 44); 17:29:12.235 INFO GermlineCNVCaller - Aggregating read-count file 0779-18.hdf5 (6 / 44); 17:29:14.939 INFO GermlineCNVCaller - Aggregating read-count file 1030-20.hdf5 (7 / 44); 17:29:17.822 INFO GermlineCNV,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7234:5312,validat,validating,5312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7234,1,['validat'],['validating']
Security,YXRpb24vQ2FsY3VsYXRlQ29udGFtaW5hdGlvbi5qYXZh) | `97.207% <0%> (+1.339%)` | `56% <0%> (+18%)` | :arrow_up: |; | [...bender/tools/walkers/mutect/FilterMutectCalls.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9GaWx0ZXJNdXRlY3RDYWxscy5qYXZh) | `97.436% <0%> (+1.603%)` | `13% <0%> (+6%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `73.973% <0%> (+2.74%)` | `11% <0%> (ø)` | :arrow_down: |; | [...ools/walkers/contamination/GetPileupSummaries.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vR2V0UGlsZXVwU3VtbWFyaWVzLmphdmE=) | `84.286% <0%> (+3.851%)` | `20% <0%> (+4%)` | :arrow_up: |; | [...ellbender/tools/exome/FilterByOrientationBias.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9GaWx0ZXJCeU9yaWVudGF0aW9uQmlhcy5qYXZh) | `86.905% <0%> (+3.886%)` | `21% <0%> (+7%)` | :arrow_up: |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `93.182% <0%> (+4.64%)` | `44% <0%> (+16%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4315#issuecomment-362048697:3167,validat,validation,3167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4315#issuecomment-362048697,1,['validat'],['validation']
Security,"Yeah, I expect to need to rewrite tests for the final port. Thanks for any help on the validation data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358036823:87,validat,validation,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358036823,1,['validat'],['validation']
Security,"Yeah, `--force` is the right thing to do, and I added it to build.gradle a few months ago as part of https://github.com/broadinstitute/gatk/pull/5081, but that PR has languished because my original package validation was lame, and I never went back and resolved it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470985048:206,validat,validation,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470985048,1,['validat'],['validation']
Security,"Yeah, it's definitely confusing, we should look into changing it for the future. We definitely do recommend using our launcher script though, which handles it for you. . It was tricky to enable both spark-submit and standalone running spark through the jar without having a way to inject the spark master as a command line argument, but there's probably a better way of handling it then the way we do. . I'm keeping this issue open, but since it's a pretty easy workaround I don't know when we'll be able to fix it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-302179455:281,inject,inject,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-302179455,1,['inject'],['inject']
Security,"Yep, antares58 is me. Elizabeth Lee. Sent with [Proton Mail](https://proton.me/) secure email. ------- Original Message -------; On Tuesday, November 22nd, 2022 at 7:14 AM, Anthony Dias-Ciarla ***@***.***> wrote:. > Hi ***@***.***(https://github.com/antares58) ,; >; > We created this ticket for one of our users on the GATK forum, [Elizabeth Lee](https://gatk.broadinstitute.org/hc/en-us/community/posts/9761457082907-JointGenotyping-ImportGvcfs-terminates-without-an-active-exception).; >; > In the interest of clarity, are you responding on her behalf? Are you the cluster admin? If you are not related to the original user, we will need to create a separate ticket.; >; > Thank you in advance for any clarity that you can provide!; >; > Best,; > Anthony; >; > —; > Reply to this email directly, [view it on GitHub](https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1323834544), or [unsubscribe](https://github.com/notifications/unsubscribe-auth/AWNKFIEGLOGOYBSTJEDLUF3WJTPNBANCNFSM6AAAAAARQLF3GE).; > You are receiving this because you were mentioned.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1336529947:81,secur,secure,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1336529947,1,['secur'],['secure']
Security,"Yes I know but still, I gave it Storage Legacy Bucket Reader access to both buckets....; Is it possible it can come from the gs://gcp-public-data--gnomad or gs://genomics-public-data buckets?; <img width=""1352"" alt=""Screenshot 2021-10-05 at 16 05 09"" src=""https://user-images.githubusercontent.com/17239533/136094811-db2fc1ff-56f0-4ad7-a3b7-dac0e4663ad3.png"">; <img width=""1357"" alt=""Screenshot 2021-10-05 at 16 07 53"" src=""https://user-images.githubusercontent.com/17239533/136095179-34f0adac-7ae6-49bf-abbf-57c21c709ddb.png"">",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492#issuecomment-934754734:61,access,access,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492#issuecomment-934754734,1,['access'],['access']
Security,"Yes, I messed up the commit message and wrote that it ""resolves issue 5433"" instead of ""resolves issue #5433"". Without the hash I guess github assumes it's stupid meatbag language and ignores it. The bug should be fixed so I'm closing the issue manually. Sorry to leave this hanging the last month, and thanks for pointing it out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5433#issuecomment-449899779:123,hash,hash,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5433#issuecomment-449899779,1,['hash'],['hash']
Security,"Yes, I see the same errors in `CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam` from `ValidateSamFile`. Here's some of the output:. ```; [March 9, 2017 7:03:42 PM EST] org.broadinstitute.hellbender.tools.picard.sam.ValidateSamFile --input src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam --use_jdk_deflater true --use_jdk_inflater true --MODE VERBOSE --MAX_OUTPUT 100 --IGNORE_WARNINGS false --VALIDATE_INDEX true --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 1 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --verbosity INFO --QUIET false; [March 9, 2017 7:03:42 PM EST] Executing as gspowley@dna on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Version: Version:4.alpha.2-170-g8d06823-SNAPSHOT; 19:03:42.998 INFO ValidateSamFile - Defaults.BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.COMPRESSION_LEVEL : 1; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_INDEX : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_MD5 : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CUSTOM_READER_FACTORY : ; 19:03:42.999 INFO ValidateSamFile - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 19:03:42.999 INFO ValidateSamFile - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.REFERENCE_FASTA : null; 19:03:43.000 INFO ValidateSamFile - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.00",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:78,Validat,ValidateSamFile,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,4,['Validat'],['ValidateSamFile']
Security,"Yes, ideally we'd generate these once and check them, but I think that would also require a little bit of process to ensure that they're always accessible to both gatkdoc and javadoc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6606#issuecomment-640585794:144,access,accessible,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6606#issuecomment-640585794,1,['access'],['accessible']
Security,"Yes, what are the plans? I too would like to know. ---; What are the plans for the tools available in Picard 2.9.2 or GATK3.7 that are not in GATK4 alpha? Is the plan eventually to port everything to GATK4? Or are some being permanently sent out to pasture?. I have specifically noticed as missing:; - CollectVariantCallingMetrics; - SetNmMdAndUqTags; - the -gvcf option for ValidateVariants. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/gatk/discussion/9736/gatk4-status-of-some-picard-gatk3-7-tools-missing-from-alpha/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3084:375,Validat,ValidateVariants,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084,1,['Validat'],['ValidateVariants']
Security,YnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `22.807% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `91.667% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/spark/ApplyBQSRSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9BcHBseUJRU1JTcGFyay5qYXZh) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `88.542% <ø> (ø)` | `28 <0> (ø)` | :arrow_down: |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ291bnRGYWxzZVBvc2l0aXZlcy5qYXZh) | `93.548% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/walkers/bqsr/BaseRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQmFzZVJlY2FsaWJyYXRvci5qYXZh) | `88.372% <ø> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [.../hellbender/tools/spark/BaseRecalibratorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmsuamF2YQ==) | `86.957% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...recalibration/RecalibrationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-354921087:2131,validat,validation,2131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-354921087,1,['validat'],['validation']
Security,"You might be right---and I think it's worse, in that the ReadCountCollection argument validation (for uniqueness of targets, etc.) also adds to the overhead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316481843:86,validat,validation,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316481843,1,['validat'],['validation']
Security,You would not have access to docker container options when using the Google backend because the running of your image is all controlled by Pipelines API. You would be able to set that value when running on a local backend but thats probably not portable enough for your workflow.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468:19,access,access,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468,1,['access'],['access']
Security,"You're totally right about the assembly failures. As we talked about in person yesterday, I worry about biasing the; likelihoods when genotyping positions near homVar variants. For the; record, the conclusion of that conversation was to inject the GGA allele; into the five best assembled haplotypes, though I'm open to something less; heuristic than ""best five"" if anyone has a good idea. (I don't want to; double the number of haplotypes by adding the GGA allele into all of them). On Thu, Apr 4, 2019 at 2:19 PM David Benjamin <notifications@github.com>; wrote:. > Update: I wrote an integration test in my branch that runs M2 with; > --kmer-size 1 --dont-increase-kmer-sizes-for-cycles. It still calls the; > given alleles, whereas in master it does not.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdF1sCpAlqKNa6S_qlL_ypNX_A0eGks5vdkI7gaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626:237,inject,inject,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626,1,['inject'],['inject']
Security,"Your interpretation sounds right, although I wish the language in the SAM spec were clearer - something like ""if 0x1 is unset, fields 0x2, 0x8, 0x20, 0x40, and 0x80 have no meaning and are ignored by the tools"". SAMRecord.IsValid() returns errors not only for 0x8(mate unmapped)/unpaired read, but also for the other four fields, so all of these errors would need to be removed. IsValid() also triggers an error when an unpaired read has RNEXT set, but the spec. ; doesn't appear to exclude this error. No error is triggered for the unpaired/PNEXT case. . So I agree that it looks like IsValid() should be changed to align with the spec. But I can also imagine potential pitfalls of leaving the GenomicsConverter code the way it is. The code adds spurious information to the bam that might cause problems with legacy versions of the tools. I don't know what the plans are for the state of the existing tool distribution once gatk4 is released. Is it possible that bam files produced in the cloud could make their way into gatk3 workflows, maybe via the sharing of bams between groups? If this happens, then unpaired reads processed in the cloud, with their mate unpaired flags set by the converter, could trigger validation errors when they are fed to the legacy tools. Is there a downside to altering the converter code as well as modifying the ; validator (I don't know what altering google packages entails...)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114510392:1213,validat,validation,1213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114510392,2,['validat'],"['validation', 'validator']"
Security,"Your solution doesn't address your third listed drawback to the current; approach, though I'm not sure there's any way to do that that wouldn't; require a pretty dramatic change. It's not obvious to me why we wanted the given alleles in the graph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:622,inject,injecting,622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767,1,['inject'],['injecting']
Security,"Yup, sorry about this---caught and fixed in #4280. I'd maybe count this as a `womtool validate` bug...?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4281#issuecomment-361069134:86,validat,validate,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4281#issuecomment-361069134,1,['validat'],['validate']
Security,[Echo] bq query audit [VS-1396] (#8847),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8854:16,audit,audit,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8854,1,['audit'],['audit']
Security,"[info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:4371,Validat,ValidateBamsWf,4371,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBamsWf']
Security,"\ ; ; ASEReadCounter \\ ; ; \-L scattered.interval\_list \\ ; ; \-R Homo\_sapiens\_assembly19.fasta \\ ; ; \-V 1000G\_phase1.snps.high\_confidence.b37.vcf.gz \\ ; ; \-I downsample\_10k.bam \\ ; ; \-O output.txt --verbosity INFO. c) Entire error log:. 19:13:25.991 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/broad/software/free/Linux/redhat\_7\_x86\_64/pkgs/gatk\_4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so. Jun 14, 2021 7:13:26 PM shaded.cloud\_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials. WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see [https://cloud.google.com/docs/authentication/](https://cloud.google.com/docs/authentication/). 19:13:26.217 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.218 INFO ASEReadCounter - The Genome Analysis Toolkit (GATK) v4.1.8.1. 19:13:26.218 INFO ASEReadCounter - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/). 19:13:26.219 INFO ASEReadCounter - Executing as [cbao@uger-c009.broadinstitute.org](mailto:cbao@uger-c009.broadinstitute.org) on Linux v3.10.0-1160.15.2.el7.x86\_64 amd64. 19:13:26.219 INFO ASEReadCounter - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0\_181-b13. 19:13:26.219 INFO ASEReadCounter - Start Date/Time: June 14, 2021 7:13:25 PM UTC. 19:13:26.219 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.219 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.220 INFO ASEReadCounter - HTSJDK Version: 2.23.0. 19:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7327:2114,authenticat,authentication,2114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7327,1,['authenticat'],['authentication']
Security,"] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:2263,hash,hash-lookup,2263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['hash'],['hash-lookup']
Security,"_64 ; INFO 10:49:20,811 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14 ; INFO 10:49:20,813 HelpFormatter - Program Args: -T LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_snippet.vcf.gz -o zeta_snippet_leftalign.vcf.gz ; INFO 10:49:20,819 HelpFormatter - Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14. ; INFO 10:49:20,819 HelpFormatter - Date/Time: 2017/08/23 10:49:20 ; INFO 10:49:20,819 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,819 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,830 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:49:21,846 GenomeAnalysisEngine - Downsampling Settings: Method: BY_SAMPLE, Target Coverage: 1000 ; WARN 10:49:22,065 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; INFO 10:49:22,989 GenomeAnalysisEngine - Preparing for traversal ; INFO 10:49:22,994 GenomeAnalysisEngine - Done preparing for traversal ; INFO 10:49:22,995 ProgressMeter - [INITIALIZATION COMPLETE; STARTING PROCESSING] ; INFO 10:49:22,995 ProgressMeter - | processed | time | per 1M | | total | remaining ; INFO 10:49:22,995 ProgressMeter - Location | sites | elapsed | sites | completed | runtime | runtime ; INFO 10:49:23,191 LeftAlignAndTrimVariants - Reference allele is too long (245) at position chr1:10146; skipping that record. Set --reference_window_stop >= 245 ; INFO 10:49:23,197 LeftAlignAndTrimVariants - Reference allele is too long (225) at position chr1:10178; skipping that record. Set --reference_window_stop >= 225 ; INFO 10:49:23,200 LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --reference_window_stop >= 221 ; INFO 10:49:23,201 LeftAlignAndTrimVariants - Reference allele is",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091:2110,validat,validation,2110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091,1,['validat'],['validation']
Security,_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Suc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875:2317,access,access,2317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875,3,['access'],['access']
Security,"_CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath). TEST_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/small""; COMMON_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common""; INPUT_DIR=""$TEST_DIR/input""; OUTPUT_DIR=""$TEST_DIR/output"". input_bam=""$INPUT_DIR/small_CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam""; output_vcf_basename=""$OUTPUT_DIR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21"". ref_fasta=""$COMMON_DIR/human_g1k_v37.20.21.fasta""; known_sites=""$COMMON_DIR/dbsnp_138.b37.20.21.vcf"". gatk ReadsPipelineSpark \; -R ${ref_fasta} \; -I ${input_bam} \; -O ${output_vcf_basename}.vcf \; --known-sites ${known_sites} \; -pairHMM AVX_LOGLESS_CACHING \; --spark-verbosity DEBUG \; -- --spark-runner SPARK --spark-master yarn-cluster \; # --conf 'spark.submit.deployMode=cluster'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; -rw-r--r-- 3 hadoop supergroup 113008112 2020-07-29 15:54 hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; ```; When I specify input as: `hdfs://cromwellhadooptest/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, (i.e. without the port) I get the same error. **Stack trace for this**:; ```; ***********************************************************************; A USER ERROR has occurred: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; ***********************************************************************; org.broadinstitute.hellbe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6730:1653,access,access,1653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730,1,['access'],['access']
Security,"_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=194510848; java.lang.IllegalArgumentException: Illegal base [] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:231); 	at htsjd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:3541,Validat,ValidateVariants,3541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,2,"['Validat', 'validat']","['ValidateVariants', 'validationExampleGood']"
Security,"_STRINGENCY STRICT --COMPRESSION_LEVEL 1 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --verbosity INFO --QUIET false; [March 9, 2017 7:03:42 PM EST] Executing as gspowley@dna on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Version: Version:4.alpha.2-170-g8d06823-SNAPSHOT; 19:03:42.998 INFO ValidateSamFile - Defaults.BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.COMPRESSION_LEVEL : 1; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_INDEX : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_MD5 : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CUSTOM_READER_FACTORY : ; 19:03:42.999 INFO ValidateSamFile - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 19:03:42.999 INFO ValidateSamFile - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.REFERENCE_FASTA : null; 19:03:43.000 INFO ValidateSamFile - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.000 INFO ValidateSamFile - Initializing engine; 19:03:43.000 INFO ValidateSamFile - Done initializing engine; ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 24466, Read name 20FUKAAXX100202:7:46:13035:77621, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to whic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:1483,Validat,ValidateSamFile,1483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,1,['Validat'],['ValidateSamFile']
Security,"_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 12:33:52.162 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 12:33:53.793 INFO CreateReadCountPanelOfNormals - ------------------------------------------------------------; 12:33:53.794 INFO CreateReadCountPanelOfNormals - The Genome Analysis Toolkit (GATK) v4.1.0.0; 12:33:53.794 INFO CreateReadCountPanelOfNormals - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Initializing engine; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 19/02/18 12:33:53 INFO SparkContext: Running Spark version 2.2.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar) to method sun.security.krb5.Config.getInstance(); WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:33:54.187 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 12:33:54.263 INFO CreateReadCountPanelOfNormals - Shutting down engine; [February 18, 2019 at 12:33:54 PM CST] org.broadinstitute.hellbender.tools.copynumber.CreateReadCountPanelOfNormals done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2147483648; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at or",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:1424,access,access,1424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,2,['access'],['access']
Security,_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /root/gatk-4.0.7.0/gatk-package-4.0.7.0-spark.jar PrintReadsSpark -I ../6484_snippet.bam -O ../output.bam --spark-master spark://10.0.0.21:7077; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark2/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark_llap/spark-llap-assembly-1.0.0.2.6.3.40-13.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; java.lang.NoClassDefFoundError: org/apache/logging/log4j/core/appender/AbstractAppender; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); at java.lang.ClassLoader.loadClass(ClassLoader.java:411); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:2581,secur,security,2581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['secur'],['security']
Security,_nio_fixes; 10:56:25.360 WARN GermlineCNVCaller -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: GermlineCNVCaller is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 10:56:25.361 INFO GermlineCNVCaller - Initializing engine; 10:56:54.347 INFO GermlineCNVCaller - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 10:56:55.287 INFO GermlineCNVCaller - Retrieving intervals from first read-count file (hdf5/grexome0426.hdf5)...; 10:56:55.384 INFO GermlineCNVCaller - No GC-content annotations for intervals found; explicit GC-bias correction will not be performed...; 10:56:55.482 INFO GermlineCNVCaller - Running the tool in the COHORT mode...; 10:56:55.485 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 10:56:55.511 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0426.hdf5 (1 / 387); 10:56:55.812 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0342.hdf5 (2 / 387); 10:56:56.274 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0316.hdf5 (3 / 387); 10:56:56.635 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0338.hdf5 (4 / 387); 10:56:57.092 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0360.hdf5 (5 / 387); 10:56:57.728 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0384.hdf5 (6 / 387); 10:56:58.144 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0213.hdf5 (7 / 387); 10:56:58.681 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0347.hdf5 (8 / 387); 10:56:59.192 INFO GermlineCNVCaller - Aggregating read-count file hdf5/grexome0125.hdf5 (9 / 387); 10:56:59.643 INFO GermlineCNVCaller - Aggregating read-count ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053:3460,Validat,Validating,3460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053,1,['Validat'],['Validating']
Security,"`CloudStorageReadChannel.create()` appears to do a GCS access outside of the retry mechanism in `CloudStorageReadChannel.read()`. It calls the constructor, which calls `CloudStorageReadChannel.fetchSize()`, which does a `gcsStorage.get(file)` followed by a `getSize()`. . We are seeing 503 failures specifically from the GCS access in `CloudStorageReadChannel.fetchSize()`:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:202); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:234); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:78); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:68); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:304); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newByteChannel(CloudStorageFileSystemProvider.java:265); at java.nio.file.Files.newByteChannel(Files.java:361); at java.nio.file.Files.newByteChannel(Files.java:407); at htsjdk.samtools.seekablestream.SeekablePathStream.<init>(SeekablePathStream.java:41); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:101); at htsjdk.tribble.readers.Ta",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253:55,access,access,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253,2,['access'],['access']
Security,"`CommandLineProgram.instanceMain()` would be a good place to set the root logging level, after downgrading to log4j 1.x. Don't confuse the Picard logger (the `htsjdk.samtools.util.Log` class) with log4j. There is current an exposed argument to set the Picard logging level in `CommandLineProgram`:. ```; @Argument(doc = ""Control verbosity of logging."", common=true); public Log.LogLevel VERBOSITY = Log.LogLevel.INFO;; ```. You'll need to hook this up to log4j as well, and come up with a unified set of logging levels that work for both log4j and Log.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/243#issuecomment-113269714:224,expose,exposed,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/243#issuecomment-113269714,1,['expose'],['exposed']
Security,`DataSourceUtils` contains string constants for fields in the config file (e.g. `CONFIG_FILE_FIELD_NAME_NAME`). These should be rolled into an enum together. This will facilitate file validation by enabling them to be iterated over automatically using the enum's built in methods.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5465:184,validat,validation,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5465,1,['validat'],['validation']
Security,"`GATKReadFilterPluginDescriptor.getAllInstances()` returns only the filters provided by the user, but I expect it to return the default ones. I know that they are added to the merged filter in `getMergedReadFilter`, but this does not allow to retrieve it as a list. In addition, there is no way to access the default filters provided. I suggest to move the code to merge into the same list the default and the user-provided filters to `getAllInstances()` and use that list in the `getMergedReadFilter`. ## EDITED:; The contract of `getAllInstances()` says that it should not include the default ones, so I propose a new specific method for retrieval.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2362:298,access,access,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2362,1,['access'],['access']
Security,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1179:45,validat,validation,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179,6,['validat'],"['validateCRAMDictionaryAgainstReference', 'validateDictionaries', 'validateToolInputs', 'validation']"
Security,"`HashedListTargetCollection` sorts targets by `IntervalUtils.LEXICOGRAPHICAL_ORDER_COMPARATOR` i.e. ASCII order. Any tool that uses this class to store its targets outputs chromosomes in the order 1, 10, 11 . . . 19, 2, 20, 21, 22, 3 . . .",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1754:1,Hash,HashedListTargetCollection,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1754,1,['Hash'],['HashedListTargetCollection']
Security,`LoadReadsFromFileFn` has a `ValidationStringency` argument that is currently ignored. This line needs to be changed to pass in a customized SamReaderFactory that respects validation . ```; ReadsDataSource bam = new ReadsDataSource(c.element());; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/745:29,Validat,ValidationStringency,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/745,2,"['Validat', 'validat']","['ValidationStringency', 'validation']"
Security,"`ValidateVariants` performs several checks that go above and beyond what the VCF spec requires for VCF files (e.g. throwing an exception if a variant has an alt allele but has a genotype of hom ref [as found by this user](https://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-)). This is good - it helps catch logic errors in our and others' pipelines. . However, we should add a flag to `ValidateVariants` that will cause it to validate solely based on the VCF spec and not the more strict guidelines.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6553:1,Validat,ValidateVariants,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6553,3,"['Validat', 'validat']","['ValidateVariants', 'validate']"
Security,"`ValidateVariants` requires a large amount of memory (>16Gb) to validate a GVCF when another GVCF is used as the interval list. This is not the case if a regular interval list is used instead. This comes up in the production `ReblockGVCFs` pipeline since we validate the reblocked GVCF using the input (unreblocked) GVCF as the interval list to validate over (with `-L`). For now we can just use larger memory machines to run this tool, but it is confusing to me why using a ~4Gb GVCF as an interval list would cause such a large increase in memory requirement.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8608:1,Validat,ValidateVariants,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8608,4,"['Validat', 'validat']","['ValidateVariants', 'validate']"
Security,"`VariantWalker` and `VariantContext` do not do variant validation at parse-time. This causes awkward errors on invalid files like the one found here:; https://gatkforums.broadinstitute.org/gatk/discussion/23809/oncotator-for-build-hg38. It would be best if there was a way to properly validate the variants before parsing them. `ValidateVariants` currently doesn't properly work when given default options (#5862). When #5862 is fixed, this may be ignored - I think validating at run-time when iterating over variants may add too much overhead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5867:55,validat,validation,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5867,4,"['Validat', 'validat']","['ValidateVariants', 'validate', 'validating', 'validation']"
Security,"```; $ git remote show origin; fatal: 'origin' does not appear to be a git repository; fatal: Could not read from remote repository. Please make sure you have the correct access rights; and the repository exists.; $ cat .git/config ; [core]; 	repositoryformatversion = 0; 	filemode = true; 	bare = false; 	logallrefupdates = true; $; ```. Hmm, here is the full log, actually I see some shared library errors at the top. Grr, I have `ncurses-6` library only. Why doesn't the build system die immediately upon an error? Anyway, this is exactly why Gentoo does not like executing zillions of evil jar files and other executables. As I said in the past, your step away from Apache ant build system was a very bad decision. You can see in the log the git tag too. I am not sure if the build system used `master` instead of `gatk` branch. Is that a problem?. [build.log.txt](https://github.com/broadinstitute/gatk/files/1933626/build.log.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687#issuecomment-383221183:171,access,access,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687#issuecomment-383221183,1,['access'],['access']
Security,"```; @Test; public void testGetInvalidPCollectionLocal() {; // ValidationStringency.SILENT should prevent any read error even though the input has what looks like invalid reads.; Pipeline p = GATKTestPipeline.create();; ReadsDataflowSource source = new ReadsDataflowSource(hiSeqBam, p);; SAMFileHeader header = source.getHeader();; final SAMSequenceDictionary sequenceDictionary = header.getSequenceDictionary();; DataflowUtils.registerGATKCoders(p);; PCollection<GATKRead> reads = source.getReadPCollection(IntervalUtils.getAllIntervalsForReference(sequenceDictionary), ValidationStringency.SILENT);; PCollection<Long> count = reads.apply(Count.globally());; // There are 1677 total reads in this file; DataflowAssert.thatSingleton(count).isEqualTo(1677L);; p.run();; }; }; ```. Is a failing one with the out of memory errors. It's invalid in some way SAMRecords being encoded.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/754#issuecomment-126030342:63,Validat,ValidationStringency,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/754#issuecomment-126030342,2,['Validat'],['ValidationStringency']
Security,"```; java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleErrorRate(QualityUtils.java:307); at org.broadinstitute.hellbender.tools.exome.orientationbiasvariantfilter.PreAdapterOrientationScorer.scoreOrientationBiasMetricsOverContext(PreAdapterOrientationScorer.java:78); at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalStart(FilterByOrientationBias.java:191); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:964); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. These calls are from IonTorrent platform (not Illumina), maybe that could be an issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-485476488:139,validat,validateArg,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-485476488,1,['validat'],['validateArg']
Security,"`ah_var_store` edition: Allows hard-filtering based on a maximum number of alt alleles [VS-1334], as well as fixing GATK Docker image building to use image IDs rather than git hashes [VS-1357]. Integration test _mostly_ successful [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/5d021859-5971-4fd7-8451-086c224fdb00). `GvsQuickstartIntegration` failed with:. ```; The bytes observed (89733530) for 'ExtractFilterTask.GvsCreateFilterSet.BigQuery Query Scanned' differ from those expected (85119360); FAIL!!! The relative difference between these is 0.0514208, which is greater than the allowed tolerance (0.05); ```. Successful tieout run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/04b840f9-9779-48d6-8faa-4425d67ddadb). [VS-1334]: https://broadworkbench.atlassian.net/browse/VS-1334?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ; [VS-1357]: https://broadworkbench.atlassian.net/browse/VS-1357?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8806:176,hash,hashes,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8806,1,['hash'],['hashes']
Security,"`mapred.max.split.size` is currently hardcoded to 10485760 in ReadsSparkSource. It should be exposed as a parameter that can be set at the command line since different values are better for different tools. It's a deprecated property, so it should probably be replaced with the new `mapreduce.input.fileinputformat.split.maxsize` instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1064:93,expose,exposed,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1064,1,['expose'],['exposed']
Security,`serializeToVcfString` should not be be in the interface for Funcotation (see `Funcotation.java`). That should be the job of the VCFOutputRenderer to sanitize any strings. A Funcotation should not care whether it is being rendered to a VCF or MAF. It's poor separation of concerns.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4797:150,sanitiz,sanitize,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4797,1,['sanitiz'],['sanitize']
Security,"a requirement is that we need to store and access the human reference file (~3GB, uncompressed) and a few other files < 1 GB each. The files will have public access so no additional security is required.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/388#issuecomment-94330634:43,access,access,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/388#issuecomment-94330634,3,"['access', 'secur']","['access', 'security']"
Security,a386c148681ab69025a0?src=pr&el=desc) will **increase** coverage by `0.008%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3027 +/- ##; ===============================================; + Coverage 79.973% 79.981% +0.008% ; Complexity 16727 16727 ; ===============================================; Files 1139 1139 ; Lines 60902 60902 ; Branches 9437 9437 ; ===============================================; + Hits 48705 48710 +5 ; + Misses 8401 8396 -5 ; Partials 3796 3796; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3027?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../DiscoverVariantsFromContigAlignmentsSGASpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3027?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9EaXNjb3ZlclZhcmlhbnRzRnJvbUNvbnRpZ0FsaWdubWVudHNTR0FTcGFyay5qYXZh) | `85.484% <ø> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/3027?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `88.542% <ø> (ø)` | `28 <0> (ø)` | :arrow_down: |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3027?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9EaXNjb3ZlclZhcmlhbnRzRnJvbUNvbnRpZ0FsaWdubWVudHNTQU1TcGFyay5qYXZh) | `95.238% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...ools/coveragemodel/germline/GermlineCNVCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/3027?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2dlcm1saW5lL0dlcm1saW5lQ05WQ2FsbGVyLmphdmE=) | `73.196% <ø> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...exome/sexgenotyper/TargetCoverageSexGenotyper.java](https://codecov.io/gh/broadin,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3027#issuecomment-306340681:1255,validat,validation,1255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3027#issuecomment-306340681,1,['validat'],['validation']
Security,a:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180:6646,secur,security,6646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180,1,['secur'],['security']
Security,"a:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 00:11:09.632 WARN TaskSetManager:66 - Lost task 15.0 in stage 1.0 (TID 519, localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:5516,Hash,HashMap,5516,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Hash'],['HashMap']
Security,aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JuYXNlcS9HZW5lRXhwcmVzc2lvbkV2YWx1YXRpb24uamF2YQ==) | `89.286% <0.000%> (+0.397%)` | :arrow_up: |; | [...llbender/tools/spark/sv/evidence/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9SZWFkTWV0YWRhdGEuamF2YQ==) | `88.480% <0.000%> (+0.490%)` | :arrow_up: |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `96.629% <0.000%> (+0.562%)` | :arrow_up: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `79.570% <0.000%> (+1.075%)` | :arrow_up: |; | [...dinstitute/hellbender/tools/sv/SiteDepthtoBAF.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9TaXRlRGVwdGh0b0JBRi5qYXZh) | `82.418% <0.000%> (+1.099%)` | :arrow_up: |; | [...lkers/validation/EvaluateInfoFieldConcordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7634#issuecomment-1364365278:3439,Validat,ValidateBasicSomaticShortMutations,3439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7634#issuecomment-1364365278,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JuYXNlcS9HZW5lRXhwcmVzc2lvbkV2YWx1YXRpb24uamF2YQ==) | `89.286% <0.000%> (+0.397%)` | :arrow_up: |; | [...llbender/tools/spark/sv/evidence/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9SZWFkTWV0YWRhdGEuamF2YQ==) | `88.480% <0.000%> (+0.490%)` | :arrow_up: |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `96.629% <0.000%> (+0.562%)` | :arrow_up: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `79.570% <0.000%> (+1.075%)` | :arrow_up: |; | [...dinstitute/hellbender/tools/sv/SiteDepthtoBAF.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9TaXRlRGVwdGh0b0JBRi5qYXZh) | `82.418% <0.000%> (+1.099%)` | :arrow_up: |; | [...lkers/validation/EvaluateInfoFieldConcordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7992#issuecomment-1218381617:3045,Validat,ValidateBasicSomaticShortMutations,3045,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7992#issuecomment-1218381617,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JuYXNlcS9HZW5lRXhwcmVzc2lvbkV2YWx1YXRpb24uamF2YQ==) | `89.286% <0.000%> (+0.397%)` | :arrow_up: |; | [...llbender/tools/spark/sv/evidence/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/8048/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9SZWFkTWV0YWRhdGEuamF2YQ==) | `88.480% <0.000%> (+0.490%)` | :arrow_up: |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/8048/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `96.629% <0.000%> (+0.562%)` | :arrow_up: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/8048/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `79.570% <0.000%> (+1.075%)` | :arrow_up: |; | [...dinstitute/hellbender/tools/sv/SiteDepthtoBAF.java](https://codecov.io/gh/broadinstitute/gatk/pull/8048/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9TaXRlRGVwdGh0b0JBRi5qYXZh) | `82.418% <0.000%> (+1.099%)` | :arrow_up: |; | [...lkers/validation/EvaluateInfoFieldConcordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/8048/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8048#issuecomment-1272595315:3847,Validat,ValidateBasicSomaticShortMutations,3847,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8048#issuecomment-1272595315,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,accept(ForEachOps.java:183) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.lambda$getMatchingFilters$2(FilterFuncotations.java:192) ; at java.base/java.util.HashMap$Values.forEach(HashMap.java:976) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.getMatchingFilters(FilterFuncotations.java:191) ; at org.broadinstitute.hellbender.tools.funcotator.FilterFuncotations.secondPassApply(FilterFuncotations.java:174) ; at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:19) ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; at java.base/java.util.stream,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7504:5820,Hash,HashMap,5820,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7504,1,['Hash'],['HashMap']
Security,"actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.:1,0,0:1:.:0,0,0,0,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:3,0,0:3:.:0,0,0,0,0,0 ./.:7,0,0:7:.:0,0,0,0,0,0 1/1:0,0,0:0:0:45,3,0,3,0,0 ./.:0,0,0 1/1:0,0,1:1:0:45,3,0,3,0,0 1/1:0,0,0:0:0:267,18,0,18,0,0 ./.:9,0,0:9:.:0,0,0,0,0,0 ; . The exactly the same happens when I run GenotypeGVCFs in --include-non-variant-site",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1905,Validat,ValidateVariants,1905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['Validat'],['ValidateVariants']
Security,ad(BlobReadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(H,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180:6519,secur,security,6519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180,1,['secur'],['security']
Security,add IBM. @frank-y-liu please review (I can't assign to you because you need write access for that),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1766:82,access,access,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1766,1,['access'],['access']
Security,add logging and validate vat to echo callset branch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8770:16,validat,validate,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8770,1,['validat'],['validate']
Security,added option for ValidateBasicSomaticShortMutations to output a vcf,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4999:17,Validat,ValidateBasicSomaticShortMutations,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4999,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,adding git hash dependent version number,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/196:11,hash,hash,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196,1,['hash'],['hash']
Security,adds arg validation to make sure margin is non-negative in SimpleInte…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3794:9,validat,validation,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3794,1,['validat'],['validation']
Security,"adinstitute/gsa-unstable/issues/1053#issuecomment-222214083). Still a thing. No work has been done here AFAIK. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-260465013). This seems like fairly low-hanging fruit -- @ronlevine . ---. @ronlevine commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613152). @ldgauthier Shouldn't a locus without genotypes bypass `AC` validation, given it's defined as: `Allele count in genotypes, for each ALT allele, in the same order as listed`?. ---. @ldgauthier commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613997). Agreed. ---. @ronlevine commented on [Thu Nov 24 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262635204). The change should be a lot simpler than proposed. The code can validate the number of alleles before it checks for the presence of genotypes in [VariantContext#validateChromosomeCounts](https://github.com/samtools/htsjdk/blob/master/src/main/java/htsjdk/variant/variantcontext/VariantContext.java#L1236). . ---. @ldgauthier commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263277972). Sorry, I needed to refresh my memory. I actually don't want to bypass AC validation for variants without genotypes, but I think you already figured that out. My proposal was more general, but you're right -- AC and AF should always have the same count as alt alleles and we don't need to check the header for that. When this came up (a year and a half ago!) we were thinking about validating all the info field annotations. ---. @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in https://github.com/samtools/htsjdk/pull/759. I can expand this to all INFO field annotations. ---. @ld",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:5843,validat,validate,5843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,2,['validat'],"['validate', 'validateChromosomeCounts']"
Security,"ah---this is what I get for making an example inputs file when we really didn't need one and for choosing the full AoU 1k release (vat_kc_vat_1) as the default. I wanted to run the validations here because it is the largest dataset and it is the AoU data (not just Anvil data) BUT it has no values for gvs_all_ac or gvs_all_an yet because that step wasn't implemented by the time of creation. (Validation #9 was added by Lee recently) The table vat_jul18 does have those values as it was created just last week, but may get cleaned up...so this might be a good best practices question for what we run this on in the future if there is ever an automated version?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7365#issuecomment-886085289:181,validat,validations,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7365#issuecomment-886085289,2,"['Validat', 'validat']","['Validation', 'validations']"
Security,ain.java:275); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.IllegalArgumentException: two input alignments' overlap on read consumes completely one of them.	1_1097_chrUn_JTFH01000492v1_decoy:501-1597_+_1097M6H_60_1_1092_O	483_612_chr17:26962677-26962806_-_482S130M491S_60_-1_281_S; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.ContigAlignmentsModifier.removeOverlap(ContigAlignmentsModifier.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.prototype.AssemblyContigAlignmentSignatureClassifier.lambda$processContigsWithTwoAlignments$e28aa838$1(AssemblyContigAlignmentSignatureClassifier.java:114); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.collection.ExternalSor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4141:13118,validat,validateArg,13118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141,1,['validat'],['validateArg']
Security,"al; se --min-assembly-region-size 50 --max-assembly-region-size 300 --active-probability-threshold 0.002 --max-prob-propagation-distance 50 --force-active false --assembly-region-padding 100 -; -padding-around-indels 75 --padding-around-snps 20 --padding-around-strs 75 --max-extension-into-assembly-region-padding-legacy 25 --max-reads-per-alignment-start 50 --enable-legacy-assemb; ly-region-trimming false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-pro; gress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md; 5 false --max-variants-per-shard 0 --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --dis; able-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false ; --gcs-max-retries 20 --gcs-project-for-requester-pays --disable-tool-default-read-filters false --minimum-mapping-quality 20 --disable-tool-default-annotations false --enable-all-annotati; ons false --allow-old-rms-mapping-quality-annotation-data false"",Version=""4.4.0.0"",Date=""2023?8?21? CST ??5:33:54"">; ##GVCFBlock0-1=minGQ=0(inclusive),maxGQ=1(exclusive); ##GVCFBlock1-2=minGQ=1(inclusive),maxGQ=2(exclusive); ##GVCFBlock10-11=minGQ=10(inclusive),maxGQ=11(exclusive); ##GVCFBlock11-12=minGQ=11(inclusive),maxGQ=12(exclusive); ##GVCFBlock12-13=minGQ=12(inclusive),maxGQ=13(exclusive); ##GVCFBlock13-14=minGQ=13(inclusive),maxGQ=14(exclusive); ##GVCFBlock14-15=minGQ=14(inclusive),maxGQ=15(exclusive); ##GVCFBlock15-16=minGQ=15(inclusive),maxGQ=16(exclusive); ##GVCFBlock16-17=minGQ=16(inclusive),maxGQ=17(exclusive); ##GVCFBlock17-18=minGQ=17(inclusive)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789:9116,validat,validation,9116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789,1,['validat'],['validation']
Security,"alArgumentException` if a reference isn't provided. . It should be a `UserException`. I don't know but I think there may be modes that don't require the reference, so it may need to give a smart error message. ```; gatk-launch ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.119 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/louisb/Workspace/gatk/build/install/gatk/lib/gkl-0.4.1.jar!/com/intel/gkl/native/libgkl_compression.dylib; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --variant src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf --doNotValidateFilteredRecords false --warnOnErrors false --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:967,Validat,ValidateVariants,967,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,3,"['Validat', 'validat']","['ValidateVariants', 'validationExampleGood']"
Security,"allow me to look at individual shards running ExtractTask if I ran GvsExtractCallsetPgenMerged. Job Manager would be an alternative for this, but it seems to be pretty much unusable for even moderately-sized jobs.); 4. Run GvsExtractCallset on the newly created cohort, making sure to use the same parameters, including scatter count. This will generate VCF files that we can use to compare to the PGEN files created during the previous step for validation.; 5. Run GvsExtractCallsetPgenMerged with the same parameters used to run GvsExtractCallsetPgen in Step 3. This will use call-caching for the extract steps and then merge the PGEN files by chromosome. (Running it this way is maybe not the ideal way to do this, but it's what I've been doing for reasons described in the parenthetical in Step 3).; 6. Create list files, by file type, containing the gs:// URIs for the .pgen, .psam, and .pvar.zst files created in Step 3, along with the .vcf.gz files created in Step 4. Upload them to the workspace to use for validation.; 7. Run ComparePgenAndVcfScatter using the file lists as inputs. If there are any differences, it will output files that contain those differences. If there are no diff files generated, the files match. ComparePgenAndVcfScatter is a workflow I wrote that converts a list of .pgen, .psam, and .pvar.zst files generated by GvsExtractCallsetPgen into .vcf.gz files and then compares those files to a list of .vcf.gz files generated by GvsExtractCallset. . It ignores basically everything except genotypes, because PGENs do not store all the other fields and annotations that the VCFs might have. It will also skip over any sites in the VCFs with >254 alleles because those will not be present in the PGEN files. Any differences are written to diff files, in the form of the differing lines in the VCFs being compared. The code for this comparison tool lives [here](https://github.com/KevinCLydon/pgen_vcf_comparator) in a repo I created under my GitHub account. (I didn't crea",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708:11597,validat,validation,11597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708,1,['validat'],['validation']
Security,"alt-table 13_tumor-alt.tsv -ref-hist 13_tumor-ref.metrics -alt-hist 13_tumor-alt-depth1.metrics -O 13_tumor-artifact-prior-table.tsv ; Using GATK jar /Applications/genomicstools/gatk/gatk-4.0.11.0/gatk-package-4.0.11.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /Applications/genomicstools/gatk/gatk-4.0.11.0/gatk-package-4.0.11.0-local.jar LearnReadOrientationModel -alt-table 13_tumor-alt.tsv -ref-hist 13_tumor-ref.metrics -alt-hist 13_tumor-alt-depth1.metrics -O 13_tumor-artifact-prior-table.tsv; 12:16:19.960 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.0.11.0/gatk-package-4.0.11.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; Nov 26, 2018 12:16:20 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:16:20.176 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 12:16:20.177 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:1145,authenticat,authenticated,1145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['authenticat'],['authenticated']
Security,"am; VALIDATION_STRINGENCY=SILENT \; REFERENCE_SEQUENCE=Homo_sapiens_assembly38.fasta \; INCLUDE_BQ_HISTOGRAM=true \; INTERVALS=wgs_coverage_regions.hg38.interval_list \; OUTPUT=example.raw_wgs_metrics \; USE_FAST_ALGORITHM=true \; READ_LENGTH=250; ```. **Output:**; ```; 18:48:46.330 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/share/picard-2.20.7-0/picard.jar!/com/intel/gkl/native/libgkl_compression.so; [Fri Sep 20 18:48:46 GMT 2019] CollectRawWgsMetrics INPUT=example.bam; [Fri Sep 20 18:48:46 GMT 2019] Executing as root@98e13b9f4ef1 on Linux 4.19.44+ amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.20.7-SNAPSHOT; [Fri Sep 20 18:49:00 GMT 2019] picard.analysis.CollectRawWgsMetrics done. Elapsed time: 0.24 minutes.; Runtime.totalMemory()=4054515712; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" java.lang.IllegalArgumentException: The requested position is not covered by this StartEdgingRecordAndOffset object.; at htsjdk.samtools.util.AbstractRecordAndOffset.validateOffset(AbstractRecordAndOffset.java:146); at htsjdk.samtools.util.EdgingRecordAndOffset$StartEdgingRecordAndOffset.getBaseQuality(EdgingRecordAndOffset.java:112); at picard.analysis.FastWgsMetricsCollector.excludeByQuality(FastWgsMetricsCollector.java:189); at picard.analysis.FastWgsMetricsCollector.processRecord(FastWgsMetricsCollector.java:144); at picard.analysis.FastWgsMetricsCollector.addInfo(FastWgsMetricsCollector.java:105); at picard.analysis.WgsMetricsProcessorImpl.processFile(WgsMetricsProcessorImpl.java:93); at picard.analysis.CollectWgsMetrics.doWork(CollectWgsMetrics.java:231); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:103); at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:113); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6163#issuecomment-533770047:1456,validat,validateOffset,1456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6163#issuecomment-533770047,1,['validat'],['validateOffset']
Security,amesystem.concatInt(FSNamesystem.java:2257); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concat(FSNamesystem.java:2219); > at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.concat(NameNodeRpcServer.java:829); > at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.concat(AuthorizationProviderProxyClientProtocol.java:285); > at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.concat(ClientNamenodeProtocolServerSideTranslatorPB.java:580); > at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); > at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617); > at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2278); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2274); > at java.security.AccessController.doPrivileged(Native Method); > at javax.security.auth.Subject.doAs(Subject.java:422); > at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924); > at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2272); > ; > org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf because writing failed with exception concat: target file /gatk-test2/WES2019-022_S4_out.vcf.parts/output is empty; > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInternal(FSNamesystem.java:2303); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInt(FSNamesystem.java:2257). #### Steps to reproduce; The user's command line was. > nohup /opt/gatk/gatk-4.1.4.0/gatk ReadsPipelineSpark --spark-runner SPARK --spark-master yarn --spark-submit-command spark2-submit -I hdfs://cloudera08/gatk-test2/WES2019-022_S4.bam -O hdfs://cloudera08/gatk-test2/WES2019-022_S4_o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6218:1831,Access,AccessController,1831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6218,1,['Access'],['AccessController']
Security,"ampleIndex);; final int[] indexesToRemove = evidences.stream().mapToInt(e -> {; final int index = evidenceIndexes.getInt(e);; if (index == MISSING_INDEX) {; throw new IllegalArgumentException(""evidence provided is not in sample"");; }; ```; We get an error when `evidenceIndexBySampleIndex(sampleIndex)` yields a `Map` that for some reason doesn't contain a read that it should. So let's investigate `evidenceIndexBySampleIndex()`. This method returns the `evidenceIndexBySampleIndex.get(sampleIndex)` field if it is not `null` (ie uninitialized); otherwise it fills it and then returns it. The code for filling it seems fine, and it explicitly loops over every sample read, so it's hard to see that the error could come from there. It seems rather that the problem is in returning the cached value whenever it is not `null`. The cached value of `evidenceIndexBySampleIndex.get(sampleIndex)` becomes invalid whenever reads are added or removed. However, you can check all the accesses of `evidenceIndexBySampleIndex` (there are only six) and verify that the class never accounts for this. So, suppose that an `AlleleLikelihoods` object invokes `evidenceIndexBySampleIndex(sampleIndex)` more than once and adds or removes reads between these. The second call returns the cached map from the first call, which is bogus. Even if it doesn't explain this issue, it is a bug. Now let's think about which public methods `evidenceIndexBySampleIndex(sampleIndex)` is called in and where this occurs in HaplotypeCaller:. * `addEvidence` (in HC this happens only in the likelihoods for annotations, downstream of our issue, so this is not the culprit).; * `filterPoorlyModeledEvidence` (this happens after Pair-HMM to the haplotype likelihoods, so not the culprit either); * `contaminationDownsampling`; * `retainEvidence` (hmmm in HC `readAlleleLikelihoods.retainEvidence(variantCallingRelevantOverlap::overlaps);` occurs immediately before `contaminationDownsampling`); * `indexOfEvidence` (nothing stands out)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625021336:1166,access,accesses,1166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625021336,1,['access'],['accesses']
Security,an exception. * What went wrong:; Execution failed for task ':gatkTabComplete'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/vsc-hard-mounts/leuven-data/304/vsc30484/git/gatk/build/tmp/gatkTabComplete/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkTabComplete'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53); at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:233); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:74); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:55); at org.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:1536,Validat,ValidatingTaskExecuter,1536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,1,['Validat'],['ValidatingTaskExecuter']
Security,"anager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).; 10:33:06.427 INFO ResourceUtils - ==============================================================; 10:33:06.427 INFO ResourceUtils - No custom resources configured for spark.driver.; 10:33:06.428 INFO ResourceUtils - ==============================================================; 10:33:06.428 INFO SparkContext - Submitted application: SortSamSpark; 10:33:06.446 INFO ResourceProfile - Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 600, script: , vendor: , cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0); 10:33:06.454 INFO ResourceProfile - Limiting resource is cpu; 10:33:06.455 INFO ResourceProfileManager - Added ResourceProfile id: 0; 10:33:06.500 INFO SecurityManager - Changing view acls to: root; 10:33:06.501 INFO SecurityManager - Changing modify acls to: root; 10:33:06.501 INFO SecurityManager - Changing view acls groups to:; 10:33:06.502 INFO SecurityManager - Changing modify acls groups to:; 10:33:06.502 INFO SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 10:33:06.755 INFO Utils - Successfully started service 'sparkDriver' on port 34861.; 10:33:06.784 INFO SparkEnv - Registering MapOutputTracker; 10:33:06.815 INFO SparkEnv - Registering BlockManagerMaster; 10:33:06.827 INFO BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 10:33:06.828 INFO BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up; 10:33:06.831 INFO SparkEnv - Registering BlockManagerMasterHeartbeat; 10:33:06.846 INFO DiskBlockManage",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:41780,Secur,SecurityManager,41780,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['Secur'],['SecurityManager']
Security,"ance. The stuff I've; worked on is a bit of a corner case, and I didn't write much of the; infrastructure, I've been tacking on features. For now I've just been keeping the gzipped text files from the UCSC; browser. They're tab delimited with two header lines, the first basically; giving info about context of the data (it's genome data for the , hg38) and; the second being a description of the columns (each being of form; tract_name.column_name). There's nothing at all sophisticated about this; format, but it's pretty generalizable and easy to parse (and create). An; example; >; > # hgIntegrator: database=hg38 region=genome Wed Apr 18 11:15:34 2018; >; > #gap.chrom gap.chromStart gap.chromEnd gap.type; >; > chr1 0 10000 telomere; >; > chr1 207666 257666 contig; >; > chr1 297968 347968 contig; >; > chr1 535988 585988 contig; >; > chr1 2702781 2746290 scaffold; >; >; For what it's worth, your description of your approach sounds like a; sensible one to me.; I am concerned about the size of the data and how we'd access it. I've; chosen the tracts I have because they are small enough to jam into; resources. On Tue, May 1, 2018 at 8:06 AM samuelklee <notifications@github.com> wrote:. > @TedBrookings <https://github.com/TedBrookings> which formats are you; > using, in particular?; >; > In the CNV package, I've taken pains to unify how tabular data are; > represented in Java, depending on whether each record is Locatable or; > whether the collection of records can be associated with a sample name or; > sequence dictionary. This allows us to represent records that extend; > Locatable with multidimensional numerical or non-numerical annotations; > along with some metadata (sample name and sequence dictionary) with a; > minimum of boilerplate. There are also base methods for producing interval; > trees, etc.; >; > However, this unification effort was a quick push I made before release,; > so some polishing or redesigning may be warranted. We may also want to add; > more forms o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551:1152,access,access,1152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385683551,1,['access'],['access']
Security,and sometimes I get:. ```; java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:170); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:3; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271423848:344,secur,security,344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271423848,5,['secur'],['security']
Security,ang.NoSuchMethodError: scala.collection.Seq.aggregate(Ljava/lang/Object;Lscala/Function2;Lscala/Function2;)Ljava/lang/Object;; at org.bdgenomics.adam.models.NonoverlappingRegions.mergeRegions(NonoverlappingRegions.scala:75); at org.bdgenomics.adam.models.NonoverlappingRegions.<init>(NonoverlappingRegions.scala:55); at org.bdgenomics.adam.models.NonoverlappingRegions$.apply(NonoverlappingRegions.scala:169); at org.bdgenomics.adam.util.TwoBitRecord$.apply(TwoBitFile.scala:193); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.bdgenomics.adam.util.TwoBitFile.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:311); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:1217,Hash,HashMap,1217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,2,['Hash'],"['HashMap', 'HashTrieMap']"
Security,"ants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Run",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:2403,Validat,ValidateVariants,2403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"ark - Inflater: IntelInflater; 16:58:10.116 INFO PrintVariantsSpark - GCS max retries/reopens: 20; 16:58:10.116 INFO PrintVariantsSpark - Requester pays: disabled; 16:58:10.116 WARN PrintVariantsSpark - . ?[1m?[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: PrintVariantsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!?[0m. 16:58:10.116 INFO PrintVariantsSpark - Initializing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_155050875104",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4367,hash,hash,4367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['hash'],['hash']
Security,"as a Selenocysteine edit. Look for the Selenocysteine; feature for the position of this on the genome; - cds_end_NF: the coding region end could not be confirmed; - cds_start_NF: the coding region start could not be confirmed; - mRNA_end_NF: the mRNA end could not be confirmed; - mRNA_start_NF: the mRNA start could not be confirmed.; - basic: the transcript is part of the gencode basic geneset. Comments. Lines may be commented out by the addition of a single # character at the start. These; lines should be ignored by your parser. Pragmas/Metadata. GTF files can contain meta-data. In the case of experimental meta-data these are ; noted by a #!. Those which are stable are noted by a ##. Meta data is a single key,; a space and then the value. Current meta data keys are:. * genome-build - Build identifier of the assembly e.g. GRCh37.p11; * genome-version - Version of this assembly e.g. GRCh37; * genome-date - The date of this assembly's release e.g. 2009-02; * genome-build-accession - The accession and source of this accession e.g. NCBI:GCA_000001405.14; * genebuild-last-updated - The date of the last genebuild update e.g. 2013-09. ------------------; Example GTF output; ------------------. #!genome-build GRCh38; 11 ensembl_havana gene 5422111 5423206 . + . gene_id ""ENSG00000167360""; gene_version ""4""; gene_name ""OR51Q1""; gene_source ""ensembl_havana""; gene_biotype ""protein_coding"";; 11 ensembl_havana transcript 5422111 5423206 . + . gene_id ""ENSG00000167360""; gene_version ""4""; transcript_id ""ENST00000300778""; transcript_version ""4""; gene_name ""OR51Q1""; gene_source ""ensembl_havana""; gene_biotype ""protein_coding""; transcript_name ""OR51Q1-001""; transcript_source ""ensembl_havana""; transcript_biotype ""protein_coding""; tag ""CCDS""; ccds_id ""CCDS31381"";; 11 ensembl_havana exon 5422111 5423206 . + . gene_id ""ENSG00000167360""; gene_version ""4""; transcript_id ""ENST00000300778""; transcript_version ""4""; exon_number ""1""; gene_name ""OR51Q1""; gene_source ""ensembl_havana""; gene_biotype """,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6488:6108,access,accession,6108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6488,3,['access'],['accession']
Security,ass file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:7009,Hash,HashMap,7009,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.runTool(HaplotypeCallerSpark.java:115); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); Caused by: java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinstitute.hellbe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:16848,Hash,HashMap,16848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Hash'],['HashMap']
Security,"ata such as through GCE, and launching a GCE instance from a [relatively similar zone](https://cloud.google.com/compute/docs/regions-zones/regions-zones) such as (`us-east1-b`, `us-east1-c`, `us-east1-d`) the quicker the result. Sometimes the setup time to launch the instance might take some time as well. I don't have a setup as the Broad to run the same test and determine what might be happening, but I just re-ran the following test on an external (non-GCE) cluster and below are the results for a 1.46 GB file, which seem to come closer to @jean-philippe-martin's most recent results (and projected using my throughput, a 34.56 GB file would take about 13 min 38 sec, but not 55 min):. ``` Bash; $ gsutil ls -l gs://pgp-harvard-data-public/hu011C57/GS000018120-DID/GS000015172-ASM/GS01669-DNA_B05/ASM/REF/coverageRefScore-chr1-GS000015172-ASM.tsv.bz2. 1563675749 2014-04-24T20:26:25Z gs://pgp-harvard-data-public/hu011C57/GS000018120-DID/GS000015172-ASM/GS01669-DNA_B05/ASM/REF/coverageRefScore-chr1-GS000015172-ASM.tsv.bz2; TOTAL: 1 objects, 1563675749 bytes (1.46 GiB). $; $ time(gsutil cp -L transfer_statistics.txt gs://pgp-harvard-data-public/hu011C57/GS000018120-DID/GS000015172-ASM/GS01669-DNA_B05/ASM/REF/coverageRefScore-chr1-GS000015172-ASM.tsv.bz2 . ). Copying gs://pgp-harvard-data-public/hu011C57/GS000018120-DID/GS000015172-ASM/GS01669-DNA_B05/ASM/REF/coverageRefScore-chr1-GS000015172-ASM.tsv.bz2...; Downloading ..././coverageRefScore-chr1-GS000015172-ASM.tsv.bz2: 372.81 MiB/372.81 MiB; Downloading ..././coverageRefScore-chr1-GS000015172-ASM.tsv.bz2: 372.81 MiB/372.81 MiB; Downloading ..././coverageRefScore-chr1-GS000015172-ASM.tsv.bz2: 372.81 MiB/372.81 MiB; Downloading ..././coverageRefScore-chr1-GS000015172-ASM.tsv.bz2: 372.81 MiB/372.81 MiB; WARNING: Found no hashes to validate object downloaded to ./coverageRefScore-chr1-GS000015172-ASM.tsv.bz2. Integrity cannot be assured without hashes. real 0m31.112s; user 0m25.286s; sys 0m21.582s. $; ```. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-227913893:1990,hash,hashes,1990,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-227913893,4,"['Integrity', 'hash', 'validat']","['Integrity', 'hashes', 'validate']"
Security,"atic_old` folders.; - There is now just a matched-pair workflow and a panel workflow. We can add a single BAM case workflow or expand the matched-pair workflow to handle this, depending on the discussion at https://github.com/broadinstitute/gatk/issues/3657.; - WES/WGS is toggled by providing an optional target-file input.; - For all workflows, we always collect integer read counts; for WGS, these are output as both HDF5 and TSV and the HDF5 is used for subsequent input.; - For the case workflow, we always collect allelic counts at all sites and output as TSV.; - [x] We should output all data files as HDF5 by default and as TSV optionally. EDIT: This is done for `CollectFragmentCounts`.; - [x] We will need to update the workflows when @MartonKN and @asmirnov239 get `PreprocessIntervals` and `CollectReadCounts` merged, respectively. These tools will remove the awkwardness required by `PadTargets` and `CalculateTargetCoverage`/`SparkGenomeReadCounts`. Denoising:; - All parameters are exposed in the PoN creation tool (#3356).; - Without a PoN, standardization and optional GC correction are performed (#3570).; - Other than the minor point about sample mean/median being used inconsistently noted above, the denoising process is essentially exactly the same mathematically as before (""superficial"" differences include the vastly improved memory and I/O optimizations, the ability to adjust number of principal components used, the removal of redundant SVDs, the enforcement of consistent GC-bias correction).; - [ ] That said, I'll carry over this TODO from above: Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - The only major difference is we no longer make a QC PoN or check for large events. This was performed awkwardly in the old pipeline, so I'd rather not port it over. Eventually we will do all denoising with the gCNV coverage model anyway.; - Pre/tangent-normalizati",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:1437,expose,exposed,1437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['expose'],['exposed']
Security,atk-package-4.0.7.0-spark.jar PrintReadsSpark -I ../6484_snippet.bam -O ../output.bam --spark-master spark://10.0.0.21:7077; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark2/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark_llap/spark-llap-assembly-1.0.0.2.6.3.40-13.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; java.lang.NoClassDefFoundError: org/apache/logging/log4j/core/appender/AbstractAppender; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); at java.lang.ClassLoader.loadClass(ClassLoader.java:411); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.java:132); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternParser.java:131); at org.apache.logging.log4j.core.pattern.PatternParser.<init>(PatternP,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:2741,access,access,2741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['access'],['access']
Security,attending to this. The security posture has greatly improved from where we started. Community greatly benefits from your effort. I have migrated to using the 4.5 release after some regression testing. Below is a list of critical and high findings with 4.5 release. There are links to snyk version update recommendations. I know sometimes its not easy just to upgrade the library version as we could end up with run time errors. I am adding this here so that its handy when ever you look at this further. Thanks again. . packageName | version | severity | language | module_id; -- | -- | -- | -- | --; com.google.protobuf:protobuf-java | 3.7.1 | high | java | [SNYK-JAVA-COMGOOGLEPROTOBUF-2331703 ](https://security.snyk.io/vuln/SNYK-JAVA-COMGOOGLEPROTOBUF-2331703 ); com.google.protobuf:protobuf-java | 3.7.1 | high | java | [SNYK-JAVA-COMGOOGLEPROTOBUF-3167772](https://security.snyk.io/vuln/SNYK-JAVA-COMGOOGLEPROTOBUF-3167772); io.netty:netty-codec-http2 | 4.1.96.Final | high | java | [SNYK-JAVA-IONETTY-5953332](https://security.snyk.io/vuln/SNYK-JAVA-IONETTY-5953332); log4j:log4j | 1.2.17 | high | java | [SNYK-JAVA-LOG4J-2342645](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-2342645); log4j:log4j | 1.2.17 | high | java | [SNYK-JAVA-LOG4J-2342646](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-2342646); log4j:log4j | 1.2.17 | high | java | [SNYK-JAVA-LOG4J-2342647](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-2342647); log4j:log4j | 1.2.17 | critical | java | [SNYK-JAVA-LOG4J-572732](https://security.snyk.io/vuln/SNYK-JAVA-LOG4J-572732); net.minidev:json-smart | 1.3.2 | high | java | [SNYK-JAVA-NETMINIDEV-3369748](https://security.snyk.io/vuln/SNYK-JAVA-NETMINIDEV-3369748); org.apache.zookeeper:zookeeper | 3.6.3 | high | java | [SNYK-JAVA-ORGAPACHEZOOKEEPER-5961102](https://security.snyk.io/vuln/SNYK-JAVA-ORGAPACHEZOOKEEPER-5961102); org.codehaus.jettison:jettison | 1.1 | high | java | [SNYK-JAVA-ORGCODEHAUSJETTISON-3168085](https://security.snyk.io/vuln/SNYK-JAVA-ORGCODEHAUSJE,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1890593067:1070,secur,security,1070,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1890593067,1,['secur'],['security']
Security,audit use of ReferenceSequenceFile and replace with ReferenceUtils.loadFastaDictionary(),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5180:0,audit,audit,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5180,1,['audit'],['audit']
Security,aults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - GCS max retries/reopens: 20; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; 18/01/09 18:30:54 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 18/01/09 18:30:54 INFO spark.SparkContext: Submitted application: BwaAndMarkDuplicatesPipelineSpark; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'sparkDriver' on port 38793.; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering MapOutputTracker; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering BlockManagerMaster; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/01/09 18:30:55 INFO sto,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:5369,Secur,SecurityManager,5369,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,"aults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:51:57.770 INFO SparkGenomeReadCounts - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:51:57.770 INFO SparkGenomeReadCounts - Deflater: IntelDeflater; 16:51:57.770 INFO SparkGenomeReadCounts - Inflater: IntelInflater; 16:51:57.770 INFO SparkGenomeReadCounts - Initializing engine; 16:51:57.770 INFO SparkGenomeReadCounts - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 17/07/21 16:51:58 INFO SparkContext: Running Spark version 2.0.2; 17/07/21 16:51:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/07/21 16:51:58 INFO SecurityManager: Changing view acls to: ameyner2; 17/07/21 16:51:58 INFO SecurityManager: Changing modify acls to: ameyner2; 17/07/21 16:51:58 INFO SecurityManager: Changing view acls groups to: ; 17/07/21 16:51:58 INFO SecurityManager: Changing modify acls groups to: ; 17/07/21 16:51:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(ameyner2); groups with view permissions: Set(); users with modify permissions: Set(ameyner2); groups with modify permissions: Set(); 17/07/21 16:51:58 INFO Utils: Successfully started service 'sparkDriver' on port 43815.; 17/07/21 16:51:58 INFO SparkEnv: Registering MapOutputTracker; 17/07/21 16:51:58 INFO SparkEnv: Registering BlockManagerMaster; 17/07/21 16:51:58 INFO DiskBlockManager: Created local directory at /tmp/ameyner2/blockmgr-d8bbd2bc-8366-4b98-a238-2d51da1689d1; 17/07/21 16:51:58 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 17/07/21 16:51:58 INFO SparkEnv: Registering OutputCommitCoordinator; 17/07/21 16:51:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.; 17/07/21 16:51:58 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.41.105.80:4040; 17/07/21 16:51:58 INFO Executor: Starting executor ID driver o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3360:3126,Secur,SecurityManager,3126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `96.629% <0.000%> (+0.562%)` | :arrow_up: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `79.570% <0.000%> (+1.075%)` | :arrow_up: |; | [...dinstitute/hellbender/tools/sv/SiteDepthtoBAF.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9TaXRlRGVwdGh0b0JBRi5qYXZh) | `82.418% <0.000%> (+1.099%)` | :arrow_up: |; | [...lkers/validation/EvaluateInfoFieldConcordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vRXZhbHVhdGVJbmZvRmllbGRDb25jb3JkYW5jZS5qYXZh) | `72.581% <0.000%> (+1.613%)` | :arrow_up: |; | [...va/org/broadinstitute/hellbender/GATKBaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9HQVRLQmFzZVRlc3QuamF2YQ==) | `98.333% <0.000%> (+1.667%)` | :arrow_up: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/7634/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broad,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7634#issuecomment-1364365278:4284,validat,validation,4284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7634#issuecomment-1364365278,1,['validat'],['validation']
Security,b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `96.629% <0.000%> (+0.562%)` | :arrow_up: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `79.570% <0.000%> (+1.075%)` | :arrow_up: |; | [...dinstitute/hellbender/tools/sv/SiteDepthtoBAF.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9TaXRlRGVwdGh0b0JBRi5qYXZh) | `82.418% <0.000%> (+1.099%)` | :arrow_up: |; | [...lkers/validation/EvaluateInfoFieldConcordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vRXZhbHVhdGVJbmZvRmllbGRDb25jb3JkYW5jZS5qYXZh) | `72.581% <0.000%> (+1.613%)` | :arrow_up: |; | [...va/org/broadinstitute/hellbender/GATKBaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9HQVRLQmFzZVRlc3QuamF2YQ==) | `98.333% <0.000%> (+1.667%)` | :arrow_up: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/7992/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broad,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7992#issuecomment-1218381617:3890,validat,validation,3890,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7992#issuecomment-1218381617,1,['validat'],['validation']
Security,"back to @lbergelson ; i exposed the hidden exceptions a bit more. Annoyingly I had to catch IOExceptions and SAMExceptions (an alternative would have been to let SAMExceptions go all the way up to the caller but that seemed suboptimal). Ideally, htsjdk should not have wrapped IOException in a SAMException but rather expose IOExceptions for what they are and leave their handling to the app layer (ie us)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/448#issuecomment-96774011:24,expose,exposed,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/448#issuecomment-96774011,2,['expose'],"['expose', 'exposed']"
Security,"bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [May 5, 2017 5:03:35 PM UTC] Executing as yarn@ip-172-30-0-122 on Linux 4.4.35-33.55.amzn1.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_121-b13; Version: Version:4.alpha.2-252-gf627ed4-SNAPSHOT; 17/05/05 17:03:35 INFO SparkContext: Running Spark version 2.1.0; 17/05/05 17:03:35 INFO SecurityManager: Changing view acls to: yarn,hadoop; 17/05/05 17:03:35 INFO SecurityManager: Changing modify acls to: yarn,hadoop; 17/05/05 17:03:35 INFO SecurityManager: Changing view acls groups to: ; 17/05/05 17:03:35 INFO SecurityManager: Changing modify acls groups to: ; 17/05/05 17:03:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, hadoop); groups with view permissions: Set(); users with modify permissions: Set(yarn, hadoop); groups with modify permissions: Set(); 17/05/05 17:03:35 INFO Utils: Successfully started service 'sparkDriver' on port 42358.; 17/05/05 17:03:35 INFO SparkEnv: Registering MapOutputTracker; 17/05/05 17:03:35 INFO SparkEnv: Registering BlockManagerMaster; 17/05/05 17:03:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 17/05/05 17:03:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 17/05/05 17:03:35 INFO DiskBlockManager: Created local directory at /mnt/yarn/usercache/hadoop/appcache/application_1493961816416_0010/blockmgr-356a706f-2395-4ef6-985a-d3a7d7b01a8a; 17/05/05 17:03:35 INFO DiskBlockManager: Created local directory at /mnt1/yarn/usercache/hadoop/appcache/application_1493961816416_0010/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046:3074,Secur,SecurityManager,3074,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,bam \; --output gatk.split.bam \; > split.log 2>&1; ```. A tiny BAM file illustrating the problem is attached (it is gzipped to allow Github upload).; [100I_rna.bam.gz](https://github.com/broadinstitute/gatk/files/2456955/100I_rna.bam.gz). #### Actual behavior; Here is the stacktrace:; ```; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Parameters to GenomeLocParser are incorrect:The stop position 3146412 is less than start 3146413 in contig chr20. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MalformedGenomeLoc: Badly formed genome unclippedLoc: Parameters to GenomeLocParser are incorrect:The stop position 3146412 is less than start 3146413 in contig chr20; at org.broadinstitute.hellbender.utils.GenomeLocParser.vglHelper(GenomeLocParser.java:280); at org.broadinstitute.hellbender.utils.GenomeLocParser.validateGenomeLoc(GenomeLocParser.java:226); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:185); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:169); at org.broadinstitute.hellbender.utils.GenomeLocParser.createGenomeLoc(GenomeLocParser.java:150); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager$SplitRead.setRead(OverhangFixingManager.java:402); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager$SplitRead.<init>(OverhangFixingManager.java:396); at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.getSplitRead(OverhangFixingManager.java:467); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Collections$2.tryAdvance(Collections.java:4717); at java.util.Collections$2.forEachRemaining(Collections.java:4725); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.A,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5293:2265,validat,validateGenomeLoc,2265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5293,1,['validat'],['validateGenomeLoc']
Security,"bgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1728,Validat,ValidateVariants,1728,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:52:19.131 INFO LeftAlignAndTrimVariants - Start Date/Time: September 5, 2018 5:52:18 PM EDT; 17:52:19.131 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 17:52:19.132 INFO LeftAlignAndTrimVariants - Picard V",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:1495,authenticat,authentication,1495,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971,1,['authenticat'],['authentication']
Security,"ble technical artifacts (false positves); ## gnomad, gnomad_index: optional database of known germline variants (see http://gnomad.broadinstitute.org/downloads); ## variants_for_contamination, variants_for_contamination_index: VCF of common variants with allele frequencies fo calculating contamination; ##; ## ** Secondary resources ** (for optional tasks); ## onco_ds_tar_gz, default_config_file: Oncotator datasources and config file; ## sequencing_center, sequence_source: metadata for Oncotator; ##; ## Outputs :; ## - One VCF file and its index with primary filtering applied; secondary filtering and functional annotation if requested.; ##; ## Cromwell version support ; ## - Successfully tested on v27; ##; ## LICENSING : ; ## This script is released under the WDL source code license (BSD-3) (see LICENSE in ; ## https://github.com/broadinstitute/wdl). Note however that the programs it calls may ; ## be subject to different licenses. Users are responsible for checking that they are; ## authorized to run all programs before running this script. Please see the docker ; ## pages at https://hub.docker.com/r/broadinstitute/* for detailed licensing information ; ## pertaining to the included programs. workflow Mutect2 {; # Runtime; String gatk4_jar; File picard_jar; String m2_docker; String oncotator_docker; Int preemptible_attempts; # Workflow options; Int scatter_count; File? intervals ; Array[String] artifact_modes; String? m2_extra_args; String? m2_extra_filtering_args; Boolean is_run_orientation_bias_filter; Boolean is_run_oncotator; # Primary inputs ; File ref_fasta; File ref_fasta_index; File ref_dict; File tumor_bam; File tumor_bam_index; String tumor_sample_name; File? normal_bam; File? normal_bam_index; String? normal_sample_name; # Primary resources; File? pon; File? pon_index; File? gnomad; File? gnomad_index; File? variants_for_contamination; File? variants_for_contamination_index; # Secondary resources / inputs; File? onco_ds_tar_gz; File? default_config_file; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3341:3101,authoriz,authorized,3101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3341,1,['authoriz'],['authorized']
Security,bq query audit [VS-1396],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8847:9,audit,audit,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8847,1,['audit'],['audit']
Security,"branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 14:03:44.358 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.358 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 14:03:44.359 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:03:44.359 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 14:03:44.359 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 14:03:44.359 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6, 2018 2:03:44 PM EDT; 14:03:44.359 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.359 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.359 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 14:03:44.359 INFO LeftAlignAndTrimVariants - Picard V",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:7452,authenticat,authentication,7452,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326,1,['authenticat'],['authentication']
Security,"broadinstitute.hellbender.tools.funcotator.Funcotator).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 23:01:58.560 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///omics/chatchawit/bundle/test/gencode/hg38/gencode.v27.chr_patch_hapl_scaff.annotation.REORDERED.gtf; 23:02:05.335 INFO ProgressMeter - Starting traversal; 23:02:05.337 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:02:06.530 INFO Funcotator - Shutting down engine; [April 27, 2018 11:02:06 PM ICT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=3420979200; java.lang.IllegalArgumentException: Invalid interval. Contig:ENST00000342066.7|ENSG00000187634.11|OTTHUMG00000040719.10|OTTHUMT00000276866.2|SAMD11-202|SAMD11|2551|protein_coding| start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getCodingSequenceFromTranscriptFasta(GencodeFuncotationFactory.java:418); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:1177); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createCodingRegionFuncotation(GencodeFuncotationFactory.java:619); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnTranscript(GencodeFuncotationFactory.java:575); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotations(GencodeFuncotationFa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157:7219,validat,validateArg,7219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157,1,['validat'],['validateArg']
Security,"bs per interval, store the data from StratificationManager, and then restore/aggregate it, we could execute VariantEval/VariantQC scatter/gathered. Here is the proposal:; ; - This assumes my PR to separate VariantEvalEngine has been merged.; - In StratificationManager, create a SerializedStratificationState class. This class is responsible for gathering the relevant state of StratificationManager and would get serialized to disk using Jackson.; - StratificationManager would have a saveToDisk(), and a new constructor that accepts the Path to a serialized SerializedStratificationState object. The implementation of saving/restoring would basically be private to StratificationManager.; - In VariantEvalEngine, make a public method for saveToDisk(), which saves StratificationManager and any potential other needed information to disk, serializing with Jackson.; - StratificationManager already has a concept of combineStrats() and Combiner. This needs to be fully implemented across the VariantEval classes; however, I propose to build off this to allow VariantEvaluators and VariantStratifiers to be combined. ; - If the above works, then it is possible to take N serialized SerializedStratificationState objects, restore and combine to create one StratificationManager that represents the data from across the genome.; - With the above steps, the core capabilities I need should be present. As far as how that's exposed in existing GATK tools, I dont have strong opinions. If you want this exposed in VariantEval, I'm happy to make an new argument for --save-state-to-disk-only, which would save the result of VariantEval's interation to a serialized file and skip the reports. To be useful, we need a companion walker to ""MergeVariantEvals"", which takes N serialized files, loads/aggregates and makes the actual report. Does anyone have thoughts or concerns on this proposal? Is this something you think you'd accept as a PR to GATK/VariantEvalEngine/StratificationManager? Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7030:3164,expose,exposed,3164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7030,2,['expose'],['exposed']
Security,build_docker script should fail early if gcloud isn't authenticated,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5353:54,authenticat,authenticated,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5353,1,['authenticat'],['authenticated']
Security,"build_docker.sh creates unzippedJar and testsJar, but it does not remove them and it fails as a result in subsequent runs. . I ran ./build_socker.sh -e <GIT LOG HASH> and I got the error message ; mv: rename ./build/bundle-files-collected to ./unzippedJar/bundle-files-collected: Directory not empty. Only after removing unzippedJar and testJar could I build the image again successfully.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5369:161,HASH,HASH,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5369,1,['HASH'],['HASH']
Security,"but for fingerprinting it seems that since it is effectively random-access,; perhaps prefetching will not be worth it?. On Fri, Apr 12, 2019 at 2:32 PM droazen <notifications@github.com> wrote:. > @yfarjoun <https://github.com/yfarjoun> We should sit down at some point; > to discuss the best way to activate the prefetching in Picard. It may be a; > little less trivial than I had thought based on the above, but should still; > be fairly simple.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0ptBXdOQ-9HlXMjjpFHI_zp-cQJqks5vgNEzgaJpZM4csje4>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782:68,access,access,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782,1,['access'],['access']
Security,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:12226,Secur,SecurityManager,12226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:11965,Secur,SecurityManager,11965,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9VdGlscy5qYXZh) | `80.593% <ø> (-0.309%)` | `124 <0> (-3)` | |; | [...rg/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2651?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzLmphdmE=) | `59.459% <100%> (+2.629%)` | `48 <5> (+3)` | :arrow_up: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2651?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `73.6% <100%> (ø)` | `37 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2651?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `93.75% <0%> (-1.563%)` | `21% <0%> (-1%)` | |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2651?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `81.081% <0%> (-0.737%)` | `24% <0%> (+8%)` | |; | [...org/broadinstitute/hellbender/utils/MathUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2651?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYXRoVXRpbHMuamF2YQ==) | `81.009% <0%> (+1.638%)` | `170% <0%> (+29%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2651?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `74.026% <0%> (+1.948%)` | `35% <0%> (ø)` | :arrow_down: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2651?src=pr&el=tree#diff-c3JjL21haW4vamF2YS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2651#issuecomment-298994813:2050,Validat,ValidateVariants,2050,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2651#issuecomment-298994813,1,['Validat'],['ValidateVariants']
Security,c=pr&el=desc) will **decrease** coverage by `0.002%`.; > The diff coverage is `86.667%`. ```diff; @@ Coverage Diff @@; ## master #5718 +/- ##; ===============================================; - Coverage 87.069% 87.067% -0.003% ; - Complexity 31875 31880 +5 ; ===============================================; Files 1940 1940 ; Lines 146738 146756 +18 ; Branches 16226 16229 +3 ; ===============================================; + Hits 127764 127776 +12 ; - Misses 13061 13065 +4 ; - Partials 5913 5915 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5718?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...walkers/validation/ConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `98.601% <100%> (-1.399%)` | `8 <6> (+2)` | |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `87.179% <50%> (-1.417%)` | `41 <0> (+2)` | |; | [...oadinstitute/hellbender/utils/pairhmm/PairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1BhaXJITU0uamF2YQ==) | `74.82% <0%> (-3.597%)` | `24% <0%> (ø)` | |; | [...hellbender/utils/pairhmm/VectorLoglessPairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1ZlY3RvckxvZ2xlc3NQYWlySE1NLmphdmE=) | `85.526% <0%> (-1.316%)` | `12% <0%> (ø)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL21haW4va,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5718#issuecomment-467164762:1278,validat,validation,1278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5718#issuecomment-467164762,1,['validat'],['validation']
Security,came up in recent profiling - hashCode computation on KMer was very inefficient and wasteful in String creation . @lbergelson can you review?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1620:30,hash,hashCode,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1620,1,['hash'],['hashCode']
Security,came up in review of #614. ; Because of sequence dict validation we needed to hardwire bogus contig lengths in the tests. This issue is about how to resolve this - keep validation and not having to lie about the lengths (and ideally not having to commit the whole reference into the repository).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/690:54,validat,validation,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/690,2,['validat'],['validation']
Security,came up on profiling - computing the hashcode over and over is expensive to we precompute it. @lbergelson please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1625:37,hash,hashcode,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1625,1,['hash'],['hashcode']
Security,"catesSpark) that running with an input in the form ""CountReadsSpark -I gs://my-bucket-dir/my-file.bam."" The tool crashes with the following unhelpful stacktraces:. ```; java.io.IOException: Error getting access token from metadata server at: http://metadata/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:208); 	at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:70); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1825); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1012); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:975); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2687); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2669); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:500); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:469); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1084); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1072); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.SparkContext.withScope(SparkContext.scala:679); 	at org.apache.spark.SparkContext.newAPIHadoopFile(SparkContext.scala:1072); 	at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:1068,access,access,1068,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['access'],['access']
Security,cePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:136); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:165); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.lang.IllegalStateException: Padded span must contain active span.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:109); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:85); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:120); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.makeAssemblyRegionFromVariantReads(FilterAlignmentArtifacts.java:280); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.apply(FilterAlignmentArtifacts.java:212); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:133); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:108); at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:139); ... 21 more; ```. #### Steps to reproduce; _Tell us how to reproduce this,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8221:12552,validat,validate,12552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8221,1,['validat'],['validate']
Security,"ch info header line, call on each VCFInfoHeaderLine getCount(vc) to get the expected number of info annotation entries; - Compare the expected number with a count based on vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some additional parsing because it returns an Object; - (Bonus points if you use the isFixedCount() and getCount() functions on the VCF info header line to simplify annotations that aren't according to the number of alt alleles); ### Test data. /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; Should fail AC/AF validation at ; `1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120`; See results using:. ```; use VCFtools; vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; ```. which outputs:; `INFO field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very appropriate to validate in htsjdk. On Thu, Jul 16, 2015 at 4:05 PM, ldgauthier notifications@github.com; wrote:. > Currently ValidateVariants relies on genotypes to transitively check that; > each alt allele occurs in at least one sample and that the AC adds up.; > However, this can fail on sites-only files because there are no genotypes.; > We should use the definition of the info annotations in the header to check; > how many entries each should have.; > Outline; > - Add a new validation type for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:1753,validat,validation,1753,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,change shards `hashCode` to fix bad distribution to partitions. fix NPE. adding uri's change from distinct to aggregate. reduce shard size by half,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/937:15,hash,hashCode,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/937,1,['hash'],['hashCode']
Security,cker image fails. #### Steps to reproduce. (base) fleharty@wm3b9-dfa docker % docker run -it broadinstitute/gatk:4.2.2.0; Unable to find image 'broadinstitute/gatk:4.2.2.0' locally; 4.2.2.0: Pulling from broadinstitute/gatk; a7fe112a8303: Already exists ; Digest: sha256:32175c3c7c1fb9f5bd6650183c9c5cf26fb822dddb0cad0123d48c33124b6065; Status: Downloaded newer image for broadinstitute/gatk:4.2.2.0; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# apt-get update; Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]; Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] ; Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB] ; Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB] ; Get:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2200 kB]; Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]; Get:16 http:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:1182,secur,security,1182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,1,['secur'],['security']
Security,conda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Successfully started service 'sparkDriver' on port 44712.; 20/10/08 18:35:28 INFO SparkEnv: Registering MapOutputTracker; 20/10/08 18:35:28 INFO SparkEnv: Registering BlockManagerMaster; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/10/08 18:35:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50a111b1-9241-4bc8-b711-cdb6d7054e70; 20/10/08 18:35:28 INFO MemoryStore: MemoryStore started with capacity 17.8 GB; 20/10/08 18:35:28 INFO SparkEnv: Registering OutputCommitCoordinator; 20/1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875:2863,Secur,SecurityManager,2863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"connector will not be configured properly; 12:33:52.162 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 12:33:53.793 INFO CreateReadCountPanelOfNormals - ------------------------------------------------------------; 12:33:53.794 INFO CreateReadCountPanelOfNormals - The Genome Analysis Toolkit (GATK) v4.1.0.0; 12:33:53.794 INFO CreateReadCountPanelOfNormals - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Initializing engine; 12:33:53.797 INFO CreateReadCountPanelOfNormals - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 19/02/18 12:33:53 INFO SparkContext: Running Spark version 2.2.0; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/share/FGI2017B/pub/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar) to method sun.security.krb5.Config.getInstance(); WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 12:33:54.187 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 12:33:54.263 INFO CreateReadCountPanelOfNormals - Shutting down engine; [February 18, 2019 at 12:33:54 PM CST] org.broadinstitute.hellbender.tools.copynumber.CreateReadCountPanelOfNormals done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2147483648; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at org.apache.spark.SparkConf.validateSettings(SparkConf.scala:546); 	at org.apache.spark",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5686:1520,authenticat,authentication,1520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686,1,['authenticat'],['authentication']
Security,"cords false --warnOnErrors false --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO Valid",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2116,Validat,ValidateVariants,2116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,cram dictionary validation should print the missing contigs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1289:16,validat,validation,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1289,1,['validat'],['validation']
Security,cutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:491); 	... 12 more; Caused by: java.io.EOFException: SSL peer shut down incorrectly; 	at sun.security.ssl.InputRecord.read(InputRecord.java:505); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	... 25 more; ```; The error seems to appear after `org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 19.15 minutes.` is logged which is surprising.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:7810,secur,security,7810,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,2,['secur'],['security']
Security,"d binding in [jar:file:/mnt/yarn/usercache/hadoop/filecache/37/__spark_libs__6987413740287883326.zip/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; 17/05/05 17:03:30 INFO SignalUtils: Registered signal handler for TERM; 17/05/05 17:03:30 INFO SignalUtils: Registered signal handler for HUP; 17/05/05 17:03:30 INFO SignalUtils: Registered signal handler for INT; 17/05/05 17:03:30 INFO ApplicationMaster: Preparing Local resources; 17/05/05 17:03:32 INFO ApplicationMaster: ApplicationAttemptId: appattempt_1493961816416_0010_000002; 17/05/05 17:03:32 INFO SecurityManager: Changing view acls to: yarn,hadoop; 17/05/05 17:03:32 INFO SecurityManager: Changing modify acls to: yarn,hadoop; 17/05/05 17:03:32 INFO SecurityManager: Changing view acls groups to: ; 17/05/05 17:03:32 INFO SecurityManager: Changing modify acls groups to: ; 17/05/05 17:03:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, hadoop); groups with view permissions: Set(); users with modify permissions: Set(yarn, hadoop); groups with modify permissions: Set(); 17/05/05 17:03:32 INFO ApplicationMaster: Starting the user application in a separate Thread; 17/05/05 17:03:32 INFO ApplicationMaster: Waiting for spark context initialization...; [May 5, 2017 5:03:35 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark --output hdfs:///output2.bam --input hdfs:///chr1.bam --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046:1501,Secur,SecurityManager,1501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"d positives and negatives and use the existing code for extracting labels, but this will require a bit of engineering and be more trouble than it's worth. There are other options---see https://ir.cwi.nl/pub/30479, for example. We might want to experiment with the LL score discussed there (see https://www.aaai.org/Papers/ICML/2003/ICML03-060.pdf for the original paper---although note that despite the paper's high citation count, I'm not sure what the canonical name for this metric actually is, but it doesn't appear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservatively filtered as truth, which will bias us towards high scores and the peaks of the positive distribution. Perhaps we can also experiment with just treating training/truth on an equal footing (I think the d",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:1257,validat,validation,1257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,1,['validat'],['validation']
Security,"d.interval\_list \\ ; ; \-R Homo\_sapiens\_assembly19.fasta \\ ; ; \-V 1000G\_phase1.snps.high\_confidence.b37.vcf.gz \\ ; ; \-I downsample\_10k.bam \\ ; ; \-O output.txt --verbosity INFO. c) Entire error log:. 19:13:25.991 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/broad/software/free/Linux/redhat\_7\_x86\_64/pkgs/gatk\_4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so. Jun 14, 2021 7:13:26 PM shaded.cloud\_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials. WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see [https://cloud.google.com/docs/authentication/](https://cloud.google.com/docs/authentication/). 19:13:26.217 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.218 INFO ASEReadCounter - The Genome Analysis Toolkit (GATK) v4.1.8.1. 19:13:26.218 INFO ASEReadCounter - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/). 19:13:26.219 INFO ASEReadCounter - Executing as [cbao@uger-c009.broadinstitute.org](mailto:cbao@uger-c009.broadinstitute.org) on Linux v3.10.0-1160.15.2.el7.x86\_64 amd64. 19:13:26.219 INFO ASEReadCounter - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0\_181-b13. 19:13:26.219 INFO ASEReadCounter - Start Date/Time: June 14, 2021 7:13:25 PM UTC. 19:13:26.219 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.219 INFO ASEReadCounter - ------------------------------------------------------------. 19:13:26.220 INFO ASEReadCounter - HTSJDK Version: 2.23.0. 19:13:26.220 INFO ASEReadCounter - Picard V",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7327:2161,authenticat,authentication,2161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7327,1,['authenticat'],['authentication']
Security,"d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [inf",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:3966,Validat,ValidateBAM,3966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBAM']
Security,"dPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbende",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2515,Validat,ValidateVariants,2515,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"dateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:6584,Validat,ValidateBAM,6584,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBAM']
Security,"dateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=194510848; java.lang.IllegalArgumentException: Illegal base [] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:231); 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:374); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:181); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:3904,Validat,ValidateVariants,3904,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"dbSNP build, it throws this error:. \[Fri Jul 23 13:25:03 CEST 2021\] picard.vcf.CollectVariantCallingMetrics done. Elapsed time: 70.55 minutes. Runtime.totalMemory()=1623195648. To get help, see [http://broadinstitute.github.io/picard/index.html#GettingHelp](http://broadinstitute.github.io/picard/index.html#GettingHelp). java.lang.NullPointerException: Cannot invoke ""htsjdk.samtools.SAMSequenceRecord.getSequenceLength()"" because the return value of ""htsjdk.samtools.SAMSequenceDictionary.getSequence(String)"" is null. at picard.util.DbSnpBitSetUtil.loadVcf(DbSnpBitSetUtil.java:163). at picard.util.DbSnpBitSetUtil.createSnpAndIndelBitSets(DbSnpBitSetUtil.java:131). at picard.vcf.CollectVariantCallingMetrics.doWork(CollectVariantCallingMetrics.java:101). at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:308). at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:37). at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160). at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203). at org.broadinstitute.hellbender.Main.main(Main.java:289). As a bit of a background, I am trying to use the latest dbSNP release (build 155, GRCh38, GCF\_000001405.39) and have tried using GATK version 4.1.9.0 and the latest 4.2.0.0, both having the same problem. To prepare the dbSNP file for use with the best practices workflow, I renamed the NCBI chromosome accession numbers  to UCSC style names using bcftools annotate, updated the vcf headers using UpdateVcfSequenceDictionary, and indexed the file using IndexFeatureFile. The dbSNP file worked well with both HaplotypeCaller and GenotypeGVCFs, with the rsids overlapping perfectly with those obtained when using the dbSNP resource bundle version. Any help with this would be greatly appreciated!<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/171466'>Zendesk ticket #171466</a>)<br>gz#171466</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7383:2426,access,accession,2426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7383,1,['access'],['accession']
Security,"de.v27.chr_patch_hapl_scaff.annotation.REORDERED.gtf; WARNING	2018-05-23 23:24:53	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 23:25:09.380 INFO ProgressMeter - Starting traversal; 23:25:09.381 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:25:20.674 INFO ProgressMeter - chr1:24929636 0.2 3000 15941.9; 23:25:42.601 INFO ProgressMeter - chr1:64681324 0.6 6000 10837.2; 23:25:54.659 INFO ProgressMeter - chr1:156245393 0.8 9000 11926.3; 23:26:06.846 INFO ProgressMeter - chr1:206965947 1.0 12000 12529.6; 23:26:12.318 INFO Funcotator - Shutting down engine; [May 23, 2018 11:26:12 PM ICT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 1.38 minutes.; Runtime.totalMemory()=10974920704; java.lang.IllegalArgumentException: Genomic positions must be > 0.; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:722); 	at org.broadinstitute.hellbender.utils.param.ParamUtils.isPositive(ParamUtils.java:153); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getAlignedPosition(FuncotatorUtils.java:336); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:1392); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createCodingRegionFuncotationForProteinCodingFeature(GencodeFuncotationFactory.java:751); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createExonFuncotation(GencodeFuncotationFactory.java:649); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnTranscript(GencodeFuncotationFactory.java:609); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.create",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391421032:4514,validat,validateArg,4514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-391421032,1,['validat'],['validateArg']
Security,"dependency-name=commons-io:commons-io&package-manager=gradle&previous-version=2.7&new-version=2.14.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/gatk/network/alerts). </details>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9003:2021,secur,security,2021,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9003,2,"['Secur', 'secur']","['Security', 'security']"
Security,"derLine) or similar; add a test to VariantContextUnitTest.java; 2) After change 1) is merged, update ValidateVariants accordingly to use the new function and add a test to its integration tests. ---. @vdauwera commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222213763). @ldgauthier is this still a thing? (in the sense of not having been addressed in htsjdk). ---. @ldgauthier commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222214083). Still a thing. No work has been done here AFAIK. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-260465013). This seems like fairly low-hanging fruit -- @ronlevine . ---. @ronlevine commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613152). @ldgauthier Shouldn't a locus without genotypes bypass `AC` validation, given it's defined as: `Allele count in genotypes, for each ALT allele, in the same order as listed`?. ---. @ldgauthier commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613997). Agreed. ---. @ronlevine commented on [Thu Nov 24 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262635204). The change should be a lot simpler than proposed. The code can validate the number of alleles before it checks for the presence of genotypes in [VariantContext#validateChromosomeCounts](https://github.com/samtools/htsjdk/blob/master/src/main/java/htsjdk/variant/variantcontext/VariantContext.java#L1236). . ---. @ldgauthier commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263277972). Sorry, I needed to refresh my memory. I actually don't want to bypass AC validation for variants without genotypes, but I think you already figured that out. My proposal was more general, but you're rig",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:5394,validat,validation,5394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,"detected as B37 in HG19 annotation mode. Performing conversion.; 17:14:13.209 WARN FuncotatorEngine - WARNING: You are using B37 as a reference. Funcotator will convert your variants to GRCh37, and this will be fine in the vast majority of cases. There MAY be some errors (e.g. in the Y chromosome, but possibly in other places as well) due to changes between the two references.; 17:14:13.411 INFO ProgressMeter - Starting traversal; 17:14:13.412 INFO ProgressMeter - Current Locus Elapsed Minutes Features Processed Features/Minute; 17:14:15.391 INFO FuncotateSegments - Shutting down engine; [September 11, 2022 5:14:15 PM GMT] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.30 minutes.; Runtime.totalMemory()=1752170496; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:917445 end:911649; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2939); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314:1253,validat,validatePositions,1253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314,2,['validat'],['validatePositions']
Security,"dian count is significantly away from the main peak (due to the abundance of low mappability bins with small counts). . Also, the second peak of chrX coverage in XY samples that you show above is not a large germline event -- it is simply a low mappable PAR-like region that borrows reads from chrY. Here's how the X coverage distribution looks like on an XY sample after mappability filtering (which removes most of all approximate homologies):; ![chrx](https://user-images.githubusercontent.com/15305869/37867778-54e3d196-2f73-11e8-8345-d8964b39a17e.png). **The second spurious peak is gone and range of NB-like behavior is pretty much perfect. Without mappability filtering, all of the bins on the second mode _will_ show up as CN = 2 events (in fact, if you look at gCNV calls on a typical XY samples, there are tons of CN = 2 calls).**. Most, if not all, of the non-NB-like coverage before/after the main peak in your plots are reads from unmappable regions, many of which show up as real CNV events if we do not filter them (reads in these regions do not follow from the coverage model and we are at the mercy of BWA). I strongly believe Genome STRiP has achieved ~ 99% experimental validation accuracy because of aggressive filtering, not because of a superior model (it's an elementary Gaussian mixture mix). Garbage in, garbage out. Anyhow, I am not comfortable at all with cutting a non-Beta release without taking care of about:. 1. Mappability-based bin/read filtering (for WGS), and; 2. Trying out and evaluating a bait-based coverage collection (for WES), so that the raw coverage distribution is more NB-like to begin with. These are both perfectly achievable goals before May 15. I'd be happy to leave stuff such as different coverage collection strategies (e.g. base call coverage) and fragment-based per-sample GC content estimation for later. These are other areas where significant improvements come from. For the record -- I am working full steam on evaluations, as we discussed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669:1391,validat,validation,1391,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669,1,['validat'],['validation']
Security,"different exception on branch https://github.com/broadinstitute/gatk/tree/lb_refactor_to_reduce_ReadSparkSink_duplication. debugging seems to point to the `.` in `testoutput.bam` as the problem, but why that's causing a problem under yarn is mysterious. ```; caused by: java.io.IOException: Mkdirs failed to create file:/home/unix/louisb/writeable/testoutput.bam/_temporary/0/_temporary/attempt_201601291710_0020_r_000000_3 (exists=false, cwd=file:/mnt/disk10/yarn/nm/usercache/louisb/appcache/application_1452219145116_0780/container_1452219145116_0780_01_000002); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:442); at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:428); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:917); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:898); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:795); at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:784); at org.seqdoop.hadoop_bam.BAMRecordWriter.<init>(BAMRecordWriter.java:74); at org.seqdoop.hadoop_bam.KeyIgnoringBAMRecordWriter.<init>(KeyIgnoringBAMRecordWriter.java:49); at org.seqdoop.hadoop_bam.KeyIgnoringBAMOutputFormat.getRecordWriter(KeyIgnoringBAMOutputFormat.java:91); at org.seqdoop.hadoop_bam.KeyIgnoringBAMOutputFormat.getRecordWriter(KeyIgnoringBAMOutputFormat.java:79); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink$SparkBAMOutputFormat.getRecordWriter(ReadsSparkSink.java:65); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1$$anonfun$12.apply(PairRDDFunctions.scala:1030); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1$$anonfun$12.apply(PairRDDFunctions.scala:1014); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); at org.apache.spark.scheduler.Task.run(Task.scala:88); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1451#issuecomment-176996853:590,Checksum,ChecksumFileSystem,590,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1451#issuecomment-176996853,4,['Checksum'],['ChecksumFileSystem']
Security,"directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260495927,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0uvegvUmCq7_G7U2PSuTpvIYl0wQks5q-Ox0gaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118). So, would adding a toggle be acceptable? And more importantly, can we make stringent validation default, with the option to not blow up on silly exome files? Will production accept that?. ---. @yfarjoun commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260617185). let me talk with production to see if we can post-facto change the exome; file... On Mon, Nov 14, 2016 at 8:27 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > So, would adding a toggle be acceptable? And more importantly, can we make; > stringent validation default, with the option to not blow up on silly exome; > files? Will production accept that?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-260519118,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0tUTNAAyuk3m_2cJ8j_3KYroaqB1ks5q-QpsgaJpZM4JNjE-; > . ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287821154). Any update on this, @yfarjoun ?. ---. @yfarjoun commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1438#issuecomment-287826525). I think we will only fix the interval list when we move exomes to; hg38....so, no. On Mon, Mar 20, 2017 at 12:45 PM, Geraldine Van der Auwera <; notifications@github.com> wrote:. > Any update on this, @yfarjoun <https://github.com/yfarjoun> ?; >; > —; > You are receiving this because you were mentioned.; >",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2520:3059,validat,validation,3059,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2520,1,['validat'],['validation']
Security,dockstore testing: move validate vat inputs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7449:24,validat,validate,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7449,1,['validat'],['validate']
Security,"ds an artificial break at 1000 bins and screws up the scaling:. ![cr-ss](https://user-images.githubusercontent.com/11076296/51122629-417be180-17e8-11e9-9a8f-e17a5d0563f5.png). To fix this, I implemented minibatch slice sampling as described in http://proceedings.mlr.press/v33/dubois14.pdf. This uses early stopping of sampling as determined by a simple statistical test to perform approximate sampling of the posterior in a way that is more well behaved:. ![cr-mb](https://user-images.githubusercontent.com/11076296/51122680-61aba080-17e8-11e9-992a-f756a267d0ce.png). Note that the scaling levels off for larger segments, but the approximation can be made exact by taking the appropriate parameter to zero (here, this parameter is set to 0.1). However, since subsampling parameters were not exposed in the old code, I have not exposed the parameters for the approximation here. We can do this in a future PR if desired. Changing these parameters can affect runtime and results, but I've set them to reasonable values for now. The implementation involved 1) creating an abstract class to extract some common functionality shared with the old batch SliceSampler (which is now no longer used in production code), 2) implementing the MinibatchSliceSampler as described in the above reference, and 3) adding some hash-based caching functionality to both the batch/minibatch implementations, as well as to the allele-fraction likelihood calculations (see related discussion in #2860). I also made a few miscellaneous improvements to code style, etc. This is a relatively sizable change and can rather dramatically change the number of segments remaining after smoothing, etc. (although primarily on small scales and probably well within the noise). I will rerun the TCGA SNP array evaluations to make sure there are no negative effects on performance from this change or those introduced in #5556. @LeeTL1220 should also run some tests. The branch might require some further tweaking based on the results.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5575:2024,hash,hash-based,2024,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575,1,['hash'],['hash-based']
Security,"ds.bam; **********. 11:25:52.673 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/fleharty/resources/picard.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Jul 14 11:25:52 EDT 2020] ValidateSamFile INPUT=concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam MODE=VERBOSE MAX_OUTPUT=100 IGNORE_WARNINGS=false VALIDATE_INDEX=true INDEX_VALIDATION_STRINGENCY=EXHAUSTIVE IS_BISULFITE_SEQUENCED=false MAX_OPEN_TEMP_FILES=8000 SKIP_MATE_VALIDATION=false VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Jul 14 11:25:52 EDT 2020] Executing as fleharty@wm462-624 on Mac OS X 10.15.5 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_191-b12; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.20.4-SNAPSHOT; WARNING	2020-07-14 11:25:52	ValidateSamFile	NM validation cannot be performed without the reference. All other validations will still occur.; ERROR: Record 18321, Read name UMI-ATT-GAA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 26312, Read name UMI-CCT-TTC-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 70755, Read name UMI-CAG-GGA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 145082, Read name UMI-AAC-ATG-5, Zero-length read without FZ, CS or CQ tag; ERROR: Record 181500, Read name UMI-ACT-CTT-1, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186837, Read name UMI-CAA-CTC-4, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186862, Read name UMI-CGC-GCC-0, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186904, Read name UMI-AGG-GTC-0, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186919, Read name UMI-CGC-TGC-0, Zero-length read without FZ, CS or CQ tag; ERROR: Record 186947, Read name UMI-TAA-TAG-3, Zero-length read without FZ, CS or CQ tag; ERROR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:1855,Validat,ValidateSamFile,1855,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,2,"['Validat', 'validat']","['ValidateSamFile', 'validation']"
Security,"e ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=194510848; java.lang.IllegalArgumentException: Illegal base [] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:231); 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:374); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:181); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:4622,Validat,ValidateVariants,4622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"e GATK3 traversal. Initially, I did plan on having `AssemblyRegionWalker` extend the former `ReadWindowWalker`, or an adapted version of your `SlidingWindowWalker`, and I did implement it like this at first, but ultimately I collapsed it into a single class for several reasons:; - Inheriting from a more generic traversal type caused usability issues and confusion with respect to the command-line arguments. The `ReadWindow` was the unit of processing for the superclass, but for `AssemblyRegionWalker` it was the unit of I/O and `AssemblyRegion` was the unit of processing, and I couldn't update the docs for `ReadWindowWalker` to clear up the confusion without mentioning `AssemblyRegion`-specific concepts.; - The `ReadShard` / `ReadWindow` was/is **only** there to prove that we can shard the data without introducing calling artifacts, and to provide a unit of parallelism for the upcoming Spark implementation. It's not something we really want to expose to users as a prominent knob, and we may hide it completely in the future once the shard size is tuned for performance.; - Inheriting from a more abstract walker type caused a number of other problems as well: methods that should have been final in the supertype could no longer be made final, with the result that tool implementations could inappropriately override engine initialization/shutdown routines. Also, there were issues with the progress meter, since both the supertype traversal and subtype traversal needed their own progress meter for their different units of processing. Ultimately it was just too awkward and forced, and the read shard is something that we eventually want to make an internal/encapsulated implementation detail anyway. GATK3 made the mistake, I think, of using long, confusing inheritance chains for its walker types, with the result that you got awkward and forced relationships like `RodWalker` inheriting from `LocusWalker`. It's better, I think, to make each traversal as standalone as possible, esp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513:1255,expose,expose,1255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513,1,['expose'],['expose']
Security,"e PairHMM as a separate project/repo on github and host AVX code there and have alternative implementations extend that project/repo (by creating repos that depend on the AVX one). . In other words, now we have 1 repo, broadinstitute/gatk. After the proposed change we'll have 3 repos (all BSD licensed):; 1) broadinstitute/gatk; 2) broadinstitute/nativePairHMM-AVX; 2) broadinstitute/nativePairHMM-PPC. We will duplicate the native code (AVX and PPC will be separate copies of C++ files etc) to simplify the testing burden. The parties interested in working on a specific architecture will contribute code directly to the respective architecture-specific repo and gatk will take occasional updates of those repos. The gatk repo will depend on the other two. The PPC repo will depend on the AVX repo (and any other native repos will depend on the AVX one). The avx and ppc repos will have their own build systems and unit tests against the new interface. The AVX repo will expose something like the following Java API (to be worked out in detail). ```; //Used to copy references to byteArrays to JNI from reads; public final class JNIReadDataHolderClass {; public byte[] readBases = null;; public byte[] readQuals = null;; public byte[] insertionGOP = null;; public byte[] deletionGOP = null;; public byte[] overallGCP = null;; }. //Used to copy references to byteArrays to JNI from haplotypes; public final class JNIHaplotypeDataHolderClass {; public byte[] haplotypeBases = null;; }. public interface NativePairHMMKernel extends AutoCloseable { . /**; * Function to initialize the fields of JNIReadDataHolderClass and JNIHaplotypeDataHolderClass from JVM.; * C++ code gets FieldIDs for these classes once and re-uses these IDs for the remainder of the program. Field IDs do not; * change per JVM session; *; * @param readDataHolderClass class type of JNIReadDataHolderClass; * @param haplotypeDataHolderClass class type of JNIHaplotypeDataHolderClass; */; void jniInitializeClassFields(Class<JNIRead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864:1130,expose,expose,1130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864,1,['expose'],['expose']
Security,"e adopt a new default branch name and retire the use of 'master'.*. The use of 'master' as the default branch is quickly tipping into the realm of being archaic, and present the image of being increasingly tone deaf. 'main' is the commonly accepted replacement on GitHub, but I'm stopping short of suggesting the replacement name, just asking ""please retire master"". . ### 'master has a specific technical meaning' . It does. And is also an example of structural racism, which; > refers to the complex interactions of large scale societal systems, practices, ideologies, and programs that produce and and perpetuate inequities for racial minorities. The key aspect of structural or systematic racism is that these macro-level mechanisms operate independent of the intentions and actions of individuals, so that even if individual racism is not present, the adverse conditions and inequalities for racial minorities will continue to exist - [Gee & Ford, 2011](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4306458/). _And if you just felt as if you were accused of being a racist, please re-read the above definition again_ I'm addressing the bureaucracy ( which I can not realistically effect much change with, but some of you can).; ; Ultimately, a fair number of people are to varying degrees uncomfortable or threatened by this trope. And on these merits alone are a good reason to ditch master. [The process is straight forward and documentation abounds](https://www.git-tower.com/learn/git/faq/git-rename-master-to-main), [there are even tools to help automate the conversion](https://github.com/dsyer/main-branch-switch). But it will take time, and is not the most exciting work in the world. . Perhaps it's a sticky change as part of all major releases, or otherwise planned for? So, that's my vote, if I were to be asked to vote that is. And, if there are detailed plans in place to make this change, horray! Link them here, and now you have a(nother?) nice honeypot for this topic. John Major",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7621:1884,threat,threatened,1884,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7621,1,['threat'],['threatened']
Security,"e canonicalized/masked kmers. The result is a Collection<long[]> variable, which is then converted to either a PSKmerSet (Hopscotch set) or PSKmerBloomFilter, depending on the desired false positive probability. . The PSKmerSet/BloomFilter classes are basically wrappers for LargeLongHopscotchSet and LongBloomFilter, respectively. They both inherit PSKmerCollection, which provides a contains() function for querying new kmers for set membership and makes loading the kmers for filtering more convenient. These classes also store the kmer size, mask, and false positive probability. They also handle canonicalization/masking on queried kmers. **PathSeqFilterSpark tool**. Input:; 1) Input BAM; 2) Host kmer set file (optional); 3) Host reference bwa image (optional). Output:; 1) BAM containing paired reads that still have mates; 2) BAM containing unpaired reads / reads whose mates were filtered out; 3) Metrics file containing read counts and elapsed wall time at each step (optional). Filtering steps performed on each read:; - If the user sets the --isHostAligned, the read will first be filtered if it is aligned sufficiently well ; - Alignment info is stripped; - A series of quality filters (same as in the previous version of this tool); - Kmerized and filtered out if at least a threshold number of kmers are in the host set (default 1); - Aligned to the host reference and filtered if it maps sufficiently well; - Sequence duplicates are removed. Other:; -Fixed bugginess in very large LongBloomFilters by changing a size variable from int to long. ; - Also realized we can't get away with using just 1 hash function in the Bloom filter. Before, I was using a single 64-bit hash and splitting it into 2 32-bit hashes, then using the hash1 + i*hash2 trick to generate each hash value. I don't think we can do this now because we allow for tables of size >2 billion bits in a single filter, so we need 2 64-bit hashes to use the trick.; -A couple of utility functions have been moved around",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3115:2256,hash,hash,2256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3115,5,['hash'],"['hash', 'hashes']"
Security,"e deleted, and its use `support = range(lo, hi)` should become `support = new IndexRange(lo, hi)`. Then `IntStream.of(support).mapToDouble(___).toArray()` becomes `range.mapToDouble(___)` and `apply(promote(support), ___)` becomes `support.mapToDouble(___)`. * `final double relErr = 1 + pow(10, -7)` should become a `static` constant. * The steps; ```java; final double maxD1 = arrayMax(d1);; final double[] d2 = apply(apply(d1, d -> d - maxD1), d -> exp(d));; final double sumD2 = sum(d2);; return apply(d2, d -> d/sumD2);; ```; inside `dnHyper` are just a home-brewed way to normalize the log-space array `d1`. Let's go throught the steps: 1) find the max. 2) subtract the max -- subtracting a constant in log-space is equivalent to dividing by a constant in real space, and since we're normalizing in the end this constant is arbitrary. It's done for numerical stability. 3) exponentiate to get an unnormalized real-space array. 4) find the sum. 5) divide by the sum to get the normalized result. The log-10 version of this is `MathUtils::normalizeFromLog10ToLinearSpace(d1)`. You could either calculate `d1` in log-10 space or convert it, replacing the above line with `return MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.applyToArrayInPlace(d1, MathUtils::logToLog10))`. The latter option is simpler. * Import static should be avoided except to escape horrible clutter, which is not the case here. * The second argument of `Utils.validateArg(condition, calculated string expression)` should become `Utils.validateArg(condition, () -> calculated string expression)`. In the first version, the expression is calculated *even if* the condition is satisfied, whereas in the second it is only calculated as needed. It's not critical here but it's a good habit to get into. PS I am a zealot of the Boy Scout Rule (always leave the camp site cleaner than you found it). It is a great way to get familiar with a large code base and a great way to make the code more readable for the next person.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266263155:2063,validat,validateArg,2063,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266263155,2,['validat'],['validateArg']
Security,"e for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() function, for each info header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some; > additional parsing because it returns an Object; > - (Bonus points if you use the isFixedCount() and getCount() functions; > on the VCF info header line to simplify annotations that aren't according; > to the number of alt alleles); > ; > Test data; > ; > /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > Should fail AC/AF validation at; > 1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120; > See results using:; > ; > use VCFtools; > vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for validateInfoFieldCounts(VCFInfoHeaderLine headerLine) or similar; add a test to VariantContextUnitTest.java; 2) After chang",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:3494,validat,validator,3494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validator']
Security,"e running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be perfor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:2048,Validat,ValidateVariants,2048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"e running on Google Compute Engine.; [Sun Jul 26 10:20:35 EDT 2020] Executing as farrell@scc-hadoop.bu.edu on Linux 3.10.0-1062.12.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; INFO 2020-07-26 10:20:35 LiftoverVcf Loading up the target reference genome.; INFO 2020-07-26 10:20:56 LiftoverVcf Lifting variants over and sorting (not yet writing the output file.); [Sun Jul 26 10:20:56 EDT 2020] picard.vcf.LiftoverVcf done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=5861015552; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException: Badly formed variant context at location chr1:596697; getEnd() was 596797 but this VariantContext contains an END key with value 532177; at htsjdk.variant.variantcontext.VariantContext.validateStop(VariantContext.java:1401); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1383); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6725:3148,validat,validate,3148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725,1,['validat'],['validate']
Security,"e.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx3000m -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://cclebams/hg38_wes/CDS-ce3y1s.hg38.bam -tumor HAP1_1 --germline-resource gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz -pon gs://gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz -L gs://fc-secure-76d1542e-1c49-4411-8268-e41e92f9f311/729d209c-0ef4-409f-b3af-2e84ff45ee36/omics_mutect2/16911ef5-efb2-4e12-86f2-f3d5a54b28c0/call-mutect2/Mutect2/4e4a27e2-6c57-40e9-8ddc-1024bdcc50c1/call-SplitIntervals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list -O output.vcf.gz --f1r2-tar-gz f1r2.tar.gz --genotype-germline-sites true --genotype-pon-sites true --emit-ref-confidence GVCF --gcs-project-for-requester-pays broad-firecloud-ccle; ```. #### Steps to reproduce. running the same pipeline as described in previous issues: #7492. But I have added ""--genotype-germline-sites true --genotype-pon-sites true --emit-ref-confidence GVCF"" as additional args. the rest of the arguments are defaults/basic from the mutect2.wdl pipeline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849:7714,secur,secure-,7714,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849,1,['secur'],['secure-']
Security,e.cloud.storage.contrib.nio.CloudStorageReadChannel.<init>(CloudStorageReadChannel.java:72); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.create(CloudStorageReadChannel.java:62); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newReadChannel(CloudStorageFileSystemProvider.java:268); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newByteChannel(CloudStorageFileSystemProvider.java:229); at java.nio.file.Files.newByteChannel(Files.java:361); at java.nio.file.Files.newByteChannel(Files.java:407); at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newInputStream(CloudStorageFileSystemProvider.java:348); at java.nio.file.Files.newInputStream(Files.java:152); at org.broadinstitute.hellbender.utils.nio.GcsNioIntegrationTest.openPublicFile(GcsNioIntegrationTest.java:33); Caused by:; java.io.IOException: Error getting access token for service account: ; at shaded.cloud-nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:319); at shaded.cloud-nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); at shaded.cloud-nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); at shaded.cloud-nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); at com.google.cloud.HttpTransportOptions$1.initialize(HttpTransportOptions.java:149); at shaded.cloud-nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud-nio.com.google.api.client.googlea,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:2067,access,access,2067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,1,['access'],['access']
Security,"e.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2200 kB]; Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]; Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [575 kB]; Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2731 kB]; Get:18 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [11.4 kB]; Get:19 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.3 kB]; Reading package lists... Done ; W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; E: The repository 'http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease' is not signed.; N: Updating from such a repository can't be done securely, and is therefore disabled by default.; N: See apt-secure(8) manpage for repository creation and user configuration details.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:2954,secur,securely,2954,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,2,['secur'],"['secure', 'securely']"
Security,e/CpxVariantCanonicalRepresentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/4677/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnRDYW5vbmljYWxSZXByZXNlbnRhdGlvbi5qYXZh) | `78.992% <71.429%> (+0.022%)` | `52 <0> (+2)` | :arrow_up: |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4677/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `90.909% <0%> (-4.213%)` | `9% <0%> (-6%)` | |; | [...hellbender/tools/walkers/mutect/Mutect2Engine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4677/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `87.654% <0%> (-3.39%)` | `50% <0%> (+1%)` | |; | [...tools/spark/validation/CompareDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4677/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay92YWxpZGF0aW9uL0NvbXBhcmVEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `82.927% <0%> (-1.518%)` | `24% <0%> (ø)` | |; | [...forms/markduplicates/MarkDuplicatesSparkUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4677/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmtVdGlscy5qYXZh) | `89.5% <0%> (-1.083%)` | `58% <0%> (-9%)` | |; | [...ellbender/tools/walkers/vqsr/CNNScoreVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4677/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50cy5qYXZh) | `74.057% <0%> (-0.829%)` | `40% <0%> (-1%)` | |; | [...r/engine/filters/ReadGroupBlackListReadFilter.java](https://codecov.io/gh/b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4677#issuecomment-383092400:2277,validat,validation,2277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4677#issuecomment-383092400,1,['validat'],['validation']
Security,"e82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:6916,Validat,ValidateBAM,6916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,1,['Validat'],['ValidateBAM']
Security,"e; [January 12, 2021 at 3:50:33 PM EST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$ap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:6749,Hash,HashMap,6749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,"eManagers; 18/01/09 18:30:58 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (18432 MB per container); 18/01/09 18:30:58 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 18/01/09 18:30:58 INFO yarn.Client: Setting up container launch context for our AM; 18/01/09 18:30:58 INFO yarn.Client: Setting up the launch environment for our AM container; 18/01/09 18:30:58 INFO yarn.Client: Preparing resources for our AM container; 18/01/09 18:30:59 INFO yarn.Client: Uploading resource file:/tmp/sun/spark-5a3e539e-2e2b-4da2-b218-2bda166bd4c0/__spark_conf__7100950787185363106.zip -> hdfs://tele-1:8020/user/sun/.sparkStaging/application_1515493209401_0001/__spark_conf__.zip; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:31:00 INFO yarn.Client: Submitting application application_1515493209401_0001 to ResourceManager; 18/01/09 18:31:00 INFO impl.YarnClientImpl: Submitted application application_1515493209401_0001; 18/01/09 18:31:00 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1515493209401_0001 and attemptId None; 18/01/09 18:31:01 INFO yarn.Client: Application report for application_1515493209401_0001 (state: ACCEPTED); 18/01/09 18:31:01 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.sun; 	 start ti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:11947,Secur,SecurityManager,11947,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,"eReadCounts - Deflater: IntelDeflater; 20:08:45.223 INFO DenoiseReadCounts - Inflater: IntelInflater; 20:08:45.223 INFO DenoiseReadCounts - GCS max retries/reopens: 20; 20:08:45.223 INFO DenoiseReadCounts - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 20:08:45.223 INFO DenoiseReadCounts - Initializing engine; 20:08:45.223 INFO DenoiseReadCounts - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 20:08:45.300 INFO DenoiseReadCounts - Reading read-counts file (BT1813.counts.hdf5)...; HDF5-DIAG: Error detected in HDF5 (1.8.14) thread 0:; #000: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5F.c line 604 in H5Fopen(): unable to open file; major: File accessibilty; minor: Unable to open file; #001: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fint.c line 1085 in H5F_open(): unable to read superblock; major: File accessibilty; minor: Read failed; #002: /mnt/scr1/abyrne/HDFJava-platypus-2.11/native/HDF5-prefix/src/HDF5/src/H5Fsuper.c line 277 in H5F_super_read(): file signature not found; major: File accessibilty; minor: Not an HDF5 file; 20:08:49.800 INFO DenoiseReadCounts - Shutting down engine; [May 18, 2021 8:08:49 PM EDT] org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=1789919232; org.broadinstitute.hdf5.HDF5LibException: exception when opening '/hpf/largeprojects/tabori/projects/bmmrd/CNA_project/gatk_cna/gatk/analysis/lgg/cnvponC2.pon.hdf5' with READ_ONLY mode: Not an HDF5 file; at org.broadinstitute.hdf5.HDF5File.open(HDF5File.java:490); at org.broadinstitute.hdf5.HDF5File.<init>(HDF5File.java:82); at org.broadinstitute.hdf5.HDF5File.<init",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7258:4104,access,accessibilty,4104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7258,1,['access'],['accessibilty']
Security,eTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:233); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:74); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:55); at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:32); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:113); at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37); at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23); at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43); at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32); at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37); at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30); at org.gradle.initialization.DefaultGradleLauncher$4.run(DefaultGradleLauncher.java:186); at org.gradle.internal.Factories$1.create(Factories.java:22); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:91); at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:53); at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:183); at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:33); at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultG,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155:2967,access,access,2967,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155,2,['access'],['access']
Security,"e_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx30g -jar /gpfs/data/lab/bin/gatk/gatk-package-4.4.0.0-local.jar FilterAlignmentArtifacts -R /gpfs/data/lab/reference-files/hg38-gatk/Homo_sapiens_assembly38.fasta -V 60603-bulk.filtered.vcf.gz -I /gpfs/data/lab/projects/Mini/analysis/STR/60603-bulk_results/60603-bulk.cram --bwa-mem-index-image /gpfs/data/lab/reference-files/hg38-gatk/Homo_sapiens_assembly38.fasta.img -O 60603-bulk.filtered.FAA.vcf.gz; ```. Error:; ```; 11:02:16.087 INFO ProgressMeter - chrX:144247387 619.0 145000 234.3; 11:05:08.297 WARN IntelInflater - Zero Bytes Written : 0; 12:29:39.297 INFO FilterAlignmentArtifacts - Shutting down engine; [August 15, 2023 at 12:29:39 PM EDT] org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts done. Elapsed time: 710.24 minutes.; Runtime.totalMemory()=4345298944; java.lang.IllegalStateException: Padded span must contain active span.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:109); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:85); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:120); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.makeAssemblyRegionFromVariantReads(FilterAlignmentArtifacts.java:280); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.apply(FilterAlignmentArtifacts.java:212); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:133); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.afterTraverse(MultiVariantWalkerGroupedOnStart.java:193); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:166); at org.broadinstitute.hellbender.engine.GATKTo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8476:1183,validat,validate,1183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8476,1,['validat'],['validate']
Security,e_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 /root/gatk-4.0.7.0/gatk-package-4.0.7.0-spark.jar PrintReadsSpark -I ../6484_snippet.bam -O ../output.bam --spark-master spark://10.0.0.21:7077; SLF4J: Class path contains multiple SLF4J bindings.; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark2/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: Found binding in [jar:file:/usr/hdp/2.6.3.40-13/spark_llap/spark-llap-assembly-1.0.0.2.6.3.40-13.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.; SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]; java.lang.NoClassDefFoundError: org/apache/logging/log4j/core/appender/AbstractAppender; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:763); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); at java.net.URLClassLoader.access$100(URLClassLoader.java:73); at java.net.URLClassLoader$1.run(URLClassLoader.java:368); at java.net.URLClassLoader$1.run(URLClassLoader.java:362); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:361); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); at java.lang.ClassLoader.loadClass(ClassLoader.java:411); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.decodeCacheFiles(PluginRegistry.java:181); at org.apache.logging.log4j.core.config.plugins.util.PluginRegistry.loadFromMainClassLoader(PluginRegistry.java:119); at org.apache.logging.log4j.core.config.plugins.util.PluginManager.collectPlugins(PluginManager.java:132); at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5126:2590,Secur,SecureClassLoader,2590,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5126,1,['Secur'],['SecureClassLoader']
Security,eadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.c,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:6542,secur,security,6542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['secur'],['security']
Security,"ed by groupReadPairs is very expensive both in time and in memory. It's a full hash shuffle of GATKReads (time expensive), that results in a gazillion 1- and 2-element Lists (memory expensive). So you certainly don't want to do it twice. But the way pairedReads and unpairedReads is set up, you *will* do it twice if you want to process both paired and unpaired reads. (And even if you aren't, someone else might try to use this code to do so.). So my first suggestion is that you remove the call to groupReadPairs from pairedReads and unpairedReads, and let a user groupReadPairs once, and reuse the resulting JavaPairRDD to process paired and unpaired reads. My second suggestion is quite a bit more complicated, but I think it would result in far better performance. I'll sketch it out here, and then I can explain it further in person, if it's a direction you'd like to pursue. The first step is to create a JavaRDD<GATKRead> in which all pairs sharing a template name are in the same partition (but without grouping them). To do that, you temporarily boost the input JavaRDD into a JavaPairRDD<String,GATKRead> by extracting the read name as a key. Then you repartition (to do the shuffle). Then you map back to an ordinary JavaRDD<GATKRead> by keeping just the value. (Note: if the BAM has queryname sort order, you can just skip this step entirely.); Now you can do a mapPartition operation to filter for paired or unpaired reads: Iterate over the reads in the partition, and keep a hash map of [name -> read] of reads that have not yet found mates. To filter for paired reads, whenever you find the name of the current read already in the table, just emit the current read and the read in the map as a pair, and delete the read from the map (you're done with that name -- this keeps the table smaller). To filter for unpaired reads, just delete any map entry that you successfully look up, and insert any name that you don't. What's left at the end of this process are all the unpaired reads.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2664#issuecomment-299955039:1578,hash,hash,1578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2664#issuecomment-299955039,1,['hash'],['hash']
Security,"ed with single line brackets. I.e. gatk typically uses. ```; if ( something ) {; doThing; } else {; otherThing; }; ```. rather than. ```; if ( something ) ; {; doThing; }; else ; {; otherThing; }; ```. 2) You use a lot of raw iterators, which is fine and is necessary in many cases. In other cases those operations can be written much more succinctly with either a for-each loop, or a stream. i.e. . ```; List<Integer> values;; Iterator itr = iterable.iterator();; while(itr.hasNext()){; Element elem = itr.next();; int value = someFunction(elem); if ( value > SOME_CONSTANT) {; values.append(value); }; }; return values;; ```. can be . ```; return StreamSupport.stream(iterable.spliterator, false); .map( elem -> someFunction(elem)); .filter( value -> value > SOME_CONSTANT ); .collect( Collectors.toList()); ```. We should probably add a utilty function to convert an iterator to a stream directly so we can stream iterators easily even if there is no associated iteratable. . 3) The tools need tests. This is important. 4) It would be good to think about how the tools can be composited into a spark pipline and run without writing intermediate files. . 5) Bitwise operations are a rarity in GATK and many of our users will not be very comfortable with them. Please avoid bit twiddling tricks when possible. When it's not possible (i.e. when you are performing tricks to treat a long as a set of byte pairs) please add detailed explanation to the comments so that readers who are less familiar will be able to follow along. Likewise all magic values should be named constants unless they are extremely obvious. . 6) Avoid state like the plague. Everything that can reasonable be static should be. Some things will require mutable state, but avoid it as much as possible. . Similarly, static mutable objects should be avoided like a plague infected with more plagues. Never expose a static object that could be mutated. (you have a static array, it's ok because it's private and nothing mutates it)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1435#issuecomment-172985394:2438,expose,expose,2438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1435#issuecomment-172985394,1,['expose'],['expose']
Security,"ed.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1926,Validat,ValidateVariants,1926,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,ee http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 21:06:12.479 INFO FeatureManager - Using codec IntervalListCodec to read file file:///paedyl01/disk1/louisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGuts/-947966988/Homo_sapiens_assembly38.bed.preprocessed.filtered.scattered.0154.interval_list; 21:06:12.640 DEBUG FeatureDataSource - Cache statistics for FeatureInput /paedyl01/disk1/louisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGermlineCohort8/Homo_sapiens_assembly38.bed.preprocessed.filtered.scattered.0154.interval_list:/paedyl01/disk1/louisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGermli947966988/Homo_sapiens_assembly38.bed.preprocessed.filtered.scattered.0154.interval_list:; 21:06:12.640 DEBUG FeatureCache - Cache hit rate was 0.00% (0 out of 0 total queries); 21:06:12.645 INFO IntervalArgumentCollection - Processing 4999155 bp from intervals; 21:06:12.656 INFO GermlineCNVCaller - Reading and validating annotated intervals...; 21:06:18.914 WARN GermlineCNVCaller - Sequence dictionary in annotated-intervals file does not match the master sequence dictionary.; 21:06:19.130 INFO GermlineCNVCaller - GC-content annotations for intervals found; explicit GC-bias correction will be performed...; 21:06:19.200 INFO GermlineCNVCaller - Running the tool in COHORT mode...; 21:06:19.200 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 21:07:11.897 DEBUG ScriptExecutor - Executing:; 21:07:11.897 DEBUG ScriptExecutor - python; 21:07:11.897 DEBUG ScriptExecutor - /paedyl01/disk1/louisshe/tmp/gatk/cohort_denoising_calling.418897092082188314.py; 21:07:11.897 DEBUG ScriptExecutor - --ploidy_calls_path=/paedyl01/disk1/louisshe/work/NGS/wdl/test_workflow_cnv/germline/cromwell-executions/CNVGermlineCohortWorkflow/d53c0a; 21:07:11.897 DEBUG ScriptExecutor - --output_calls_path=/paedyl01/disk1/louisshe/out/NMD/batch1_2023/batch1_all/cnv/cohort_calls/batc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8952:6615,validat,validating,6615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8952,1,['validat'],['validating']
Security,eekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 28 more; Caused by: com.google.cloud.storage.StorageException: Read timed out; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:186); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:512); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:128); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:125); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:92); 	at shaded.cloud_nio.com.google.api.gax.retrying.RetryingFutureImpl.executeAttempt(RetryingFutureImpl.java:141); 	at shaded.cloud_nio.com.google.api.gax.retrying.RetryingFutureImpl.access$500(RetryingFutureImpl.java:59); 	at shaded.cloud_nio.com.google.api.gax.retrying.RetryingFutureImpl$AttemptFutureCallback.onFailure(RetryingFutureImpl.java:177); 	at shaded.cloud_nio.com.google.api.gax.core.ApiFutures$1.onFailure(ApiFutures.java:52); 	at shaded.cloud_nio.com.google.common.util.concurrent.Futures$6.run(Futures.java:1764); 	at shaded.cloud_nio.com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:456); 	at shaded.cloud_nio.com.google.common.util.concurrent.Futures$ImmediateFuture.addListener(Futures.java:153); 	at shaded.cloud_nio.com.google.common.util.concurrent.ForwardingListenableFuture.addListener(ForwardingListenableFuture.java:47); 	at shaded.cloud_nio.com.google.api.gax.core.internal.ApiFutureToListenableFuture.addListener(ApiFutureToListenableFuture.java:53); 	at shaded.cloud_nio.com.google.common.util.concurrent.Futures.addCallback(Futures.java:1776); 	at shaded.cloud_nio.com.google.common.util.concurrent.Futures.addCallback(Futures,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180:4061,access,access,4061,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180,1,['access'],['access']
Security,"efaults.COMPRESSION_LEVEL : 1; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_INDEX : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_MD5 : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CUSTOM_READER_FACTORY : ; 19:03:42.999 INFO ValidateSamFile - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 19:03:42.999 INFO ValidateSamFile - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.REFERENCE_FASTA : null; 19:03:43.000 INFO ValidateSamFile - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.000 INFO ValidateSamFile - Initializing engine; 19:03:43.000 INFO ValidateSamFile - Done initializing engine; ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 24466, Read name 20FUKAAXX100202:7:46:13035:77621, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97940, Read name 20FUKAAXX100202:5:7:21464:86224, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 97955, Read name 20GAVAAXX100126:5:7:1291:122571, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ERROR: Record 112212, Read name 20GAVAAXX100126:8:1:1429:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:1950,Validat,ValidateSamFile,1950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,1,['Validat'],['ValidateSamFile']
Security,"egions within the reference,; > and therefore will have fine mapping quality even though they are artifacts.; >; > There are published ""decoy genomes"" -- essentially pseudo-contigs of; > regions missing from the reference, and mapping with BWA in memory to; > *those* might be very helpful.; >; > So, we need to: 1) get our hands on a decoy genome that will play nicely; > with BWA, and 2) talk to the SV team.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-296515266>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdCJQob4WqdwDN0R8jvbNGT1l0vSCks5rzBOmgaJpZM4Lb8pz>; > .; >. ---. @davidbenjamin commented on [Wed May 03 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-298946022). Copying comments from closed issue #993. Instead of running an aligner in memory, let's first try preprocessing an alignability (to the ref + decoy) resource file. Then we can simply query this file at each called variant. > ENCODE used a kmer size of 36 bp, which is seriously obsolete and will tend to underestimate alignability. However, the GEM program (paper here: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0030377 and binary here: http://algorithms.cnag.cat/wiki/The_GEM_library#Documentation and blog post on how to run it here: http://blog.kokocinski.net/index.php/sequence-mappability-alignability?blog=2) was used by ENCODE to produce this track and we can easily produce it ourselves with any kmer size and any mismatch threshold. > Furthermore, once we make this track we can store this track in memory eg as a `HashedListTargetCollection` and therefore we can query it for every read to get an annotation for the number of uniquely mappable reads (up to some error tolerance). > One more thing: we can also query based on the start position of each read's mate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2930:5486,Hash,HashedListTargetCollection,5486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2930,1,['Hash'],['HashedListTargetCollection']
Security,el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50c0NvbmZpZ1BpY2tlclVuaXRUZXN0LmphdmE=) | `99.415% <0%> (-0.19%)` | `34% <0%> (+14%)` | |; | [...utils/variant/GATKVariantContextUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5038/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzVW5pdFRlc3QuamF2YQ==) | `87.194% <0%> (-0.088%)` | `316% <0%> (+156%)` | |; | [...ct/CreateSomaticPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5038/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `100% <0%> (ø)` | `6% <0%> (+3%)` | :arrow_up: |; | [.../validation/RemoveNearbyIndelsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5038/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `100% <0%> (ø)` | `5% <0%> (+2%)` | :arrow_up: |; | [...walkers/validation/ConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5038/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `100% <0%> (ø)` | `10% <0%> (+4%)` | :arrow_up: |; | [...dation/AnnotateVcfWithBamDepthIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5038/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQW5ub3RhdGVWY2ZXaXRoQmFtRGVwdGhJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `100% <0%> (ø)` | `12% <0%> (+5%)` | :arrow_up: |; | ... and [10 more](https://codecov.io/gh/broadinstitute/gatk/pull/5038/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5038#issuecomment-406399931:3578,validat,validation,3578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5038#issuecomment-406399931,1,['validat'],['validation']
Security,eline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 21/01/12 15:50:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-273b4c87-579e-4d57-81de-aa47a79634bb; 21/01/12 15:50:31 INFO MemoryStore: MemoryStore started with capacity 9.2 GB; 21/01/12 15:50:31 INFO SparkEnv: Registering OutputCommitCoordinator; 21/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:1101,Secur,SecurityManager,1101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,7,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"ellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. The user mentioned that this didn't happen on GATK 4.1, so I've been comparing both versions of the code. It turns out that the implementation of ""GenotypingEngine.java"" has changed since then, and after some digging, I noticed that the issue is that the newer versions have uninitialized instances of the class ""OneShotLogger"". The fix is simple, I've added the change myself and built GATK again. The user reports that the issue is gone. Just add the following code inside the constructor method:. ``` ; protected GenotypingEngine(final Config configuration,; final SampleList samples,; final boolean doAlleleSpecificCalcs) {; this.configuration = Utils.nonNull(configuration, ""the configuration cannot be null"");; Utils.validate(!samples.asListOfSamples().isEmpty(), ""the sample list cannot be null or empty"");; this.samples = samples;; this.doAlleleSpecificCalcs = doAlleleSpecificCalcs;; logger = LogManager.getLogger(getClass());; this.oneShotLogger = new OneShotLogger(logger); // <------ ADD THIS LINE; numberOfGenomes = this.samples.numberOfSamples() * configuration.genotypeArgs.samplePloidy;; alleleFrequencyCalculator = AlleleFrequencyCalculator.makeCalculator(configuration.genotypeArgs);; }; ```. #### Steps to reproduce; See description, but I can't provide the exact inputs used for it. #### Expected behavior; The null pointer exception shouldn't occur, there should be a warning only. #### Actual behavior; Program crashes with null pointer exception for high enough values of ploidy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8158:3863,validat,validate,3863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8158,1,['validat'],['validate']
Security,ellbender/tools/splitNCigarReadsSnippet.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.sam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.sam; src/test/resources/org/broadinstitute/hellbender/tools/validation/marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/picard.marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.bai; src/test/resources/org/broadinstitute/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.HACKEDhg38header.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.snps.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.mixedTest.input.vcf.idx; src/test/resources/org/broadinstitute/hel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:45664,validat,validation,45664,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['validat'],['validation']
Security,emBase.java:2185); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1832); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1013); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:976); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2812); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:100); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2849); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2831); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:389); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:171); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:168); 	at java.base/java.security.AccessController.doPrivileged(Native Method); 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:168); 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:176); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:80); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:926); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:550); 	at org.broadinstitu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:1696,secur,security,1696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['secur'],['security']
Security,emory including 384 MB overhead; 18/01/09 18:30:58 INFO yarn.Client: Setting up container launch context for our AM; 18/01/09 18:30:58 INFO yarn.Client: Setting up the launch environment for our AM container; 18/01/09 18:30:58 INFO yarn.Client: Preparing resources for our AM container; 18/01/09 18:30:59 INFO yarn.Client: Uploading resource file:/tmp/sun/spark-5a3e539e-2e2b-4da2-b218-2bda166bd4c0/__spark_conf__7100950787185363106.zip -> hdfs://tele-1:8020/user/sun/.sparkStaging/application_1515493209401_0001/__spark_conf__.zip; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:31:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:31:00 INFO yarn.Client: Submitting application application_1515493209401_0001 to ResourceManager; 18/01/09 18:31:00 INFO impl.YarnClientImpl: Submitted application application_1515493209401_0001; 18/01/09 18:31:00 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1515493209401_0001 and attemptId None; 18/01/09 18:31:01 INFO yarn.Client: Application report for application_1515493209401_0001 (state: ACCEPTED); 18/01/09 18:31:01 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.sun; 	 start time: 1515493860237; 	 final status: UNDEFINED; 	 tracking URL: http://tele-1:8088/proxy/application_1515493209401_0001/; 	 user: sun; 18/01/09 18:31:02 INFO yarn.Client: Application report for application_1515493209401_0001 (state: ACCEPTED); 18/01/09,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:12105,Secur,SecurityManager,12105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,3,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"en't according to the number of alt alleles); ### Test data. /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; Should fail AC/AF validation at ; `1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120`; See results using:. ```; use VCFtools; vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; ```. which outputs:; `INFO field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very appropriate to validate in htsjdk. On Thu, Jul 16, 2015 at 4:05 PM, ldgauthier notifications@github.com; wrote:. > Currently ValidateVariants relies on genotypes to transitively check that; > each alt allele occurs in at least one sample and that the AC adds up.; > However, this can fail on sites-only files because there are no genotypes.; > We should use the definition of the info annotations in the header to check; > how many entries each should have.; > Outline; > - Add a new validation type for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() function, for each info header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some; > additional parsing because it returns an Object; > - (Bonus points if you use the isFixedCount() and getCount() functions; > on the VCF info header li",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:2125,Validat,ValidateVariants,2125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['Validat'],['ValidateVariants']
Security,"en't seen discussed in these threads.; Perhaps it's impractical, but I'll mention it anyway. It seems like ; another approach would be to create (internal to the implementation) a ; ""header tag"" that could be efficiently serialized; and passed as part of the SAMRecord when you need to distribute it. The ; header tag could be used by the receiver to reattach the SAMRecord to ; its header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and complexity of the header tag might also depend on the ; execution environment. If the execution environment only supports a ; small finite number of headers, the header tag could be a small integer, ; or in a different execution environment it could be; a unique hash of the header or something like that. Memory footprint in ; the receiver is minimized because many SAMRecords can all share the same ; header object.; This requires more work to support in each execution environment, but it ; seems like it could be efficient and allows application code written to ; operate on SAMRecords to be portable; across different execution environments without having to contend with ; the possible presence of headerless SAMRecords. -Bob. On 9/17/15 4:28 PM, droazen wrote:. > @davidadamsphd https://github.com/davidadamsphd, @lbergelson ; > https://github.com/lbergelson, and myself met for an hour or two ; > just now to discuss this issue, and after reviewing all the options I ; > think we were convinced by the following argument:; > ; > The |SAMRecord| class currently allows its header to be set to null, ; > so if there are cases where the class won't function properly or can ; > enter int",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:2261,hash,hash,2261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,1,['hash'],['hash']
Security,en; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 10 more; Caused by: com.google.cloud.storage.StorageException: 403 Forbidden; 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to broad-jg-dev-11k-call-set/JointGenotyping/0cb36821-b8bf-4e6d-a352-07b101f6b7d1/call-ApplyRecalibration/shard-1734/GMKF_Seidman_CHD_WGS_904.filtered.1734.vcf.gz.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:526); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:114); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUni,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3735:3476,access,access,3476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3735,1,['access'],['access']
Security,"engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done initializing engine; 17:43:53.294 INFO ProgressMeter - Starting traversal; 17:43:53.294 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 17:43:53.302 INFO ValidateVariants - Shutting down engine; [March 21, 2017 5:43:53 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=194510848; java.lang.IllegalArgumentException: Illegal base [] seen in the allele; 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:231); 	at htsjdk.variant.variantcontext.Allele.create(Allele.java:374); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:181); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.str",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:4119,Validat,ValidateVariants,4119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"enotypeGVCFs \; 	-R 128_Mmul_10.fasta \; 	--variant gendb:///home/exacloud/gscratch/prime-seq/cachedData/16b9ede7-6db8-103a-9262-f8f3fc86a851/WGS_Feb22_1852.gdb \; 	-O /home/exacloud/gscratch/prime-seq/workDir/1bb5295c-6ec5-103a-8692-f8f3fc86cd3f/Job1.work/WGS_pre-mGAPv2.3_1852.vcf.gz \; 	--annotate-with-num-discovered-alleles \; 	-stand-call-conf 30 \; 	--max-alternate-alleles 6 \; 	--force-output-intervals mmul10.WGS-WXS.whitelist.v2.3.sort.merge.bed \; 	-L 1:1-3714165 \; 	--only-output-calls-starting-in-intervals \; 	--genomicsdb-shared-posixfs-optimizations; ```. and the exception:. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/broadinstitute/hellbender/relocated/com/google/common/base/Function; 	at org.broadinstitute.hellbender.Main.<clinit>(Main.java:45); Caused by: java.lang.ClassNotFoundException: org.broadinstitute.hellbender.relocated.com.google.common.base.Function; 	at java.net.URLClassLoader$1.run(URLClassLoader.java:370); 	at java.net.URLClassLoader$1.run(URLClassLoader.java:362); 	at java.security.AccessController.doPrivileged(Native Method); 	at java.net.URLClassLoader.findClass(URLClassLoader.java:361); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	... 1 more; Caused by: java.util.zip.ZipException: invalid LOC header (bad signature); 	at java.util.zip.ZipFile.read(Native Method); 	at java.util.zip.ZipFile.access$1400(ZipFile.java:60); 	at java.util.zip.ZipFile$ZipFileInputStream.read(ZipFile.java:716); 	at java.util.zip.ZipFile$ZipFileInflaterInputStream.fill(ZipFile.java:419); 	at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:158); 	at sun.misc.Resource.getBytes(Resource.java:124); 	at java.net.URLClassLoader.defineClass(URLClassLoader.java:462); 	at java.net.URLClassLoader.access$100(URLClassLoader.java:73); 	at java.net.URLClassLoader$1.run(URLClassLoader.java:368). ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675:1632,secur,security,1632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675,4,"['Access', 'access', 'secur']","['AccessController', 'access', 'security']"
Security,"ent with the command:; ```; conda env create -n gatk -f scripts/gatkcondaenv.yml; ```; This currently fails with the following message (at least on MacOS):; ```; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpack_file; flatten=not filename.endswith('.whl'); File ""/Users/markw/anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 482, in unzip_file; zipfp = open(filename, 'rb'); FileNotFoundError: [Errno 2] No such file or directory: '/Users/markw/IdeaProjects/gatk/scripts/build/gatkPythonPackageArchive.zip'; ```; Moving gatkcondaenv.yml to the GATK root solves the issue. We can either change the yml location or modify the readme.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4741:1148,hash,hashes,1148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4741,4,['hash'],['hashes']
Security,ent.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:494); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.io.EOFException: SSL peer shut down incorrectly; 	at sun.security.ssl.InputRecord.read(InputRecord.java:505); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	... 34 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:3986,secur,security,3986,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156,2,['secur'],['security']
Security,ent: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_libs__7655440475844189559.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:8088/proxy/application_1603353714322_0004/; 	 user: jacky; 20/10/22 12:02:35 INFO yarn.Client: Application report for application_1603353714322_0004 (state: AC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6906:3481,Secur,SecurityManager,3481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906,1,['Secur'],['SecurityManager']
Security,"ents - Gencode 34 CANONICAL; 17:14:13.209 INFO FuncotatorEngine - VCF sequence dictionary detected as B37 in HG19 annotation mode. Performing conversion.; 17:14:13.209 WARN FuncotatorEngine - WARNING: You are using B37 as a reference. Funcotator will convert your variants to GRCh37, and this will be fine in the vast majority of cases. There MAY be some errors (e.g. in the Y chromosome, but possibly in other places as well) due to changes between the two references.; 17:14:13.411 INFO ProgressMeter - Starting traversal; 17:14:13.412 INFO ProgressMeter - Current Locus Elapsed Minutes Features Processed Features/Minute; 17:14:15.391 INFO FuncotateSegments - Shutting down engine; [September 11, 2022 5:14:15 PM GMT] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.30 minutes.; Runtime.totalMemory()=1752170496; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:917445 end:911649; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2939); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866); at org.broadinstitu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314:1170,validat,validateArg,1170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314,2,['validat'],['validateArg']
Security,"epare, factored out sample name (#7288); - Remove training sites only param from ExtractFeatures broadinstitute/dsp-spec-ops#261; - add param for mem for indels (#7282); - Ah prepare localize option (#7299); - Export sites only vcf STEP 1-- 317 add AC, AN, AF to the final VCF (#7279); - AoU GVS Cohort Extract wdl (#7242); - reliability (#7310); - bump to include FT tag filtering (#7316); - First pass at a Terra QuickStart (#7267); - Ah fix timestamp query (#7319); - 313 Cleanup Extract Cohort params (#7293); - bump bq storage version. See GVS-332 (#7330); - Variant Store extraction - Add VCF size to output (#7329); - add WARP-style scattering to SNPsVariantRecalibrator in GvsCreateFilterSet (#7320); - added ref ranges support (#7337); - 318 Sites only filtered vcf then annotate wdl (#7305); - Replace service_account_json (file) with service_account_json_path (string) to allow call-caching (#7347); - Parallelize create filterset by breaking out the 3 filter set file creation/loads into separate tasks (#7342); - Create WDL to validate VAT and add first test (#7352); - Add task for VAT validation #3 (#7360); - Add task for VAT validation #4 (#7363); - Instructions on how to download BQ Metadata and visualize results (#7359); - don't mix contigs, rightsize memory (#7361); - Add custom annotations as ac an af (#7351); - Add task for VAT validation #8 & 9 (#7364); - added bcftools, upgraded gcloud version (#7369); - fix wdl (#7378); - Update .dockstore.yml; - Add VAT validation rule #5 [VS-16] (#7365); - Add VAT validation rule #7 [VS-14] and validation rule #6 [VS-15] (#7379); - Batching of samples for create import TSVs (#7382); - Add VAT validation rule #2 [VS-19] (#7374); - Create VAT scripts directory (#7386); - fixing SA change from file to string (#7371); - add extract_subpop script (#7387); - Add is_loaded column to sample_info and logic to populate after ingest [VS-158] (#7389); - Add Gnomad subpopulation info into the VAT (#7381); - implement GVS ID assignment (#",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:15969,validat,validate,15969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,8,['validat'],"['validate', 'validation']"
Security,eq.1mb.1RG.sg4.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/HiSeq.1mb.1RG.sg5.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.dict; src/test/resources/org/broadinstitute/hellbender/tools/Homo_sapiens_assembly18.10k_lines.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/dream3-chr20.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_2.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/dream/vcfs/sample_4.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/mutect/na12878-chr20-consumes-zero-reference-bases.bai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/repeated_reads.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/mutect/validation/nearby_indels.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/NA12878.rg_subset.chr1.recal_data.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/NA12878.rg_subset.chrY_Plus.recal_data.table.gz; src/test/resources/org/broadinstitute/hellbender/tools/originalQuals.chr1.1-1K.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.chr1only.dict; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.chr1only.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.intervals; src/test/resources/org/broadinstitute/hellbender/tools/print_reads_sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.sorted.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/print_reads.sorted.chr1_1.bam.bai; ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:39469,validat,validation,39469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['validat'],['validation']
Security,er #2643 +/- ##; ===============================================; + Coverage 76.126% 76.133% +0.007% ; - Complexity 11150 11160 +10 ; ===============================================; Files 769 769 ; Lines 40751 40767 +16 ; Branches 7110 7115 +5 ; ===============================================; + Hits 31022 31037 +15 ; + Misses 7062 7061 -1 ; - Partials 2667 2669 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2643?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2643?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `76.73% <71.429%> (+0.414%)` | `25 <0> (+2)` | :arrow_up: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2643?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `93.75% <0%> (-1.563%)` | `21% <0%> (-1%)` | |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2643?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `81.081% <0%> (-0.737%)` | `24% <0%> (+8%)` | |; | [...ute/hellbender/utils/recalibration/RecalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2643?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL1JlY2FsVXRpbHMuamF2YQ==) | `89.407% <0%> (+0.045%)` | `52% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2643?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `74.026% <0%> (+1.948%)` | `35% <0%> (ø)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-298471381:1542,Validat,ValidateVariants,1542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-298471381,1,['Validat'],['ValidateVariants']
Security,"er container); 17/10/11 14:19:12 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/11 14:19:12 INFO yarn.Client: Setting up container launch context for our AM; 17/10/11 14:19:12 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/11 14:19:12 INFO yarn.Client: Preparing resources for our AM container; 17/10/11 14:19:12 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/11 14:19:12 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-8c88439f-dcb0-48b2-86f3-fc82cef4c438/__spark_conf__8945422067005652415.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507683879816_0006/__spark_conf__8945422067005652415.zip; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/11 14:19:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); users with modify permissions: Set(hdfs); 17/10/11 14:19:13 INFO yarn.Client: Submitting application 6 to ResourceManager; 17/10/11 14:19:13 INFO impl.YarnClientImpl: Submitted application application_1507683879816_0006; 17/10/11 14:19:14 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:14 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start time: 1507702753100; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507683879816_0006/; 	 user: hdfs; 17/10/11 14:19:15 INFO yarn.Client: Application report for application_1507683879816_0006 (state: ACCEPTED); 17/10/11 14:19:15 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(null); 17/10/11 14:19:15 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:6305,Secur,SecurityManager,6305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,3,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"er of query methods in GoogleGenomicsReadAdapter adapter; throw if the corresponding field is not present in the underlying read. For some; of these there are guard methods you can call to avoid this (see for example; the changes in ReadUtils.java), but for some of the others I'm not sure how to; usefully query the state without already knowing the answer, ie.:. -isSupplementaryAlignment; -isSecondaryAlignment,; -failsVendorQualityCheck; -isDuplicate; -mateIsReverseStrand. To have fidelity with SAMRecord.getSAMString , we need to be able to query these; (as does ReadUtils.getFlags, which has a similar problem, but I changed that to; use guard methods to prevent throwing). In a couple of cases I had to change; the Read adapter to not throw. We need to figure out if this kind; of change is ok. or what the alternative is. 2) This is incidental to this PR, but there are a few inconsistencies between how; GenomicsConverter.makeSAMRecord and ReadUtils compute derived state values, ie. flags.; I can work around these in the getSAMString tests (I'm using Read->SAMRecord; conversions to validate the tests), but the underlying format conversions; are inconsistent. Should we align them ?. For example, GenomicsConverter sets the firstInPair flag on the SAMRecord if readNumber==0,; even if numberOfReads==1, whereas the ReadUtils/GoogleReadAdapter requires readNumber==0; and numberOfReads==2. Likewise the unmapped flag is determined differently: Genomics converter: (http://google-genomics.readthedocs.org/en/latest/migrating_tips.html):; final boolean unmapped = (read.getAlignment() == null || ; read.getAlignment().getPosition() == null || ; read.getAlignment().getPosition().getPosition() == null);; ReadUtils:; private boolean positionIsUnmapped( final Position position ) {; return position == null ||; position.getReferenceName() == null || position.getReferenceName().equals(SAMRecord.NO_ALIGNMENT_REFERENCE_NAME) ||; position.getPosition() == null || position.getPosition() < 0;; }",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/871:1160,validat,validate,1160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871,1,['validat'],['validate']
Security,"er.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1641,Validat,ValidateVariants,1641,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,er/engine/MultiVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5032/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTXVsdGlWYXJpYW50V2Fsa2VyLmphdmE=) | `96.154% <0%> (-0.398%)` | `24% <0%> (+11%)` | |; | [...der/tools/walkers/variantutils/SelectVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5032/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50cy5qYXZh) | `79.405% <0%> (-0.181%)` | `158% <0%> (+43%)` | |; | [...nder/utils/samples/MendelianViolationUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5032/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zYW1wbGVzL01lbmRlbGlhblZpb2xhdGlvblVuaXRUZXN0LmphdmE=) | `100% <0%> (ø)` | `47% <0%> (+7%)` | :arrow_up: |; | [...eVcfWithExpectedAlleleFractionIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5032/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQW5ub3RhdGVWY2ZXaXRoRXhwZWN0ZWRBbGxlbGVGcmFjdGlvbkludGVncmF0aW9uVGVzdC5qYXZh) | `100% <0%> (ø)` | `10% <0%> (+3%)` | :arrow_up: |; | [...s/walkers/variantutils/SelectVariantsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5032/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c1VuaXRUZXN0LmphdmE=) | `100% <0%> (ø)` | `14% <0%> (+2%)` | :arrow_up: |; | [.../validation/RemoveNearbyIndelsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5032/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `100% <0%> (ø)` | `4% <0%> (+1%)` | :arrow_up: |; | ... and [14 more](https://codecov.io/gh/broadinstitute/gatk/pull/5032/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5032#issuecomment-406335133:3484,validat,validation,3484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5032#issuecomment-406335133,1,['validat'],['validation']
Security,"er: IntelDeflater; 10:33:37.513 INFO Mutect2 - Inflater: IntelInflater; 10:33:37.514 INFO Mutect2 - GCS max retries/reopens: 20; 10:33:37.514 INFO Mutect2 - Requester pays: disabled; 10:33:37.514 INFO Mutect2 - Initializing engine; 10:33:37.874 INFO Mutect2 - Shutting down engine; [August 28, 2019 at 10:33:37 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.05 minutes.; Runtime.totalMemory()=161480704; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:463); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:457); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.GATKTool.validateSequenceDictionaries(GATKTool.java:769); at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:711); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.onStartup(AssemblyRegionWalker.java:161); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291). This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/60577#Comment_60577",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6142:3501,validat,validateDictionaries,3501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6142,2,['validat'],"['validateDictionaries', 'validateSequenceDictionaries']"
Security,erException` instead. ```; ./gatk-launch BwaSpark -I hdfs://sn1:8020/user/$USER/gatk/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -R hdfs://sn1:8020/user/$USER/gatk/human_g1k_v37.fasta -O hdfs://sn1:8020/user/$USER/gatk/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam -- --sparkRunner SPARK --sparkMaster spark://sn1:7077 --driver-memory 8G --num-executors 4 --executor-cores 9 --executor-memory 27g; ```. ```; java.lang.NullPointerException; at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getContigNames(SequenceDictionaryUtils.java:464); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.getCommonContigsByName(SequenceDictionaryUtils.java:458); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.compareDictionaries(SequenceDictionaryUtils.java:234); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:150); at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.validateToolInputs(GATKSparkTool.java:402); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:312); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:108); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:166); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:185); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:76); at org.broadinstitute.hellbender.Main.main(Main.java:92); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2020:1012,validat,validateDictionaries,1012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2020,1,['validat'],['validateDictionaries']
Security,"erator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:912); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 00:11:09.632 WARN TaskSetManager:66 - Lost task 15.0 in stage 1.0 (TID 519, localhost): java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinsti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:5502,Hash,HashMap,5502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Hash'],['HashMap']
Security,"erer.java:216); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:168); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:781); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); ```; and; ```; java.lang.IllegalStateException: Allele in genotype G* not in the variant context [C*, T]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.tools.exome.orientationbiasvariantfilter.OrientationBiasFilterer.annotateVariantContextsWithFilterResults(OrientationBiasFilterer.java:216); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:211); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:840); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.br",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3291:2321,validat,validate,2321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3291,1,['validat'],['validate']
Security,"erformed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The following items are necessary done for auto",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:1068,validat,validations,1068,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502,1,['validat'],['validations']
Security,"error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.:1,0,0:1:.:0,0,0,0,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:3,0,0:3:.:0,0,0,0,0,0 ./.:7,0,0:7:.:0,0,0,0,0,0 1/1:0,0,0:0:0:45,3,0,3,0,0 ./.:0,0,0 1/1:0,0,1:1:0:45,3,0,3,0,0 1/1:0,0,0:0:0:267,18,0,18,0,0 ./.:9,0,0:9:.:0,0,0,0,0,0 ; . The exactly the same happens when I run GenotypeGVCFs in --include-non-variant-sites and when I run GenotypeGVCFS and ValidateVariants in v4.1.7.0. In principle, these sites just take up space in the vcf, as the corr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1975,validat,validation,1975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['validat'],['validation']
Security,"error specified; 1 error; 1 warning; :compileJava FAILED; :compileJava (Thread[Daemon worker Thread 2,5,main]) completed. Took 4.116 secs. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileJava'.; > Compilation failed; see the compiler error output for details. * Try:; Run with --debug option to get more log output. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':compileJava'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35); at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52); at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53); at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:233); at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:74); at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPla",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4248:6010,Validat,ValidatingTaskExecuter,6010,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248,1,['Validat'],['ValidatingTaskExecuter']
Security,"es); gatk SplitNCigarReads. ### Affected version(s); - gatk 4.2.6.1. ### Description ; I produced the bam files using STAR, and adjusted the MQ value to 60. I then used sambamba markdup to mark duplicate, then I proceeded to use SplitNCigarReads. The CPU load for SplitNCigarReads was very high and at certain times can spike up to 2400%. I tried limiting the cpu usage with commands like `-XX:ParallelGCThreads=1` and `-XX:ConcGCThreads=1`, but it doesn't seem to have an effect. (The cpu usage sometimes do stay at 100%) I also adjusted the MQ value in STAR to lessen the load in SplitNCigarReads. I also tried to increase the read size to reduce I/O time.; ![image](https://user-images.githubusercontent.com/106958825/175206165-08b28567-d671-45fa-b033-f20c4792edb7.png). #### Steps to reproduce; STAR; ```; STAR \; --genomeDir ${star_reference_path} \; --runThreadN 16 \; --readFilesIn ${file_1} ${file_2} \; --readFilesCommand ""gunzip -c"" \; --sjdbOverhang 149 \; --outSAMtype BAM SortedByCoordinate \; --outBAMsortingThreadN 16 \; --outSAMmultNmax 1 \; --outSAMmapqUnique 60 \; --outSAMattrRGline ID:${id} LB:RNASEQ SM:${sample_name} PL:ILLUMINA PU:${platform_unit} PM:${instrument_id} \; --limitBAMsortRAM 50000000000 \; --twopassMode Basic \; --outFileNamePrefix /rawdata/rnaseq/clean/bam/1.; ```. Mark Duplicate; ```; sambamba markdup \; -t 4 \; --tmpdir=/tmp \; --hash-table-size=262144 \; --overflow-list-size=67108864 \; /rawdata/rnaseq/clean/bam/1.Aligned.sortedByCoord.out.bam \; /rawdata/rnaseq/clean/bam/1.aligned.duplicate_marked.sorted.bam \; ```. SplitNCigarReads; ```; gatk --java-options ""-Djava.io.tmpdir=/tmp -Xmx20G -XX:ParallelGCThreads=1 -XX:ConcGCThreads=1"" SplitNCigarReads \; -R ${reference_path} \; --tmp-dir /tmp \; -I /rawdata/rnaseq/clean/bam/1.aligned.duplicate_marked.sorted.bam \; -O /rawdata/rnaseq/clean/bam_gatk/1.aligned.duplicate_marked.sorted.bam \; --create-output-bam-md5 TRUE \; --max-reads-in-memory 1000000 \; --skip-mapping-quality-transform TRUE \; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7914:1418,hash,hash-table-size,1418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7914,1,['hash'],['hash-table-size']
Security,"es.githubusercontent.com/11076296/158385777-6174f8b8-7abb-4b31-92d1-11cc8064854b.png). Note that the malaria data used was pretty small: chr1-2 training (~20k positive training/truth variants, ~50k negative training variants; note also that the threshold for determining negative training was not tuned---a threshold corresponding to a 98% truth sensitivity was arbitrarily chosen), chr3 validation (~50k variants), and chr4-6 test (~150k variants). The LL score is calculated from a validation set held out from the training/truth positives used to train the model, while the F1 score is calculated using ""orthogonal truth"" positives/negatives determined using 3 families of ~30 trios each. However, there's some arbitrariness in how we define the boundary for the latter positives/negatives, and hence some arbitrariness in the F1 score itself. But I'd expect using gold-standard GIAB truth would be more straightforward. Not sure how much we can conclude, but that the validation and test F1s are similar and that the validation LL score isn't *too* far off are encouraging. That said, there is a pretty big drop in recall when optimizing LL. But we should also expect some discrepancy between LL and F1, according to one of the papers linked above. I would hope that with more variants or reliable training/truth (as in your data), things might stabilize or line up better. I'll try running with more malaria data, as well. The following trios x sites heatmap (top plot) for the validation set might better illustrate the arbitrariness in F1 (click to enlarge):. ![image](https://user-images.githubusercontent.com/11076296/158385585-1a0dfe8e-d4b7-4770-aed0-19ad81162c92.png). Here, yellow = het errors (since these are supposed to be clonal malaria samples), red = Mendelian errors, grey = no calls, green = Mendelian consistency, white = reference. The second plot shows the training/truth positives used to train the model and to calculate the LL score in the validation shard. The third plot s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1067396431:1148,validat,validation,1148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1067396431,2,['validat'],['validation']
Security,esources/org/broadinstitute/hellbender/tools/spark/sv/utils/SVContext.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/splitNCigarReadsSnippet.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.bam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.cram; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.dict; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/split_reads_missing_lib.sam; src/test/resources/org/broadinstitute/hellbender/tools/split_reads.sam; src/test/resources/org/broadinstitute/hellbender/tools/validation/marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/picard.marked.CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam; src/test/resources/org/broadinstitute/hellbender/tools/validation/single.read.bai; src/test/resources/org/broadinstitute/hellbender/tools/valid.cram.crai; src/test/resources/org/broadinstitute/hellbender/tools/valid.dict; src/test/resources/org/broadinstitute/hellbender/tools/valid.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.indels.recal.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.input.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.HACKEDhg38header.vcf.gz.tbi; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.postSNPinput.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/VQSR/VQSR.AStest.snps.recal.vcf.idx; src/test/r,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:45543,validat,validation,45543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['validat'],['validation']
Security,"et held out from the training/truth positives used to train the model, while the F1 score is calculated using ""orthogonal truth"" positives/negatives determined using 3 families of ~30 trios each. However, there's some arbitrariness in how we define the boundary for the latter positives/negatives, and hence some arbitrariness in the F1 score itself. But I'd expect using gold-standard GIAB truth would be more straightforward. Not sure how much we can conclude, but that the validation and test F1s are similar and that the validation LL score isn't *too* far off are encouraging. That said, there is a pretty big drop in recall when optimizing LL. But we should also expect some discrepancy between LL and F1, according to one of the papers linked above. I would hope that with more variants or reliable training/truth (as in your data), things might stabilize or line up better. I'll try running with more malaria data, as well. The following trios x sites heatmap (top plot) for the validation set might better illustrate the arbitrariness in F1 (click to enlarge):. ![image](https://user-images.githubusercontent.com/11076296/158385585-1a0dfe8e-d4b7-4770-aed0-19ad81162c92.png). Here, yellow = het errors (since these are supposed to be clonal malaria samples), red = Mendelian errors, grey = no calls, green = Mendelian consistency, white = reference. The second plot shows the training/truth positives used to train the model and to calculate the LL score in the validation shard. The third plot shows the ""orthogonal truth"" positives/negatives used to calculate F1. So we can see that the difficulty in deriving F1 as a function of the score along the horizontal axis to give the third plot lies in collapsing the columns in the top plot into a single condition positive or condition negative status. Again, hard to do so without some arbitrariness; I simply came up with some rules to convert various amounts of red, yellow, green, etc. in each column to a red/white/green status. If you're u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1067396431:1659,validat,validation,1659,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1067396431,1,['validat'],['validation']
Security,etryHelper.java:47); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleCl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:6466,secur,security,6466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['secur'],['security']
Security,etryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:114); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.net.UnknownHostException: www.googleapis.com; 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:668); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetH,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094:6597,secur,security,6597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094,1,['secur'],['security']
Security,"eue; SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=121, target=bigquerystorage.googleapis.com:443} was not shutdown properly!!! ~*~*~*; Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.; java.lang.RuntimeException: ManagedChannel allocation site; 	at io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93); 	at io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53); 	at io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44); 	at io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:615); 	at io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:261); 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createSingleChannel(InstantiatingGrpcChannelProvider.java:360); 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.access$1800(InstantiatingGrpcChannelProvider.java:81); 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider$1.createSingleChannel(InstantiatingGrpcChannelProvider.java:231); 	at com.google.api.gax.grpc.ChannelPool.create(ChannelPool.java:72); 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.createChannel(InstantiatingGrpcChannelProvider.java:241); 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:219); 	at com.google.api.gax.rpc.ClientContext.create(ClientContext.java:199); 	at com.google.cloud.bigquery.storage.v1.stub.EnhancedBigQueryReadStub.create(EnhancedBigQueryReadStub.java:89); 	at com.google.cloud.bigquery.storage.v1.BigQueryReadClient.<init>(BigQueryReadClient.java:129); 	at com.google.cloud.bigquery.storage.v1.BigQueryReadClient.create(BigQueryReadClient.java:110); 	at com.google.cloud.bigquery.storage.v1.BigQueryReadClient.create(BigQueryReadClient.java:102); 	at org.broadinstitute.hellbender.utils.bigquery.St",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7583:1303,access,access,1303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7583,1,['access'],['access']
Security,eup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/qc/pileup/reads_data_source_test1.samtools.pileup.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.IMPROPER_PAIR.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.MultiContext.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.NON_REF.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.SYNONYMOUS_CODING.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/rnaseq/ASEReadCounter/NA12878.chr20_2444518_2637800.RNAseq.warnings.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/UnmarkDuplicates/allDuplicates.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_incompatibleDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents_lexDict.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/complexEvents.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validati,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:60190,Validat,ValidateVariants,60190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['Validat'],['ValidateVariants']
Security,execute(NetHttpRequest.java:93); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:158); 	at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:489); 	at com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:206); 	at com.google.cloud.hadoop.util.CredentialConfiguration.getCredential(CredentialConfiguration.java:70); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1825); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1012); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:975); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2687); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2669); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:295); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:500); 	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(FileInputFormat.java:469); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1084); 	at org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2.apply(SparkContext.scala:1072); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.SparkContext.withScope(SparkContext.scala:679); 	at org.apache.spark.SparkContext.newAPIHadoopFile(SparkContext.scala:1072); 	at org.apa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4369:7498,access,access,7498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369,1,['access'],['access']
Security,executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:347); ... 17 more; Caused by:; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); at shaded.cloud-nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); at shaded.cloud-nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); at shaded.cloud-nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:317); ... 27 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:4009,secur,security,4009,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,2,['secur'],['security']
Security,"executing `gradle test -Dtest.single=ValidateVariantsIntegrationTest`; produces, among other things, this:. testBadID2_OKif_notInDBSNP(org.broadinstitute.hellbender.tools.walkers.ValidateVariantsIntegrationTest) produced standard out/err: [Wed Mar 18 21:15:38 EDT 2015] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants --dbsnp **org.broadinstitute.hellbender.engine.FeatureInput@4c4054af** **--validationTypeToExclude [REF, ALLELES, CHR_COUNTS]**. Two problems:; 1) FeatureInput needs a meaningful toString; 2) the argument that is a list of enum values should be printed as multiples of 'validationTypeToExclude' each with a value (so that the commandline is copy-paste-able)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/318:37,Validat,ValidateVariantsIntegrationTest,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/318,5,"['Validat', 'validat']","['ValidateVariants', 'ValidateVariantsIntegrationTest', 'validationTypeToExclude']"
Security,expose DEFAULT_FEATURE_CACHE_LOOKAHEAD as a configurable option,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3489:0,expose,expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3489,1,['expose'],['expose']
Security,expose intervalMerging Argument in IntervalArguments,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/165:0,expose,expose,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/165,1,['expose'],['expose']
Security,"f --recal-file recalibration. cat sb-recalibrated-tiny.vcf; ##fileformat=VCFv4.2; ##FILTER=<ID=LOW_VQSLOD,Description=""VQSLOD < 0.0"">; ##FILTER=<ID=PASS,Description=""Site contains at least one allele that passes filters"">; ##GATKCommandLine=<ID=ApplyVQSR,CommandLine=""ApplyVQSR --recal-file /Users/vlad/tmp/sb/recalibration --output sb-recalibrated-tiny-renamed4.vcf --variant sb-good-tiny-renamed4.vcf --use-allele-specific-annotations false --ignore-all-filters false --exclude-filtered false --mode SNP --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays --disable-tool-default-read-filters false"",Version=""4.1.9.0"",Date=""31 May 2021 12:07:54 PM"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##INFO=<ID=NEGATIVE_TRAIN_SITE,Number=0,Type=Flag,Description=""This variant was used to build the negative training set of bad variants"">; ##INFO=<ID=POSITIVE_TRAIN_SITE,Number=0,Type=Flag,Description=""This variant was used to build the positive training set of good variants"">; ##INFO=<ID=SB,Number=1,Type=Float,Description=""Strand Bias"">; ##INFO=<ID=VQSLOD,Number=1,Type=Float,Description=""Log odds of being a true variant versus being false under the trained gaussian mixture model"">; ##INFO=<ID=culprit,Number=1,Type=String,Description=""The annotation which w",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7280:2401,validat,validation,2401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7280,1,['validat'],['validation']
Security,"f.gz`) . The log issue looks very similar to that described here [#7162)](https://github.com/broadinstitute/gatk/issues/7162), but the *Problematic frame* information is different. ; As suggested in this issue [#5690](https://github.com/broadinstitute/gatk/issues/5690), the problem disappears when using gatk 4.1.3.0 on the same inputs. . log:; ```bash; 17:37:20.674 INFO ProgressMeter - chr20:43968267 10.6 44000 4132.2; 17:37:38.646 INFO ProgressMeter - chr22:22736335 10.9 45000 4110.5; 17:37:52.672 INFO ProgressMeter - chrX:7000139 11.2 46000 4113.9; 17:38:05.421 INFO ProgressMeter - chrX:26360893 11.4 47000 4125.0; 17:38:17.207 INFO ProgressMeter - chrX:44917184 11.6 48000 4141.4; 17:38:29.312 INFO ProgressMeter - chrX:77681733 11.8 49000 4155.3; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fc0ccec5cdb, pid=15987, tid=15988; #; # JRE version: OpenJDK Runtime Environment (11.0.11+9) (build 11.0.11+9-Ubuntu-0ubuntu2.18.04); # Java VM: OpenJDK 64-Bit Server VM (11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # C [libc.so.6+0x97cdb] cfree+0x31b; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/kt/core.15987); #; # An error report file with more information is saved as:; # /home/kt/hs_err_pid15987.log; ```. #### Steps to reproduce; My commands:; ```bash; gatk --java-options ""-Xmx11g"" \; FilterAlignmentArtifacts \; -R GRCh38.no_alt_analysis_set.fa \; -V in.vcf.gz \; -I bamout.bam \; --bwa-mem-index-image Homo_sapiens_assembly38.fa.img \; --num-regular-contigs 194 \; --max-reasonable-fragment-length 2000 \; --drop-ratio 0.1 \; --indel-start-tolerance 8 \; -O out.vcf.gz; ```; I copied the input vcfs (small: test.cf.gz and initial: m2.vcf.gz), bamout and ""hs_err_pid.logs"" to `gs://iseq/kt/strange-bug/` ; I hope you can access them. ; Best,; Kasia",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7247:2633,access,access,2633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7247,1,['access'],['access']
Security,"factor of around four, which gzip often does not reach (because it doesn't know ahead of time that DNA has only four letters).; Use reference genome fasta as proxy for nearly no repetition at all. It doesn't compress much beyond 2bit. Tweaking of the Huffmann coding etc. might have influenced the compression level much in this case, by ""giving the compressor a subtle hint about the four letters"".; Paradoxically, Intel might have optimized for average data and thus brought a disadvantage for the four letter nature of DNA (and also the few letters used in quality data encoding compared to text). 3. BQSR:; When I did interleaving compression experiments, I noticed that the BQSR step decreases compressiblity considerably.; In this example I had the same BAM file in different versions that were aligned to hs38DH, hs38, hs37d5 and could compress them to nearly the size of one, by putting similar pieces of the files after one another.; Adding the same BAM with BQSR increased final file size more than several pre-BQSR versions together.; Note: This piece-meal packing might be useful for different BAMs mostly only with many BAMs where similar regions accumulate. 4. Even faster:; In my experience, level 0 (no compression) (with samtools view -u) increases speed even more, if files are on a lz4 encrypted disk (such as with ZFS).; The speed-up of lz4 over even level 1 of any gzip-like compression is substantial.; With data on SSDs or similarly fast storage, that can make a huge difference. Another factor 6 six faster than level 1 on compression and a factor 9 on decompression. The then possible decompression speed of 3GB/s makes it possible to e.g. load a 180GB bam into a RAM disk in 60 seconds on a sufficiently fast SSD array (e.g. as on an aws ec2 i3.8xlarge instance).; Still 600MB/s if the RAM is also lz4 compressed. See image from https://github.com/lz4/lz4 below.; ![grafik](https://user-images.githubusercontent.com/1612006/35339046-d84b8b78-011f-11e8-99ec-a36cde725bb3.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673:3572,encrypt,encrypted,3572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673,1,['encrypt'],['encrypted']
Security,fb822dddb0cad0123d48c33124b6065; Status: Downloaded newer image for broadinstitute/gatk:4.2.2.0; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# ; (gatk) root@bc90fdaf700c:/gatk# apt-get update; Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]; Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB] ; Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB] ; Get:4 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [543 kB] ; Get:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6786 B] ; Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1426 kB] ; Err:5 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease ; The following signatures couldn't be verified because the public key is not available: NO_PUBKEY FEEA9169307EA071 NO_PUBKEY 8B57C5C2836F4BEB; Get:7 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2295 kB] ; Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] ; Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] ; Get:10 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB] ; Get:11 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]; Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB] ; Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB] ; Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2200 kB]; Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]; Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [575 kB]; Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2731 kB]; Get:18 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [11.4 kB]; Get:19 http://archive.ubuntu.com/ubuntu bionic,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7447:1488,secur,security,1488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7447,1,['secur'],['security']
Security,fix for sequence dict validation on cram,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1275:22,validat,validation,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1275,1,['validat'],['validation']
Security,fix inefficient hashcode computation and added tests to 100%,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1620:16,hash,hashcode,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1620,1,['hash'],['hashcode']
Security,fix invalid certificate for gatk-jenkins,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2446:12,certificate,certificate,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2446,1,['certificate'],['certificate']
Security,fix issue with validatevariants when validatign a gvcf and a record is followed by a record that is fully encompassed by the first one. The interval math was off in this case,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3530:15,validat,validatevariants,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3530,2,['validat'],"['validatevariants', 'validatign']"
Security,fix the script to validate-reads-spark-pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1921:18,validat,validate-reads-spark-pipeline,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1921,1,['validat'],['validate-reads-spark-pipeline']
Security,fixes #1398 . @yfarjoun can you review? it's a super simple picard-style CLP for comparing quals between bams (needed for GATK4 validation of BQSR - may be useful for GoTC too (?)),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1415:128,validat,validation,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1415,1,['validat'],['validation']
Security,"fixes #1486 (code already existed, just needed to be exposed). I found a limitation in Hadoop-BAM (https://github.com/HadoopGenomics/Hadoop-BAM/issues/68) regarding reading blocked vcfs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1496:53,expose,exposed,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1496,1,['expose'],['exposed']
Security,fixes #754. updating spark along side the dataflow jump; also updating other dependencies as well. changing GatkTestPipeline to downgrade a naming error to a warning; replacing calls to setName; replacing calls to setCoder with calls to withCoder when possible. hooking up the validation stringency for local files; fixes #745. disabling failing test and opening #774 to reenable it,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/775:277,validat,validation,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/775,1,['validat'],['validation']
Security,"fixes the issue where CommandLineExceptions produced no error message. added a public getUsage() method to CommandLineProgram; added a catch for these in instanceMain(), where the CommandLineProgram is in scope for printing the usage message; added a protected accessor getCommandLineParser to CommandLineProgram which guards against having an uninitialized CommandLineParser; moved the ""A USER ERROR HAS OCCURRED"" text out of the actual user exception and into the pretty printing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2340:261,access,accessor,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2340,1,['access'],['accessor']
Security,"flater: IntelInflater; 18:11:33.871 INFO PrintReadsSpark - GCS max retries/reopens: 20; 18:11:33.871 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:11:33.871 INFO PrintReadsSpark - Initializing engine; 18:11:33.871 INFO PrintReadsSpark - Done initializing engine; 17/10/13 18:11:33 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 17/10/13 18:11:34 WARN spark.SparkConf: spark.master yarn-client is deprecated in Spark 2.0+, please instead use ""yarn"" with specified deploy mode.; 17/10/13 18:11:34 INFO spark.SparkContext: Submitted application: PrintReadsSpark; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing view acls groups to: ; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing modify acls groups to: ; 17/10/13 18:11:34 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); groups with view permissions: Set(); users with modify permissions: Set(hdfs); groups with modify permissions: Set(); 17/10/13 18:11:34 INFO util.Utils: Successfully started service 'sparkDriver' on port 45754.; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/13 18:11:34 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 17/10/13 18:11:34 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 17/10/13 18:11:34 INFO storage.DiskBlockManager: Created local directory at /tmp/hdfs/blockmgr-ea0e0669-2981-4277-80a0-a67eddf1001d; 17/10/13 18:11:34 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB; 17/10/13 18:11:34 INFO spark.SparkE",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:4186,Secur,SecurityManager,4186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['Secur'],['SecurityManager']
Security,"fo header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some; > additional parsing because it returns an Object; > - (Bonus points if you use the isFixedCount() and getCount() functions; > on the VCF info header line to simplify annotations that aren't according; > to the number of alt alleles); > ; > Test data; > ; > /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > Should fail AC/AF validation at; > 1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120; > See results using:; > ; > use VCFtools; > vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for validateInfoFieldCounts(VCFInfoHeaderLine headerLine) or similar; add a test to VariantContextUnitTest.java; 2) After change 1) is merged, update ValidateVariants accordingly to use the new function and add a test to its integration tests. ---. @vdauwera commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222213763). @ldgauthier is this still a thing? (i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:3815,validat,validation,3815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,for @lbergelson - the validation fails now however. See https://github.com/broadinstitute/gatk/issues/1922,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1921#issuecomment-226817370:22,validat,validation,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1921#issuecomment-226817370,1,['validat'],['validation']
Security,"from @eitanbanks ""it must emit the non-reference genotype concordance rate by default. I don't think Picard does this now, but it's critical (esp. for CRSP validation from now on). And there should be a choice to count filtered/missing records in the truth set as discordant.""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/56#issuecomment-74611983:156,validat,validation,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/56#issuecomment-74611983,1,['validat'],['validation']
Security,"g engine; 00:05:57.036 INFO ProgressMeter - Starting traversal; 00:05:57.036 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr16:10185 the annotation AS_VarDP=59|115|0 was not a numerical value and was ignored; 00:07:26.967 WARN ReferenceConfidenceVariantContextMerger - Reducible annotation 'AS_VarDP' detected, add -G StandardAnnotation -G AS_StandardAnnotation to the command to annotate in the final VC with this annotation.; 00:07:26.991 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.02938786500000001,Cpu time(s),0.029037034000000003; [August 25, 2021 12:07:27 AM EDT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.55 minutes.; Runtime.totalMemory()=1807745024; java.lang.NullPointerException; at java.util.HashMap.putMapEntries(HashMap.java:500); at java.util.HashMap.putAll(HashMap.java:784); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:211); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:281); at org.broadinstitute.hellbender.engine.VariantLocusWalker.lambda$traverse$0(VariantLocusWalker.java:135); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.Ref",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437:8033,Hash,HashMap,8033,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437,1,['Hash'],['HashMap']
Security,g(ConfigurationUtil.java:39); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createOptionsBuilderFromConfig(GoogleHadoopFileSystemBase.java:2185); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1832); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1013); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:976); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2812); 	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:100); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2849); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2831); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:389); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:171); 	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:168); 	at java.base/java.security.AccessController.doPrivileged(Native Method); 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:168); 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:176); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:80); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:926); 	at org.broadinstitute.hellbender.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6522:1553,secur,security,1553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6522,1,['secur'],['security']
Security,g.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); 18/10/17 19:23:59 ERROR Executor: Exception in task 518.0 in stage 0.0 (TID 518); java.io.FileNotFoundException: /home/data/WGS/F002/F002.sort.bam (Too many open files); 	at java.io.FileInputStream.open0(Native Method); 	at java.io.FileInputStream.open(FileInputStream.java:195); 	at java.io.FileInputStream.<init>(FileInputStream.java:138); 	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:106); 	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:202); 	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:349); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); 	at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:147); 	at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:222); 	at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:187); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:186); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:141); 	at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:70); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316:5323,Checksum,ChecksumFileSystem,5323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316,1,['Checksum'],['ChecksumFileSystem']
Security,g/broadinstitute/hellbender/tools/walkers/ValidateVariants/gvcf.basepairResolution.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet_BAD_INCOMPLETE_REGION.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.BAD_MISSING_NON_REF.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/NA12891.AS.chr20snippet.missingrefblock.g.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad3.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleBad.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleRSIDonPositionNotInDBSNP.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationUnusedAllelesBugFix.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/IS3.snv.indel.sv-vs-G15512.prenormal.sorted.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/validation/basicshortmutpileup/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtriMixedPloidyTest.vcf; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioPopPriorsTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors/CEUtrioTest_chr1.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/Calculat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:61487,Validat,ValidateVariants,61487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,2,"['Validat', 'validat']","['ValidateVariants', 'validationExampleRSIDonPositionNotInDBSNP']"
Security,"gPloidy - GCS max retries/reopens: 20; 15:09:27.690 INFO DetermineGermlineContigPloidy - Requester pays: disabled; 15:09:27.690 INFO DetermineGermlineContigPloidy - Initializing engine; 15:09:37.241 INFO DetermineGermlineContigPloidy - Done initializing engine; 15:09:37.253 INFO DetermineGermlineContigPloidy - No contig-ploidy model was provided, running in cohort mode...; 15:09:37.253 INFO DetermineGermlineContigPloidy - Intervals specified...; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 15:09:38.533 INFO FeatureManager - Using codec IntervalListCodec to read file file:///home/n.liorni/snakemake_cnv_gatk/results/cnv/targets.preprocessed.interval_list; 15:09:38.659 INFO IntervalArgumentCollection - Processing 548086 bp from intervals; 15:09:38.697 INFO DetermineGermlineContigPloidy - Validating and aggregating coverage per contig from input read-count files...; 15:09:38.711 INFO DetermineGermlineContigPloidy - Aggregating read-count file results/cnv/hdf5/MGM20-0848_S4.hdf5 (1 / 4); 15:09:38.734 INFO DetermineGermlineContigPloidy - Aggregating read-count file results/cnv/hdf5/MGM20-0872_S2.hdf5 (2 / 4); 15:09:38.745 INFO DetermineGermlineContigPloidy - Aggregating read-count file results/cnv/hdf5/MGM20-1121_S4.hdf5 (3 / 4); 15:09:38.757 INFO DetermineGermlineContigPloidy - Aggregating read-count file results/cnv/hdf5/MGM20-1543_S10.hdf5 (4 / 4); 15:12:24.486 INFO DetermineGermlineContigPloidy - Shutting down engine; [18 ottobre 2021 15.12.24 CEST] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 2.95 minutes.; Runtime.totalMemory()=2215116800; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/cohort_determine_ploidy_and_depth.1340409154615700376.py --sample_cover",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905:4324,Validat,Validating,4324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7444#issuecomment-945753905,1,['Validat'],['Validating']
Security,"galArgumentException: beta must be greater than 0 but got -87566.7500301585; ```; ""this error only comes after the first pass of filtermutectCalls completed."". ValidateVarinats shows no errors when run on VCF.; ""The stats file was created by mutect2 for each shard and then joined with MergeMutectStats. Similar the read orientation model was built with the f1r2 files from all shards."". @davidbenjamin. --------------; Hi there,. I have a simulated dataset of related samples and currently running Mutect2 on it (10 tumor samples WGS with 130x); I managed to run everything through and now FilterMutectCalls crashes after the first pass through the variants with. ```; [October 1, 2019 12:16:16 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 370.68 minutes.; Runtime.totalMemory()=20597702656; java.lang.IllegalArgumentException: beta must be greater than 0 but got -87566.7500301585; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:14); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:42); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.learn(BinomialCluster.java:33); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$learnAndClearAccumulatedData$7(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.utils.IndexRange.forEach(IndexRange.java:116); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthP",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202:1042,validat,validateArg,1042,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202,1,['validat'],['validateArg']
Security,"gatk --java-options ""-Xmx4g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" BaseRecalibrator -I /mnt/fq2bam/sample1.markdup.sorted.bam \; -R /mnt/fq2bam/inputs/reference/files/Homo_sapiens_assembly38.fasta \; --known-sites /mnt/fq2bam/inputs/resources/files/Homo_sapiens_assembly38.known_indels.vcf.gz \; --known-sites /mnt/fq2bam/inputs/resources/files/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; --known-sites /mnt/fq2bam/inputs/resources/files/Homo_sapiens_assembly38.dbsnp138.vcf.gz \; -L chr1 \; -DF MappingQualityNotZeroReadFilter \; -DF MappedReadFilter \; -O /mnt/fq2bam/sample1_BQSR001.recal_data.table. I got the following error. java.lang.IllegalStateException: No cigar elements left after removing leading and trailing deletions.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:138); at org.broadinstitute.hellbender.utils.read.CigarBuilder.make(CigarBuilder.java:143); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.consolidateCigar(BaseRecalibrationEngine.java:293); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:118); at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:189); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:100); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8523:791,validat,validate,791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8523,1,['validat'],['validate']
Security,"gatk silently sets TMP_DIR globally readable/writable for all users. This is problematic for admins trying to maintain a secure multi-user environment. It would be better (imho) if gatk tests if TMP_DIR is writeable and errors out when it is not instead of just globally making it writeable by all users. src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java. for (final File f : TMP_DIR) {; // Intentionally not checking the return values, because it may be that the program does not; // need a tmp_dir. If this fails, the problem will be discovered downstream.; if (!f.exists()) f.mkdirs();; f.setReadable(true, false);; f.setWritable(true, false);",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4513:121,secur,secure,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4513,1,['secur'],['secure']
Security,gatk/pull/4029?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `22.807% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `91.667% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/spark/ApplyBQSRSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9BcHBseUJRU1JTcGFyay5qYXZh) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `88.542% <ø> (ø)` | `28 <0> (ø)` | :arrow_down: |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ291bnRGYWxzZVBvc2l0aXZlcy5qYXZh) | `93.548% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/walkers/bqsr/BaseRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4029/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQmFzZVJlY2FsaWJyYXRvci5qYXZh) | `88.372% <ø> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [.../hellbender/tools/spark/BaseRecalibratorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/402,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-354921087:1833,validat,validation,1833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-354921087,1,['validat'],['validation']
Security,"ge tested against the workflow (#8062); - VS-637 Address a couple of issues in SampleLoadStatus handling in GVSImportGenomes. (#8052); - Revert Alpinizing of apt dependent task [VS-688] (#8065); - Fix missing vat schema JSONs [VS-699] (#8072); - Fix integration expectations for fixed AD [VS-689] (#8066); - VS-698 Remove unnecessary columns from Call set statistics (#8073); - Fix Dockerfile nits that break 20.10.21 (#8078); - Nirvana 3.18.1 Docker images support [VS-661] (#8082); - Add option to not prepare __REF_DATA or __SAMPLES tables to Prepare [VS-697] (#8079); - ""build-base"" Docker image for faster variantstore image builds [VS-712] (#8085); - GVS / Hail VDS integration test [VS-639] (#8086); - Remove AI/AN from VDS docs [VS-726] (#8096); - Add flag for cost_observability table writing to support sub-cohort use case [VS-521] (#8093); - Document STS delivery process for VDS [VS-727] (#8101); - delete obsolete callset_QC directory and its contents [VS-318] (#8108); - doc link typo and add check for control samples in AVRO export (#8110); - Add defaults for scatter_count in GvsExtractCohortFromSampleNames [VS-496] (#8109); - Escape table names properly in ValidateVat WDL (#8116); - Vs 741 fix indefinite freeze in split intervals task when using exome data (#8113); - VAT Readme updates (#8090); - WDL and python scripts to use the VDS in the VAT (#8077); - VS-757 - Use JASIX to make sub-jsons of annotated output of Nirvana (#8133); - add note about permissions for P&S workflow to work (#8135); - VS-759 (and VS-760) (#8137); - VS-765. Scatter the RemoveDuplicates task. (#8144); - update delivery docs based on latest VDS delivery run [VS-770] (#8150); - Add monitoring to index vcf (#8151); - Make some noise when VDS validation succeeds (#8155); - Handle empty genes annotation file. (#8153); - Add escapes for otherwise problematic dataset / table names. (#8162); - New WDL to create VAT tsvs from previously generated BigQuery table. (#8165); - Treat withdrawn samples in ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:30901,Validat,ValidateVat,30901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['Validat'],['ValidateVat']
Security,"ge-4.0.0.0-local.jar HaplotypeCaller -L chr5 --reference genomes/ucsc_hg19.fasta --input NA12878_S1_md.bam --output hc_variants_7.vcf --bam-output realigned_slice_7.bam --max-reads-per-alignment-start 1000 --min-base-quality-score 0 --minimum-mapping-quality 0 --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityAvailableReadFilter --disable-read-filter NotSecondaryAlignmentReadFilter --disable-read-filter NotDuplicateReadFilter --disable-read-filter PassesVendorQualityCheckReadFilter --disable-read-filter NonZeroReferenceLengthAlignmentReadFilter --disable-read-filter GoodCigarReadFilter --disable-read-filter WellformedReadFilter`; [January 10, 2018 2:39:19 PM EST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 91.81 minutes.; Runtime.totalMemory()=7215251456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr5 start:71357769 end:71357768; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.tra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4120:1267,validat,validateArg,1267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120,1,['validat'],['validateArg']
Security,geImpl$5.call(StorageImpl.java:241); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.fetchSize(CloudStorageReadChannel.java:232); 	... 22 more; Caused by: java.net.SocketTimeoutException: connect timed out; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetH,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:6929,secur,security,6929,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['secur'],['security']
Security,"genotypes. We should use the definition of the info annotations in the header to check how many entries each should have.; ### Outline; - Add a new validation type for info-field counts to enum and to switch statement; - Grab info headers from input VCF with something like GATKVCFUtils.getVCFHeadersFromRods(getToolkit(), variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; - In the map() function, for each info header line, call on each VCFInfoHeaderLine getCount(vc) to get the expected number of info annotation entries; - Compare the expected number with a count based on vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some additional parsing because it returns an Object; - (Bonus points if you use the isFixedCount() and getCount() functions on the VCF info header line to simplify annotations that aren't according to the number of alt alleles); ### Test data. /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; Should fail AC/AF validation at ; `1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120`; See results using:. ```; use VCFtools; vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; ```. which outputs:; `INFO field at 1:768589 .. INFO tag [AC=1] expected different number of values (expected 2, found 1),INFO tag [AF=0.00047] expected different number of values (expected 2, found 1)`; ### Notes. Currently, all the validation modes call out to HTSJDK. Do we want to put the new functionality there as well?. ---. @yfarjoun commented on [Thu Jul 16 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122130280). I think that it is very appropriate to validate in htsjdk. On Thu, Jul 16, 2015 at 4:05 PM, ldgauthier notifications@github.com; wrote:. > Currently ValidateVariants relies on genotypes to transitively check that; > each alt allele occurs in at least one sample and that the AC adds up.; > However, this can fail on sites-only files because there are no geno",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:1332,validat,validation,1332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,get gcloud authorization working on travis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/444:11,authoriz,authorization,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/444,1,['authoriz'],['authorization']
Security,"gine; 19:10:31.451 INFO CalculateContamination - Shutting down engine; [March 6, 2022 7:10:31 PM CST] org.broadinstitute.hellbender.tools.walkers.contamination.CalculateContamination done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2141192192; java.lang.IllegalArgumentException: there is no such column: contig; 	at org.broadinstitute.hellbender.utils.tsv.DataLine.columnIndex(DataLine.java:483); 	at org.broadinstitute.hellbender.utils.tsv.DataLine.get(DataLine.java:452); 	at org.broadinstitute.hellbender.utils.tsv.DataLine.get(DataLine.java:581); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary$PileupSummaryTableReader.createRecord(PileupSummary.java:193); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary$PileupSummaryTableReader.createRecord(PileupSummary.java:188); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.fetchNextRecord(TableReader.java:364); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.access$200(TableReader.java:99); 	at org.broadinstitute.hellbender.utils.tsv.TableReader$1.hasNext(TableReader.java:472); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.utils.tsv.TableReader.toList(TableReader.java:532); 	at org.broadinstitute.hellbender.tools.walkers.contamination.PileupSummary.readFromFile(PileupSummary.java:139); 	at org.broadinstitute.hellbender.tools.walkers.contamination.CalculateContamination.doWork(CalculateContamination.java:116); 	at org.broadinstitute.hell",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7707:3994,access,access,3994,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7707,1,['access'],['access']
Security,google-cloud-java: CloudStorageReadChannel.create() does a GCS access outside of the retry mechanism in CloudStorageReadChannel.read(),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253:63,access,access,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253,1,['access'],['access']
Security,google-cloud-nio 0.123.23: certain non-requester-pays accesses fail when --gcs-project-for-requester-pays is specified,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7716:54,access,accesses,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7716,1,['access'],['accesses']
Security,google.cloud.RetryHelper.runWithRetries(RetryHelper.java:47); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.secu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:6913,secur,security,6913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['secur'],['security']
Security,gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:108); at org.gradle.api.internal.tasks.execution.ResolveBeforeExecutionOutputsTaskExecuter.execute(ResolveBeforeExecutionOutputsTaskExecuter.java:67); at org.gradle.api.internal.tasks.execution.ResolveAfterPreviousExecutionStateTaskExecuter.execute(ResolveAfterPreviousExecutionStateTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:94); at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:95); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57); at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskEx,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:2108,Validat,ValidatingTaskExecuter,2108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716,1,['Validat'],['ValidatingTaskExecuter']
Security,"gs://depmapomicsdata/1000g_pon.hg38.vcf.gz; 20:59:55.629 INFO Mutect2 - Shutting down engine; [October 4, 2021 8:59:55 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=876609536; code: 403; message: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; reason: forbidden; location: null; retryable: false; com.google.cloud.storage.StorageException: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:406); at com.google.cloud.storage.StorageImpl$4.call(StorageImpl.java:217); ...; ```. This happens while it runs the command:. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15500m\ ; -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\ ; -I gs://cclebams/hg38_wes/CDS-00rz9N.hg38.bam -tumor BC1_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE --germline-resource gs://gcp-public-data--gnomad/release/3.0/vcf/genomes/gnomad.genomes.r3.0.sites.vcf.bgz\ ; -pon gs://gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz\ ; -L gs://fc-secure-d2a2d895-a7af-4117-bdc7-652d7d268324/7a157f4a-7d93-4a3e-aaf4-c41833463f5a/Mutect2/3be8ce8e-1075-4063-bc43-6f61e386c3f5/call-SplitIntervals/cacheCopy/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list\ ; -O output.vcf.gz --f1r2-tar-gz f1r2.tar.gz --gcs-project-for-requester-pays broad-firecloud-ccle; ```. But I gave read (both regular and legacy) access to gs://cclebams (this is a requester pays bucket). This was done on GATK 4.2.2 docker. Best,",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492:2132,secur,secure-,2132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492,2,"['access', 'secur']","['access', 'secure-']"
Security,"gsutil working is not a good predictor of gatk working. It's possible for default credentials to be wrong but gsutil credentials to be fine at the same time. Here is an example of how to get into this situation:. ```; // set application credentials; gcloud auth login; // unset default credentials (alternatively, forget to set them in the first place); gcloud auth application-default revoke; // gsutil works; gsutil cat $VCF > /dev/null; // GATK does not work; ./gatk-launch SelectVariants --verbosity=DEBUG -V $VCF -L 1:1000-2000 -O /tmp/foo.vcf; A USER ERROR has occurred: Couldn't read file (...); ```. Please make sure to set up Google Cloud access as follows:; ```; $ gcloud auth application-default login; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281526964:648,access,access,648,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281526964,1,['access'],['access']
Security,"h a stack trace:; ```; code: 401; message: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; reason: required; location: Authorization; retryable: false; com.google.cloud.storage.StorageException: Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:220); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:415); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:198); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:195); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); at com.google.cloud.RetryHelper.run(RetryHelper.java:74); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:51); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:195); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:673); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:429); at org.broadinstitute.hellbender.engine.ReadsDataSource.<init>(ReadsDataSource.java:206); ```. ```; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 401 Unauthorized; {; ""code"" : 401,; ""errors"" : [ {; ""domain"" : ""global"",; ""location"" : ""Authorization"",; ""locationType"" : ""header"",; ""message"" : ""Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram."",; ""reason"" : ""required""; } ],; ""message"" : ""Anonymous caller does not have storage.objects.get access to joel-cram/SAM24339124.cram.""; }; ```. ### Desired; Something like ""Unable to read gs://joel-cram/SAM24339124.cram due to permissions. Have you enabled Google Cloud Application Default Credentials by running 'gcloud auth application-default login'? See [this forum post] for details.""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5468:1992,Authoriz,Authorization,1992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5468,3,"['Authoriz', 'access']","['Authorization', 'access']"
Security,h/broadinstitute/gatk/pull/5397/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9Db2xsZWN0RjFSMkNvdW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.917% <0%> (-99.083%)` | `1% <0%> (-12%)` | |; | [.../walkers/bqsr/BaseRecalibratorIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5397/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQmFzZVJlY2FsaWJyYXRvckludGVncmF0aW9uVGVzdC5qYXZh) | `1.031% <0%> (-98.969%)` | `1% <0%> (-7%)` | |; | [...ers/vqsr/FilterVariantTranchesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5397/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvRmlsdGVyVmFyaWFudFRyYW5jaGVzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.053% <0%> (-98.947%)` | `1% <0%> (-5%)` | |; | [...s/variantutils/VariantsToTableIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5397/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGVJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.205% <0%> (-98.795%)` | `1% <0%> (-20%)` | |; | [...walkers/validation/ConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5397/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.563% <0%> (-98.438%)` | `1% <0%> (-5%)` | |; | [...ientation/ReadOrientationModelIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5397/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9SZWFkT3JpZW50YXRpb25Nb2RlbEludGVncmF0aW9uVGVzdC5qYXZh) | `1.667% <0%> (-98.333%)` | `1% <0%> (-5%)` | |; | ... and [154 more](https://codecov.io/gh/broadinstitute/gatk/pull/5397/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-437157098:3542,validat,validation,3542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5397#issuecomment-437157098,1,['validat'],['validation']
Security,"h/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for validateInfoFieldCounts(VCFInfoHeaderLine headerLine) or similar; add a test to VariantContextUnitTest.java; 2) After change 1) is merged, update ValidateVariants accordingly to use the new function and add a test to its integration tests. ---. @vdauwera commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222213763). @ldgauthier is this still a thing? (in the sense of not having been addressed in htsjdk). ---. @ldgauthier commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222214083). Still a thing. No work has been done here AFAIK. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-260465013). This seems like fairly low-hanging fruit -- @ronlevine . ---. @ronlevine commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613152). @ldgauthier Shouldn't a locus without genotypes bypass `AC` validation, given it's defined as: `Allele count in genotypes, for each ALT allele, in the same order as listed`?. ---. @ldgauthier commented on [Wed No",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:4521,Validat,ValidateVariants,4521,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['Validat'],['ValidateVariants']
Security,haded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:92); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:47); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.Abstra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:6310,secur,security,6310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['secur'],['security']
Security,handle normal reads in validation sample in BasicSomaticValidator,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5322:23,validat,validation,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5322,1,['validat'],['validation']
Security,hashtable lookups are expensive in Kryo and they add up to 15% or more of runtime (top hotspot on Xprof). https://twitter.com/aphyr/status/478638361150636032. This PR turns off reference tracking in Kryo which speeds things up ~7.2mins vs 7.4mins on MarkDuplicatesSpark but it's a bit risky because I think it may result in an infinite loop for cyclic object graphs. We do not have any cyclic object graphs now and so it's fine. The PR is to open a convo about this.; @tomwhite @droazen @laserson wdyt?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1734:0,hash,hashtable,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1734,1,['hash'],['hashtable']
Security,"have been written, a new file is created with the index at the top and the contents of the temporary .pgen file appended to it. When `WRITE_SEPARATE_INDEX` is selected, the index is instead written to a separate .pgi file. The default is `WRITE_AND_COPY`. #### max-alt-alleles; The PGEN format can only support up to 254 alt alleles per site. This argument allows you to specify a limit. The default is the max of 254. Any sites with more alt alleles than the specified max will not be written. #### lenient-ploidy-validation; PGEN is a bit quirky in that it requires samples to be diploid but has a special case for sex chromosomes, which are allowed to be haploid. By default, any attempt to write a record with an unsupported ploidy will result in an exception being thrown. If this flag is used, then ploidy failures will instead be logged and the records will be written as missing. #### writer-log-file; The C++ code in the PGEN writer in PGEN-JNI will log sites that exceed max-alt-alleles and with unsupported ploidy (if lenient-ploidy-validation is set) to the specified log file, if this argument is set. #### allow-empty-pgen; Empty PGEN files are not technically valid PGEN files. However, for parallel processing purposes, it is sometimes helpful to allow the creation of empty files when there are no variants to be written. The GvsExtractCallsetPgenMerged workflow relies on this. If this flag is set and no variants are written, an empty .pgen, .psam, and .pvar.zst file will be written in `onShutdown()`. By default (i.e. if this flag is not set), if there are no variants written, an exception will be thrown. . ### Part 3: GvsExtractCallsetPgenMerged; GvsExtractCallsetPgenMerged is a WDL workflow that calls ExtractCohortToPgen to extract data from GVS and write it to PGEN files, and then merges those PGEN files by chromosome. This workflow has 3 steps:. #### Step 1: GvsExtractCallsetPgen; This is a workflow based very closely on the GvsExtractCallset workflow (which is used f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708:5098,validat,validation,5098,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708,1,['validat'],['validation']
Security,"he Y chromosome, but possibly in other places as well) due to changes between the two references. ; ; 12:37:55.679 INFO  ProgressMeter - Starting traversal ; ; 12:37:55.679 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Features Processed  Features/Minute ; ; 12:37:56.198 WARN  FuncotatorUtils - Reference allele is different than the reference coding sequence (strand: -, alt = G, ref G != T reference coding seq) @\[chr1:13839497\]!  Substituting given allele for sequence code (TTC->GTC) ; ; 12:37:56.213 INFO  FuncotateSegments - Shutting down engine ; ; \[February 9, 2022 12:37:56 PM EST\] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.24 minutes. ; ; Runtime.totalMemory()=3139436544 ; ; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:29534 end:14501 ; ;     at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2938) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866) ; ;     at org.broadinstitute.hellbender.tools.funcotator.DataSourceF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7676:2483,validat,validatePositions,2483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7676,1,['validat'],['validatePositions']
Security,he.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.apache.hadoop.ipc.Client.call(Client.java:1475); 	at org.apache.hadoop.ipc.Client.call(Client.java:1412); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229); 	at com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:255); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.hadoop.io.retry.RetryInvocation,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:9686,secur,security,9686,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['secur'],['security']
Security,he.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:237); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:488); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:468); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:458); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:3528,secur,security,3528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['secur'],['security']
Security,he.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106); 	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73); 	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1228); 	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1213); 	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(D,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:6445,secur,security,6445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['secur'],['security']
Security,he.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Failed to read bam header from /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:1865,secur,security,1865,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['secur'],['security']
Security,"here's an exhaustive list of classes that need to be registered to run MarkDuplicates and ReadsPipeline. I did register them and it did not influence the runtime though. ```; kryo.register(scala.Tuple3[].class);; kryo.register(java.lang.Object[].class, new DefaultArraySerializers.ObjectArraySerializer());; kryo.register(java.lang.Class.class, new DefaultSerializers.ClassSerializer());; kryo.register(java.util.LinkedHashMap.class, new MapSerializer());; kryo.register(java.util.HashMap.class, new MapSerializer());; kryo.register(java.util.ArrayList.class, new CollectionSerializer());; kryo.register(htsjdk.samtools.BAMRecord.class);; kryo.register(htsjdk.samtools.SAMBinaryTagAndValue.class);; kryo.register(htsjdk.samtools.ValidationStringency.class, new DefaultSerializers.EnumSerializer(ValidationStringency.class));; kryo.register(htsjdk.samtools.SAMFileHeader.class);; kryo.register(htsjdk.samtools.SAMProgramRecord.class);; kryo.register(htsjdk.samtools.SAMReadGroupRecord.class);; kryo.register(htsjdk.samtools.SAMSequenceDictionary.class);; kryo.register(htsjdk.samtools.SAMSequenceRecord.class);; kryo.register(PairedEnds.class);; try {; kryo.register(Class.forName(""scala.reflect.ClassTag$$anon$1""));; } catch (ClassNotFoundException e) {; //not a big deal, we'll just not register it; logger.debug(""Can't register class "" + e.getLocalizedMessage());; }. //; kryo.register(org.broadinstitute.hellbender.utils.variant.MinimalVariant.class);; kryo.register(org.broadinstitute.hellbender.utils.SimpleInterval.class);; kryo.register(org.broadinstitute.hellbender.utils.collections.IntervalsSkipList.class);; kryo.register(java.util.Hashtable.class);; kryo.register(org.broadinstitute.hellbender.utils.collections.IntervalsSkipListOneContig.class);; kryo.register(int[].class);; kryo.register(org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.class);; kryo.register(org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.class);; kryo.register(scala",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1733#issuecomment-212427242:481,Hash,HashMap,481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1733#issuecomment-212427242,3,"['Hash', 'Validat']","['HashMap', 'ValidationStringency']"
Security,"his version includes a fix for the issue we were seeing which required multiple pulls; removed the workaround (fixes #1404). The problem was that we were using an ssh git remote. git-lfs fails in this case because it can't authenticate. (unclear to me if this is a bug or not, I don't know if github requires authentication for ssh access to public repos). In versions <= 1.1.0 git-lfs was falling back to trying over an http connection. They removed this fallback mechanism in 1.1.1. See github/git-lfs#1090 for discussion.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1600:223,authenticat,authenticate,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1600,3,"['access', 'authenticat']","['access', 'authenticate', 'authentication']"
Security,"hmm, I can't get it to work. I run. ```; ./gatk-launch RunMinimalBWAMEM -bwaPath /broad/software/free/Linux/redhat_6_x86_64/pkgs/bwa_0.7.12/bwa -I ./src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunMinimalBWAMEM/interleaved.fastq -p -R src/test/resources/large/human_g1k_v37.20.21.fasta --outputDirectory outbwa -O foo.sam; ```. this blows up with . ```; [E::bwa_idx_load_from_disk] fail to locate the index files; /broad/software/free/Linux/redhat_6_x86_64/pkgs/bwa_0.7.12/bwa mem -t 1 -p src/test/resources/large/human_g1k_v37.20.21.fasta ./src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunMinimalBWAMEM/interleaved.fastq. at org.broadinstitute.hellbender.tools.spark.sv.RunMinimalBWAMEM.validateResults(RunMinimalBWAMEM.java:128); at org.broadinstitute.hellbender.tools.spark.sv.RunMinimalBWAMEM.doWork(RunMinimalBWAMEM.java:110); at org.broadinstitute.hellbender.tools.spark.sv.RunMinimalBWAMEM.doWork(RunMinimalBWAMEM.java:23); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:174); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:67); at org.broadinstitute.hellbender.Main.main(Main.java:82); ```. but when i run. ```; /broad/software/free/Linux/redhat_6_x86_64/pkgs/bwa_0.7.12/bwa mem -t 1 -p src/test/resources/large/human_g1k_v37.20.21.fasta ./src/test/resources/org/broadinstitute/hellbender/tools/spark/sv/RunMinimalBWAMEM/interleaved.fastq; ```. it works just fine. Back to @SHuang-Broad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1701#issuecomment-213470195:726,validat,validateResults,726,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1701#issuecomment-213470195,1,['validat'],['validateResults']
Security,"houghts for @samuelklee. For example, CollectFragmentCounts produces the following hybrid-type `@RG` line:. ![screenshot 2018-02-22 15 05 48](https://user-images.githubusercontent.com/11543866/36908820-66b90938-1e0a-11e8-8830-793ff3f71e96.png). ```; @RG ID:GATKCopyNumber SM:HCC1143_tumor; ```; Official format specifications are at https://samtools.github.io/hts-specs/. Let me briefly describe the #choices. ---; If we are to follow conventions used in the alignment world (SAM specs, for interval lists), then... We note data transformations using `@PG` program groups. These can be added successively to the same data file, given unique `@PG ID` fields, and collectively these lines showcase the history of data transformations for a dataset. The `@RG` group is reserved for lane level data and yes, does unify based on the sample or library. ---; If we examine VCFs, the convention is to use `#` hashtags to denote header rows (VCF specs). Double hashtags `##` denote all metadata lines and a single hashtag `#` denotes the line with the column labels. Here are some select rows from an M2 VCF header:; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=artifact_in_normal,Description=""artifact_in_normal"">; ...; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ...; ##GATKCommandLine=<ID=FilterMutectCalls,CommandLine=""FilterMutectCalls...; ...; ##GATKCommandLine=<ID=Mutect2,CommandLine=""Mutect2 --tumor-sample HCC1143_tumor ...; ...; ##INFO=<ID=TLOD,Number=A,Type=Float,Description=""Tumor LOD score"">; ##Mutect Version=2.1-beta; ##command=FilterByOrientationBias --output hcc1143_T_clean-filtered.vcf...; ...; ##contig=<ID=chr1,length=248956422>; ##contig=<ID=chr2,length=242193529>; ...; ##contig=<ID=HLA-DRB1*16:02:01,length=11005>; ##filtering_status=These calls have been filtered by FilterMutectCalls to label false positives with a list of failed filters and true positives with PASS.; ##normal_sample=HCC1143_normal; ##orientatio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4481:963,hash,hashtags,963,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4481,2,['hash'],"['hashtag', 'hashtags']"
Security,"htsjdk versions older than 2.1.1 would remove NM and MD tags on bam->cram compression, and then automatically regenerate NM tags when reading cram. Starting with 2.1.1, in order to ensure lossless round-tripping, it no longer does either, and restores only the tags present in the compressed file . As a result, any cramfile read with 2.1.1+ that was generated with older htsjdk versions (or samtools) will fail validation due to missing NM tags. So this PR contains an updated cram file that contains NM tags for the SAMFileValidation tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1551:412,validat,validation,412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1551,1,['validat'],['validation']
Security,https://gatk-jenkins.broadinstitute.org/ is currently giving a warning when you try to visit it. We need to fix it's certificate so that it doesn't give a scary warning. It says it expired several days ago. @davidbernick Could you look into this?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2446:117,certificate,certificate,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2446,1,['certificate'],['certificate']
Security,"https://github.com/broadinstitute/gatk/blob/c6daf7dd02b866907fbfebad150baeb540c35bce/src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/JointGermlineCNVSegmentation.java#L701. I'm running into a recurrent issue in JointGermlineCNVSegmentation, running after PostprocessGermlineCNVCalls in a gCNV pipeline. A number of batches are being merged in parallel - some of those succeed, some fail. It's not clear just yet if this is a deterministic failure, I'll re-run a few times and see if I can answer that. . ```text; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chrX:6383391 [VC SAMPLE_ID.segments.vcf.gz @ chrX:6383391-17732942 Q3076.53 of type=NO_VARIATION alleles=[N*] attr={END=17732942} GT=GT:CN:NP:QA:QS:QSE:QSS	0:1:581:1:3077:4:20 filters=. ... Caused by: java.lang.IllegalStateException: Encountered genotype with ploidy 1 but 2 alleles.; 	at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); 	at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.correctGenotypePloidy(JointGermlineCNVSegmentation.java:701); 	at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.prepareGenotype(JointGermlineCNVSegmentation.java:682); ```. The VCF row in question is . ```text; chrX	6383391	CNV_chrX_6383391_17732942	N	.	3076.53	.	END=17732942	GT:CN:NP:QA:QS:QSE:QSS	0:1:581:1:3077:4:20; ```. The characterisation of this row as `type=NO_VARIATION alleles=[N*]` seems... partially correct? There is no variation at this locus, but I'm not sure why alleles is `N*`. In this situation, as I read it, the first clause should be satisfied: 1 allele, and allele is no-call. Instead the variant process is dying in the else side of the condition. Could you clarify if I'm interpreting this correctly?. Relevant versioning:; ```; 13:18:38.320 INFO JointGermlineCNVSegmentation - ------------------------------------------------------------; 13:18:38.321 INFO JointGermlineCNVSegmentation - The Genome Analy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8834:933,validat,validate,933,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8834,1,['validat'],['validate']
Security,"i,. Using GATK mutect2's wdl file on Terra (version 21 on agora) I keep getting the same error:; ""pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket"" . Here is part of the stacktrace : ; ```; 20:59:48.744 INFO Mutect2 - Inflater: IntelInflater; 20:59:48.744 INFO Mutect2 - GCS max retries/reopens: 20; 20:59:48.744 INFO Mutect2 - Requester pays: enabled. Billed to: broad-firecloud-ccle; 20:59:48.744 INFO Mutect2 - Initializing engine; 20:59:54.630 INFO FeatureManager - Using codec VCFCodec to read file gs://depmapomicsdata/1000g_pon.hg38.vcf.gz; 20:59:55.629 INFO Mutect2 - Shutting down engine; [October 4, 2021 8:59:55 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=876609536; code: 403; message: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; reason: forbidden; location: null; retryable: false; com.google.cloud.storage.StorageException: pet-102022583875839491351@broad-firecloud-ccle.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket.; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:406); at com.google.cloud.storage.StorageImpl$4.call(StorageImpl.java:217); ...; ```. This happens while it runs the command:. ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx15500m\ ; -jar /root/gatk.jar Mutect2 -R gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta\ ; -I gs://cclebams/hg38_wes/CDS-00rz9N.hg38.bam -tumor BC1_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE --germline-resource gs://gcp-public-data--gnomad/release/3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492:982,access,access,982,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492,1,['access'],['access']
Security,"ializing engine. 07:33:16.008 INFO FeatureManager - Using codec VCFCodec to read file file:///nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz. 07:33:16.053 INFO IntervalArgumentCollection - Processing 16569 bp from intervals. 07:33:16.059 INFO FilterMutectCalls - Done initializing engine. 07:33:16.157 INFO ProgressMeter - Starting traversal. 07:33:16.157 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute. 07:33:16.158 INFO FilterMutectCalls - Starting pass 0 through the variants. 07:33:17.341 INFO FilterMutectCalls - Finished pass 0 through the variants. 07:33:17.404 INFO FilterMutectCalls - Shutting down engine. [September 20, 2020 7:33:17 AM PDT] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.04 minutes. Runtime.totalMemory()=1256194048. java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.param.ParamUtils.isPositive(ParamUtils.java:165). at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:13). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:43). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.<init>(BinomialCluster.java:17). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:184). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(Filte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6850:4600,validat,validateArg,4600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850,1,['validat'],['validateArg']
Security,"ile:///run/media/riadh/One%20Touch/Reference_data_b38/gnomad.genomes.v3.1.2.sites.chr3.vcf.bgz; 10:58:19.971 INFO FeatureManager - Using codec VCFCodec to read file file:///run/media/riadh/My%20Book_From%20Eiklid/Analysis/gatk-4.2.4.1/ensembl-vep/PE69_chr3.vcf; 10:58:20.063 INFO VariantAnnotator - Done initializing engine; 10:58:20.091 WARN VariantAnnotatorEngine - The requested expression attribute ""gnomad.ALT"" is missing from the header in its resource file gnomad; 10:58:20.140 INFO ProgressMeter - Starting traversal; 10:58:20.140 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 10:58:42.160 INFO VariantAnnotator - Shutting down engine; [March 17, 2022 at 10:58:42 AM CET] org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator done. Elapsed time: 0.37 minutes.; Runtime.totalMemory()=17158897664; java.lang.IllegalStateException: Allele in genotype C not in the variant context [C*, CT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.base/java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1464); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1420); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053:3961,Validat,Validation,3961,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053,1,['Validat'],['Validation']
Security,"ility to tweak sample-every-Nth-variant parameter for SNP model creation (#8019); - add initial notebook copy pasta (#8008); - add sample_table_timestamp to GetNumSamplesLoaded (#8022); - Batched Avro export [VS-630] (#8020); - Updating references to old GATK for VS-620 (#8023); - VS-517 Use standard version of GetBQTableLastModifiedDatetime in GvsValidateVat (#8024); - Fix bug in GvsWithdrawSamples.wdl (#8026); - Ah 617 exposing the drop_state parameter to the GvsJointVariantCalling wdl used for beta (and internal customer) (#8032); - Expose maximum-training-variants VQSR parameter [VS-634] (#8029); - Callset statistics [VS-560] (#8018); - Check for withdrawn before exporting to AVRO files [VS-646] (#8039); - Small updates to GVS Integration WDL [VS-618] (#8042); - Rework Hail script generation [VS-616] (#8034); - Alpine based Variant Store Docker image [VS-648] (#8044); - update warp version (#7906); - Fail Avro extract and callset stats on bad filter name [VS-655] (#8046); - Vs 629 failure to retrieve job information during ingest (#8047); - Restore accidentally removed bcftools [VS-661] (#8051); - Allowing our pipeline to function with a sample size of one (#8055); - Vs 665 re create vcf for cd 68 po 52339 with ad padding fixed (#8057); - VS-665 and VS-620 updating code to use latest docker images containing Rori's AD calculation changes in extract (#8061); - updating the beta workflow to use the latest jar, representing the version of GATK George tested against the workflow (#8062); - VS-637 Address a couple of issues in SampleLoadStatus handling in GVSImportGenomes. (#8052); - Revert Alpinizing of apt dependent task [VS-688] (#8065); - Fix missing vat schema JSONs [VS-699] (#8072); - Fix integration expectations for fixed AD [VS-689] (#8066); - VS-698 Remove unnecessary columns from Call set statistics (#8073); - Fix Dockerfile nits that break 20.10.21 (#8078); - Nirvana 3.18.1 Docker images support [VS-661] (#8082); - Add option to not prepare __REF_DATA or __",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:28794,Expose,Expose,28794,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,2,['Expose'],['Expose']
Security,"ilter.OrientationBiasFilterer.annotateVariantContextsWithFilterResults(OrientationBiasFilterer.java:216); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:168); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:781); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); ```; and; ```; java.lang.IllegalStateException: Allele in genotype G* not in the variant context [C*, T]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.tools.exome.orientationbiasvariantfilter.OrientationBiasFilterer.annotateVariantContextsWithFilterResults(OrientationBiasFilterer.java:216); 	at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalSuccess(FilterByOrientationBias.java:211); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:840); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.he",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3291:2227,validat,validateGenotypes,2227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3291,1,['validat'],['validateGenotypes']
Security,"imVariants - Reference allele is too long (212) at position chr2_KI270894v1_alt:202602; skipping that record. Set --reference_window_stop >= 212 ; INFO 21:38:54,233 LeftAlignAndTrimVariants - Reference allele is too long (220) at position chr2_KI270894v1_alt:204859; skipping that record. Set --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **ma",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487:7468,validat,validation,7468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487,1,['validat'],['validation']
Security,"ime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at StudentAws$.main(StudentAws.scala:8); 	at StudentAws.main(StudentAws.scala); Exception in thread ""main"" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method); 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793); 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249); 	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454); 	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377); 	at org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:48); 	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192); 	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640); 	at o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:8246,Checksum,ChecksumFileSystem,8246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['Checksum'],['ChecksumFileSystem']
Security,"in `BwaSparkEngine` the method `alignWithBwa` is like this. ```; public JavaRDD<GATKRead> alignWithBWA(final JavaSparkContext ctx, final JavaRDD<GATKRead> unalignedReads, final SAMFileHeader readsHeader) {; //Note: SparkContext is not serializable so we don't store it in the engine and set this property here. Setting it multiple times is fine.; // ensure reads in a pair fall in the same partition (input split), so they are processed together; ctx.hadoopConfiguration().setBoolean(BAMInputFormat.KEEP_PAIRED_READS_TOGETHER_PROPERTY, true);. final JavaRDD<Tuple2<ShortRead, ShortRead>> shortReadPairs = convertToUnalignedReadPairs(unalignedReads);; final JavaRDD<String> samLines = align(shortReadPairs);; final SAMLineParser samLineParser = new SAMLineParser(new DefaultSAMRecordFactory(), ValidationStringency.SILENT, readsHeader, null, null);; final Broadcast<SAMLineParser> samLineParserBroadcast = ctx.broadcast(samLineParser);; return samLines.map(r -> new SAMRecordToGATKReadAdapter(samLineParserBroadcast.getValue().parseLine(r)));; }; ```. note that the parser is distributed by broadcast and thus shared by all tasks in an executor. That's a race condition because the parser is mutable (eg the `fields` field in the coded that gets mutated for each decode call). https://github.com/broadinstitute/gatk/issues/2039 may be caused by this bug",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2050:793,Validat,ValidationStringency,793,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2050,1,['Validat'],['ValidationStringency']
Security,"ine the earlier stages of your pipeline that produce your bam to ensure you get a correctly formed bam. I'm going to close this ticket now since this doesn't appear to be an issue with Mutect2. (base) wm462-624:Downloads fleharty$ java -jar $PICARD ValidateSamFile I=concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam ; INFO	2020-07-14 11:25:52	ValidateSamFile	. ********** NOTE: Picard's command line syntax is changing.; **********; ********** For more information, please see:; ********** https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition); **********; ********** The command line looks like this in the new syntax:; **********; ********** ValidateSamFile -I concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam; **********. 11:25:52.673 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/fleharty/resources/picard.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Jul 14 11:25:52 EDT 2020] ValidateSamFile INPUT=concatenated_ACC5611A1_XXXXXX_consensusalign_ds.bam MODE=VERBOSE MAX_OUTPUT=100 IGNORE_WARNINGS=false VALIDATE_INDEX=true INDEX_VALIDATION_STRINGENCY=EXHAUSTIVE IS_BISULFITE_SEQUENCED=false MAX_OPEN_TEMP_FILES=8000 SKIP_MATE_VALIDATION=false VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Jul 14 11:25:52 EDT 2020] Executing as fleharty@wm462-624 on Mac OS X 10.15.5 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_191-b12; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.20.4-SNAPSHOT; WARNING	2020-07-14 11:25:52	ValidateSamFile	NM validation cannot be performed without the reference. All other validations will still occur.; ERROR: Record 18321, Read name UMI-ATT-GAA-2, Zero-length read without FZ, CS or CQ tag; ERROR: Record 26312, Read name UMI-CCT-TTC-1, Zero-l",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132:1094,Validat,ValidateSamFile,1094,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-658247132,1,['Validat'],['ValidateSamFile']
Security,ineCNVCaller - . !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: GermlineCNVCaller is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 21:54:28.627 INFO GermlineCNVCaller - Initializing engine; 21:54:31.994 INFO GermlineCNVCaller - Done initializing engine; log4j:WARN No appenders could be found for logger (org.broadinstitute.hdf5.HDF5Library).; log4j:WARN Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 21:54:33.457 INFO GermlineCNVCaller - Intervals specified...; 21:54:34.113 INFO IntervalArgumentCollection - Processing 10999816 bp from intervals; 21:54:34.145 INFO GermlineCNVCaller - No GC-content annotations for intervals found; explicit GC-bias correction will not be performed...; 21:54:34.217 INFO GermlineCNVCaller - Running the tool in the COHORT mode...; 21:54:34.217 INFO GermlineCNVCaller - Validating and aggregating data from input read-count files...; 21:54:34.241 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG00096.lc.soohee1k.hdf5 (1 / 24); 21:54:36.539 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG00268.lc.soohee1k.hdf5 (2 / 24); 21:54:37.967 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG00419.lc.soohee1k.hdf5 (3 / 24); 21:54:40.147 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG00759.lc.soohee1k.hdf5 (4 / 24); 21:54:41.782 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG01051.lc.soohee1k.hdf5 (5 / 24); 21:54:43.197 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG01112.lc.soohee1k.hdf5 (6 / 24); 21:54:45.169 INFO GermlineCNVCaller - Aggregating read-count file /home/shlee/gcnv/low_coverage_1k/HG01500.lc.soohee1k.hdf5 (7 / 24); 21:54:46.852 I,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4826:2913,Validat,Validating,2913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4826,1,['Validat'],['Validating']
Security,"info annotations in the header to check; > how many entries each should have.; > Outline; > - Add a new validation type for info-field counts to enum and to; > switch statement; > - Grab info headers from input VCF with something like; > GATKVCFUtils.getVCFHeadersFromRods(getToolkit(),; > variantCollection.variants.getName()) and VCFHeader::getInfoHeaderLines; > - In the map() function, for each info header line, call on each; > VCFInfoHeaderLine getCount(vc) to get the expected number of info; > annotation entries; > - Compare the expected number with a count based on; > vc.getAttribute(currentVCFinfoHeaderLine.getID()), which will require some; > additional parsing because it returns an Object; > - (Bonus points if you use the isFixedCount() and getCount() functions; > on the VCF info header line to simplify annotations that aren't according; > to the number of alt alleles); > ; > Test data; > ; > /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > Should fail AC/AF validation at; > 1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120; > See results using:; > ; > use VCFtools; > vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for valid",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:3379,validat,validation,3379,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,"ing false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2585,Validat,ValidateVariants,2585,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"ining CachingIndexedFastaSequenceFile/overloads; - [ ] Update tools in the pathseq package (PathSeqBwaSpark, PathSeqScoreSpark) that do directory manipulation. [Edit] Somewhat tangentially, PathSeqBwaSpark currently rejects read inputs specified through `--inputs` and uses separate args to allow the user to identify inputs as paired or unpaired. Once this is using `GATKPathSpecifier` this could be changed to use ""--inputs"" annotated with tags instead. Might be a problem for WDL gen though (which doesn't support tags).; - [ ] Test utilities (createTempFile/Dir, etc. that return GATKPath); - [ ] Add a `toHadoopPath` method to `GATKPath` that returns a `org.apache.hadoop.fs.Path`.; - [ ] Change tools that generate multiple output files using a stem (SplitReads, etc) to use the `resolve` methods listed above once they're available.; - [ ] All usages of `PrintStream` should be replaced with `OutputStreamWriter` (code that requires printf-style formatting can use `write` with `String.format` instead of the `printf` methods). `PrintStream` doesn't propagate IOExceptions and instead requires calls to `checkError`, but almost all usages of `PrintStream` don't call it.; - [ ] Update `org.broadinstitute.hellbender.utils.report` (`GATKReport` and friends) to eliminate `File` references and `PrintStream` usages.; - [ ] Update `org.broadinstitute.hellbender.utils.recalibration` (`RecalUtils` and friends) to eliminate `File` references and `PrintStream` usages.; - [ ] Fix cases where we have a tool with a `File` that needs to be accessible to R code (determine if the code can handle non-local file paths). i.e.`VariantRecalibrator` TRANCHES_FILE.; - [ ] Fix cases where we have a tool with a `File` that needs to be accessible to Python (determine if the code can handle non-local file paths).; - [ ] `FeatureInput` should have all of it's String constructors removed, and only take GATKPath inputs. The constructor overloads that take tag Maps can be removed, and all call sites updated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6610:2290,access,accessible,2290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6610,2,['access'],['accessible']
Security,input argument lists are now printed like this. ```; --validationTypeToExclude REF --validationTypeToExclude ALLELES --validationTypeToExclude CHR_COUNTS ; ```. and features like this. ```; --dbsnp /Users/louisb/Workspace/hellbender/src/test/resources/Homo_sapiens_assembly19.dbsnp135.chr1_1M.exome_intervals.vcf; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/318#issuecomment-84031055:55,validat,validationTypeToExclude,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/318#issuecomment-84031055,3,['validat'],['validationTypeToExclude']
Security,"institute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; A second case involved `--alleles` input:; ```; 22	16464044	rs571268158	CCAGGTCT	C; 22	16464051	rs569099729	T	C; ```; and crashed similarly, with:; ```; java.lang.IllegalStateException: Allele in genotype CCAGGTCT* not in the variant context [T*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336:2898,validat,validate,2898,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336,1,['validat'],['validate']
Security,institute.hellbender.utils.locusiterator.LocusIteratorByState.lazyLoadNextAlignmentContext(LocusIteratorByState.java:288); at org.broadinstitute.hellbender.utils.locusiterator.LocusIteratorByState.hasNext(LocusIteratorByState.java:225); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.getPileupsOverReference(AssemblyBasedCallerUtils.java:443); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.ReferenceConfidenceModel.calculateRefConfidence(ReferenceConfidenceModel.java:195); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:645); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:212); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); ```; This hypothesis is further evidenced by the fact that one user at least claims that their input file validates and that they couldn't find the problem reads by looking at the input files manually. We probably will want to look at an example file in the debugger to catch what is happening at this site. We have refactored a bunch of code adjacent to this function recently so its possible this is a recent regression.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6490:3006,validat,validates,3006,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6490,1,['validat'],['validates']
Security,"institute/gatk/issues/6553. However, it would be nice if you could actually investigate the formatting error. Unfortunately my formatting error isn't the same as reported in the other post. I have 105 error in which the 1st alternative allele is a spanning deletion and the 2nd (and 3rd) is either an indel or snp. It's true that the 2nd and 3rd allele is actually not found in my samples. I even have 7 occurances in which the 1st allele (spanning deletion) has allele frequency 1.00. my code is the following for GenotypeGVCFs:. java -Xms32G -Xmx32G -jar ${gatk4} GenotypeGVCFs -R ${ref} -V ${pipeline}/${name}\_v4.1.6.0.g.vcf.gz -O ${vcf}/${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list 2> ${log}/${name}\_v4.1.6.0\_genotype.log. for ValidateVariants:. java -Xms10G -Xmx10G -jar ${gatk4} ValidateVariants -R ${ref} -V ${name}\_v4.1.6.0.vcf.gz -L ${pipeline}/${name}\_intervals.list --warn-on-errors 2> ${log}/${name}\_v4.1.6.0\_genotype\_valivar.log. the warning in ValidateVariants and the site look like this:. 14:12:15.126 WARN ValidateVariants - \*\*\*\*\* Input 1st\_v4.1.6.0.vcf.gz fails strict validation of type ALL: one or more of the ALT allele(s) for the record at position chr\_1:1088200 are not observed at all in the sample genotypes \*\*\*\*\* ; ; chr\_1 1088200 . T \*,TAAAAAAAAAAAA 64.39 . AC=8,0;AF=0.667,0.00;AN=12;DP=118;ExcessHet=3.0103;FS=0.000;InbreedingCoeff=0.4286;MLEAC=7,7;MLEAF=0.583,0.583;MQ=58.73;QD=32.19;SOR=2.303 GT:AD:DP:GQ:PL ./.:9,0,0:9:.:0,0,0,0,0,0 0/0:9,0,0:9:0:0,0,113,0,113,113 ./.:10,0,0:10:.:0,0,0,0,0,0 ./.:5,0,0:5:.:0,0,0,0,0,0 1/1:0,0,1:1:0:225,15,0,15,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:12,0,0:12:.:0,0,0,0,0,0 ./.:8,0,0:8:.:0,0,0,0,0,0 0/0:3,0,0:3:0:0,0,43,0,43,43 ./.:7,0,0:7:.:0,0,0,0,0,0 ./.:1,0,0:1:.:0,0,0,0,0,0 ./.:0,0,0:0:.:0,0,0,0,0,0 ./.:3,0,0:3:.:0,0,0,0,0,0 ./.:7,0,0:7:.:0,0,0,0,0,0 1/1:0,0,0:0:0:45,3,0,3,0,0 ./.:0,0,0 1/1:0,0,1:1:0:45,3,0,3,0,0 1/1:0,0,0:0:0:267,18,0,18,0,0 ./.:9,0,0:9:.:0,0,0,0,0,0 ; . The exactly the",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630:1840,Validat,ValidateVariants,1840,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630,1,['Validat'],['ValidateVariants']
Security,"intReadsSpark - Deflater: IntelDeflater; 18:11:33.871 INFO PrintReadsSpark - Inflater: IntelInflater; 18:11:33.871 INFO PrintReadsSpark - GCS max retries/reopens: 20; 18:11:33.871 INFO PrintReadsSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:11:33.871 INFO PrintReadsSpark - Initializing engine; 18:11:33.871 INFO PrintReadsSpark - Done initializing engine; 17/10/13 18:11:33 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 17/10/13 18:11:34 WARN spark.SparkConf: spark.master yarn-client is deprecated in Spark 2.0+, please instead use ""yarn"" with specified deploy mode.; 17/10/13 18:11:34 INFO spark.SparkContext: Submitted application: PrintReadsSpark; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing view acls groups to: ; 17/10/13 18:11:34 INFO spark.SecurityManager: Changing modify acls groups to: ; 17/10/13 18:11:34 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); groups with view permissions: Set(); users with modify permissions: Set(hdfs); groups with modify permissions: Set(); 17/10/13 18:11:34 INFO util.Utils: Successfully started service 'sparkDriver' on port 45754.; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering MapOutputTracker; 17/10/13 18:11:34 INFO spark.SparkEnv: Registering BlockManagerMaster; 17/10/13 18:11:34 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 17/10/13 18:11:34 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 17/10/13 18:11:34 INFO storage.DiskBlockManager: Created local directory at /tmp/hdfs/blockmgr-ea0e0669-2981-4277-80a0-a67eddf1001d; 17/10/13 18:11:34 INFO memory.MemoryStore: ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:4108,Secur,SecurityManager,4108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['Secur'],['SecurityManager']
Security,io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:7981,secur,security,7981,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['secur'],['security']
Security,io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:6275,secur,security,6275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['secur'],['security']
Security,io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9763,secur,security,9763,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['secur'],['security']
Security,io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1659,secur,security,1659,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['secur'],['security']
Security,ion 2.16.3. $ git-lfs pull --include src/main/resources/large; No default remote. No remotes defined. Current time in UTC: ; 2018-04-20 20:10:32. ENV:; LocalWorkingDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999; LocalGitDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalGitStorageDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git; LocalMediaDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/objects; LocalReferenceDir=; TempDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs/tmp; ConcurrentTransfers=3; TusTransfers=false; BasicTransfersOnly=false; SkipDownloadErrors=false; FetchRecentAlways=false; FetchRecentRefsDays=7; FetchRecentCommitsDays=0; FetchRecentRefsIncludeRemotes=true; PruneOffsetDays=3; PruneVerifyRemoteAlways=false; PruneRemoteName=origin; LfsStorageDir=/scratch/var/tmp/portage/sci-biology/gatk-9999/work/gatk-9999/.git/lfs; AccessDownload=none; AccessUpload=none; DownloadTransfers=basic; UploadTransfers=basic. Client IP addresses:; xx.xx.xx.xx; xx.xx.xx.xx; xx.xx.xx.xx; portage$ ls -latr; total 188; -rw-r--r-- 1 portage portage 428 Apr 20 22:05 codecov.yml; -rwxr-xr-x 1 portage portage 5741 Apr 20 22:05 build_docker.sh; -rw-r--r-- 1 portage portage 32161 Apr 20 22:05 build.gradle; -rw-r--r-- 1 portage portage 37502 Apr 20 22:05 README.md; -rw-r--r-- 1 portage portage 1502 Apr 20 22:05 LICENSE.TXT; -rw-r--r-- 1 portage portage 1555 Apr 20 22:05 Dockerfile; -rw-r--r-- 1 portage portage 1128 Apr 20 22:05 AUTHORS; -rw-r--r-- 1 portage portage 8237 Apr 20 22:05 .travis.yml; -rw-r--r-- 1 portage portage 395 Apr 20 22:05 .gitignore; -rw-r--r-- 1 portage portage 128 Apr 20 22:05 .gitattributes; -rw-r--r-- 1 portage portage 142 Apr 20 22:05 .dockerignore; drwxr-xr-x 2 portage portage 4096 Apr 20 22:05 resources_for_CI; drwxr-xr-x 2 portage portage 4096 Apr 20 22:05 hooks; -rwxr-xr-x 1 portage portage 5242 Apr 20 22:05 gradlew; drwxr-xr-x 3 portage port,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4687:16348,Access,AccessDownload,16348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4687,2,['Access'],"['AccessDownload', 'AccessUpload']"
Security,"ion for variants without genotypes, but I think you already figured that out. My proposal was more general, but you're right -- AC and AF should always have the same count as alt alleles and we don't need to check the header for that. When this came up (a year and a half ago!) we were thinking about validating all the info field annotations. ---. @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in https://github.com/samtools/htsjdk/pull/759. I can expand this to all INFO field annotations. ---. @ldgauthier commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265221057). Expanding to all INFO annotations would be wonderful, but that can be a separate issue. ---. @ronlevine commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265223581). That's not the only one, @magicDGS requested validating the `AF` values (which can be a separate issue). . ---. @vdauwera commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265226356). I think this one requires some additional discussion, so let's hold off for now -- it's not essential for 3.7 and we can't wait any longer to release. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-287824654). @ldgauthier Would it be ok to kick this down the road to whenever ValidateVariants gets ported to GATK4?. ---. @ldgauthier commented on [Tue Mar 21 2017](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-288223822). Yeah, this isn't critical for any production pipelines - pass that buck. On Mar 20, 2017 12:56 PM, ""Geraldine Van der Auwera"" <; notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> Would it be ok to kick this; > down the road to whenever ValidateVariants gets ported t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:7293,validat,validating,7293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validating']
Security,"ion. We will repeat the het-genotyping step, but this is cheap and it's probably better to repeat it to make sure filtering is applied consistently. It would also require more changes to the command line to specify where to output the hets for each sample during multisample segmentation and to skip genotyping in each scatter, if we were to go that route. There are many possible combinations of inputs that need to be tested, but the same is already true of the current ModelSegments. Furthermore, there are slight wrinkles when running in tumor-only mode (i.e., when `--normal-allelic-counts` are not available). Because each sample is genotyped indiviudally, each may yield a different set of hets (in contrast to genotyping in matched-normal mode, in which the normal determines the set of hets used in all samples). We will thus have to take the intersection of these hets before performing multisample segmentation. Unfortunately, we will not be able to re-perform this intersection in each scatter, since we will no longer have access to the hets from the other samples. However, we *will* ultimately intersect the hets from each sample with the joint segmentation before modeling, which may be a rough proxy for the intersection of hets from all samples. As always, tumor-only mode may yield suboptimal results in certain scenarios, e.g., high purity CNLOH. I think I'm OK with just documenting these wrinkles, rather than working too hard to iron them out. I think this structure sets us up nicely to accommodate germline tagging/filtering in the near future. We can still pass the Picard interval list containing the joint segmentation to the scatter for the normal, but can instead subsequently pass the *.modelBegin.seg result from the normal to the tumors. This modeled-segment file will have breakpoints identical to those from the joint segmentation (as opposed to the *.modelFinal.seg result, since that undergoes segment smoothing/merging), but will also contain the segment-level p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549:3176,access,access,3176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-607313549,1,['access'],['access']
Security,irectRetryingExecutor.submit(DirectRetryingExecutor.java:92); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:47); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:6843,secur,security,6843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['secur'],['security']
Security,"ired by the VCF spec, but this provides a much more flexible interface for other similar niche applications, like genotyping individuals with other known aneuploidies. The global `-ploidy` flag will still provide the background default (or the built-in ploidy of 2 for humans), but the user input value will supersede these in overlapping regions. Note that the overlap is checked against the active region, meaning variants near the boundary of the `--ploidy-regions` file may end up with GT fields having ploidy slightly differently than expected, for example if your custom region overlaps a given active region but the variant ends up being written to a location outside that interval. In this case the ploidy from the user input would be used rather than any other default. # Implementation Details. The key idea is to allow `HaplotypeCallerEngine` to initialize multiple genotyping engines based on the `--ploidy-regions` input. The intervals are first parsed to check for positive integer ploidy values, and then used to create hashmaps of ploidy -> genotyper. The engine uses two types of genotypers: one for active region determination and one for doing the actual genotyping. Both admit a ploidy paramter passed via `hcArgs`. This PR modifies the `HaplotypeCallerArgumentCollection` class to include a method for creating copies of this object with differing ploidy amounts. These then get fed to the constructors of the appropriate genotyper classes, which are organized into two hashmaps. In every situation where one of these genotypers is used, we instead begin the scope by calling a ""get local genotyper"" method that performs the logic of checking whether the region of interest overlaps any of the user-provided regions, and then selects the appropriate `localEngine` genotyper for the task, ensuring the user-provided ploidy supersedes any other defaults. # A Note on Dependency. The flexibility of using either .bed or .interval_list files to specify this information depends on [th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8464:1372,hash,hashmaps,1372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8464,1,['hash'],['hashmaps']
Security,"isn't match. The error log looks like below. Exception in thread ""main"" java.lang.NoSuchMethodError: scala.collection.Seq.aggregate(Ljava/lang/Object;Lscala/Function2;Lscala/Function2;)Ljava/lang/Object;; at org.bdgenomics.adam.models.NonoverlappingRegions.mergeRegions(NonoverlappingRegions.scala:75); at org.bdgenomics.adam.models.NonoverlappingRegions.<init>(NonoverlappingRegions.scala:55); at org.bdgenomics.adam.models.NonoverlappingRegions$.apply(NonoverlappingRegions.scala:169); at org.bdgenomics.adam.util.TwoBitRecord$.apply(TwoBitFile.scala:193); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at org.bdgenomics.adam.util.TwoBitFile$$anonfun$6.apply(TwoBitFile.scala:70); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at org.bdgenomics.adam.util.TwoBitFile.<init>(TwoBitFile.scala:70); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:43); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:41); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:311); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073:1139,Hash,HashMap,1139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073,2,['Hash'],"['HashMap', 'HashTrieMap']"
Security,it blows up for me when getting the sequence dictionary from the reference. I run this on the cloud. ```; ./gatk-launch CountVariantsSpark -V hdfs:///user/akiezun/dbsnp_138.b37.20.21.vcf.blockgz.gz -L 20 -R hdfs:///user/akiezun/human_g1k_v37.fasta -- --sparkRunner GCS --cluster dataproc-cluster-3; ```. and I get. ```; java.lang.IllegalArgumentException: java.net.UnknownHostException: null; at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:377); at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:310); at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:176); at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:678); at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:619); at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:149); at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653); at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:92); at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2687); at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2669); at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371); at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:170); at hdfs.jsr203.HadoopFileSystem.<init>(HadoopFileSystem.java:106); at hdfs.jsr203.HadoopFileSystemProvider.newFileSystem(HadoopFileSystemProvider.java:165); at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); at org.broadinstitute.hellbender.utils.io.IOUtils.getPath(IOUtils.java:528); at org.broadinstitute.hellbender.engine.datasources.ReferenceHadoopSource.getReferenceSequenceDictionary(ReferenceHadoopSource.java:39); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.getReferenceSequenceDictionary(ReferenceMultiSource.java:110); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:354); at org.broadinstitute.hellbender.engine.spark.GATK,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1936#issuecomment-229433523:414,secur,security,414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1936#issuecomment-229433523,4,"['Secur', 'access', 'secur']","['SecurityUtil', 'access', 'security']"
Security,it(DirectRetryingExecutor.java:92); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:47); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:125); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685:6381,secur,security,6381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685,1,['secur'],['security']
Security,"it(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	... 15 more; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.""; }; 	at shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_ni",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:4145,access,access,4145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['access'],['access']
Security,"ithout --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-execution",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6710:6360,Validat,ValidateBamsWf,6360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710,2,['Validat'],"['ValidateBAM', 'ValidateBamsWf']"
Security,ity.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:7914,secur,security,7914,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['secur'],['security']
Security,ity.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:6208,secur,security,6208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['secur'],['security']
Security,ity.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9696,secur,security,9696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['secur'],['security']
Security,"ize 250`.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimVariants - Start Date/Time",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:1039,authenticat,authenticated,1039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543,1,['authenticat'],['authenticated']
Security,"jars, because it increases entropy on the distribution & support side of things. I would much prefer to see this resolved by project development branches. With the possibility of making project-specific nightly builds off of those branches, to enable pointing people to hot fixes for a specific toolset without taking in whatever else is going on in other projects. ---. @droazen commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215757315). Alright, to give an overview of where this stands, we have several options on the table for solving this problem:; 1. Split the GATK into even more repos (a CNV-only repo, a HaplotypeCaller repo) that are versioned separately. GATK release X would then consist of CNV version Y, HaplotypeCaller version Z, gatk-public version P, etc. This is probably the most ""correct"" solution from a software engineering perspective, but might be a nightmare to work with.; 2. Have the ability to release jars with a subset of the tools exposed to the user (eg., CNV-only jars). Geraldine hates this one, and it does seem like a bad idea to have these incomplete jars floating out in the wild.; 3. Everyone develops on separate branches, and merges to master only when everything in a branch is ""release-ready"". In this scenario master itself is always (theoretically, at least) ready for release. This solves the original problem of release of some tools being blocked by others, but creates some other problems: last-minute merge conflicts across dev teams, large amounts of code being held back for months while it undergoes testing, harder to share code across groups, more complex git workflows for everyone.; 4. Everyone is free to merge development versions of tools to master (as is currently the case), and most of the time we try to release everything in the GATK together. On rare occasions when, eg., CNV needs a release now and HC is not ready, we create a branch off of the last tagged release, cherry-pic",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:3486,expose,exposed,3486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,1,['expose'],['exposed']
Security,java:205); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.runTool(HaplotypeCallerSpark.java:115); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); Caused by: java.lang.IllegalStateException: Duplicate key [B@4e233a3c; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculat; ionEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngi; ne.java:253); at org.broadinsti,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018:16834,Hash,HashMap,16834,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018,1,['Hash'],['HashMap']
Security,java:2219); > at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.concat(NameNodeRpcServer.java:829); > at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.concat(AuthorizationProviderProxyClientProtocol.java:285); > at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.concat(ClientNamenodeProtocolServerSideTranslatorPB.java:580); > at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); > at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617); > at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2278); > at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2274); > at java.security.AccessController.doPrivileged(Native Method); > at javax.security.auth.Subject.doAs(Subject.java:422); > at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924); > at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2272); > ; > org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf because writing failed with exception concat: target file /gatk-test2/WES2019-022_S4_out.vcf.parts/output is empty; > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInternal(FSNamesystem.java:2303); > at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInt(FSNamesystem.java:2257). #### Steps to reproduce; The user's command line was. > nohup /opt/gatk/gatk-4.1.4.0/gatk ReadsPipelineSpark --spark-runner SPARK --spark-master yarn --spark-submit-command spark2-submit -I hdfs://cloudera08/gatk-test2/WES2019-022_S4.bam -O hdfs://cloudera08/gatk-test2/WES2019-022_S4_out.vcf -R hdfs://cloudera08/gatk-test1/ucsc.hg19.fasta --known-sites hdfs://cloudera08/gatk-test1/dbsnp_150_hg19.vcf.gz --,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6218:1957,secur,security,1957,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6218,1,['secur'],['security']
Security,java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. 8/02/23 23:06:24 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/02/23 23:06:24 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/02/23 23:06:24 INFO spark.SparkContext: Successfully stopped SparkC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:3386,validat,validateArg,3386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validateArg']
Security,java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:7065,validat,validateArg,7065,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validateArg']
Security,java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Shutdown hook called; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/farrell/spark-94fa6743-3d29-4748-b8f8-d13a52dfed31; ```. The command line is:. ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:13857,validat,validateArg,13857,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validateArg']
Security,java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 68 more; ```. Also anecdotally it seems to happen less often.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:11038,secur,security,11038,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,5,['secur'],['security']
Security,javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 41 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.secu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:5207,secur,security,5207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['secur'],['security']
Security,javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.secu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8695,secur,security,8695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['secur'],['security']
Security,"joun is willing to help.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-252247496,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACnk0lAsJd9NECpPP0JYVp2ziDhga0B9ks5qxkRUgaJpZM4KQT_3; > . ---. @vdauwera commented on [Wed Oct 26 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-256499771). Writing pipeline-help now and cc'ing everyone involved in this thread. Will try to get some kind of protocol set up for debugging things that happen in the cloud pipeline, because I expect this will happen again. But if it gets too complicated we could also mock up some fake records that would reproduce this. It seems to me that shouldn't be too hard. . ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-260498705). I need to ping Daniel on getting access to the files. ---. @ronlevine commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275576931). @vdauwera Can you get the data? I can take a look a this issue. ---. @vdauwera commented on [Thu Jan 26 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-275578721). Oh, they gave me access to the files but I never took the next step of figuring out which files are relevant. There are twenty thousand samples... I'm not sure what is the best way to approach this. ---. @ldgauthier commented on [Wed Mar 01 2017](https://github.com/broadinstitute/gsa-unstable/issues/1489#issuecomment-283365248). It would be too computationally expensive and just generally painful to get; that dropped allele. I'd suggest making a unit test with some fake data.; You'll need two positions: one upstream with a deletion to generate the *; and one for the SNP. I think the dropped allele was a 1bp deletion at the; same position t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2959:2982,access,access,2982,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2959,1,['access'],['access']
Security,"k; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 INFO LeftAlignAndTrimVariants - Start Date/Time: September 5, 2018 4:34:35 PM EDT; 16:34:35.414 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 16:34:35.415 INFO LeftAlignAndTrimVariants - Picard V",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:1414,authenticat,authentication,1414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494,1,['authenticat'],['authentication']
Security,kGraphExecuter.java:256); 	at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:336); 	at org.gradle.internal.progress.DefaultBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:328); 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:199); 	at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:110); 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:249); 	at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:238); 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.processTask(DefaultTaskPlanExecutor.java:123); 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.access$200(DefaultTaskPlanExecutor.java:79); 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:104); 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker$1.execute(DefaultTaskPlanExecutor.java:98); 	at org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.execute(DefaultTaskExecutionPlan.java:663); 	at org.gradle.execution.taskgraph.DefaultTaskExecutionPlan.executeWithTask(DefaultTaskExecutionPlan.java:597); 	at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor$TaskExecutorWorker.run(DefaultTaskPlanExecutor.java:98); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:46); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.con,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445:11429,access,access,11429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446253445,1,['access'],['access']
Security,"king each executor to shut down; 19/04/08 19:03:28 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Stopped; 19/04/08 19:03:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 19/04/08 19:03:28 INFO MemoryStore: MemoryStore cleared; 19/04/08 19:03:28 INFO BlockManager: BlockManager stopped; 19/04/08 19:03:28 INFO BlockManagerMaster: BlockManagerMaster stopped; 19/04/08 19:03:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 19/04/08 19:03:28 INFO SparkContext: Successfully stopped SparkContext; 19:03:28.389 INFO HaplotypeCallerSpark - Shutting down engine; [April 8, 2019 7:03:28 PM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=941096960; Exception in thread ""main"" java.lang.StackOverflowError; 	at java.util.HashMap.putMapEntries(HashMap.java:501); 	at java.util.HashMap.<init>(HashMap.java:490); 	at com.esotericsoftware.kryo.Generics.<init>(Generics.java:47); 	at com.esotericsoftware.kryo.serializers.FieldSerializerGenericsUtil.buildGenericsScope(FieldSerializerGenericsUtil.java:116); 	at com.esotericsoftware.kryo.serializers.FieldSerializerGenericsUtil.newCachedFieldOfGenericType(FieldSerializerGenericsUtil.java:225); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.newCachedField(FieldSerializer.java:368); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.createCachedFields(FieldSerializer.java:331); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.rebuildCachedFields(FieldSerializer.java:261); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.rebuildCachedFields(FieldSerializer.java:182); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esoterics",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:18424,Hash,HashMap,18424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,1,['Hash'],['HashMap']
Security,"king from the original JAR. . The JAVA file where I added the most helpful statements was in CommandLineProgram.java which is actually in ""gatk"" repo (not ""gatk-protected"" repo). If I look at a LOG, I can see ""EAS"" my initials and see c40e75b which appears to be a more recent commit compared to 3a2bb0d. ```; EAS in main!!!!; EAS to call instanceMain second....; EAS to call instanceMain first....; 17:28:40.295 INFO SparkGenomeReadCounts - EAS ABOUT TO CALL instanceMainPostParseArgs in instanceMain in clp.java ; 17:28:40.396 INFO IntelGKLUtils - Trying to load Intel GKL library from:; 	jar:file:/cromwell_root/fc-7ac504fc-7fe4-4bc1-89d3-7f16317b8ff4/eddie.jar!/com/intel/gkl/native/libIntelGKL.so; 17:28:40.498 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [December 1, 2016 5:28:40 PM UTC] org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts --binsize 5000 --outputFile this.entity_id.coverage.tsv --reference Homo_sapiens_assembly19.fasta --input firecloud-tcga-open-access/tutorial/bams/C835.HCC1143_BL.4.bam --keepXYMT false --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; [December 1, 2016 5:28:40 PM UTC] Executing as root@71bfa07f6996 on Linux 3.16.0-0.bpo.4-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: Version:c40e75b-SNAPSHOT; 17:28:40.501 INFO SparkGenomeReadCounts - Defaults.BUFFER_SIZE : 131072; ```. ---. @eddiebroad commented on [Wed Dec 07 2016](https://github.com/broadinstitute/gatk-protected/issues/806#issuecomment-265470147). I want to mention in my case, all the reference files were present (fasta, fai, dict) BUT the dict was in a different directory and NOT in the same directory as the other two ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2922:5232,access,access,5232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2922,1,['access'],['access']
Security,"ks in advance!. ```; gatk ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Default",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911:1116,Validat,ValidateVariants,1116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911,1,['Validat'],['ValidateVariants']
Security,"l or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all dependencies without conflicts. 5. Engine team will continue to search for Java-based solutions while this evaluation is ongoing, but this proposal at least unblocks the CNV team for now.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3501:1352,authenticat,authentication,1352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501,1,['authenticat'],['authentication']
Security,"l000209_random, chr21_gl000210_random, chrUn_gl000211, chrUn_gl000212, chrUn_gl000213, chrUn_gl000214, chrUn_gl000215, chrUn_gl000216, chrUn_gl000217, chrUn_gl000218, chrUn_gl000219, chrUn_gl000220, chrUn_gl000221, chrUn_gl000222, chrUn_gl000223, chrUn_gl000224, chrUn_gl000225, chrUn_gl000226, chrUn_gl000227, chrUn_gl000228, chrUn_gl000229, chrUn_gl000230, chrUn_gl000231, chrUn_gl000232, chrUn_gl000233, chrUn_gl000234, chrUn_gl000235, chrUn_gl000236, chrUn_gl000237, chrUn_gl000238, chrUn_gl000239, chrUn_gl000240, chrUn_gl000241, chrUn_gl000242, chrUn_gl000243, chrUn_gl000244, chrUn_gl000245, chrUn_gl000246, chrUn_gl000247, chrUn_gl000248, chrUn_gl000249]; reads contigs = []; 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:163); 	at org.broadinstitute.hellbender.utils.SequenceDictionaryUtils.validateDictionaries(SequenceDictionaryUtils.java:98); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.validateToolInputs(GATKSparkTool.java:469); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:361); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:119); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:176); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:34855,validat,validateToolInputs,34855,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['validat'],['validateToolInputs']
Security,"l_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2184,Validat,ValidateVariants,2184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,lassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306); 	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:16,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:7078,Hash,HashMap,7078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,"lbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; A second case involved `--alleles` input:; ```; 22	16464044	rs571268158	CCAGGTCT	C; 22	16464051	rs569099729	T	C; ```; and crashed similarly, with:; ```; java.lang.IllegalStateException: Allele in genotype CCAGGTCT* not in the variant context [T*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336:2804,validat,validateGenotypes,2804,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336,1,['validat'],['validateGenotypes']
Security,lbender.relocated.com.google.common.collect.AbstractMapBasedMultimap.put; 0.5% 370 + 1 org.broadinstitute.hellbender.utils.baq.BAQ.calcBAQFromHMM; 0.5% 360 + 0 org.broadinstitute.hellbender.relocated.com.google.common.collect.ImmutableListMultimap.copyOf; 0.4% 348 + 5 scala.collection.IndexedSeqOptimized$class.zip; 0.4% 330 + 3 com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read; 0.4% 325 + 0 htsjdk.samtools.SAMBinaryTagAndValue.find; 0.4% 322 + 0 org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.getReadGroup; 66.2% 45378 + 7026 Total compiled (including elided). Stub + native Method ; 11.8% 0 + 9359 java.lang.String.intern; 7.1% 0 + 5608 java.util.zip.Deflater.deflateBytes; 6.9% 0 + 5492 java.lang.System.identityHashCode; 2.8% 0 + 2196 java.util.zip.Inflater.inflateBytes; 1.8% 0 + 1447 java.net.SocketInputStream.socketRead0; 0.6% 0 + 484 java.io.FileOutputStream.writeBytes; 0.4% 0 + 285 java.util.zip.Inflater.reset; 0.3% 0 + 259 sun.nio.ch.NativeThread.current; 0.3% 0 + 222 sun.nio.ch.EPollArrayWrapper.epollWait; 0.2% 0 + 137 java.util.zip.Deflater.reset; 0.1% 0 + 115 sun.nio.ch.FileDispatcherImpl.read0; 0.1% 0 + 113 org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray; 0.1% 67 + 4 java.lang.ClassLoader.defineClass1; 0.1% 0 + 51 java.util.zip.ZipFile.getEntry; 0.1% 0 + 41 java.lang.Throwable.fillInStackTrace; 0.0% 0 + 24 org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSums; 0.0% 0 + 23 java.lang.System.arraycopy; 0.0% 0 + 18 java.lang.Object.clone; 0.0% 1 + 15 java.io.UnixFileSystem.getBooleanAttributes0; 0.0% 0 + 14 sun.reflect.Reflection.getClassAccessFlags; 0.0% 0 + 13 java.lang.Thread.isInterrupted; 0.0% 0 + 11 java.lang.Class.isPrimitive; 0.0% 0 + 11 java.lang.Class.isArray; 0.0% 0 + 10 sun.nio.ch.FileDispatcherImpl.size0; 0.0% 4 + 5 java.security.AccessController.doPrivileged; 33.0% 77 + 26077 Total stub (including elided). Thread-local ticks:; 29.9% 33828 Blocked (of total); 0.0% 3 Class loader. ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1657#issuecomment-208967490:5291,secur,security,5291,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1657#issuecomment-208967490,2,"['Access', 'secur']","['AccessController', 'security']"
Security,"le.cloud.genomics.dataflow.utils.DataflowWorkarounds registerGenomicsCoders; INFO: Registering coder for VariantAnnotation; Jul 14, 2015 1:14:51 PM com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds registerGenomicsCoders; INFO: Registering coder for SearchAnnotationSetsRequest; Jul 14, 2015 1:14:51 PM com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds registerGenomicsCoders; INFO: Registering coder for RangePosition; Jul 14, 2015 1:14:51 PM com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds registerGenomicsCoders; INFO: Registering coder for SearchJobsRequest; Jul 14, 2015 1:14:51 PM com.google.cloud.genomics.dataflow.utils.DataflowWorkarounds registerGenomicsCoders; INFO: Registering coder for ExportVariantSetRequest; 15/07/14 13:14:51 INFO spark.SparkPipelineRunner: Executing pipeline using the SparkPipelineRunner.; 15/07/14 13:14:51 INFO spark.SparkContext: Running Spark version 1.3.1; 15/07/14 13:14:51 INFO spark.SecurityManager: Changing view acls to: louisb; 15/07/14 13:14:51 INFO spark.SecurityManager: Changing modify acls to: louisb; 15/07/14 13:14:51 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(louisb); users with modify permissions: Set(louisb); 15/07/14 13:14:52 INFO slf4j.Slf4jLogger: Slf4jLogger started; 15/07/14 13:14:52 INFO Remoting: Starting remoting; 15/07/14 13:14:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@wm1b0-8ab.broadinstitute.org:65238]; 15/07/14 13:14:52 INFO util.Utils: Successfully started service 'sparkDriver' on port 65238.; 15/07/14 13:14:52 INFO spark.SparkEnv: Registering MapOutputTracker; 15/07/14 13:14:52 INFO spark.SparkEnv: Registering BlockManagerMaster; 15/07/14 13:14:52 INFO storage.DiskBlockManager: Created local directory at /var/folders/xt/vq7wz8955r1401mv8w0f4zf9qbfwzl/T/louisb/spark-7b286138-5fde-4fcb-bc34-3c6a86da6c0c/blockmgr-46eb69b0-d3ca-4004-bf32-ab103c0787f2; 15/07/14 13:1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713:16199,Secur,SecurityManager,16199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/639#issuecomment-121313713,1,['Secur'],['SecurityManager']
Security,leapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:347); ... 17 more; Caused by:; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); at shaded.cloud-nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); at shaded.cloud-nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); at shaded.cloud-nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAcc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:3925,secur,security,3925,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,1,['secur'],['security']
Security,lection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. 8/02/23 23:06:24 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/02/23 23:06:24 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/02/23 23:06:24 INFO spark.SparkContext: Successfully stopped SparkContext; 23:06:24.240 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:3469,validat,validatePositions,3469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validatePositions']
Security,lection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.co,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:7148,validat,validatePositions,7148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validatePositions']
Security,"lection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Shutdown hook called; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/farrell/spark-94fa6743-3d29-4748-b8f8-d13a52dfed31; ```. The command line is:. ```; gatk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:13940,validat,validatePositions,13940,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['validat'],['validatePositions']
Security,"lem:. ```; chr1	10027	.	A	C,G	.	PASS	.	GT:AD:AF:DP	1/2:0,5,5:0.500,0.500:10; ```. vs. ```; chr1	10027	.	A	C,G	.	PASS	.	GT:AD:DP	1/2:0,5,5:10; ```. The output for GATK 4.1.4.1 or when the AF field is removed looks like this:; ```; chr1	10027	.	A	C	.	PASS	.	GT:AD:DP	./.:0,5:10; chr1	10027	.	A	G	.	PASS	.	GT:AD:DP	./.:0,5:10; ```. #### Steps to reproduce; ```; $gatk/gatk LeftAlignAndTrimVariants -R $reference --split-multi-allelics -V test.input.vcf -O test.output.vcf; ```. #### Expected behavior; LeftAlignAndTrimVariants should be able to split multiallelic records in a VCF to two separate records as in GATK version 4.1.4.1. The AF field is removed from the 4.1.4.1 output, however. #### Actual behavior; GATK fails at a multiallelic record with the following error (GATK 4.2.0.0):; ```; java.lang.IllegalArgumentException: the range size cannot be negative; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); 	at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:107); 	at org.broadinstitute.hellbender.utils.IndexRange.<init>(IndexRange.java:67); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.splitASSBTable(GATKVariantContextUtils.java:1533); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.splitSomaticVariantContextToBiallelics(GATKVariantContextUtils.java:1501); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants.apply(LeftAlignAndTrimVariants.java:225); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$Ite",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7211:1543,validat,validate,1543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7211,1,['validat'],['validate']
Security,"lfs pull (#7806); - Document AoU SOP (up to the VAT) [VS-63] (#7807); - Incident VS 365 clinvar classification fix (#7769); - VS-390. Add precision and sensitivity wdl (#7813); - Quickstart based integration test [VS-357] (#7812); - 365 vat python testing additions (#7756); - VS 396 clinvar grabs too many values (#7823); - Added a test to validate WDLs in the scripts directory. (#7826) (#7829); - VAT Performance / Reliability Improvements (#7828); - VAT naming conventions [VS-410] (#7827); - Rc remove ad from vat (#7832); - bugfix, we were trying to grep a binary file (#7837); - Cleanup scripts/variantstore [VS-414] (#7834); - Merge VAT TSV files into single bgzipped file [VS-304] (#7848); - Handle fully and partially loaded samples [VS-262] [VS-258] (#7843); - Ingest Error Handling Fixes [VS-261] (#7841); - First cut at a python notebook to validate inputs. (#7845); - Compute filter scatter [VS-392] (#7852); - remove withdrawn req (#7844); - Improve import error message [VS-437] (#7855); - Fix Input Validation python notebook (#7853); - Add VAT Validation check that aa_change and exon_number are consistently set. (#7850); - Ingest 10K [VS-344] (#7860); - X/Y chromosome reweighting for better extract shard runtime balance [VS-389] (#7868); - VET Ingest Validation / Allow Ingest of non-VQSR'ed data (#7870); - Fix AoU workflow bugs (#7874); - Curate input arrays to skip already ingested sample data [VS-246] (#7862); - KM upload GVS product sheet (#7883); - Default extract scatter width [VS-415] (#7878); - Volatile tasks review [VS-447] (#7880); - Update Quickstart Integration for X/Y scaling changes [VS-464] (#7881); - clean up dockstore; - Rc vs 63 vat sop documentation (#7879); - Fix up FQ and race condition issues with volatile tasks work [VS-478] (#7888); - Use gvs-internal project in integration test (#7901); - Add cost observability BQ table [VS-441] (#7891); - Add preliminary labels to queries [VS-381] (#7902); - Workflow compute costs [VS-472] (#7905); - Fix bu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:24617,Validat,Validation,24617,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,['Validat'],['Validation']
Security,licatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.fore,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:6880,Hash,HashMap,6880,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,lication_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:8088/proxy/application_1603353714322_0004/; 	 user: jacky; 20/10/22 12:02:35 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:36 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:37 INFO yarn.Client: Application report ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6906:3561,Secur,SecurityManager,3561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906,3,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,lidator.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CYXNpY1NvbWF0aWNTaG9ydE11dGF0aW9uVmFsaWRhdG9yLmphdmE=) | `64.865% <64.865%> (ø)` | `5 <5> (?)` | |; | [.../basicshortmutpileup/BetaBinomialDistribution.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CZXRhQmlub21pYWxEaXN0cmlidXRpb24uamF2YQ==) | `68.182% <68.182%> (ø)` | `4 <4> (?)` | |; | [...ation/basicshortmutpileup/AllelePileupCounter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9BbGxlbGVQaWxldXBDb3VudGVyLmphdmE=) | `81.25% <81.25%> (ø)` | `12 <12> (?)` | |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `85.965% <85.965%> (ø)` | `7 <7> (?)` | |; | [...ion/basicshortmutpileup/PowerCalculationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9Qb3dlckNhbGN1bGF0aW9uVXRpbHMuamF2YQ==) | `95.238% <95.238%> (ø)` | `15 <15> (?)` | |; | [...bender/utils/GATKProtectedVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HQVRLUHJvdGVjdGVkVmFyaWFudENvbnRleHRVdGlscy5qYXZh) | `77.901% <95.833%> (+6.472%)` | `70 <23> (+23)` | :arrow_up: |; | [...ion/basicshortmutpileup/B,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3755#issuecomment-341515732:2828,Validat,ValidateBasicSomaticShortMutations,2828,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3755#issuecomment-341515732,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,lientRequest.java:300); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at shaded.cloud-nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:347); ... 17 more; Caused by:; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); at shaded.cloud-nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); at shaded.cloud-nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); at shaded.cloud-nio.com.goog,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2514:3855,secur,security,3855,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2514,1,['secur'],['security']
Security,"linked hash set, linked hash map",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1844:7,hash,hash,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1844,2,['hash'],['hash']
Security,litIntervals		6/5/2017	https://github.com/broadinstitute/gatk-protected/blob/ec40da398e4185fa8fb0c62453304e8315f8f4e1/src/main/java/org/broadinstitute/hellbender/tools/walkers/SplitIntervals.java	scripts/mutect2_wdl/mutect2.wdl	https://github.com/broadinstitute/gatk/pull/3032	yes	Default value: INTERVAL_SUBDIVISION. warn users to be careful when dividing lengthy genomic intervals. Perhaps it would be wise to specify the workflow in which this tool would be used. Something for the second pass.; 44	GetPileupSummaries	beta; helper tool for CalculateContamination	6/5/2017	https://github.com/broadinstitute/gatk-protected/blob/2bf35790393332da5414b42ec6dca813fcc63202/src/main/java/org/broadinstitute/hellbender/tools/walkers/contamination/GetPileupSummaries.java	scripts/mutect2_wdl/mutect2.wdl	https://github.com/broadinstitute/gatk/pull/3006	yes	; 33	AnnotateVcfWithBamDepth	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/AnnotateVcfWithBamDepth.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 34	AnnotateVcfWithExpectedAlleleFraction	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/AnnotateVcfWithExpectedAlleleFraction.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 37	CalculateMixingFractions	internal (DB)	5/30	https://github.com/broadinstitute/gatk-protected/blob/e6278def94038d76339d0fd95ce2badb3bc44a22/src/main/java/org/broadinstitute/hellbender/tools/walkers/validation/CalculateMixingFractions.java	scripts/mutect2_wdl/unsupported/hapmap_sensitivity_truth.wdl	https://github.com/broadinstitute/gatk-protected/pull/1131	yes	; 47	RemoveNearbyIndels	i,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3055:12697,validat,validation,12697,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3055,1,['validat'],['validation']
Security,"lity shouldn't really change across some of them.; ; I'm currently just using call outs to system commands to diff and h5diff the VCFs and HDF5s, respectively. I think the latter command should be available in the GATK Conda environment. This will be a bit awkward, in the sense that the tests for this tool will require the Conda environment, but the tool itself will not. But I think this is probably preferable to writing test code to compare HDF5s, minimal though that might be, since the schema might change in the future.; - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs. Could perhaps expand on the `resources` parameter once the required labels are settled.; - [x] Parameter validation.; - [x] Clean up docs for parent walker.; - [x] Decide on required labels. I think ""training"" and ""calibration"" (rather than the legacy ""training"" and ""truth"") might be good candidates. EDIT: Switched ""truth"" to ""calibration"" throughout the codebase.; - [x] Validate privileged labels (snp, training, calibration) in parent walker.; ; Future work:. - [ ] Clean up unlabeled outputs. This includes 1) sorting the corresponding HDF5, and 2) outputting a corresponding sites-only VCF. Unlike the labeled sites, which are written individually to VCF as we traverse them, unlabeled sites are placed into a reservoir of fixed size for subsampling purposes. Thus, we cannot write them to VCF as with labeled sites; furthermore, after traversal, the unlabeled sites are not ordered within the reservoir. Ultimately, the lack of this VCF means that extracted, unlabeled sites cannot be tagged as such by the scoring tool in the final VCF.; - [ ] Consider downsampling of labeled data. This is not done because 1) of the complications just mentioned, 2) we assume that labeled data is precious and that one-time extraction of it will always be relatively cheap, especially compared to training (and that training implementations can always downsample, if needed), and 3) using -L functionality to subs",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059:3440,Validat,Validate,3440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059,1,['Validat'],['Validate']
Security,"lling all running tasks in stage 2: Stage finished; 23/11/16 12:09:10 INFO DAGScheduler: Job 2 finished: parquet at StudentAws.scala:36, took 10.369237 s; 23/11/16 12:09:10 INFO FileFormatWriter: Start to commit write Job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; 23/11/16 12:09:10 ERROR FileFormatWriter: Aborting job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method); 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793); 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249); 	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454); 	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377); 	at org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:48); 	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192); 	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640); 	at o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:2603,Checksum,ChecksumFileSystem,2603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['Checksum'],['ChecksumFileSystem']
Security,"log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 23:01:58.560 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///omics/chatchawit/bundle/test/gencode/hg38/gencode.v27.chr_patch_hapl_scaff.annotation.REORDERED.gtf; 23:02:05.335 INFO ProgressMeter - Starting traversal; 23:02:05.337 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:02:06.530 INFO Funcotator - Shutting down engine; [April 27, 2018 11:02:06 PM ICT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=3420979200; java.lang.IllegalArgumentException: Invalid interval. Contig:ENST00000342066.7|ENSG00000187634.11|OTTHUMG00000040719.10|OTTHUMT00000276866.2|SAMD11-202|SAMD11|2551|protein_coding| start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getCodingSequenceFromTranscriptFasta(GencodeFuncotationFactory.java:418); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:1177); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createCodingRegionFuncotation(GencodeFuncotationFactory.java:619); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnTranscript(GencodeFuncotationFactory.java:575); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotations(GencodeFuncotationFactory.java:487); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.Genc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157:7302,validat,validatePositions,7302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157,1,['validat'],['validatePositions']
Security,"looks like we need to run a special fetch command to get access to the pr merge commits, ex:; ```; git fetch origin +refs/pull/3217/merge; ```; Looks like the change is a bit more complicated than I hoped.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3217#issuecomment-313238500:57,access,access,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3217#issuecomment-313238500,1,['access'],['access']
Security,"loped a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The following items are necessary done for automatic evaluation:** ; - Dataset + truth. We need an access to a high quality public cohort with matched whole genomes. These genomes have to have a corresponding high quality truth set generated from split-read/read-pair methods. From that cohort we need to find 50-200 relatively homogeneous samples.; - An established validation workflow that outputs a set predetermined metrics that are unlikely to change in a future. Such as a sensitivity/specificity stratified by event size and allelic frequency.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:1767,validat,validation,1767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502,3,"['access', 'validat']","['access', 'validation']"
Security,"lpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 17:43:53.293 INFO ValidateVariants - Done init",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2922,Validat,ValidateVariants,2922,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,lse; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - GCS max retries/reopens: 20; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 18:30:54.424 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; 18/01/09 18:30:54 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1; 18/01/09 18:30:54 INFO spark.SparkContext: Submitted application: BwaAndMarkDuplicatesPipelineSpark; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls to: sun; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing view acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: Changing modify acls groups to: ; 18/01/09 18:30:54 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sun); groups with view permissions: Set(); users with modify permissions: Set(sun); groups with modify permissions: Set(); 18/01/09 18:30:55 INFO util.Utils: Successfully started service 'sparkDriver' on port 38793.; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering MapOutputTracker; 18/01/09 18:30:55 INFO spark.SparkEnv: Registering BlockManagerMaster; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 18/01/09 18:30:55 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 18/01/09 18:30:55 INFO storage.DiskBlockManager: Created local directory at /tmp/sun/blockmgr-b03058dc-763a-449c-bd05-18f3304c01ea; 18/01/09 18:30:55 INFO memory.MemoryStore: Mem,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:5519,Secur,SecurityManager,5519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['Secur'],['SecurityManager']
Security,ltBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:394); at org.gradle.internal.operations.DefaultBuildOperationExecutor$1.execute(DefaultBuildOperationExecutor.java:165); at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:250); at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:158); at org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:92); at org.gradle.internal.operations.DelegatingBuildOperationExecutor.run(DelegatingBuildOperationExecutor.java:31); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:461); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:444); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.access$200(ExecuteActionsTaskExecuter.java:93); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$TaskExecution.execute(ExecuteActionsTaskExecuter.java:237); at org.gradle.internal.execution.steps.ExecuteStep.lambda$execute$1(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:26); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:58); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:35); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-590387973:7551,access,access,7551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-590387973,2,['access'],['access']
Security,"lters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.287 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood.vcf; 17:43:53.291 WARN IndexUtils - Feature file ""/Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/ValidateVariants/validationExampleGood",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2750,Validat,ValidateVariants,2750,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,ltiIntervalLocalReadShard.iterator(MultiIntervalLocalReadShard.java:134); 	at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.<init>(AssemblyRegionIterator.java:86); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:188); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. #### Steps to reproduce; The error occurs when running a command: ; ```; gatk Mutect2 -R /home/genome/gatk.hg38/Homo_sapiens_assembly38.fasta -L panel_collapsed.bed -I bam/tumour_recalibrated.bam -I bam/normal_recalibrated.bam -tumor tumour -normal normal -germline-resource /home/genome/gatk.hg38/af-only-gnomad.hg38.vcf.gz -pon /home/genome/pon/PON_B1.vcf --genotype-pon-sites --f1r2-tar-gz results/learnOrientation/tumour_lo.tar.gz -O results/Mutect2/tumour.s.vcf.gz -bamout bam/tumour.mutect2.bam --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter --af-of-alleles-not-in-resource 0.000001; ```. #### Expected behavior; Mutect2 producing outputs. #### Actual behavior; Full log: ; [Mutect2_error.txt](https://github.com/broadinstitute/gatk/files/8772744/Mutect2_error.txt). ---. I would be grateful if you could help me to investigate the cause of this error. I couldn't find any clues when googling it and tried `picard ValidateSamFile` but it returns no errors or warnings. Many thanks!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7872:3181,Validat,ValidateSamFile,3181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7872,1,['Validat'],['ValidateSamFile']
Security,"ly$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at StudentAws$.main(StudentAws.scala:8); 	at StudentAws.main(StudentAws.scala); Exception in thread ""main"" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method); 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793); 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249); 	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454); 	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377); 	at org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:48); 	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192); 	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640); 	at org.apache.spark.sql.exec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:8276,Checksum,ChecksumFileSystem,8276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['Checksum'],['ChecksumFileSystem']
Security,"m%20Eiklid/Analysis/gatk-4.2.4.1/ensembl-vep/PE69_chr3.vcf; 10:58:20.063 INFO VariantAnnotator - Done initializing engine; 10:58:20.091 WARN VariantAnnotatorEngine - The requested expression attribute ""gnomad.ALT"" is missing from the header in its resource file gnomad; 10:58:20.140 INFO ProgressMeter - Starting traversal; 10:58:20.140 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 10:58:42.160 INFO VariantAnnotator - Shutting down engine; [March 17, 2022 at 10:58:42 AM CET] org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator done. Elapsed time: 0.37 minutes.; Runtime.totalMemory()=17158897664; java.lang.IllegalStateException: Allele in genotype C not in the variant context [C*, CT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.base/java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1464); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1420); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:568); 	at org.broadinstitute.hellbender.tools.walkers.annotato",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053:4162,Validat,Validation,4162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053,1,['Validat'],['Validation']
Security,"m.google.cloud.genomics.gatk.common. I've been working on this bam file issue, correcting errors in the files used for tests. Many of the errors involve reads with FLAGs that indicate that they are in pairs, but the mate is not extant in the file, causing the error. A way to fix this without deleting the offending reads is to set the FLAG to zero and also modify the RNEXT, PNEXT, and TLEN fields, if necessary, so that the read becomes single (provided that the values of all of these fields are not important for the tests). However, when I do this, I find that tests that write and then read bam files fail, because when the just-written file is read back, SAM validation complains that the mate unmapped FLAG is set for an unpaired read. It turns out that the copy of the file written by the test substitutes the value '8' for '0' as the FLAG for the modified reads. The relevant code in GenomicsConvertermakeSamRecord() (line 170) is:. flags += ((read.getNextMatePosition() == null || read.getNextMatePosition.getPosition() == null)) ? 8 : 0;. The effect of this line is that all reads which have null mate positions, even those which the FLAG specifies as unpaired, get the mate unmapped FLAG set, causing the validation errors that i'm seeing. The reason the tests have not failed before is apparently that the existing test files do not contain any reads with FLAGs that specify them as unpaired. A simple fix for this would be to convert the line above to:. flags += ( paired && (read.getNextMatePosition() == null || read.getNextMatePosition.getPosition() == null)) ? 8 : 0;. The redundant parens in the original code suggest that something like this may have been intended,but the google genomics documentation at http://google-genomics.readthedocs.org/en/latest/migrating_tips.html gives the following pseudocode:. flags += read.nextMatePosition.position == null ? 8 : 0 #mate_unmapped. so it looks like the doc supports the existing code. Should I submit this as an issue? . Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114101033:1375,validat,validation,1375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114101033,1,['validat'],['validation']
Security,mail.com>; Date: Tue Dec 12 11:26:31 2017 -0500. disabled some gCNV WDL tests. commit 6d8ca07fef41518b5b157fb9a214d4536c617156; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 10:54:54 2017 -0500. fixed DenoiseReadCountsIntegrationTest files. commit adfbef12f2ab90f93b49a4f786979549648e1f22; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Mon Dec 11 02:22:56 2017 -0500. removed CNV evaluation code from this branch. commit 18c8d31f39a1964474c5d7b12ee8cbfafc4ac9e2; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Sun Dec 10 00:19:58 2017 -0500. GS VCF parser outputs dict for samples instead of list. commit b138be39cd8428342668ee6678079021006f983b; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Sun Dec 10 00:15:19 2017 -0500. renaming. commit eab5c90b74b4eb6bd11acb0fd1e0fa58a3b5b0c7; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 16:23:40 2017 -0500. exposed a global preemptible_attempts to gCNV workflows; set OMP_NUM_THREADS and MKL_NUM_THREADS to the number of requested CPUs. commit ad6fe348d6a7896c169b2b0499e2a4bca34021ad; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 10:21:25 2017 -0500. reverted log level in germline CNV tests. commit d9eb4e504baab834a9efc07cc3479176db2946ce; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 10:20:30 2017 -0500. the proper python environment yml for mkl and open -- leads to orders of magnitude speedup!. commit fea6bf874e0b62262a3b1d239ce4d76792d5c416; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 09:31:43 2017 -0500. revert. commit 456c53f88d01b603f4175d8896a0dac036af03f8; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 08:17:22 2017 -0500. enabled openmp g++ linking in theano. commit e2afef14ddb957f2dbdea76fd783d3bfb8d7a64e; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 08:04:19 2017 -0500. mkl. commit 43e2a65201286161fcd5bfe7dbb21ae888e1,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:2311,expose,exposed,2311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,1,['expose'],['exposed']
Security,making the version number depend on the git hash using a gradle git plugin from https://github.com/ajoberstar/gradle-git. It seems like the top gradle-git integration library. There are lots of pre-baked things in it to help with releases and such that we can grow into.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/196:44,hash,hash,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/196,1,['hash'],['hash']
Security,manage_sv_pipeline checks version from gatk-spark.jar and compares it; to the current git hash (to ensure the correct version is run). Newer; gatk versions had a slightly different file name format and caused; errors parsing the hash. This updates the hash check and produces; more comprehensible error messages when it fails. Resolves: #3593,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3595:90,hash,hash,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3595,3,['hash'],['hash']
Security,"mand line argument is highly dubious.) . It's possible that apache code does something similar to fully decoding that could affect performance. All that is to say that we cannot achieve performance improvement with our original blueprint simply because this expensive ""fullyDecode"" operation seems to be a mythical operation that is never used in reality. So while I could not speed up SelectVariants, I cleaned up the code and added the following new arguments:. * `--select-genotype`: with this new genotype-specific JEXL argument, we support filtering by genotype fields like 'GQ > 0', where the behavior in the multi-sample case is 'GQ > 0' in at least one sample. I have not added the ability to do 'GQ > 0 for all samples' but it should be a simple (but not easy…) exercise in boolean operations.; * `applyJexlFiltersBeforeFilteringGenotypes`: if set to true, we do the JEXL checking before we subset by samples. In my tests, performance improvement from this option was very modest. Subsetting a ~3k 1kg SV vcf to a single sample was about 30 seconds faster (out of ~20 min total run time) than the default. I kept it in the PR because I thought some user might find it useful, but I wouldn't be opposed to removing it. Tests needed:; - [x] Filter by genotypes with a new flag --genotype-select, with the default behavior being 'passes if at least one sample passes' ; - [x] Multiple --select expressions should be combined with logical-or; - [x] Test string annotations (e.g. ALGORITHM == 'depth'); - [x] Jexl involving with logical-and (e.g. AC > 0 && AF > 0.01); - [x] Access genotypes directly e.g. vc.getsample('NA12878'); - [x] DP > 0 as --genotype-select and as --select; - [x] Combine --select and --select-genotypes; - [x] Code path that uses ""fully-decode""; - [x] Failing cases (reference genotype fields in --select and vice versa); - [x] `--applyJexlFiltersBeforeFilteringGenotypes.` Does this actually give us performance advantage? ; - [x] Add a test for `select-random-fraction`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8092:3012,Access,Access,3012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8092,1,['Access'],['Access']
Security,"markw@WMC9F-819:~/IdeaProjects/gatk$ ./gatk-launch PrintReadsSpark -I gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam -O hs37d5cs.reads.txt --apiKey XXXXXXXXXXXXXXXXXXXX --verbosity DEBUG -- --sparkRunner GCS --cluster mw-test --project broad-dsde-methods; Using GATK jar /Users/markw/IdeaProjects/gatk/build/libs/gatk-package-4.alpha.2-157-g7d7c5ec-SNAPSHOT-spark.jar; jar caching is disabled because GATK_GCS_STAGING is not set. please set GATK_GCS_STAGING to a bucket you have write access too in order to enable jar caching; add the following line to you .bashrc or equivalent startup script. export GATK_GCS_STAGING=gs://<my_bucket>/. Replacing spark-submit style args with dataproc style args. --cluster mw-test --project broad-dsde-methods -> --cluster mw-test --project broad-dsde-methods --properties spark.kryoserializer.buffer.max=512m,spark.driver.maxResultSize=0,spark.driver.userClassPathFirst=true,spark.io.compression.codec=lzf,spark.yarn.executor.memoryOverhead=600,spark.driver.extraJavaOptions=-Dsamjdk.compression_level=1 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true ,spark.executor.extraJavaOptions=-Dsamjdk.compression_level=1 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true. Running:; gcloud dataproc jobs submit spark --cluster mw-test --project broad-dsde-methods --properties spark.kryoserializer.buffer.max=512m,spark.driver.maxResultSize=0,spark.driver.userClassPathFirst=true,spark.io.compression.codec=lzf,spark.yarn.executor.memoryOverhead=600,spark.driver.extraJavaOptions=-Dsamjdk.compression_level=1 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true ,spark.executor.extraJavaOptions=-Dsamjdk.compression_level=1 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true --jar /Users/markw/IdeaProjects/gatk/build/libs/gatk-package-4.alpha.2-157-g7d7c5ec-SNAPSHOT-spark.jar -- PrintReadsSpark -I gs://mw-pathseq-test/hs37d5cs.reads.sorted.bam -O hs37d5cs.reads.txt --apiKey XXXXXXXXXXXXXXXXXXXXX --verbosity DEBUG --sparkMaster yarn; Copying file:///Users/markw/IdeaProjects/gatk/build/libs/gatk-package-4.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929:485,access,access,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2394#issuecomment-277823929,1,['access'],['access']
Security,"mblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; The second case included the following `--alleles` input:; ```; 22	16464044	rs571268158	CCAGGTCT	C; 22	16464051	rs569099729	T	C; ```; and it crashed similarly, with:; ```; java.lang.IllegalStateException: Allele in genotype CCAGGTCT* not in the variant context [T*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5337:2848,validat,validateGenotypes,2848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5337,1,['validat'],['validateGenotypes']
Security,"mentations of copy-ratio, allele-fraction, and ""multidimensional"" (joint) segmentation. All implementations are pretty boilerplate; they simply partition by contig and then call out to KernelSegmenter. Note that there is some logic in multidimensional segmentation that only uses the first het in each copy-ratio interval and if any are available, and imputes the alt-allele fraction to 0.5 if not.; -Makes sense for @mbabadi to review this, since he reviewed the KernelSegmenter PR. Added modeling classes and tests for ModelSegments CNV pipeline.; -Most of this code is copied from the old MCMC code. However, I've done some overall code cleanup and refactoring, especially to remove some overextraction of methods in the allele-fraction likelihoods (see #2860). I also added downsampling and scaling of likelihoods to cut down on runtime. Tests have been simplified and rewritten to use simulated data.; -@LeeTL1220 do you think you could take a look?. Added ModelSegments CLI.; -Mostly control flow to handle optional inputs and validation, but there is some ugly and not well documented code that essentially does the GetHetCoverage step. We'll refactor later, I filed #3915.; -@asmirnov239 can review. This is lower priority than the gCNV VCF writing. Deleted gCNV WDL and Cromwell tests.; -Trivial to review. Added WDL and Cromwell tests for ModelSegments CNV pipeline.; -This includes the cost optimizations from @meganshand and @jsotobroad (sorry guys, I wasn't sure how to track your contributions while fixing up commits!) I also added tests for both GC/no-GC pair workflows.; -@MartonKN should review to gain familiarity with the WDL. Note that this WDL has already been through many revisions from @meganshand, @jsotobroad, and @LeeTL1220, so hopefully there shouldn't be too much for you to find serious fault with. Note that I punted on adding MultidimensionalKernelSegmenterUnitTest and ModelSegmentsIntegrationTest. Filed #3916. Closes #2858. (FINALLY!); Closes #3825.; Closes #3661.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3913:1600,validat,validation,1600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3913,1,['validat'],['validation']
Security,"methods.internal, executor 48): java.lang.IllegalArgumentException: Unexpected CIGAR format with deletion neighboring clipping; cigar elements are: [1190M, 4D, 53M, 2I, 26M, 2I, 31M, 2D, 1450S]; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:681); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.validateCigar(SvCigarUtils.java:134); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.getUnclippedReadLength(SvCigarUtils.java:161); 	at org.broadinstitute.hellbender.tools.spark.sv.utils.SvCigarUtils.computeAssociatedDistOnRead(SvCigarUtils.java:330); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.AlignmentInterval.readIntervalAlignedToRefSpan(AlignmentInterval.java:634); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.extractAltHaplotypeSeq(CpxVariantDetector.java:852); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.access$300(CpxVariantDetector.java:47); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector$AnnotatedContig.annotate(CpxVariantDetector.java:194); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector$AnnotatedContig.<init>(CpxVariantDetector.java:132); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantDetector.lambda$inferSvAndWriteVCF$14707a88$1(CpxVariantDetector.java:60); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collect",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4260:5745,access,access,5745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260,1,['access'],['access']
Security,"micsdb.GenomicsDBImport.getFeatureReadersSerially(GenomicsDBImport.java:602); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:490); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:153); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadinstitute.hellbender.Main.main(Main.java:277); Caused by: com.google.cloud.storage.StorageException: 443301511749-compute@developer.gserviceaccount.com does not have storage.objects.get access to fc-50c768b1-a285-4c95-8d8c-8ce209f1fda8/744139c5-3371-4a67-a2c8-e054e46f814f/ReblockGVCF/601ea396-b6cf-4baa-95c7-83e88b92c194/call-GenotypeGVCF/09C97227.c9cd4496-b4ed-4686-babd-177c66168178.vcf.gz.tbi.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:614); 	... 15 more; Caused by: shaded.cloud_nio.com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; """,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592:2625,access,access,2625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592,1,['access'],['access']
Security,"mment-262613152). @ldgauthier Shouldn't a locus without genotypes bypass `AC` validation, given it's defined as: `Allele count in genotypes, for each ALT allele, in the same order as listed`?. ---. @ldgauthier commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613997). Agreed. ---. @ronlevine commented on [Thu Nov 24 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262635204). The change should be a lot simpler than proposed. The code can validate the number of alleles before it checks for the presence of genotypes in [VariantContext#validateChromosomeCounts](https://github.com/samtools/htsjdk/blob/master/src/main/java/htsjdk/variant/variantcontext/VariantContext.java#L1236). . ---. @ldgauthier commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263277972). Sorry, I needed to refresh my memory. I actually don't want to bypass AC validation for variants without genotypes, but I think you already figured that out. My proposal was more general, but you're right -- AC and AF should always have the same count as alt alleles and we don't need to check the header for that. When this came up (a year and a half ago!) we were thinking about validating all the info field annotations. ---. @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in https://github.com/samtools/htsjdk/pull/759. I can expand this to all INFO field annotations. ---. @ldgauthier commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265221057). Expanding to all INFO annotations would be wonderful, but that can be a separate issue. ---. @ronlevine commented on [Tue Dec 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-265223581). That's not the only one, @magicDGS requested validating the `AF` val",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:6292,validat,validation,6292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['validat'],['validation']
Security,"more recent versions of gatk have a different message now, which is also confusing:. ```; ./gatk-launch PrintReadsSpark -I hdfs://local/print_reads.sorted.bam -O output.bam -- --sparkRunner SPARK --sparkMaster yarn-client; ```. ```; java.lang.IllegalArgumentException: java.net.UnknownHostException: local; at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374); at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:310); at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:176); at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:707); at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:650); at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:148); at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2643); at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:93); at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2680); at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2662); at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:379); at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:183); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReads(GATKSparkTool.java:337); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:317); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:308); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(Co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1257#issuecomment-175789890:328,secur,security,328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1257#issuecomment-175789890,4,"['Secur', 'access', 'secur']","['SecurityUtil', 'access', 'security']"
Security,mory including 384 MB overhead; 17/10/13 18:11:36 INFO yarn.Client: Setting up container launch context for our AM; 17/10/13 18:11:36 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/13 18:11:36 INFO yarn.Client: Preparing resources for our AM container; 17/10/13 18:11:37 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-c7e5eece-205e-4bce-a69b-4168c9b79045/__spark_conf__2918234914787361986.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507856833944_0003/__spark_conf__.zip; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); groups with view permissions: Set(); users with modify permissions: Set(hdfs); groups with modify permissions: Set(); 17/10/13 18:11:37 INFO yarn.Client: Submitting application application_1507856833944_0003 to ResourceManager; 17/10/13 18:11:37 INFO impl.YarnClientImpl: Submitted application application_1507856833944_0003; 17/10/13 18:11:37 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1507856833944_0003 and attemptId None; 17/10/13 18:11:38 INFO yarn.Client: Application report for application_1507856833944_0003 (state: ACCEPTED); 17/10/13 18:11:38 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: root.users.hdfs; 	 start time: 1507889497661; 	 final status: UNDEFINED; 	 tracking URL: http://mg:8088/proxy/application_1507856833944_0003/; 	 user: hdfs; 17/10/13 18:11:39 INFO yarn.Client: Application report for application_1507856833944_0003 (state: ACCEPTED); 17/10/13 ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:10868,Secur,SecurityManager,10868,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,3,"['Secur', 'authenticat']","['SecurityManager', 'authentication']"
Security,"most people get protected. I'd rather push the pain down to public (unless; it doubles the pain and both repos need this). Oh btw, perhaps we should spin off the HDF5 to a separate project that we; would just inject in gatk; wdyt?. On Thu, Jun 9, 2016 at 10:37 AM, Louis Bergelson notifications@github.com; wrote:. > do we want this in protected? It means people have to go through arcane; > installation procedures...; > ; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/gatk/pull/1901#issuecomment-224914735,; > or mute the thread; > https://github.com/notifications/unsubscribe/AB5rLyoyUN__Bfdub4Sejc920Eh84aQUks5qKCUMgaJpZM4IxmGO; > .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1901#issuecomment-224925037:209,inject,inject,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1901#issuecomment-224925037,1,['inject'],['inject']
Security,ms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:6839,Hash,HashMap,6839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['Hash'],['HashMap']
Security,mutect2 expose param,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8447:8,expose,expose,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8447,1,['expose'],['expose']
Security,"n [Wed Oct 19 2016](https://github.com/broadinstitute/gatk-protected/issues/751). Things that we discussed with @samuelklee that can be done to aid it:. -I think that all files we generate for individual case samples---""ReadCountCollection"" files for coverage profiles, ""AllelicCountCollection"" files for het pulldowns, and segment files---should contain the sample name as metadata in a header comment with a common tag (e.g., #sampleName = ...). Currently, these sample names are stored in column headers, in the fields of a SAMPLE column, or not at all, depending on the type of file. This would drastically simplify the use of the SampleNameFinder class, which would basically only contain a single method to parse this header comment and return the name. -CLIs that generate a file from an input BAM (CalculateTargetCoverage, GetHetCoverage, etc.) should take the sample name from that BAM by default. Since these are the first steps in our workflows, we could also optionally allow the user to specify a sample name different from that in the BAM. -Subsequent CLIs should then take the sample name from the header comment. -CLIs that take multiple non-BAM input files should check for consistency of the sample names as part of the argument validation step. -CLIs that output the sample name in plots should derive these from the header comment. -For files that contain data from multiple samples (e.g., the output of CombineReadCounts), we can probably leave the sample names in the column headers, but it would be nice to output the type of data stored in a header comment as well (e.g., PCOV or RAW). At some point I think we should restrict to RAW output only, see https://github.com/broadinstitute/gatk-protected/issues/615. -Entity names specified by the input file for the WDLs can be separate from the BAM sample names by default. However, if we do allow the user to optionally specify sample names as described in the first bullet point, we can set up the WDL to pass the entity names.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2910:1271,validat,validation,1271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2910,1,['validat'],['validation']
Security,"n `CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam` from `ValidateSamFile`. Here's some of the output:. ```; [March 9, 2017 7:03:42 PM EST] org.broadinstitute.hellbender.tools.picard.sam.ValidateSamFile --input src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam --use_jdk_deflater true --use_jdk_inflater true --MODE VERBOSE --MAX_OUTPUT 100 --IGNORE_WARNINGS false --VALIDATE_INDEX true --IS_BISULFITE_SEQUENCED false --MAX_OPEN_TEMP_FILES 8000 --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 1 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --verbosity INFO --QUIET false; [March 9, 2017 7:03:42 PM EST] Executing as gspowley@dna on Linux 3.10.0-514.10.2.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Version: Version:4.alpha.2-170-g8d06823-SNAPSHOT; 19:03:42.998 INFO ValidateSamFile - Defaults.BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.COMPRESSION_LEVEL : 1; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_INDEX : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CREATE_MD5 : false; 19:03:42.999 INFO ValidateSamFile - Defaults.CUSTOM_READER_FACTORY : ; 19:03:42.999 INFO ValidateSamFile - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 19:03:42.999 INFO ValidateSamFile - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 19:03:42.999 INFO ValidateSamFile - Defaults.REFERENCE_FASTA : null; 19:03:43.000 INFO ValidateSamFile - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:03:43.000 INFO ValidateSamFile - Defaults.USE_CRAM_REF_DOWNLOAD : false; 19:03:43.000 INFO ValidateSamFile - Deflater JdkDeflater; 19:03:43.000 INFO ValidateSamFile - Inflater JdkInflater; 19:03:43.000 INFO ValidateSamFile - In",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571:1019,Validat,ValidateSamFile,1019,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-285513571,1,['Validat'],['ValidateSamFile']
Security,"n stage 2: Stage finished; 23/11/16 12:09:10 INFO DAGScheduler: Job 2 finished: parquet at StudentAws.scala:36, took 10.369237 s; 23/11/16 12:09:10 INFO FileFormatWriter: Start to commit write Job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; 23/11/16 12:09:10 ERROR FileFormatWriter: Aborting job b17a4b92-9ee1-46cc-858a-08ed0b22fb8b.; java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z; 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method); 	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793); 	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249); 	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454); 	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972); 	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404); 	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377); 	at org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:48); 	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192); 	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640); 	at org.apache.spark.sql.exec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:2633,Checksum,ChecksumFileSystem,2633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['Checksum'],['ChecksumFileSystem']
Security,"naging and querying Supplementary alignment; > information from read alignment records:; >; > Some of the things that I think smell:; >; > 1.; >; > Querying: implemented in htsjdk consists in forging artificial; > SAMRecords that contain only the alignment info in the SA tag element... It; > seems to me that it makes more sense to create class to hold this; > information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder; > already has defined a private inner class with that in mind ""SARead"" so why; > not flesh it out and make it public.; > 2.; >; > Writing: currently SATagBuilder gets attached to a read, parsing its; > current SA attribute content into SARead instances. It provides the; > possibility adding additional SAM record one by one or clearing the list.; > ... then it actually updates the SA attribute on the original read when a; > method (setTag) is explicitly called.; >; > I don't see the need to attach the SATag Builder to a read... it could; > perfectly be free standing; the same builder could be re-apply to several; > reads for that matter and I don't see any gain in hiding the read SA tag; > setting process,... even if typically this builder output would go to the; > ""SA"" tag, perhaps at some point we would like to also write SA coordinate; > list somewhere else, some other tag name or perhaps an error message... why; > impose this single purpose limitation?; >; > I suggest to drop the notion of a builder for a more general custom; > ReadAlignmentInfo (or whatever name) list. Such list could be making; > reference to a dictionary to validate its elements, prevent duplicates,; > keep the primary SA in the first position... etc.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3324>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZft11VTCtCHT_xr89kPL7hMFYQyhks5sQNghgaJpZM4Ofpkb>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323:2350,validat,validate,2350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323,1,['validat'],['validate']
Security,"naryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace/gatk/src/test/resources/org/broadinstitute/hellbender/tools/walkers/Va",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2321,Validat,ValidateVariants,2321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
Security,"nch SparkGenomeReadCounts -I hdfs://scc/user/farrell/adsp/bams/SRR990385.bam -o SRR990385.ReadCounts -R /restricted/projectnb/genpro/bundle/2.8/b37/human_g1k_v37.fasta --verbosity ERROR -- --sparkRunner SPARK --sparkMaster yarn --num-executors 1 --executor-memory 4G --executor-cores 3`. [December 3, 2017 2:56:35 PM EST] org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts done. Elapsed time: 0.57 minutes.; Runtime.totalMemory()=982515712; org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 0.0 failed 4 times, most recent failure: Lost task 12.3 in stage 0.0 (TID 14, scc-q09.scc.bu.edu, executor 1): java.lang.IllegalArgumentException: **Wrong FS: hdfs://scc:8020/user/farrell/adsp/bams/SRR990385.bai, expected: hdfs://scc**; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:193); at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:105); at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302); at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298); at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766); at org.seqdoop.hadoop_bam.util.WrapSeekable.openPath(WrapSeekable.java:60); at org.seqdoop.hadoop_bam.BAMRecordReader.initialize(BAMRecordReader.java:142); at org.seqdoop.hadoop_bam.BAMInputFormat.createRecordReader(BAMInputFormat.java:121); at org.seqdoop.hadoop_bam.AnySAMInputFormat.createRecordReader(AnySAMInputFormat.java:190); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.liftedTree1$1(NewHadoopRDD.scala:178); at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:177); at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3909:1390,access,access,1390,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3909,1,['access'],['access']
Security,nches 14766 14773 +7 ; ===============================================; + Hits 114640 114660 +20 ; - Misses 12746 12748 +2 ; - Partials 5327 5334 +7; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4999?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tmutpileup/BasicSomaticShortMutationValidator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4999/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CYXNpY1NvbWF0aWNTaG9ydE11dGF0aW9uVmFsaWRhdG9yLmphdmE=) | `60.526% <0%> (-4.339%)` | `5 <3> (ø)` | |; | [...dateBasicSomaticShortMutationsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4999/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zSW50ZWdyYXRpb25UZXN0LmphdmE=) | `100% <100%> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/4999/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `83.486% <75%> (-3.419%)` | `19 <4> (+6)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/4999/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `71.292% <0%> (-0.957%)` | `35% <0%> (-1%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4999/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `73.973% <0%> (+2.74%)` | `11% <0%> (ø)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4999#issuecomment-405370854:1680,Validat,ValidateBasicSomaticShortMutations,1680,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4999#issuecomment-405370854,1,['Validat'],['ValidateBasicSomaticShortMutations']
Security,"ncy SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [March 21, 2017 5:43:53 PM EDT] Executing as louisb@WMD2A-31E on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b16; Version: Version:4.alpha.2-189-g724fbd0-SNAPSHOT; 17:43:53.162 INFO ValidateVariants - Defaults.BUFFER_SIZE : 131072; 17:43:53.162 INFO ValidateVariants - Defaults.COMPRESSION_LEVEL : 1; 17:43:53.162 INFO ValidateVariants - Defaults.CREATE_INDEX : false; 17:43:53.163 INFO ValidateVariants - Defaults.CREATE_MD5 : false; 17:43:53.163 INFO ValidateVariants - Defaults.CUSTOM_READER_FACTORY :; 17:43:53.163 INFO ValidateVariants - Defaults.EBI_REFERENCE_SERVICE_URL_MASK : http://www.ebi.ac.uk/ena/cram/md5/%s; 17:43:53.163 INFO ValidateVariants - Defaults.NON_ZERO_BUFFER_SIZE : 131072; 17:43:53.163 INFO ValidateVariants - Defaults.REFERENCE_FASTA : null; 17:43:53.163 INFO ValidateVariants - Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:43:53.163 INFO ValidateVariants - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:43:53.163 INFO ValidateVariants - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:43:53.163 INFO ValidateVariants - Deflater IntelDeflater; 17:43:53.163 INFO ValidateVariants - Inflater IntelInflater; 17:43:53.163 INFO ValidateVariants - Initializing engine; 17:43:53.270 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/louisb/Workspace",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2509:2250,Validat,ValidateVariants,2250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2509,1,['Validat'],['ValidateVariants']
