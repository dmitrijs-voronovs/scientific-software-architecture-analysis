quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Energy Efficiency,"c amount of memory; on the stack. This amount is subject to stack allocation limits. Query for this feature with ``__has_builtin(__builtin_alloca)``. ``__builtin_alloca_with_align``; -------------------------------. ``__builtin_alloca_with_align`` is used to dynamically allocate memory on the; stack while controlling its alignment. Memory is automatically freed upon; function termination. **Syntax**:. .. code-block:: c++. __builtin_alloca_with_align(size_t n, size_t align). **Example of Use**:. .. code-block:: c++. void init(float* data, size_t nbelems);; void process(float* data, size_t nbelems);; int foo(size_t n) {; auto mem = (float*)__builtin_alloca_with_align(; n * sizeof(float),; CHAR_BIT * alignof(float));; init(mem, n);; process(mem, n);; /* mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca_with_align`` is meant to be used to allocate a dynamic amount of memory; on the stack. It is similar to ``__builtin_alloca`` but accepts a second; argument whose value is the alignment constraint, as a power of 2 in *bits*. Query for this feature with ``__has_builtin(__builtin_alloca_with_align)``. .. _langext-__builtin_assume:. ``__builtin_assume``; --------------------. ``__builtin_assume`` is used to provide the optimizer with a boolean; invariant that is defined to be true. **Syntax**:. .. code-block:: c++. __builtin_assume(bool). **Example of Use**:. .. code-block:: c++. int foo(int x) {; __builtin_assume(x != 0);; // The optimizer may short-circuit this check using the invariant.; if (x == 0); return do_something();; return do_something_else();; }. **Description**:. The boolean argument to this function is defined to be true. The optimizer may; analyze the form of the expression provided as the argument and deduce from; that information used to optimize the program. If the condition is violated; during execution, the behavior is undefined. The argument itself is never; evaluated, so any side effects of the expression will be discar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:98496,power,power,98496,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['power'],['power']
Energy Efficiency,"c array type are valid. There is no problem with out of; bounds indices in this sense. Indexing into an array only depends on the size of; the array element, not the number of elements. A common example of how this is used is arrays where the size is not known.; It's common to use array types with zero length to represent these. The fact; that the static type says there are zero elements is irrelevant; it's perfectly; valid to compute arbitrary element indices, as the computation only depends on; the size of the array element, not the number of elements. Note that zero-sized; arrays are not a special case here. This sense is unconnected with ``inbounds`` keyword. The ``inbounds`` keyword is; designed to describe low-level pointer arithmetic overflow conditions, rather; than high-level array indexing rules. Analysis passes which wish to understand array indexing should not assume that; the static array type bounds are respected. The second sense of being out of bounds is computing an address that's beyond; the actual underlying allocated object. With the ``inbounds`` keyword, the result value of the GEP is ``poison`` if the; address is outside the actual underlying allocated object and not the address; one-past-the-end. Without the ``inbounds`` keyword, there are no restrictions on computing; out-of-bounds addresses. Obviously, performing a load or a store requires an; address of allocated and sufficiently aligned memory. But the GEP itself is only; concerned with computing addresses. Can array indices be negative?; ------------------------------. Yes. This is basically a special case of array indices being out of bounds. Can I compare two values computed with GEPs?; --------------------------------------------. Yes. If both addresses are within the same allocated object, or; one-past-the-end, you'll get the comparison result you expect. If either is; outside of it, integer arithmetic wrapping may occur, so the comparison may not; be meaningful. Can I do GEP with a di",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:13727,allocate,allocated,13727,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['allocate'],['allocated']
Energy Efficiency,"c performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umax.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_umin:. '``llvm.vp.reduce.umin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:768934,reduce,reduce,768934,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"c(..) {; #ifdef INSTALL_GWP_ASAN_STUBS; if (GWPASanAllocator.shouldSample(..)); return GWPASanAllocator.allocate(..);; #endif. // ... the rest of your allocator code here.; }. Then, all the supporting allocator needs to do is compile with; ``-DINSTALL_GWP_ASAN_STUBS`` and link against the GWP-ASan library! For; performance reasons, we strongly recommend static linkage of the GWP-ASan; library. Guarded Allocation Pool; -----------------------. The core of GWP-ASan is the guarded allocation pool. Each sampled allocation is; backed using its own *guarded* slot, which may consist of one or more accessible; pages. Each guarded slot is surrounded by two *guard* pages, which are mapped as; inaccessible. The collection of all guarded slots makes up the *guarded; allocation pool*. Buffer Underflow/Overflow Detection; -----------------------------------. We gain buffer-overflow and buffer-underflow detection through these guard; pages. When a memory access overruns the allocated buffer, it will touch the; inaccessible guard page, causing memory exception. This exception is caught and; handled by the internal crash handler. Because each allocation is recorded with; metadata about where (and by what thread) it was allocated and deallocated, we; can provide information that will help identify the root cause of the bug. Allocations are randomly selected to be either left- or right-aligned to provide; equal detection of both underflows and overflows. Use after Free Detection; ------------------------. The guarded allocation pool also provides use-after-free detection. Whenever a; sampled allocation is deallocated, we map its guarded slot as inaccessible. Any; memory accesses after deallocation will thus trigger the crash handler, and we; can provide useful information about the source of the error. Please note that the use-after-free detection for a sampled allocation is; transient. To keep memory overhead fixed while still detecting bugs, deallocated; slots are randomly reused to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:3714,allocate,allocated,3714,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['allocate'],['allocated']
Energy Efficiency,"c. which should produce reduced IR that reproduces the crash. Be warned the; ``llvm-reduce`` is still fairly immature and may crash. If none of the above work, you can get the IR before a crash by running the; ``opt`` command with the ``--print-before-all --print-module-scope`` flags to; dump the IR before every pass. Be warned that this is very verbose. .. _backend-crash:. Backend code generator bugs; ---------------------------. If you find a bug that crashes clang in the code generator, compile your; source file to a .bc file by passing ""``-emit-llvm -c -o foo.bc``"" to; clang (in addition to the options you already pass). Once your have; foo.bc, one of the following commands should fail:. #. ``llc foo.bc``; #. ``llc foo.bc -relocation-model=pic``; #. ``llc foo.bc -relocation-model=static``. If none of these crash, please follow the instructions for a :ref:`front-end; bug<frontend-crash>`. If one of these do crash, you should be able to reduce; this with one of the following :doc:`bugpoint <Bugpoint>` command lines (use; the one corresponding to the command above that failed):. #. ``bugpoint -run-llc foo.bc``; #. ``bugpoint -run-llc foo.bc --tool-args -relocation-model=pic``; #. ``bugpoint -run-llc foo.bc --tool-args -relocation-model=static``. Please run this, then file a bug with the instructions and reduced .bc file; that bugpoint emits. If something goes wrong with bugpoint, please submit; the ""foo.bc"" file and the option that llc crashes with. LTO bugs; ---------------------------. If you encounter a bug that leads to crashes in the LLVM LTO phase when using; the ``-flto`` option, follow these steps to diagnose and report the issue:. Compile your source file to a ``.bc`` (Bitcode) file with the following options,; in addition to your existing compilation options:. .. code-block:: bash. export CFLAGS=""-flto -fuse-ld=lld"" CXXFLAGS=""-flto -fuse-ld=lld"" LDFLAGS=""-Wl,-plugin-opt=save-temps"". These options enable LTO and save temporary files generated during compil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:5456,reduce,reduce,5456,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduce']
Energy Efficiency,"c; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmax.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmax.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmin:. '``llvm.vector.reduce.fmin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmin.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmin.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmin.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with minimum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:659507,reduce,reduce,659507,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"c_fp128 %Val). Overview:; """""""""""""""""". The '``llvm.sqrt``' intrinsics return the square root of the specified value. Arguments:; """""""""""""""""""". The argument and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``sqrt``' function but without; trapping or setting ``errno``. For types specified by IEEE-754, the result; matches a conforming libm implementation. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. '``llvm.powi.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.powi`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. Generally, the only supported type for the exponent is the one matching; with the C type ``int``. ::. declare float @llvm.powi.f32.i32(float %Val, i32 %power); declare double @llvm.powi.f64.i16(double %Val, i16 %power); declare x86_fp80 @llvm.powi.f80.i32(x86_fp80 %Val, i32 %power); declare fp128 @llvm.powi.f128.i32(fp128 %Val, i32 %power); declare ppc_fp128 @llvm.powi.ppcf128.i32(ppc_fp128 %Val, i32 %power). Overview:; """""""""""""""""". The '``llvm.powi.*``' intrinsics return the first operand raised to the; specified (positive or negative) power. The order of evaluation of; multiplications is not defined. When a vector of floating-point type is; used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The second argument is an integer power, and the first is a value to; raise to that power. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.sin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sin`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:558066,power,power,558066,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored out, the LLVM code generator uses the; :doc:`TableGen/index` tool to describe big chunks of the; target machine, which allows the use of domain-specific and target-specific; abstractio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7607,efficient,efficient,7607,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['efficient'],['efficient']
Energy Efficiency,"calar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ===",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241120,allocate,allocated,241120,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"calar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX940, GFX941, GFX942; are defined in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx940-gfx941-gfx942-table`. .. table:: AMDHSA Memory Model Code Sequences GFX940, GFX941, GFX942; :name: amdgpu-amdhsa-memory-model",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:291138,allocate,allocated,291138,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6717,ADAPT,ADAPTIVE,6717,roofit/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html,1,['ADAPT'],['ADAPTIVE']
Energy Efficiency,"calling convention; is specified) matches the target C calling conventions. This calling; convention supports varargs function calls and tolerates some; mismatch in the declared prototype and implemented declaration of; the function (as does normal C).; ""``fastcc``"" - The fast calling convention; This calling convention attempts to make calls as fast as possible; (e.g. by passing things in registers). This calling convention; allows the target to use whatever tricks it wants to produce fast; code for the target, without having to conform to an externally; specified ABI (Application Binary Interface). `Tail calls can only; be optimized when this, the tailcc, the GHC or the HiPE convention is; used. <CodeGenerator.html#tail-call-optimization>`_ This calling; convention does not support varargs and requires the prototype of all; callees to exactly match the prototype of the function definition.; ""``coldcc``"" - The cold calling convention; This calling convention attempts to make code in the caller as; efficient as possible under the assumption that the call is not; commonly executed. As such, these calls often preserve all registers; so that the call does not break any live ranges in the caller side.; This calling convention does not support varargs and requires the; prototype of all callees to exactly match the prototype of the; function definition. Furthermore the inliner doesn't consider such function; calls for inlining.; ""``ghccc``"" - GHC convention; This calling convention has been implemented specifically for use by; the `Glasgow Haskell Compiler (GHC) <http://www.haskell.org/ghc>`_.; It passes everything in registers, going to extremes to achieve this; by disabling callee save registers. This calling convention should; not be used lightly but only for specific situations such as an; alternative to the *register pinning* performance technique often; used when implementing functional programming languages. At the; moment only X86, AArch64, and RISCV support this c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:13184,efficient,efficient,13184,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency,"case of *read write* access, ``1`` is to be used. ``locality``; indicates the expected persistence of data in cache, from ``0`` which means that; data can be discarded from cache after its next use to ``3`` which means that; data is going to be reused a lot once in cache. ``1`` and ``2`` provide; intermediate behavior between these two extremes. Query for this feature with ``__has_builtin(__builtin_prefetch)``. ``__sync_swap``; ---------------. ``__sync_swap`` is used to atomically swap integers or pointers in memory. **Syntax**:. .. code-block:: c++. type __sync_swap(type *ptr, type value, ...). **Example of Use**:. .. code-block:: c++. int old_value = __sync_swap(&value, new_value);. **Description**:. The ``__sync_swap()`` builtin extends the existing ``__sync_*()`` family of; atomic intrinsics to allow code to atomically swap the current value with the; new value. More importantly, it helps developers write more efficient and; correct code by avoiding expensive loops around; ``__sync_bool_compare_and_swap()`` or relying on the platform specific; implementation details of ``__sync_lock_test_and_set()``. The; ``__sync_swap()`` builtin is a full barrier. ``__builtin_addressof``; -----------------------. ``__builtin_addressof`` performs the functionality of the built-in ``&``; operator, ignoring any ``operator&`` overload. This is useful in constant; expressions in C++11, where there is no other way to take the address of an; object that overloads ``operator&``. Clang automatically adds; ``[[clang::lifetimebound]]`` to the parameter of ``__builtin_addressof``. **Example of use**:. .. code-block:: c++. template<typename T> constexpr T *addressof(T &value) {; return __builtin_addressof(value);; }. ``__builtin_function_start``; -----------------------------. ``__builtin_function_start`` returns the address of a function body. **Syntax**:. .. code-block:: c++. void *__builtin_function_start(function). **Example of use**:. .. code-block:: c++. void a() {}; void *p = __buil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:117088,efficient,efficient,117088,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['efficient'],['efficient']
Energy Efficiency,"case, we want to be able to elide copies into ``bar``'s argument; slots. That means we need to have more than one set of argument frames; active at the same time. First, we need to allocate the frame for the; outer call so we can pass it in as the hidden struct return pointer to; the middle call. Then we do the same for the middle call, allocating a; frame and passing its address to ``Foo``'s default constructor. By; wrapping the evaluation of the inner ``bar`` with stack save and; restore, we can have multiple overlapping active call frames. Callee-cleanup Calling Conventions; ----------------------------------. Another wrinkle is the existence of callee-cleanup conventions. On; Windows, all methods and many other functions adjust the stack to clear; the memory used to pass their arguments. In some sense, this means that; the allocas are automatically cleared by the call. However, LLVM; instead models this as a write of undef to all of the inalloca values; passed to the call instead of a stack adjustment. Frontends should; still restore the stack pointer to avoid a stack leak. Exceptions; ----------. There is also the possibility of an exception. If argument evaluation; or copy construction throws an exception, the landing pad must do; cleanup, which includes adjusting the stack pointer to avoid a stack; leak. This means the cleanup of the stack memory cannot be tied to the; call itself. There needs to be a separate IR-level instruction that can; perform independent cleanup of arguments. Efficiency; ----------. Eventually, it should be possible to generate efficient code for this; construct. In particular, using inalloca should not require a base; pointer. If the backend can prove that all points in the CFG only have; one possible stack level, then it can address the stack directly from; the stack pointer. While this is not yet implemented, the plan is that; the inalloca attribute should not change much, but the frontend IR; generation recommendations may change.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst:5888,efficient,efficient,5888,interpreter/llvm-project/llvm/docs/InAlloca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst,1,['efficient'],['efficient']
Energy Efficiency,ce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338094,reduce,reduce,338094,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,ceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helper.h; llvm/tools/llvm-xray/llvm-xray.cpp; llvm/tools/llvm-xray/trie-node.h; llvm/tools/llvm-xray/xray,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338883,reduce,reduce,338883,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,ceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helper.h; llvm/tools/llvm-xray/llvm-xray.cpp; llvm/tools/llvm-xray/trie-node.h; llvm/tools/llvm-xray/xray-account.h; llvm/tools/llvm-xray/xray-color-helper.cp,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338937,reduce,reduce,338937,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,ceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helper.h; llvm/tools/llvm-xray/llvm-xray.cpp; llvm/tools/llvm-xray/trie-node.h; llvm/tools/llvm-xray/xray-account.h; llvm/tools/llvm-xray/xray-color-helper.cpp; llvm/tools/llvm-xray/xray-color-helper.h; llvm/tool,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338989,reduce,reduce,338989,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"cern.ch/doc/v628/classRooAbsPdf.html) with an option string was removed. This way of configuring the fit was deprecated since at least since ROOT 5.02.; Subsequently, the `RooMinimizer::fit(const char*)` function and the [RooMCStudy](https://root.cern.ch/doc/v628/classRooMCStudy.html) constructor that takes an option string were removed as well.; - The overload of `RooAbsData::createHistogram` that takes integer parameters for the bin numbers is now deprecated and will be removed in ROOT 6.30.; This was done to avoid confusion with inconsistent behavior when compared to other `createHistogram` overloads.; Please use the verson of `createHistogram` that takes RooFit command arguments.; - The `RooAbsData::valid()` method to cache valid entries in the variable range; was removed. It was not implemented in RooDataSet, so it never worked as; intended. Related to it was the `RooDataHist::cacheValidEntries()` function, which is removed as well.; The preferred way to reduce RooFit datasets to subranges is [RooAbsData::reduce()](https://root.cern.ch/doc/v628/classRooAbsData.html#acfa7b31e5cd751eec1bc4e95d2796390).; - The longtime-deprecated `RooStats::HistFactory::EstimateSummary` class is removed, including the functions that use it. The information that it was meant to store is managed by the `RooStats::HistFactory::Measurement` object since many years.; - The `RooSuperCategory::MakeIterator()` function that was deprecated since 6.22 is now removed. Please use range-based loops to iterate over the category states.; - The `HybridCalculatorOriginal` and `HypoTestInverterOriginal` classes in RooStats that were deprecated for a very long time aleady are removed. Please use `HybridCalculator` and `HypoTestInverter`.; - The `RooSimPdfBuilder` that was deprecated in ROOT 5.20 and replaced by the `RooSimWSTool` is removed.; - The RDataFrame factory functions `MakeNumpyDataFrame`, `MakeCsvDataFrame`, `MakeArrowDataFrame`, `MakeNTupleDataFrame` and `MakeSqliteDataFrame` are now depr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:3512,reduce,reduce,3512,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,2,['reduce'],['reduce']
Energy Efficiency,"ces are generally available. For these, all the type; indices considered together must match all the types in one of the tuples. So; ``.legalFor({{s16, s32}, {s32, s64}})`` will only accept ``{s16, s32}``, or; ``{s32, s64}`` but will not accept ``{s16, s64}``. * ``legalForTypesWithMemSize()``, ``narrowScalarForTypesWithMemSize()``, etc. are; similar to ``legalFor()``, ``narrowScalarFor()``, etc. but additionally require a; MachineMemOperand to have a given size in each tuple. * ``legalForCartesianProduct()``, ``narrowScalarForCartesianProduct()``, etc. are; satisfied if each type index matches one element in each of the independent; sets. So ``.legalForCartesianProduct({s16, s32}, {s32, s64})`` will accept; ``{s16, s32}``, ``{s16, s64}``, ``{s32, s32}``, and ``{s32, s64}``. Composite Rules; """""""""""""""""""""""""""""". There are some composite rules for common situations built out of the above facilities:. * ``widenScalarToNextPow2()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is not a power of 2 and selects a target type that is the next; largest power of 2. .. _clampscalar:. * ``minScalar()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is smaller than the given minimum and selects the minimum as the; target type. Similarly, there is also a ``maxScalar()`` for the maximum and a; ``clampScalar()`` to do both at once. * ``minScalarSameAs()`` is like ``minScalar()`` but the minimum is taken from another; type index. * ``moreElementsToNextMultiple()`` is like ``moreElementsToNextPow2()`` but is based on; multiples of X rather than powers of 2. .. _min-legalizerinfo:. Minimum Rule Set; ^^^^^^^^^^^^^^^^. GlobalISel's legalizer has a great deal of flexibility in how a given target; shapes the GMIR that the rest of the backend must handle. However, there are; a small number of requirements that all targets must meet. Before discussing the minimum requirements, we'll need some terminology:. Producer Type Set; The set of types wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:10118,power,power,10118,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,2,['power'],['power']
Energy Efficiency,"cess to the pointer. To avoid this, the compiler employs; compile-time restrictions and emits run-time checks as necessary to ensure the; new count value doesn't exceed the actual length of the buffer. Section; `Maintaining correctness of bounds annotations`_ provides more details about; this programming model. .. code-block:: c. int g;. void foo(int *__counted_by(count) p, size_t count) {; count++; // may violate the invariant of __counted_by; count--; // may violate the invariant of __counted_by if count was 0.; count = g; // may violate the invariant of __counted_by; // depending on the value of `g`.; }. The requirement to annotate all pointers with explicit bounds information could; present a significant adoption burden. To tackle this issue, the model; incorporates the concept of a ""wide pointer"" (a.k.a. fat pointer) â€“ a larger; pointer that carries bounds information alongside the pointer value. Utilizing; wide pointers can potentially reduce the adoption burden, as it contains bounds; information internally and eliminates the need for explicit bounds annotations.; However, wide pointers differ from standard C pointers in their data layout,; which may result in incompatibilities with the application binary interface; (ABI). Breaking the ABI complicates interoperability with external code that has; not adopted the same programming model. ``-fbounds-safety`` harmonizes the wide pointer and the bounds annotation; approaches to reduce the adoption burden while maintaining the ABI. In this; model, local variables of pointer type are implicitly treated as wide pointers,; allowing them to carry bounds information without requiring explicit bounds; annotations. Please note that this approach doesn't apply to function parameters; which are considered ABI-visible. As local variables are typically hidden from; the ABI, this approach has a marginal impact on it. In addition,; ``-fbounds-safety`` employs compile-time restrictions to prevent implicit wide; pointers from sil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:5341,reduce,reduce,5341,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['reduce'],['reduce']
Energy Efficiency,"ch ""assumptions"" create; constraints on the values of the program, and those constraints are; recorded in the ProgramState object (and are manipulated by the; ConstraintManager). If assuming the conditions of a branch would; cause the constraints to be unsatisfiable, the branch is considered; infeasible and that path is not taken. This is how we get; path-sensitivity. We reduce exponential blow-up by caching nodes. If; a new node with the same state and program point as an existing node; would get generated, the path ""caches out"" and we simply reuse the; existing node. Thus the ExplodedGraph is not a DAG; it can contain; cycles as paths loop back onto each other and cache out. ProgramState and ExplodedNodes are basically immutable once created. Once; one creates a ProgramState, you need to create a new one to get a new; ProgramState. This immutability is key since the ExplodedGraph represents; the behavior of the analyzed program from the entry point. To; represent these efficiently, we use functional data structures (e.g.,; ImmutableMaps) which share data between instances. Finally, individual Checkers work by also manipulating the analysis; state. The analyzer engine talks to them via a visitor interface.; For example, the PreVisitCallExpr() method is called by ExprEngine; to tell the Checker that we are about to analyze a CallExpr, and the; checker is asked to check for any preconditions that might not be; satisfied. The checker can do nothing, or it can generate a new; ProgramState and ExplodedNode which contains updated checker state. If it; finds a bug, it can tell the BugReporter object about the bug,; providing it an ExplodedNode which is the last node in the path that; triggered the problem. = Notes about C++ =. Since now constructors are seen before the variable that is constructed; in the CFG, we create a temporary object as the destination region that; is constructed into. See ExprEngine::VisitCXXConstructExpr(). In ExprEngine::processCallExit(), we alway",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt:3016,efficient,efficiently,3016,interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,1,['efficient'],['efficiently']
Energy Efficiency,"ch enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umax.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_umin:. '``llvm.vp.reduce.umin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umin``' intrinsic performs the unsigned-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:769079,reduce,reduce,769079,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ch must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fadd``' intrinsic performs the floating-point ``ADD``; reduction (:ref:`llvm.vector.reduce.fadd <int_vector_reduce_fadd>`) of the; vector operand ``val`` on each enabled lane, adding it to the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``-0.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fadd.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float -0.0, float -0.0, float -0.0, float -0.0>; %also.r = call float @llvm.vector.reduce.fadd.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_mul:. '``llvm.vp.reduce.mul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicate",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:751872,reduce,reduce,751872,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"che; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is; Â Â Â Â Â Â Â Â Â ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option. Â The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeate",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:6043,adapt,adapting,6043,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,2,['adapt'],['adapting']
Energy Efficiency,"chitecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored out, the LLVM code generator uses the; :doc:`TableGen/index` tool to describe big chunks of the; target machine, which allows the use of domain-specific and target-specific; abstractions to reduce the amount of repetition. As LLVM continues to be developed and refined, we plan to move more and more of; the target description to the ``.td`` form. Doing so gives us a number of; advantages. The most important is that it makes it easier to port LLVM because; it reduces the amount of C++ code that has to be written, and the surface area; of the code generator that needs to be understood before someone can get; something working. Second, it makes it easier to change things. In particular,; if tables and other things are all emitted by ``tblgen``, we only need a change; in one place (``tblgen``) to update all of the targets to a new interface. .. _Abstract target description:; .. _target description:. Target description classes; ==========================. The LLVM target description classes (located in the ``include/llvm/Target``; directory) provide an abstract description of the target machine independent of; any particular client. These classes are designed to capture the *abstract*; properties of the target (such as the instructions and registers it has), and do; not incorporate any particular pieces of code generation algorithms. All of the target description classes (except the :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>` class) are designed to be subclassed by the concrete target; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:8984,reduce,reduces,8984,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['reduce'],['reduces']
Energy Efficiency,"ck:: text. DBG_VALUE_LIST !123, !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_plus), %1, %2. And has the following operands:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable location; operands are inserted into the final DWARF Expression in positions indicated; by the DW_OP_LLVM_arg operator in the `DIExpression; <LangRef.html#diexpression>`_. The position at which the DBG_VALUEs are inserted should correspond to the; positions of their matching ``llvm.dbg.value`` intrinsics in the IR block. As; with optimization, LLVM aims to preserve the order in which variable; assignments occurred in the source program. However SelectionDAG performs some; instruction scheduling, which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void @llvm.dbg.value(metadata i32 %bar.0, metadata !3, metadata !DIExpression()), !dbg !5; %addr1 = getelementptr i32, i32 *%addr, i32 1, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr1, metadata !3, metadata !DIExpression()), !dbg !5; %loaded1 = load i32, i32* %addr1, !dbg !5; %addr2 = getelementptr i32, i32 *%addr, i32 %bar.0, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr2, metadata !3, metadata !DIExpression(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:29061,schedul,scheduling,29061,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['schedul'],['scheduling']
Energy Efficiency,"ckground,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False âˆ’ Print method-specific help message. CreateMVAPdfs No False âˆ’ Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False âˆ’ Events with negative weights are ignored in the training (but are included for testing and performance evaluation). VolumeRangeMode No Adaptive Unscaled, MinMax, RMS, Adaptive, kNN Method to determine volume size. KernelEstimator No Box Box, Sphere, Teepee, Gauss, Sinc3, Sinc5, Sinc7, Sinc9, Sinc11, Lanczos2, Lanczos3, Lanczos5, Lanczos8, Trim Kernel estimation function. DeltaFrac No 3 âˆ’ nEventsMin/Max for minmax and rms volume range. NEventsMin No 100 âˆ’ nEventsMin for adaptive volume range. NEventsMax No 200 âˆ’ nEventsMax for adaptive volume range. MaxVIterations No 150 âˆ’ MaxVIterations for adaptive volume range. InitialScale No 0.99 âˆ’ InitialScale for adaptive volume range. GaussSigma No 0.1 âˆ’ Width (wrt volume size) of Gaussian kernel estimator. NormTree No False âˆ’ Normalize binary search tree. Configuration options for MVA method :. Configuration options reference for MVA method: FDA. Option Array Default value Predefined values Description. V No False âˆ’ Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None âˆ’ List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False âˆ’ Print method-specific help message. CreateMVAPdfs No False âˆ’ Create PDFs for classifier outp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:4849,adapt,adaptive,4849,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['adapt'],['adaptive']
Energy Efficiency,"cks) ... somefunc(42);; assert(3 != 4 && ""laws of math are failing me"");. A = foo(42, 92) + bar(X);. The reason for doing this is not completely arbitrary. This style makes control; flow operators stand out more, and makes expressions flow better. Prefer Preincrement; ^^^^^^^^^^^^^^^^^^^. Hard fast rule: Preincrement (``++X``) may be no slower than postincrement; (``X++``) and could very well be a lot faster than it. Use preincrementation; whenever possible. The semantics of postincrement include making a copy of the value being; incremented, returning it, and then preincrementing the ""work value"". For; primitive types, this isn't a big deal. But for iterators, it can be a huge; issue (for example, some iterators contains stack and set objects in them...; copying an iterator could invoke the copy ctor's of these as well). In general,; get in the habit of always using preincrement, and you won't have a problem. Namespace Indentation; ^^^^^^^^^^^^^^^^^^^^^. In general, we strive to reduce indentation wherever possible. This is useful; because we want code to `fit into 80 columns`_ without excessive wrapping, but; also because it makes it easier to understand the code. To facilitate this and; avoid some insanely deep nesting on occasion, don't indent namespaces. If it; helps readability, feel free to add a comment indicating what namespace is; being closed by a ``}``. For example:. .. code-block:: c++. namespace llvm {; namespace knowledge {. /// This class represents things that Smith can have an intimate; /// understanding of and contains the data associated with it.; class Grokable {; ...; public:; explicit Grokable() { ... }; virtual ~Grokable() = 0;. ... };. } // namespace knowledge; } // namespace llvm. Feel free to skip the closing comment when the namespace being closed is; obvious for any reason. For example, the outer-most namespace in a header file; is rarely a source of confusion. But namespaces both anonymous and named in; source files that are being closed",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:58507,reduce,reduce,58507,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['reduce'],['reduce']
Energy Efficiency,"clang were updated to r227800. This includes everything from the clang 3.6 release. ### Dictionary Generation. Detect usage of #pragma once for inlined headers. Turn on verbosity of genreflex if the VERBOSE environment variable is defined. Optimise forward declarations in rootmap files in order to make their interpretation faster. Propagate attributes specified in xml selection files to selected classes even when selected through typedefs. Optimise selection procedure caching selected declarations in the selection rules, therewith avoiding to query the AST twice. Include in the PCH all the STL and C headers to guarantee portability of binaries from SLC6 to CC7. ## I/O Libraries. ### I/O New functionalities. - Support for forward_list and I/O of unordered stl containers.; - Support for std::complex. ### I/O Behavior change. - The I/O now properly skip the content of base class onfile that have been removed from the in-memory class layout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:8729,schedul,scheduling,8729,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['schedul'],['scheduling']
Energy Efficiency,"class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ~~~. The following properties of radionuclides can be currently accessed via; getters in the TGeoElementRN class:. Atomic number and charge (from the base class TGeoElement). - Isomeric number (`ISO`); - ENDF code - following the convention: `ENDF=10000*Z+100*A+ISO`; - Isomeric energy level [`MeV`]; - Mass excess [`MeV`]; - Half life [`s`]; - Spin/Parity - can be retrieved with: `TGeoElementRN::GetTitle()`; - Hynalation and ingestion toxicities; - List of decays - `TGeoElementRN::GetDecays()`. The radioactive decays of a radionuclide are represented by the class; TGeoDecayChannel and they are stored in a TObjArray. Decay; provides:. - Decay mode; - Variation of isomeric number; - `Q` value for the decay [`GeV`]; - Parent element; - Daughter element. Radionuclides are linked one to each other via their decays, until the; last element in the decay chain which must be stable. One can iterate; decay chains using the iterator TGeoElemIter:. ~~~{.cpp}; root[] TGeoElemIter next(c14);; root[] TGeoElementRN *elem;; root[] while ((elem=next())) next.Print();; 6-C-014 (100% BetaMinus) T1/2=1.81e+11; 7-N-014 stable; ~~~. To create a radioactive material based on a radionuclide, one should; use the constructor:. ~~~{.cpp}; TGeoMaterial(const char *name, TGeoElement *elem, Double_t density); ~~~. To create a radioactive mixture,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:6113,energy,energy,6113,geom/geom/doc/materials.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md,1,['energy'],['energy']
Energy Efficiency,"cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class loader (see below). .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:1209,reduce,reduce,1209,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,1,['reduce'],['reduce']
Energy Efficiency,"cling/${lib_path}/*.h; ${CLING_SOURCE_DIR}/include/cling/${lib_path}/*.def; ); set_source_files_properties(${headers} PROPERTIES HEADER_FILE_ONLY ON). file( GLOB_RECURSE tds; ${CLING_SOURCE_DIR}/include/cling/${lib_path}/*.td; ); source_group(""TableGen descriptions"" FILES ${tds}); set_source_files_properties(${tds}} PROPERTIES HEADER_FILE_ONLY ON). if(headers OR tds); set(srcs ${headers} ${tds}); endif(); endif(); endif(MSVC_IDE OR XCODE); if(srcs OR ARG_ADDITIONAL_HEADERS); set(srcs; ADDITIONAL_HEADERS; ${srcs}; ${ARG_ADDITIONAL_HEADERS} # It may contain unparsed unknown args.; ); endif(); if(ARG_SHARED); set(ARG_ENABLE_SHARED SHARED); endif(). if (MSVC); # On Windows exceptions arenâ€™t as generic as an x64 ABI.; # Stack unwinding code must be generated for every function between the; # throw and catch blocks.; if (${name} STREQUAL ""clingInterpreter""); # All of libClingInterpreter is compiled with exceptions, mostly because; # llvm_unreachable throws an exception. Otherwise it could be reduced:; # Exception.cpp, Interpreter.cpp, IncrementalParser.cpp,; # IncrementalExecutor.cpp; set(cling_ex_file_match "".cpp$""); elseif(${name} STREQUAL ""clingUserInterface""); # For libClingUserInterface, only UserInterface.cpp uses exceptions.; set(cling_ex_file_match ""^UserInterface.cpp$""); endif(); if(cling_ex_file_match); # needs to be on before llvm_add_library so flags can be set below; set(LLVM_REQUIRES_EH ON); set(LLVM_REQUIRES_RTTI ON); endif(); endif(). # Set DISABLE_LLVM_LINK_LLVM_DYLIB to disable linking against shared LLVM; llvm_add_library(${name} ${ARG_ENABLE_SHARED} DISABLE_LLVM_LINK_LLVM_DYLIB ${ARG_UNPARSED_ARGUMENTS} ${srcs}). if (MSVC AND cling_ex_file_match); # /EHs because cling_runtime_internal_throwIfInvalidPointer is extern â€œCâ€; if (cling_ex_file_match); foreach(file_var ${ARGN}); if (file_var MATCHES ${cling_ex_file_match}); set_property(SOURCE ${file_var} APPEND_STRING PROPERTY COMPILE_FLAGS; "" /D _HAS_EXCEPTIONS=1 /EHs /GR /wd4714 ""); elseif (file_var MATCHE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt:12924,reduce,reduced,12924,interpreter/cling/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/CMakeLists.txt,1,['reduce'],['reduced']
Energy Efficiency,clude/mlir/Target/LLVMIR/TypeToLLVM.h; mlir/include/mlir/Target/LLVMIR/Dialect/All.h; mlir/include/mlir/Target/LLVMIR/Dialect/AMX/AMXToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/ArmNeon/ArmNeonToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/ArmSVE/ArmSVEToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/LLVMIR/LLVMToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/NVVM/NVVMToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/OpenACC/OpenACCToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/ROCDL/ROCDLToLLVMIRTranslation.h; mlir/include/mlir/Target/LLVMIR/Dialect/X86Vector/X86VectorToLLVMIRTranslation.h; mlir/include/mlir/Target/SPIRV/Deserialization.h; mlir/include/mlir/Target/SPIRV/Serialization.h; mlir/include/mlir/Target/SPIRV/SPIRVBinaryUtils.h; mlir/include/mlir/Tools/mlir-lsp-server/MlirLspServerMain.h; mlir/include/mlir/Tools/mlir-reduce/MlirReduceMain.h; mlir/include/mlir/Tools/PDLL/AST/Context.h; mlir/include/mlir/Tools/PDLL/AST/Diagnostic.h; mlir/include/mlir/Tools/PDLL/CodeGen/CPPGen.h; mlir/include/mlir/Tools/PDLL/CodeGen/MLIRGen.h; mlir/include/mlir/Tools/PDLL/ODS/Constraint.h; mlir/include/mlir/Tools/PDLL/ODS/Context.h; mlir/include/mlir/Tools/PDLL/ODS/Dialect.h; mlir/include/mlir/Tools/PDLL/ODS/Operation.h; mlir/include/mlir/Tools/PDLL/Parser/Parser.h; mlir/include/mlir/Transforms/ControlFlowSinkUtils.h; mlir/include/mlir/Transforms/DialectConversion.h; mlir/include/mlir/Transforms/GreedyPatternRewriteDriver.h; mlir/include/mlir/Transforms/InliningUtils.h; mlir/include/mlir/Transforms/LocationSnapshot.h; mlir/include/mlir/Transforms/Passes.h; mlir/include/mlir/Transforms/RegionUtils.h; mlir/include/mlir-c/AffineExpr.h; mlir/include/mlir-c/AffineMap.h; mlir/include/mlir-c/BuiltinAttributes.h; mlir/include/mlir-c/BuiltinTypes.h; mlir/include/mlir-c/Conversion.h; mlir/include/mlir-c/Debug.h; mlir/inclu,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:374735,reduce,reduce,374735,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"column names in the RDataFrame object is now also; usable from a node of a distributed computation graph. This makes the generation of said computation graph slightly; less lazy than before. Notably, it used to be the case that a distributed computation graph could be defined with; code that was not yet available on the user's local application, but that would only become available in the; distributed worker. Now a call such as `df.Define(""mycol"", ""return run_my_fun();"")` needs to be at least declarable; to the interpreter also locally so that the column can be properly tracked. ## Histogram Libraries. ### Upgrade TUnfold to version 17.9. The [TUnfold package](https://www.desy.de/~sschmitt/tunfold.html) inside ROOT is upgraded from version 17.6 to version 17.9. ## Math Libraries. ### Usage of `std::span<const double>` in Minuit 2 interfaces. To avoid forcing the user to do manual memory allocations via `std::vector`, the interfaces of Minuit 2 function adapter classes like `ROOT::Minuit2::FCNBase` or `ROOT::Minuit2::FCNGradientBase` were changed to accept `std::span<const double>` arguments instead of `std::vector<double> const&`.; This should have minimal impact on users, since one should usual use Minuit 2 via the `ROOT::Math::Minimizer` interface, which is unchanged. ## RooFit Libraries. ### Miscellaneous. * Setting `useHashMapForFind(true)` is not supported for RooArgLists anymore, since hash-assisted finding by name hash can be ambiguous: a RooArgList is allowed to have different elements with the same name. If you want to do fast lookups by name, convert your RooArgList to a RooArgSet. * The function `RooFit::bindFunction()` now supports arbitrary many input variables when binding a Python function. * The `ExportOnly()` attribute of the `RooStats::HistFactory::Measurement` object is now switched on by default, and the associated getter and setter functions are deprecated. They will be removed in ROOT 6.36. If you want to fit the model as well instead of just ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md:4374,adapt,adapter,4374,README/ReleaseNotes/v634/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md,1,['adapt'],['adapter']
Energy Efficiency,"column. For example, leaf `""l""` under branch `""b""` might now be mentioned as `""l""` as well as `""b.l""`, while only one of the two spellings might have been recognized before.; - Certain RDF-related types in the `ROOT::Detail` and `ROOT::Internal` namespaces have been renamed, most notably `RCustomColumn` is now `RDefine`. This does not impact code that only makes use of entities in the public ROOT namespace, and should not impact downstream code unless it was patching or reusing internal `RDataFrame` types. ### Notable bug fixes and improvements. - A critical issue has been fixed that could potentially result in wrong data being silently read in multi-thread runs when an input `TChain` contained more than one `TTree` coming from the _same_ input file. More details are available at [#7143](https://github.com/root-project/root/issues/7143).; - The start-up time of event loops with large computation graphs with many just-in-time-compiled expressions (e.g. thousands of string `Filter`s and `Define`s) has been greatly reduced. See [the corresponding pull request](https://github.com/root-project/root/pull/7651) for more details. The full list of bug fixes for this release is available below. ### Distributed computing with RDataFrame; ROOT 6.24 introduces `ROOT.RDF.Experimental.Distributed`, an experimental python package that enhances RDataFrame with distributed computing capabilities. The new package allows distributing RDataFrame applications through one of the supported distributed backends. The package was designed so that different backends can be easily plugged in. Currently the [Apache Spark](http://spark.apache.org/) backend is supported and support for [Dask](https://dask.org/) is coming soon. The backend submodules of this package expose their own `RDataFrame` objects. The only needed change in user code is to substitute `ROOT.RDataFrame` calls with such backend-specific `RDataFrame`s. For example:. ```python; import ROOT. # Point RDataFrame calls to the Spark spe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:9848,reduce,reduced,9848,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['reduce'],['reduced']
Energy Efficiency,"constructor and; destructors will be run for every element in the array (re-sizable vectors only; construct those elements actually used). .. _dss_tinyptrvector:. llvm/ADT/TinyPtrVector.h; ^^^^^^^^^^^^^^^^^^^^^^^^. ``TinyPtrVector<Type>`` is a highly specialized collection class that is; optimized to avoid allocation in the case when a vector has zero or one; elements. It has two major restrictions: 1) it can only hold values of pointer; type, and 2) it cannot hold a null pointer. Since this container is highly specialized, it is rarely used. .. _dss_smallvector:. llvm/ADT/SmallVector.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallVector<Type, N>`` is a simple class that looks and smells just like; ``vector<Type>``: it supports efficient iteration, lays out elements in memory; order (so you can do pointer arithmetic between elements), supports efficient; push_back/pop_back operations, supports efficient random access to its elements,; etc. The main advantage of SmallVector is that it allocates space for some number of; elements (N) **in the object itself**. Because of this, if the SmallVector is; dynamically smaller than N, no malloc is performed. This can be a big win in; cases where the malloc/free call is far more expensive than the code that; fiddles around with the elements. This is good for vectors that are ""usually small"" (e.g. the number of; predecessors/successors of a block is usually less than 8). On the other hand,; this makes the size of the SmallVector itself large, so you don't want to; allocate lots of them (doing so will waste a lot of space). As such,; SmallVectors are most useful when on the stack. In the absence of a well-motivated choice for the number of; inlined elements ``N``, it is recommended to use ``SmallVector<T>`` (that is,; omitting the ``N``). This will choose a default number of; inlined elements reasonable for allocation on the stack (for example, trying; to keep ``sizeof(SmallVector<T>)`` around 64 bytes). SmallVector also provides a nice porta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:59787,allocate,allocates,59787,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocates']
Energy Efficiency,"contain the; address of each function, along with the relative offset of each basic block. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various dynamic entries, decoded global descriptor sections, and decoded; Android-specific ELF notes. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. .. option:: --program-headers, --segments, -l. Display the program headers. .. option:: --raw-relr. Do not decode relocations in RELR relocation sections when displaying them. .. option:: --section-mapping. Display the section to segment mapping. .. option:: --stack-sizes. Display the contents ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:5750,consumption,consumption,5750,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,1,['consumption'],['consumption']
Energy Efficiency,"containing the; neutral value ``INT_MAX`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smin.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. '``llvm.vp.reduce.umax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umax``' intrinsic performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:767125,reduce,reduce,767125,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"contributions. This policy covers all llvm.org subprojects, including Clang,; LLDB, libc++, etc. This policy is also designed to accomplish the following objectives:. #. Attract both users and developers to the LLVM project. #. Make life as simple and easy for contributors as possible. #. Keep the top of tree as stable as possible. #. Establish awareness of the project's :ref:`copyright, license, and patent; policies <copyright-license-patents>` with contributors to the project. This policy is aimed at frequent contributors to LLVM. People interested in; contributing one-off patches can do so in an informal way by sending them to the; `llvm-commits mailing list; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ and engaging another; developer to see it through the process. Developer Policies; ==================. This section contains policies that pertain to frequent LLVM developers. We; always welcome `one-off patches`_ from people who do not routinely contribute to; LLVM, but we expect more from frequent contributors to keep the system as; efficient as possible for everyone. Frequent LLVM contributors are expected to; meet the following requirements in order for LLVM to maintain a high standard of; quality. Stay Informed; -------------. Developers should stay informed by reading the `LLVM Discourse forums`_ and subscribing; to the categories of interest for notifications. Paying attention to changes being made by others is a good way to see what other people; are interested in and watching the flow of the project as a whole. Contibutions to the project are made through :ref:`GitHub Pull Requests <github-reviews>`.; You can subscribe to notification for areas of the codebase by joining; one of the `pr-subscribers-* <https://github.com/orgs/llvm/teams?query=pr-subscribers>`_; GitHub teams. This `mapping <https://github.com/llvm/llvm-project/blob/main/.github/new-prs-labeler.yml>`_; indicates which team is associated with a particular paths in the repository. Yo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:1584,efficient,efficient,1584,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['efficient'],['efficient']
Energy Efficiency,"controlled with an option. Arguments:; """""""""""""""""""". The integer argument is the loop decrement value used to decrement the loop; iteration counter. Semantics:; """""""""""""""""""". The '``llvm.loop.decrement.*``' intrinsics do a ``SUB`` of the loop iteration; counter with the given loop decrement value, and return false if the loop; should exit, this ``SUB`` is not allowed to wrap. The result is a condition; that is used by the conditional branch controlling the loop. Vector Reduction Intrinsics; ---------------------------. Horizontal reductions of vectors can be expressed using the following; intrinsics. Each one takes a vector operand as an input and applies its; respective operation across all elements of the vector, returning a single; scalar result of the same element type. .. _int_vector_reduce_add:. '``llvm.vector.reduce.add.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.add.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.add.*``' intrinsics do an integer ``ADD``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fadd:. '``llvm.vector.reduce.fadd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fadd.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fadd.*``' intrinsics do a floating-point; ``ADD`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. O",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:650573,reduce,reduce,650573,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"corresponds; to the level 0 in the stored array, while the last node will correspond; to level `n`. For each level, the node, volume and global matrix can be; retrieved using corresponding getters:. ``` {.cpp}; TGeoHMatrix *GetMatrix(Int_t level=-1) const; TGeoNode *GetNode(Int_t level=-1) const; TGeoShape *GetShape(Int_t level=-1) const; TGeoVolume *GetVolume(Int_t level=-1) const; ```. By default the object at level n is retrieved (the align-able object). Once created, a physical node can be misaligned, meaning that its; positioning matrix or even the shape.:. ``` {.cpp}; void Align(TGeoMatrix* newmat=0, TGeoShape* newshape=0,; Bool_t check=kFALSE); ```. The convention used is that newmat represents the new local matrix of; the last node in the branch with respect to its mother volume. The; `Align()` method will actually duplicate the corresponding branch within; the logical hierarchy, creating new volumes and nodes. This is mandatory; in order to avoid problems due to replicated volumes and can create; exhaustive memory consumption if used abusively. Once aligned, a physical node is ready to be tracked. The operation can; be done only after the geometry was closed. Important NOTE: Calling the `Align()` method for a physical node changes; the node pointers for the stored node branch in the active geometry, Due; to this the other defined physical nodes containing elements of this; path will be invalid. Example:. ``` {.cpp}; TGeoPhysicalNode *pn1 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_2"");; TGeoPhysicalNode *pn2 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_3"");; ...; pn1->Align(...);; ```. The call to `pn1->Align()` will invalidate the pointer to the node `B_1`; in `pn2` object.. The way out is to either call `pn1->Align()` before; the creation of `pn2`, either to use a global method that will correct; all existing physical nodes:. ``` {.cpp}; void RefreshPhysicalNodes(Bool_t lock = kTRUE); ```. The method above will optionally lock the possibility of doing any",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:149066,consumption,consumption,149066,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['consumption'],['consumption']
Energy Efficiency,"counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycle",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31544,schedul,schedulers,31544,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['schedulers']
Energy Efficiency,"cpp}; enum EObjBits {; kCanDelete = BIT(0), // if can be deleted; kMustCleanup = BIT(3), // if destructor must call RecursiveRemove(); kObjInCanvas = BIT(3), // for backward compatibility only; kIsReferenced = BIT(4), // if referenced by TRef or TRefArray; kHasUUID = BIT(5), // if has a TUUID, fUniqueID=UUIDNumber; kCannotPick = BIT(6), // if cannot be picked in a pad; kNoContextMenu = BIT(8), // if does not want a context menu; kInvalidObject = BIT(13) // object ctor succeeded but the object should not be used; };; ```. For example, the bits `kMustCleanup` and `kCanDelete` are used in; **`TObject`**. See ""The kCanDelete Bit"" and ""The kMustCleanup Bit"". They; can be set by any object and should not be reused. Make sure not; to overlap them in any given hierarchy. The bit 13 (`kInvalidObject`) is; set when an object could not be read from a ROOT file. It will check; this bit and will skip to the next object on the file. The **`TObject`** constructor initializes the `fBits` to zero depending; if the object is created on the stack or allocated on the heap. When the; object is created on the stack, the `kCanDelete` bit is set to false to; protect from deleting objects on the stack. The high 8 bits are reserved; for the system usage; the low 24 bits are user settable. `fUniqueID` is; a data member used to give a unique identification number to an object.; It is initialized to zero by the **`TObject`** constructor. ROOT does; not use this data member. The two data members (`fBits` and `fUniqueID`); are streamed out when writing an object to disk. If you do not use them,; you can save some space and time by specifying:. ``` {.cpp}; MyClass::Class()->IgnoreTObjectStreamer();; ```. This sets a bit in the **`TClass`** object. If the file is compressed,; the savings are minimal since most values are zero; however, it saves; some space when the file is not compressed. A call; to` IgnoreTObjectStreamer` also prevents the creation of two additional; branches when splitting the obj",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md:6702,allocate,allocated,6702,documentation/users-guide/AddingaClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md,1,['allocate'],['allocated']
Energy Efficiency,cross-dso; Disable control flow integrity (CFI) checks for cross-DSO calls.; -fno-sanitize-coverage=<value>; Disable specified features of coverage instrumentation for Sanitizers; -fno-sanitize-memory-track-origins; Disable origins tracking in MemorySanitizer; -fno-sanitize-memory-use-after-dtor; Disable use-after-destroy detection in MemorySanitizer; -fno-sanitize-recover=<value>; Disable recovery for specified sanitizers; -fno-sanitize-stats Disable sanitizer statistics gathering.; -fno-sanitize-thread-atomics; Disable atomic operations instrumentation in ThreadSanitizer; -fno-sanitize-thread-func-entry-exit; Disable function entry/exit instrumentation in ThreadSanitizer; -fno-sanitize-thread-memory-access; Disable memory access instrumentation in ThreadSanitizer; -fno-sanitize-trap=<value>; Disable trapping for specified sanitizers; -fno-standalone-debug Limit debug information produced to reduce size of debug binary; -fno-strict-aliasing Disable optimizations based on strict aliasing rules (default); -fobjc-runtime=<value> Specify the target Objective-C runtime kind and version; -fprofile-exclude-files=<value>; Instrument only functions from files where names don't match all the regexes separated by a semi-colon; -fprofile-filter-files=<value>; Instrument only functions from files where names match any regex separated by a semi-colon; -fprofile-generate=<dirname>; Generate instrumented code to collect execution counts into a raw profile file in the directory specified by the argument. The filename uses default_%m.profraw pattern; (overridden by LLVM_PROFILE_FILE env var); -fprofile-generate; Generate instrumented code to collect execution counts into default_%m.profraw file; (overridden by '=' form of option or LLVM_PROFILE_FILE env var); -fprofile-instr-generate=<file_name_pattern>; Generate instrumented code to collect execution counts into the file whose name pattern is specified as the argument; (overridden by LLVM_PROFILE_FILE env var); -fprofile-instr-gene,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:181243,reduce,reduce,181243,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduce']
Energy Efficiency,"ction(no-op-function),no-op-module' /tmp/a.ll -S. A more complete example, and ``-debug-pass-manager`` to show the execution; order:. .. code-block:: shell. $ opt -passes='no-op-module,cgscc(no-op-cgscc,function(no-op-function,loop(no-op-loop))),function(no-op-function,loop(no-op-loop))' /tmp/a.ll -S -debug-pass-manager. Improper nesting can lead to error messages such as. .. code-block:: shell. $ opt -passes='no-op-function,no-op-module' /tmp/a.ll -S; opt: unknown function pass 'no-op-module'. The nesting is: module (-> cgscc) -> function -> loop, where the CGSCC nesting is optional. There are a couple of special cases for easier typing:. * If the first pass is not a module pass, a pass manager of the first pass is; implicitly created. * For example, the following are equivalent. .. code-block:: shell. $ opt -passes='no-op-function,no-op-function' /tmp/a.ll -S; $ opt -passes='function(no-op-function,no-op-function)' /tmp/a.ll -S. * If there is an adaptor for a pass that lets it fit in the previous pass; manager, that is implicitly created. * For example, the following are equivalent. .. code-block:: shell. $ opt -passes='no-op-function,no-op-loop' /tmp/a.ll -S; $ opt -passes='no-op-function,loop(no-op-loop)' /tmp/a.ll -S. For a list of available passes and analyses, including the IR unit (module,; CGSCC, function, loop) they operate on, run. .. code-block:: shell. $ opt --print-passes. or take a look at ``PassRegistry.def``. To make sure an analysis named ``foo`` is available before a pass, add; ``require<foo>`` to the pass pipeline. This adds a pass that simply requests; that the analysis is run. This pass is also subject to proper nesting. For; example, to make sure some function analysis is already computed for all; functions before a module pass:. .. code-block:: shell. $ opt -passes='function(require<my-function-analysis>),my-module-pass' /tmp/a.ll -S. Status of the New and Legacy Pass Managers; ==========================================. LLVM currently contai",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:19654,adapt,adaptor,19654,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['adapt'],['adaptor']
Energy Efficiency,ctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llv,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338625,reduce,reduce,338625,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"ctionDAG based; instruction selector. Portions of the DAG instruction selector are generated from the target; description (``*.td``) files. Our goal is for the entire instruction selector; to be generated from these ``.td`` files, though currently there are still; things that require custom C++ code. `GlobalISel <https://llvm.org/docs/GlobalISel/index.html>`_ is another; instruction selection framework. .. _SelectionDAG:. Introduction to SelectionDAGs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG provides an abstraction for code representation in a way that; is amenable to instruction selection using automatic techniques; (e.g. dynamic-programming based optimal pattern matching selectors). It is also; well-suited to other phases of code generation; in particular, instruction; scheduling (SelectionDAG's are very close to scheduling DAGs post-selection).; Additionally, the SelectionDAG provides a host representation where a large; variety of very-low-level (but target-independent) `optimizations`_ may be; performed; ones which require extensive information about the instructions; efficiently supported by the target. The SelectionDAG is a Directed-Acyclic-Graph whose nodes are instances of the; ``SDNode`` class. The primary payload of the ``SDNode`` is its operation code; (Opcode) that indicates what operation the node performs and the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operands, which are edges to; the node defining the used value. Because nodes may define multiple values,; edges are represented by instances of the ``SDValue`` class, which is a; ``<SDNode, unsigned>`` pair, indicating the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:34152,efficient,efficiently,34152,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['efficient'],['efficiently']
Energy Efficiency,"ctions are provided to check origin tracking status and results. .. code-block:: c. /// Retrieves the immediate origin associated with the given data. The returned; /// origin may point to another origin.; ///; /// The type of 'data' is arbitrary. The function accepts a value of any type,; /// which can be truncated or extended (implicitly or explicitly) as necessary.; /// The truncation/extension operations will preserve the label of the original; /// value.; dfsan_origin dfsan_get_origin(long data);. /// Retrieves the very first origin associated with the data at the given; /// address.; dfsan_origin dfsan_get_init_origin(const void *addr);. /// Prints the origin trace of the label at the address `addr` to stderr. It also; /// prints description at the beginning of the trace. If origin tracking is not; /// on, or the address is not labeled, it prints nothing.; void dfsan_print_origin_trace(const void *addr, const char *description);. /// Prints the origin trace of the label at the address `addr` to a pre-allocated; /// output buffer. If origin tracking is not on, or the address is`; /// not labeled, it prints nothing.; ///; /// `addr` is the tainted memory address whose origin we are printing.; /// `description` is a description printed at the beginning of the trace.; /// `out_buf` is the output buffer to write the results to. `out_buf_size` is; /// the size of `out_buf`. The function returns the number of symbols that; /// should have been written to `out_buf` (not including trailing null byte '\0').; /// Thus, the string is truncated iff return value is not less than `out_buf_size`.; size_t dfsan_sprint_origin_trace(const void *addr, const char *description,; char *out_buf, size_t out_buf_size);. /// Returns the value of `-dfsan-track-origins`.; int dfsan_get_track_origins(void);. The following functions are provided to register hooks called by custom wrappers. .. code-block:: c. /// Sets a callback to be invoked on calls to `write`. The callback is invoked; ///",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst:3841,allocate,allocated,3841,interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,1,['allocate'],['allocated']
Energy Efficiency,"ctor of floating-point values. To ignore the start value, negative zero (``-0.0``) can be used, as it is; the neutral value of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fmul operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fmul(start_value, input_vector); result = start_value;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:653250,reduce,reduce,653250,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ctor operand ``val`` on each enabled lane, adding it to the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``-0.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fadd.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float -0.0, float -0.0, float -0.0, float -0.0>; %also.r = call float @llvm.vector.reduce.fadd.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_mul:. '``llvm.vp.reduce.mul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``MUL`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:752477,reduce,reduce,752477,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ctor.reduce.fmax.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmin:. '``llvm.vector.reduce.fmin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmin.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmin.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmin.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with minimum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmaximum:. '``llvm.vector.reduce.fmaximum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:659660,reduce,reduce,659660,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"cts, which only potentially could be displayed in the browser. In case of 10 objects it does not matter, but for 1000 or 100000 objects this will be a major performance penalty. With such big amount of data one will never achieve higher update rate. The second problem is I/O. To read the first object from the ROOT file, one need to perform several (about 5) file-reading operations via http protocol.; There is no http file locking mechanism (at least not for standard web servers),; therefore there is no guarantee that the file content is not changed/replaced between consequent read operations. Therefore, one should expect frequent I/O failures while trying to monitor data from ROOT binary files. There is a workaround for the problem - one could load the file completely and exclude many partial I/O operations by this. To achieve this with JSROOT, one should add ""+"" sign at the end of the file name. Of course, it only could work for small files. If somebody still wants to use monitoring of data from ROOT files, could try link like:. - <https://root.cern/js/latest/?nobrowser&file=../files/hsimple.root+&item=hpx;1&monitoring=2000>. In this particular case, the histogram is not changing. ## JSROOT API. JSROOT can be used in arbitrary HTML pages to display data, produced with or without ROOT-based applications. Many different examples of JSROOT API usage can be found on [JSROOT API examples](https://root.cern/js/latest/api.htm) page. ### Import JSROOT functionality. Major JSROOT functions are located in `main.mjs` module and can be imported like:. ```javascript; <script type='module'>; import { openFile, draw } from 'https://root.cern/js/latest/modules/main.mjs';; let filename = ""https://root.cern/js/files/hsimple.root"";; let file = await openFile(filename);; let obj = await file.readObject(""hpxpy;1"");; await draw(""drawing"", obj, ""colz"");; </script>; ```. Here the default location `https://root.cern/js/latest/` is specified. One always can install JSROOT on private web serv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:33597,monitor,monitoring,33597,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency,"culator with a Poisson problem, reproduces; results from table IV and V of the original; paperï¿½Phys.Rev.D57:3873-3889,1998.; rs401d_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with the neutrino oscillation toy; example described in the original paperï¿½Phys.Rev.D57:3873-3889,1998.; Reproduces figure 12.; rs_bernsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. ï¿½This; class can be used inï¿½conjunctionï¿½with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. ï¿½; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. ï¿½Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. ï¿½Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. ï¿½Useful for debugging. SamplingDistribution and theï¿½TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. ï¿½The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). ï¿½; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. ï¿½The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. ï¿½We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. ï¿½The following concrete implementation; of the Te",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26296,power,powerful,26296,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,['power'],['powerful']
Energy Efficiency,"cuted, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; mo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:35279,schedul,scheduling,35279,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"cution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/doxygen/classllvm_1_1DominatorSet.html>`_ needs to be; calculated at a time. The effectiveness of the ``PassManager`` is influenced directly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserved"" set is intentionally conservative in the face of an; unimplemented :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. Not implementing when it should be implemented will have the effect of; not allowing any analysis results to live across the execution of your pass. The ``PassManager`` class exposes a ``--debug-pass`` command line options that; is useful for debugging pass execution, seeing how things work, and diagnosing; when you should be preserving more analyses than you currently are. (To get; information about all of the variants of the ``--debug-pass`` option, just type; ""``opt -help-hidden``""). By using the --debug-pass=Structure option, for example, we can see how our; :ref:`Hello World <writing-an-llvm-pass-basiccode>` pass interacts with other; passes. Lets try it out with the gvn and licm passes:. .. code-block:: console. $ opt -load lib/LLVMHello.s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:42807,schedul,scheduling,42807,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['schedul'],['scheduling']
Energy Efficiency,"d 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be automatically assigned; - Implement 'nostat' draw option - disabled stat drawing; - Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:10748,monitor,monitor,10748,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['monitor'],['monitor']
Energy Efficiency,"d RDICT. The ROOT precompiled header (PCH) reduces the CPU and memory cost for ROOT's; most used libraries. The precompiled header technology is well-understood since; decades [[4]]. It is an efficient on-disk representation of the state of the; compiler after parsing a set of headers. It can be loaded before starting the; next instance to avoid doing redundant work. At build time, rootcling (ROOT's; dictionary generator) creates such PCH file which is attached at ROOT startup; time. Its major drawback is the fact that if third-party users want to include; their libraries, they have to recompile it every time there is a change. RDICT files store some useful information (in particular about class offsets) in; ROOT files to avoid the potentially expensive call to the interpreter if the; information is not the PCH. For example, ROOT's libGeom and other third-party; code. This is done to circumvent the costly call to `ShowMembers` which will; require parsing. ROOTMAP files reduce parsing for code which is not in the PCH. Consider; `foo::bar` and `S` are defined in `libFoo`'s `Foo.h`:; ```cpp; // Foo.h; namespace foo { struct bar{}; }; struct S{};; ```. ```bash; # libFoo.rootmap; { decls }; namespace foo { }; struct S;; ; [ libFoo.so ]; # List of selected classes; class bar; struct S; ```. ```cpp; // G__Foo.cxx (aka libFoo dictionary); namespace {; void TriggerDictionaryInitialization_libFoo_Impl() {; static const char* headers[] = {""Foo.h""}; // More scaffolding; extern int __Cling_AutoLoading_Map;; namespace foo{struct __attribute__((annotate(""$clingAutoload$Foo.h""))) bar;}; struct __attribute__((annotate(""$clingAutoload$Foo.h""))) S;; // More initialization scaffolding.; }; ```. The code snippet bellow demonstrates the efforts which ROOT does to; avoid parsing redundant code. ```cpp; // ROOT prompt; root [] S *s; // #1: does not require a definition.; root [] foo::bar *baz1; // #2: does not require a definition.; root [] foo::bar baz2; // #3: requires a definition.; ```.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:6843,reduce,reduce,6843,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['reduce'],['reduce']
Energy Efficiency,"d add some more. For example,; by browsing the `LLVM language reference <../../LangRef.html>`_ you'll find; several other interesting instructions that are really easy to plug into; our basic framework. Function Code Generation; ========================. Code generation for prototypes and functions must handle a number of; details, which make their code less beautiful than expression code; generation, but allows us to illustrate some important points. First,; let's talk about code generation for prototypes: they are used both for; function bodies and external function declarations. The code starts; with:. .. code-block:: c++. Function *PrototypeAST::codegen() {; // Make the function type: double(double,double) etc.; std::vector<Type*> Doubles(Args.size(),; Type::getDoubleTy(*TheContext));; FunctionType *FT =; FunctionType::get(Type::getDoubleTy(*TheContext), Doubles, false);. Function *F =; Function::Create(FT, Function::ExternalLinkage, Name, TheModule.get());. This code packs a lot of power into a few lines. Note first that this; function returns a ""Function\*"" instead of a ""Value\*"". Because a; ""prototype"" really talks about the external interface for a function; (not the value computed by an expression), it makes sense for it to; return the LLVM Function it corresponds to when codegen'd. The call to ``FunctionType::get`` creates the ``FunctionType`` that; should be used for a given Prototype. Since all function arguments in; Kaleidoscope are of type double, the first line creates a vector of ""N""; LLVM double types. It then uses the ``Functiontype::get`` method to; create a function type that takes ""N"" doubles as arguments, returns one; double as a result, and that is not vararg (the false parameter; indicates this). Note that Types in LLVM are uniqued just like Constants; are, so you don't ""new"" a type, you ""get"" it. The final line above actually creates the IR Function corresponding to; the Prototype. This indicates the type, linkage and name to use, as; well as",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst:11403,power,power,11403,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst,1,['power'],['power']
Energy Efficiency,"d and if no type is given, the same type as the; previous variable is assumed. This leaf list has three integers called; `ntrack`, `nseg`, and `nvtex`. ``` {.cpp}; ""ntrack/I:nseg:nvtex""; ```. There is one more rule: when no type is given for the very first leaf,; it becomes a `float` (F). This leaf list has three floats called `temp`,; `mass`, and `px`. ``` {.cpp}; ""temp:mass:px""; ```. The symbols used for the type are:. - `C`: a character string terminated by the 0 character; - `B`: an 8 bit signed integer; - `b`: an 8 bit unsigned integer; - `S`: a 16 bit signed integer; - `s`: a 16 bit unsigned integer; - `I`: a 32 bit signed integer; - `i`: a 32 bit unsigned integer; - `L`: a 64 bit signed integer; - `l`: a 64 bit unsigned integer; - `G`: a long signed integer, stored as 64 bit; - `g`: a long unsigned integer, stored as 64 bit; - `F`: a 32 bit floating point; - `D`: a 64 bit floating point; - `O`: [the letter 'o', not a zero] a boolean (Bool\_t). The type is used for a byte count to decide how much space to allocate.; The variable written is simply the block of bytes starting at the; starting address given in the second parameter. It may or may not match; the leaf list depending on whether or not the programmer is being; careful when choosing the leaf address, name, and type. By default, a variable will be copied with the number of bytes specified; in the type descriptor symbol. However, if the type consists of two; characters, the number specifies the number of bytes to be used when; copying the variable to the output buffer. The line below describes; `ntrack` to be written as a 16-bit integer (rather than a 32-bit; integer). ``` {.cpp}; ""ntrack/I2""; ```. With this Branch method, you can also add a leaf that holds an entire; array of variables. To add an array of floats use the `f[n]` notation; when describing the leaf. ``` {.cpp}; Float_t f[10];; tree->Branch(""fBranch"",f,""f[10]/F"");; ```. You can also add an array of variable length:. ``` {.cpp}; {; TFile *f =",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:21747,allocate,allocate,21747,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['allocate'],['allocate']
Energy Efficiency,"d backtraces with inlining information, but does not; include any information about variables, their locations or types. :option:`-gmodules` Generate debug information that contains external; references to types defined in Clang modules or precompiled headers instead; of emitting redundant debug type information into every object file. This; option transparently switches the Clang module format to object file; containers that hold the Clang module together with the debug information.; When compiling a program that uses Clang modules or precompiled headers,; this option produces complete debug information with faster compile; times and much smaller object files. This option should not be used when building static libraries for; distribution to other machines because the debug info will contain; references to the module cache on the machine the object files in the; library were built on. .. option:: -fstandalone-debug -fno-standalone-debug. Clang supports a number of optimizations to reduce the size of debug; information in the binary. They work based on the assumption that the; debug type information can be spread out over multiple compilation units.; For instance, Clang will not emit type definitions for types that are not; needed by a module and could be replaced with a forward declaration.; Further, Clang will only emit type info for a dynamic C++ class in the; module that contains the vtable for the class. The :option:`-fstandalone-debug` option turns off these optimizations.; This is useful when working with 3rd-party libraries that don't come with; debug information. This is the default on Darwin. Note that Clang will; never emit type information for types that are not referenced at all by the; program. .. option:: -feliminate-unused-debug-types. By default, Clang does not emit type information for types that are defined; but not used in a program. To retain the debug info for these unused types,; the negation **-fno-eliminate-unused-debug-types** can be used. .",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:12901,reduce,reduce,12901,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['reduce'],['reduce']
Energy Efficiency,"d barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the scheduling model isn't always a viable; option though (maybe because the instruction is modeled incorrectly on; purpose or the instruction's behaviour is quite complex). The; CustomBehaviour class can be used in these cases to enforce proper; instruction modeling (often by customizing data dependencies and detecting; hazards that :program:`llvm-mca` has no way of knowing about). :program:`llvm-mca` comes w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:43543,schedul,scheduling,43543,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"d execution one could automatically reload hierarchy (_hreload property) or; update view of displayed object (_update_item property); 5. Use HierarchyPainter for implementing draw.htm. This let us handle; all different kinds of extra attributes in central place; 6. Fix problem in tabs layout - new tab should be add to direct child; 7. When drawing several tabs, activate frame before drawing - only then; real frame size will be set; 8. Fix problem with GetBBox - it only can be used for visible elements in mozilla.; 9. Support drawing of fit parameters in stat box, use (as far as possible) stat and; fit format for statistic display; 10. Implement 'g' formatting kind for stat box output - one need to checks; significant digits when producing output.; 11. Support new draw options for TGraph: 'C', 'B1', '0', '2', '3', '4', '[]'; 12. Primary support for STL containers in IO part. Allows to read ROOT6 TF1.; 13. Full support of TGraphBentErrors; 14. Support objects drawing from JSON files in default user interface, including; monitoring. One could open file from link like: https://root.cern.ch/js/dev/?json=demo/canvas_tf1.json; 15. Introduce JSROOT.FFormat function to convert numeric values into string according; format like 6.4g or 5.7e. Used for statistic display. ## Changes in 3.5; 1. Fix error in vertical text alignment; 2. Many improvements in TPaletteAxis drawing - draw label, avoid too large ticks.; 3. Fix error with col drawing - bin with maximum value got wrong color; 4. Test for existing jquery.js, jquery-ui.js and d3.js libraries, reuse when provided; 5. Fix several I/O problems; now one could read files, produced in Geant4; 6. Implement 'e2' drawing option for TH1 class,; use by default 'e' option when TH1 has non-empty fSumw2; 7. Reuse statistic from histogram itself, when no axis selection done; 8. Support log/lin z scale for color drawing; 9. Implement interactive z-scale selection on TPaletteAxis; 10. Allow to redraw item with other draw options (before one ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:65135,monitor,monitoring,65135,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitoring']
Energy Efficiency,"d many; different ways of classifying them: flow-sensitive vs. flow-insensitive,; context-sensitive vs. context-insensitive, field-sensitive; vs. field-insensitive, unification-based vs. subset-based, etc. Traditionally,; alias analyses respond to a query with a `Must, May, or No`_ alias response,; indicating that two pointers always point to the same object, might point to the; same object, or are known to never point to the same object. The LLVM `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`__ class is the; primary interface used by clients and implementations of alias analyses in the; LLVM system. This class is the common interface between clients of alias; analysis information and the implementations providing it, and is designed to; support a wide range of implementations and clients (but currently all clients; are assumed to be flow-insensitive). In addition to simple alias analysis; information, this class exposes Mod/Ref information from those implementations; which can provide it, allowing for powerful analyses and transformations to work; well together. This document contains information necessary to successfully implement this; interface, use it, and to test both sides. It also explains some of the finer; points about what exactly results mean. ``AliasAnalysis`` Class Overview; ================================. The `AliasAnalysis <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`__; class defines the interface that the various alias analysis implementations; should support. This class exports two important enums: ``AliasResult`` and; ``ModRefResult`` which represent the result of an alias query or a mod/ref; query, respectively. The ``AliasAnalysis`` interface exposes information about memory, represented in; several different ways. In particular, memory objects are represented as a; starting address and size, and function calls are represented as the actual; ``call`` or ``invoke`` instructions that performs the call. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:1429,power,powerful,1429,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['power'],['powerful']
Energy Efficiency,"d polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; MappingNormalization<> except that it heap allocates the normalized object; when reading YAML. It never destroys the normalized object. The denormalize(); method can this return ""this"". Default values; --------------; Within a mapping() method, calls to io.mapRequired() mean that that key is; required to exist when parsing YAML documents, otherwise YAML I/O will issue an; error. On the other hand, keys registered with io.mapOptional() are allowed to not; exist in the YAML document being read. So what value is put in the field; for those optional keys?; There are two steps to how those optional fields are filled in. First, the; second parameter to the mapping() method is a reference to a native class. That; native class must have a default constructor. Whatever value the default; constructor initially sets for an optional field will be that field's value.; Second, the mapOptional() method has an optional third parameter. If provided; it is the value that mapOptional() should set that field to if the YAML document; does not ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:19737,allocate,allocates,19737,interpreter/llvm-project/llvm/docs/YamlIO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst,1,['allocate'],['allocates']
Energy Efficiency,"d prepend `button;`; string to the icon name to let browser show command as extra button. In last case one could hide command element from elements list:. ```cpp; serv->Hide(""/DoSomething"");; ```. One can find example of command interface usage in [tutorials/http/httpcontrol.C](https://github.com/root-project/root/blob/master/tutorials/http/httpcontrol.C) macro. ## Customize user interface. JSROOT is used to implement UI for the THttpServer. Default webpage shows list of registered objects on the left side and drawing area on the right side - [see example](https://root.cern/js/latest/httpserver.C/). JSROOT allows to configure different parameters via URL - like monitoring interval or name of displayed items [item=Files/job1.root/hpxpy&opt=colz&monitoring=1000](https://root.cern/js/latest/httpserver.C/?item=Files/job1.root/hpxpy&opt=colz&monitoring=1000). Some of such parameters can be configured already on the server:. ```cpp; serv->SetItemField(""/"", ""_monitoring"", ""1000""); // monitoring interval in ms; serv->SetItemField(""/"", ""_drawitem"", ""Files/job1.root/hpxpy""); // item to draw; serv->SetItemField(""/"", ""_drawopt"", ""colz"");; ```. In such case URL parameters are not required - specified item will be displayed automatically when web page is opened.; One also can configure to display several items at once. For that one also can configure layout of the drawing area:. ```cpp; serv->SetItemField(""/"", ""_layout"", ""grid2x2""); // layout for drawing area; serv->SetItemField(""/"", ""_drawitem"", ""[Files/job1.root/hpxpy,Files/job1.root/hpx]""); // items; serv->SetItemField(""/"", ""_drawopt"", ""[colz,hist]""); // options; ```. One also can change appearance of hierarchy browser on the left side of the web page:. ```cpp; serv->SetItemField(""/"", ""_browser"", ""off""); // allowed ""fix"" (default), ""float"", ""no"", ""off""; serv->SetItemField(""/"", ""_toptitle"", ""Custom title""); // title of web page, shown when browser off; ```. If necessary, one also can automatically open ROOT file when web page i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:6970,monitor,monitoring,6970,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['monitor'],['monitoring']
Energy Efficiency,"d*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:36924,schedul,scheduler,36924,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"d, but mismatched ones will be left alone.; ``allockind(""KIND"")``; Describes the behavior of an allocation function. The KIND string contains comma; separated entries from the following options:. * ""alloc"": the function returns a new block of memory or null.; * ""realloc"": the function returns a new block of memory or null. If the; result is non-null the memory contents from the start of the block up to; the smaller of the original allocation size and the new allocation size; will match that of the ``allocptr`` argument and the ``allocptr``; argument is invalidated, even if the function returns the same address.; * ""free"": the function frees the block of memory specified by ``allocptr``.; Functions marked as ""free"" ``allockind`` must return void.; * ""uninitialized"": Any newly-allocated memory (either a new block from; a ""alloc"" function or the enlarged capacity from a ""realloc"" function); will be uninitialized.; * ""zeroed"": Any newly-allocated memory (either a new block from a ""alloc""; function or the enlarged capacity from a ""realloc"" function) will be; zeroed.; * ""aligned"": the function returns memory aligned according to the; ``allocalign`` parameter. The first three options are mutually exclusive, and the remaining options; describe more details of how the function behaves. The remaining options; are invalid for ""free""-type functions.; ``allocsize(<EltSizeParam>[, <NumEltsParam>])``; This attribute indicates that the annotated function will always return at; least a given number of bytes (or null). Its arguments are zero-indexed; parameter numbers; if one argument is provided, then it's assumed that at; least ``CallSite.Args[EltSizeParam]`` bytes will be available at the; returned pointer. If two are provided, then it's assumed that; ``CallSite.Args[EltSizeParam] * CallSite.Args[NumEltsParam]`` bytes are; available. The referenced parameters must be integer types. No assumptions; are made about the contents of the returned block of memory.; ``alwaysinline``; This",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:79081,allocate,allocated,79081,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"d-stripping, but before memory; is allocated or nodes assigned their final target vmaddrs. Passes run at this stage benefit from pruning, as dead functions and data; have been stripped from the graph. However new content can still be added; to the graph, as target and working memory have not been allocated yet. Notable use cases: Building Global Offset Table (GOT), Procedure Linkage; Table (PLT), and Thread Local Variable (TLV) entries. #. Asynchronously allocate memory. Calls the ``JITLinkContext``'s ``JITLinkMemoryManager`` to allocate both; working and target memory for the graph. As part of this process the; ``JITLinkMemoryManager`` will update the addresses of all nodes; defined in the graph to their assigned target address. Note: This step only updates the addresses of nodes defined in this graph.; External symbols will still have null addresses. #. Phase 2. #. Run post-allocation passes. These passes are run on the graph after working and target memory have; been allocated, but before the ``JITLinkContext`` is notified of the; final addresses of the symbols in the graph. This gives these passes a; chance to set up data structures associated with target addresses before; any JITLink clients (especially ORC queries for symbol resolution) can; attempt to access them. Notable use cases: Setting up mappings between target addresses and; JIT data structures, such as a mapping between ``__dso_handle`` and; ``JITDylib*``. #. Notify the ``JITLinkContext`` of the assigned symbol addresses. Calls ``JITLinkContext::notifyResolved`` on the link graph, allowing; clients to react to the symbol address assignments made for this graph.; In ORC this is used to notify any pending queries for *resolved* symbols,; including pending queries from concurrently running JITLink instances that; have reached the next step and are waiting on the address of a symbol in; this graph to proceed with their link. #. Identify external symbols and resolve their addresses asynchronously. Calls the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:19757,allocate,allocated,19757,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocated']
Energy Efficiency,"d/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analyzes instruction; dispatch events, as well as static/dynamic dispatch stall events. This view; is disabled by default. .. option:: -scheduler-stats. Enable extra scheduler statistics. This view collects and analyzes instruction; issue events. This view is disabled by default. .. option:: -retire-stats. Enable extra retire control unit statistics. This view is disabled by default. .. option:: -instruction-info. Enable the instruction info view. This is enabled by default. .. option:: -show-encoding. Enable the printing of instruction encodings within the instruction info view. .. option:: -show-barriers. Enable the printing of LoadBarrier and StoreBarrier flags within the; instruction info view. .. option:: -all-stats. Print all hardware statistics. This enables extra statistics related to the; dispatch logic, the hardware schedulers, the register file(s), and the retire; control unit. This option is disabled by default. .. option:: -all-views. Enable all the view. .. option:: -instruction-tables. Prints resource pressure information based on the static information; available from the processor model. This differs from",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:5481,schedul,scheduler-stats,5481,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler-stats']
Energy Efficiency,"d1 + d.get_field2(); ... return total; ...; >>> print(tsdcm(a, d)); 155; >>>. Demo: Numba physics example; ---------------------------. Motivating example taken from:; `numba_scalar_impl.py <https://github.com/numba/numba-examples/blob/master/examples/physics/lennard_jones/numba_scalar_impl.py>`_. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext; ...; >>> cppyy.cppdef(""""""; ... #include <vector>; ... struct Atom {; ... float x;; ... float y;; ... float z;; ... };; ...; ... std::vector<Atom> atoms = {{1, 2, 3}, {2, 3, 4}, {3, 4, 5}, {4, 5, 6}, {5, 6, 7}};; ... """"""); ...; >>> @numba.njit; >>> def lj_numba_scalar(r):; ... sr6 = (1./r)**6; ... pot = 4.*(sr6*sr6 - sr6); ... return pot. >>> @numba.njit; >>> def distance_numba_scalar(atom1, atom2):; ... dx = atom2.x - atom1.x; ... dy = atom2.y - atom1.y; ... dz = atom2.z - atom1.z; ...; ... r = (dx * dx + dy * dy + dz * dz) ** 0.5; ...; ... return r; ...; >>> def potential_numba_scalar(cluster):; ... energy = 0.0; ... for i in range(cluster.size() - 1):; ... for j in range(i + 1, cluster.size()):; ... r = distance_numba_scalar(cluster[i], cluster[j]); ... e = lj_numba_scalar(r); ... energy += e; ...; ... return energy; ...; >>> print(""Total lennard jones potential ="", potential_numba_scalar(cppyy.gbl.atoms)); Total lennard jones potential = -0.5780277345740283. Overhead; --------. The main overhead of JITing Numba traces is in the type annotation in Numba; itself, optimization of the IR and assembly by the backend less so.; (There is also a non-negligible cost to Numba initialization, which is why; ``cppyy`` does not provide automatic extension hooks.); The use of ``cppyy`` bound C++, which relies on the same Numba machinery,; does not change that, since the reflection-based lookups are in C++ and; comparatively very fast.; For example, there is no appreciable difference in wall clock time to JIT a; trace using Numba's included math functions (from module ``math`` or; ``numpy``) or one ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:8866,energy,energy,8866,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,1,['energy'],['energy']
Energy Efficiency,"d:. '``llvm.vector.reduce.and.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:655970,reduce,reduce,655970,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"d:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VAL",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:26342,allocate,allocated,26342,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency,"ddition to; all the simple types. When using a **`TTree`**, we fill its branch buffers with leaf data and; the buffers are written to disk when it is full. Branches, buffers, and; leafs, are explained a little later in this chapter, but for now, it is; important to realize that each object is not written individually, but; rather collected and written a bunch at a time. This is where the **`TTree`** takes advantage of compression and will; produce a much smaller file than if the objects were written; individually. Since the unit to be compressed is a buffer, and the; **`TTree`** contains many same-class objects, the header of the objects; can be compressed. The **`TTree`** reduces the header of each object, but it still contains; the class name. Using compression, the class name of each same-class; object has a good chance of being compressed, since the compression; algorithm recognizes the bit pattern representing the class name. Using; a **`TTree`** and compression the header is reduced to about 4 bytes; compared to the original 60 bytes. However, if compression is turned; off, you will not see these large savings. The **`TTree`** is also used to optimize the data access. A tree uses a; hierarchy of branches, and each branch can be read independently from; any other branch. Now, assume that `Px` and `Py` are data members of the; event, and we would like to compute `Px2 + Py2` for every event; and histogram the result. If we had saved the million events without a **`TTree`** we would have; to:. - read each event in its entirety into memory; - extract the `Px` and `Py` from the event; - compute the sum of the squares; - fill a histogram. We would have to do that a million times! This is very time consuming,; and we really do not need to read the entire event, every time. All we; need are two little data members (`Px` and `Py`). On the other hand, if; we use a tree with one branch containing `Px` and another branch; containing `Py`, we can read all values of `Px` and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:1534,reduce,reduced,1534,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['reduce'],['reduced']
Energy Efficiency,"de:. ::. float sequential_fadd(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, negative zero (``-0.0``) can be used, as it is; the neutral value of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. O",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:652872,reduce,reduce,652872,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"de:. alpha.deadcode.UnreachableCode (C, C++); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check unreachable code. .. code-block:: cpp. // C; int test() {; int x = 1;; while(x);; return x; // warn; }. // C++; void test() {; int a = 2;. while (a > 1); a--;. if (a > 1); a++; // warn; }. // Objective-C; void test(id x) {; return;; [x retain]; // warn; }. alpha.fuchsia; ^^^^^^^^^^^^^. .. _alpha-fuchsia-lock:. alpha.fuchsia.Lock; """"""""""""""""""""""""""""""""""""; Similarly to :ref:`alpha.unix.PthreadLock <alpha-unix-PthreadLock>`, checks for; the locking/unlocking of fuchsia mutexes. .. code-block:: cpp. spin_lock_t mtx1;. void bad1(void); {; spin_lock(&mtx1);; spin_lock(&mtx1);	// warn: This lock has already been acquired; }. alpha.llvm; ^^^^^^^^^^. .. _alpha-llvm-Conventions:. alpha.llvm.Conventions; """""""""""""""""""""""""""""""""""""""""""". Check code for LLVM codebase conventions:. * A StringRef should not be bound to a temporary std::string whose lifetime is shorter than the StringRef's.; * Clang AST nodes should not have fields that can allocate memory. alpha.osx; ^^^^^^^^^. .. _alpha-osx-cocoa-DirectIvarAssignment:. alpha.osx.cocoa.DirectIvarAssignment (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for direct assignments to instance variables. .. code-block:: objc. @interface MyClass : NSObject {}; @property (readonly) id A;; - (void) foo;; @end. @implementation MyClass; - (void) foo {; _A = 0; // warn; }; @end. .. _alpha-osx-cocoa-DirectIvarAssignmentForAnnotatedFunctions:. alpha.osx.cocoa.DirectIvarAssignmentForAnnotatedFunctions (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for direct assignments to instance variables in; the methods annotated with ``objc_no_direct_instance_variable_assignment``. .. code-block:: objc. @interface MyClass : NSObject {}; @property (readonly) id A;; - (void) fAnnotated __attribute__((; annotate(""objc_no_direct_instance_variable_assignment"")));; - (void) fNotAnnotated;; @end. @implementation MyClass; - (void) fAnnotated {;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:57022,allocate,allocate,57022,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['allocate'],['allocate']
Energy Efficiency,"declaration (from stl math.h) is broken.; # FIXME: Revise after a llvm upgrade or reproduce it outside rootcling.; list(REMOVE_ITEM HEADERS ""Math/Math.h""). if(vc); # We do not link against libVc.a thus it makes no sense to check for; # version compatibility between libraries and header files. This fixes; # ROOT-11002 where upon building the modules.idx we run the static ctor; # runLibraryAbiCheck which fails to find the corresponding symbol.; set(dictoptions ""-m"" ""Vc"" ""-mByproduct"" ""Vc"" ""-D"" ""Vc_NO_VERSION_CHECK""); endif(vc); endif(). ROOT_ADD_C_FLAG(_flags -Wno-strict-overflow) # Avoid what it seems a compiler false positive warning; ROOT_ADD_C_FLAG(_flags -Wno-maybe-uninitialized) # Avoid what it seems a compiler false positive warning; ROOT_ADD_C_FLAG(_flags -Wno-parentheses-equality). if(imt); set(MATHCORE_DEPENDENCIES Imt); endif(). if(veccore); set(MATHCORE_BUILTINS VECCORE); set(MATHCORE_LIBRARIES ${VecCore_LIBRARIES}); endif(). ROOT_STANDARD_LIBRARY_PACKAGE(MathCore; HEADERS; ${HEADERS}; SOURCES; src/AdaptiveIntegratorMultiDim.cxx; src/BasicMinimizer.cxx; src/BinData.cxx; src/BrentMethods.cxx; src/BrentMinimizer1D.cxx; src/BrentRootFinder.cxx; src/ChebyshevPol.cxx; src/DataRange.cxx; src/Delaunay2D.cxx; src/DistSampler.cxx; src/DistSamplerOptions.cxx; src/Factory.cxx; src/FitConfig.cxx; src/FitData.cxx; src/FitResult.cxx; src/FitUtil.cxx; src/Fitter.cxx; src/GaussIntegrator.cxx; src/GaussLegendreIntegrator.cxx; src/GenAlgoOptions.cxx; src/GoFTest.cxx; src/IOptions.cxx; src/Integrator.cxx; src/IntegratorOptions.cxx; src/MersenneTwisterEngine.cxx; src/MinimTransformFunction.cxx; src/Minimizer.cxx; src/MinimizerOptions.cxx; src/MinimizerVariableTransformation.cxx; src/MixMaxEngineImpl17.cxx; src/MixMaxEngineImpl240.cxx; src/MixMaxEngineImpl256.cxx; src/ParameterSettings.cxx; src/PdfFuncMathCore.cxx; src/ProbFuncMathCore.cxx; src/QuantFuncMathCore.cxx; src/RandomFunctions.cxx; src/RanluxppEngineImpl.cxx; src/RichardsonDerivator.cxx; src/RootFinder.cxx; src/Spars",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/CMakeLists.txt:3494,Adapt,AdaptiveIntegratorMultiDim,3494,math/mathcore/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/CMakeLists.txt,1,['Adapt'],['AdaptiveIntegratorMultiDim']
Energy Efficiency,deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helper.h; llvm/tools/llvm-xray/llvm-xray.cpp; llvm/tools/llvm-xray/trie-node.h; llvm/tools/llvm-xray/xray-account.h; llvm/tools/llvm-xray/xray-color-helper.cpp; llvm/tools/llvm-xray/xray-color-helper.h; llvm/tools/llvm-xray/xray-converter.cpp; llvm/tools/llvm-xray/xray-converter.h; llvm/tools/llvm-xray/xray-fdr-dump.cpp; llvm/tools/llvm-xray/xray-graph-diff.cpp; llvm/tools/l,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:339155,reduce,reduce,339155,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"described with combination of planes, can; be rendered in this fashion - e.g. a clipping tube is not possible. - Each additional clipping plane requires an additional render pass -; so the more active planes the more time the render will take. Set the current clip object with **`TGLClipSet::SetClipType`**. ``` {.cpp}; v->GetClipSet()->SetClipType(TGLClipSet::kClipPlane);; ```. Configure the clip object with **`TGLClipSet::SetClipState`**. ``` {.cpp}; Double_t planeEq[4] = {0.5,1.0,-1.0, 2.0};; v->GetClipSet()->SetClipState(TGLClipSet::kClipPlane, planeEq);; ```. As with cameras, any clip can be configured at any time, but you must; set the clip current to see the effect. #### Manipulators. *Manipulators* are GUI â€˜widgets' or controls attached to a 3D object in; the viewer, allowing a direct manipulation of the object's geometry.; There are three manipulators for the three basic geometries; transformations. In each case, the *manipulator* consists of three; components, one for each local axis of the object, shown in standard; colors: red (X), green (Y) and blue (Z). ![GL Viewer object manipulators](pictures/030000DE.png). Activate the *manipulator* by moving the mouse over one of these; components (which turns yellow to indicate active state). Click with; left mouse and drag this active component to perform the manipulation.; Toggle between the *manipulator* types using the â€˜x', â€˜c', â€˜v' keys; while the mouse cursor is above the manipulator. Note: Manipulators; cannot be controlled via the API at present. #### Guides. Guides are visual aids drawn into the viewer world. Controls for these; are under the ""Guides"" tab:. Viewer Controls Pane Guides Tab. Axes show the world (global) frame *coordinate*directions: X (red), Y; (green) and Z (blue). The negative portion of the *axis* line is shown; in dark color, the positive in bright. The *axis* name and minimum /; maximum values are labeled in the same color. There are three options; for *axes* drawing - selected by radio ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:116490,green,green,116490,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['green'],['green']
Energy Efficiency,"design; principle that semantically important behavior should be explicit. A simple; fix is to clear the instance variable manually during ``dealloc``; a more; holistic solution is to move semantically important side-effects out of; ``dealloc`` and into a separate teardown phase which can rely on working with; well-formed objects. .. _arc.misc.autoreleasepool:. ``@autoreleasepool``; --------------------. To simplify the use of autorelease pools, and to bring them under the control; of the compiler, a new kind of statement is available in Objective-C. It is; written ``@autoreleasepool`` followed by a *compound-statement*, i.e. by a new; scope delimited by curly braces. Upon entry to this block, the current state; of the autorelease pool is captured. When the block is exited normally,; whether by fallthrough or directed control flow (such as ``return`` or; ``break``), the autorelease pool is restored to the saved state, releasing all; the objects in it. When the block is exited with an exception, the pool is not; drained. ``@autoreleasepool`` may be used in non-ARC translation units, with equivalent; semantics. A program is ill-formed if it refers to the ``NSAutoreleasePool`` class. .. admonition:: Rationale. Autorelease pools are clearly important for the compiler to reason about, but; it is far too much to expect the compiler to accurately reason about control; dependencies between two calls. It is also very easy to accidentally forget; to drain an autorelease pool when using the manual API, and this can; significantly inflate the process's high-water-mark. The introduction of a; new scope is unfortunate but basically required for sane interaction with the; rest of the language. Not draining the pool during an unwind is apparently; required by the Objective-C exceptions implementation. .. _arc.misc.externally_retained:. Externally-Retained Variables; -----------------------------. In some situations, variables with strong ownership are considered; externally-retaine",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:91125,drain,drained,91125,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['drain'],['drained']
Energy Efficiency,"detailed in; `OpenCL C v3.0 6.7.8 <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_C.html#addr-spaces-inference>`_. The default address space is ""generic-memory"", which is a virtual address space; that overlaps the global, local, and private address spaces. SYCL mode enables; following conversions:. - explicit conversions to/from the default address space from/to the address; space-attributed type; - implicit conversions from the address space-attributed type to the default; address space; - explicit conversions to/from the global address space from/to the; ``__attribute__((opencl_global_device))`` or; ``__attribute__((opencl_global_host))`` address space-attributed type; - implicit conversions from the ``__attribute__((opencl_global_device))`` or; ``__attribute__((opencl_global_host))`` address space-attributed type to the; global address space. All named address spaces are disjoint and sub-sets of default address space. The SPIR target allocates SYCL namespace scope variables in the global address; space. Pointers to default address space should get lowered into a pointer to a generic; address space (or flat to reuse more general terminology). But depending on the; allocation context, the default address space of a non-pointer type is assigned; to a specific address space. This is described in; `common address space deduction rules <https://www.khronos.org/registry/SYCL/specs/sycl-2020/html/sycl-2020.html#subsec:commonAddressSpace>`_; section. This is also in line with the behaviour of CUDA (`small example; <https://godbolt.org/z/veqTfo9PK>`_). ``multi_ptr`` class implementation example:. .. code-block:: C++. // check that SYCL mode is ON and we can use non-standard decorations; #if defined(__SYCL_DEVICE_ONLY__); // GPU/accelerator implementation; template <typename T, address_space AS> class multi_ptr {; // DecoratedType applies corresponding address space attribute to the type T; // DecoratedType<T, global_space>::type == ""__attribute__((ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SYCLSupport.rst:2539,allocate,allocates,2539,interpreter/llvm-project/clang/docs/SYCLSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SYCLSupport.rst,1,['allocate'],['allocates']
Energy Efficiency,"dicated rep as part of it's dynamic; complication phase. Also, if a basic block contains ONLY a move, then; that can be trivally translated into a conditional move... > I agree that we need a static data space. Otherwise, emulating global; > data gets unnecessarily complex. Definitely. Also a later item though. :). > We once talked about adding a symbolic thread-id field to each; > ..; > Instead, it could a great topic for a separate study. Agreed. :). > What is the semantics of the IA64 stop bit?. Basically, the IA64 writes instructions like this:; mov ...; add ...; sub ...; op xxx; op xxx; ;;; mov ...; add ...; sub ...; op xxx; op xxx; ;;. Where the ;; delimits a group of instruction with no dependencies between; them, which can all be executed concurrently (to the limits of the; available functional units). The ;; gets translated into a bit set in one; of the opcodes. The advantages of this representation is that you don't have to do some; kind of 'thread id scheduling' pass by having to specify ahead of time how; many threads to use, and the representation doesn't have a per instruction; overhead... > And finally, another thought about the syntax for arrays :-); > Although this syntax:; > array <dimension-list> of <type>; > is verbose, it will be used only in the human-readable assembly code so; > size should not matter. I think we should consider it because I find it; > to be the clearest syntax. It could even make arrays of function; > pointers somewhat readable. My only comment will be to give you an example of why this is a bad; idea. :). Here is an example of using the switch statement (with my recommended; syntax):. switch uint %val, label %otherwise, ; [%3 x {uint, label}] [ { uint %57, label %l1 }, ; { uint %20, label %l2 }, ; { uint %14, label %l3 } ]. Here it is with the syntax you are proposing:. switch uint %val, label %otherwise, ; array %3 of {uint, label} ; array of {uint, label}; { uint %57, label %l1 },; { uint %20, label %l2 },; { uint %14, labe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt:7659,schedul,scheduling,7659,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,1,['schedul'],['scheduling']
Energy Efficiency,"dif(). if(${t} IN_LIST need_network); list(APPEND labels needs_network); endif(). # These tests on ARM64 need much more than 20 minutes - increase the timeout; if(ROOT_ARCHITECTURE MATCHES arm64 OR ROOT_ARCHITECTURE MATCHES ppc64); set(thisTestTimeout 3000) # 50m; else(); set(thisTestTimeout 1200) # 20m; endif(). ROOT_ADD_TEST(tutorial-${tname}; COMMAND ${ROOT_root_CMD} -b -l -q ${createThreadPool} ${CMAKE_CURRENT_SOURCE_DIR}/${t}${${tname}-aclic}; PASSRC ${rc} FAILREGEX ""Error in <"" "": error:"" ""segmentation violation"" ""FROM HESSE STATUS=FAILED"" ""warning: Failed to call""; LABELS ${labels}; DEPENDS tutorial-hsimple ${${tname}-depends}; ENVIRONMENT ${TUTORIAL_ENV}; TIMEOUT ${thisTestTimeout}). if(${t} IN_LIST multithreaded); # Makes sure that this doesn't run in parallel with other multithreaded tutorials, and that cmake doesn't start too; # many other tests. That we use 4 processors is actually a lie, because IMT takes whatever it finds.; # However, even this poor indication of MT behaviour is a good hint for cmake to reduce congestion.; set_tests_properties(tutorial-${tname} PROPERTIES RESOURCE_LOCK multithreaded PROCESSORS ${NProcessors}); endif(); endforeach(). #---Loop over all MPI tutorials and define the corresponding test---------; foreach(t ${mpi_tutorials}); list(FIND returncode_1 ${t} index); if(index EQUAL -1); set(rc 0); else(); set(rc 255); endif(); string(REPLACE "".C"" """" tname ${t}); string(REPLACE ""/"" ""-"" tname ${tname}). # These tests on ARM64 need much more than 20 minutes - increase the timeout; if(ROOT_ARCHITECTURE MATCHES arm64 OR ROOT_ARCHITECTURE MATCHES ppc64); set(thisTestTimeout 3000) # 50m; else(); set(thisTestTimeout 1200) # 20m; endif(). ROOT_ADD_TEST(tutorial-${tname}; COMMAND ${MPIEXEC_EXECUTABLE} ${MPIEXEC_NUMPROC_FLAG} 4 ${ROOT_root_CMD} -b -l -q ${CMAKE_CURRENT_SOURCE_DIR}/${t}${${tname}-aclic}; PASSRC ${rc} FAILREGEX ""Error in <"" "": error:"" ""segmentation violation"" ""FROM HESSE STATUS=FAILED"" ""warning: Failed to call""; LABELS tutorial;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/CMakeLists.txt:24971,reduce,reduce,24971,tutorials/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/CMakeLists.txt,1,['reduce'],['reduce']
Energy Efficiency,"ding class as is the case in `EventHeader` and; `Event`. ``` {.cpp}; class EventHeader {; private:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;; // ... list of methods; ClassDef(EventHeader,1) //Event Header; };; ```. ### The Track Class. The `Track` class descends from **`TObject`** since tracks are in a; **`TClonesArray`** (i.e. a ROOT collection class) and contains a; selection of basic types and an array of vertices. Its **`TObject`**; inheritance enables `Track` to be in a collection and in `Event` is a; **`TClonesArray`** of `Tracks`. ``` {.cpp}; class Track : public TObject {; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Float_t fCharge; //Charge of this track; Float_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion. // method definitions ...; ClassDef(Track,1) //A track segment; };; ```. ### Writing the Tree. We create a simple tree with two branches both holding `Event` objects.; One is split and the other is not. We also create a pointer to an; `Event` object (`event`). ``` {.cpp}; void tree4w() {; // check to see if the event class is in the dictionary; // if it is not load the definition in libEvent.so; if (!TClassTable::GetDict(""Event"")) {; gSystem->Load(""$ROOTSYS/test/libEvent.so"");; }; // create a Tree file tree4.root; TFile f(""tree4.root"",""RECREATE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:61465,charge,charge,61465,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['charge'],['charge']
Energy Efficiency,discourse category. You **must** have a Discourse account associated with the email address you are sending from or the email will be rejected. <table border=1>; <tr><th>Discourse Category</th><th>Email Address</th></tr>; <tr><td>Beginner</td><td>beginners@discourse.llvm.org</td></tr>; <tr><td>LLVM Project</td><td>llvmproject@discourse.llvm.org</td></tr>; <tr><td>IR & Optimizations</td><td>IR.Optimizations@discourse.llvm.org</td></tr>; <tr><td>IR & Optimizations - Loop Optimizations</td><td>IR.Optimizations-Loops@discourse.llvm.org</td></tr>; <tr><td>Code Generation</td><td>codegen@discourse.llvm.org</td></tr>; <tr><td>Code Generation - AMDGPU</td><td>codegen-amdgpu@discourse.llvm.org</td></tr>; <tr><td>Code Generation - Common Infrastructure</td><td>codegen-common@discourse.llvm.org</td></tr>; <tr><td>Code Generation - AArch64</td><td>codegen-aarch64@discourse.llvm.org</td></tr>; <tr><td>Code Generation - Arm</td><td>codegen-arm@discourse.llvm.org</td></tr>; <tr><td>Code Generation - PowerPC</td><td>codegen-powerpc@discourse.llvm.org</td></tr>; <tr><td>Code Generation - RISCV</td><td>codegen-riscv@discourse.llvm.org</td></tr>; <tr><td>Code Generation - WebAssembly</td><td>codegen-webassembly@discourse.llvm.org</td></tr>; <tr><td>Code Generation - X86</td><td>codegen-x86@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend</td><td>clang@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Using Clang</td><td>clang-users@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - clangd</td><td>clangd@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Building Clang</td><td>clang-build@discourse.llvm.org</td></tr>; <tr><td>Clang Frontend - Static Analyzer</td><td>clang-staticanalyzer@discourse.llvm.org</td></tr>; <tr><td>Runtimes</td><td>runtimes@discourse.llvm.org</td></tr>; <tr><td>Runtimes - C++</td><td>runtimes-cxx@discourse.llvm.org</td></tr>; <tr><td>Runtimes - Sanitizers</td><td>runtimes-sanitizers@discourse.llvm.org</td></tr>; <tr><td>Runtimes - C</td><td>run,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md:3288,power,powerpc,3288,interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DiscourseMigrationGuide.md,1,['power'],['powerpc']
Energy Efficiency,"duce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:657085,reduce,reduce,657085,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"duction. That is, the reduction begins with; the start value and performs an fadd operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fadd(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, negative zero (``-0.0``) can be used, as it is; the neutral value of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:652699,reduce,reduce,652699,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"duled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction sche",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43729,schedul,schedule,43729,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['schedule']
Energy Efficiency,"e (by avoid the fast merge technique). The equivalent in TFileMerger is to call; merger->SetFastMethod(kFALSE); To make sure that the class emulation layer of ROOT does not double delete an object,; tell the StreamerElement representing one of the pointers pointing to the object; to never delete the object. For example:. TClass::AddRule(""HepMC::GenVertex m_event attributes=NotOwner"");. The handling of memory by the collection proxy has been improved in the case of a; collection of pointers which can now become owner of its content. The default, for backward compatibility reasons and to avoid double delete (at the expense; of memory leaks), the container of pointers are still not owning their content; unless they are a free standing container (i.e. itself not contained in another; object).; To make a container of pointers become owner of its content do something like:. TClass::AddRule(""ObjectVector<LHCb::MCRichDigitSummary> m_vector options=Owner"");. Added TKey::Reset and TKey::WriteFileKeepBuffer to allow derived classes (TBasket) to be re-use as key rather than always recreated.; TH1::Streamer and TGraph2D::Streamer no longer reset the kCanDelete bit directly so that the user can give; ownership of the object to the canvas they are stored with. However, if they are saved on their own, the mechanism; that associates them to the current directory (DirectoryAutoAdd) will now reset the bit to avoid any possible; ownsership confusion.; Added TFile::SetOffset and TFile::ReadBuffer(char *buf, Long64_t pos, Int_t len); to drastically reduce; the number of fseek done on the physical file when using the TTreeCache.; To support future changes in the API of the CollectionProxy, we added the new #define:; ROOT_COLLECTIONPROXY_VERSION and REFLEX_COLLECTIONPROXY_VERSION. Reduce possible confusions and conflicts by always using in TClass and TStreamerInfo the version of template instance names with ULong64_t and Long64_t rather than [unsigned] long long.; new Hadoop TFile plugin. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:12504,reduce,reduce,12504,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,3,"['Reduce', 'reduce']","['Reduce', 'reduce']"
Energy Efficiency,"e `LinkDef.h` file tells `rootcling` which classes should; be added to the dictionary. ``` {.cpp}; #ifdef __CLING__; #pragma link C++ class SClass;; #endif; ```. Three options can trail the class name:. - `-` : tells `rootcling` **not** to generate the `Streamer` method for; this class. This is necessary for those classes that need a; customized `Streamer` method. ``` {.cpp}; #pragma link C++ class SClass-; // no streamer; ```. - **`!`** : tells `rootcling` **not** to generate the; `operator>>(`**`TBuffer`** `&b,MyClass *&obj)` method for this; class. This is necessary to be able to write pointers to objects of; classes not inheriting from **`TObject`**. ``` {.cpp}; #pragma link C++ class SClass!; // no >> operator; // or; #pragma link C++ class SClass-!; // no streamer, no >> operator; ```. - **+** : in ROOT version 1 and 2 tells `rootcling` to generate a; `Streamer` with extra byte count information. This adds an integer; to each object in the output buffer, but it allows for powerful; error correction in case a `Streamer` method is out of sync with; data in the file. The `+` option is mutual exclusive with both the; `-` and `!` options. IMPORTANT NOTE: In ROOT Version 3 and later, a ""+"" after the class name; tells `rootcling` to use the new I/O system. The byte count check is; always added. The new I/O system has many advantages including support; automatic schema evolution, full support for STL collections and better; run-time performance. We strongly recommend using it. ``` {.cpp}; #pragma link C++ class SClass+; // add byte count; ```. For information on `Streamers` see ""Input/Output"". To get help on; `rootcling` type on the UNIX command line: **`rootcling -h`**. #### The Order Matters. When using template classes, the order of the pragma statements matters.; For example, here is a template class `Tmpl` and a normal class `Norm`,; which holds a specialized instance of a `Tmpl`:. ``` {.cpp}; class Norm {; private:; Tmpl<int>* fIntTmpl;; public:; ...; };; ```. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md:22117,power,powerful,22117,documentation/users-guide/AddingaClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md,1,['power'],['powerful']
Energy Efficiency,"e algorithm is controlled by the given absolute and relative tolerance. The iterations are continued until the following condition is satisfied; $$; absErr <= max ( epsAbs, epsRel * Integral); $$; Where *absErr* is an estimate of the absolute error (it can be retrieved with `GSLIntegrator::Error()`) and *Integral* is the estimate of the function integral; (it can be obtained with `GSLIntegrator::Result()`). The possible integration algorithm types to use with the GSLIntegrator are the following. More information is provided in the `GSL` users documentation.; * `ROOT::Math::Integration::kNONADAPTIVE` : based on `gsl_integration_qng`. It is a non-adaptive procedure which uses fixed Gauss-Kronrod-Patterson abscissae; to sample the integrand at a maximum of 87 points. It is provided for fast integration of smooth functions.; * `ROOT::Math::Integration::kADAPTIVE`: based on `gsl_integration_qag`. It is an adaptiva Gauss-Kronrod integration algorithm, the integration region is divided into subintervals, and on each; iteration the subinterval with the largest estimated error is bisected. It is possible to specify the integration rule as an extra enumeration parameter. The possible rules are; * `Integration::kGAUSS15` : 15 points Gauss-Konrod rule (value = 1); * `Integration::kGAUSS21` : 21 points Gauss-Konrod rule (value = 2); * `Integration::kGAUSS31` : 31 points Gauss-Konrod rule (value = 3); * `Integration::kGAUSS41` : 41 points Gauss-Konrod rule (value = 4); * `Integration::kGAUSS51` : 51 points Gauss-Konrod rule (value = 5); * `Integration::kGAUSS61` : 61 points Gauss-Konrod rule (value = 6); 	 The higher-order rules give better accuracy for smooth functions, while lower-order rules save time when the function contains local difficulties, such as discontinuities. If no integration rule; 	 is passed, the 31 points rule is used as default. * 	 `ROOT::Math::Integration::kADAPTIVESINGULAR`: based on `gsl_integration_qags`. It is an integration type which can be used in the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:56553,adapt,adaptiva,56553,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['adapt'],['adaptiva']
Energy Efficiency,"e are a lot of different ways to do this. :). .. _dss_sortedvectormap:. A sorted 'vector'; ^^^^^^^^^^^^^^^^^. If your usage pattern follows a strict insert-then-query approach, you can; trivially use the same approach as :ref:`sorted vectors for set-like containers; <dss_sortedvectorset>`. The only difference is that your query function (which; uses std::lower_bound to get efficient log(n) lookup) should only compare the; key, not both the key and value. This yields the same advantages as sorted; vectors for sets. .. _dss_stringmap:. llvm/ADT/StringMap.h; ^^^^^^^^^^^^^^^^^^^^. Strings are commonly used as keys in maps, and they are difficult to support; efficiently: they are variable length, inefficient to hash and compare when; long, expensive to copy, etc. StringMap is a specialized container designed to; cope with these issues. It supports mapping an arbitrary range of bytes to an; arbitrary other object. The StringMap implementation uses a quadratically-probed hash table, where the; buckets store a pointer to the heap allocated entries (and some other stuff).; The entries in the map must be heap allocated because the strings are variable; length. The string data (key) and the element object (value) are stored in the; same allocation with the string data immediately after the element object.; This container guarantees the ""``(char*)(&Value+1)``"" points to the key string; for a value. The StringMap is very fast for several reasons: quadratic probing is very cache; efficient for lookups, the hash value of strings in buckets is not recomputed; when looking up an element, StringMap rarely has to touch the memory for; unrelated objects when looking up a value (even when hash collisions happen),; hash table growth does not recompute the hash values for strings already in the; table, and each pair in the map is store in a single allocation (the string data; is stored in the same allocation as the Value of a pair). StringMap also provides query methods that take byte ran",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:88924,allocate,allocated,88924,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"e corresponds; to the level 0 in the stored array, while the last node will correspond; to level `n`. For each level, the node, volume and global matrix can be; retrieved using corresponding getters:. ~~~{.cpp}; TGeoHMatrix *GetMatrix(Int_t level=-1) const; TGeoNode *GetNode(Int_t level=-1) const; TGeoShape *GetShape(Int_t level=-1) const; TGeoVolume *GetVolume(Int_t level=-1) const; ~~~. By default the object at level n is retrieved (the align-able object). Once created, a physical node can be misaligned, meaning that its; positioning matrix or even the shape.:. ~~~{.cpp}; void Align(TGeoMatrix* newmat=0, TGeoShape* newshape=0,; Bool_t check=kFALSE); ~~~. The convention used is that newmat represents the new local matrix of; the last node in the branch with respect to its mother volume. The; `Align()` method will actually duplicate the corresponding branch within; the logical hierarchy, creating new volumes and nodes. This is mandatory; in order to avoid problems due to replicated volumes and can create; exhaustive memory consumption if used abusively. Once aligned, a physical node is ready to be tracked. The operation can; be done only after the geometry was closed. Important NOTE: Calling the `Align()` method for a physical node changes; the node pointers for the stored node branch in the active geometry, Due; to this the other defined physical nodes containing elements of this; path will be invalid. Example:. ~~~{.cpp}; TGeoPhysicalNode *pn1 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_2"");; TGeoPhysicalNode *pn2 =; gGeoManager->MakePhysicalNode(""/A_1/B_1/C_3"");; ...; pn1->Align(...);; ~~~. The call to `pn1->Align()` will invalidate the pointer to the node `B_1`; in `pn2` object.. The way out is to either call `pn1->Align()` before; the creation of `pn2`, either to use a global method that will correct; all existing physical nodes:. ~~~{.cpp}; void RefreshPhysicalNodes(Bool_t lock = kTRUE); ~~~. The method above will optionally lock the possibility of doing any; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:109606,consumption,consumption,109606,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['consumption'],['consumption']
Energy Efficiency,"e creating the volume; itself, so we will describe the bits and pieces needed for making the; geometry before moving to an architectural point of view. As far as materials are concerned, they represent the physical; properties of the solid from which a volume is made. Materials are just; a support for the data that has to be provided to the tracking engine; that uses this geometry package. Due to this fact, the; **`TGeoMaterial`** class is more like a thin data structure needed for; building the corresponding native materials of the Monte-Carlo tracking; code that uses **`TGeo`**. ### Elements, Materials and Mixtures. In order to make easier material and mixture creation, one can use the; pre-built table of elements owned by **`TGeoManager`** class:. ``` {.cpp}; TGeoElementTable *table = gGeoManager->GetElementTable();; TGeoElement *element1 = table->GetElement(Int_t Z);; TGeoElement *element2 = table->FindElement(""Copper"");; ```. Materials made of single elements can be defined by their atomic mass; (`A`), charge (`Z`) and density (`rh`o). One can also create a material; by specifying the element that it is made of. Optionally the radiation; and absorption lengths can be also provided; otherwise they can be; computed on-demand [`G3`]. The class representing them is; **`TGeoMaterial`**:. ``` {.cpp}; TGeoMaterial(const char *name,Double_t a,Double_t z,; Double_t density, Double_t radlen=0,Double_t intlen=0);; TGeoMaterial(const char *name, TGeoElement *elem,; Double_t density);; TGeoMaterial(const char* name, Double_t a, Double_t z,; Double_t rho,; TGeoMaterial::EGeoMaterialState state,; Double_t temperature = STP_temperature,; Double_t pressure = STP_pressure); ```. Any material or derived class is automatically indexed after creation.; The assigned index is corresponding to the last entry in the list of; materials owned by **`TGeoManager`** class. This can be changed using; the **`TGeoMaterial`**`::SetIndex()` method, however it is not; recommended while using the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:14140,charge,charge,14140,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['charge'],['charge']
Energy Efficiency,"e definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL. Â Â Â Â Â Â Â Â Â Â Â Â Â ; chain.AddFile(""root:// .....?msd=CERN""). Â and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is; Â Â Â Â Â Â Â Â Â ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5033,monitor,monitor,5033,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,2,['monitor'],['monitor']
Energy Efficiency,"e done |; +------------+-------------+------------------------+---------------------------------+. .. _coro.end.results:. 'llvm.coro.end.results' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.end.results(...). Overview:; """""""""""""""""". The '``llvm.coro.end.results``' intrinsic captures values to be returned from; unique-suspend returned-continuation coroutines. Arguments:; """""""""""""""""""". The number of arguments must match the return type of the continuation function:. - if the return type of the continuation function is ``void`` there must be no; arguments. - if the return type of the continuation function is a ``struct``, the arguments; will be of element types of that ``struct`` in order;. - otherwise, it is just the return value of the continuation function. .. code-block:: llvm. define {ptr, ptr} @g(ptr %buffer, ptr %ptr, i8 %val) presplitcoroutine {; entry:; %id = call token @llvm.coro.id.retcon.once(i32 8, i32 8, ptr %buffer,; ptr @prototype,; ptr @allocate, ptr @deallocate); %hdl = call ptr @llvm.coro.begin(token %id, ptr null). ... cleanup:; %tok = call token (...) @llvm.coro.end.results(i8 %val); call i1 @llvm.coro.end(ptr %hdl, i1 0, token %tok); unreachable. ... declare i8 @prototype(ptr, i1 zeroext); . 'llvm.coro.end.async' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i1 @llvm.coro.end.async(ptr <handle>, i1 <unwind>, ...). Overview:; """""""""""""""""". The '``llvm.coro.end.async``' marks the point where execution of the resume part; of the coroutine should end and control should return to the caller. As part of; its variable tail arguments this instruction allows to specify a function and; the function's arguments that are to be tail called as the last action before; returning. Arguments:; """""""""""""""""""". The first argument should refer to the coroutine handle of the enclosing; coroutine. A frontend is allowed to supply null as the first parameter, in this; case `coro-early` pass will replace the null with a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:48047,allocate,allocate,48047,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['allocate'],['allocate']
Energy Efficiency,"e embedded in the node type ``T``, usually; ``T`` publicly derives from ``ilist_node<T>``. .. _dss_ilist_sentinel:. Sentinels; ^^^^^^^^^. ``ilist``\ s have another specialty that must be considered. To be a good; citizen in the C++ ecosystem, it needs to support the standard container; operations, such as ``begin`` and ``end`` iterators, etc. Also, the; ``operator--`` must work correctly on the ``end`` iterator in the case of; non-empty ``ilist``\ s. The only sensible solution to this problem is to allocate a so-called *sentinel*; along with the intrusive list, which serves as the ``end`` iterator, providing; the back-link to the last element. However conforming to the C++ convention it; is illegal to ``operator++`` beyond the sentinel and it also must not be; dereferenced. These constraints allow for some implementation freedom to the ``ilist`` how to; allocate and store the sentinel. The corresponding policy is dictated by; ``ilist_traits<T>``. By default a ``T`` gets heap-allocated whenever the need; for a sentinel arises. While the default policy is sufficient in most cases, it may break down when; ``T`` does not provide a default constructor. Also, in the case of many; instances of ``ilist``\ s, the memory overhead of the associated sentinels is; wasted. To alleviate the situation with numerous and voluminous; ``T``-sentinels, sometimes a trick is employed, leading to *ghostly sentinels*. Ghostly sentinels are obtained by specially-crafted ``ilist_traits<T>`` which; superpose the sentinel with the ``ilist`` instance in memory. Pointer; arithmetic is used to obtain the sentinel, which is relative to the ``ilist``'s; ``this`` pointer. The ``ilist`` is augmented by an extra pointer, which serves; as the back-link of the sentinel. This is the only field in the ghostly; sentinel which can be legally accessed. .. _dss_other:. Other Sequential Container options; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Other STL containers are available, such as ``std::string``. There are a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:69681,allocate,allocated,69681,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"e files 1.000000; Info in <TCanvas::Print>:; file ResistanceDistribution.png has been created; *==* ----- End of Job ----- Date/Time = Wed Feb 15 23:00:08 2012; Lite-0: all output objects have been merged; ```. Log files of the whole processing chain are kept in the directory; `~.proof` for each worker node. This is very helpful for debugging or if; something goes wrong. As the method described here also works without; using PROOF, the development work on an analysis script can be done in; the standard way on a small subset of the data, and only for the full; processing one would use parallelism via PROOF. It is worth to remind the reader that the speed of typical data analysis; programs limited by the I/O speed (for example the latencies implied by; reading data from a hard drive). It is therefore expected that this; limitation cannot be eliminated with the usage of any parallel analysis; toolkit. ### Optimisation Regarding N-tuples ###. ROOT automatically applies compression algorithms on n-tuples to reduce; the memory consumption. A value that is in most cases the same will; consume only small space on your disk (but it has to be decompressed on; reading). Nevertheless, you should think about the design of your; n-tuples and your analyses as soon as the processing time exceeds some; minutes. - Try to keep your n-tuples simple and use appropriate variable types.; If your measurement has only a limited precision, it is needless to; store it with double precision. - Experimental conditions that do not change with every single; measurement should be stored in a separate tree. Although the; compression can handle redundant values, the processing time; increase with every variable that has to be filled. - The function `SetCacheSize(long)` specifies the size of the cache; for reading a `TTree` object from a file. The default value is 30MB.; A manual increase may help in certain situations. Please note that; the caching mechanism can cover only one `TTree` object per `TFi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:13338,reduce,reduce,13338,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,2,"['consumption', 'reduce']","['consumption', 'reduce']"
Energy Efficiency,"e files:. #. a.out.0.0.preopt.bc (Before any link-time optimizations (LTO) are applied); #. a.out.0.2.internalize.bc (After initial optimizations are applied); #. a.out.0.4.opt.bc (After an extensive set of optimizations); #. a.out.0.5.precodegen.bc (After LTO but before translating into machine code). Execute one of the following commands to identify the source of the problem:. #. ``opt ""-passes=lto<O3>"" a.out.0.2.internalize.bc``; #. ``llc a.out.0.5.precodegen.bc``. If one of these do crash, you should be able to reduce; this with :program:`llvm-reduce`; command line (use the bc file corresponding to the command above that failed):. .. code-block:: bash. llvm-reduce --test reduce.sh a.out.0.2.internalize.bc. Example of reduce.sh script. .. code-block:: bash. $ cat reduce.sh; #!/bin/bash -e. path/to/not --crash path/to/opt ""-passes=lto<O3>"" $1 -o temp.bc 2> err.log; grep -q ""It->second == &Insn"" err.log. Here we have grepped the failed assert message. Please run this, then file a bug with the instructions and reduced .bc file; that llvm-reduce emits. .. _miscompiling:. Miscompilations; ===============. If clang successfully produces an executable, but that executable doesn't run; right, this is either a bug in the code or a bug in the compiler. The first; thing to check is to make sure it is not using undefined behavior (e.g.; reading a variable before it is defined). In particular, check to see if the; program is clean under various `sanitizers; <https://github.com/google/sanitizers>`_ (e.g. ``clang; -fsanitize=undefined,address``) and `valgrind <http://valgrind.org/>`_. Many; ""LLVM bugs"" that we have chased down ended up being bugs in the program being; compiled, not LLVM. Once you determine that the program itself is not buggy, you should choose; which code generator you wish to compile the program with (e.g. LLC or the JIT); and optionally a series of LLVM passes to run. For example:. .. code-block:: bash. bugpoint -run-llc [... optzn passes ...] file-to-test.bc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:7882,reduce,reduced,7882,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduced']
Energy Efficiency,"e goal of this tutorial is to introduce you to LLVM's ORC JIT APIs, show how; these APIs interact with other parts of LLVM, and to teach you how to recombine; them to build a custom JIT that is suited to your use-case. The structure of the tutorial is:. - Chapter #1: Investigate the simple KaleidoscopeJIT class. This will; introduce some of the basic concepts of the ORC JIT APIs, including the; idea of an ORC *Layer*. - `Chapter #2 <BuildingAJIT2.html>`_: Extend the basic KaleidoscopeJIT by adding; a new layer that will optimize IR and generated code. - `Chapter #3 <BuildingAJIT3.html>`_: Further extend the JIT by adding a; Compile-On-Demand layer to lazily compile IR. - `Chapter #4 <BuildingAJIT4.html>`_: Improve the laziness of our JIT by; replacing the Compile-On-Demand layer with a custom layer that uses the ORC; Compile Callbacks API directly to defer IR-generation until functions are; called. - `Chapter #5 <BuildingAJIT5.html>`_: Add process isolation by JITing code into; a remote process with reduced privileges using the JIT Remote APIs. To provide input for our JIT we will use a lightly modified version of the; Kaleidoscope REPL from `Chapter 7 <LangImpl07.html>`_ of the ""Implementing a; language in LLVM tutorial"". Finally, a word on API generations: ORC is the 3rd generation of LLVM JIT API.; It was preceded by MCJIT, and before that by the (now deleted) legacy JIT.; These tutorials don't assume any experience with these earlier APIs, but; readers acquainted with them will see many familiar elements. Where appropriate; we will make this connection with the earlier APIs explicit to help people who; are transitioning from them to ORC. JIT API Basics; ==============. The purpose of a JIT compiler is to compile code ""on-the-fly"" as it is needed,; rather than compiling whole programs to disk ahead of time as a traditional; compiler does. To support that aim our initial, bare-bones JIT API will have; just two functions:. 1. ``Error addModule(std::unique_ptr<Module",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst:1916,reduce,reduced,1916,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,1,['reduce'],['reduced']
Energy Efficiency,"e handling of ACLiC options on the command line (for example a.C+g).; In TClass::BuildEmulatedRealData properly handle the case of TNamed member that are not base class.; On the command line:; ; Fix the tab-completion of filenames in the sub-directories.; Prevent the unadvertent replacement of an arrow with a dot when the left side is actually a pointer. More user friendly stacktrace in case of a crash, with hints where; the problem might be. On Linux and MacOS X these stacktraces are generated; by the script $ROOTSYS/etc/gdb-backtrace.sh. Using the Root.StackTraceMessage; resource one can customize the message printed by the script. The entire; script can be replaced using the Root.StacktraceScript resource.; Numerous minor bug fixes... New module editline ; The new module editline enhances the prompt, giving type and syntax feedback using e.g. colors.; Class names are highlighted blue when typed, indicating that it is known to ROOT.; Matching parenthesis pairs are highlighted green when typed, or when the cursor is moved to a bracket. This works for () {} and [] brackets.; Any mismatched brackets (those without a matching partner) will be highlighted red when typed or when the cursor is moved to the bracket.; Tab completion output is colored magenta to differentiate between tab completion output and user input.; All of the colors are configurable in the .rootrc file.; They can be specified as #rgb or #rrggbb or color names:; black, red, green, yellow, blue, magenta, cyan or white.; They can be followed by an optional bold (alias light) or underlined.; Rint.ReverseColor allows to quickly toggle between the default ""light on dark"" (yes) instead of ""dark on light"" (no), depending on the terminal background.; An example configuration would be:. Rint.TypeColor: blue; Rint.BracketColor: bold green; Rint.BadBracketColor: underlined red; Rint.TabColor: magenta; Rint.PromptColor: black; Rint.ReverseColor: no. The enhanced prompt is available on all platforms with [n]curses",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v526/index.html:1714,green,green,1714,core/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v526/index.html,2,['green'],['green']
Energy Efficiency,"e i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43129,schedul,scheduled,43129,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"e i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:656086,reduce,reduce,656086,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"e implementation featured in; `Chromium <https://cs.chromium.org/chromium/src/components/gwp_asan/>`_. The; long-term support goal is to ensure feature-parity where reasonable, and to; support compiler-rt as the reference implementation. Allocator Support; -----------------. GWP-ASan is not a replacement for a traditional allocator. Instead, it works by; inserting stubs into a supporting allocator to redirect allocations to GWP-ASan; when they're chosen to be sampled. These stubs are generally implemented in the; implementation of ``malloc()``, ``free()`` and ``realloc()``. The stubs are; extremely small, which makes using GWP-ASan in most allocators fairly trivial.; The stubs follow the same general pattern (example ``malloc()`` pseudocode; below):. .. code:: cpp. #ifdef INSTALL_GWP_ASAN_STUBS; gwp_asan::GuardedPoolAllocator GWPASanAllocator;; #endif. void* YourAllocator::malloc(..) {; #ifdef INSTALL_GWP_ASAN_STUBS; if (GWPASanAllocator.shouldSample(..)); return GWPASanAllocator.allocate(..);; #endif. // ... the rest of your allocator code here.; }. Then, all the supporting allocator needs to do is compile with; ``-DINSTALL_GWP_ASAN_STUBS`` and link against the GWP-ASan library! For; performance reasons, we strongly recommend static linkage of the GWP-ASan; library. Guarded Allocation Pool; -----------------------. The core of GWP-ASan is the guarded allocation pool. Each sampled allocation is; backed using its own *guarded* slot, which may consist of one or more accessible; pages. Each guarded slot is surrounded by two *guard* pages, which are mapped as; inaccessible. The collection of all guarded slots makes up the *guarded; allocation pool*. Buffer Underflow/Overflow Detection; -----------------------------------. We gain buffer-overflow and buffer-underflow detection through these guard; pages. When a memory access overruns the allocated buffer, it will touch the; inaccessible guard page, causing memory exception. This exception is caught and; handled by the in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:2844,allocate,allocate,2844,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['allocate'],['allocate']
Energy Efficiency,"e integer constant.; - ``M``: Print as a register set suitable for ldm/stm. Also prints *all*; register operands subsequent to the specified one (!), so use carefully.; - ``Q``: Print the low-order register of a register-pair, or the low-order; register of a two-register operand.; - ``R``: Print the high-order register of a register-pair, or the high-order; register of a two-register operand.; - ``H``: Print the second register of a register-pair. (On a big-endian system,; ``H`` is equivalent to ``Q``, and on little-endian system, ``H`` is equivalent; to ``R``.). .. FIXME: H doesn't currently support printing the second register; of a two-register operand. - ``e``: Print the low doubleword register of a NEON quad register.; - ``f``: Print the high doubleword register of a NEON quad register.; - ``m``: Print the base register of a memory operand without the ``[`` and ``]``; adornment. Hexagon:. - ``L``: Print the second register of a two-register operand. Requires that it; has been allocated consecutively to the first. .. FIXME: why is it restricted to consecutive ones? And there's; nothing that ensures that happens, is there?. - ``I``: Print the letter 'i' if the operand is an integer constant, otherwise; nothing. Used to print 'addi' vs 'add' instructions. LoongArch:. - ``z``: Print $zero register if operand is zero, otherwise print it normally. MSP430:. No additional modifiers. MIPS:. - ``X``: Print an immediate integer as hexadecimal; - ``x``: Print the low 16 bits of an immediate integer as hexadecimal.; - ``d``: Print an immediate integer as decimal.; - ``m``: Subtract one and print an immediate integer as decimal.; - ``z``: Print $0 if an immediate zero, otherwise print normally.; - ``L``: Print the low-order register of a two-register operand, or prints the; address of the low-order word of a double-word memory operand. .. FIXME: L seems to be missing memory operand support. - ``M``: Print the high-order register of a two-register operand, or prints the; addre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:237322,allocate,allocated,237322,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"e is incompatible with the ``minsize``, ``optsize``, and; ``optnone`` attributes.; ``optforfuzzing``; This attribute indicates that this function should be optimized; for maximum fuzzing signal.; ``optnone``; This function attribute indicates that most optimization passes will skip; this function, with the exception of interprocedural optimization passes.; Code generation defaults to the ""fast"" instruction selector.; This attribute cannot be used together with the ``alwaysinline``; attribute; this attribute is also incompatible; with the ``minsize``, ``optsize``, and ``optdebug`` attributes. This attribute requires the ``noinline`` attribute to be specified on; the function as well, so the function is never inlined into any caller.; Only functions with the ``alwaysinline`` attribute are valid; candidates for inlining into the body of this function.; ``optsize``; This attribute suggests that optimization passes and code generator; passes make choices that keep the code size of this function low,; and otherwise do optimizations specifically to reduce code size as; long as they do not significantly impact runtime performance.; This attribute is incompatible with the ``optdebug`` and ``optnone``; attributes.; ``""patchable-function""``; This attribute tells the code generator that the code; generated for this function needs to follow certain conventions that; make it possible for a runtime function to patch over it later.; The exact effect of this attribute depends on its string value,; for which there currently is one legal possibility:. * ``""prologue-short-redirect""`` - This style of patchable; function is intended to support patching a function prologue to; redirect control away from the function in a thread safe; manner. It guarantees that the first instruction of the; function will be large enough to accommodate a short jump; instruction, and will be sufficiently aligned to allow being; fully changed via an atomic compare-and-swap instruction.; While the first requir",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:96600,reduce,reduce,96600,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"e models are generated by TableGen by the SubtargetEmitter,; using the ``CodeGenSchedModels`` class. This is distinct from the itinerary; method of specifying machine resource use. The tool ``utils/schedcover.py``; can be used to determine which instructions have been covered by the; schedule model description and which haven't. The first step is to use the; instructions below to create an output file. Then run ``schedcover.py`` on the; output file:. .. code-block:: shell. $ <src>/utils/schedcover.py <build>/lib/Target/AArch64/tblGenSubtarget.with; instruction, default, CortexA53Model, CortexA57Model, CycloneModel, ExynosM3Model, FalkorModel, KryoModel, ThunderX2T99Model, ThunderXT8XModel; ABSv16i8, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_2VXVY_2cyc, KryoWrite_2cyc_XY_XY_150ln, ,; ABSv1i64, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_1VXVY_2cyc, KryoWrite_2cyc_XY_noRSV_67ln, ,; ... To capture the debug output from generating a schedule model, change to the; appropriate target directory and use the following command:; command with the ``subtarget-emitter`` debug option:. .. code-block:: shell. $ <build>/bin/llvm-tblgen -debug-only=subtarget-emitter -gen-subtarget \; -I <src>/lib/Target/<target> -I <src>/include \; -I <src>/lib/Target <src>/lib/Target/<target>/<target>.td \; -o <build>/lib/Target/<target>/<target>GenSubtargetInfo.inc.tmp \; > tblGenSubtarget.dbg 2>&1. Where ``<build>`` is the build directory, ``src`` is the source directory,; and ``<target>`` is the name of the target.; To double check that the above command is what is needed, one can capture the; exact TableGen command from a build by using:. .. code-block:: shell. $ VERBOSE=1 make ... and search for ``llvm-tblgen`` commands in the output. Instruction Relation Mapping; ----------------------------. This TableGen feature is used to relate instructions with each other. It is; particularly useful when you have multiple instruction formats and need to; switch between them after instruction sele",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:43992,schedul,schedule,43992,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['schedul'],['schedule']
Energy Efficiency,"e of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAGBuilder`` class. The intent of this pass; is to expose as much low-level, target-specific details to the SelectionDAG as; possible. This pass is mostly hard-coded (e.g. an LLVM ``add`` turns into an; ``SDNode add`` while a ``getelementptr`` is expanded into the obvious; arithmetic). This pass requires target-specific hooks to lower calls, returns,; varargs, etc. For these features, the :raw-html:`<tt>` `TargetLowering`_; :raw-html:`</tt>` interface is used. .. _legalize types:; .. _Legalize SelectionDAG Types:; .. _Legalize SelectionDAG Ops:. SelectionDAG LegalizeTypes Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the types that; are natively supported by the target. There are two main ways of converting values of unsupported scalar types to; values of supported types: converting small types to larger types (""promoting""),; and breaking up large integer types into smaller ones (""expanding""). For; example, a target might require that all f32 values are promoted to f64 and that; all i1/i8/i16 values are promoted to i32. The same target might require that; all i64 values be expanded into pairs of i32 values. These changes can insert; sign and zero extensions as needed to make sure that the final code has the same; behavior as the input. There are two main ways of converting values of unsupported vector types to; value of supported types: splitting vector types, multiple times if necessary,; until a legal type is found, and extending vector types by adding elements to; the end to round them out to legal types (""widening""). If a vector gets split; all the way down to single-element parts with no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:40972,charge,charge,40972,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['charge'],['charge']
Energy Efficiency,"e or @protocol; declaration. Clang does not allow variable declarations to appear; within these declarations unless they are marked extern.; Variables may still be declared in an @implementation. @interface XX; int a; // not allowed in clang; int b = 1; // not allowed in clang; extern int c; // allowed; @end. C++ compatibility. Variable-length arrays. GCC and C99 allow an array's size to be determined at run; time. This extension is not permitted in standard C++. However, Clang; supports such variable length arrays for compatibility with GNU C and; C99 programs.; If you would prefer not to use this extension, you can disable it with; -Werror=vla. There are several ways to fix your code:. replace the variable length array with a fixed-size array if you can; determine a reasonable upper bound at compile time; sometimes this is as; simple as changing int size = ...; to const int size; = ...; (if the initializer is a compile-time constant);; use std::vector or some other suitable container type;; or; allocate the array on the heap instead using new Type[] -; just remember to delete[] it. Unqualified lookup in templates. Some versions of GCC accept the following invalid code:. template <typename T> T Squared(T x) {; return Multiply(x, x);; }. int Multiply(int x, int y) {; return x * y;; }. int main() {; Squared(5);; }. Clang complains:. my_file.cpp:2:10: error: call to function 'Multiply' that is neither visible in the template definition nor found by argument-dependent lookup; return Multiply(x, x);; ^; my_file.cpp:10:3: note: in instantiation of function template specialization 'Squared<int>' requested here; Squared(5);; ^; my_file.cpp:5:5: note: 'Multiply' should be declared prior to the call site; int Multiply(int x, int y) {; ^. The C++ standard says that unqualified names like Multiply; are looked up in two ways. First, the compiler does unqualified lookup in the scope; where the name was written. For a template, this means the lookup is; done at the point where th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html:11652,allocate,allocate,11652,interpreter/llvm-project/clang/www/compatibility.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html,2,['allocate'],['allocate']
Energy Efficiency,"e recorded in the history; file `$HOME/.root_hist`. It is a text file, and you can edit, cut, and; paste from it. You can specify the history file in the `system.rootrc`; file, by setting the `Rint.History `option. You can also turn off the; command logging in the `system.rootrc` file with the option:; `Rint.History: -`. The number of history lines to be kept can be set also in `.rootrc`; by:. ```; Rint.HistSize: 500; Rint.HistSave: 400; ```. The first value defines the maximum of lines kept; once it is reached; all, the last `HistSave` lines will be removed. One can set `HistSize`; to 0 to disable history line management. There is also implemented an; environment variable called `ROOT_HIST`. By setting; `ROOT_HIST=300:200` the above values can be overriden - the first; value corresponds to `HistSize`, the (optional) second one to; `HistSave`. You can set `ROOT_HIST=0` to disable the history. ### Tracking Memory Leaks. You can track memory usage and detect leaks by monitoring the number; of objects that are created and deleted (see **`TObjectTable`**). To; use this facility, edit the file `$ROOTSYS/etc/system.rootrc` or; `.rootrc` if you have this file and add the two following lines:. ```; Root.ObjectStat: 1; ```. In your code or on the command line you can type the line:. ``` {.cpp}; gObjectTable->Print();; ```. This line will print the list of all active classes and the number of; instances for each class. By comparing consecutive print outs, you can; see objects that you forgot to delete. Note that this method cannot; show leaks coming from the allocation of non-objects or classes; unknown to ROOT. ## Converting from PAW to ROOT. The web page at:; <http://root.cern.ch/root/HowtoConvertFromPAW.html#TABLE> gives the; ""translation"" table of some commonly used PAW commands into ROOT. If; you move the mouse cursor over the picture at:; <http://root.cern.ch/root/HowtoConvertFromPAW.html#SET>, you will get; the corresponding ROOT commands as tooltips. ### Converting HB",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md:39510,monitor,monitoring,39510,documentation/users-guide/GettingStarted.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md,1,['monitor'],['monitoring']
Energy Efficiency,"e reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpointâ€™s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test thatâ€™s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpointâ€™s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isnâ€™t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. Itâ€™s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduceâ€™s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the toolâ€™s beha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1396,reduce,reduce,1396,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md,1,['reduce'],['reduce']
Energy Efficiency,"e result vector type. The fifth operand is the explicit vector length of; the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.fmuladd``' intrinsic performs floating-point multiply-add (:ref:`llvm.fuladd <int_fmuladd>`); of the first, second, and third vector operand on each enabled lane. The result; on disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.fmuladd.v4f32(<4 x float> %a, <4 x float> %b, <4 x float> %c, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.fmuladd(<4 x float> %a, <4 x float> %b, <4 x float> %c); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_reduce_add:. '``llvm.vp.reduce.add.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.add.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.add.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``ADD`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.add``' intrinsic performs the integer ``ADD`` reduction; (:ref:`llvm.vector.reduce.add <int_vector_reduce",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:748417,reduce,reduce,748417,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"e shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Lua License; ------. ### Included only if built with Lua support. http://www.lua.org/license.html. > Copyright (C) 1994-2020 Lua.org, PUC-Rio.; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. SQLite3 License; ------. ### Included only if built with Lua and SQLite support. http://www.sqlite.org/copyright.html. > 2001-09-15; >; > The author disclaims copyright to this source code. In place of; > a legal notice",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:1767,charge,charge,1767,net/http/civetweb/LICENSE.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md,1,['charge'],['charge']
Energy Efficiency,"e signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific propert",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42485,schedul,scheduled,42485,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"e the default policy is sufficient in most cases, it may break down when; ``T`` does not provide a default constructor. Also, in the case of many; instances of ``ilist``\ s, the memory overhead of the associated sentinels is; wasted. To alleviate the situation with numerous and voluminous; ``T``-sentinels, sometimes a trick is employed, leading to *ghostly sentinels*. Ghostly sentinels are obtained by specially-crafted ``ilist_traits<T>`` which; superpose the sentinel with the ``ilist`` instance in memory. Pointer; arithmetic is used to obtain the sentinel, which is relative to the ``ilist``'s; ``this`` pointer. The ``ilist`` is augmented by an extra pointer, which serves; as the back-link of the sentinel. This is the only field in the ghostly; sentinel which can be legally accessed. .. _dss_other:. Other Sequential Container options; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Other STL containers are available, such as ``std::string``. There are also various STL adapter classes such as ``std::queue``,; ``std::priority_queue``, ``std::stack``, etc. These provide simplified access; to an underlying container but don't affect the cost of the container itself. .. _ds_string:. String-like containers; ----------------------. There are a variety of ways to pass around and use strings in C and C++, and; LLVM adds a few new options to choose from. Pick the first option on this list; that will do what you need, they are ordered according to their relative cost. Note that it is generally preferred to *not* pass strings around as ``const; char*``'s. These have a number of problems, including the fact that they; cannot represent embedded nul (""\0"") characters, and do not have a length; available efficiently. The general replacement for '``const char*``' is; StringRef. For more information on choosing string containers for APIs, please see; :ref:`Passing Strings <string_apis>`. .. _dss_stringref:. llvm/ADT/StringRef.h; ^^^^^^^^^^^^^^^^^^^^. The StringRef class is a simple value class t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:70708,adapt,adapter,70708,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['adapt'],['adapter']
Energy Efficiency,"e type system in all sorts of interesting ways. Simple; arrays are very easy and are quite useful for many different; applications. Adding them is mostly an exercise in learning how the; LLVM `getelementptr <../../LangRef.html#getelementptr-instruction>`_ instruction; works: it is so nifty/unconventional, it `has its own; FAQ <../../GetElementPtr.html>`_!; - **standard runtime** - Our current language allows the user to access; arbitrary external functions, and we use it for things like ""printd""; and ""putchard"". As you extend the language to add higher-level; constructs, often these constructs make the most sense if they are; lowered to calls into a language-supplied runtime. For example, if; you add hash tables to the language, it would probably make sense to; add the routines to a runtime, instead of inlining them all the way.; - **memory management** - Currently we can only access the stack in; Kaleidoscope. It would also be useful to be able to allocate heap; memory, either with calls to the standard libc malloc/free interface; or with a garbage collector. If you would like to use garbage; collection, note that LLVM fully supports `Accurate Garbage; Collection <../../GarbageCollection.html>`_ including algorithms that; move objects and need to scan/update the stack.; - **exception handling support** - LLVM supports generation of `zero; cost exceptions <../../ExceptionHandling.html>`_ which interoperate with; code compiled in other languages. You could also generate code by; implicitly making every function return an error value and checking; it. You could also make explicit use of setjmp/longjmp. There are; many different ways to go here.; - **object orientation, generics, database access, complex numbers,; geometric programming, ...** - Really, there is no end of crazy; features that you can add to the language.; - **unusual domains** - We've been talking about applying LLVM to a; domain that many people are interested in: building a compiler for a; specific la",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst:3336,allocate,allocate,3336,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,1,['allocate'],['allocate']
Energy Efficiency,"e used directly as; boxed literals (this avoids conflicts with future ``'@'``-prefixed; Objective-C keywords). Instead, an enum value must be placed inside a; boxed expression. The following example demonstrates configuring an; ``AVAudioRecorder`` using a dictionary that contains a boxed enumeration; value:. .. code-block:: objc. enum {; AVAudioQualityMin = 0,; AVAudioQualityLow = 0x20,; AVAudioQualityMedium = 0x40,; AVAudioQualityHigh = 0x60,; AVAudioQualityMax = 0x7F; };. - (AVAudioRecorder *)recordToFile:(NSURL *)fileURL {; NSDictionary *settings = @{ AVEncoderAudioQualityKey : @(AVAudioQualityMax) };; return [[AVAudioRecorder alloc] initWithURL:fileURL settings:settings error:NULL];; }. The expression ``@(AVAudioQualityMax)`` converts ``AVAudioQualityMax``; to an integer type, and boxes the value accordingly. If the enum has a; :ref:`fixed underlying type <objc-fixed-enum>` as in:. .. code-block:: objc. typedef enum : unsigned char { Red, Green, Blue } Color;; NSNumber *red = @(Red), *green = @(Green), *blue = @(Blue); // => [NSNumber numberWithUnsignedChar:]. then the fixed underlying type will be used to select the correct; ``NSNumber`` creation method. Boxing a value of enum type will result in a ``NSNumber`` pointer with a; creation method according to the underlying type of the enum, which can; be a :ref:`fixed underlying type <objc-fixed-enum>`; or a compiler-defined integer type capable of representing the values of; all the members of the enumeration:. .. code-block:: objc. typedef enum : unsigned char { Red, Green, Blue } Color;; Color col = Red;; NSNumber *nsCol = @(col); // => [NSNumber numberWithUnsignedChar:]. Boxed C Strings; ---------------. A C string literal prefixed by the ``'@'`` token denotes an ``NSString``; literal in the same way a numeric literal prefixed by the ``'@'`` token; denotes an ``NSNumber`` literal. When the type of the parenthesized; expression is ``(char *)`` or ``(const char *)``, the result of the; boxed expression is a poin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst:6343,green,green,6343,interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst,1,['green'],['green']
Energy Efficiency,"e used to identify the derived class.; * **IsActive**: indicates if the field is the active field of a union.; * **IsMutable**: indicates if the field is marked as mutable. Inline descriptors are filled in by the `CtorFn` of blocks, which leaves storage; in an uninitialised, but valid state. Descriptors; -----------. Descriptors are generated at bytecode compilation time and contain information; required to determine if a particular memory access is allowed in constexpr.; They also carry all the information required to emit a diagnostic involving; a memory access, such as the declaration which originates the block.; Currently there is a single kind of descriptor encoding information for all; block types. Pointers; --------. Pointers, implemented in ``Pointer.h`` are represented as a tagged union.; Some of these may not yet be available in upstream ``clang``. * **BlockPointer**: used to reference memory allocated and managed by the; interpreter, being the only pointer kind which allows dereferencing in the; interpreter; * **ExternPointer**: points to memory which can be addressed, but not read by; the interpreter. It is equivalent to APValue, tracking a declaration and a path; of fields and indices into that allocation.; * **TargetPointer**: represents a target address derived from a base address; through pointer arithmetic, such as ``((int *)0x100)[20]``. Null pointers are; target pointers with a zero offset.; * **TypeInfoPointer**: tracks information for the opaque type returned by; ``typeid``; * **InvalidPointer**: is dummy pointer created by an invalid operation which; allows the interpreter to continue execution. Does not allow pointer; arithmetic or dereferencing. Besides the previously mentioned union, a number of other pointer-like types; have their own type:. * **ObjCBlockPointer** tracks Objective-C blocks; * **FnPointer** tracks functions and lazily caches their compiled version; * **MemberPointer** tracks C++ object members. Void pointers, which can be bu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst:8859,allocate,allocated,8859,interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,1,['allocate'],['allocated']
Energy Efficiency,"e vectorizer may decide to fall back on fixed width; vectorization if the target does not support scalable vectors. The interleave count is specified by ``interleave_count(_value_)``, where; _value_ is a positive integer. This is useful for specifying the optimal; width/count of the set of target architectures supported by your application. .. code-block:: c++. #pragma clang loop vectorize_width(2); #pragma clang loop interleave_count(2); for(...) {; ...; }. Specifying a width/count of 1 disables the optimization, and is equivalent to; ``vectorize(disable)`` or ``interleave(disable)``. Vector predication is enabled by ``vectorize_predicate(enable)``, for example:. .. code-block:: c++. #pragma clang loop vectorize(enable); #pragma clang loop vectorize_predicate(enable); for(...) {; ...; }. This predicates (masks) all instructions in the loop, which allows the scalar; remainder loop (the tail) to be folded into the main vectorized loop. This; might be more efficient when vector predication is efficiently supported by the; target platform. Loop Unrolling; --------------. Unrolling a loop reduces the loop control overhead and exposes more; opportunities for ILP. Loops can be fully or partially unrolled. Full unrolling; eliminates the loop and replaces it with an enumerated sequence of loop; iterations. Full unrolling is only possible if the loop trip count is known at; compile time. Partial unrolling replicates the loop body within the loop and; reduces the trip count. If ``unroll(enable)`` is specified the unroller will attempt to fully unroll the; loop if the trip count is known at compile time. If the fully unrolled code size; is greater than an internal limit the loop will be partially unrolled up to this; limit. If the trip count is not known at compile time the loop will be partially; unrolled with a heuristically chosen unroll factor. .. code-block:: c++. #pragma clang loop unroll(enable); for(...) {; ...; }. If ``unroll(full)`` is specified the unroller will att",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:165920,efficient,efficient,165920,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['efficient'],"['efficient', 'efficiently']"
Energy Efficiency,"e+Asserts; build to use these features. .. _datastructure:. Picking the Right Data Structure for a Task; ===========================================. LLVM has a plethora of data structures in the ``llvm/ADT/`` directory, and we; commonly use STL data structures. This section describes the trade-offs you; should consider when you pick one. The first step is a choose your own adventure: do you want a sequential; container, a set-like container, or a map-like container? The most important; thing when choosing a container is the algorithmic properties of how you plan to; access the container. Based on that, you should use:. * a :ref:`map-like <ds_map>` container if you need efficient look-up of a; value based on another value. Map-like containers also support efficient; queries for containment (whether a key is in the map). Map-like containers; generally do not support efficient reverse mapping (values to keys). If you; need that, use two maps. Some map-like containers also support efficient; iteration through the keys in sorted order. Map-like containers are the most; expensive sort, only use them if you need one of these capabilities. * a :ref:`set-like <ds_set>` container if you need to put a bunch of stuff into; a container that automatically eliminates duplicates. Some set-like; containers support efficient iteration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not support; efficient look-up based on a key. * a :ref:`string <ds_string>` container is a specialized sequential container or; reference structure that is used for character or byte arrays. * a :ref:`bit <ds_bit>` container provides an efficient way to store and; perform set operations on sets of numeric id's, while automatical",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:55707,efficient,efficient,55707,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"e, version 2, hence; the version number 2.1.]. Preamble. The licenses for most software are designed to take away your; freedom to share and change it. By contrast, the GNU General Public; Licenses are intended to guarantee your freedom to share and change; free software--to make sure the software is free for all its users. This license, the Lesser General Public License, applies to some; specially designated software packages--typically libraries--of the; Free Software Foundation and other authors who decide to use it. You; can use it too, but we suggest you first think carefully about whether; this license or the ordinary General Public License is the better; strategy to use in any particular case, based on the explanations below. When we speak of free software, we are referring to freedom of use,; not price. Our General Public Licenses are designed to make sure that; you have the freedom to distribute copies of free software (and charge; for this service if you wish); that you receive source code or can get; it if you want it; that you can change the software and use pieces of; it in new free programs; and that you are informed that you can do; these things. To protect your rights, we need to make restrictions that forbid; distributors to deny you these rights or to ask you to surrender these; rights. These restrictions translate to certain responsibilities for; you if you distribute copies of the library or if you modify it. For example, if you distribute copies of the library, whether gratis; or for a fee, you must give the recipients all the rights that we gave; you. You must make sure that they, too, receive or can get the source; code. If you link other code with the library, you must provide; complete object files to the recipients, so that they can relink them; with the library after making changes to the library and recompiling; it. And you must show them these terms so they know their rights. We protect your rights with a two-step method: (1) we copyright",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt:1364,charge,charge,1364,LGPL2_1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt,2,['charge'],['charge']
Energy Efficiency,"e-1294211. LLVM has a StringMap class that is advertised as more efficient than; std::map<std::string, ValueType>. Mainly it does fewer allocations; because the key is not a std::string. Replace the use of std::map<std::string, ValueType> with String Map.; One specific case is the LVSymbolNames definitions. //===----------------------------------------------------------------------===//; // Calculate unique offset for CodeView elements.; //===----------------------------------------------------------------------===//; In order to have the same logical functionality as the ELF Reader, such; as:. - find scopes contribution to debug info; - sort by its physical location. The logical elements must have an unique offset (similar like the DWARF; DIE offset). //===----------------------------------------------------------------------===//; // Move 'initializeFileAndStringTables' to the COFF Library.; //===----------------------------------------------------------------------===//; There is some code in the CodeView reader that was extracted/adapted; from 'tools/llvm-readobj/COFFDumper.cpp' that can be moved to the COFF; library. We had a similar case with code shared with llvm-pdbutil that was moved; to the PDB library: https://reviews.llvm.org/D122226. //===----------------------------------------------------------------------===//; // Move 'getSymbolKindName'/'formatRegisterId' to the CodeView Library.; //===----------------------------------------------------------------------===//; There is some code in the CodeView reader that was extracted/adapted; from 'lib/DebugInfo/CodeView/SymbolDumper.cpp' that can be used. //===----------------------------------------------------------------------===//; // Use of std::unordered_set instead of std::set.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125784#inline-1221421. Replace the std::set usage for DeducedScopes, UnresolvedScopes and; IdentifiedNamespaces with std",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt:5598,adapt,adapted,5598,interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,2,['adapt'],['adapted']
Energy Efficiency,"e. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments is valid. In this case, all; variable operands are handled just like; ``llvm.experimental.stackmap.*``. The difference is that space will; still be reserved for patching, a call will be emitted, and a return; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:9695,allocate,allocated,9695,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['allocate'],['allocated']
Energy Efficiency,"e090.png). We have developed a new high resolution deconvolution algorithm. We have; observed that the Gold deconvolution converges to its stable state; (solution). It is useless to increase the number of iterations, the; result obtained does not change. To continue decreasing the width of; peaks, we have found that when the solution reaches its stable state, it; is necessary to stop iterations, then to change the vector in a way and; repeat again the Gold deconvolution. We have found that in order to change the; particular solution we need to apply a non-linear boosting function to it.; The power function proved to give the best results. At the beginning the; function calculates exact solution of the Toeplitz system of linear; equations. $$ x^{(0)} = [x_e^2(0),x_e^2(1),...,x_e^2(N-1),]^T$$; where; $$ x_e=H^{'-1}y^{'}$$. Then it applies the Gold deconvolution algorithm to the solution and; carries out preset number of iterations. Then the power function with; the exponent equal to the boosting coefficient is applied to the; deconvolved data. These data are then used as initial estimate of the; solution of linear system of equations and again the Gold algorithm is; employed. The whole procedure is repeated `number_of_repetitions` times. The form of the high-resolution deconvolution function is. ```{.cpp}; char *Deconvolution1HighResolution(float *source,; const float *resp,; int size,; int number_of_iterations,; int number_of_repetitions,; double boost);; ```. This function calculates deconvolution from the source spectrum according; to the response spectrum. The result is placed in the vector pointed by the source pointer. Function parameters:. - **`source`**: pointer to the vector of the source spectrum; - **`resp`**: pointer to the vector of the response spectrum; - **`size`**: length of source and the response spectra; - **`number_of_iterations`**: for details we refer to manual; - **`number_of_repetitions`**: for details we refer to manual; - **`boost`**: boosti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:28275,power,power,28275,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['power'],['power']
Energy Efficiency,"e; (named *Average Wait times*) reports useful timing statistics, which should; help diagnose performance bottlenecks caused by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and the second index is the; instruction index (i.e., where it appears in the code sequence). Since this; example was generated using 3 iterations: ``-iterations=3``, the iteration; indices range from 0-2 inclusively. Excluding the first and last column, the remaining columns are in cycles.; Cycles are numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become available. By the time vmulps is; dispatched, operands are already available, and pipeline JFPU1 is ready to; serve another instruction. So the instruction can be immediately issued on the; JFPU1 pipeline. That is demonstrated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:24268,schedul,scheduler,24268,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"e; result type. If only ``nnan`` is set then the neutral value is ``+Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>` intrinsic (and thus the; '``llvm.minnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmin.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float QNAN, float QNAN, float QNAN, float QNAN>; %reduction = call float @llvm.vector.reduce.fmin.v4f32(<4 x float> %masked.a); %also.r = call float @llvm.minnum.f32(float %reduction, float %start). .. _int_get_active_lane_mask:. '``llvm.get.active.lane.mask.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x i1> @llvm.get.active.lane.mask.v4i1.i32(i32 %base, i32 %n); declare <8 x i1> @llvm.get.active.lane.mask.v8i1.i64(i64 %base, i64 %n); declare <16 x i1> @llvm.get.active.lane.mask.v16i1.i64(i64 %base, i64 %n); declare <vscale x 16 x i1> @llvm.get.active.lane.mask.nxv16i1.i64(i64 %base, i64 %n). Overview:; """""""""""""""""". Create a mask representing active and inactive vector lanes. Arguments:; """""""""""""""""""". Both operands have the same scalar integer type. The result is a vector with; the i1 element type. Semantics:; """""""""""""""""""". The '``llvm.get.active.lane.mask.*``' intrinsics are semantically equivalent; to:. ::. %m[i] = icmp ult (%base + i), %n. where ``%m`` is a vector (mask) of active/inactive lane",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:776618,reduce,reduce,776618,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"e; result type. If only ``nnan`` is set then the neutral value is ``-Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>` intrinsic (and thus the; '``llvm.maxnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmax.v4f32(float %float, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float QNAN, float QNAN, float QNAN, float QNAN>; %reduction = call float @llvm.vector.reduce.fmax.v4f32(<4 x float> %masked.a); %also.r = call float @llvm.maxnum.f32(float %reduction, float %start). .. _int_vp_reduce_fmin:. '``llvm.vp.reduce.fmin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmin.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmin.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:773745,reduce,reduce,773745,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,eArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/ll,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338363,reduce,reduce,338363,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"e``, and; ""_ZnwmSt11align_val_t"" for aligned ``::operator::new`` and; ``::operator::delete``. Matching malloc/realloc/free calls within a family; can be optimized, but mismatched ones will be left alone.; ``allockind(""KIND"")``; Describes the behavior of an allocation function. The KIND string contains comma; separated entries from the following options:. * ""alloc"": the function returns a new block of memory or null.; * ""realloc"": the function returns a new block of memory or null. If the; result is non-null the memory contents from the start of the block up to; the smaller of the original allocation size and the new allocation size; will match that of the ``allocptr`` argument and the ``allocptr``; argument is invalidated, even if the function returns the same address.; * ""free"": the function frees the block of memory specified by ``allocptr``.; Functions marked as ""free"" ``allockind`` must return void.; * ""uninitialized"": Any newly-allocated memory (either a new block from; a ""alloc"" function or the enlarged capacity from a ""realloc"" function); will be uninitialized.; * ""zeroed"": Any newly-allocated memory (either a new block from a ""alloc""; function or the enlarged capacity from a ""realloc"" function) will be; zeroed.; * ""aligned"": the function returns memory aligned according to the; ``allocalign`` parameter. The first three options are mutually exclusive, and the remaining options; describe more details of how the function behaves. The remaining options; are invalid for ""free""-type functions.; ``allocsize(<EltSizeParam>[, <NumEltsParam>])``; This attribute indicates that the annotated function will always return at; least a given number of bytes (or null). Its arguments are zero-indexed; parameter numbers; if one argument is provided, then it's assumed that at; least ``CallSite.Args[EltSizeParam]`` bytes will be available at the; returned pointer. If two are provided, then it's assumed that; ``CallSite.Args[EltSizeParam] * CallSite.Args[NumEltsParam]`` bytes are;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:78920,allocate,allocated,78920,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"ease file bugs when you see issues of any kind so we can assess; where development on C++ analysis support needs to be focused.; To try out C++ analysis support, it should work out of the box using scan-build. If you are using this checker build; as a replacement to the analyzer bundled with Xcode, first use the set-xcode-analyzer script to change Xcode to use; your version of the analyzer. You will then need to modify one configuration file in Xcode to enable C++ analysis support. This can; be done with the following steps:. Find the clang .xcspec file:; $ cd /Developer/Library; $ find . | grep xcspec | grep Clang; ./Xcode/<SNIP>/Clang LLVM 1.0.xcplugin/Contents/Resources/Clang LLVM 1.0.xcspec. The exact location of the file may vary depending on your installation of Xcode. Edit that file, and look for the string ""--analyze"":. SourceFileOption = ""--analyze"";; FileTypes = (; ""sourcecode.c.c"",; ""sourcecode.c.objc"",; );; ... Change the ""FileTypes"" entry to:. FileTypes = (; ""sourcecode.c.c"",; ""sourcecode.c.objc"",; ""sourcecode.cpp.cpp"",; ""sourcecode.cpp.objcpp"",; );. Restart Xcode. checker-255; built: February 11, 2011; highlights:. Mac OS X builds are now Intel i386 and x86_64 only (no ppc support); Turns on new -init method checker by default; Reduces memory usage of analyzer by 10%; Misc. fixes to reduce false positives on dead stores and idempotent operations. checker-254; built: January 27, 2011; highlights:. Introduces new -init method checker to check if a super class's init method is properly called.; Objective-C retain/release checker now reasons about calls to property accessor methods (setter/getter).; Introduces new attribute ns_consumes_self to educate the Objective-C retain/release checker about custom ""init-like"" methods that do not follow the standard Cocoa naming conventions.; Introduces new attributes ns_consumed and cf_consumed to educate the Objective-C retain/release checker about methods/functions that decrement the reference count of a parameter. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:12955,reduce,reduce,12955,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,3,"['Reduce', 'reduce']","['Reduces', 'reduce']"
Energy Efficiency,"eated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %masked.a); %also.r = and i32 %reduction, %start. .. _int_vp_reduce_or:. '``llvm.vp.reduce.or.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.or.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.or.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``OR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.or``' intrinsic performs the integer ``OR`` reduction; (:ref:`llvm.vector.reduce.or <int_vector_reduce_or>`) of the vector operand; ``val`` on each enabled lane, performing an '``or``' of that with the scalar; ``start_va",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:758971,reduce,reduce,758971,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ecay`, `Delta`; and `Epsilon`. #### Steepest Descent Algorithm. Weights are set to the minimum along the line defined by the gradient.; The only parameter for this method is `Tau`. Lower `Tau` = higher; precision = slower search. A value `Tau=3` seems reasonable. #### Conjugate Gradients With the Polak-Ribiere Updating Formula. Weights are set to the minimum along the line defined by the conjugate; gradient. Parameters are `Tau` and `Reset`, which defines the epochs; where the direction is reset to the steepest descent (estimated by; using the Polak-Ribiere formula). #### Conjugate Gradients With the Fletcher-Reeves Updating Formula. Weights are set to the minimum along the line defined by the conjugate; gradient. Parameters are `Tau` and `Reset`, which defines the epochs; where the direction is reset to the steepest descent (estimated by; using the Fletcher-Reeves formula). #### The Broyden, Fletcher, Goldfarb, Shanno (BFGS) Method. It implies the computation of a `NxN` matrix, but seems more powerful; at least for less than 300 weights. Parameters are `Tau` and `Reset`,; which defines the epochs where the direction is reset to the steepest; descent. ### Using the Network. Neural network are build from a set of ""samples"". A sample is a set of; values defining the inputs and the corresponding output that the; network should ideally provide. In ROOT this is a **`TTree`** entry.; The first thing to be decided is the network layout. This layout is; described in a string where the layers are separated by semicolons.; The input/output layers are defined by giving the expression for each; neuron, separated by comas. Hidden layers are just described by the; number of neurons. In addition, input and output layer formulas can be preceded by '@'; (e.g. ""@out"") if one wants to normalize the corresponding value. Also,; if the string ends with '`!`', output neurons are set up for; classification, i.e. with a sigmoid (1 neuron) or softmax (more; neurons) activation function. Many ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:73903,power,powerful,73903,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['power'],['powerful']
Energy Efficiency,"ecial semantics of this; type mean that no arithmetic is ever performed directly on ``__fp16`` values;; see below. * ``_Float16`` is supported on the following targets:. * 32-bit ARM (natively on some architecture versions); * 64-bit ARM (AArch64) (natively on ARMv8.2a and above); * AMDGPU (natively); * SPIR (natively); * X86 (if SSE2 is available; natively if AVX512-FP16 is also available); * RISC-V (natively if Zfh or Zhinx is available). * ``__bf16`` is supported on the following targets (currently never natively):. * 32-bit ARM; * 64-bit ARM (AArch64); * RISC-V; * X86 (when SSE2 is available). (For X86, SSE2 is available on 64-bit and all recent 32-bit processors.). ``__fp16`` and ``_Float16`` both use the binary16 format from IEEE; 754-2008, which provides a 5-bit exponent and an 11-bit significand; (counting the implicit leading 1). ``__bf16`` uses the `bfloat16; <https://en.wikipedia.org/wiki/Bfloat16_floating-point_format>`_ format,; which provides an 8-bit exponent and an 8-bit significand; this is the same; exponent range as `float`, just with greatly reduced precision. ``_Float16`` and ``__bf16`` follow the usual rules for arithmetic; floating-point types. Most importantly, this means that arithmetic operations; on operands of these types are formally performed in the type and produce; values of the type. ``__fp16`` does not follow those rules: most operations; immediately promote operands of type ``__fp16`` to ``float``, and so; arithmetic operations are defined to be performed in ``float`` and so result in; a value of type ``float`` (unless further promoted because of other operands).; See below for more information on the exact specifications of these types. When compiling arithmetic on ``_Float16`` and ``__bf16`` for a target without; native support, Clang will perform the arithmetic in ``float``, inserting; extensions and truncations as necessary. This can be done in a way that; exactly matches the operation-by-operation behavior of native support,; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:31588,reduce,reduced,31588,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['reduce'],['reduced']
Energy Efficiency,"ecific files in a build, without affecting the main compilation flags; used for the other files in the project. In these cases, you can use the flag ``-fno-profile-instr-generate`` (or; ``-fno-profile-generate``) to disable profile generation, and; ``-fno-profile-instr-use`` (or ``-fno-profile-use``) to disable profile use. Note that these flags should appear after the corresponding profile; flags to have an effect. .. note::. When none of the translation units inside a binary is instrumented, in the; case of Fuchsia the profile runtime will not be linked into the binary and; no profile will be produced, while on other platforms the profile runtime; will be linked and profile will be produced but there will not be any; counters. Instrumenting only selected files or functions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes it's useful to only instrument certain files or functions. For; example in automated testing infrastructure, it may be desirable to only; instrument files or functions that were modified by a patch to reduce the; overhead of instrumenting a full system. This can be done using the ``-fprofile-list`` option. .. option:: -fprofile-list=<pathname>. This option can be used to apply profile instrumentation only to selected; files or functions. ``pathname`` should point to a file in the; :doc:`SanitizerSpecialCaseList` format which selects which files and; functions to instrument. .. code-block:: console. $ clang++ -O2 -fprofile-instr-generate -fprofile-list=fun.list code.cc -o code. The option can be specified multiple times to pass multiple files. .. code-block:: console. $ clang++ -O2 -fprofile-instr-generate -fcoverage-mapping -fprofile-list=fun.list -fprofile-list=code.list code.cc -o code. Supported sections are ``[clang]``, ``[llvm]``, and ``[csllvm]`` representing; clang PGO, IRPGO, and CSIRPGO, respectively. Supported prefixes are ``function``; and ``source``. Supported categories are ``allow``, ``skip``, and ``forbid``.; ``skip`` adds ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:116113,reduce,reduce,116113,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduce']
Energy Efficiency,"ecifically; for that purpose. The **`TTree`** class is optimized to reduce disk; space and enhance access speed. A **`TNtuple`** is a **`TTree`** that is; limited to only hold floating-point numbers; a **`TTree`** on the other; hand can hold all kind of data, such as objects or arrays in addition to; all the simple types. When using a **`TTree`**, we fill its branch buffers with leaf data and; the buffers are written to disk when it is full. Branches, buffers, and; leafs, are explained a little later in this chapter, but for now, it is; important to realize that each object is not written individually, but; rather collected and written a bunch at a time. This is where the **`TTree`** takes advantage of compression and will; produce a much smaller file than if the objects were written; individually. Since the unit to be compressed is a buffer, and the; **`TTree`** contains many same-class objects, the header of the objects; can be compressed. The **`TTree`** reduces the header of each object, but it still contains; the class name. Using compression, the class name of each same-class; object has a good chance of being compressed, since the compression; algorithm recognizes the bit pattern representing the class name. Using; a **`TTree`** and compression the header is reduced to about 4 bytes; compared to the original 60 bytes. However, if compression is turned; off, you will not see these large savings. The **`TTree`** is also used to optimize the data access. A tree uses a; hierarchy of branches, and each branch can be read independently from; any other branch. Now, assume that `Px` and `Py` are data members of the; event, and we would like to compute `Px2 + Py2` for every event; and histogram the result. If we had saved the million events without a **`TTree`** we would have; to:. - read each event in its entirety into memory; - extract the `Px` and `Py` from the event; - compute the sum of the squares; - fill a histogram. We would have to do that a million times! Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:1220,reduce,reduces,1220,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['reduce'],['reduces']
Energy Efficiency,"ecified section. If the; definition is located in a different section, the behavior is undefined. LLVM allows an explicit code model to be specified for globals. If the; target supports it, it will emit globals in the code model specified,; overriding the code model used to compile the translation unit.; The allowed values are ""tiny"", ""small"", ""kernel"", ""medium"", ""large"".; This may be extended in the future to specify global data layout that; doesn't cleanly fit into a specific code model. By default, global initializers are optimized by assuming that global; variables defined within the module are not modified from their; initial values before the start of the global initializer. This is; true even for variables potentially accessible from outside the; module, including those with external linkage or appearing in; ``@llvm.used`` or dllexported variables. This assumption may be suppressed; by marking the variable with ``externally_initialized``. An explicit alignment may be specified for a global, which must be a; power of 2. If not present, or if the alignment is set to zero, the; alignment of the global is set by the target to whatever it feels; convenient. If an explicit alignment is specified, the global is forced; to have exactly that alignment. Targets and optimizers are not allowed; to over-align the global if the global has an assigned section. In this; case, the extra alignment could be observable: for example, code could; assume that the globals are densely packed in their section and try to; iterate over them as an array, alignment padding would break this; iteration. For TLS variables, the module flag ``MaxTLSAlign``, if present,; limits the alignment to the given value. Optimizers are not allowed to; impose a stronger alignment on these variables. The maximum alignment; is ``1 << 32``. For global variable declarations, as well as definitions that may be; replaced at link time (``linkonce``, ``weak``, ``extern_weak`` and ``common``; linkage types), the a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:34454,power,power,34454,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"eclare { float, i32 } @llvm.frexp.f32.i32(float %Val); declare { double, i32 } @llvm.frexp.f64.i32(double %Val); declare { x86_fp80, i32 } @llvm.frexp.f80.i32(x86_fp80 %Val); declare { fp128, i32 } @llvm.frexp.f128.i32(fp128 %Val); declare { ppc_fp128, i32 } @llvm.frexp.ppcf128.i32(ppc_fp128 %Val); declare { <2 x float>, <2 x i32> } @llvm.frexp.v2f32.v2i32(<2 x float> %Val). Overview:; """""""""""""""""". The '``llvm.frexp.*``' intrinsics perform the frexp function. Arguments:; """""""""""""""""""". The argument is a :ref:`floating-point <t_floating>` or; :ref:`vector <t_vector>` of floating-point values. Returns two values; in a struct. The first struct field matches the argument type, and the; second field is an integer or a vector of integer values with the same; number of elements as the argument. Semantics:; """""""""""""""""""". This intrinsic splits a floating point value into a normalized; fractional component and integral exponent. For a non-zero argument, returns the argument multiplied by some power; of two such that the absolute value of the returned value is in the; range [0.5, 1.0), with the same sign as the argument. The second; result is an integer such that the first result raised to the power of; the second result is the input argument. If the argument is a zero, returns a zero with the same sign and a 0; exponent. If the argument is a NaN, a NaN is returned and the returned exponent; is unspecified. If the argument is an infinity, returns an infinity with the same sign; and an unspecified exponent. .. _int_log:. '``llvm.log.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.log`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.log.f32(float %Val); declare double @llvm.log.f64(double %Val); declare x86_fp80 @llvm.log.f80(x86_fp80 %Val); declare fp128 @llvm.log.f128(fp128 %Val); declare ppc_fp128 @llvm.log.ppcf128(ppc_fp128 %Val). Overview:;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:566988,power,power,566988,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instructi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43204,schedul,scheduled,43204,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"ector read from a TTreeReaderArray from root prompt; * [[ROOT-9261](https://its.cern.ch/jira/browse/ROOT-9261)] - TMatrixTSparse fails to transpose non-square matrices; * [[ROOT-9284](https://its.cern.ch/jira/browse/ROOT-9284)] - BUG (See description note) PyDoubleBuffer tolist and numpy array cause segfault.; * [[ROOT-9313](https://its.cern.ch/jira/browse/ROOT-9313)] - Crash in TFile::Close on Fedora, ROOT v6.10; * [[ROOT-9320](https://its.cern.ch/jira/browse/ROOT-9320)] - Make GenVector data structures constexpr; * [[ROOT-9321](https://its.cern.ch/jira/browse/ROOT-9321)] - Dictionary generation: type normalization issue in pcm file; * [[ROOT-9448](https://its.cern.ch/jira/browse/ROOT-9448)] - libNew returns nullptr instead of implementing operator new, has many warnings; * [[ROOT-9983](https://its.cern.ch/jira/browse/ROOT-9983)] - [DOC] hadd --help does not show description and epilogue; * [[ROOT-10033](https://its.cern.ch/jira/browse/ROOT-10033)] - ROOT::EnableImplicitMT: Number of threads in scheduling environments; * [[ROOT-10231](https://its.cern.ch/jira/browse/ROOT-10231)] - TMatrixD(a,TMatrixD::kInvMult,b) requires b.GetNcols() = a.GetNcols(); * [[ROOT-10320](https://its.cern.ch/jira/browse/ROOT-10320)] - ROOT/meta does not support anonymous unions/structs; * [[ROOT-10425](https://its.cern.ch/jira/browse/ROOT-10425)] - Missing symbols not reported as missing anymore; * [[ROOT-10546](https://its.cern.ch/jira/browse/ROOT-10546)] - RDataFrame cannot be interrupted from PyROOT; * [[ROOT-10593](https://its.cern.ch/jira/browse/ROOT-10593)] - Segmentation fault when calling a not-yet-defined function from ROOT interpreter; * [[ROOT-10607](https://its.cern.ch/jira/browse/ROOT-10607)] - Several ROOT 7 tests fail when assertions are enabled; * [[ROOT-10613](https://its.cern.ch/jira/browse/ROOT-10613)] - Configuration does not fail when fail-on-missing is ON and cudnn is not found; * [[ROOT-10621](https://its.cern.ch/jira/browse/ROOT-10621)] - Segfault if TFile is used",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:54202,schedul,scheduling,54202,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['schedul'],['scheduling']
Energy Efficiency,"ectory and to activate it use cmake -Dr=ON .. ~~~{.sh}; mkdir compile; cd compile; cmake -Dr=ON ..; make -j 5; ~~~. ### Compiling ROOTR on Gnu/Linux with CMake:; **NOTE:** Tested on Gnu/Linux Debian Jessie with gcc 4.9. **Prerequisities**; install; (For debian-based distros). ~~~{.sh}; apt-get install r-base r-base-dev; ~~~; Install needed R packages, open R and in the prompt type. ~~~{.sh}; install.packages(c('Rcpp','RInside')); ~~~; select a mirror and install. Install the next additional packages for R TMVA interface. ~~~{.sh}; install.packages(c('C50','RSNNS','e1071','xgboost')); ~~~. Download code from git repo. ~~~{.sh}; git clone http://root.cern.ch/git/root.git; ~~~. To compile ROOTR lets to create a compilation directory and to activate it use cmake -Dr=ON .. ~~~{.sh}; mkdir compile; cd compile; cmake -Dr=ON ..; make -j 5; ~~~. ## How does it work ?; There is a class called TRInterface which is located at the header TRInterface.h and uses the namespace `ROOT::R`, it is in charge; of making calls to R to give and obtain data. This class has a series of overcharged operators which ease the passing and obtaining of data; and code from R to C++ and vice versa. To create an object of this class the user must use the static methods `ROOT::R::TRInterface::Instance`; and `ROOT::R::TRInterface::InstancePtr` which return a reference object and a pointer object respectively. ~~~{.cxx}; #include<TRInterface.h>; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; ~~~. ## Running R code and passing/getting variables.; We have different ways to run R code and pass/obtain data to/from R environment: using the methods Execute(code) and; Eval(code). ~~~{.cxx}; #include<TRInterface.h>. //creating an instance; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; //executing simple r commands with the operator <<; r<<""print('hello ROOTR')"";; r<<""vec=c(1,2,3)""<<""print(vec)"";. //executing R's code using the method Execute that doesn't return anything; r.Execute(""prin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:3231,charge,charge,3231,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['charge'],['charge']
Energy Efficiency,"ects; (""shapes"") - filled /added by negotiation with viewer via; **`TVirtualViewer3D`**. A typical interaction between viewer and client using these, taken from; **`TGeoPainter`** is:. ``` {.cpp}; TVirtualViewer3D * viewer = gPad->GetViewer3D();; // Does viewer prefer local frame positions?; Bool_t localFrame = viewer->PreferLocalFrame();; // Perform first fetch of buffer from the shape and try adding it to the viewer; const TBuffer3D &buffer = shape.GetBuffer3D(TBuffer3D::kCore |; TBuffer3D::kBoundingBox |; TBuffer3D::kShapeSpecific,; localFrame);; Int_t reqSections = viewer->AddObject(buffer, &addDaughters);. // If the viewer requires additional sections fetch from the shape; // (if possible) and add again; if (reqSections != TBuffer3D::kNone); shape.GetBuffer3D(reqSections, localFrame);; ```. Together these allow clients to publish objects to any one of the 3D; viewers free of viewer specific drawing code. They allow our simple x3d; viewer, and considerably more sophisticated OpenGL one to both work with; both geometry libraries (`g3d` and `geom`) efficiently. In addition to external viewers, created in separate windows, this; architecture is also used by internal **`TPad`** drawing when it; requires 3D projections. Publishing to a viewer consists of the; following steps:. 1- Create / obtain viewer handle. 2- Begin scene on viewer. 3- Fill mandatory parts of TBuffer3D describing object. 4- Add to viewer. 5- Fill optional parts of TBuffer3D as requested by viewer. [ .... repeat 3/4/5 as required for other/child objects]. 6- End scene on viewer. You should attach the top-level node of your external geometry (or the; manager) to a **`TPad`** object using **`TObject::Draw()`, and perform; the publishing to the viewer in your object's `TObject::Paint()`; overloaded method. See ""Scene Rebuilds"", and example scripts, for more; details.**. #### Creating / Obtaining Viewer Handle. External viewers are bound to a **`TPad`** object (this may be removed; as a requirement in t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:123904,efficient,efficiently,123904,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['efficient'],['efficiently']
Energy Efficiency,"ed by CP to set up; ``COMPUTE_PGM_RSRC1.FLOAT_MODE``.; 19:18 2 bits FLOAT_DENORM_MODE_16_64 Wavefront starts execution; with specified denorm mode; for half/double (16; and 64-bit) floating point; precision floating point; operations. Floating point denorm mode; values are defined in; :ref:`amdgpu-amdhsa-floating-point-denorm-mode-enumeration-values-table`. Used by CP to set up; ``COMPUTE_PGM_RSRC1.FLOAT_MODE``.; 20 1 bit PRIV Must be 0. Start executing wavefront; in privilege trap handler; mode. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.PRIV``.; 21 1 bit ENABLE_DX10_CLAMP GFX9-GFX11; Wavefront starts execution; with DX10 clamp mode; enabled. Used by the vector; ALU to force DX10 style; treatment of NaN's (when; set, clamp NaN to zero,; otherwise pass NaN; through). Used by CP to set up; ``COMPUTE_PGM_RSRC1.DX10_CLAMP``.; WG_RR_EN GFX12; If 1, wavefronts are scheduled; in a round-robin fashion with; respect to the other wavefronts; of the SIMD. Otherwise, wavefronts; are scheduled in oldest age order. CP is responsible for filling in; ``COMPUTE_PGM_RSRC1.WG_RR_EN``.; 22 1 bit DEBUG_MODE Must be 0. Start executing wavefront; in single step mode. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.DEBUG_MODE``.; 23 1 bit ENABLE_IEEE_MODE GFX9-GFX11; Wavefront starts execution; with IEEE mode; enabled. Floating point; opcodes that support; exception flag gathering; will quiet and propagate; signaling-NaN inputs per; IEEE 754-2008. Min_dx10 and; max_dx10 become IEEE; 754-2008 compliant due to; signaling-NaN propagation; and quieting. Used by CP to set up; ``COMPUTE_PGM_RSRC1.IEEE_MODE``.; DISABLE_PERF GFX12; Reserved. Must be 0.; 24 1 bit BULKY Must be 0. Only one work-group allowed; to execute on a compute; unit. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.BULKY``.; 25 1 bit CDBG_USER Must be 0. Flag that can be used to; control debugging code. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.CDBG_USER``.; 26 1 bit FP16_OVFL GFX6-GFX8; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:167733,schedul,scheduled,167733,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"ed clearly using at least one of two; mechanisms:; 1) It will be in a separate directory tree with its own `LICENSE.txt` or; `LICENSE` file at the top containing the specific license and restrictions; which apply to that software, or; 2) It will contain specific license and restriction terms at the top of every; file. ==============================================================================; Legacy LLVM License (https://llvm.org/docs/DeveloperPolicy.html#legacy):; ==============================================================================; University of Illinois/NCSA; Open Source License. Copyright (c) 2003-2019 University of Illinois at Urbana-Champaign.; All rights reserved. Developed by:. LLVM Team. University of Illinois at Urbana-Champaign. http://llvm.org. Permission is hereby granted, free of charge, to any person obtaining a copy of; this software and associated documentation files (the ""Software""), to deal with; the Software without restriction, including without limitation the rights to; use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies; of the Software, and to permit persons to whom the Software is furnished to do; so, subject to the following conditions:. * Redistributions of source code must retain the above copyright notice,; this list of conditions and the following disclaimers. * Redistributions in binary form must reproduce the above copyright notice,; this list of conditions and the following disclaimers in the; documentation and/or other materials provided with the distribution. * Neither the names of the LLVM Team, University of Illinois at; Urbana-Champaign, nor the names of its contributors may be used to; endorse or promote products derived from this Software without specific; prior written permission. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS; FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/LICENSE.TXT:12650,charge,charge,12650,interpreter/llvm-project/llvm/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/LICENSE.TXT,3,['charge'],['charge']
Energy Efficiency,"ed clearly using at least one of two; mechanisms:; 1) It will be in a separate directory tree with its own `LICENSE.txt` or; `LICENSE` file at the top containing the specific license and restrictions; which apply to that software, or; 2) It will contain specific license and restriction terms at the top of every; file. ==============================================================================; Legacy LLVM License (https://llvm.org/docs/DeveloperPolicy.html#legacy):; ==============================================================================; University of Illinois/NCSA; Open Source License. Copyright (c) 2007-2019 University of Illinois at Urbana-Champaign.; All rights reserved. Developed by:. LLVM Team. University of Illinois at Urbana-Champaign. http://llvm.org. Permission is hereby granted, free of charge, to any person obtaining a copy of; this software and associated documentation files (the ""Software""), to deal with; the Software without restriction, including without limitation the rights to; use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies; of the Software, and to permit persons to whom the Software is furnished to do; so, subject to the following conditions:. * Redistributions of source code must retain the above copyright notice,; this list of conditions and the following disclaimers. * Redistributions in binary form must reproduce the above copyright notice,; this list of conditions and the following disclaimers in the; documentation and/or other materials provided with the distribution. * Neither the names of the LLVM Team, University of Illinois at; Urbana-Champaign, nor the names of its contributors may be used to; endorse or promote products derived from this Software without specific; prior written permission. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS; FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT:12650,charge,charge,12650,interpreter/llvm-project/clang/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT,1,['charge'],['charge']
Energy Efficiency,"ed is generated.; ``-runs``; Number of individual test runs, -1 (the default) to run indefinitely.; ``-max_len``; Maximum length of a test input. If 0 (the default), libFuzzer tries to guess; a good value based on the corpus (and reports it).; ``-len_control``; Try generating small inputs first, then try larger inputs over time.; Specifies the rate at which the length limit is increased (smaller == faster).; Default is 100. If 0, immediately try inputs with size up to max_len.; ``-timeout``; Timeout in seconds, default 1200. If an input takes longer than this timeout,; the process is treated as a failure case.; ``-rss_limit_mb``; Memory usage limit in Mb, default 2048. Use 0 to disable the limit.; If an input requires more than this amount of RSS memory to execute,; the process is treated as a failure case.; The limit is checked in a separate thread every second.; If running w/o ASAN/MSAN, you may use 'ulimit -v' instead.; ``-malloc_limit_mb``; If non-zero, the fuzzer will exit if the target tries to allocate this; number of Mb with one malloc call.; If zero (default) same limit as rss_limit_mb is applied.; ``-timeout_exitcode``; Exit code (default 77) used if libFuzzer reports a timeout.; ``-error_exitcode``; Exit code (default 77) used if libFuzzer itself (not a sanitizer) reports a bug (leak, OOM, etc).; ``-max_total_time``; If positive, indicates the maximum total time in seconds to run the fuzzer.; If 0 (the default), run indefinitely.; ``-merge``; If set to 1, any corpus inputs from the 2nd, 3rd etc. corpus directories; that trigger new code coverage will be merged into the first corpus; directory. Defaults to 0. This flag can be used to minimize a corpus.; ``-merge_control_file``; Specify a control file used for the merge process.; If a merge process gets killed it tries to leave this file in a state; suitable for resuming the merge. By default a temporary file will be used.; ``-minimize_crash``; If 1, minimizes the provided crash input.; Use with -runs=N or ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:11228,allocate,allocate,11228,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['allocate'],['allocate']
Energy Efficiency,"ed lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %masked.a); %also.r = xor i32 %reduction, %start. .. _int_vp_reduce_smax:. '``llvm.vp.reduce.smax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smax``' intrinsic performs the signed-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.smax <int_vector_reduce_smax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:762999,reduce,reduce,762999,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a group. :program:`llvm-mca`'s scheduler internally groups instructions into three sets:. * WaitSet: a set of instructions whose operands are not ready.; * ReadySet: a set of instructions ready to execute.; * IssuedSet: a set of instructions executing. Depending on the operands availability, instructions that are dispatched to the; scheduler are either placed into the WaitSet or into the ReadySet. Every cycle, the scheduler checks if instructions can be moved from the WaitSet; to the ReadySet, and if instructions from the ReadySet can be issued to the; underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:38273,schedul,scheduler,38273,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"ed versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible, we create a list of items, or; Atoms, that are contained in the data for each name. First comes the type of; the data in each atom:. .. code-block:: c. enum AtomType; {; eAtomTypeNULL = 0u,; eAtomTypeDIEOffset = 1u, // DIE offset, check form for encoding; eAtomTypeCUOffset = 2u, // DIE offset of the compiler unit header that contains the item in question; eAtomTypeTag = 3u, // DW_TAG_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71455,efficient,efficient,71455,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['efficient'],['efficient']
Energy Efficiency,"ed with [TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class. TBufferJSON generates such object representation, which could be directly used in [JSROOT](https://root.cern/js/) for drawing. `root.json` request returns either complete object or just object member like:. ```bash; [shell] wget http://localhost:8080/Objects/subfolder/obj/fTitle/root.json; ```. The result will be: `""title""`. For the `root.json` request one could specify the 'compact' parameter, which allow to reduce the number of spaces and new lines without data lost. This parameter can have values from '0' (no compression) till '3' (no spaces and new lines at all).; In addition, one can use simple compression algorithm for big arrays. If compact='10', zero values in the begin and at the end; of the array will be excluded. If compact='20', similar values or large zero gaps in-between will be compressed. Such array; compression support in JSROOT from version 4.8.2. Usage of `root.json` request is about as efficient as binary `root.bin` request. Comparison of different request methods with TH2 histogram from hsimple.C shown in the table:. | Request | Size |; | :---------------------- | :--------- |; | root.bin | 7672 bytes |; | root.bin.gz | 1582 bytes |; | root.json | 8570 bytes |; | root.json?compact=3 | 6004 bytes |; | root.json?compact=23 | 5216 bytes |; | root.json.gz?compact=23 | 1855 bytes |. One should remember that JSON representation always includes names of the data fields which are not present in the binary representation. Even then the size difference is negligible. `root.json` used in JSROOT to request objects from THttpServer. ### Generating images out of objects. For the ROOT classes which are implementing Draw method (like [TH1](https://root.cern/doc/master/classTH1.html) or [TGraph](https://root.cern/doc/master/classTGraph.html)) one could produce images with requests: `root.png`, `root.gif`, `root.jpeg`. For example:. ```bash; [shell] wget ""http://localhost:8080/Files/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:17537,efficient,efficient,17537,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['efficient'],['efficient']
Energy Efficiency,"ed; previously.; - Facilitate using Normalized sums of TF1 objects and convolutions, by adding the `NSUM` and `CONV` operators for TF1 objects built with formula expressions; - `TF1(""model"", ""NSUM(gaus , expo)"", xmin, xmax)` will create a function composed of a normalized sum of a gaussian and an exponential.; - `TF1(""voigt"", ""CONV(breitwigner, gausn) , -15, 15)` will create a TF1 object made of a convolution between a Breit-Wigner and a Gaussian. ; - `TFormula` supports vectorization. All the `TF1` objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats class",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:17661,power,power-,17661,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,2,['power'],"['power', 'power-']"
Energy Efficiency,"eduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmin:. '``llvm.vector.reduce.fmin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmin.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmin.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmin.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with minimum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmaximum:. '``llvm.vector.reduce.fmaximum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmaximum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:659800,reduce,reduce,659800,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ee::TClusterIterator (i.e. this replaces += fAutoFlush):. TTree::TClusterIterator clusterIter = tree->GetClusterIterator(which_entry_to_start_from);; Long64_t clusterStart;; while( (clusterStart = clusterIter()) < tree-<GetEntries()) {; printf(""The cluster starts at %lld and ends at %lld\n"",clusterStart,clusterIter.GetNextEntry()-1);; }; See TTreeCache::FillBuffer for a concrete usage example. Significant improvement of the performance of SetBranchAddress/SetAddress (by a factor 3 to 10 depending on the length/complexity of the classname).; Prevent the unlimited growth of the TBasket's buffer even if the basket is reused.; When the basket is Reset (this happens when it is written and will be reused),; if the TBuffer size is greater than. - twice the data in the current basket; and - twice the average data in each basket (of this branch); and - twice the requeste basket size (TBranch::GetBasketSize).; the size of the buffer is reduced to the max of; 'the data in the current basket' and 'the average' and the requested; buffer size and aligned to next highest multiple of 512.; In TBranchRef distinguish between the entry we need (now called RequestedEntry) and the; entry we have read (fReadEntry) so that we can avoid re-reading the same entry too many; times when executing TRef::GetObject.; Reduce by 40% the time taken GetEntry for a branch created using a leaflist (exclusive of the decompression time).; Introduce TVirtualPerfStats::FileUnzipEvent to be able to keep track of the cost of unzipping and use this in TTreePerfStats and TBasket ... This give a good picture of where the time in unzip or in unstreaming; Add more clusters to the TTreeCache buffer until fBufferMinSize is hit to avoid severely underfilled buffer when; a low number of branches is selected/used.; When reading backwards, make sure to load a full (new) cluster and several other fixes to TTreeCache.; Reduce the memory used by a TTree in half. Refactor the code reading and writing the TBasket data.; A si",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:1111,reduce,reduced,1111,tree/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html,2,['reduce'],['reduced']
Energy Efficiency,"ee; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 8. Work-Group ID Z (1 SGPR). The value comes from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 9. Implicit Argument Ptr (2 SGPRs). The value is computed by adding an offset to Kernarg Segment Ptr to get the; global address space pointer to the first kernarg implicit argument. The input and result arguments are assigned in order in the following manner:. .. note::. There are likely some errors and omissions in the following description that; need correction. .. TODO::. Check the Clang source code to decipher how function arguments and return; results are handled. Also see the AMDGPU specific values used. * VGPR arguments are assigned to consecutive VGPRs starting at VGPR0 up to; VGPR31. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. .. TODO::. How are overly aligned structures allocated on the stack?. * SGPR arguments are assigned to consecutive SGPRs starting at SGPR0 up to; SGPR29. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. Note that decomposed struct type arguments may have some fields passed in; registers and some in memory. .. TODO::. So, a struct which can pass some fields as decomposed register arguments, will; pass the rest as decomposed stack elements? But an argument that will not start; in registers will not be decomposed and will be passed as a non-decomposed; stack value?. The following is not part of the AMDGPU function calling convention but; describes how the AMDGPU implements function calls:. 1. SGPR33 is used as a frame pointer (FP) if necessary. Like the SP it is an; unswizzled scratch address. It is only needed if runtime sized ``alloca``; are used, or for the reasons defined in ``SIFrameLowering``.; 2. Runtime stack align",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:397157,allocate,allocated,397157,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"eeded to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__morestack``, instead of returning, calls; into ``.LBB0_2``. This is possible since both, the size of the ``ret``; instruction and the PC of call to ``__morestack`` are known. When the function; body returns, control is transferred back to ``__morestack``. ``__morestack``; then de-allocates the new stacklet, restores the correct SP value, and does a; second return, which returns control to the correct caller. Variable Sized Allocas; ----------------------. The section on `allocating stacklets`_ automatically assumes that every stack; frame will be of fixed size. However, LLVM allows the use of the ``llvm.alloca``; intrinsic to allocate dynamically sized blocks of memory on the stack. When; faced with such a variable-sized alloca, code is generated to:. * Check if the current stacklet has enough space. If yes, just bump the SP, like; in the normal case.; * If not, generate a call to ``libgcc``, which allocates the memory from the; heap. The memory allocated from the heap is linked into a list in the current; stacklet, and freed along with the same. This prevents a memory leak.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:2278,allocate,allocates,2278,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,4,['allocate'],"['allocate', 'allocated', 'allocates']"
Energy Efficiency,"eeded. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An example of a branch with an object allocated and; owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = new Event();; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. TTreeFormula (TTree::Draw, TTree::Scan). Fix CollectionTree->Scan(""reco_ee_et[][2]:reco_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:2295,allocate,allocated,2295,tree/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html,2,['allocate'],['allocated']
Energy Efficiency,"eference manual has been moved into Doxygen. Still some work and; polish has to be done but the reference guide in this new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly avoid costly checks (extra RecursiveRemove and lock). We removed the need to create a TThread object per thread in a multi-threaded application. Now ROOT can be used with any threading model (e.g. OpenMP, STL threads, TBB) transparently. All the internal synchronisation mechanisms of ROOT are activated by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TContext` which record the current directory; and will restore it at destruction time and does not change the current directory. The constructor for `TDirectory::TContext` that",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:2180,reduce,reduced,2180,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['reduce'],['reduced']
Energy Efficiency,eferenceTracker.h; llvm/tools/llvm-pdbutil/YAMLOutputStyle.h; llvm/tools/llvm-profgen/CallContext.h; llvm/tools/llvm-profgen/CSPreInliner.cpp; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/del,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337217,reduce,reduce,337217,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"eferences; ^^^^^^^^^^^^^^^^. In C, similar to arrays on the function prototypes, a reference to array is; automatically promoted (or ""decayed"") to a pointer to its first element (e.g.,; ``&arr[0]``). In `-fbounds-safety`, array references are promoted to ``__bidi_indexable``; pointers which contain the upper and lower bounds of the array, with the; equivalent of ``&arr[0]`` serving as the lower bound and ``&arr[array_size]``; (or one past the last element) serving as the upper bound. This applies to all; types of arrays including constant-length arrays, variable-length arrays (VLAs),; and flexible array members annotated with `__counted_by`. In the following example, reference to ``vla`` promotes to ``int; *__bidi_indexable``, with ``&vla[n]`` as the upper bound and ``&vla[0]`` as the; lower bound. Then, it's copied to ``int *p``, which is implicitly ``int; *__bidi_indexable p``. Please note that value of ``n`` used to create the upper; bound is ``10``, not ``100``, in this case because ``10`` is the actual length; of ``vla``, the value of ``n`` at the time when the array is being allocated. .. code-block:: c. void foo(void) {; int n = 10;; int vla[n];; n = 100;; int *p = vla; // { .ptr: &vla[0], .upper: &vla[10], .lower: &vla[0] }; // it's `&vla[10]` because the value of `n` was 10 at the; // time when the array is actually allocated.; // ...; }. By promoting array references to ``__bidi_indexable``, all array accesses are; bounds checked in ``-fbounds-safety``, just as ``__bidi_indexable`` pointers; are. Maintaining correctness of bounds annotations; ---------------------------------------------. ``-fbounds-safety`` maintains correctness of bounds annotations by performing; additional checks when a pointer object and/or its related value containing the; bounds information is updated. For example, ``__single`` expresses an invariant that the pointer must either; point to a single valid object or be a null pointer. To maintain this invariant,; the compiler inserts c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:34671,allocate,allocated,34671,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['allocate'],['allocated']
Energy Efficiency,"efine; - Fill; - Filter; - Graph; - Histo[1,2,3]D; - Max; - Mean; - Min; - Profile[1,2,3]D; - Snapshot; - Sum. with support for more operations coming in the future. Any distributed RDataFrame backend inherits the dependencies of the underlying software needed to distribute the applications. The Spark backend for example has the following runtime dependencies (ROOT will build just fine without, but the feature will be unavailable without these packages):. - [pyspark](https://spark.apache.org/docs/latest/api/python/index.html), that in turn has its own set of dependencies:; - [Java](https://www.java.com/en/); - [py4j](https://www.py4j.org/). Tests for the Spark backend can be turned ON/OFF with the new build option `test_distrdf_pyspark` (OFF by default). ## Histogram Libraries. ## Math Libraries. - Update the definitions of the physical constants using the recommended 2018 values from NIST.; - Use also the new SI definition of base units from 2019, where the Planck constant, the Boltzmann constant, the elementary electric charge and the Avogadro constant are exact numerical values. See <https://en.wikipedia.org/wiki/2019_redefinition_of_the_SI_base_units>. Note that with this new definition the functions `TMath::HUncertainty()`, `TMath::KUncertainty()`, `TMath::QeUncertainty()` and `TMath::NaUncertainty()` all return a `0.0` value.; - Due to some planned major improvements to `RVec`, the layout of `RVec` objects will change in a backward-incompatible way between v6.24 and v6.26.; Because of this, we now print a warning if an application is reading or writing a `ROOT::RVec` object from/to a ROOT file. We assume this is an; exceedingly rare case, as the ROOT interface typically used to manipulate `RVec`s is `RDataFrame`, and `RDataFrame` performs an on-the-fly; `RVec <-> std::vector` conversion rather than writing `RVec`s to disk. Note that, currently, `RVecs` written e.g. in a `TTree` cannot be read back; using certain ROOT interfaces (e.g. `TTreeReaderArray`, `RDataF",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:12367,charge,charge,12367,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['charge'],['charge']
Energy Efficiency,"efining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. code-block:: cmake. macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`` wrapper functions are; all defined in ``AddLLVM.cmake`` which is installed as part of the LLVM; distribution. It can be included and used by any LLVM sub-project that requires; LLVM. .. note::. Not all LLVM projects require LLVM for all use cases. For example compiler-rt; can be built without LLVM, and the compiler-rt sanitizer libraries are used; with GCC. Useful Built-in Commands; ========================. CMake has a bunch of useful built-in commands. This document isn't going to; go into details about them because The CMake project has excellent; docum",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:13297,reduce,reduce,13297,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['reduce'],['reduce']
Energy Efficiency,"efore creating the volume; itself, so we will describe the bits and pieces needed for making the; geometry before moving to an architectural point of view. As far as materials are concerned, they represent the physical; properties of the solid from which a volume is made. Materials are just; a support for the data that has to be provided to the tracking engine; that uses this geometry package. Due to this fact, the; TGeoMaterial class is more like a thin data structure needed for; building the corresponding native materials of the Monte-Carlo tracking; code that uses TGeo. \anchor GM00a; ### Elements, Materials and Mixtures. In order to make easier material and mixture creation, one can use the; pre-built table of elements owned by TGeoManager class:. ~~~{.cpp}; TGeoElementTable *table = gGeoManager->GetElementTable();; TGeoElement *element1 = table->GetElement(Int_t Z);; TGeoElement *element2 = table->FindElement(""Copper"");; ~~~. Materials made of single elements can be defined by their atomic mass; (`A`), charge (`Z`) and density (`rho`). One can also create a material; by specifying the element that it is made of. Optionally the radiation; and absorption lengths can be also provided; otherwise they can be; computed on-demand [`G3`]. The class representing them is; TGeoMaterial:. ~~~{.cpp}; TGeoMaterial(const char *name,Double_t a,Double_t z,; Double_t density, Double_t radlen=0,Double_t intlen=0);; TGeoMaterial(const char *name, TGeoElement *elem,; Double_t density);; TGeoMaterial(const char* name, Double_t a, Double_t z,; Double_t rho,; TGeoMaterial::EGeoMaterialState state,; Double_t temperature = STP_temperature,; Double_t pressure = STP_pressure); ~~~. Any material or derived class is automatically indexed after creation.; The assigned index is corresponding to the last entry in the list of; materials owned by TGeoManager class. This can be changed using; the `TGeoMaterial::SetIndex()` method, however it is not; recommended while using the geometry package in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:1612,charge,charge,1612,geom/geom/doc/materials.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md,1,['charge'],['charge']
Energy Efficiency,"eful for finding; bugs, we ask you to bear in mind a few points when using it.; Work-in-Progress; The analyzer is a continuous work-in-progress. There are many planned; enhancements to improve both the precision and scope of its analysis algorithms; as well as the kinds of bugs it will find. While there are fundamental; limitations to what static analysis can do, we have a long way to go before; hitting that wall.; Slower than Compilation; Operationally, using static analysis to; automatically find deep program bugs is about trading CPU time for the hardening; of code. Because of the deep analysis performed by state-of-the-art static; analysis tools, static analysis can be much slower than compilation.; While the Clang Static Analyzer is being designed to be as fast and; light-weight as possible, please do not expect it to be as fast as compiling a; program (even with optimizations enabled). Some of the algorithms needed to find; bugs require in the worst case exponential time.; The Clang Static Analyzer runs in a reasonable amount of time by both; bounding the amount of checking work it will do as well as using clever; algorithms to reduce the amount of work it must do to find bugs.; False Positives; Static analysis is not perfect. It can falsely flag bugs in a program where; the code behaves correctly. Because some code checks require more analysis; precision than others, the frequency of false positives can vary widely between; different checks. Our long-term goal is to have the analyzer have a low false; positive rate for most code on all checks.; Please help us in this endeavor by reporting false; positives. False positives cannot be addressed unless we know about; them.; More Checks; Static analysis is not magic; a static analyzer can only find bugs that it; has been specifically engineered to find. If there are specific kinds of bugs; you would like the Clang Static Analyzer to find, please feel free to; file feature requests or contribute your own; patches. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/index.html:3416,reduce,reduce,3416,interpreter/llvm-project/clang/www/analyzer/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/index.html,2,['reduce'],['reduce']
Energy Efficiency,"egratorMultiDim::kMISER` | `ROOT::Math:::GSLMCIntegrator` |; | `ROOT::Math::IntegratorMultiDim::kPLAIN` | `ROOT::Math:::GSLMCIntegrator` |. The control parameters for the integration algorithms can be specified using the; `ROOT::Math::IntegratorMultiDimOptions` class. Static methods are provided to change the default values.; It is possible to print the list of default control parameters using the `ROOT::Math::IntegratorMultiDimOptions::Print` function.; Example:; ```{.cpp}; ROOT::Math::IntegratorMultiDimOptions opt;; opt.Print();; Integrator Type : ADAPTIVE; Absolute tolerance : 1e-09; Relative tolerance : 1e-09; Workspace size : 100000; (max) function calls : 100000; ```; Depending on the algorithm, some of the control parameters might have no effect. #### `ROOT::Math::AdaptiveIntegratorMultiDim`. This class implements an adaptive quadrature integration method for multi dimensional functions. It is described in this paper; *Genz, A.A. Malik, An adaptive algorithm for numerical integration over an N-dimensional rectangular region, J. Comput. Appl. Math. 6 (1980) 295-302*.; It is part of the *MathCore* library.; The user can control the relative and absolute tolerance and the maximum allowed number of function evaluation. #### `ROOT::Math::GSLMCIntegrator`. It is a class for performing numerical integration of a multidimensional function. It uses the numerical integration algorithms of GSL, which reimplements the algorithms used; in the QUADPACK, a numerical integration package written in Fortran. Plain MC, MISER and VEGAS integration algorithms are supported for integration over finite (hypercubic) ranges.; For a detail description of the GSL methods visit the GSL users guide.; Specific configuration options (documented in the GSL user guide) for the `ROOT::Math::GSLMCIntegration` can be set directly in the class, or when using it via the `ROOT::Math::IntegratorMultiDim`; interface, can be defined using the `ROOT::Math::IntegratorMultiDimOptions`. ## Function Deriv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:61333,adapt,adaptive,61333,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['adapt'],['adaptive']
Energy Efficiency,"el; <https://discord.com/channels/636084430946959380/976196303681896538>`__.; * :ref:`IRC`. Doing this can help:; * overcome potential anxiety to call in for a first time,; * people who prefer to first exchange a few messages through text chat; before dialing in, and; * remind the wider community that office hours do exist.; * If you decide to no longer host office hours, please do remove your entry; from the list above. .. _IRC:. IRC; ---. Users and developers of the LLVM project (including subprojects such as Clang); can be found in #llvm on `irc.oftc.net <irc://irc.oftc.net/llvm>`_. The channel; is actively moderated. The #llvm-build channel has a bot for; `LLVM buildbot <http://lab.llvm.org/buildbot/#/console>`_ status changes. The; bot will post a message with a link to a build bot and a blamelist when a build; goes from passing to failing and again (without the blamelist) when the build; goes from failing back to passing. It is a good channel for actively monitoring; build statuses, but it is a noisy channel due to the automated messages. The; channel is not actively moderated. In addition to the traditional IRC there is a; `Discord <https://discord.com/channels/636084430946959380/636725486533345280>`_; chat server available. To sign up, please use this; `invitation link <https://discord.com/invite/xS7Z362>`_. .. _meetups-social-events:. Meetups and social events; -------------------------. .. toctree::; :hidden:. MeetupGuidelines. Besides developer `meetings and conferences <https://llvm.org/devmtg/>`_,; there are several user groups called; `LLVM Socials <https://www.meetup.com/pro/llvm/>`_. We greatly encourage you to; join one in your city. Or start a new one if there is none:. :doc:`MeetupGuidelines`. .. _community-proposals:. Community wide proposals; ------------------------. Proposals for massive changes in how the community behaves and how the work flow; can be better. .. toctree::; :hidden:. Proposals/GitHubMove; BugpointRedesign; Proposals/TestSuite;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst:17396,monitor,monitoring,17396,interpreter/llvm-project/llvm/docs/GettingInvolved.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingInvolved.rst,1,['monitor'],['monitoring']
Energy Efficiency,"elect=movl; --report=list; --print=symbols,types,instructions,summary; test-dwarf-clang.o. Logical View:; [000] {File} 'test-dwarf-clang.o'. [001] {CompileUnit} 'test.cpp'; [003] {Code} 'movl	$0x7, -0x1c(%rbp)'; [003] {Code} 'movl	$0x7, -0x4(%rbp)'; [003] {Code} 'movl	%eax, -0x4(%rbp)'; [003] {Code} 'movl	%esi, -0x14(%rbp)'; [003] {Code} 'movl	-0x14(%rbp), %eax'; [003] {Code} 'movl	-0x4(%rbp), %eax'; [003] 4 {TypeAlias} 'INTEGER' -> 'int'; [004] 5 {Variable} 'CONSTANT' -> 'const INTEGER'. -----------------------------; Element Total Found; -----------------------------; Scopes 3 0; Symbols 4 1; Types 2 1; Lines 17 6; -----------------------------; Total 26 8. COMPARISON MODE; ^^^^^^^^^^^^^^^; In this mode :program:`llvm-debuginfo-analyzer` compares logical views; to produce a report with the logical elements that are missing or added.; This a very powerful aid in finding semantic differences in the debug; information produced by different toolchain versions or even completely; different toolchains altogether (For example a compiler producing DWARF; can be directly compared against a completely different compiler that; produces CodeView). Given the previous example we found the above debug information issue; (related to the previous invalid scope location for the **'typedef int; INTEGER'**) by comparing against another compiler. Using GCC to generate test-dwarf-gcc.o, we can apply a selection pattern; with the printing mode to obtain the following logical view output. .. code-block:: none. llvm-debuginfo-analyzer --attribute=level; --select-regex --select-nocase --select=INTe; --report=list; --print=symbols,types; test-dwarf-clang.o test-dwarf-gcc.o. Logical View:; [000] {File} 'test-dwarf-clang.o'. [001] {CompileUnit} 'test.cpp'; [003] 4 {TypeAlias} 'INTEGER' -> 'int'; [004] 5 {Variable} 'CONSTANT' -> 'const INTEGER'. Logical View:; [000] {File} 'test-dwarf-gcc.o'. [001] {CompileUnit} 'test.cpp'; [004] 4 {TypeAlias} 'INTEGER' -> 'int'; [004] 5 {Variable} 'CONSTANT' -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst:28122,power,powerful,28122,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst,1,['power'],['powerful']
Energy Efficiency,"element, not the number of elements. A common example of how this is used is arrays where the size is not known.; It's common to use array types with zero length to represent these. The fact; that the static type says there are zero elements is irrelevant; it's perfectly; valid to compute arbitrary element indices, as the computation only depends on; the size of the array element, not the number of elements. Note that zero-sized; arrays are not a special case here. This sense is unconnected with ``inbounds`` keyword. The ``inbounds`` keyword is; designed to describe low-level pointer arithmetic overflow conditions, rather; than high-level array indexing rules. Analysis passes which wish to understand array indexing should not assume that; the static array type bounds are respected. The second sense of being out of bounds is computing an address that's beyond; the actual underlying allocated object. With the ``inbounds`` keyword, the result value of the GEP is ``poison`` if the; address is outside the actual underlying allocated object and not the address; one-past-the-end. Without the ``inbounds`` keyword, there are no restrictions on computing; out-of-bounds addresses. Obviously, performing a load or a store requires an; address of allocated and sufficiently aligned memory. But the GEP itself is only; concerned with computing addresses. Can array indices be negative?; ------------------------------. Yes. This is basically a special case of array indices being out of bounds. Can I compare two values computed with GEPs?; --------------------------------------------. Yes. If both addresses are within the same allocated object, or; one-past-the-end, you'll get the comparison result you expect. If either is; outside of it, integer arithmetic wrapping may occur, so the comparison may not; be meaningful. Can I do GEP with a different pointer type than the type of the underlying object?; ----------------------------------------------------------------------------------. Ye",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:13867,allocate,allocated,13867,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['allocate'],['allocated']
Energy Efficiency,"elevant primitive types by the interpreter loop or by the; evaluating emitter. Primitive Types; ---------------. * ``PT_{U|S}int{8|16|32|64}``. Signed or unsigned integers of a specific bit width, implemented using; the ```Integral``` type. * ``PT_{U|S}intFP``. Signed or unsigned integers of an arbitrary, but fixed width used to; implement integral types which are required by the target, but are not; supported by the host. Under the hood, they rely on APValue. The; ``Integral`` specialisation for these types is required by opcodes to; share an implementation with fixed integrals. * ``PT_Bool``. Representation for boolean types, essentially a 1-bit unsigned; ``Integral``. * ``PT_RealFP``. Arbitrary, but fixed precision floating point numbers. Could be; specialised in the future similarly to integers in order to improve; floating point performance. * ``PT_Ptr``. Pointer type, defined in ``""Pointer.h""``. A pointer can be either null,; reference interpreter-allocated memory (``BlockPointer``) or point to an; address which can be derived, but not accessed (``ExternPointer``). * ``PT_FnPtr``. Function pointer type, can also be a null function pointer. Defined; in ``""FnPointer.h""``. * ``PT_MemPtr``. Member pointer type, can also be a null member pointer. Defined; in ``""MemberPointer.h""``. * ``PT_VoidPtr``. Void pointer type, can be used for round-trip casts. Represented as; the union of all pointers which can be cast to void.; Defined in ``""VoidPointer.h""``. * ``PT_ObjCBlockPtr``. Pointer type for ObjC blocks. Defined in ``""ObjCBlockPointer.h""``. Composite types; ---------------. The interpreter distinguishes two kinds of composite types: arrays and; records (structs and classes). Unions are represented as records, except; at most a single field can be marked as active. The contents of inactive; fields are kept until they are reactivated and overwritten.; Complex numbers (``_Complex``) and vectors; (``__attribute((vector_size(16)))``) are treated as arrays. Bytecode Executi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst:2458,allocate,allocated,2458,interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,1,['allocate'],['allocated']
Energy Efficiency,"eliminated by ``InstCombine``. The major benefit of this; transformation is that it makes many other loop optimizations, such as; ``LoopUnswitch``\ ing, simpler. You can read more in the; :ref:`loop terminology section for the LCSSA form <loop-terminology-lcssa>`. .. _passes-licm:. ``licm``: Loop Invariant Code Motion; ------------------------------------. This pass performs loop invariant code motion, attempting to remove as much; code from the body of a loop as possible. It does this by either hoisting code; into the preheader block, or by sinking code to the exit blocks if it is safe.; This pass also promotes must-aliased memory locations in the loop to live in; registers, thus hoisting and sinking ""invariant"" loads and stores. Hoisting operations out of loops is a canonicalization transform. It enables; and simplifies subsequent optimizations in the middle-end. Rematerialization; of hoisted instructions to reduce register pressure is the responsibility of; the back-end, which has more accurate information about register pressure and; also handles other optimizations than LICM that increase live-ranges. This pass uses alias analysis for two purposes:. #. Moving loop invariant loads and calls out of loops. If we can determine; that a load or call inside of a loop never aliases anything stored to, we; can hoist it or sink it like any other instruction. #. Scalar Promotion of Memory. If there is a store instruction inside of the; loop, we try to move the store to happen AFTER the loop instead of inside of; the loop. This can only happen if a few conditions are true:. #. The pointer stored through is loop invariant.; #. There are no stores or loads in the loop which *may* alias the pointer.; There are no calls in the loop which mod/ref the pointer. If these conditions are true, we can promote the loads and stores in the; loop of the pointer to use a temporary alloca'd variable. We then use the; :ref:`mem2reg <passes-mem2reg>` functionality to construct the appropriat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:24056,reduce,reduce,24056,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['reduce'],['reduce']
Energy Efficiency,eltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/too,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338257,reduce,reduce,338257,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"em->Load(""libA""); // #4: explicit loading of libA. No full descriptor required.; root [] do(); // #5: error: implicit loading of libA is currently unsupported. ```. This pattern is not only used in the ROOT prompt but in I/O hotspots such as; `ShowMembers` and `TClass::IsA`. A naive implementation of this feature would require inclusion of all reachable; library descriptors (aka header files) at ROOT startup time. Of course this is; not feasible and ROOT inserts a set of optimizations to fence itself from the; costly full header inclusion. Unfortunately, several of them are home-grown and; in a few cases inaccurate (eg line #5) causing a noticeable technical debt. Here we will briefly describe the three common layers of optimizations: ROOT PCH,; ROOTMAP and RDICT. The ROOT precompiled header (PCH) reduces the CPU and memory cost for ROOT's; most used libraries. The precompiled header technology is well-understood since; decades [[4]]. It is an efficient on-disk representation of the state of the; compiler after parsing a set of headers. It can be loaded before starting the; next instance to avoid doing redundant work. At build time, rootcling (ROOT's; dictionary generator) creates such PCH file which is attached at ROOT startup; time. Its major drawback is the fact that if third-party users want to include; their libraries, they have to recompile it every time there is a change. RDICT files store some useful information (in particular about class offsets) in; ROOT files to avoid the potentially expensive call to the interpreter if the; information is not the PCH. For example, ROOT's libGeom and other third-party; code. This is done to circumvent the costly call to `ShowMembers` which will; require parsing. ROOTMAP files reduce parsing for code which is not in the PCH. Consider; `foo::bar` and `S` are defined in `libFoo`'s `Foo.h`:; ```cpp; // Foo.h; namespace foo { struct bar{}; }; struct S{};; ```. ```bash; # libFoo.rootmap; { decls }; namespace foo { }; struct S;;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:6051,efficient,efficient,6051,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['efficient'],['efficient']
Energy Efficiency,"emcpy.element.unordered.atomic.*``' intrinsic is a specialization of the; '``llvm.memcpy.*``' intrinsic. It differs in that the ``dest`` and ``src`` are treated; as arrays with elements that are exactly ``element_size`` bytes, and the copy between; buffers uses a sequence of :ref:`unordered atomic <ordering>` load/store operations; that are a positive integer multiple of the ``element_size`` in size. Arguments:; """""""""""""""""""". The first three arguments are the same as they are in the :ref:`@llvm.memcpy <int_memcpy>`; intrinsic, with the added constraint that ``len`` is required to be a positive integer; multiple of the ``element_size``. If ``len`` is not a positive integer multiple of; ``element_size``, then the behaviour of the intrinsic is undefined. ``element_size`` must be a compile-time constant positive power of two no greater than; target-specific atomic access size limit. For each of the input pointers ``align`` parameter attribute must be specified. It; must be a power of two no less than the ``element_size``. Caller guarantees that; both the source and destination pointers are aligned to that boundary. Semantics:; """""""""""""""""""". The '``llvm.memcpy.element.unordered.atomic.*``' intrinsic copies ``len`` bytes of; memory from the source location to the destination location. These locations are not; allowed to overlap. The memory copy is performed as a sequence of load/store operations; where each access is guaranteed to be a multiple of ``element_size`` bytes wide and; aligned at an ``element_size`` boundary. The order of the copy is unspecified. The same value may be read from the source; buffer many times, but only one write is issued to the destination buffer per; element. It is well defined to have concurrent reads and writes to both source and; destination provided those reads and writes are unordered atomic when specified. This intrinsic does not provide any additional ordering guarantees over those; provided by a set of unordered loads from the source locati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:958620,power,power,958620,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ementPtr; GlobalISel/index; GwpAsan; HowToSetUpLLVMStyleRTTI; HowToUseAttributes; InAlloca; LangRef; LibFuzzer; MarkedUpDisassembly; MIRLangRef; OptBisect; PCSectionsMetadata; PDB/index; PointerAuth; ScudoHardenedAllocator; MemTagSanitizer; Security; SecurityTransparencyReports; SegmentedStacks; StackMaps; SpeculativeLoadHardening; Statepoints; SymbolizerMarkupFormat; SystemLibrary; TestingGuide; TransformMetadata; TypeMetadata; XRay; XRayExample; XRayFDRFormat; YamlIO. API Reference; -------------. `Doxygen generated documentation <https://llvm.org/doxygen/>`_; (`classes <https://llvm.org/doxygen/inherits.html>`_). :doc:`HowToUseAttributes`; Answers some questions about the new Attributes infrastructure. LLVM Reference; --------------. ======================; Command Line Utilities; ======================. :doc:`LLVM Command Guide <CommandGuide/index>`; A reference manual for the LLVM command line utilities (""man"" pages for LLVM; tools). :doc:`Bugpoint`; Automatic bug finder and test-case reducer description and usage; information. :doc:`OptBisect`; A command line option for debugging optimization-induced failures. :doc:`SymbolizerMarkupFormat`; A reference for the log symbolizer markup accepted by ``llvm-symbolizer``. :doc:`The Microsoft PDB File Format <PDB/index>`; A detailed description of the Microsoft PDB (Program Database) file format. ==================; Garbage Collection; ==================. :doc:`GarbageCollection`; The interfaces source-language compilers should use for compiling GC'd; programs. :doc:`Statepoints`; This describes a set of experimental extensions for garbage; collection support. =========; LibFuzzer; =========. :doc:`LibFuzzer`; A library for writing in-process guided fuzzers. :doc:`FuzzingLLVM`; Information on writing and using Fuzzers to find bugs in LLVM. ========; LLVM IR; ========. :doc:`LLVM Language Reference Manual <LangRef>`; Defines the LLVM intermediate representation and the assembly form of the; different nodes. :doc:`InAllo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Reference.rst:1379,reduce,reducer,1379,interpreter/llvm-project/llvm/docs/Reference.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Reference.rst,1,['reduce'],['reducer']
Energy Efficiency,"ement_size>); declare void @llvm.memmove.element.unordered.atomic.p0.p0.i64(ptr <dest>,; ptr <src>,; i64 <len>,; i32 <element_size>). Overview:; """""""""""""""""". The '``llvm.memmove.element.unordered.atomic.*``' intrinsic is a specialization; of the '``llvm.memmove.*``' intrinsic. It differs in that the ``dest`` and; ``src`` are treated as arrays with elements that are exactly ``element_size``; bytes, and the copy between buffers uses a sequence of; :ref:`unordered atomic <ordering>` load/store operations that are a positive; integer multiple of the ``element_size`` in size. Arguments:; """""""""""""""""""". The first three arguments are the same as they are in the; :ref:`@llvm.memmove <int_memmove>` intrinsic, with the added constraint that; ``len`` is required to be a positive integer multiple of the ``element_size``.; If ``len`` is not a positive integer multiple of ``element_size``, then the; behaviour of the intrinsic is undefined. ``element_size`` must be a compile-time constant positive power of two no; greater than a target-specific atomic access size limit. For each of the input pointers the ``align`` parameter attribute must be; specified. It must be a power of two no less than the ``element_size``. Caller; guarantees that both the source and destination pointers are aligned to that; boundary. Semantics:; """""""""""""""""""". The '``llvm.memmove.element.unordered.atomic.*``' intrinsic copies ``len`` bytes; of memory from the source location to the destination location. These locations; are allowed to overlap. The memory copy is performed as a sequence of load/store; operations where each access is guaranteed to be a multiple of ``element_size``; bytes wide and aligned at an ``element_size`` boundary. The order of the copy is unspecified. The same value may be read from the source; buffer many times, but only one write is issued to the destination buffer per; element. It is well defined to have concurrent reads and writes to both source; and destination provided those reads and wri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:961548,power,power,961548,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ements associated to the accessed pages, which could; speed up operations that need to iterate over initialized elements in a; non-ordered manner. .. _dss_vector:. <vector>; ^^^^^^^^. ``std::vector<T>`` is well loved and respected. However, ``SmallVector<T, 0>``; is often a better option due to the advantages listed above. std::vector is; still useful when you need to store more than ``UINT32_MAX`` elements or when; interfacing with code that expects vectors :). One worthwhile note about std::vector: avoid code like this:. .. code-block:: c++. for ( ... ) {; std::vector<foo> V;; // make use of V.; }. Instead, write this as:. .. code-block:: c++. std::vector<foo> V;; for ( ... ) {; // make use of V.; V.clear();; }. Doing so will save (at least) one heap allocation and free per iteration of the; loop. .. _dss_deque:. <deque>; ^^^^^^^. ``std::deque`` is, in some senses, a generalized version of ``std::vector``.; Like ``std::vector``, it provides constant time random access and other similar; properties, but it also provides efficient access to the front of the list. It; does not guarantee continuity of elements within memory. In exchange for this extra flexibility, ``std::deque`` has significantly higher; constant factor costs than ``std::vector``. If possible, use ``std::vector`` or; something cheaper. .. _dss_list:. <list>; ^^^^^^. ``std::list`` is an extremely inefficient class that is rarely useful. It; performs a heap allocation for every element inserted into it, thus having an; extremely high constant factor, particularly for small data types.; ``std::list`` also only supports bidirectional iteration, not random access; iteration. In exchange for this high cost, std::list supports efficient access to both ends; of the list (like ``std::deque``, but unlike ``std::vector`` or; ``SmallVector``). In addition, the iterator invalidation characteristics of; std::list are stronger than that of a vector class: inserting or removing an; element into the list does not inva",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:65540,efficient,efficient,65540,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"emory.; :program:`llvm-exegesis` checks the liveliness of registers (i.e. any register; use has a corresponding def or is a ""live in""). If your code depends on the; value of some registers, you need to use snippet annotations to ensure setup; is performed properly. For example, the following code snippet depends on the values of XMM1 (which; will be set by the tool) and the memory buffer passed in RDI (live in). .. code-block:: none. # LLVM-EXEGESIS-LIVEIN RDI; # LLVM-EXEGESIS-DEFREG XMM1 42; vmulps	(%rdi), %xmm1, %xmm2; vhaddps	%xmm2, %xmm2, %xmm3; addq $0x10, %rdi. Example 3: benchmarking with memory annotations; -----------------------------------------------. Some snippets require memory setup in specific places to execute without; crashing. Setting up memory can be accomplished with the `LLVM-EXEGESIS-MEM-DEF`; and `LLVM-EXEGESIS-MEM-MAP` annotations. To execute the following snippet:. .. code-block:: none. movq $8192, %rax; movq (%rax), %rdi. We need to have at least eight bytes of memory allocated starting `0x2000`.; We can create the necessary execution environment with the following; annotations added to the snippet:. .. code-block:: none. # LLVM-EXEGESIS-MEM-DEF test1 4096 7fffffff; # LLVM-EXEGESIS-MEM-MAP test1 8192. movq $8192, %rax; movq (%rax), %rdi. EXAMPLE 4: analysis; -------------------. Assuming you have a set of benchmarked instructions (either latency or uops) as; YAML in file `/tmp/benchmarks.yaml`, you can analyze the results using the; following command:. .. code-block:: bash. $ llvm-exegesis --mode=analysis \; --benchmarks-file=/tmp/benchmarks.yaml \; --analysis-clusters-output-file=/tmp/clusters.csv \; --analysis-inconsistencies-output-file=/tmp/inconsistencies.html. This will group the instructions into clusters with the same performance; characteristics. The clusters will be written out to `/tmp/clusters.csv` in the; following format:. .. code-block:: none. cluster_id,opcode_name,config,sched_class; ...; 2,ADD32ri8_DB,,WriteALU,1.00; 2,AD",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:7203,allocate,allocated,7203,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['allocate'],['allocated']
Energy Efficiency,"en an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:9943,monitor,monitoring,9943,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['monitor'],['monitoring']
Energy Efficiency,"en expecting an expression"");; case tok_identifier:; return ParseIdentifierExpr();; case tok_number:; return ParseNumberExpr();; case '(':; return ParseParenExpr();; }; }. Now that you see the definition of this function, it is more obvious why; we can assume the state of CurTok in the various functions. This uses; look-ahead to determine which sort of expression is being inspected, and; then parses it with a function call. Now that basic expressions are handled, we need to handle binary; expressions. They are a bit more complex. Binary Expression Parsing; =========================. Binary expressions are significantly harder to parse because they are; often ambiguous. For example, when given the string ""x+y\*z"", the parser; can choose to parse it as either ""(x+y)\*z"" or ""x+(y\*z)"". With common; definitions from mathematics, we expect the later parse, because ""\*""; (multiplication) has higher *precedence* than ""+"" (addition). There are many ways to handle this, but an elegant and efficient way is; to use `Operator-Precedence; Parsing <http://en.wikipedia.org/wiki/Operator-precedence_parser>`_.; This parsing technique uses the precedence of binary operators to guide; recursion. To start with, we need a table of precedences:. .. code-block:: c++. /// BinopPrecedence - This holds the precedence for each binary operator that is; /// defined.; static std::map<char, int> BinopPrecedence;. /// GetTokPrecedence - Get the precedence of the pending binary operator token.; static int GetTokPrecedence() {; if (!isascii(CurTok)); return -1;. // Make sure it's a declared binop.; int TokPrec = BinopPrecedence[CurTok];; if (TokPrec <= 0) return -1;; return TokPrec;; }. int main() {; // Install standard binary operators.; // 1 is lowest precedence.; BinopPrecedence['<'] = 10;; BinopPrecedence['+'] = 20;; BinopPrecedence['-'] = 20;; BinopPrecedence['*'] = 40; // highest.; ...; }. For the basic form of Kaleidoscope, we will only support 4 binary; operators (this can obviously be exten",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst:12509,efficient,efficient,12509,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,1,['efficient'],['efficient']
Energy Efficiency,"en implemented specifically for use by; the `High-Performance Erlang; (HiPE) <http://www.it.uu.se/research/group/hipe/>`_ compiler, *the*; native code compiler of the `Ericsson's Open Source Erlang/OTP; system <http://www.erlang.org/download.shtml>`_. It uses more; registers for argument passing than the ordinary C calling; convention and defines no callee-saved registers. The calling; convention properly supports `tail call; optimization <CodeGenerator.html#tail-call-optimization>`_ but requires; that both the caller and the callee use it. It uses a *register pinning*; mechanism, similar to GHC's convention, for keeping frequently; accessed runtime components pinned to specific hardware registers.; At the moment only X86 supports this convention (both 32 and 64; bit).; ""``anyregcc``"" - Dynamic calling convention for code patching; This is a special convention that supports patching an arbitrary code; sequence in place of a call site. This convention forces the call; arguments into registers but allows them to be dynamically; allocated. This can currently only be used with calls to; llvm.experimental.patchpoint because only this intrinsic records; the location of its arguments in a side table. See :doc:`StackMaps`.; ""``preserve_mostcc``"" - The `PreserveMost` calling convention; This calling convention attempts to make the code in the caller as; unintrusive as possible. This convention behaves identically to the `C`; calling convention on how arguments and return values are passed, but it; uses a different set of caller/callee-saved registers. This alleviates the; burden of saving and recovering a large register set before and after the; call in the caller. If the arguments are passed in callee-saved registers,; then they will be preserved by the callee across the call. This doesn't; apply for values returned in callee-saved registers. - On X86-64 the callee preserves all general purpose registers, except for; R11 and return registers, if any. R11 can be used as a sc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:15970,allocate,allocated,15970,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"en on the [demo page](https://root.cern/js/latest/httpserver.C/). One could also specify similar URL parameters to configure the displayed items and drawing options. It is also possible to display one single item from the THttpServer server like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hpxpy/draw.htm?opt=colz>. ## Data monitoring with JSROOT. ### Monitoring with http server. The best possibility to organize the monitoring of data from a running application; is to use THttpServer. In such case the client can always access the latest; changes and request only the items currently displayed in the browser.; To enable monitoring, one should activate the appropriate checkbox or; provide __monitoring__ parameter in the URL string like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hprof/draw.htm?monitoring=1000>. The parameter value is the update interval in milliseconds. ### JSON file-based monitoring. Solid file-based monitoring (without integration of THttpServer into application) can be; implemented in JSON format. There is the [TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class,; which is capable to convert any (beside TTree) ROOT object into JSON. Any ROOT application can use such class to; create JSON files for selected objects and write such files in a directory,; which can be accessed via web server. Then one can use JSROOT to read such files and display objects in a web browser. There is a demonstration page showing such functionality: <https://root.cern/js/latest/demo/update_draw.htm>.; This demo page reads in cycle 20 json files and displays them. If one has a web server which already provides such JSON file, one could specify the URL to this file like:. <https://root.cern/js/latest/demo/update_draw.htm?addr=../httpserver.C/Canvases/c1/root.json.gz>. Here the same problem with [Cross-Origin Request](https://developer.mozilla.org/en/http_access_control) can appear. If the web server configuration cannot be chan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:31056,monitor,monitoring,31056,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency,"en the block is exited normally,; whether by fallthrough or directed control flow (such as ``return`` or; ``break``), the autorelease pool is restored to the saved state, releasing all; the objects in it. When the block is exited with an exception, the pool is not; drained. ``@autoreleasepool`` may be used in non-ARC translation units, with equivalent; semantics. A program is ill-formed if it refers to the ``NSAutoreleasePool`` class. .. admonition:: Rationale. Autorelease pools are clearly important for the compiler to reason about, but; it is far too much to expect the compiler to accurately reason about control; dependencies between two calls. It is also very easy to accidentally forget; to drain an autorelease pool when using the manual API, and this can; significantly inflate the process's high-water-mark. The introduction of a; new scope is unfortunate but basically required for sane interaction with the; rest of the language. Not draining the pool during an unwind is apparently; required by the Objective-C exceptions implementation. .. _arc.misc.externally_retained:. Externally-Retained Variables; -----------------------------. In some situations, variables with strong ownership are considered; externally-retained by the implementation. This means that the variable is; retained elsewhere, and therefore the implementation can elide retaining and; releasing its value. Such a variable is implicitly ``const`` for safety. In; contrast with ``__unsafe_unretained``, an externally-retained variable still; behaves as a strong variable outside of initialization and destruction. For; instance, when an externally-retained variable is captured in a block the value; of the variable is retained and released on block capture and destruction. It; also affects C++ features such as lambda capture, ``decltype``, and template; argument deduction. Implicitly, the implementation assumes that the :ref:`self parameter in a; non-init method <arc.misc.self>` and the :ref:`variable in a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:91810,drain,draining,91810,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['drain'],['draining']
Energy Efficiency,"en unmaintained for several years; it does not build with current ruby versions.; Given that this effectively meant that Ruby was dysfunctional and given that nobody (but package maintainers) has complained, we decided to remove it. ### Removal of previously deprecated or disabled packages. The packages `afs`, `chirp`, `glite`, `sapdb`, `srp` and `ios` have been removed from ROOT.; They were deprecated before, or never ported from configure, make to CMake. ### Remove GLUtesselator forward declaration from TVirtualX.h. It was never used in TVirtualX interfaces. If GLUtesselator forward declaration is required, use TGLUtil.h include instead. ## C++ Modules Technology Preview. ROOT has several features which interact with libraries and require implicit; header inclusion. This can be triggered by reading or writing data on disk,; or user actions at the prompt. Often, the headers are immutable and reparsing is; redundant. C++ Modules are designed to minimize the reparsing of the same; header content by providing an efficient on-disk representation of C++ Code. This is an experimental feature which can be enabled by compiling ROOT with; `-Druntime_cxxmodules=On`. You can read more about the current state of the; feature [here](../../README.CXXMODULES.md). ## Core Libraries. ### New command line flag ""--version"" for root. `root --version` now displays ROOT version and build info and quits:. ```; ROOT Version: 6.15/01; Built for linuxx8664gcc on Sep 20 2018, 11:04:35; From heads/master@v6-13-04-1273-gea3f4333a2; ```. ### Fish support for thisroot script. `. bin/thisroot.fish` sets up the needed ROOT environment variables for one of the ROOT team's favorite shells, the [fish shell](https://fishshell.com/). ### Change of setting the compression algorithm in `rootrc`. The previous setting called `ROOT.ZipMode` is now unused and ignored.; Instead, use `Root.CompressionAlgorithm` which sets the compression algorithm according to the values of [ECompression](https://root.cern/doc/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:2277,efficient,efficient,2277,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['efficient'],['efficient']
Energy Efficiency,"en.wikipedia.org/wiki/Control-flow_graph#Reducibility>`_; has a more formal definition, which basically says that every cycle has; a dominating header. * Irreducible control-flow can occur at any level of the loop nesting.; That is, a loop that itself does not contain any loops can still have; cyclic control flow in its body; a loop that is not nested inside; another loop can still be part of an outer cycle; and there can be; additional cycles between any two loops where one is contained in the other.; However, an LLVM :ref:`cycle<cycle-terminology>` covers both, loops and; irreducible control flow. * The `FixIrreducible <https://llvm.org/doxygen/FixIrreducible_8h.html>`_; pass can transform irreducible control flow into loops by inserting; new loop headers. It is not included in any default optimization pass; pipeline, but is required for some back-end targets. * Exiting edges are not the only way to break out of a loop. Other; possibilities are unreachable terminators, [[noreturn]] functions,; exceptions, signals, and your computer's power button. * A basic block ""inside"" the loop that does not have a path back to the; loop (i.e. to a latch or header) is not considered part of the loop.; This is illustrated by the following code. .. code-block:: C. for (unsigned i = 0; i <= n; ++i) {; if (c1) {; // When reaching this block, we will have exited the loop.; do_something();; break;; }; if (c2) {; // abort(), never returns, so we have exited the loop.; abort();; }; if (c3) {; // The unreachable allows the compiler to assume that this will not rejoin the loop.; do_something();; __builtin_unreachable();; }; if (c4) {; // This statically infinite loop is not nested because control-flow will not continue with the for-loop.; while(true) {; do_something();; }; }; }. * There is no requirement for the control flow to eventually leave the; loop, i.e. a loop can be infinite. A **statically infinite loop** is a; loop that has no exiting edges. A **dynamically infinite loop** has;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:5976,power,power,5976,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['power'],['power']
Energy Efficiency,"enVector_exception class is created only when the throwing of exception is enabled. This avoids the allocation of an un-needed std::string. This problem was observed in CMS when converting from 4D-vectors based on mass to standard (x,y,z,t) vectors, when the mass is zero. In this case, a numerical error creates artificially small negative masses returned by the (x,y,z,t) vector. Eventually a protection could be added when calculating M2(), to avoid negative values due to numerical rounding.; ; Fix a problem in the assignment operator of the ROOT::Math::PxPyPzM4D class. Avoid having nan when converting for example from PxPyPzME4D to PxPyPzM4D when the mass is negative. ; Throw always exception in the non-supported setters (i.e. SetPt on a PxPyPzEVector) methods, which are generated only for the CINT dictionary. These methods flag a compiled-error when running in C++ mode. SMatrix. Change implementation of the SMatrix::Invert and SMatrix::Inverse methods. Now the optimized method based on the Cramer rule is used only for matrix up to sizes 2x2. The standard methods based on LU (for ordinary square matrix) or Bunch-Kaufman factorization (for square matrix) are used. The factorization method, although slower for small size matrices, they suffer much less from numerical precision problems.; New methods SMatrix::Invert and SMatrix::InverseFast are added for using the Cramer rule for up to matrix of sizes 5x5. This method has exactly the same implementation as the Invert and Inverse of the previous ROOT version.; ; Physics. TLorentzVector:Change in the implementation of the function SetPtEtaPhi and SetPtEtaPhiM the algorithm to calculate z from pt and eta. Use now, as in the GenVector package, the expression z = pt * sinh(eta) instead of using the tangent and the arc-tangent. This is is more efficient and avoids a problem found on 64 bit machines when eta=0. by Dariusz Miskowiec. Unuran. New version (1.3) from Josef Leydold fixing some warnings on Windows Visual Studio 9. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html:5910,efficient,efficient,5910,math/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html,2,['efficient'],['efficient']
Energy Efficiency,"enable optimizations that may decrease floating point; precision. .. option:: -soft-float. Causes :program:`lli` to generate software floating point library calls instead of; equivalent hardware instructions. CODE GENERATION OPTIONS; -----------------------. .. option:: -code-model=model. Choose the code model from:. .. code-block:: text. default: Target default code model; tiny: Tiny code model; small: Small code model; kernel: Kernel code model; medium: Medium code model; large: Large code model. .. option:: -disable-post-RA-scheduler. Disable scheduling after register allocation. .. option:: -disable-spill-fusing. Disable fusing of spill code into instructions. .. option:: -jit-enable-eh. Exception handling should be enabled in the just-in-time compiler. .. option:: -join-liveintervals. Coalesce copies (default=true). .. option:: -nozero-initialized-in-bss. Don't place zero-initialized symbols into the BSS section. .. option:: -pre-RA-sched=scheduler. Instruction schedulers available (before register allocation):. .. code-block:: text. =default: Best scheduler for the target; =none: No scheduling: breadth first sequencing; =simple: Simple two pass scheduling: minimize critical path and maximize processor utilization; =simple-noitin: Simple two pass scheduling: Same as simple except using generic latency; =list-burr: Bottom-up register reduction list scheduling; =list-tdrr: Top-down register reduction list scheduling; =list-td: Top-down list scheduler. .. option:: -regalloc=allocator. Register allocator to use (default=linearscan). .. code-block:: text. =bigblock: Big-block register allocator; =linearscan: linear scan register allocator; =local: local register allocator; =simple: simple register allocator. .. option:: -relocation-model=model. Choose relocation model from:. .. code-block:: text. =default: Target default relocation model; =static: Non-relocatable code; =pic: Fully relocatable, position independent code; =dynamic-no-pic: Relocatable external referenc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:4279,schedul,schedulers,4279,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,1,['schedul'],['schedulers']
Energy Efficiency,"end(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. The `entry` block establishes the coroutine frame. The `coro.size`_ intrinsic is; lowered to a constant representing the size required for the coroutine frame.; The `coro.begin`_ intrinsic initializes the coroutine frame and returns the; coroutine handle. The second parameter of `coro.begin` is given a block of memory; to be used if the coroutine frame needs to be allocated dynamically.; The `coro.id`_ intrinsic serves as coroutine identity useful in cases when the; `coro.begin`_ intrinsic get duplicated by optimization passes such as; jump-threading. The `cleanup` block destroys the coroutine frame. The `coro.free`_ intrinsic,; given the coroutine handle, returns a pointer of the memory block to be freed or; `null` if the coroutine frame was not allocated dynamically. The `cleanup`; block is entered when coroutine runs to completion by itself or destroyed via; call to the `coro.destroy`_ intrinsic. The `suspend` block contains code to be executed when coroutine runs to; completion or suspended. The `coro.end`_ intrinsic marks the point where; a coroutine needs to return control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is building the coroutine frame. The; def-use chains are analyzed to determine which objects need be kept alive across; suspend points. In the coroutine shown in the previous section, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:13056,allocate,allocated,13056,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['allocate'],['allocated']
Energy Efficiency,"end_amd_kernel_code_t* directive. For any; amd_kernel_code_t values that are unspecified a default value will be used. The; default value for all keys is 0, with the following exceptions:. - *amd_code_version_major* defaults to 1.; - *amd_kernel_code_version_minor* defaults to 2.; - *amd_machine_kind* defaults to 1.; - *amd_machine_version_major*, *machine_version_minor*, and; *amd_machine_version_stepping* are derived from the value of the -mcpu option; that is passed to the assembler.; - *kernel_code_entry_byte_offset* defaults to 256.; - *wavefront_size* defaults 6 for all targets before GFX10. For GFX10 onwards; defaults to 6 if target feature ``wavefrontsize64`` is enabled, otherwise 5.; Note that wavefront size is specified as a power of two, so a value of **n**; means a size of 2^ **n**.; - *call_convention* defaults to -1.; - *kernarg_segment_alignment*, *group_segment_alignment*, and; *private_segment_alignment* default to 4. Note that alignments are specified; as a power of 2, so a value of **n** means an alignment of 2^ **n**.; - *enable_tg_split* defaults to 1 if target feature ``tgsplit`` is enabled for; GFX90A onwards.; - *enable_wgp_mode* defaults to 1 if target feature ``cumode`` is disabled for; GFX10 onwards.; - *enable_mem_ordered* defaults to 1 for GFX10 onwards. The *.amd_kernel_code_t* directive must be placed immediately after the; function label and before any instructions. For a full list of amd_kernel_code_t keys, refer to AMDGPU ABI document,; comments in lib/Target/AMDGPU/AmdKernelCodeT.h and test/CodeGen/AMDGPU/hsa.s. .. _amdgpu-amdhsa-assembler-example-v2:. Code Object V2 Example Source Code; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. warning::; Code object V2 generation is no longer supported by this version of LLVM. Here is an example of a minimal assembly source file, defining one HSA kernel:. .. code::; :number-lines:. .hsa_code_object_version 1,0; .hsa_code_object_isa. .hsatext; .globl hello_world; .p2align 8; .amdgpu_hsa_kernel hello_w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:434747,power,power,434747,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['power'],['power']
Energy Efficiency,"ends for various; format / architecture combinations (as of July 2023). Support levels:. * None: No backend. JITLink will return an ""architecture not supported"" error.; Represented by empty cells in the table below.; * Skeleton: A backend exists, but does not support commonly used relocations.; Even simple programs are likely to trigger an ""unsupported relocation"" error.; Backends in this state may be easy to improve by implementing new relocations.; Consider getting involved!; * Basic: The backend supports simple programs, isn't ready for general use yet.; * Usable: The backend is useable for general use for at least one code and; relocation model.; * Good: The backend supports almost all relocations. Advanced features like; native thread local storage may not be available yet.; * Complete: The backend supports all relocations and object format features. .. list-table:: Availability and Status; :widths: 10 30 30 30; :header-rows: 1; :stub-columns: 1. * - Architecture; - ELF; - COFF; - MachO; * - arm32; - Skeleton; -; -; * - arm64; - Usable; -; - Good; * - LoongArch; - Good; -; -; * - PowerPC 64; - Usable; -; -; * - RISC-V; - Good; -; -; * - x86-32; - Basic; -; -; * - x86-64; - Good; - Usable; - Good. .. [1] See ``llvm/examples/OrcV2Examples/LLJITWithObjectLinkingLayerPlugin`` for; a full worked example. .. [2] If not for *hidden* scoped symbols we could eliminate the; ``JITLinkDylib*`` argument to ``JITLinkMemoryManager::allocate`` and; treat every object as a separate simulated dylib for the purposes of; memory layout. Hidden symbols break this by generating in-range accesses; to external symbols, requiring the access and symbol to be allocated; within range of one another. That said, providing a pre-reserved address; range pool for each simulated dylib guarantees that the relaxation; optimizations will kick in for all intra-dylib references, which is good; for performance (at the cost of whatever overhead is introduced by; reserving the address-range up-front).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:46814,allocate,allocate,46814,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,2,['allocate'],"['allocate', 'allocated']"
Energy Efficiency,"enecks are highlighted; in the summary view. Bottleneck analysis is currently not supported for; processors with an in-order backend. .. option:: -json. Print the requested views in valid JSON format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views refer to them by index. However, not all views are; currently supported. For example, the report from the bottleneck analysis is; not printed out in JSON. All the default views are currently supported. .. option:: -disable-cb. Force usage of the generic CustomBehaviour and InstrPostProcess classes rather; than using the target specific implementation. The generic classes never; detect any custom hazards or make any post processing modifications to; instructions. .. option:: -disable-im. Force usage of the generic InstrumentManager rather than using the target; specific implementation. The generic class creates Instruments that provide; no extra information, and InstrumentManager never overrides the default; schedule class for a given instruction. EXIT STATUS; -----------. :program:`llvm-mca` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. USING MARKERS TO ANALYZE SPECIFIC CODE BLOCKS; ---------------------------------------------; :program:`llvm-mca` allows for the optional usage of special code comments to; mark regions of the assembly code to be analyzed. A comment starting with; substring ``LLVM-MCA-BEGIN`` marks the beginning of an analysis region. A; comment starting with substring ``LLVM-MCA-END`` marks the end of a region.; For example:. .. code-block:: none. # LLVM-MCA-BEGIN; ...; # LLVM-MCA-END. If no user-defined region is specified, then :program:`llvm-mca` assumes a; default region which contains every instruction in the input file. Every region; is analyzed in isolation, and the final performance report is the union of all; the reports generated for every analysis region. Analy",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:7892,schedul,schedule,7892,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['schedule']
Energy Efficiency,"enerate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3152,reduce,reduce,3152,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['reduce'],['reduce']
Energy Efficiency,"ent; out-of-bounds (OOB) memory accesses, which remain a major source of security; vulnerabilities in C. ``-fbounds-safety`` aims to eliminate this class of bugs; by turning OOB accesses into deterministic traps. The ``-fbounds-safety`` extension offers bounds annotations that programmers can; use to attach bounds to pointers. For example, programmers can add the; ``__counted_by(N)`` annotation to parameter ``ptr``, indicating that the pointer; has ``N`` valid elements:. .. code-block:: c. void foo(int *__counted_by(N) ptr, size_t N);. Using this bounds information, the compiler inserts bounds checks on every; pointer dereference, ensuring that the program does not access memory outside; the specified bounds. The compiler requires programmers to provide enough bounds; information so that the accesses can be checked at either run time or compile; time â€” and it rejects code if it cannot. The most important contribution of ``-fbounds-safety`` is how it reduces the; programmer's annotation burden by reconciling bounds annotations at ABI; boundaries with the use of implicit wide pointers (a.k.a. ""fat"" pointers) that; carry bounds information on local variables without the need for annotations. We; designed this model so that it preserves ABI compatibility with C while; minimizing adoption effort. The ``-fbounds-safety`` extension has been adopted on millions of lines of; production C code and proven to work in a consumer operating system setting. The; extension was designed to enable incremental adoption â€” a key requirement in; real-world settings where modifying an entire project and its dependencies all; at once is often not possible. It also addresses multiple of other practical; challenges that have made existing approaches to safer C dialects difficult to; adopt, offering these properties that make it widely adoptable in practice:. * It is designed to preserve the Application Binary Interface (ABI).; * It interoperates well with plain C code.; * It can be adopted par",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:1233,reduce,reduces,1233,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['reduce'],['reduces']
Energy Efficiency,"entry in the assembly. Indirect calls with the :ref:`kcfi operand; bundle<ob_kcfi>` will emit a check that compares the type identifier to the; metadata. Example:. .. code-block:: text. define dso_local i32 @f() !kcfi_type !0 {; ret i32 0; }; !0 = !{i32 12345678}. Clang emits ``kcfi_type`` metadata nodes for address-taken functions with; ``-fsanitize=kcfi``. .. _md_memprof:. '``memprof``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^. The ``memprof`` metadata is used to record memory profile data on heap; allocation calls. Multiple context-sensitive profiles can be represented; with a single ``memprof`` metadata attachment. Example:. .. code-block:: text. %call = call ptr @_Znam(i64 10), !memprof !0, !callsite !5; !0 = !{!1, !3}; !1 = !{!2, !""cold""}; !2 = !{i64 4854880825882961848, i64 1905834578520680781}; !3 = !{!4, !""notcold""}; !4 = !{i64 4854880825882961848, i64 -6528110295079665978}; !5 = !{i64 4854880825882961848}. Each operand in the ``memprof`` metadata attachment describes the profiled; behavior of memory allocated by the associated allocation for a given context.; In the above example, there were 2 profiled contexts, one allocating memory; that was typically cold and one allocating memory that was typically not cold. The format of the metadata describing a context specific profile (e.g.; ``!1`` and ``!3`` above) requires a first operand that is a metadata node; describing the context, followed by a list of string metadata tags describing; the profile behavior (e.g. ``cold`` and ``notcold``) above. The metadata nodes; describing the context (e.g. ``!2`` and ``!4`` above) are unique ids; corresponding to callsites, which can be matched to associated IR calls via; :ref:`callsite metadata<md_callsite>`. In practice these ids are formed via; a hash of the callsite's debug info, and the associated call may be in a; different module. The contexts are listed in order from leaf-most call (the; allocation itself) to the outermost callsite context required for uniquely; identify",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:324622,allocate,allocated,324622,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"ents specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.experimental.constrained.ldexp``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type0>; @llvm.experimental.constrained.ldexp(<type0> <op1>, <type1> <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.ldexp``' performs the ldexp function. Arguments:; """""""""""""""""""". The first argument and the return value are :ref:`floating-point; <t_floating>` or :ref:`vector <t_vector>` of floating-point values of; the same type. The second argument is an integer with the same number; of elements. The third and fourth arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function multiplies the first argument by 2 raised to the second; argument's power. If the first argument is NaN or infinite, the same; value is returned. If the result underflows a zero with the same sign; is returned. If the result overflows, the result is an infinity with; the same sign. '``llvm.experimental.constrained.sin``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.experimental.constrained.sin(<type> <op1>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.sin``' intrinsic returns the sine of the; first operand. Arguments:; """""""""""""""""""". The first argument and the return type are floating-point numbers of the same; type. The second and third arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function returns the sine of the specified operand, returning the; same values as the libm ``sin`` functions would, and handles error; conditio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:893729,power,power,893729,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ents. N: David Blaikie; E: dblaikie@gmail.com; D: General bug fixing/fit & finish, mostly in Clang. N: Neil Booth; E: neil@daikokuya.co.uk; D: APFloat implementation. N: Alex Bradbury; E: asb@igalia.com; D: RISC-V backend. N: Misha Brukman; E: brukman+llvm@uiuc.edu; W: http://misha.brukman.net; D: Portions of X86 and Sparc JIT compilers, PowerPC backend; D: Incremental bitcode loader. N: Cameron Buschardt; E: buschard@uiuc.edu; D: The `mem2reg' pass - promotes values stored in memory to registers. N: Brendon Cahoon; E: bcahoon@codeaurora.org; D: Loop unrolling with run-time trip counts. N: Chandler Carruth; E: chandlerc@gmail.com; E: chandlerc@google.com; D: Hashing algorithms and interfaces; D: Inline cost analysis; D: Machine block placement pass; D: SROA. N: Casey Carter; E: ccarter@uiuc.edu; D: Fixes to the Reassociation pass, various improvement patches. N: Evan Cheng; E: evan.cheng@apple.com; D: ARM and X86 backends; D: Instruction scheduler improvements; D: Register allocator improvements; D: Loop optimizer improvements; D: Target-independent code generator improvements. N: Dan Villiom Podlaski Christiansen; E: danchr@gmail.com; E: danchr@cs.au.dk; W: http://villiom.dk; D: LLVM Makefile improvements; D: Clang diagnostic & driver tweaks; S: Aarhus, Denmark. N: Jeff Cohen; E: jeffc@jolt-lang.org; W: http://jolt-lang.org; D: Native Win32 API portability layer. N: John T. Criswell; E: criswell@uiuc.edu; D: Original Autoconf support, documentation improvements, bug fixes. N: Anshuman Dasgupta; E: adasgupt@codeaurora.org; D: Deterministic finite automaton based infrastructure for VLIW packetization. N: Stefanus Du Toit; E: stefanus.du.toit@intel.com; D: Bug fixes and minor improvements. N: Rafael Avila de Espindola; E: rafael@espindo.la; D: MC and LLD work. N: Dave Estes; E: cestes@codeaurora.org; D: AArch64 machine description for Cortex-A53. N: Alkis Evlogimenos; E: alkis@evlogimenos.com; D: Linear scan register allocator, many codegen improvements, Java frontend.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT:2423,schedul,scheduler,2423,interpreter/llvm-project/llvm/CREDITS.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT,1,['schedul'],['scheduler']
Energy Efficiency,"eportee, the committee will:. * Explain that an incident was reported that involves the reportee.; * In this explanation, the focus will be on the impact of their behavior, not; their intent.; * Reiterate the Code of Conduct and that their behavior may be deemed; inappropriate.; * Give them the opportunity to state their view of the incident.; * Explain the possible resolutions that may be enforced should the CoC; committee determine there is a breach. The reportee will be given a week to respond with the option to request; additional time if needed and subject to approval of the CoC Committee. .. _Resolutions:. Resolutions; ===========. The committee should agree unanimously on a resolution. In the event that the; committee cannot reach a unanimous resolution, the LLVM Foundation Board of; Directors will help resolve the situation and determine if the resolution can; proceed without a unanimous vote. When deciding on a resolution, the goal is to address the report in an; appropriate way, while also looking to prevent or reduce the risk of continuing; harm in the future. Any action deemed necessary by the committee will be; taken, but below is a list of possible resolutions:. * Taking no further action as the incident was determined not to be a; violation.; * A private verbal warning and/or reprimand from the committee to the; individual(s) involved and request to stop this behavior. This conversation; may happen in person, email, by phone, video chat, or IRC.; * Request that the reportee avoid any interaction with, and physical proximity; to, another person for the remainder of the event.; * Refusal of alcoholic beverage purchases by the reportee at LLVM events.; * Ending a talk/tutorial/etc at an LLVM event early. See immediate response; checklist for further clarification.; * Not publishing the video or slides of a talk.; * Not allowing a speaker to give (further) talks at LLVM events for a specified; amount of time or ever.; * Requiring that the reportee immediat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ResponseGuide.rst:7194,reduce,reduce,7194,interpreter/llvm-project/llvm/docs/ResponseGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ResponseGuide.rst,1,['reduce'],['reduce']
Energy Efficiency,"eps are taken by TableGen when a record is built. Classes are simply; abstract records and so go through the same steps. 1. Build the record name (:token:`NameValue`) and create an empty record. 2. Parse the parent classes in the :token:`ParentClassList` from left to; right, visiting each parent class's ancestor classes from top to bottom. a. Add the fields from the parent class to the record.; b. Substitute the template arguments into those fields.; c. Add the parent class to the record's list of inherited classes. 3. Apply any top-level ``let`` bindings to the record. Recall that top-level; bindings only apply to inherited fields. 4. Parse the body of the record. * Add any fields to the record.; * Modify the values of fields according to local ``let`` statements.; * Define any ``defvar`` variables. 5. Make a pass over all the fields to resolve any inter-field references. 6. Add the record to the final record list. Because references between fields are resolved (step 5) after ``let`` bindings are; applied (step 3), the ``let`` statement has unusual power. For example:. .. code-block:: text. class C <int x> {; int Y = x;; int Yplus1 = !add(Y, 1);; int xplus1 = !add(x, 1);; }. let Y = 10 in {; def rec1 : C<5> {; }; }. def rec2 : C<5> {; let Y = 10;; }. In both cases, one where a top-level ``let`` is used to bind ``Y`` and one; where a local ``let`` does the same thing, the results are:. .. code-block:: text. def rec1 { // C; int Y = 10;; int Yplus1 = 11;; int xplus1 = 6;; }; def rec2 { // C; int Y = 10;; int Yplus1 = 11;; int xplus1 = 6;; }. ``Yplus1`` is 11 because the ``let Y`` is performed before the ``!add(Y,; 1)`` is resolved. Use this power wisely. Using Classes as Subroutines; ============================. As described in `Simple values`_, a class can be invoked in an expression; and passed template arguments. This causes TableGen to create a new anonymous; record inheriting from that class. As usual, the record receives all the; fields defined in the class. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:54354,power,power,54354,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['power'],['power']
Energy Efficiency,"equirements of the first section of; [intro.progress] of the C++ Standard. As a consequence, a loop in a; function with the `mustprogress` attribute can be assumed to terminate if; it does not interact with the environment in an observable way, and; terminating loops without side-effects can be removed. If a `mustprogress`; function does not satisfy this contract, the behavior is undefined. This; attribute does not apply transitively to callees, but does apply to call; sites within the function. Note that `willreturn` implies `mustprogress`.; ``""warn-stack-size""=""<threshold>""``; This attribute sets a threshold to emit diagnostics once the frame size is; known should the frame size exceed the specified value. It takes one; required integer value, which should be a non-negative integer, and less; than `UINT_MAX`. It's unspecified which threshold will be used when; duplicate definitions are linked together with differing values.; ``vscale_range(<min>[, <max>])``; This function attribute indicates `vscale` is a power-of-two within a; specified range. `min` must be a power-of-two that is greater than 0. When; specified, `max` must be a power-of-two greater-than-or-equal to `min` or 0; to signify an unbounded maximum. The syntax `vscale_range(<val>)` can be; used to set both `min` and `max` to the same value. Functions that don't; include this attribute make no assumptions about the value of `vscale`.; ``""nooutline""``; This attribute indicates that outlining passes should not modify the; function. Call Site Attributes; ----------------------. In addition to function attributes the following call site only; attributes are supported:. ``vector-function-abi-variant``; This attribute can be attached to a :ref:`call <i_call>` to list; the vector functions associated to the function. Notice that the; attribute cannot be attached to a :ref:`invoke <i_invoke>` or a; :ref:`callbr <i_callbr>` instruction. The attribute consists of a; comma separated list of mangled names. The order ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:111090,power,power-of-two,111090,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power-of-two']
Energy Efficiency,"er all variables.; These two overloads previously behaved inconsistently when the `correctForBinSize` or `inverseBinCor` flags were set.; If you use the `RooDataHist::sum()` function in you own classes, please check that it can still be used with its new logic.; The new and corrected bin correction behaviour is:. - `correctForBinSize`: multiply counts in each bin by the bin volume corresponding to the variables in `sumSet`; - `inverseBinCor`: divide counts in each bin by the bin volume corresponding to the variables *not* in `sumSet`. ### New fully parametrised Crystal Ball shape class. So far, the Crystal Ball distribution has been represented in RooFit only by the `RooCBShape` class, which has a Gaussian core and a single power-law tail on one side.; This release introduces [`RooCrystalBall`](https://root.cern/doc/v624/classRooCrystalBall.html), which implements some common generalizations of the Crystal Ball shape:. - symmetric or asymmetric power-law tails on both sides; - different width parameters for the left and right sides of the Gaussian core. The new `RooCrystalBall` class can substitute the `RooDSCBShape` and `RooSDSCBShape`, which were passed around in the community. ## 2D Graphics Libraries. - Add the method `AddPoint`to `TGraph(x,y)` and `TGraph2D(x,y,z)`, equivalent to `SetPoint(g->GetN(),x,y)`and `SetPoint(g->GetN(),x,y,z)`; - Option `E0` draws error bars and markers are drawn for bins with 0 contents. Now, combined; with options E1 and E2, it avoids error bars clipping. ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### Multithreaded support for FastCGI. Now when THttpServer creates FastCGI engine, 10 worker threads used to process requests; received via FastCGI channel. This significantly increase a performance, especially when; several clients are connected. ### Better security for THttpServer with webgui. If THttpServer created for use with webgui widgets (RBrowser, RCanvas, REve), it only will; p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:24365,power,power-law,24365,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['power'],['power-law']
Energy Efficiency,"er arguments, will; pass the rest as decomposed stack elements? But an argument that will not start; in registers will not be decomposed and will be passed as a non-decomposed; stack value?. The following is not part of the AMDGPU function calling convention but; describes how the AMDGPU implements function calls:. 1. SGPR33 is used as a frame pointer (FP) if necessary. Like the SP it is an; unswizzled scratch address. It is only needed if runtime sized ``alloca``; are used, or for the reasons defined in ``SIFrameLowering``.; 2. Runtime stack alignment is supported. SGPR34 is used as a base pointer (BP); to access the incoming stack arguments in the function. The BP is needed; only when the function requires the runtime stack alignment. 3. Allocating SGPR arguments on the stack are not supported. 4. No CFI is currently generated. See; :ref:`amdgpu-dwarf-call-frame-information`. .. note::. CFI will be generated that defines the CFA as the unswizzled address; relative to the wave scratch base in the unswizzled private address space; of the lowest address stack allocated local variable. ``DW_AT_frame_base`` will be defined as the swizzled address in the; swizzled private address space by dividing the CFA by the wavefront size; (since CFA is always at least dword aligned which matches the scratch; swizzle element size). If no dynamic stack alignment was performed, the stack allocated arguments; are accessed as negative offsets relative to ``DW_AT_frame_base``, and the; local variables and register spill slots are accessed as positive offsets; relative to ``DW_AT_frame_base``. 5. Function argument passing is implemented by copying the input physical; registers to virtual registers on entry. The register allocator can spill if; necessary. These are copied back to physical registers at call sites. The; net effect is that each function call can have these values in entirely; distinct locations. The IPRA can help avoid shuffling argument registers.; 6. Call sites are implemen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:398673,allocate,allocated,398673,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"er contents. Many improvements in text and axis rendering for orthographic; view markup. In TGLSceneBase add data-member Bool_t; fSelectable allowing one to preventing any of its elements to be; selected. Useful when given scene is used as background to help guid; the eye. Eve. Added support for internal window management. Windows can be; arranged in horizontal/vertical stacks, tabs and main windows.; The containers and individaul windows can be moved to arbitrary; window-slot. See classes TEveWindow and TEveWindowManager. See tutorial tutorials/eve/test_windows.C. TEveQuadSet -- Add flag 'Bool_t fAntiFlick'. If on (now the; default) it causes each quad to be also rendered as a pixel, thus; preventing it from disappearing when zoomed away. This is needed for visualization of small quads, e.g. silicon; detectors digits. TEveCalo classes -- Add support for automatic rebinning; of 3D views (only supported for 2D views before). In 2D mode support; automatic determination of the cell color based on the most energetic; contribution from available calo slices. Add support for enumerative registration of calorimeter towers. Before; one had to provide THStack as input. See TEveCaloDataVec; class. TEveTrackList -- Generalized API for finding of momentum; limits. TEveTrackPropagator now supports propagation of charged; particles in arbitrary / external magnetic field. Propagation can be; done with the helix-stepper or with the Runge-Kutta method. New abstract interface to magnetic field TEveMagField to get; field vector at given position. Implement two interfaces:; TEveMagFieldConst for constant magnetic field and; TEveMagFieldDuo (two constant magnetic fields, chosen by; cylindrical radius). See examples in tutorials/eve/track.C. TEvePointSetArray -- Added underflow and overflow bins. Many improvements in text and axis rendering for axes in; non-linear projections and for the dedicated lego view. New tutorial tutorials/eve/lineset_test.py showing how; tu run Eve from python. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v522/index.html:1721,charge,charged,1721,graf3d/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v522/index.html,2,['charge'],['charged']
Energy Efficiency,"er for a concrete usage example. Significant improvement of the performance of SetBranchAddress/SetAddress (by a factor 3 to 10 depending on the length/complexity of the classname).; Prevent the unlimited growth of the TBasket's buffer even if the basket is reused.; When the basket is Reset (this happens when it is written and will be reused),; if the TBuffer size is greater than. - twice the data in the current basket; and - twice the average data in each basket (of this branch); and - twice the requeste basket size (TBranch::GetBasketSize).; the size of the buffer is reduced to the max of; 'the data in the current basket' and 'the average' and the requested; buffer size and aligned to next highest multiple of 512.; In TBranchRef distinguish between the entry we need (now called RequestedEntry) and the; entry we have read (fReadEntry) so that we can avoid re-reading the same entry too many; times when executing TRef::GetObject.; Reduce by 40% the time taken GetEntry for a branch created using a leaflist (exclusive of the decompression time).; Introduce TVirtualPerfStats::FileUnzipEvent to be able to keep track of the cost of unzipping and use this in TTreePerfStats and TBasket ... This give a good picture of where the time in unzip or in unstreaming; Add more clusters to the TTreeCache buffer until fBufferMinSize is hit to avoid severely underfilled buffer when; a low number of branches is selected/used.; When reading backwards, make sure to load a full (new) cluster and several other fixes to TTreeCache.; Reduce the memory used by a TTree in half. Refactor the code reading and writing the TBasket data.; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch.; In TTree::Fill, call FlushBasket before calling OptimizeBaskets so that we have a correct; and accurate value of fTotBytes to use as the requested memory.; In TTree::OptimizeBasket enforces hard minimun for the basket ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:1479,Reduce,Reduce,1479,tree/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html,1,['Reduce'],['Reduce']
Energy Efficiency,"er is not updated via a ``PHI`` node, which; can also be controlled with an option. Arguments:; """""""""""""""""""". The integer argument is the loop decrement value used to decrement the loop; iteration counter. Semantics:; """""""""""""""""""". The '``llvm.loop.decrement.*``' intrinsics do a ``SUB`` of the loop iteration; counter with the given loop decrement value, and return false if the loop; should exit, this ``SUB`` is not allowed to wrap. The result is a condition; that is used by the conditional branch controlling the loop. Vector Reduction Intrinsics; ---------------------------. Horizontal reductions of vectors can be expressed using the following; intrinsics. Each one takes a vector operand as an input and applies its; respective operation across all elements of the vector, returning a single; scalar result of the same element type. .. _int_vector_reduce_add:. '``llvm.vector.reduce.add.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.add.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.add.*``' intrinsics do an integer ``ADD``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fadd:. '``llvm.vector.reduce.fadd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fadd.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fadd.*``' intrinsics do a floating-point; ``ADD`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:650516,reduce,reduce,650516,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"er with a boolean; invariant that is defined to be true. **Syntax**:. .. code-block:: c++. __builtin_assume(bool). **Example of Use**:. .. code-block:: c++. int foo(int x) {; __builtin_assume(x != 0);; // The optimizer may short-circuit this check using the invariant.; if (x == 0); return do_something();; return do_something_else();; }. **Description**:. The boolean argument to this function is defined to be true. The optimizer may; analyze the form of the expression provided as the argument and deduce from; that information used to optimize the program. If the condition is violated; during execution, the behavior is undefined. The argument itself is never; evaluated, so any side effects of the expression will be discarded. Query for this feature with ``__has_builtin(__builtin_assume)``. .. _langext-__builtin_assume_separate_storage:. ``__builtin_assume_separate_storage``; -------------------------------------. ``__builtin_assume_separate_storage`` is used to provide the optimizer with the; knowledge that its two arguments point to separately allocated objects. **Syntax**:. .. code-block:: c++. __builtin_assume_separate_storage(const volatile void *, const volatile void *). **Example of Use**:. .. code-block:: c++. int foo(int *x, int *y) {; __builtin_assume_separate_storage(x, y);; *x = 0;; *y = 1;; // The optimizer may optimize this to return 0 without reloading from *x.; return *x;; }. **Description**:. The arguments to this function are assumed to point into separately allocated; storage (either different variable definitions or different dynamic storage; allocations). The optimizer may use this fact to aid in alias analysis. If the; arguments point into the same storage, the behavior is undefined. Note that the; definition of ""storage"" here refers to the outermost enclosing allocation of any; particular object (so for example, it's never correct to call this function; passing the addresses of fields in the same struct, elements of the same array,; etc.). Query f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:99779,allocate,allocated,99779,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['allocate'],['allocated']
Energy Efficiency,"er) parameters. External parameters can be specified as; std::vector$<$double$>$ or as MnUserParameters. The return value is; always a MnUserParameterState. The optional argument $\mbox{maxcalls}$ specifies the (approximate); maximum number of function calls after which the calculation will be; stopped. ## MnMachinePrecision ##. [api:epsmac]. ### MnMachinePrecision() ###. M determines the nominal precision itself in the default constructor; MnMachinePrecision(). ### setPrecision(double eps) ###. Informs M that the relative floating point arithmetic precision is; $\mbox{eps}$. The method can be used to override M 's own; determination, when the user knows that the $\mbox{FCN}$ function; value is not calculated to the nominal machine accuracy. Typical values; of $\mbox{eps}$ are between $10^{-5}$ and $10^{-14}$. ## MnMigrad and VariableMetricMinimizer ##. [api:migrad]. MnMigrad provides minimization of the function by the method of; $\mbox{MIGRAD}$, the most efficient and complete single method,; recommended for general functions (see also [api:minimize]), and the; functionality for parameters interaction. It also retains the result; from the last minimization in case the user may want to do subsequent; minimization steps with parameter interactions in between the; minimization requests. The minimization is done by the; VariableMetricMinimizer. Minimization of the function can be done by; directly using the VariableMetricMinimizer if no parameters interaction; is required. The minimization produces as a by-product the error matrix; of the parameters, which is usually reliable unless warning messages are; produced. ### MnMigrad(const FCNBase&, const std::vector$<$double$>$&, const std::vector$<$double$>$&, unsigned int) ###. Constructor for the minimal required interface: $\mbox{FCN}$ and; starting values for parameters and uncertainties. Optional the strategy; level in MnStrategy can be specified. ### MnMigrad(const FCNBase&, const MnUserParameters&, unsigned int) ###",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:41906,efficient,efficient,41906,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['efficient'],['efficient']
Energy Efficiency,"er; on top of it. It also lets us focus on the more interesting compilers; related projects. > 2. Design issues to consider (an initial list that we should continue; > to modify). Note that I'm not trying to suggest actual solutions here,; > but just various directions we can pursue:. Understood. :). > a. A single-assignment VM, which we've both already been thinking; > about. Yup, I think that this makes a lot of sense. I am still intrigued,; however, by the prospect of a minimally allocated VM representation... I; think that it could have definite advantages for certain applications; (think very small machines, like PDAs). I don't, however, think that our; initial implementations should focus on this. :). Here are some other auxiliary goals that I think we should consider:. 1. Primary goal: Support a high performance dynamic compilation; system. This means that we have an ""ideal"" division of labor between; the runtime and static compilers. Of course, the other goals of the; system somewhat reduce the importance of this point (f.e. portability; reduces performance, but hopefully not much); 2. Portability to different processors. Since we are most familiar with; x86 and solaris, I think that these two are excellent candidates when; we get that far...; 3. Support for all languages & styles of programming (general purpose; VM). This is the point that disallows java style bytecodes, where all; array refs are checked for bounds, etc...; 4. Support linking between different language families. For example, call; C functions directly from Java without using the nasty/slow/gross JNI; layer. This involves several subpoints:; A. Support for languages that require garbage collectors and integration; with languages that don't. As a base point, we could insist on; always using a conservative GC, but implement free as a noop, f.e. > b. A strongly-typed VM. One question is do we need the types to be; > explicitly declared or should they be inferred by the dynamic; > compiler?. B. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:3409,reduce,reduce,3409,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['reduce'],['reduce']
Energy Efficiency,"erPC Processors manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Book E: Enhanced PowerPC Architecture <https://www.nxp.com/docs/en/user-guide/BOOK_EUM.pdf>`_. * `EREF: A Programmer's Reference Manual for Freescale Embedded Processors (EREFRM) <https://www.nxp.com/files-static/32bit/doc/ref_manual/EREF_RM.pdf>`_. * `Signal Processing Engine (SPE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/SPEPEM.pdf>`_. * `Variable-Length Encoding (VLE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/VLEPEM.pdf>`_. Other documents, collections, notes; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `PowerPC Compiler Writer's Guide <http://www.ibm.com/chips/techlib/techlib.nsf/techdocs/852569B20050FF7785256996007558C6>`_; * `Intro to PowerPC Architecture <http://www.ibm.com/developerworks/linux/library/l-powarch/>`_; * `Various IBM specifications and white papers <https://www.power.org/documentation/?document_company=105&document_category=all&publish_year=all&grid_order=DESC&grid_sort=title>`_; * `PowerPC ABI documents <http://penguinppc.org/dev/#library>`_; * `PowerPC64 alignment of long doubles (from GCC) <http://gcc.gnu.org/ml/gcc-patches/2003-09/msg00997.html>`_; * `Long branch stubs for powerpc64-linux (from binutils) <http://sources.redhat.com/ml/binutils/2002-04/msg00573.html>`_. AMDGPU; ------. Refer to :doc:`AMDGPUUsage` for additional documentation. RISC-V; ------; * `RISC-V User-Level ISA Specification <https://riscv.org/specifications/>`_. C-SKY; ------; * `C-SKY Architecture User Guide <https://github.com/c-sky/csky-doc/blob/master/CSKY%20Architecture%20user_guide.pdf>`_; * `C-SKY V2 ABI <https://github.com/c-sky/csky-doc/blob/master/C-SKY_V2_CPU_Applications_Binary_Interface_Standards_Manual.pdf>`_. LoongArch; ---------; * `LoongArch Reference Manual - Volume 1: Basic Architecture <https://loongson.github.io/LoongArch-Documentation/LoongArch-Vol1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:4079,power,power,4079,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,1,['power'],['power']
Energy Efficiency,"erate=`` or by setting the ``LLVM_PROFILE_FILE``; environment variable to specify an alternate file. If non-default file name; is specified by both the environment variable and the command line option,; the environment variable takes precedence. The file name pattern specified; can include different modifiers: ``%p``, ``%h``, ``%m``, ``%t``, and ``%c``. Any instance of ``%p`` in that file name will be replaced by the process; ID, so that you can easily distinguish the profile output from multiple; runs. .. code-block:: console. $ LLVM_PROFILE_FILE=""code-%p.profraw"" ./code. The modifier ``%h`` can be used in scenarios where the same instrumented; binary is run in multiple different host machines dumping profile data; to a shared network based storage. The ``%h`` specifier will be substituted; with the hostname so that profiles collected from different hosts do not; clobber each other. While the use of ``%p`` specifier can reduce the likelihood for the profiles; dumped from different processes to clobber each other, such clobbering can still; happen because of the ``pid`` re-use by the OS. Another side-effect of using; ``%p`` is that the storage requirement for raw profile data files is greatly; increased. To avoid issues like this, the ``%m`` specifier can used in the profile; name. When this specifier is used, the profiler runtime will substitute ``%m``; with a unique integer identifier associated with the instrumented binary. Additionally,; multiple raw profiles dumped from different processes that share a file system (can be; on different hosts) will be automatically merged by the profiler runtime during the; dumping. If the program links in multiple instrumented shared libraries, each library; will dump the profile data into its own profile data file (with its unique integer; id embedded in the profile name). Note that the merging enabled by ``%m`` is for raw; profile data generated by profiler runtime. The resulting merged ""raw"" profile data; file still needs to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:104815,reduce,reduce,104815,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduce']
Energy Efficiency,"erator find(StringRef Key);. and clients can call it using any one of:. .. code-block:: c++. Map.find(""foo""); // Lookup ""foo""; Map.find(std::string(""bar"")); // Lookup ""bar""; Map.find(StringRef(""\0baz"", 4)); // Lookup ""\0baz"". Similarly, APIs which need to return a string may return a ``StringRef``; instance, which can be used directly or converted to an ``std::string`` using; the ``str`` member function. See ``llvm/ADT/StringRef.h`` (`doxygen; <https://llvm.org/doxygen/StringRef_8h_source.html>`__) for more; information. You should rarely use the ``StringRef`` class directly, because it contains; pointers to external memory it is not generally safe to store an instance of the; class (unless you know that the external storage will not be freed).; ``StringRef`` is small and pervasive enough in LLVM that it should always be; passed by value. The ``Twine`` class; ^^^^^^^^^^^^^^^^^^^. The ``Twine`` (`doxygen <https://llvm.org/doxygen/classllvm_1_1Twine.html>`__); class is an efficient way for APIs to accept concatenated strings. For example,; a common LLVM paradigm is to name one instruction based on the name of another; instruction with a suffix, for example:. .. code-block:: c++. New = CmpInst::Create(..., SO->getName() + "".cmp"");. The ``Twine`` class is effectively a lightweight `rope; <http://en.wikipedia.org/wiki/Rope_(computer_science)>`_ which points to; temporary (stack allocated) objects. Twines can be implicitly constructed as; the result of the plus operator applied to strings (i.e., a C strings, an; ``std::string``, or a ``StringRef``). The twine delays the actual concatenation; of strings until it is actually required, at which point it can be efficiently; rendered directly into a character array. This avoids unnecessary heap; allocation involved in constructing the temporary results of string; concatenation. See ``llvm/ADT/Twine.h`` (`doxygen; <https://llvm.org/doxygen/Twine_8h_source.html>`__) and :ref:`here <dss_twine>`; for more information. As with a ``S",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:9857,efficient,efficient,9857,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"ere no basket is stored with the TTree object.; Fix the axis used for an histogram created by TTree::Draw for a branch of TString or std::string objects.; MakeProxy now correctly support branches that created with a leaflist with more than one leaf; (usually used for C-struct).; TTree::CloneTree and TChain::Merge in fast mode now can recover from some mismatch errors between; the input and output TTrees by falling back to using the 'slow' mode. In particular this allow; a 'fast cloning' to handle files that requires schema evolution (albeit it is of course much slower).; Make sure that the TTreeCache is not attempting to cache (wrongly) the content of branches that are in an auxiliary files.; Make sure that FillBuffer does it work when the learning phase is over even if the entry number is 'low' for the 'current' file of a chain.; If TTree::SetEventList is called, TTree::GetEntryList no longer relinquish ownership of the automatically created TEntryList; Add the ability to see the TTree UserInfo list from the TBrowser; Fix the case of reading a TTree containing an 'old' class layout that contained a std::vector that is no longer part of the current class layout; Implement direct interfaces from TTree to the result of TSelector::Draw; TTree:GetVal(int) and TTree::GetVar(int); In TTree::ReadFile add the possibility to read multiple input files and add support for large/wide Trees definition.; Added support for ""5-D"" plotting.; Added support for std::bitset; Reduce the memory used by the mechanism keeping track of the entry of variables sizes within a basket (fEntryOffset).; The memory used now automatically decrease if the number of entries in the basket is less than 1/4 oflength of fEntryOffset.; Also the default length fEntryOffset can be set via TTree::SetDefaultEntryOffsetLen which can be optionially applied to the; existing branches. Parallel Coordinates. Fix a memory leak. The TParallelCoord destructor was not called; when the canvas used to draw it was closed. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html:1672,Reduce,Reduce,1672,tree/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html,1,['Reduce'],['Reduce']
Energy Efficiency,"eriment. The complete source for; `ATLFast` can be down loaded at; <ftp://root.cern.ch/root/atlfast.tar.gz>. Once we compile and run; `ATLFast` we get a ROOT file called `atlfast.root`, containing the; `ATLFast` objects. When we open the file, we get a warning that the file; contains classes that are not in the dictionary. This is correct; since we did not load the class definitions. ``` {.cpp}; root[] TFile f(""atlfast.root""); Warning in <TClass::TClass>: no dictionary for class TMCParticle is available; Warning in <TClass::TClass>: no dictionary for class ATLFMuon available; ```. We can see the `StreamerInfo `for the classes:. ``` {.cpp}; root[] f.ShowStreamerInfo(); ...; StreamerInfo for class: ATLFMuon, version=1; BASE TObject offset= 0 type=66 Basic ROOT object; BASE TAtt3D offset= 0 type= 0 3D attributes; Int_t m_KFcode offset= 0 type= 3 Muon KF-code; Int_t m_MCParticle offset= 0 type= 3 Muon position in MCParticles list; Int_t m_KFmother offset= 0 type= 3 Muon mother KF-code; Int_t m_UseFlag offset= 0 type= 3 Muon energy usage flag; Int_t m_Isolated offset= 0 type= 3 Muon isolation (1 for isolated); Float_t m_Eta offset= 0 type= 5 Eta coordinate; Float_t m_Phi offset= 0 type= 5 Phi coordinate; Float_t m_PT offset= 0 type= 5 Transverse energy; Int_t m_Trigger offset= 0 type= 3 Result of trigger...; ```. However, when we try to use a specific class we get a warning because; the class is not in the dictionary. We can create a class using; `gROOT->GetClass()` which makes a fake class from the `StreamerInfo`. ``` {.cpp}; // Build a 'fake' class; root[] gROOT->GetClass(""ATLFMuon""); (const class TClass*)0x87e5c08; // The fake class has a StreamerInfo; root[] gROOT->GetClass(""ATLFMuon"")->GetStreamerInfo()->ls(); StreamerInfo for class: ATLFMuon, version=1; BASE TObject offset= 0 type=66 Basic ROOT object; BASE TAtt3D offset= 0 type= 0 3D attributes; Int_t m_KFcode offset= 16 type= 3 Muon KF-code; Int_t m_MCParticle offset= 20 type= 3 Muon position in MCParticles list; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:86037,energy,energy,86037,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,2,['energy'],['energy']
Energy Efficiency,"erlying transport protocol to use ""s3:"",; ""s3http:"", ""s3https:"" [""s3"" uses HTTPS]. The current schema, namely; ""as3:"", is supported for backwards compatibility.; - extend support for other S3 service providers that do not offer the; virtual hosting functionality (currently only Amazon offers this).; - support the possibility of specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The id",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:1554,efficient,efficiently,1554,net/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md,1,['efficient'],['efficiently']
Energy Efficiency,"ern/js/latest/?file=https://root.cern/files/brahms.root&item=brahms;1&opt=dflt); * SLD: [full](https://root.cern/js/latest/?file=https://root.cern/files/sld.root&item=sld;1&opt=dflt;clipxyz). Together with geometry one could display tracks (TEveTrack) and hits (TEvePointSet, TPolyMarker3D) objects.; Either one do it interactively by drag and drop, or superimpose drawing with `+` sign like:. - [item=simple_alice.json.gz+tracks_hits.root/tracks+tracks_hits.root/hits](https://root.cern/js/latest/?nobrowser&json=../files/geom/simple_alice.json.gz&file=../files/geom/tracks_hits.root&item=simple_alice.json.gz+tracks_hits.root/tracks+tracks_hits.root/hits). There is a problem of correct rendering of transparent volumes. To solve problem in general is very expensive (in terms of computing power), therefore several approximation solution can be applied:; * **dpnt**: distance from camera view to the volume center used as rendering order; * **dbox**: distance to nearest point from bonding box used as rendering order (**default**); * **dsize**: volume size is used as rendering order, can be used for centered volumes with many shells around; * **dray**: use raycasting to sort volumes in order they appear along rays, coming out of camera point; * **ddflt**: default three.js method for rendering transparent volumes; For different geometries different methods can be applied. In any case, all opaque volumes rendered first. ## Reading ROOT files from other servers. In principle, one could open any ROOT file placed in the web, providing the full URL to it like:. - <https://jsroot.gsi.de/latest/?file=https://root.cern/js/files/hsimple.root&item=hpx>. But one should be aware of [Same-origin policy](https://en.wikipedia.org/wiki/Same-origin_policy),; when the browser blocks requests to files from domains other than current web page.; To enable CORS on Apache web server, hosting ROOT files, one should add following lines to `.htaccess` file:. <IfModule mod_headers.c>; <FilesMatch ""\.root""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:26728,power,power,26728,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['power'],['power']
Energy Efficiency,"ernal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, there comes a subtle semantic difference: the Python; ``__new__`` allocates memory for the proxy object only, and ``__init__``; initializes the proxy by creating or binding the C++ object.; Thus, no C++ memory is allocated until ``__init__``.; The advantages are simple: the proxy can now check whether it is initialized,; because the pointer to C++ memory will be NULL if not; it can be a reference; to another proxy holding the actual C++ memory; and it can now transparently; implement a C++ smart pointer.; If ``__init__`` is never called, eg. when a call to the base class; ``__init__`` is missing in a derived class override, then accessing the proxy; will result in a Python ``ReferenceError`` exception. `Destructors`; -------------. There should no be reason to call a destructor directly in CPython, but e.g.; PyPy uses a garbage collector and that makes it sometimes useful to destruct; a C++ object exactly when you want it destroyed.; Destructors are by convention accessible through the ``__destruct__`` method; (since ""~"" can not be part of a Python method name).; If a Python-side derived class overrides ``__destruct__``, that method will; be called when the instance gets deleted in C++.; The Pyth",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:2210,allocate,allocated,2210,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,1,['allocate'],['allocated']
Energy Efficiency,"ersion`` (ubyte). A version number (see Section 7.24 Call Frame Information). This number is; specific to the call frame information and is independent of the DWARF; version number. The value of the CIE version number is 4. .. note::. Would this be increased to 5 to reflect the changes in these extensions?. 4. ``augmentation`` (sequence of UTF-8 characters). A null-terminated UTF-8 string that identifies the augmentation to this CIE; or to the FDEs that use it. If a reader encounters an augmentation string; that is unexpected, then only the following fields can be read:. * CIE: length, CIE_id, version, augmentation; * FDE: length, CIE_pointer, initial_location, address_range. If there is no augmentation, this value is a zero byte. *The augmentation string allows users to indicate that there is additional; vendor and target architecture specific information in the CIE or FDE which; is needed to virtually unwind a stack frame. For example, this might be; information about dynamically allocated data which needs to be freed on exit; from the routine.*. *Because the* ``.debug_frame`` *section is useful independently of any*; ``.debug_info`` *section, the augmentation string always uses UTF-8; encoding.*. The recommended format for the augmentation string is:. | ``[``\ *vendor*\ ``:v``\ *X*\ ``.``\ *Y*\ [\ ``:``\ *options*\ ]\ ``]``\ *. Where *vendor* is the producer, ``vX.Y`` specifies the major X and minor Y; version number of the extensions used, and *options* is an optional string; providing additional information about the extensions. The version number; must conform to semantic versioning [:ref:`SEMVER <amdgpu-dwarf-SEMVER>`].; The *options* string must not contain the ""\ ``]``\ "" character. For example:. ::. [abc:v0.0][def:v1.2:feature-a=on,feature-b=3]. 5. ``address_size`` (ubyte). The size of a target address in this CIE and any FDEs that use it, in bytes.; If a compilation unit exists for this frame, its address size must match the; address size here. 6. ``segme",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:198577,allocate,allocated,198577,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency,"ersonalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the parent function that can be called; as though they were a function pointer with a very special calling convention.; The frame pointer of the parent frame is passed into the funclet either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implements the EH action by accessing local variables; in memory through the frame pointer, and returning some appropriate value,; continuing the EH process. No variables live in to or out of the funclet can be; allocated in registers. The C++ personality also uses funclets to contain the code for catch blocks; (i.e. all user code between the braces in ``catch (Type obj) { ... }``). The; runtime must use funclets for catch bodies because the C++ exception object is; allocated in a child stack frame of the function handling the exception. If the; runtime rewound the stack back to frame of the catch, the memory holding the; exception would be overwritten quickly by subsequent function calls. The use of; funclets also allows ``__CxxFrameHandler3`` to implement rethrow without; resorting to TLS. Instead, the runtime throws a special exception, and then uses; SEH (``__try / __except``) to resume execution with new information in the child; frame. In other words, the successive unwinding approach is incompatible with Visual; C++ exceptions and general purpose Windows exception handling. Because the C++; exception object lives in stack memory, LLVM cannot provide a custom personality; function that uses landingpads. Similarly, SEH does not provide any mechanism; to rethrow an exception or continue unwinding. Therefore, LLVM must use the IR; constructs described later in this document to implement compatible exception; handling. SEH filter expressi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:22865,allocate,allocated,22865,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,1,['allocate'],['allocated']
Energy Efficiency,"es a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; "".kernarg_segment_size"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; "".group_segment_fixed_size"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; "".private_segment_fixed_size"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; "".kernarg_segment_align"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; "".wavefront_size"" integer Required Wavefront size. Must; be a power of 2.; "".sgpr_count"" integer Required Number of scalar; registers required by a; wavefront for; GFX6-GFX9. A register; is required if it is; used explicitly, or; if a higher numbered; register is used; explicitly. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX9); and XNACK (for; GFX8-GFX9). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; "".vgpr_count"" integer Required Number of vector; registers required by; each work-item for; GFX6-GFX9. A register; is required if it is; used explicitly, or; if a higher numbered; register is used; explicitly.; "".agpr_count"" integer Required Number of accumulator; registers required by; each work-item for; GFX90A, GFX908.; "".max_flat_workgroup_size"" integer Required Maximum flat; work-group size; supported by the; kernel in work-items.; Must be >=1 and; consistent with; ReqdWorkGroupSize if; not 0, 0, 0.; "".sgpr_spill_count"" integer Number of store",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:134370,power,power,134370,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['power'],['power']
Energy Efficiency,"es an external symbol and its target; addressable. The target addressable must not be referenced by any other; symbols. * ``removeAbsoluteSymbol`` removes an absolute symbol and its target; addressable. The target addressable must not be referenced by any other; symbols. * ``removeDefinedSymbol`` removes a defined symbol, but *does not* remove; its target block. * ``removeBlock`` removes the given block. * ``splitBlock`` split a given block in two at a given index (useful where; it is known that a block contains decomposable records, e.g. CFI records; in an eh-frame section). * Graph utility operations. * ``getName`` returns the name of this graph, which is usually based on the; name of the input object file. * ``getTargetTriple`` returns an `llvm::Triple` for the executor process. * ``getPointerSize`` returns the size of a pointer (in bytes) in the executor; process. * ``getEndinaness`` returns the endianness of the executor process. * ``allocateString`` copies data from a given ``llvm::Twine`` into the; link graph's internal allocator. This can be used to ensure that content; created inside a pass outlives that pass's execution. .. _generic_link_algorithm:. Generic Link Algorithm; ======================. JITLink provides a generic link algorithm which can be extended / modified at; certain points by the introduction of JITLink :ref:`passes`. At the end of each phase the linker packages its state into a *continuation*; and calls the ``JITLinkContext`` object to perform a (potentially high-latency); asynchronous operation: allocating memory, resolving external symbols, and; finally transferring linked memory to the executing process. #. Phase 1. This phase is called immediately by the ``link`` function as soon as the; initial configuration (including the pass pipeline setup) is complete. #. Run pre-prune passes. These passes are called on the graph before it is pruned. At this stage; ``LinkGraph`` nodes still have their original vmaddrs. A mark-live pass; (supplied b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:17130,allocate,allocateString,17130,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocateString']
Energy Efficiency,"es an iteration, and the second index is the; instruction index (i.e., where it appears in the code sequence). Since this; example was generated using 3 iterations: ``-iterations=3``, the iteration; indices range from 0-2 inclusively. Excluding the first and last column, the remaining columns are in cycles.; Cycles are numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become available. By the time vmulps is; dispatched, operands are already available, and pipeline JFPU1 is ready to; serve another instruction. So the instruction can be immediately issued on the; JFPU1 pipeline. That is demonstrated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:24596,schedul,scheduler,24596,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"es http access to objects from running ROOT application.; JSROOT is used to implement the user interface in the web browsers. The layout of the main page coming from THttpServer is very similar to normal JSROOT page.; One could browse existing items and display them. A snapshot of running; server can be seen on the [demo page](https://root.cern/js/latest/httpserver.C/). One could also specify similar URL parameters to configure the displayed items and drawing options. It is also possible to display one single item from the THttpServer server like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hpxpy/draw.htm?opt=colz>. ## Data monitoring with JSROOT. ### Monitoring with http server. The best possibility to organize the monitoring of data from a running application; is to use THttpServer. In such case the client can always access the latest; changes and request only the items currently displayed in the browser.; To enable monitoring, one should activate the appropriate checkbox or; provide __monitoring__ parameter in the URL string like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hprof/draw.htm?monitoring=1000>. The parameter value is the update interval in milliseconds. ### JSON file-based monitoring. Solid file-based monitoring (without integration of THttpServer into application) can be; implemented in JSON format. There is the [TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class,; which is capable to convert any (beside TTree) ROOT object into JSON. Any ROOT application can use such class to; create JSON files for selected objects and write such files in a directory,; which can be accessed via web server. Then one can use JSROOT to read such files and display objects in a web browser. There is a demonstration page showing such functionality: <https://root.cern/js/latest/demo/update_draw.htm>.; This demo page reads in cycle 20 json files and displays them. If one has a web server which already provides such JSON file,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:30737,monitor,monitoring,30737,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency,"es if the kernel argument; is volatile qualified. Only; present if ""ValueKind"" is; ""GlobalBuffer"". ""IsPipe"" boolean Indicates if the kernel argument; is pipe qualified. Only present; if ""ValueKind"" is ""Pipe"". .. TODO::. Can GlobalBuffer be pipe; qualified?. ================= ============== ========= ================================. .. .. table:: AMDHSA Code Object V2 Kernel Code Properties Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-code-properties-metadata-map-v2-table. ============================ ============== ========= =====================; String Key Value Type Required? Description; ============================ ============== ========= =====================; ""KernargSegmentSize"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; ""GroupSegmentFixedSize"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; ""PrivateSegmentFixedSize"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; ""KernargSegmentAlign"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; ""WavefrontSize"" integer Required Wavefront size. Must; be a power of 2.; ""NumSGPRs"" integer Required Number of scalar; registers used by a; wavefront for; GFX6-GFX11. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX10); and XNACK (for; GFX8-GFX10). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; ""NumVGPRs"" integer Required Number of vector; registers used by; each work-item for; GFX6-GFX11; ""MaxFlatWorkGroupSize"" integer Required Maximum flat; work-group si",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:127990,allocate,allocated,127990,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"es(CGAM);; PB.registerFunctionAnalyses(FAM);; PB.registerLoopAnalyses(LAM);; PB.crossRegisterProxies(LAM, FAM, CGAM, MAM);. // Create the pass manager.; // This one corresponds to a typical -O2 optimization pipeline.; ModulePassManager MPM = PB.buildPerModuleDefaultPipeline(OptimizationLevel::O2);. // Optimize the IR!; MPM.run(MyModule, MAM);. The C API also supports most of this, see ``llvm-c/Transforms/PassBuilder.h``. Adding Passes to a Pass Manager; ===============================. For how to write a new PM pass, see :doc:`this page <WritingAnLLVMNewPMPass>`. To add a pass to a new PM pass manager, the important thing is to match the; pass type and the pass manager type. For example, a ``FunctionPassManager``; can only contain function passes:. .. code-block:: c++. FunctionPassManager FPM;; // InstSimplifyPass is a function pass; FPM.addPass(InstSimplifyPass());. If you want to add a loop pass that runs on all loops in a function to a; ``FunctionPassManager``, the loop pass must be wrapped in a function pass; adaptor that goes through all the loops in the function and runs the loop; pass on each one. .. code-block:: c++. FunctionPassManager FPM;; // LoopRotatePass is a loop pass; FPM.addPass(createFunctionToLoopPassAdaptor(LoopRotatePass()));. The IR hierarchy in terms of the new PM is Module -> (CGSCC ->) Function ->; Loop, where going through a CGSCC is optional. .. code-block:: c++. FunctionPassManager FPM;; // loop -> function; FPM.addPass(createFunctionToLoopPassAdaptor(LoopFooPass()));. CGSCCPassManager CGPM;; // loop -> function -> cgscc; CGPM.addPass(createCGSCCToFunctionPassAdaptor(createFunctionToLoopPassAdaptor(LoopFooPass())));; // function -> cgscc; CGPM.addPass(createCGSCCToFunctionPassAdaptor(FunctionFooPass()));. ModulePassManager MPM;; // loop -> function -> module; MPM.addPass(createModuleToFunctionPassAdaptor(createFunctionToLoopPassAdaptor(LoopFooPass())));; // function -> module; MPM.addPass(createModuleToFunctionPassAdaptor(FunctionFooPass(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:2076,adapt,adaptor,2076,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['adapt'],['adaptor']
Energy Efficiency,"es, etc...). 6. Define a set of generally useful annotations to add to the VM; representation. For example, a function can be analysed to see if it; has any sideeffects when run... also, the MOD/REF sets could be; calculated, etc... we would have to determine what is reasonable. This; would generally be used to make IP optimizations cheaper for the; runtime compiler... > o Explicit instructions to handle aliasing, e.g.s:; > -- an instruction to say ""I speculate that these two values are not; > aliased, but check at runtime"", like speculative execution in; > EPIC?; > -- or an instruction to check whether two values are aliased and; > execute different code depending on the answer, somewhat like; > predicated code in EPIC. These are also very good points... if this can be determined at compile; time. I think that an epic style of representation (not the instruction; packing, just the information presented) could be a very interesting model; to use... more later... > o (This one is a difficult but powerful idea.); > A ""thread-id"" field on every instruction that allows the static; > compiler to generate a set of parallel threads, and then have; > the runtime compiler and hardware do what they please with it.; > This has very powerful uses, but thread-id on every instruction; > is expensive in terms of instruction size and code size.; > We would need to compactly encode it somehow. Yes yes yes! :) I think it would be *VERY* useful to include this kind; of information (which EPIC architectures *implicitly* encode. The trend; that we are seeing supports this greatly:. 1. Commodity processors are getting massive SIMD support:; * Intel/Amd MMX/MMX2; * AMD's 3Dnow!; * Intel's SSE/SSE2; * Sun's VIS; 2. SMP is becoming much more common, especially in the server space.; 3. Multiple processors on a die are right around the corner. If nothing else, not designing this in would severely limit our future; expansion of the project... > Also, this will require some reading on at least ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:7001,power,powerful,7001,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['power'],['powerful']
Energy Efficiency,"es, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31863,schedul,scheduler,31863,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"es. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. =========",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:210614,allocate,allocated,210614,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"esponds to a developersâ€™ intuitions, allowing them to make changes in; their code, and to see the result of these changes without interrupting the; running program. Interactive programming gives programmers the freedom to; explore different scenarios while developing software, writing one expression; at a time, figuring out what to do next at each step, and enabling them to; quickly identify and fix bugs whenever they arise. As an example, the; High-Energy Physics community includes professionals with a variety of; backgrounds, including physicists, nuclear engineers, and software; engineers. Cling allows for interactive data analysis in `ROOT; <https://root.cern/>`_ by giving researchers a way to prototype their C++ code,; allowing them to tailor it to the particular scope of the analysis they want to; pursue on a particular set of data before being added to the main framework. **Interpreted language** is a way to achieve interactive programming. In; statically compiled language, all source code is converted into native machine; code and then executed by the processor before being run. An interpreted; language instead runs through source programs line by line, taking an; executable segment of source code, turning it into machine code, and then; executing it. With this approach, when a change is made by the programmer, the; interpreter will convey it without the need for the entire source code to be; manually compiled. Interpreted languages are flexible, and offer features like; dynamic typing and smaller program size. **Cling** is not an interpreter, it is a Just-In-Time (JIT) compiler that feels; like an interpreter, and allows C++, a language designed to be compiled, to be; interpreted. When using Cling, the programmer benefits from both the power of; C++ language, such as high-performance, robustness, fastness, efficiency,; versatility, and the capability of an interpreter, which allows for interactive; exploration and on-the-fly inspection of the source-code.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst:2010,power,power,2010,interpreter/cling/docs/chapters/interactivity.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst,1,['power'],['power']
Energy Efficiency,"ess of an aggregate argument that is being passed by; value through memory. Primarily, this feature is required for; compatibility with the Microsoft C++ ABI. Under that ABI, class; instances that are passed by value are constructed directly into; argument stack memory. Prior to the addition of inalloca, calls in LLVM; were indivisible instructions. There was no way to perform intermediate; work, such as object construction, between the first stack adjustment; and the final control transfer. With inalloca, all arguments passed in; memory are modelled as a single alloca, which can be stored to prior to; the call. Unfortunately, this complicated feature comes with a large; set of restrictions designed to bound the lifetime of the argument; memory around the call. For now, it is recommended that frontends and optimizers avoid producing; this construct, primarily because it forces the use of a base pointer.; This feature may grow in the future to allow general mid-level; optimization, but for now, it should be regarded as less efficient than; passing by value with a copy. Intended Usage; ==============. The example below is the intended LLVM IR lowering for some C++ code; that passes two default-constructed ``Foo`` objects to ``g`` in the; 32-bit Microsoft C++ ABI. .. code-block:: c++. // Foo is non-trivial.; struct Foo { int a, b; Foo(); ~Foo(); Foo(const Foo &); };; void g(Foo a, Foo b);; void f() {; g(Foo(), Foo());; }. .. code-block:: text. %struct.Foo = type { i32, i32 }; declare void @Foo_ctor(%struct.Foo* %this); declare void @Foo_dtor(%struct.Foo* %this); declare void @g(<{ %struct.Foo, %struct.Foo }>* inalloca %memargs). define void @f() {; entry:; %base = call i8* @llvm.stacksave(); %memargs = alloca <{ %struct.Foo, %struct.Foo }>; %b = getelementptr <{ %struct.Foo, %struct.Foo }>* %memargs, i32 1; call void @Foo_ctor(%struct.Foo* %b). ; If a's ctor throws, we must destruct b.; %a = getelementptr <{ %struct.Foo, %struct.Foo }>* %memargs, i32 0; invoke void @Fo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst:1282,efficient,efficient,1282,interpreter/llvm-project/llvm/docs/InAlloca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InAlloca.rst,1,['efficient'],['efficient']
Energy Efficiency,"essing C source code. The main; interface to this library for outside clients is the large ``Preprocessor``; class. It contains the various pieces of state that are required to coherently; read tokens out of a translation unit. The core interface to the ``Preprocessor`` object (once it is set up) is the; ``Preprocessor::Lex`` method, which returns the next :ref:`Token <Token>` from; the preprocessor stream. There are two types of token providers that the; preprocessor is capable of reading from: a buffer lexer (provided by the; :ref:`Lexer <Lexer>` class) and a buffered token stream (provided by the; :ref:`TokenLexer <TokenLexer>` class). .. _Token:. The Token class; ---------------. The ``Token`` class is used to represent a single lexed token. Tokens are; intended to be used by the lexer/preprocess and parser libraries, but are not; intended to live beyond them (for example, they should not live in the ASTs). Tokens most often live on the stack (or some other location that is efficient; to access) as the parser is running, but occasionally do get buffered up. For; example, macro definitions are stored as a series of tokens, and the C++; front-end periodically needs to buffer tokens up for tentative parsing and; various pieces of look-ahead. As such, the size of a ``Token`` matters. On a; 32-bit system, ``sizeof(Token)`` is currently 16 bytes. Tokens occur in two forms: :ref:`annotation tokens <AnnotationToken>` and; normal tokens. Normal tokens are those returned by the lexer, annotation; tokens represent semantic information and are produced by the parser, replacing; normal tokens in the token stream. Normal tokens contain the following; information:. * **A SourceLocation** --- This indicates the location of the start of the; token. * **A length** --- This stores the length of the token as stored in the; ``SourceBuffer``. For tokens that include them, this length includes; trigraphs and escaped newlines which are ignored by later phases of the; compiler. By pointi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:44909,efficient,efficient,44909,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"ested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. *",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:10425,reduce,reduces,10425,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['reduce'],['reduces']
Energy Efficiency,"et 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:63432,efficient,efficiently,63432,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['efficient'],['efficiently']
Energy Efficiency,"et, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fadd operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fadd(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, negative zero (``-0.0``) can be used, as it is; the neutral value of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(doubl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:652472,reduce,reduce,652472,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"etTracker`` are guaranteed to be; disjoint, calculate mod/ref information and volatility for the set, and keep; track of whether or not all of the pointers in the set are Must aliases. The; AliasSetTracker also makes sure that sets are properly folded due to call; instructions, and can provide a list of pointers in each set. As an example user of this, the `Loop Invariant Code Motion; <doxygen/structLICM.html>`_ pass uses ``AliasSetTracker``\s to calculate alias; sets for each loop nest. If an ``AliasSet`` in a loop is not modified, then all; load instructions from that set may be hoisted out of the loop. If any alias; sets are stored to **and** are must alias sets, then the stores may be sunk; to outside of the loop, promoting the memory location to a register for the; duration of the loop nest. Both of these transformations only apply if the; pointer argument is loop-invariant. The AliasSetTracker implementation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The AliasSetTracker class is implemented to be as efficient as possible. It; uses the union-find algorithm to efficiently merge AliasSets when a pointer is; inserted into the AliasSetTracker that aliases multiple sets. The primary data; structure is a hash table mapping pointers to the AliasSet they are in. The AliasSetTracker class must maintain a list of all of the LLVM ``Value*``\s; that are in each AliasSet. Since the hash table already has entries for each; LLVM ``Value*`` of interest, the AliasesSets thread the linked list through; these hash-table nodes to avoid having to allocate memory unnecessarily, and to; make merging alias sets extremely efficient (the linked list merge is constant; time). You shouldn't need to understand these details if you are just a client of the; AliasSetTracker, but if you look at the code, hopefully this brief description; will help make sense of why things are designed the way they are. Using the ``AliasAnalysis`` interface directly; ----------------------------------------------. If",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:21689,efficient,efficient,21689,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['efficient'],['efficient']
Energy Efficiency,ettyBuiltinDumper.cpp; llvm/tools/llvm-pdbutil/PrettyEnumDumper.cpp; llvm/tools/llvm-pdbutil/PrettyExternalSymbolDumper.cpp; llvm/tools/llvm-pdbutil/PrettyTypeDumper.cpp; llvm/tools/llvm-pdbutil/TypeReferenceTracker.h; llvm/tools/llvm-pdbutil/YAMLOutputStyle.h; llvm/tools/llvm-profgen/CallContext.h; llvm/tools/llvm-profgen/CSPreInliner.cpp; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; l,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337014,reduce,reduce,337014,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"ev( x, {a0[0.1],a1[0.2],a2[-0.3]}))"". Create a RooAddPdf model of a RooGaussian and a RooChebychev (which; are implicitly named model_0 and model_1), its observable x and its; parameters m,a0,a1,a2,Nsig and Nbkg; Note that each object may be created only once (with [] or () brackets) but may be referenced multiple; times in the expression by just giving the name. Here is a much more complicated example:. ""PROD::sig(BMixDecay::sig_t( dt[-20,20], mixState[mixed=1,unmix=-1], tagFlav[B0=1,B0bar=-1],; tau[1.54], dm[0.472], w[0.05], dw[0],; AddModel({GaussModel(dt,biasC[-10,10],sigmaC[0.1,3],dterr[0.01,0.2]),; GaussModel(dt,0,sigmaT[3,10]),; GaussModel(dt,0,20)},{fracC[0,1],fracT[0,1]}),; DoubleSided ),; Gaussian::sig_m( mes[5.20,5.30], mB0[5.20,5.30], sigmB0[0.01,0.05] )"". This create a double-sided Bmixing decay p.d.f. with observables dt,; per-event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:21173,energy,energy,21173,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,['energy'],['energy']
Energy Efficiency,"evelopers even use ``__underscored`` names; in headers to avoid collisions with ""normal"" names that (by; convention) shouldn't even be macros. These conventions are a; barrier to entry for developers coming from non-C languages, are; boilerplate for more experienced developers, and make our headers; far uglier than they should be. * **Tool confusion**: In a C-based language, it is hard to build tools; that work well with software libraries, because the boundaries of; the libraries are not clear. Which headers belong to a particular; library, and in what order should those headers be included to; guarantee that they compile correctly? Are the headers C, C++,; Objective-C++, or one of the variants of these languages? What; declarations in those headers are actually meant to be part of the; API, and what declarations are present only because they had to be; written as part of the header file?. Semantic import; ---------------; Modules improve access to the API of software libraries by replacing the textual preprocessor inclusion model with a more robust, more efficient semantic model. From the user's perspective, the code looks only slightly different, because one uses an ``import`` declaration rather than a ``#include`` preprocessor directive:. .. code-block:: c. import std.io; // pseudo-code; see below for syntax discussion. However, this module import behaves quite differently from the corresponding ``#include <stdio.h>``: when the compiler sees the module import above, it loads a binary representation of the ``std.io`` module and makes its API available to the application directly. Preprocessor definitions that precede the import declaration have no impact on the API provided by ``std.io``, because the module itself was compiled as a separate, standalone module. Additionally, any linker flags required to use the ``std.io`` module will automatically be provided when the module is imported [#]_; This semantic import model addresses many of the problems of the preproce",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:4004,efficient,efficient,4004,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['efficient'],['efficient']
Energy Efficiency,"event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22070,adapt,adaptive,22070,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,['adapt'],['adaptive']
Energy Efficiency,"event weights applied squared. Redesign of RooFit dataset class structure. The original class structure of RooFit featured an abstract dataset; class RooAbsData. Inheriting from that was a single class; RooTreeData, which implemented datasets with a ROOT; TTree-based storage implementation, and inheriting from that; two classes RooDataSet , representing unbinned data, and; RooDataHist, representing binned data. A main problem with; this structure was that the implementation of the storage technology; (TTree) and the data representation (binned vs unbinned) were; intertwined. Starting with version 3.00, the class structure has been; rearranged: Now classes RooDataSet and RooDataHist inherit directly; from class RooAbsData, and class RooAbsData now owns an object that; inherits from RooAbsDataStore that implements the storage of the; data. This new class structure allows multiple data storage implementations to; be applied efficiently to both RooDataSet and RooDataHist; At present a single implementation of RooAbsDataStore exists,; class RooTreeDataStore, that contains the storage implementation; formerly implement in class RooTreeData. Methods in class RooTreeData; that were not specific to the storage technology have been moved to; class RooAbsData. If your user code only uses the classes RooDataSet,RooDataHist and RooAbsData; nothing will change: Existing RooDataSets and RooDataHists; (that inherit from RooTreeData) can be read in without problems in; RooFit 3.00 and will be converted on the fly to the new dataset structure; in memory. User code that explicitly uses RooTreeData pointers should; be changed to RooAbsData pointers. This change should be transparent; for all uses, with the exception of the RooTreeData::tree() method.; Explicit access to tree implementation can still be obtained; through the RooTreeDataStore::tree() method. (A pointer to the datastore; can be obtained through the RooAbsData::store() method.); Note that in future releases it is no longer ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:14312,efficient,efficiently,14312,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,['efficient'],['efficiently']
Energy Efficiency,"evices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Progr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:149664,allocate,allocate,149664,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocate']
Energy Efficiency,"ew TGeo classes support:; - browsing through volumes hierarchy; - changing visibility flags; - drawing of selected volumes; 2. New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames; 3. Significant (factor 4) I/O performance improvement:; - use ArrayBuffer class in HTTP requests instead of String; - use native arrays (like Int32Array) for array data members; - highly optimize streamer infos handling; 4. TH2 drawing optimization:; - if there are too many non-empty bins, combine them together; - when zoom-in, all original bins will be displayed separately; - let draw big TH2 histogram faster than in 1 sec; - optimization can be disabled by providing '&optimize=0' in URL; 5. TF1 drawing optimization:; - function 'compiled' only once; 6. Reorganize scripts structure:; - move all math functions to JSRootMath.js; - TH2, TF1, THStack and TMultiGraph painters moved into JSRootPainter.more.js script; - reduce size of scripts required for default functionality; 7. Update all basic libraries:; - d3.js - v3.5.9,; - jquery.js - v2.1.4,; - jquery-ui.js - v1.11.4,; - three.js - r73; 8. Implement ROOT6-like color palettes:; - all palettes in range 51...112 are implemented; - by default palette 57 is used; - one could change default palette with '&palette=111' in URL; - or palette can be specified in draw option like '&opt=colz,pal77'. ## Changes in 3.9; 1. Support non-equidistant bins for TH1/TH2 objects.; 2. Display entries count from histo.fEntries member, only when not set use computed value; 3. Support italic and bold text when used with MathJax; 4. Improve TF1 drawing - support exp function in TFormula, fix errors with logx scale, enable zoom-in, (re)calculate function points when zooming; 5. Support several columns in TLegend; 6. Introduce context menus for x/y axis, add some items similar to native ROOT menus; 7. Introduce context menu for TPaveStats, let switch single elements in the box; 8. Enable usage o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:60434,reduce,reduce,60434,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['reduce'],['reduce']
Energy Efficiency,"exceptions to be thrown through Clang compiled stack frames (on many; targets, this will enable unwind information for functions that might have; an exception thrown through them). For most targets, this is enabled by; default for C++. .. option:: -ftrapv. Generate code to catch integer overflow errors. Signed integer overflow is; undefined in C. With this flag, extra code is generated to detect this and; abort when it happens. .. option:: -fvisibility. This flag sets the default visibility level. .. option:: -fcommon, -fno-common. This flag specifies that variables without initializers get common linkage.; It can be disabled with :option:`-fno-common`. .. option:: -ftls-model=<model>. Set the default thread-local storage (TLS) model to use for thread-local; variables. Valid values are: ""global-dynamic"", ""local-dynamic"",; ""initial-exec"" and ""local-exec"". The default is ""global-dynamic"". The default; model can be overridden with the tls_model attribute. The compiler will try; to choose a more efficient model if possible. .. option:: -flto, -flto=full, -flto=thin, -emit-llvm. Generate output files in LLVM formats, suitable for link time optimization.; When used with :option:`-S` this generates LLVM intermediate language; assembly files, otherwise this generates LLVM bitcode format object files; (which may be passed to the linker depending on the stage selection options). The default for :option:`-flto` is ""full"", in which the; LLVM bitcode is suitable for monolithic Link Time Optimization (LTO), where; the linker merges all such modules into a single combined module for; optimization. With ""thin"", :doc:`ThinLTO <../ThinLTO>`; compilation is invoked instead. .. note::. On Darwin, when using :option:`-flto` along with :option:`-g` and; compiling and linking in separate steps, you also need to pass; ``-Wl,-object_path_lto,<lto-filename>.o`` at the linking step to instruct the; ld64 linker not to delete the temporary object file generated during Link; Time Optimization (th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:14943,efficient,efficient,14943,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['efficient'],['efficient']
Energy Efficiency,"executed.; * \- : Instruction executed, waiting to be retired. Below is the timeline view for a subset of the dot-product example located in; ``test/tools/llvm-mca/X86/BtVer2/dot-product.s`` and processed by; :program:`llvm-mca` using the following command:. .. code-block:: bash. $ llvm-mca -mtriple=x86_64-unknown-unknown -mcpu=btver2 -iterations=3 -timeline dot-product.s. .. code-block:: none. Timeline view:; 012345; Index 0123456789. [0,0] DeeER. . . vmulps	%xmm0, %xmm1, %xmm2; [0,1] D==eeeER . . vhaddps	%xmm2, %xmm2, %xmm3; [0,2] .D====eeeER . vhaddps	%xmm3, %xmm3, %xmm4; [1,0] .DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [1,1] . D=eeeE---R . vhaddps	%xmm2, %xmm2, %xmm3; [1,2] . D====eeeER . vhaddps	%xmm3, %xmm3, %xmm4; [2,0] . DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [2,1] . D====eeeER . vhaddps	%xmm2, %xmm2, %xmm3; [2,2] . D======eeeER vhaddps	%xmm3, %xmm3, %xmm4. Average Wait times (based on the timeline view):; [0]: Executions; [1]: Average time spent waiting in a scheduler's queue; [2]: Average time spent waiting in a scheduler's queue while ready; [3]: Average time elapsed from WB until retire stage. [0] [1] [2] [3]; 0. 3 1.0 1.0 3.3 vmulps	%xmm0, %xmm1, %xmm2; 1. 3 3.3 0.7 1.0 vhaddps	%xmm2, %xmm2, %xmm3; 2. 3 5.7 0.0 0.0 vhaddps	%xmm3, %xmm3, %xmm4; 3 3.3 0.5 1.4 <total>. The timeline view is interesting because it shows instruction state changes; during execution. It also gives an idea of how the tool processes instructions; executed on the target, and how their timing information might be calculated. The timeline view is structured in two tables. The first table shows; instructions changing state over time (measured in cycles); the second table; (named *Average Wait times*) reports useful timing statistics, which should; help diagnose performance bottlenecks caused by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:22568,schedul,scheduler,22568,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['schedul'],['scheduler']
Energy Efficiency,"exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. All LLVM passes are subclasses of the `Pass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ class, which implement; functionality by overriding virtual methods inherited from ``Pass``. Depending; on how your pass works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""Hello"" pass is; designed to simply print out the name of non-external functions that exist in; the program being compiled. It does not modify the program at all, it just; inspects it. The source code and files for this pass are available in the LLVM; so",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:1278,schedul,schedules,1278,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,2,"['efficient', 'schedul']","['efficient', 'schedules']"
Energy Efficiency,"f failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries exe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:1341,reduce,reduce,1341,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['reduce'],['reduce']
Energy Efficiency,"f no dynamic stack alignment was performed, the stack allocated arguments; are accessed as negative offsets relative to ``DW_AT_frame_base``, and the; local variables and register spill slots are accessed as positive offsets; relative to ``DW_AT_frame_base``. 5. Function argument passing is implemented by copying the input physical; registers to virtual registers on entry. The register allocator can spill if; necessary. These are copied back to physical registers at call sites. The; net effect is that each function call can have these values in entirely; distinct locations. The IPRA can help avoid shuffling argument registers.; 6. Call sites are implemented by setting up the arguments at positive offsets; from SP. Then SP is incremented to account for the known frame size before; the call and decremented after the call. .. note::. The CFI will reflect the changed calculation needed to compute the CFA; from SP. 7. 4 byte spill slots are used in the stack frame. One slot is allocated for an; emergency spill slot. Buffer instructions are used for stack accesses and; not the ``flat_scratch`` instruction. .. TODO::. Explain when the emergency spill slot is used. .. TODO::. Possible broken issues:. - Stack arguments must be aligned to required alignment.; - Stack is aligned to max(16, max formal argument alignment); - Direct argument < 64 bits should check register budget.; - Register budget calculation should respect ``inreg`` for SGPR.; - SGPR overflow is not handled.; - struct with 1 member unpeeling is not checking size of member.; - ``sret`` is after ``this`` pointer.; - Caller is not implementing stack realignment: need an extra pointer.; - Should say AMDGPU passes FP rather than SP.; - Should CFI define CFA as address of locals or arguments. Difference is; apparent when have implemented dynamic alignment.; - If ``SCRATCH`` instruction could allow negative offsets, then can make FP be; highest address of stack frame and use negative offset for locals. Would; allow S",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:399924,allocate,allocated,399924,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"f supported; platforms. Most notably Windows is not supported until at least 6.02.; 6.00/00 supports only. - Linux 32 bit and 64 bit, i32 and x86-64 and x32 (see below).; - OSX 64 bit on x86-64. More platforms are expected to be available later; the lack of support; stems from Cling and Clang/LLVM not being ported to these platforms yet. To aleviate the pain for Windows users who want to try ROOT 6 we provide; a recipe on how to run ROOT 6 in a VM on Windows. Building ROOT also requires a C++11 compatible compiler, so one needs to either have installed gcc >= 4.8 or Clang >= 3.4. On most lecagy platforms these newer compilers are available via a special install.; See the [build prerequisites](https://root.cern/install/dependencies/) page. Despite that, an additional platform as been added: the [x32; psAPI](https://sites.google.com/site/x32abi/), called linuxx32gcc. It is; a regular x86-64 ABI but with shorter pointers (4 bytes instead of 8).; This reduces the addressable memory per process to 4GB - but that is; usally sufficient. The advantages are reduced memory consumption (due to; the smaller pointers) and increased performance compared to 32 bit; applications due to the availability of the 64 bit instructions. The; Clang developers mailing list archive [contains a good; comparison](http://clang-developers.42468.n3.nabble.com/Re-PATCH-add-x32-psABI-support-td4024297.html). To build and run binaries compiled in x32, toolchain support is needed.; That is available in the in binutils (2.22), GCC (4.8), glibc (2.16),; Linux kernel (3.4) and even GDB (7.5). These versions are not available; in regular distributions yet (except for [this beta Gentoo; distro](http://dev.gentoo.org/~vapier/x32/stage3-amd64-x32-20120605.tar.xz); built in x32); once they are, building and running x86-64 and x32; side-by-side will be possible. ## Build System; ROOT 6.00/00 can be built either using the classic ""./configure;make"" method or using CMake.; The CMake system has been completed fo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md:1042,reduce,reduces,1042,core/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md,1,['reduce'],['reduces']
Energy Efficiency,"f the TStreamerInfo::ReadBuffer switch statement is replaced by 4 new action functions,; one for the object wise reading, one for the member wise reading for TClonesArray and vector of pointers,; one for the member wise reading for a vector of object and one for all other collections. Each collection (proxy) needs to provide 5 new free standing functions:. // Set of functions to iterate easily throught the collection; static const Int_t fgIteratorArenaSize = 16; // greater than sizeof(void*) + sizeof(UInt_t). typedef void (*CreateIterators_t)(void *collection, void **begin_arena, void **end_arena);; virtual CreateIterators_t GetFunctionCreateIterators(Bool_t read = kTRUE) = 0;; // begin_arena and end_arena should contain the location of a memory arena of size fgIteratorSize.; // If the collection iterator are of that size or less, the iterators will be constructed in place in those location; // (new with placement.) Otherwise the iterators will be allocated via a regular new and their address returned by; // modifying the value of begin_arena and end_arena. typedef void* (*CopyIterator_t)(void *dest, const void *source);; virtual CopyIterator_t GetFunctionCopyIterator(Bool_t read = kTRUE) = 0;; // Copy the iterator source, into dest. dest should contain the location of a memory arena of size fgIteratorSize.; // If the collection iterator is of that size or less, the iterator will be constructed in place in this location; // (new with placement.) Otherwise the iterator will be allocated via a regular new and its address returned by; // modifying the value of dest. typedef void* (*Next_t)(void *iter, const void *end);; virtual Next_t GetFunctionNext(Bool_t read = kTRUE) = 0;; // iter and end should be pointers to respectively an iterator to be incremented and the result of collection.end(); // If the iterator has not reached the end of the collection, 'Next' increment the iterator 'iter' and return 0 if; // the iterator reached the end.; // If the end was not reached, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:6306,allocate,allocated,6306,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,2,['allocate'],['allocated']
Energy Efficiency,"f the build process; because they are code generators for parts of the infrastructure. ``codegen-diff``. ``codegen-diff`` finds differences between code that LLC; generates and code that LLI generates. This is useful if you are; debugging one of them, assuming that the other generates correct output. For; the full user manual, run ```perldoc codegen-diff'``. ``emacs/``. Emacs and XEmacs syntax highlighting for LLVM assembly files and TableGen; description files. See the ``README`` for information on using them. ``getsrcs.sh``. Finds and outputs all non-generated source files,; useful if one wishes to do a lot of development across directories; and does not want to find each file. One way to use it is to run,; for example: ``xemacs `utils/getsources.sh``` from the top of the LLVM source; tree. ``llvmgrep``. Performs an ``egrep -H -n`` on each source file in LLVM and; passes to it a regular expression provided on ``llvmgrep``'s command; line. This is an efficient way of searching the source base for a; particular regular expression. ``TableGen/``. Contains the tool used to generate register; descriptions, instruction set descriptions, and even assemblers from common; TableGen description files. ``vim/``. vim syntax-highlighting for LLVM assembly files; and TableGen description files. See the ``README`` for how to use them. .. _simple example:. An Example Using the LLVM Tool Chain; ====================================. This section gives an example of using LLVM with the Clang front end. Example with clang; ------------------. #. First, create a simple C file, name it 'hello.c':. .. code-block:: c. #include <stdio.h>. int main() {; printf(""hello world\n"");; return 0;; }. #. Next, compile the C file into a native executable:. .. code-block:: console. % clang hello.c -o hello. .. note::. Clang works just like GCC by default. The standard -S and -c arguments; work as usual (producing a native .s or .o file, respectively). #. Next, compile the C file into an LLVM bitcode f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:41570,efficient,efficient,41570,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['efficient'],['efficient']
Energy Efficiency,"f the enclosing module. .. parsed-literal::. *config-macros-declaration*:; ``config_macros`` *attributes*:sub:`opt` *config-macro-list*:sub:`opt`. *config-macro-list*:; *identifier* (',' *identifier*)*. Each *identifier* in the *config-macro-list* specifies the name of a macro. The compiler is required to maintain different variants of the given module for differing definitions of any of the named macros. A *config-macros-declaration* shall only be present on a top-level module, i.e., a module that is not nested within an enclosing module. The ``exhaustive`` attribute specifies that the list of macros in the *config-macros-declaration* is exhaustive, meaning that no other macro definition is intended to have an effect on the API of that module. .. note::. The ``exhaustive`` attribute implies that any macro definitions; for macros not listed as configuration macros should be ignored; completely when building the module. As an optimization, the; compiler could reduce the number of unique module variants by not; considering these non-configuration macros. This optimization is not; yet implemented in Clang. A translation unit shall not import the same module under different definitions of the configuration macros. .. note::. Clang implements a weak form of this requirement: the definitions; used for configuration macros are fixed based on the definitions; provided by the command line. If an import occurs and the definition; of any configuration macro has changed, the compiler will produce a; warning (under the control of ``-Wconfig-macros``). **Example:** A logging library might provide different API (e.g., in the form of different definitions for a logging macro) based on the ``NDEBUG`` macro setting:. .. parsed-literal::. module MyLogger {; umbrella header ""MyLogger.h""; config_macros [exhaustive] NDEBUG; }. Conflict declarations; ~~~~~~~~~~~~~~~~~~~~~; A *conflict-declaration* describes a case where the presence of two different modules in the same translation unit is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:47338,reduce,reduce,47338,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['reduce'],['reduce']
Energy Efficiency,"f the program that as they are excluded from the testcase.; These options allow you to choose the; static native code compiler, or a custom command, (see **--exec-command**); respectively. The interpreter and the JIT backends cannot currently; be used as the ""safe"" backends. **--exec-command** *command*. This option defines the command to use with the **--run-custom** and; **--safe-custom** options to execute the bitcode testcase. This can; be useful for cross-compilation. **--compile-command** *command*. This option defines the command to use with the **--compile-custom**; option to compile the bitcode testcase. The command should exit with a; failure exit code if the file is ""interesting"" and should exit with a; success exit code (i.e. 0) otherwise (this is the same as if it crashed on; ""interesting"" inputs). This can be useful for; testing compiler output without running any link or execute stages. To; generate a reduced unit test, you may add CHECK directives to the; testcase and pass the name of an executable compile-command script in this form:. .. code-block:: sh. #!/bin/sh; llc ""$@""; not FileCheck [bugpoint input file].ll < bugpoint-test-program.s. This script will ""fail"" as long as FileCheck passes. So the result; will be the minimum bitcode that passes FileCheck. **--safe-path** *path*. This option defines the path to the command to execute with the; **--safe-{int,jit,llc,custom}**; option. **--verbose-errors**\ =\ *{true,false}*. The default behavior of bugpoint is to print ""<crash>"" when it finds a reduced; test that crashes compilation. This flag prints the output of the crashing; program to stderr. This is useful to make sure it is the same error being; tracked down and not a different error that happens to crash the compiler as; well. Defaults to false. EXIT STATUS; -----------. If **bugpoint** succeeds in finding a problem, it will exit with 0. Otherwise,; if an error occurs, it will exit with a non-zero value. SEE ALSO; --------. :manpage:`opt(1)`; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:6269,reduce,reduced,6269,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,1,['reduce'],['reduced']
Energy Efficiency,"f this data source.; - Add the `ROOT::Experimental::TAdoptAllocator<T>`, an allocator which allows to adopt existing memory. If memory is adopted, upon allocation a copy is performed in the new, potentially more extended, memory region.; - Add `ROOT::Experimental::VecOps::TVec<T>` a class which represents a contiguous array, inspired by Numpy arrays. `TVec` offer a convenient interface, almost identical to the one of `std::vector`. It can own or adopt its memory. As well as a set of tools which make analysis of collections easier, avoiding to loop over the individual elements of the collections. Basic arithmetic operations such as +,-,*,/,% between TVecs and scalars and TVecs are supported. Most popular math functions which act on TVecs are provided. Helpers to calculate basic quantities such as sum, mean, variance or standard deviation of TVecs are provided.; A powerful and concise syntax for expressing cuts is available:; ```; // mu_pts_tvec and mu_etas_tvec are two equally sized TVecs holding kinematic properties of muons; // a filter on muons pseudorapidities is applied considering a range in pseudo rapidity.; filtered_mu_pts_tvec = mu_pts_tvec[abs(mu_etas_tvec) < 2)];; ```; - The `TArrayBranch` class has been removed and replaced by the more powerful `TVec`.; - Columns on disk stored as C arrays should be read as `TVec`s, `std::vector` columns can be read as `TVec`s if requested. Jitted transformations and actions consider `std::vector` columns as well as C array columns `TVec`s.; - In jitted transformations and actions, `std::vector` and C array columns are read as `TVec`s.; - When snapshotting, columns read from trees which are of type `std::vector` or C array and read as TVecs are persistified on disk as a `std::vector` or C arrays respectively - no transformation happens. `TVec` columns, for example coming from `Define`s, are written as `std::vector<T, TAdoptAllocator<T>>`. #### Fixes; - Do not alphabetically order columns before snapshotting to avoid issues",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:9057,power,powerful,9057,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['power'],['powerful']
Energy Efficiency,"f:`SmallPtrSet <dss_smallptrset>`. The magic of this class is that it handles small sets extremely efficiently, but; gracefully handles extremely large sets without loss of efficiency. .. _dss_smallptrset:. llvm/ADT/SmallPtrSet.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallPtrSet`` has all the advantages of ``SmallSet`` (and a ``SmallSet`` of; pointers is transparently implemented with a ``SmallPtrSet``). If more than N; insertions are performed, a single quadratically probed hash table is allocated; and grows as needed, providing extremely efficient access (constant time; insertion/deleting/queries with low constant factors) and is very stingy with; malloc traffic. Note that, unlike :ref:`std::set <dss_set>`, the iterators of ``SmallPtrSet``; are invalidated whenever an insertion occurs. Also, the values visited by the; iterators are not visited in sorted order. .. _dss_stringset:. llvm/ADT/StringSet.h; ^^^^^^^^^^^^^^^^^^^^. ``StringSet`` is a thin wrapper around :ref:`StringMap\<char\> <dss_stringmap>`,; and it allows efficient storage and retrieval of unique strings. Functionally analogous to ``SmallSet<StringRef>``, ``StringSet`` also supports; iteration. (The iterator dereferences to a ``StringMapEntry<char>``, so you; need to call ``i->getKey()`` to access the item of the StringSet.) On the; other hand, ``StringSet`` doesn't support range-insertion and; copy-construction, which :ref:`SmallSet <dss_smallset>` and :ref:`SmallPtrSet; <dss_smallptrset>` do support. .. _dss_denseset:. llvm/ADT/DenseSet.h; ^^^^^^^^^^^^^^^^^^^. DenseSet is a simple quadratically probed hash table. It excels at supporting; small values: it uses a single allocation to hold all of the pairs that are; currently inserted in the set. DenseSet is a great way to unique small values; that are not simple pointers (use :ref:`SmallPtrSet <dss_smallptrset>` for; pointers). Note that DenseSet has the same requirements for the value type that; :ref:`DenseMap <dss_densemap>` has. .. _dss_sparseset:. llvm/ADT/Spa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:79507,efficient,efficient,79507,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"fetime.start``' call marks the object as alive, but it; does not change the address of the object. If ``ptr`` is a non-stack-allocated object, it does not point to the first; byte of the object or it is a stack object that is already alive, it simply; fills all bytes of the object with ``poison``. .. _int_lifeend:. '``llvm.lifetime.end``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.lifetime.end(i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.lifetime.end``' intrinsic specifies the end of a memory object's; lifetime. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is variable sized. The second argument is a pointer; to the object. Semantics:; """""""""""""""""""". If ``ptr`` is a stack-allocated object and it points to the first byte of the; object, the object is dead.; ``ptr`` is conservatively considered as a non-stack-allocated object if; the stack coloring algorithm that is used in the optimization pipeline cannot; conclude that ``ptr`` is a stack-allocated object. Calling ``llvm.lifetime.end`` on an already dead alloca is no-op. If ``ptr`` is a non-stack-allocated object or it does not point to the first; byte of the object, it is equivalent to simply filling all bytes of the object; with ``poison``. '``llvm.invariant.start``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The memory object can belong to any address space. ::. declare ptr @llvm.invariant.start.p0(i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.invariant.start``' intrinsic specifies that the contents of; a memory object will not change. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is variable sized. The second argument is a pointer; to the object. Semantics:; """""""""""""""""""". This intrinsic indicates that until an ``llvm.invariant.end`` that u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:863203,allocate,allocated,863203,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['allocate'],['allocated']
Energy Efficiency,"ficantly reduce linking time for LLVM; executables on ELF-based platforms, such as Linux. If you are building LLVM; for the first time and lld is not available to you as a binary package, then; you may want to use the gold linker as a faster alternative to GNU ld. * -DCMAKE_BUILD_TYPE; Controls optimization level and debug information of the build. This setting; can affect RAM and disk usage, see :ref:`CMAKE_BUILD_TYPE <cmake_build_type>`; for more information. * -DLLVM_ENABLE_ASSERTIONS; This option defaults to ON for Debug builds and defaults to OFF for Release; builds. As mentioned in the previous option, using the Release build type and; enabling assertions may be a good alternative to using the Debug build type. * -DLLVM_PARALLEL_LINK_JOBS; Set this equal to number of jobs you wish to run simultaneously. This is; similar to the -j option used with make, but only for link jobs. This option; can only be used with ninja. You may wish to use a very low number of jobs,; as this will greatly reduce the amount of memory used during the build; process. If you have limited memory, you may wish to set this to 1. * -DLLVM_TARGETS_TO_BUILD; Set this equal to the target you wish to build. You may wish to set this to; X86; however, you will find a full list of targets within the; llvm-project/llvm/lib/Target directory. * -DLLVM_OPTIMIZED_TABLEGEN; Set this to ON to generate a fully optimized tablegen during your build. This; will significantly improve your build time. This is only useful if you are; using the Debug build type. * -DLLVM_ENABLE_PROJECTS; Set this equal to the projects you wish to compile (e.g. clang, lld, etc.) If; compiling more than one project, separate the items with a semicolon. Should; you run into issues with the semicolon, try surrounding it with single quotes. * -DLLVM_ENABLE_RUNTIMES; Set this equal to the runtimes you wish to compile (e.g. libcxx, libcxxabi, etc.); If compiling more than one runtime, separate the items with a semicolon. Should; you r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:45474,reduce,reduce,45474,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['reduce'],['reduce']
Energy Efficiency,"ficient instead; of complicating the API. Right now I have no preference or objections between the alternatives but there; are some random thoughts:. * Maybe it would be great to have a guideline how to evolve the analyzer and; follow it, so it can help us to decide in similar situations. * I do care about performance in this case. The reason is that we have a; limited performance budget. And I think we should not expect most of the checker; writers to add modeling of language constructs. So, in my opinion, it is ok to; have less nice/more verbose API for language modeling if we can have better; performance this way, since it only needs to be done once, and is done by the; framework developers. **Artem:** These are some great questions, i guess it'd be better to discuss; them more openly. As a quick dump of my current mood:. * To me it seems obvious that we need to aim for a checker API that is both; simple and powerful. This can probably by keeping the API as powerful as; necessary while providing a layer of simple ready-made solutions on top of it.; Probably a few reusable components for assembling checkers. And this layer; should ideally be pleasant enough to work with, so that people would prefer to; extend it when something is lacking, instead of falling back to the complex; omnipotent API. I'm thinking of AST matchers vs. AST visitors as a roughly; similar situation: matchers are not omnipotent, but they're so nice. * Separation between core and checkers is usually quite strange. Once we have; shared state traits, i generally wouldn't mind having region store or range; constraint manager as checkers (though it's probably not worth it to transform; them - just a mood). The main thing to avoid here would be the situation when; the checker overwrites stuff written by the core because it thinks it has a; better idea what's going on, so the core should provide a good default behavior. * Yeah, i totally care about performance as well, and if i try to implement; appr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst:6288,power,powerful,6288,interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/InitializerLists.rst,1,['power'],['powerful']
Energy Efficiency,"fied clearly using at least one of two; mechanisms:; 1) It will be in a separate directory tree with its own `LICENSE.txt` or; `LICENSE` file at the top containing the specific license and restrictions; which apply to that software, or; 2) It will contain specific license and restriction terms at the top of every; file. ==============================================================================; Legacy LLVM License (https://llvm.org/docs/DeveloperPolicy.html#legacy):; ==============================================================================; University of Illinois/NCSA; Open Source License. Copyright (c) 2007-2018 University of Illinois at Urbana-Champaign.; All rights reserved. Developed by:. LLVM Team. University of Illinois at Urbana-Champaign. http://llvm.org. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:. * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution. * Neither the names of the LLVM Team, University of Illinois at Urbana-Champaign, nor the names of its contributors may be used to endorse or promote products derived from this Software without specific prior written permission. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHAL",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-format-vs/ClangFormat/license.txt:12650,charge,charge,12650,interpreter/llvm-project/clang/tools/clang-format-vs/ClangFormat/license.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-format-vs/ClangFormat/license.txt,1,['charge'],['charge']
Energy Efficiency,"fiers), this is lowered; into v_dot8c_i32_i4 for targets which support it.; RDNA3 does not offer v_dot8_i32_i4, and rather offers; v_dot4_i32_iu4 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrie",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42359,schedul,scheduling,42359,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduling']
Energy Efficiency,"files can have inaccuracies or missing block/; edge counters. The profile inference algorithm (profi) can be used to infer; missing blocks and edge counts, and improve the quality of profile data.; Enable it with ``-fsample-profile-use-profi``. .. code-block:: console. $ clang++ -O2 -gline-tables-only -fprofile-sample-use=code.prof \; -fsample-profile-use-profi code.cc -o code. Sample Profile Formats; """""""""""""""""""""""""""""""""""""""""""". Since external profilers generate profile data in a variety of custom formats,; the data generated by the profiler must be converted into a format that can be; read by the backend. LLVM supports three different sample profile formats:. 1. ASCII text. This is the easiest one to generate. The file is divided into; sections, which correspond to each of the functions with profile; information. The format is described below. It can also be generated from; the binary or gcov formats using the ``llvm-profdata`` tool. 2. Binary encoding. This uses a more efficient encoding that yields smaller; profile files. This is the format generated by the ``create_llvm_prof`` tool; in https://github.com/google/autofdo. 3. GCC encoding. This is based on the gcov format, which is accepted by GCC. It; is only interesting in environments where GCC and Clang co-exist. This; encoding is only generated by the ``create_gcov`` tool in; https://github.com/google/autofdo. It can be read by LLVM and; ``llvm-profdata``, but it cannot be generated by either. If you are using Linux Perf to generate sampling profiles, you can use the; conversion tool ``create_llvm_prof`` described in the previous section.; Otherwise, you will need to write a conversion tool that converts your; profiler's native format into one of these three. Sample Profile Text Format; """""""""""""""""""""""""""""""""""""""""""""""""""". This section describes the ASCII text format for sampling profiles. It is,; arguably, the easiest one to generate. If you are interested in generating any; of the other two, consult the ``ProfileData`` l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:96086,efficient,efficient,96086,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"filing tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_B",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:10069,reduce,reduce,10069,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['reduce'],['reduce']
Energy Efficiency,"finition and intrinsics support for new instructions that were; introduced in LoongArch Reference Manual V1.10.; * Emitted adjacent ``pcaddu18i+jirl`` instrunction sequence with one relocation; ``R_LARCH_CALL36`` instead of ``pcalau12i+jirl`` with two relocations; ``R_LARCH_PCALA_{HI20,LO12}`` for function call in medium code model.; * The code model of global variables can now be overridden by means of the newly; added LLVM IR attribute, ``code_model``.; * Added support for the ``llvm.is.fpclass`` intrinsic.; * ``mulodi4`` and ``muloti4`` libcalls were disabled due to absence in libgcc.; * Added initial support for auto vectorization.; * Added initial support for linker relaxation.; * Assorted codegen improvements. Changes to the MIPS Backend; ---------------------------. Changes to the PowerPC Backend; ------------------------------. * LLJIT's JIT linker now defaults to JITLink on 64-bit ELFv2 targets.; * Initial-exec TLS model is supported on AIX.; * Implemented new resource based scheduling model of POWER7 and POWER8.; * ``frexp`` libcall now references correct symbol name for ``fp128``.; * Optimized materialization of 64-bit immediates, code generation of; ``vec_promote`` and atomics.; * Global constant strings are pooled in the TOC under one entry to reduce the; number of entries in the TOC.; * Added a number of missing Power10 extended mnemonics.; * Added the SCV instruction.; * Fixed register class for the paddi instruction.; * Optimize VPERM and fix code order for swapping vector operands on LE.; * Added various bug fixes and code gen improvements. AIX Support/improvements:. * Support for a non-TOC-based access sequence for the local-exec TLS model (called small local-exec).; * XCOFF toc-data peephole optimization and bug fixes.; * Move less often used __ehinfo TOC entries to the end of the TOC section.; * Fixed problems when the AIX libunwind unwinds starting from a signal handler; and the function that raised the signal happens to be a leaf function that; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:5648,schedul,scheduling,5648,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['schedul'],['scheduling']
Energy Efficiency,"floating-point operation must treat any input denormal value as; zero. In some situations, if an instruction does not respect this; mode, the input may need to be converted to 0 as if by; ``@llvm.canonicalize`` during lowering for correctness. ``""denormal-fp-math-f32""``; Same as ``""denormal-fp-math""``, but only controls the behavior of; the 32-bit float type (or vectors of 32-bit floats). If both are; are present, this overrides ``""denormal-fp-math""``. Not all targets; support separately setting the denormal mode per type, and no; attempt is made to diagnose unsupported uses. Currently this; attribute is respected by the AMDGPU and NVPTX backends. ``""thunk""``; This attribute indicates that the function will delegate to some other; function with a tail call. The prototype of a thunk should not be used for; optimization purposes. The caller is expected to cast the thunk prototype to; match the thunk target prototype. ``""tls-load-hoist""``; This attribute indicates that the function will try to reduce redundant; tls address calculation by hoisting tls variable. ``uwtable[(sync|async)]``; This attribute indicates that the ABI being targeted requires that; an unwind table entry be produced for this function even if we can; show that no exceptions passes by it. This is normally the case for; the ELF x86-64 abi, but it can be disabled for some compilation; units. The optional parameter describes what kind of unwind tables; to generate: ``sync`` for normal unwind tables, ``async`` for asynchronous; (instruction precise) unwind tables. Without the parameter, the attribute; ``uwtable`` is equivalent to ``uwtable(async)``.; ``nocf_check``; This attribute indicates that no control-flow check will be performed on; the attributed entity. It disables -fcf-protection=<> for a specific; entity to fine grain the HW control flow protection mechanism. The flag; is target independent and currently appertains to a function or function; pointer.; ``shadowcallstack``; This attribute indicate",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:108549,reduce,reduce,108549,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"fmin.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmin.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with minimum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmaximum:. '``llvm.vector.reduce.fmaximum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmaximum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmaximum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmaximum.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maximum.*``'; intrinsic. That is, this intrinsic propagates NaNs and +0.0 is considered; greater than -0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fminimum:. '``llvm.vector.reduce.fminimum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fminimum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fminimum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:660727,reduce,reduce,660727,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"fo Debug, Verbose, Info VerboseLevel (Debug/Verbose/Info). Configuration options for the PDF class :. Configuration options reference for class: PDF. Option Array Default value Predefined values Description. NSmooth No 0 âˆ’ Number of smoothing iterations for the input histograms. MinNSmooth No -1 âˆ’ Min number of smoothing iterations, for bins with most data. MaxNSmooth No -1 âˆ’ Max number of smoothing iterations, for bins with least data. NAvEvtPerBin No 50 âˆ’ Average number of events per PDF bin. Nbins No 0 âˆ’ Defined number of bins for the histogram from which the PDF is created. CheckHist No False âˆ’ Whether or not to check the source histogram of the PDF. PDFInterpol No Spline2 Spline0, Spline1, Spline2, Spline3, Spline5, KDE Interpolation method for reference histograms (e.g. Spline2 or KDE). KDEtype No Gauss Gauss KDE kernel type (1=Gauss). KDEiter No Nonadaptive Nonadaptive, Adaptive Number of iterations (1=non-adaptive, 2=adaptive). KDEFineFactor No 1 âˆ’ Fine tuning factor for Adaptive KDE: Factor to multyply the width of the kernel. KDEborder No None None, Renorm, Mirror Border effects treatment (1=no treatment , 2=kernel renormalization, 3=sample mirroring). Configuration options for Factory running :. Configuration options reference for class: Factory. Option Array Default value Predefined values Description. V No False âˆ’ Verbose flag. Color No True âˆ’ Flag for coloured screen output (default: True, if in batch mode: False). Transformations No âˆ’ List of transformations to test; formatting example: Transformations=I;D;P;U;G,D, for identity, decorrelation, PCA, Uniform and Gaussianisation followed by decorrelation transformations. Silent No False âˆ’ Batch mode: boolean silent flag inhibiting any output from TMVA after the creation of the factory class object (default: False). DrawProgressBar No True âˆ’ Draw progress bar to display training, testing and evaluation schedule (default: True). AnalysisType No Auto Classification, Regression, Multiclass, Auto Set the anal",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:34367,Adapt,Adaptive,34367,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['Adapt'],['Adaptive']
Energy Efficiency,"following; intrinsics. Each one takes a vector operand as an input and applies its; respective operation across all elements of the vector, returning a single; scalar result of the same element type. .. _int_vector_reduce_add:. '``llvm.vector.reduce.add.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.add.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.add.*``' intrinsics do an integer ``ADD``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fadd:. '``llvm.vector.reduce.fadd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fadd.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fadd.*``' intrinsics do a floating-point; ``ADD`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fadd operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fadd(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:651154,reduce,reduce,651154,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"footprint. If weight errors are not needed, RooDataHist now allocates only 40% of the memory that the old implementation used. #### Fix bin volume correction logic in `RooDataHist::sum()`. The public member function `RooDataHist::sum()` has three overloads.; Two of these overloads accept a `sumSet` parameter to not sum over all variables.; These two overloads previously behaved inconsistently when the `correctForBinSize` or `inverseBinCor` flags were set.; If you use the `RooDataHist::sum()` function in you own classes, please check that it can still be used with its new logic.; The new and corrected bin correction behaviour is:. - `correctForBinSize`: multiply counts in each bin by the bin volume corresponding to the variables in `sumSet`; - `inverseBinCor`: divide counts in each bin by the bin volume corresponding to the variables *not* in `sumSet`. ### New fully parametrised Crystal Ball shape class. So far, the Crystal Ball distribution has been represented in RooFit only by the `RooCBShape` class, which has a Gaussian core and a single power-law tail on one side.; This release introduces [`RooCrystalBall`](https://root.cern/doc/v624/classRooCrystalBall.html), which implements some common generalizations of the Crystal Ball shape:. - symmetric or asymmetric power-law tails on both sides; - different width parameters for the left and right sides of the Gaussian core. The new `RooCrystalBall` class can substitute the `RooDSCBShape` and `RooSDSCBShape`, which were passed around in the community. ## 2D Graphics Libraries. - Add the method `AddPoint`to `TGraph(x,y)` and `TGraph2D(x,y,z)`, equivalent to `SetPoint(g->GetN(),x,y)`and `SetPoint(g->GetN(),x,y,z)`; - Option `E0` draws error bars and markers are drawn for bins with 0 contents. Now, combined; with options E1 and E2, it avoids error bars clipping. ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### Multithreaded support for FastCGI. Now when THttpServer creates",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:24140,power,power-law,24140,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['power'],['power-law']
Energy Efficiency,"for debugging; or program visualization purposes. Transform passes can use (or invalidate); the analysis passes. Transform passes all mutate the program in some way.; Utility passes provides some utility but don't otherwise fit categorization.; For example passes to extract functions to bitcode or write a module to bitcode; are neither analysis nor transform passes. The table of contents above; provides a quick summary of each pass and links to the more complete pass; description later in the document. Analysis Passes; ===============. This section describes the LLVM Analysis Passes. ``aa-eval``: Exhaustive Alias Analysis Precision Evaluator; ----------------------------------------------------------. This is a simple N^2 alias analysis accuracy evaluator. Basically, for each; function in the program, it simply queries to see how the alias analysis; implementation answers alias queries between each pair of pointers in the; function. This is inspired and adapted from code by: Naveen Neelakantam, Francesco; Spadini, and Wojciech Stryjewski. ``basic-aa``: Basic Alias Analysis (stateless AA impl); ------------------------------------------------------. A basic alias analysis pass that implements identities (two different globals; cannot alias, etc), but does no stateful analysis. ``basiccg``: Basic CallGraph Construction; -----------------------------------------. Yet to be written. .. _passes-da:. ``da``: Dependence Analysis; ---------------------------. Dependence analysis framework, which is used to detect dependences in memory; accesses. ``domfrontier``: Dominance Frontier Construction; ------------------------------------------------. This pass is a simple dominator construction algorithm for finding forward; dominator frontiers. ``domtree``: Dominator Tree Construction; ----------------------------------------. This pass is a simple dominator construction algorithm for finding forward; dominators. ``dot-callgraph``: Print Call Graph to ""dot"" file; ----------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:1510,adapt,adapted,1510,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['adapt'],['adapted']
Energy Efficiency,"for the current point.; Therefore, the first step is to convert the global current point and; direction in the local reference frame of the current volume and to; compute the distance to exit its shape from inside. The returned value; is again compared to the maximum allowed step (the proposed one) and in; case the distance is safe no other action is performed and the proposed; step is approved. In case the boundary is closer, the computed distance; is taken as maximum allowed step. For optimization purposed, for; particles starting very close to the current volume boundary (less than; 0.01 microns) and exiting the algorithm stops here. After computing the distance to exit the current node, the distance to; the daughter of the current volume which is crossed next is computed by; **`TGeoManager`**`::FindNextDaughterBoundary().` This computes the; distance to all daughter candidates that can be possibly crossed by; using volume voxelization. The algorithm is efficient in average only in; case the number of daughters is greater than 4. For fewer nodes, a; simple loop is performed and the minimum distance (from a point outside; each shape) is taken and compared to the maximum allowed step. The step; value is again updated if `step<stepmax` . A special case is when the current node is declared as possibly; overlapping with something else. If this is the case, the distance is; computed for all possibly overlapping candidates, taking into account; the overlapping priorities (see also: "" Overlapping volumes ""). The global matrix describing the next crossed physical node is; systematically computed in case the value of the proposed step is; negative. In this case, one can subsequently call; `TGeoManager::ComputeNormalFast()` to get the normal vector to the; crossed surface, after propagating the current point with the; `TGeoManager::GetStep()` value. This propagation can be done like:. ``` {.cpp}; Double_t *current_point = gGeoManager->GetCurrentPoint();; Double_t *current_di",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:163419,efficient,efficient,163419,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['efficient'],['efficient']
Energy Efficiency,"four operands of the `X86 addressing mode`_, which are; currently matched with custom C++ code). In addition, we'll extend fragments; so that a fragment can match multiple different patterns. * We don't automatically infer flags like ``isStore``/``isLoad`` yet. * We don't automatically generate the set of supported registers and operations; for the `Legalizer`_ yet. * We don't have a way of tying in custom legalized nodes yet. Despite these limitations, the instruction selector generator is still quite; useful for most of the binary and logical operations in typical instruction; sets. If you run into any problems or can't figure out how to do something,; please let Chris know!. .. _Scheduling and Formation:; .. _SelectionDAG Scheduling and Formation:. SelectionDAG Scheduling and Formation Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The scheduling phase takes the DAG of target instructions from the selection; phase and assigns an order. The scheduler can pick an order depending on; various constraints of the machines (i.e. order for minimal register pressure or; try to cover instruction latencies). Once an order is established, the DAG is; converted to a list of :raw-html:`<tt>` `MachineInstr`_\s :raw-html:`</tt>` and; the SelectionDAG is destroyed. Note that this phase is logically separate from the instruction selection phase,; but is tied to it closely in the code because it operates on SelectionDAGs. Future directions for the SelectionDAG; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Optional function-at-a-time selection. #. Auto-generate entire selector from ``.td`` file. .. _SSA-based Machine Code Optimizations:. SSA-based Machine Code Optimizations; ------------------------------------. To Be Written. Live Intervals; --------------. Live Intervals are the ranges (intervals) where a variable is *live*. They are; used by some `register allocator`_ passes to determine if two or more virtual; registers which require the same physical register are live at the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:53661,schedul,scheduler,53661,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['schedul'],['scheduler']
Energy Efficiency,"freelist; which can help mitigate some use-after-free situations. This feature is fairly; costly in terms of performance and memory footprint, is mostly controlled by; runtime options and is disabled by default. Allocations Header; ------------------; Every chunk of heap memory returned to an application by the allocator will be; preceded by a header. This has two purposes:. - being to store various information about the chunk, that can be leveraged to; ensure consistency of the heap operations;. - being able to detect potential corruption. For this purpose, the header is; checksummed and corruption of the header will be detected when said header is; accessed (note that if the corrupted header is not accessed, the corruption; will remain undetected). The following information is stored in the header:. - the class ID for that chunk, which identifies the region where the chunk; resides for Primary backed allocations, or 0 for Secondary backed allocations;. - the state of the chunk (available, allocated or quarantined);. - the allocation type (malloc, new, new[] or memalign), to detect potential; mismatches in the allocation APIs used;. - the size (Primary) or unused bytes amount (Secondary) for that chunk, which is; necessary for reallocation or sized-deallocation operations;. - the offset of the chunk, which is the distance in bytes from the beginning of; the returned chunk to the beginning of the backend allocation (the ""block"");. - the 16-bit checksum;. This header fits within 8 bytes on all platforms supported, and contributes to a; small overhead for each allocation. The checksum is computed using a CRC32 (made faster with hardware support); of the global secret, the chunk pointer itself, and the 8 bytes of header with; the checksum field zeroed out. It is not intended to be cryptographically; strong. The header is atomically loaded and stored to prevent races. This is important; as two consecutive chunks could belong to different threads. We work on local; copies",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:3276,allocate,allocated,3276,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['allocate'],['allocated']
Energy Efficiency,"function -> module; MPM.addPass(createModuleToFunctionPassAdaptor(createFunctionToLoopPassAdaptor(LoopFooPass())));; // function -> module; MPM.addPass(createModuleToFunctionPassAdaptor(FunctionFooPass()));. // loop -> function -> cgscc -> module; MPM.addPass(createModuleToPostOrderCGSCCPassAdaptor(createCGSCCToFunctionPassAdaptor(createFunctionToLoopPassAdaptor(LoopFooPass()))));; // function -> cgscc -> module; MPM.addPass(createModuleToPostOrderCGSCCPassAdaptor(createCGSCCToFunctionPassAdaptor(FunctionFooPass())));. A pass manager of a specific IR unit is also a pass of that kind. For; example, a ``FunctionPassManager`` is a function pass, meaning it can be; added to a ``ModulePassManager``:. .. code-block:: c++. ModulePassManager MPM;. FunctionPassManager FPM;; // InstSimplifyPass is a function pass; FPM.addPass(InstSimplifyPass());. MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));. Generally you want to group CGSCC/function/loop passes together in a pass; manager, as opposed to adding adaptors for each pass to the containing upper; level pass manager. For example,. .. code-block:: c++. ModulePassManager MPM;; MPM.addPass(createModuleToFunctionPassAdaptor(FunctionPass1()));; MPM.addPass(createModuleToFunctionPassAdaptor(FunctionPass2()));; MPM.run();. will run ``FunctionPass1`` on each function in a module, then run; ``FunctionPass2`` on each function in the module. In contrast,. .. code-block:: c++. ModulePassManager MPM;. FunctionPassManager FPM;; FPM.addPass(FunctionPass1());; FPM.addPass(FunctionPass2());. MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));. will run ``FunctionPass1`` and ``FunctionPass2`` on the first function in a; module, then run both passes on the second function in the module, and so on.; This is better for cache locality around LLVM data structures. This similarly; applies for the other IR types, and in some cases can even affect the quality; of optimization. For example, running all loop passes on a loop may",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:3865,adapt,adaptors,3865,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['adapt'],['adaptors']
Energy Efficiency,"g macro; [alarmStateLabel setText:alarmText];. OS X Checkers. Name, DescriptionExample. osx.API; (C); Check for proper uses of various Apple APIs:; dispatch_once. void test() {; dispatch_once_t pred = 0;; dispatch_once(&pred, ^(){}); // warn: dispatch_once uses local; }. osx.NumberObjectConversion; (C, C++, ObjC); Check for erroneous conversions of objects representing numbers; into numbers. NSNumber *photoCount = [albumDescriptor objectForKey:@""PhotoCount""];; // Warning: Comparing a pointer value of type 'NSNumber *'; // to a scalar integer value; if (photoCount > 0) {; [self displayPhotos];; }. osx.SecKeychainAPI; (C); Check for improper uses of the Security framework's Keychain APIs:; SecKeychainItemCopyContent; SecKeychainFindGenericPassword; SecKeychainFindInternetPassword; SecKeychainItemFreeContent; SecKeychainItemCopyAttributesAndData; SecKeychainItemFreeAttributesAndData. void test() {; unsigned int *ptr = 0;; UInt32 length;. SecKeychainItemFreeContent(ptr, &length);; // warn: trying to free data which has not been allocated; }. void test() {; unsigned int *ptr = 0;; UInt32 *length = 0;; void *outData;. OSStatus st =; SecKeychainItemCopyContent(2, ptr, ptr, length, outData);; // warn: data is not released; }. void test() {; unsigned int *ptr = 0;; UInt32 *length = 0;; void *outData;. OSStatus st =; SecKeychainItemCopyContent(2, ptr, ptr, length, &outData);. SecKeychainItemFreeContent(ptr, outData);; // warn: only call free if a non-NULL buffer was returned; }. void test() {; unsigned int *ptr = 0;; UInt32 *length = 0;; void *outData;. OSStatus st =; SecKeychainItemCopyContent(2, ptr, ptr, length, &outData);. st = SecKeychainItemCopyContent(2, ptr, ptr, length, &outData);; // warn: release data before another call to the allocator. if (st == noErr); SecKeychainItemFreeContent(ptr, outData);; }. void test() {; SecKeychainItemRef itemRef = 0;; SecKeychainAttributeInfo *info = 0;; SecItemClass *itemClass = 0;; SecKeychainAttributeList *attrList = 0;; UInt32 *len",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html:13406,allocate,allocated,13406,interpreter/llvm-project/clang/www/analyzer/available_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html,2,['allocate'],['allocated']
Energy Efficiency,"g on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of the wavefront access this using dword (4 byte) interleaving. The mapping; used from private address to backing memory address is:. ``wavefront-scratch-base +; ((private-address / 4) * wavefront-size * 4) +; (wavefront-lane-id * 4) + (private-address % 4)``. If each lane of a wavefront accesses the same private address, the; interleaving results in adjacent dwords being accessed and hence requires; fewer cache lines to be fetched. There are different ways that the wavefront scratch base address is; determined by a wavefront (see; :ref:`amdg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:26599,allocate,allocates,26599,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocates']
Energy Efficiency,"g the neutral value; ``1.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to the starting value. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fmul; <int_vector_reduce_fmul>`) for more detail on the semantics. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmul.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float 1.0, float 1.0, float 1.0, float 1.0>; %also.r = call float @llvm.vector.reduce.fmul.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_and:. '``llvm.vp.reduce.and.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.and.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.and``' intrinsic performs the integer ``AND`` reduction; (:ref:`llvm.vector.reduce.and <int_vector_reduce",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:756817,reduce,reduce,756817,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"g-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``sqrt``' function but without; trapping or setting ``errno``. For types specified by IEEE-754, the result; matches a conforming libm implementation. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. '``llvm.powi.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.powi`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. Generally, the only supported type for the exponent is the one matching; with the C type ``int``. ::. declare float @llvm.powi.f32.i32(float %Val, i32 %power); declare double @llvm.powi.f64.i16(double %Val, i16 %power); declare x86_fp80 @llvm.powi.f80.i32(x86_fp80 %Val, i32 %power); declare fp128 @llvm.powi.f128.i32(fp128 %Val, i32 %power); declare ppc_fp128 @llvm.powi.ppcf128.i32(ppc_fp128 %Val, i32 %power). Overview:; """""""""""""""""". The '``llvm.powi.*``' intrinsics return the first operand raised to the; specified (positive or negative) power. The order of evaluation of; multiplications is not defined. When a vector of floating-point type is; used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The second argument is an integer power, and the first is a value to; raise to that power. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.sin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sin`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.sin.f32(float %Val); declare double @llvm.sin.f64(double %Val); declare x86_fp80 @llvm.sin.f80(x86_fp80 %Val); declare fp128 @llvm.sin.f128(fp128 %Val); declare ppc_fp128 @ll",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:558259,power,power,558259,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"g.cpp needs to be; revisited. The check is there to work around a misuse of directives in inline; assembly. //===---------------------------------------------------------------------===//. It would be good to detect collector/target compatibility instead of silently; doing the wrong thing. //===---------------------------------------------------------------------===//. It would be really nice to be able to write patterns in .td files for copies,; which would eliminate a bunch of explicit predicates on them (e.g. no side; effects). Once this is in place, it would be even better to have tblgen; synthesize the various copy insertion/inspection methods in TargetInstrInfo. //===---------------------------------------------------------------------===//. Stack coloring improvements:. 1. Do proper LiveStacks analysis on all stack objects including those which are; not spill slots.; 2. Reorder objects to fill in gaps between objects.; e.g. 4, 1, <gap>, 4, 1, 1, 1, <gap>, 4 => 4, 1, 1, 1, 1, 4, 4. //===---------------------------------------------------------------------===//. The scheduler should be able to sort nearby instructions by their address. For; example, in an expanded memset sequence it's not uncommon to see code like this:. movl $0, 4(%rdi); movl $0, 8(%rdi); movl $0, 12(%rdi); movl $0, 0(%rdi). Each of the stores is independent, and the scheduler is currently making an; arbitrary decision about the order. //===---------------------------------------------------------------------===//. Another opportunitiy in this code is that the $0 could be moved to a register:. movl $0, 4(%rdi); movl $0, 8(%rdi); movl $0, 12(%rdi); movl $0, 0(%rdi). This would save substantial code size, especially for longer sequences like; this. It would be easy to have a rule telling isel to avoid matching MOV32mi; if the immediate has more than some fixed number of uses. It's more involved; to teach the register allocator how to do late folding to recover from; excessive register pressure. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:5233,schedul,scheduler,5233,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,2,['schedul'],['scheduler']
Energy Efficiency,"g; stringWithCString:]``"") and the basename is the selector only; (""``stringWithCString:``""). Mach-O Changes; """""""""""""""""""""""""""". The sections names for the apple hash tables are for non-mach-o files. For; mach-o files, the sections should be contained in the ``__DWARF`` segment with; names as follows:. * ""``.apple_names``"" -> ""``__apple_names``""; * ""``.apple_types``"" -> ""``__apple_types``""; * ""``.apple_namespaces``"" -> ""``__apple_namespac``"" (16 character limit); * ""``.apple_objc``"" -> ""``__apple_objc``"". .. _codeview:. CodeView Debug Info Format; ==========================. LLVM supports emitting CodeView, the Microsoft debug info format, and this; section describes the design and implementation of that support. Format Background; -----------------. CodeView as a format is clearly oriented around C++ debugging, and in C++, the; majority of debug information tends to be type information. Therefore, the; overriding design constraint of CodeView is the separation of type information; from other ""symbol"" information so that type information can be efficiently; merged across translation units. Both type information and symbol information is; generally stored as a sequence of records, where each record begins with a; 16-bit record size and a 16-bit record kind. Type information is usually stored in the ``.debug$T`` section of the object; file. All other debug info, such as line info, string table, symbol info, and; inlinee info, is stored in one or more ``.debug$S`` sections. There may only be; one ``.debug$T`` section per object file, since all other debug info refers to; it. If a PDB (enabled by the ``/Zi`` MSVC option) was used during compilation,; the ``.debug$T`` section will contain only an ``LF_TYPESERVER2`` record pointing; to the PDB. When using PDBs, symbol information appears to remain in the object; file ``.debug$S`` sections. Type records are referred to by their index, which is the number of records in; the stream before a given record plus ``0x1000``. Many co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:82906,efficient,efficiently,82906,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['efficient'],['efficiently']
Energy Efficiency,"ge process:. 1. When clang compiles a source file with ``-fcoverage-mapping``, it; generates the mapping information that describes the mapping between the; source ranges and the profiling instrumentation counters.; This information gets embedded into the LLVM IR and conveniently; ends up in the final executable file when the program is linked. 2. It is also used by *llvm-cov* - the mapping information is extracted from an; object file and is used to associate the execution counts (the values of the; profile instrumentation counters), and the source ranges in a file.; After that, the tool is able to generate various code coverage reports; for the program. The coverage mapping format aims to be a ""universal format"" that would be; suitable for usage by any frontend, and not just by Clang. It also aims to; provide the frontend the possibility of generating the minimal coverage mapping; data in order to reduce the size of the IR and object files - for example,; instead of emitting mapping information for each statement in a function, the; frontend is allowed to group the statements with the same execution count into; regions of code, and emit the mapping information only for those regions. Advanced Concepts; =================. The remainder of this guide is meant to give you insight into the way the; coverage mapping format works. The coverage mapping format operates on a per-function level as the; profile instrumentation counters are associated with a specific function.; For each function that requires code coverage, the frontend has to create; coverage mapping data that can map between the source code ranges and; the profile instrumentation counters for that function. Mapping Region; --------------. The function's coverage mapping data contains an array of mapping regions.; A mapping region stores the `source code range`_ that is covered by this region,; the `file id <coverage file id_>`_, the `coverage mapping counter`_ and; the region's kind.; There are several kinds",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:2533,reduce,reduce,2533,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,1,['reduce'],['reduce']
Energy Efficiency,"ge* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this table. In the case of AMD; Jaguar, there are two register files, one for floating-point registers (JFpuPRF); and one for integer registers (JIntegerPRF). The table shows that of the 900; instructions processed, there were 900 mappings created. Since this dot-product; example utilized only floating point registers, the JFPuPRF was responsible for; creating the 900 mappings. H",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:32273,schedul,scheduler,32273,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['schedul'],"['scheduler', 'scheduler-stats']"
Energy Efficiency,"get will be; installed as part of all distributions it appears in, and it'll be exported by; the last distribution it appears in (the order of distributions is the order; they appear in *LLVM_DISTRIBUTIONS*). We also define some umbrella targets (e.g.; ``llvm-libraries`` to install all LLVM libraries); a target can appear in a; different distribution than its umbrella, in which case the target will be; exported by the distribution it appears in (and not the distribution its; umbrella appears in). Set *LLVM_STRICT_DISTRIBUTIONS* to ``On`` if you want to; enforce a target appearing in only one distribution and umbrella distributions; being consistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:6971,power,powerful,6971,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['power'],['powerful']
Energy Efficiency,"get; simulated dylib, a reference to the ``LinkGraph`` that must be allocated for,; and a callback to run once an ``InFlightAlloc`` has been constructed.; ``JITLinkMemoryManager`` implementations can (optionally) use the ``JD``; argument to manage a per-simulated-dylib memory pool (since code model; constraints are typically imposed on a per-dylib basis, and not across; dylibs) [2]_. The ``LinkGraph`` describes the object file that we need to; allocate memory for. The allocator must allocate working memory for all of; the Blocks defined in the graph, assign address space for each Block within the; executing processes memory, and update the Blocks' addresses to reflect this; assignment. Block content should be copied to working memory, but does not need; to be transferred to executor memory yet (that will be done once the content is; fixed up). ``JITLinkMemoryManager`` implementations can take full; responsibility for these steps, or use the ``BasicLayout`` utility to reduce; the task to allocating working and executor memory for *segments*: chunks of; memory defined by permissions, alignments, content sizes, and zero-fill sizes.; Once the allocation step is complete the memory manager should construct an; ``InFlightAlloc`` object to represent the allocation, and then pass this object; to the ``OnAllocated`` callback. The ``InFlightAlloc`` object has two virtual methods:. .. code-block:: c++. using OnFinalizedFunction = unique_function<void(Expected<FinalizedAlloc>)>;; using OnAbandonedFunction = unique_function<void(Error)>;. /// Called prior to finalization if the allocation should be abandoned.; virtual void abandon(OnAbandonedFunction OnAbandoned) = 0;. /// Called to transfer working memory to the target and apply finalization.; virtual void finalize(OnFinalizedFunction OnFinalized) = 0;. The linking process will call the ``finalize`` method on the ``InFlightAlloc``; object if linking succeeds up to the finalization step, otherwise it will call; ``abandon`` to ind",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:28368,reduce,reduce,28368,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['reduce'],['reduce']
Energy Efficiency,"gets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations between regression target and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities inside the cells reaches a minimum. BDT:; Introduced gradient boosting and stochastic gradient boosting for ; classification with BDT (as desribed by Friedman 1999). See ""BDTG"" ; example in TMVAClassification.C/cxx. A new option allows to restrict the maximum tree depth. This may be used to; avoid overtraining and often gives better performance than pruning. (The; pruning mechanism needs to be revisited). MLP:; Introduced recognition of convergence via general ConvergenceTest-class for; interrupting computations when convergence is reached. This feature has is; used now in MethodMLP. Improved treatment of event-weights in BFGS training. Implemented random and importance sampling of events in DataSet. Implemented; the usage of this feature for MLP",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:2435,adapt,adapting,2435,tmva/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html,2,['adapt'],['adapting']
Energy Efficiency,"giving type and syntax feedback using e.g. colors.; Class names are highlighted blue when typed, indicating that it is known to ROOT.; Matching parenthesis pairs are highlighted green when typed, or when the cursor is moved to a bracket. This works for () {} and [] brackets.; Any mismatched brackets (those without a matching partner) will be highlighted red when typed or when the cursor is moved to the bracket.; Tab completion output is colored magenta to differentiate between tab completion output and user input.; All of the colors are configurable in the .rootrc file.; They can be specified as #rgb or #rrggbb or color names:; black, red, green, yellow, blue, magenta, cyan or white.; They can be followed by an optional bold (alias light) or underlined.; Rint.ReverseColor allows to quickly toggle between the default ""light on dark"" (yes) instead of ""dark on light"" (no), depending on the terminal background.; An example configuration would be:. Rint.TypeColor: blue; Rint.BracketColor: bold green; Rint.BadBracketColor: underlined red; Rint.TabColor: magenta; Rint.PromptColor: black; Rint.ReverseColor: no. The enhanced prompt is available on all platforms with [n]curses, including Linux, Solaris and MacOS; the bold and underline options are available also for black and white terminals. You can export (or setenv) TERM=xterm-256color for nicer colors.; With editline comes also an improved terminal input handler.; It supports e.g. ^O (Ctrl-o) to replay the history: suppose you have entered. ...; root [3] i = func(); root [4] i += 12; root [5] printf(""i is %d\n"", i). You now want to re-run these three lines.; As always, you press the up cursor three times to see. root [6] i = func(). and now press ^O (Ctrl-o) to run the line, and prepare the next line:. root [6] i = func()^O; root [7] i += 12^O; root [8] printf(""i is %d\n"", i)^O; root [9] . allowing you to re-run that part of the history without having to press the up-arrow again and again.; Currently, editline is disabled ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v526/index.html:2540,green,green,2540,core/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v526/index.html,2,['green'],['green']
Energy Efficiency,"gnstack``' keyword second, the '``inteldialect``' keyword; third and the '``unwind``' keyword last. Inline Asm Constraint String; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The constraint list is a comma-separated string, each element containing one or; more constraint codes. For each element in the constraint list an appropriate register or memory; operand will be chosen, and it will be made available to assembly template; string expansion as ``$0`` for the first constraint in the list, ``$1`` for the; second, etc. There are three different types of constraints, which are distinguished by a; prefix symbol in front of the constraint code: Output, Input, and Clobber. The; constraints must always be given in that order: outputs first, then inputs, then; clobbers. They cannot be intermingled. There are also three different categories of constraint codes:. - Register constraint. This is either a register class, or a fixed physical; register. This kind of constraint will allocate a register, and if necessary,; bitcast the argument or result to the appropriate type.; - Memory constraint. This kind of constraint is for use with an instruction; taking a memory operand. Different constraints allow for different addressing; modes used by the target.; - Immediate value constraint. This kind of constraint is for an integer or other; immediate value which can be rendered directly into an instruction. The; various target-specific constraints allow the selection of a value in the; proper range for the instruction you wish to use it with. Output constraints; """""""""""""""""""""""""""""""""""". Output constraints are specified by an ""``=``"" prefix (e.g. ""``=r``""). This; indicates that the assembly will write to this operand, and the operand will; then be made available as a return value of the ``asm`` expression. Output; constraints do not consume an argument from the call instruction. (Except, see; below about indirect outputs). Normally, it is expected that no output locations are written to by the assembly; e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:211207,allocate,allocate,211207,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocate']
Energy Efficiency,"gpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is usefu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6669,reduce,reduce,6669,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['reduce'],['reduce']
Energy Efficiency,"gref_triple:. Target Triple; -------------. A module may specify a target triple string that describes the target; host. The syntax for the target triple is simply:. .. code-block:: llvm. target triple = ""x86_64-apple-macosx10.7.0"". The *target triple* string consists of a series of identifiers delimited; by the minus sign character ('-'). The canonical forms are:. ::. ARCHITECTURE-VENDOR-OPERATING_SYSTEM; ARCHITECTURE-VENDOR-OPERATING_SYSTEM-ENVIRONMENT. This information is passed along to the backend so that it generates; code for the proper architecture. It's possible to override this on the; command line with the ``-mtriple`` command line option. .. _objectlifetime:. Object Lifetime; ----------------------. A memory object, or simply object, is a region of a memory space that is; reserved by a memory allocation such as :ref:`alloca <i_alloca>`, heap; allocation calls, and global variable definitions.; Once it is allocated, the bytes stored in the region can only be read or written; through a pointer that is :ref:`based on <pointeraliasing>` the allocation; value.; If a pointer that is not based on the object tries to read or write to the; object, it is undefined behavior. A lifetime of a memory object is a property that decides its accessibility.; Unless stated otherwise, a memory object is alive since its allocation, and; dead after its deallocation.; It is undefined behavior to access a memory object that isn't alive, but; operations that don't dereference it such as; :ref:`getelementptr <i_getelementptr>`, :ref:`ptrtoint <i_ptrtoint>` and; :ref:`icmp <i_icmp>` return a valid result.; This explains code motion of these instructions across operations that; impact the object's lifetime.; A stack object's lifetime can be explicitly specified using; :ref:`llvm.lifetime.start <int_lifestart>` and; :ref:`llvm.lifetime.end <int_lifeend>` intrinsic function calls. .. _pointeraliasing:. Pointer Aliasing Rules; ----------------------. Any memory access must be done thro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:140348,allocate,allocated,140348,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,gs from specified component. .. option:: -gen-clang-diag-groups. Generate Clang diagnostic groups. .. option:: -gen-clang-diags-index-name. Generate Clang diagnostic name index. .. option:: -gen-clang-basic-reader. Generate Clang BasicReader classes. .. option:: -gen-clang-basic-writer. Generate Clang BasicWriter classes. .. option:: -gen-clang-comment-nodes. Generate Clang AST comment nodes. .. option:: -gen-clang-decl-nodes. Generate Clang AST declaration nodes. .. option:: -gen-clang-stmt-nodes. Generate Clang AST statement nodes. .. option:: -gen-clang-type-nodes. Generate Clang AST type nodes. .. option:: -gen-clang-type-reader. Generate Clang AbstractTypeReader class. .. option:: -gen-clang-type-writer. Generate Clang AbstractTypeWriter class. .. option:: -gen-clang-opcodes. Generate Clang constexpr interpreter opcodes. .. option:: -gen-clang-sa-checkers. Generate Clang static analyzer checkers. .. option:: -gen-clang-comment-html-tags. Generate efficient matchers for HTML tag names that are used in; documentation comments. .. option:: -gen-clang-comment-html-tags-properties. Generate efficient matchers for HTML tag properties. .. option:: -gen-clang-comment-html-named-character-references. Generate function to translate named character references to UTF-8 sequences. .. option:: -gen-clang-comment-command-info. Generate command properties for commands that are used in documentation comments. .. option:: -gen-clang-comment-command-list. Generate list of commands that are used in documentation comments. .. option:: -gen-clang-opencl-builtins. Generate OpenCL builtin declaration handlers. .. option:: -gen-arm-neon. Generate ``arm_neon.h`` for Clang. .. option:: -gen-arm-fp16. Generate ``arm_fp16.h`` for Clang. .. option:: -gen-arm-bf16. Generate ``arm_bf16.h`` for Clang. .. option:: -gen-arm-neon-sema. Generate ARM NEON sema support for Clang. .. option:: -gen-arm-neon-test. Generate ARM NEON tests for Clang. .. option:: -gen-arm-sve-header. Generate ``arm_sve.h``,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:5238,efficient,efficient,5238,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,1,['efficient'],['efficient']
Energy Efficiency,"gument. The; ``release`` and ``acq_rel`` orderings are not valid on ``load`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic loads. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemporal`` does not have any; defined semantics for atomic loads. The optional constant ``align`` argument specifies the alignment of the; operation (that is, the alignment of the memory address). It is the; responsibility of the code emitter to ensure that the alignment information is; correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address space. Access of the high bytes can interfere with debugging tools, so; should not be accessed if the function has the ``sanitize_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. An omitted ``align`` argument means that the operation has the; ABI alignment for the target. The optional ``!nontemporal`` metadata must reference a single; metadata name ``<nontemp_node>`` corresponding to a metadata node with one; ``i32`` entry of value 1. The existence of the ``!nontemporal``; metadata on the instruction tells the optimizer and code generator; that this load is not expected to be reused in the cache. The code; generat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:414210,efficient,efficient,414210,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency,"h enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MIN`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smax.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 -128, i8 -128, i8 -128, i8 -128>; %reduction = call i8 @llvm.vector.reduce.smax.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smax.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_smin:. '``llvm.vp.reduce.smin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smin``' intrinsic performs the signed-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.smin ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:764950,reduce,reduce,764950,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two result files and filter short running tests:. ```bash; % test-suite/utils/compare.py --filter-short baseline.json experiment.json; ...; Program baseline experiment diff. SingleSour.../Benchmarks/Linpack/linpack-pc 5.16 4.30 -16.5%; MultiSourc...erolling-dbl/LoopRerolling-dbl 7.01 7.86 12.2%; SingleSour...UnitTests/Vectorizer/gcc-loops 3.89 3.54 -9.0%; ...; ```. - Merge multiple baseline and experiment result files by taking the minimum; runtime each:. ```bash; % test-suite/utils/compare.py base0.json base1.json base2.json vs exp0.json exp1.json exp2.json; ```. ### Continuous Tracking with LNT. LNT is a set of client and server tools for continuously monitoring; performance. You can find more information at; [https://llvm.org/docs/lnt](https://llvm.org/docs/lnt). The official LNT instance; of the LLVM project is hosted at [http://lnt.llvm.org](http://lnt.llvm.org). External Suites; ---------------. External suites such as SPEC can be enabled by either. - placing (or linking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:8696,monitor,monitoring,8696,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,1,['monitor'],['monitoring']
Energy Efficiency,"hadow call stack' in the function prolog in; non-leaf functions and loading the return address from the shadow call stack; in the function epilog. The return address is also stored on the regular stack; for compatibility with unwinders, but is otherwise unused. The aarch64 implementation is considered production ready, and; an `implementation of the runtime`_ has been added to Android's libc; (bionic). An x86_64 implementation was evaluated using Chromium and was found; to have critical performance and security deficiencies--it was removed in; LLVM 9.0. Details on the x86_64 implementation can be found in the; `Clang 7.0.1 documentation`_. .. _`implementation of the runtime`: https://android.googlesource.com/platform/bionic/+/808d176e7e0dd727c7f929622ec017f6e065c582/libc/bionic/pthread_create.cpp#128; .. _`Clang 7.0.1 documentation`: https://releases.llvm.org/7.0.1/tools/clang/docs/ShadowCallStack.html. Comparison; ----------. To optimize for memory consumption and cache locality, the shadow call; stack stores only an array of return addresses. This is in contrast to other; schemes, like :doc:`SafeStack`, that mirror the entire stack and trade-off; consuming more memory for shorter function prologs and epilogs with fewer; memory accesses. `Return Flow Guard`_ is a pure software implementation of shadow call stacks; on x86_64. Like the previous implementation of ShadowCallStack on x86_64, it is; inherently racy due to the architecture's use of the stack for calls and; returns. Intel `Control-flow Enforcement Technology`_ (CET) is a proposed hardware; extension that would add native support to use a shadow stack to store/check; return addresses at call/return time. Being a hardware implementation, it; would not suffer from race conditions and would not incur the overhead of; function instrumentation, but it does require operating system support. .. _`Return Flow Guard`: https://xlab.tencent.com/en/2016/11/02/return-flow-guard/; .. _`Control-flow Enforcement Technology",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ShadowCallStack.rst:1317,consumption,consumption,1317,interpreter/llvm-project/clang/docs/ShadowCallStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ShadowCallStack.rst,1,['consumption'],['consumption']
Energy Efficiency,"han only when C99 parsing is; requested, including for statements. [testme]. Block literal expressions may occur within Block literal expressions; (nest) and all variables captured by any nested blocks are implicitly; also captured in the scopes of their enclosing Blocks. A Block literal expression may be used as the initialization value for; Block variables at global or local static scope. The Invoke Operator; ===================. Blocks are :block-term:`invoked` using function call syntax with a; list of expression parameters of types corresponding to the; declaration and returning a result type also according to the; declaration. Given:. .. code-block:: c. int (^x)(char);; void (^z)(void);; int (^(*y))(char) = &x;. the following are all legal Block invocations:. .. code-block:: c. x('a');; (*y)('a');; (true ? x : *y)('a'). The Copy and Release Operations; ===============================. The compiler and runtime provide :block-term:`copy` and; :block-term:`release` operations for Block references that create and,; in matched use, release allocated storage for referenced Blocks. The copy operation ``Block_copy()`` is styled as a function that takes; an arbitrary Block reference and returns a Block reference of the same; type. The release operation, ``Block_release()``, is styled as a; function that takes an arbitrary Block reference and, if dynamically; matched to a Block copy operation, allows recovery of the referenced; allocated memory. The ``__block`` Storage Qualifier; =================================. In addition to the new Block type we also introduce a new storage; qualifier, :block-term:`__block`, for local variables. [testme: a; __block declaration within a block literal] The ``__block`` storage; qualifier is mutually exclusive to the existing local storage; qualifiers auto, register, and static. [testme] Variables qualified by; ``__block`` act as if they were in allocated storage and this storage; is automatically recovered after last use of said varia",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:6443,allocate,allocated,6443,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['allocate'],['allocated']
Energy Efficiency,"hanges are applied and buildmaster is; reconfigured. #. Make sure you can start the buildbot-worker and successfully connect; to the silent buildmaster. Then set up your buildbot-worker to start; automatically at the start up time. See the buildbot documentation; for help. You may want to restart your computer to see if it works. #. Check the status of your buildbot-worker on the `Waterfall Display (Staging); <http://lab.llvm.org/staging/#/waterfall>`_ to make sure it is; connected, and the `Workers Display (Staging); <http://lab.llvm.org/staging/#/workers>`_ to see if administrator; contact and worker information are correct. #. At this point, you have a working builder connected to the staging; buildmaster. You can now make sure it is reliably green and keeps; up with the build queue. No notifications will be sent, so you can; keep an unstable builder connected to staging indefinitely. #. (Optional) Once the builder is stable on the staging buildmaster with; several days of green history, you can choose to move it to the production; buildmaster to enable developer notifications. Please email `Galina; Kistanova <mailto:gkistanova@gmail.com>`_ for review and approval. To move a worker to production (once approved), stop your worker, edit the; buildbot.tac file to change the port number from 9994 to 9990 and start it; again. Best Practices for Configuring a Fast Builder; =============================================. As mentioned above, we generally have a strong preference for; builders which can build every commit as they come in. This section; includes best practices and some recommendations as to how to achieve; that end. The goal; In 2020, the monorepo had just under 35 thousand commits. This works; out to an average of 4 commits per hour. Already, we can see that a; builder must cycle in less than 15 minutes to have a hope of being; useful. However, those commits are not uniformly distributed. They; tend to cluster strongly during US working hours. Looking at a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:7424,green,green,7424,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['green'],['green']
Energy Efficiency,"hat TH1/TH2 superimposing in 3D works properly; 4. Fix - use provided options in JSROOT.redraw function; 5. Fix - arb8 shape, used in composite. ## Changes in 5.7.1; 1. Fix - cover for WebVR API inconsistencies in Android devices (#184); 2. Fix - add more checks in TF1 GetParName/GetParValue methods (#185); 3. Fix - bins highlight in lego drawing with ""zero"" option; 4. Fix - drawing tracks with geometry from TObjArray; 5. Fix - interactive TGraph point move on time scale; 6. Fix - arb8 shapes faces building. ## Changes in 5.7.0; 1. Add support of TProfile2Poly class; 2. Add support of TGeoOverlap class, provide access from TGeoManager; 3. Add support of TGeoHalfSpace for composites; 4. Implement TF2 drawings update, see tutorials/graphics/anim.C; 5. Improve windows handling in flex(ible) layout; 6. Better position for text in TH2Poly drawings; 7. Enable projections drawing also with TH2 lego plots; 8. Use gStyle attributes to draw histogram title; 9. Use requestAnimationFrame when do monitoring, improves performance; 10. Support eve7 geometry viewer - render data generated in ROOT itself; 11. Many adjustment with new TWebCanvas - interactivity, attributes/position updates; 12. Provide initial WebVR support (#176), thanks to Diego Marcos (@dmarcos); 13. Upgrade three.js 86 -> 102, use SoftwareRenderer instead of CanvasRenderer; 14. Upgrade d3.js 4.4.4 -> 5.7.0; 15. Use d3.js and three.js from npm when running with node.js; 16. Fix - support clipping for tracks and points in geo painter; 17. Fix - drawing of TGeoNode with finder; 18. Fix - key press events processed only in active pad (ROOT-9128); 19. Fix - use X0/Y0 in xtru shape (#182), thanks to @altavir; 20. Move most of ui5-specific code into ROOT repository, where it will be maintained; 21. Provide special widget for object inspector. ## Changes in 5.6.4; 1. Fix - try workaround corrupted data in TTree; 2. Fix - support min0 draw option like ROOT does; 3. Fix - correctly handle TH2Poly draw options; 4. Fix - sel",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:30317,monitor,monitoring,30317,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitoring']
Energy Efficiency,"hat `x` can only have one value. When control flow from; the ""then"" and ""else"" branches joins, `x` can have either value. Abstract algebra provides a nice formalism that models this kind of structure,; namely, a lattice. A join-semilattice is a partially ordered set, in which every; two elements have a least upper bound (called a *join*). ```; join(a, b) â©¾ a and join(a, b) â©¾ b and join(x, x) = x; ```. For this problem we will use the lattice of subsets of integers, with set; inclusion relation as ordering and set union as a join. Lattices are often represented visually as Hasse diagrams. Here is a Hasse; diagram for our lattice that tracks subsets of integers:. ![Hasse diagram for a lattice of integer sets](DataFlowAnalysisIntroImages/IntegerSetsInfiniteLattice.svg). Computing the join in the lattice corresponds to finding the lowest common; ancestor (LCA) between two nodes in its Hasse diagram. There is a vast amount of; literature on efficiently implementing LCA queries for a DAG, however Efficient; Implementation of Lattice Operations (1989); ([CiteSeerX](https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.106.4911),; [doi](https://doi.org/10.1145%2F59287.59293)) describes a scheme that; particularly well-suited for programmatic implementation. ### Too much information and ""top"" values. Let's try to find the possible sets of values of `x` in a function that modifies; `x` in a loop:. ```c++; void ExampleOfInfiniteSets() {; int x = 0; // x is {0}; while (condition()) {; x += 1; // x is {0; 1; 2; â€¦}; }; print(x); // x is {0; 1; 2; â€¦}; }; ```. We have an issue: `x` can have any value greater than zero; that's an infinite; set of values, if the program operated on mathematical integers. In C++ `int` is; limited by `INT_MAX` so technically we have a set `{0; 1; â€¦; INT_MAX}` which is; still really big. To make our analysis practical to compute, we have to limit the amount of; information that we track. In this case, we can, for example, arbitrarily limit; the size o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:3740,efficient,efficiently,3740,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['efficient'],['efficiently']
Energy Efficiency,"hat an exception object's; destructor will not throw and code simplification is possible. .. option:: -ftrap-function=[name]. Instruct code generator to emit a function call to the specified; function name for ``__builtin_trap()``. LLVM code generator translates ``__builtin_trap()`` to a trap; instruction if it is supported by the target ISA. Otherwise, the; builtin is translated into a call to ``abort``. If this option is; set, then the code generator will always lower the builtin to a call; to the specified function regardless of whether the target ISA has a; trap instruction. This option is useful for environments (e.g.; deeply embedded) where a trap cannot be properly handled, or when; some custom behavior is desired. .. option:: -ftls-model=[model]. Select which TLS model to use. Valid values are: ``global-dynamic``, ``local-dynamic``,; ``initial-exec`` and ``local-exec``. The default value is; ``global-dynamic``. The compiler may use a different model if the; selected model is not supported by the target, or if a more; efficient model can be used. The TLS model can be overridden per; variable using the ``tls_model`` attribute. .. option:: -femulated-tls. Select emulated TLS model, which overrides all -ftls-model choices. In emulated TLS mode, all access to TLS variables are converted to; calls to __emutls_get_address in the runtime library. .. option:: -mhwdiv=[values]. Select the ARM modes (arm or thumb) that support hardware division; instructions. Valid values are: ``arm``, ``thumb`` and ``arm,thumb``.; This option is used to indicate which mode (arm or thumb) supports; hardware division instructions. This only applies to the ARM; architecture. .. option:: -m[no-]crc. Enable or disable CRC instructions. This option is used to indicate whether CRC instructions are to; be generated. This only applies to the ARM architecture. CRC instructions are enabled by default on ARMv8. .. option:: -mgeneral-regs-only. Generate code which only uses the general purpose regi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:83701,efficient,efficient,83701,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"hat does static storage duration do when zero for the type is not all zero bits?; Unknown. 17; C89; 39 unrelated questions about C89; Unknown. 18; NAD; How does fscanf behave in the presence of multibyte characters?; N/A. 19; NAD; Definition of the term ""printing character"" and isgraph(); N/A. 20; NAD; Is a compiler which allows the Relaxed Ref/Def linkage model to be considered a conforming compiler?; Yes. 21; C89; What is the result of: printf(""%#.4o"", 345);?; N/A. 22; C89; What is the result of: strtod(""100ergs"", &ptr);?; N/A. 23; NAD; what is the result of strtod(""0.0e99999"", &ptr);?; N/A. 24; NAD; In subclause 7.10.1.4 The strtod function: What does '""C"" locale' mean?; N/A. 25; NAD; What is meant by 'representable floating-point value?'; Yes. 26; NAD; Can a strictly conforming program contain a string literal with '$' or '@'?; Yes. 27; C89; Can there be characters in the character set that are not in the required source character set?; Yes. 28; NAD; Do object access rules apply to dynamically allocated objects?; Unknown. 29; NAD; Do two types have to have the same tag to be compatible?; No. 30; NAD; Can 'sin(DBL_MAX)' result in 'errno' being set to 'EDOM'?; N/A. 31; NAD; Can constant expressions overflow?; Yes. 32; NAD; Must implementations diagnose extensions to the constant evaluation rules?; No. 33; NAD; Conformance questions around 'shall' violations outside of constraints sections; Yes. 34; C89; External declarations in different scopes; Yes. 35; NAD; Questions about definition of functions without a prototype. Partial; Tags declared directly within an identifier list are incorrectly scoped; to the prototype rather than to the function body.; . 36; NAD; May floating-point constants be represented with more precision than implied by its type?; Yes. 37; NAD; Questions about multibyte characters and Unicode; Yes. 38; NAD; Questions about argument substitution during macro expansion; Yes. 39; NAD; Questions about the ""C"" locale; Yes. 40; NAD; 9 unrelated quest",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html:2734,allocate,allocated,2734,interpreter/llvm-project/clang/www/c_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html,2,['allocate'],['allocated']
Energy Efficiency,"hat is RooFit?. [RooFit] is a statistical data analysis tool, widely used in scientific; research, especially in the high-energy physics (HEP) field. It is an; extension of the ROOT framework, a C++ based data analysis framework that; provides tools for data storage, analysis, and visualization. RooFit provides; a set of tools/classes to define and evaluate probability density functions; (PDFs), perform maximum likelihood fits, perform statistical tests, etc. ## Proof of Concept: Speeding up RooFit using Automatic Differentiation (AD). RooFit is used to reduce statistical models (functions) to find a set of; parameters that minimize the value of the function. This minimization happens; via one of several methods relying heavily on the computation of derivatives; of the function with respect to its free parameters. Currently, the; computation of Numerical Derivatives is the most time-consuming component of; RooFit [^1]. On the other hand, derivatives computed using the Automatic; Differentiation tool [Clad] have been shown to be far more efficient [^2]. \htmlonly; <div class=""pyrootbox"">; \endhtmlonly. Main Advantage of using AD with RooFit: efficient and more precise; derivatives. It computes derivatives with high precision, avoiding the errors; that may arise from approximating derivatives using finite differences. \htmlonly; </div>; \endhtmlonly. ### AD Support essentially requires Code Generation. As we'll discuss in upcoming sections, *AD support* can be added using *C++; Code generation*.; These two terms may be used interchangeably in this document, since the term; *Code Generation* better helps visualize the transformation that is enabling; AD support. ## Current Status of Code Generation in RooFit. RooFit is an extensive toolkit.; The initiative to add AD support/ Code Generation has been started, but has; not yet achieved full coverage for the models defined/maintained in RooFit. ## How Clad enables AD support using Source Code Transformation. [Clad] is a C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:1354,efficient,efficient,1354,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['efficient'],['efficient']
Energy Efficiency,"hat value; the capture variable is; destroyed when the block literal is, i.e. at the end of the enclosing scope. The :ref:`inference <arc.ownership.inference>` rules apply equally to; ``__block`` variables, which is a shift in semantics from non-ARC, where; ``__block`` variables did not implicitly retain during capture. ``__block`` variables of retainable object owner type are moved off the stack; by initializing the heap copy with the result of moving from the stack copy. With the exception of retains done as part of initializing a ``__strong``; parameter variable or reading a ``__weak`` variable, whenever these semantics; call for retaining a value of block-pointer type, it has the effect of a; ``Block_copy``. The optimizer may remove such copies when it sees that the; result is used only as an argument to a call. When a block pointer type is converted to a non-block pointer type (such as; ``id``), ``Block_copy`` is called. This is necessary because a block allocated; on the stack won't get copied to the heap when the non-block pointer escapes.; A block pointer is implicitly converted to ``id`` when it is passed to a; function as a variadic argument. .. _arc.misc.exceptions:. Exceptions; ----------. By default in Objective C, ARC is not exception-safe for normal releases:. * It does not end the lifetime of ``__strong`` variables when their scopes are; abnormally terminated by an exception.; * It does not perform releases which would occur at the end of a; full-expression if that full-expression throws an exception. A program may be compiled with the option ``-fobjc-arc-exceptions`` in order to; enable these, or with the option ``-fno-objc-arc-exceptions`` to explicitly; disable them, with the last such argument ""winning"". .. admonition:: Rationale. The standard Cocoa convention is that exceptions signal programmer error and; are not intended to be recovered from. Making code exceptions-safe by; default would impose severe runtime and code size penalties on code tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:97440,allocate,allocated,97440,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['allocate'],['allocated']
Energy Efficiency,"hat would be:. ::. ready> def test(x) 1+2+x;; Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double 2.000000e+00, 1.000000e+00; %addtmp1 = fadd double %addtmp, %x; ret double %addtmp1; }. Constant folding, as seen above, in particular, is a very common and; very important optimization: so much so that many language implementors; implement constant folding support in their AST representation. With LLVM, you don't need this support in the AST. Since all calls to; build LLVM IR go through the LLVM IR builder, the builder itself checked; to see if there was a constant folding opportunity when you call it. If; so, it just does the constant fold and return the constant instead of; creating an instruction. Well, that was easy :). In practice, we recommend always using; ``IRBuilder`` when generating code like this. It has no ""syntactic; overhead"" for its use (you don't have to uglify your compiler with; constant checks everywhere) and it can dramatically reduce the amount of; LLVM IR that is generated in some cases (particular for languages with a; macro preprocessor or that use a lot of constants). On the other hand, the ``IRBuilder`` is limited by the fact that it does; all of its analysis inline with the code as it is built. If you take a; slightly more complex example:. ::. ready> def test(x) (1+2+x)*(x+(1+2));; ready> Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double 3.000000e+00, %x; %addtmp1 = fadd double %x, 3.000000e+00; %multmp = fmul double %addtmp, %addtmp1; ret double %multmp; }. In this case, the LHS and RHS of the multiplication are the same value.; We'd really like to see this generate ""``tmp = x+3; result = tmp*tmp;``""; instead of computing ""``x+3``"" twice. Unfortunately, no amount of local analysis will be able to detect and; correct this. This requires two transformations: reassociation of; expressions (to make the add's lexically identical) and Common; Subexpression Elimination",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:2131,reduce,reduce,2131,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['reduce'],['reduce']
Energy Efficiency,"have been identified; through years of use: confusing to use, slow, it doesnâ€™t always produce high; quality test cases, etc. This document proposes a new approach with a narrower; focus: minimization of IR test cases. ## Proposed New Design. ### Narrow focus: test-case reduction; The main focus will be a code reduction strategy to obtain much smaller test; cases that still have the same property as the original one. This will be done; via classic delta debugging and by adding some IR-specific reductions (e.g.; replacing globals, removing unused instructions, etc), similar to what; already exists, but with more in-depth minimization. Granted, if the community differs on this proposal, the legacy code could still; be present in the tool, but with the caveat of still being documented and; designed towards delta reduction. ### Command-Line Options; We are proposing to reduce the plethora of bugpointâ€™s options to just two: an; interesting-ness test and the arguments for said test, similar to other delta; reduction tools such as CReduce, Delta, and Lithium; the tool should feel less; cluttered, and there should also be no uncertainty about how to operate it. The interesting-ness test thatâ€™s going to be run to reduce the code is given; by name:; `--test=<test_name>`; If a `--test` option is not given, the program exits; this option is similar; to bugpointâ€™s current `-compile-custom` option, which lets the user run a; custom script. The interesting-ness test would be defined as a script that returns 0 when the; IR achieves a user-defined behaviour (e.g. failure to compile on clang) and a; nonzero value when otherwise. Leaving the user the freedom to determine what is; and isnâ€™t interesting to the tool, and thus, streamlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. Itâ€™s worth noting that the input",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:1050,reduce,reduce,1050,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md,1,['reduce'],['reduce']
Energy Efficiency,"he '``llvm.vp.reduce.xor``' intrinsic performs the integer ``XOR`` reduction; (:ref:`llvm.vector.reduce.xor <int_vector_reduce_xor>`) of the vector operand; ``val`` on each enabled lane, performing an '``xor``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %masked.a); %also.r = xor i32 %reduction, %start. .. _int_vp_reduce_smax:. '``llvm.vp.reduce.smax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:762740,reduce,reduce,762740,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"he PATH. ; A complete list of options can be obtained by running scan-build; with no arguments.; Output of scan-build. The output of scan-build is a set of HTML files, each one which represents a; separate bug report. A single index.html file is generated for; surveying all of the bugs. You can then just open index.html in a web; browser to view the bug reports. Where the HTML files are generated is specified with a -o option to; scan-build. If -o isn't specified, a directory in /tmp; is created to store the files (scan-build will print a message telling; you where they are). If you want to view the reports immediately after the build; completes, pass -V to scan-build. Recommended Usage Guidelines; This section describes a few recommendations with running the analyzer.; ALWAYS analyze a project in its ""debug"" configuration; Most projects can be built in a ""debug"" mode that enables assertions.; Assertions are picked up by the static analyzer to prune infeasible paths, which; in some cases can greatly reduce the number of false positives (bogus error; reports) emitted by the tool.; Another option is to use --force-analyze-debug-code flag of; scan-build tool which would enable assertions automatically.; Use verbose output when debugging scan-build; scan-build takes a -v option to emit verbose output about; what it's doing; two -v options emit more information. Redirecting the; output of scan-build to a text file (make sure to redirect standard; error) is useful for filing bug reports against scan-build or the; analyzer, as we can see the exact options (and files) passed to the analyzer.; For more comprehensible logs, don't perform a parallel build.; Run './configure' through scan-build; If an analyzed project uses an autoconf generated configure script,; you will probably need to run configure script through; scan-build in order to analyze the project.; Example. $ scan-build ./configure; $ scan-build --keep-cc make. The reason configure also needs to be run through; sc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/scan-build.html:6356,reduce,reduce,6356,interpreter/llvm-project/clang/www/analyzer/scan-build.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/scan-build.html,2,['reduce'],['reduce']
Energy Efficiency,"he architecture interface question is also; > important for portable Java-type VMs?. I forsee the architecture looking kinda like this: (which is completely; subject to change). 1. The VM code is NOT guaranteed safe in a java sense. Doing so makes it; basically impossible to support C like languages. Besides that,; certifying a register based language as safe at run time would be a; pretty expensive operation to have to do. Additionally, we would like; to be able to statically eliminate many bounds checks in Java; programs... for example. 2. Instead, we can do the following (eventually): ; * Java bytecode is used as our ""safe"" representation (to avoid; reinventing something that we don't add much value to). When the; user chooses to execute Java bytecodes directly (ie, not; precompiled) the runtime compiler can do some very simple; transformations (JIT style) to convert it into valid input for our; VM. Performance is not wonderful, but it works right.; * The file is scheduled to be compiled (rigorously) at a later; time. This could be done by some background process or by a second; processor in the system during idle time or something...; * To keep things ""safe"" ie to enforce a sandbox on Java/foreign code,; we could sign the generated VM code with a host specific private; key. Then before the code is executed/loaded, we can check to see if; the trusted compiler generated the code. This would be much quicker; than having to validate consistency (especially if bounds checks have; been removed, for example). > This is important because the audiences for these two goals are very; > different. Architects and many compiler people care much more about; > the second question. The Java compiler and OS community care much more; > about the first one. 3. By focusing on a more low level virtual machine, we have much more room; for value add. The nice safe ""sandbox"" VM can be provided as a layer; on top of it. It also lets us focus on the more interesting compilers; related proj",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:1469,schedul,scheduled,1469,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['schedul'],['scheduled']
Energy Efficiency,"he entire array, and a separate ""fUniqueID"" value for each; reference. For further information, see the above URL. ## Some useful container classes. ### TObjArray and TClonesArray. The TObjArray class can be used to support an array of objects. The objects need not be of the; same type, but each object must be of a class type that inherits from TObject. We have already; seen a specific example of the use of TObjArray, in the StreamerInfo record, where it is used; to hold an array of TStreamerElement objects, each of which is of a class inheriting from; TStreamerElement, which in turn inherits from TObject. The TClonesArray class is a specialization of the TObjArray class for holding an array; of objects that are all of the same type. The format of a TClonesArray object; is given in \ref tclonesarray. There are two great advantages in the use of TClonesArray over TObjArray when the objects; all will be of the same class:. 1. Memory for the objects will be allocated only once for the entire array, rather; than the per-object allocation for TObjArray. This can be done because all the; objects are the same size.; 2. In the case of TObjArray, the stored objects are written sequentially. However,; in a TClonesArray, by default, each object is split one level deep into its base; class(es) and data members, and each of these members is written sequentially for; all objects in the array before the next member is written. This has two advantages:; 1. Greater compression can be achieved when similar data is consecutive.; 2. The object's data members can easily be split into different TTree branches; (TTrees are discussed below). ### TTree. A TTree is a highly specialized container class for efficient storage and retrieval of user data.; The use of TTrees is discussed in detail in the; [Trees chapter of the Root Manual](https://root.cern/manual/trees/). Here we discuss in particular how a TTree is stored in a ROOTIO file. A TTree object is split into one or more branches (class ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:12659,allocate,allocated,12659,io/doc/TFile/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md,1,['allocate'],['allocated']
Energy Efficiency,"he minimum value of a multi-parameter; function (the ""$\mbox{FCN}$"") and analyze the shape of the function; around the minimum. The principal application is foreseen for; statistical analysis, working on chisquare or log-likelihood functions,; to compute the best-fit parameter values and uncertainties, including; correlations between the parameters. It is especially suited to handle; difficult problems, including those which may require guidance in order; to find the correct solution. ## What M is not intended to do ##. Although M will of course solve easy problems faster than complicated; ones, it is not intended for the repeated solution of identically; parametrized problems (such as track fitting in a detector) where a; specialized program will in general be much more efficient. ## Further remarks ##. M was initially written in Fortran around 1975-1980 at CERN by Fred; James @bib-MINUIT. Its main field of usage is statistical data analysis; of experimental data recorded at CERN, but it is also used by people; doing data analysis outside CERN or outside high energy physics (HEP).; In 2002 Fred James started a project aiming to re-implement M in an; object-oriented way using . More information about recent developments, releases and installation; can be obtained from the M homepage @bib-C++MINUIT. The names of M applications are written in capital letters (e.g.; $\mbox{MIGRAD}$, $\mbox{MINOS}$, $\mbox{CONTOURS}$), the; corresponding names of the classes are written using sans-serif font; type (MnMigrad, MnMinos, MnContours). # Introduction: M basic concepts #. [sec:intro]. ## The organization of M ##. The M package acts on a multiparameter *objective function* which is; called â€” for historical reasons â€” the $\mbox{FCN}$ function (see; [howto:fcn]). This function is usually a chisquared or a logâ€“likelihood,; but it could also be a mathematical function. The $\mbox{FCN}$; function needs to be written in for which M defines the pure abstract; base class FCNBase as inte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:1159,energy,energy,1159,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['energy'],['energy']
Energy Efficiency,"he point number `ipoint`.; - When a 2D histogram was drawn with error bars and has a function in its list; it was impossible to rotate it interactively. This problem was reported; [here](https://root-forum.cern.ch/t/2d-histogram-fit-draws-to-wrong-scale/26369).; - As more and more people are using `TGraph2D` for random cloud of points, the default; drawing option implying Delaunay triangulation was not appropriate. The default; drawing option is now change to `P0`.; - It is now possible to set the value of `MaxDigits` on individual axis as; requested [here](https://sft.its.cern.ch/jira/browse/ROOT-35).; For example, to accept 6 digits number like 900000 on the X axis of the; histogram `h` call:; ```{.cpp}; h->GetXaxis()->SetMaxDigits(6);; ```; - Auto-coloring for TF1 (drawing options PFC, PLC and PMC) is implemented. ## 3D Graphics Libraries; - When a LEGO plot was drawn with Theta=90, the X and Y axis were misplaced. ## Geometry Libraries; - Added system of units and physical constants matching the CLHEP port to Geant4, adapted to ROOT by Marko Petric.; - Computing radiation length and nuclear interaction length for mixtures as in Geant4 to have; numeric matching of average properties.; - Added support for reading region definition and production cuts for e+, e-, gamma, p; from GDML files; - Added support for reading/writing parts of the geometry tree to GDML (Markus Frank). ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## Parallelism; - Fix issue which prevented nested TBB task execution without race conditions, e.g. in TDataFrame; - Fix race condition in TTreeProcessorMT due to TBB nested task execution; - The TTaskGroup class has been added to the ROOT::Experimental namespace. It allows to submit to the runtime; item of work which are dealt with in parallel;; - The Async template function has been added the ROOT::Experimental namespace. The template function is analogous; to *std::async* but without the possibility of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:22954,adapt,adapted,22954,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['adapt'],['adapted']
Energy Efficiency,"he register; allocator. Instruction folding; ^^^^^^^^^^^^^^^^^^^. *Instruction folding* is an optimization performed during register allocation; that removes unnecessary copy instructions. For instance, a sequence of; instructions such as:. ::. %EBX = LOAD %mem_address; %EAX = COPY %EBX. can be safely substituted by the single instruction:. ::. %EAX = LOAD %mem_address. Instructions can be folded with the; ``TargetRegisterInfo::foldMemoryOperand(...)`` method. Care must be taken when; folding instructions; a folded instruction can be quite different from the; original instruction. See ``LiveIntervals::addIntervalsForSpills`` in; ``lib/CodeGen/LiveIntervalAnalysis.cpp`` for an example of its use. Built in register allocators; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The LLVM infrastructure provides the application developer with three different; register allocators:. * *Fast* --- This register allocator is the default for debug builds. It; allocates registers on a basic block level, attempting to keep values in; registers and reusing registers as appropriate. * *Basic* --- This is an incremental approach to register allocation. Live; ranges are assigned to registers one at a time in an order that is driven by; heuristics. Since code can be rewritten on-the-fly during allocation, this; framework allows interesting allocators to be developed as extensions. It is; not itself a production register allocator but is a potentially useful; stand-alone mode for triaging bugs and as a performance baseline. * *Greedy* --- *The default allocator*. This is a highly tuned implementation of; the *Basic* allocator that incorporates global live range splitting. This; allocator works hard to minimize the cost of spill code. * *PBQP* --- A Partitioned Boolean Quadratic Programming (PBQP) based register; allocator. This allocator works by constructing a PBQP problem representing; the register allocation problem under consideration, solving this using a PBQP; solver, and mapping the solution back t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:69490,allocate,allocates,69490,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['allocate'],['allocates']
Energy Efficiency,"he specified path:. ``` {.cpp}; Root.ShowPath: false; ```. Activate memory statistics. ``` {.cpp}; Root.ObjectStat: 0; ```. Global debug mode. When `>0` turns on progressively more details; debugging. ``` {.cpp}; Root.Debug: 0; Root.Stacktrace: yes; ```. Settings for X11 behaviour. ``` {.cpp}; X11.Sync: no; X11.FindBestVisual: yes; ```. Default editor in use. ``` {.cpp}; Unix.*.Editor: vi; WinNT.*.Editor: notepad; ```. Default 3d Viewer. By default 3-D views are shown in the pad, if the; next line is activated, the default viewer will be OpenGL. ``` {.cpp}; Viewer3D.DefaultDrawOption: ogl; ```. Default Fitter (current choices are `Minuit`, `Minuit2`, `Fumili` and; `Fumili2`). ``` {.cpp}; Root.Fitter: Minuit; ```. Specify list of file endings which **`TTabCom`** (TAB completion) should; ignore. ``` {.cpp}; TabCom.FileIgnore: .cpp:.h:.cmz; ```. ### TCanvas Specific Settings. Opaque move and resize show full pad during the operation instead of; only the outline. Especially for resize you will need serious CPU power.; `UseScreenFactor=true` means to size canvas according to size of screen,; so a canvas still looks good on a low resolution laptop screen without; having to change canvas size in macros. ``` {.cpp}; Canvas.MoveOpaque: false; Canvas.ResizeOpaque: false; Canvas.UseScreenFactor: true; ```. Hight color 2 is the red one. ``` {.cpp}; Canvas.HighLightColor: 2; ```. Next three settings are related to different user interface parts of; canvas window. If they are set to true, the corresponding event status; bar, tool bar, graphics editor will be activated by default. ``` {.cpp}; Canvas.ShowEventStatus: false; Canvas.ShowToolBar: false; Canvas.ShowEditor: false; ```. AutoExec allows **`TExec`** objects to be executed on mouse and key; events. ``` {.cpp}; Canvas.AutoExec: true; ```. Canvas print directory is set to the current one by default:. ``` {.cpp}; Canvas.PrintDirectory .; ```. Printer settings:. ``` {.cpp}; WinNT.*.Print.Command: AcroRd32.exe; #Unix.*.Print.Comm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InstallandBuild.md:5318,power,power,5318,documentation/users-guide/InstallandBuild.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InstallandBuild.md,1,['power'],['power']
Energy Efficiency,"he specified value.; If the value is less than negative zero, a floating-point exception occurs; and the return value is architecture specific. '``llvm.experimental.constrained.pow``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.experimental.constrained.pow(<type> <op1>, <type> <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.pow``' intrinsic returns the first operand; raised to the (positive or negative) power specified by the second operand. Arguments:; """""""""""""""""""". The first two arguments and the return value are floating-point numbers of the; same type. The second argument specifies the power to which the first argument; should be raised. The third and fourth arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power,; returning the same values as the libm ``pow`` functions would, and; handles error conditions in the same way. '``llvm.experimental.constrained.powi``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.experimental.constrained.powi(<type> <op1>, i32 <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.powi``' intrinsic returns the first operand; raised to the (positive or negative) power specified by the second operand. The; order of evaluation of multiplications is not defined. When a vector of; floating-point type is used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The first argument and the return value are floating-point numbers of the same; type. The second argument is a 32-bit signed integer specifying the power to; which the first argument should be raised. The third and fourth arguments specify the rounding mode and exception; behavior as ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:891719,power,power,891719,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"he start of its lifetime,; and resetting it to the stack pointer Address Tag at the end of; it. Unallocated stack space is expected to match the Address Tag of; SP; this allows to skip tagging of any variable when memory safety can; be statically proven. Allocating a truly random tag for each stack variable in a large; function may incur significant code size overhead, because it means; that each variable's address is an independent, non-rematerializable; value; thus a function with N local variables will have extra N live; values to keep through most of its life time. For this reason MemTagSanitizer generates at most one random tag per; function, called a ""base tag"". Other stack variables, if there are; any, are assigned tags at a fixed offset from the base. Please refer to `this document; <https://github.com/google/sanitizers/wiki/Stack-instrumentation-with-ARM-Memory-Tagging-Extension-(MTE)>`_; for more details about stack instrumentation. Heap tagging; ============. **Note:** this part is not implemented as of Oct 2019. MemTagSanitizer will use :doc:`ScudoHardenedAllocator`; with additional code to update memory tags when. * New memory is obtained from the system.; * An allocation is freed. There is no need to change Allocation Tags for the bulk of the; allocated memory in malloc(), as long as a pointer with the matching; Address Tag is returned. More information; ================. * `LLVM Developer Meeting 2018 talk on Memory Tagging <https://llvm.org/devmtg/2018-10/slides/Serebryany-Stepanov-Tsyrklevich-Memory-Tagging-Slides-LLVM-2018.pdf>`_; * `Memory Tagging Whitepaper <https://arxiv.org/pdf/1802.09517.pdf>`_. .. _Memory Tagging Extension: https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/arm-a-profile-architecture-2018-developments-armv85a; .. _AddressSanitizer: https://clang.llvm.org/docs/AddressSanitizer.html; .. _HardwareAssistedAddressSanitizer: https://clang.llvm.org/docs/HardwareAssistedAddressSanitizerDesign.html; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst:3236,allocate,allocated,3236,interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst,1,['allocate'],['allocated']
Energy Efficiency,"he swizzled SP value by:. | swizzled SP = unswizzled SP / wavefront size. This may be used to obtain the private address space address of stack; objects and to convert this address to a flat address by adding the flat; scratch aperture base address. The swizzled SP value is always 4 bytes aligned for the ``r600``; architecture and 16 byte aligned for the ``amdgcn`` architecture. .. note::. The ``amdgcn`` value is selected to avoid dynamic stack alignment for the; OpenCL language which has the largest base type defined as 16 bytes. On entry, the swizzled SP value is the address of the first function; argument passed on the stack. Other stack passed arguments are positive; offsets from the entry swizzled SP value. The function may use positive offsets beyond the last stack passed argument; for stack allocated local variables and register spill slots. If necessary,; the function may align these to greater alignment than 16 bytes. After these; the function may dynamically allocate space for such things as runtime sized; ``alloca`` local allocations. If the function calls another function, it will place any stack allocated; arguments after the last local allocation and adjust SGPR32 to the address; after the last local allocation. 9. All other registers are unspecified.; 10. Any necessary ``s_waitcnt`` has been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struct; arguments in C ABI. Callee is responsible for allocating stack memory and; copying the value of the struct if modified. Note that the backend still; supports byval for struct arguments. On exit from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are considered clobbered registers.; 2. The following registers are preserved and have the same value as on entry:. * FLAT_SCRATCH; * EXEC; * GFX6-GFX8: M0; * All SGPR registers except the clobbered registers of SG",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:389536,allocate,allocate,389536,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocate']
Energy Efficiency,"he vector operand; ``val`` on each enabled lane, performing an '``or``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.or.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %masked.a); %also.r = or i32 %reduction, %start. .. _int_vp_reduce_xor:. '``llvm.vp.reduce.xor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.xor.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.xor.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``XOR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.xor``' intrinsic performs the integer ``XOR`` reduction; (:ref:`llvm.vector.reduce.xor <int_vector_reduce",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:760865,reduce,reduce,760865,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"he; :ref:`amdgpu-amdhsa-hsa-aql-queue` the address of which can be obtained with; Queue Ptr SGPR (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline constant; registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``. In 64 bit; address mode the aperture sizes are 2^32 bytes and the base is aligned to 2^32; which makes it easier to convert from flat to segment or segment to flat. Image and Samplers; ~~~~~~~~~~~~~~~~~~. Image and sample handles created by an HSA compatible runtime (see; :ref:`amdgpu-os`) are 64-bit addresses of a hardware 32-byte V# and 48 byte S#; object respectively. In order to support the HSA ``query_sampler`` operations; two extra dwords are used to store the HSA BRIG enumeration values for the; queries that are not trivially deducible from the S# representation. HSA Signals; ~~~~~~~~~~~. HSA signal handles created by an HSA compatible runtime (see :ref:`amdgpu-os`); are 64-bit addresses of a structure allocated in memory accessible from both the; CPU and GPU. The structure is defined by the runtime and subject to change; between releases. For example, see [AMD-ROCm-github]_. .. _amdgpu-amdhsa-hsa-aql-queue:. HSA AQL Queue; ~~~~~~~~~~~~~. The HSA AQL queue structure is defined by an HSA compatible runtime (see; :ref:`amdgpu-os`) and subject to change between releases. For example, see; [AMD-ROCm-github]_. For some processors it contains fields needed to implement; certain language features such as the flat address aperture bases. It also; contains fields used by CP such as managing the allocation of scratch memory. .. _amdgpu-amdhsa-kernel-descriptor:. Kernel Descriptor; ~~~~~~~~~~~~~~~~~. A kernel descriptor consists of the information needed by CP to initiate the; execution of a kernel, including the entry point address of the machine code; that implements the kernel. Code Object V3 Kernel Descriptor; ++++++++++++++++++++++++++++++++. CP microcode requi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:157275,allocate,allocated,157275,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"he; indices is that of ``elt``. Example:; """""""""""""""". .. code-block:: llvm. %agg1 = insertvalue {i32, float} undef, i32 1, 0 ; yields {i32 1, float undef}; %agg2 = insertvalue {i32, float} %agg1, float %val, 1 ; yields {i32 1, float %val}; %agg3 = insertvalue {i32, {float}} undef, float %val, 1, 0 ; yields {i32 undef, {float %val}}. .. _memoryops:. Memory Access and Addressing Operations; ---------------------------------------. A key design point of an SSA-based representation is how it represents; memory. In LLVM, no memory locations are in SSA form, which makes things; very simple. This section describes how to read, write, and allocate; memory in LLVM. .. _i_alloca:. '``alloca``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = alloca [inalloca] <type> [, <ty> <NumElements>] [, align <alignment>] [, addrspace(<num>)] ; yields type addrspace(num)*:result. Overview:; """""""""""""""""". The '``alloca``' instruction allocates memory on the stack frame of the; currently executing function, to be automatically released when this; function returns to its caller. If the address space is not explicitly; specified, the object is allocated in the alloca address space from the; :ref:`datalayout string<langref_datalayout>`. Arguments:; """""""""""""""""""". The '``alloca``' instruction allocates ``sizeof(<type>)*NumElements``; bytes of memory on the runtime stack, returning a pointer of the; appropriate type to the program. If ""NumElements"" is specified, it is; the number of elements allocated, otherwise ""NumElements"" is defaulted; to be one. If a constant alignment is specified, the value result of the; allocation is guaranteed to be aligned to at least that boundary. The; alignment may not be greater than ``1 << 32``. The alignment is only optional when parsing textual IR; for in-memory IR,; it is always present. If not specified, the target can choose to align the; allocation on any convenient boundary compatible with the type. '``type``' may be any sized type. Structs ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:409114,allocate,allocates,409114,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocates']
Energy Efficiency,"hen used with ``-x`` or ``-p``.; If the section(s) are not compressed, they are displayed as is. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output is an expanded and structured format.; ``GNU`` (the default) output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --extra-sym-info. Display extra information (section name) when showing symbols. .. option:: --section-groups, -g. Display section groups. .. option:: --expand-relocs. When used with :option:`--relocations`, display each relocation in an expanded; multi-line format. .. option:: --file-header, -h. Display file headers. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --headers, -e. Equivalent to setting: :option:`--file-header`, :option:`--program-headers`,; and :option:`--sections`. .. option:: --help. Display a summary of command line options. .. option:: --hex-dump=<section[,section,...]>, -x. Display the specified section(s) as hexadecimal bytes. ``section`` may be a; section index or section name. .. option:: --memtag. Display information abo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:2040,consumption,consumption,2040,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,1,['consumption'],['consumption']
Energy Efficiency,"her options you can use are:. .. code-block:: bash. Use Ninja instead of Make: ""-G Ninja""; Build with assertions on: ""-DLLVM_ENABLE_ASSERTIONS=True""; Local (non-sudo) install path: ""-DCMAKE_INSTALL_PREFIX=$HOME/llvm/install""; CPU flags: ""DCMAKE_C_FLAGS=-mcpu=cortex-a15"" (same for CXX_FLAGS). After that, just typing ``make -jN`` or ``ninja`` will build everything.; ``make -jN check-all`` or ``ninja check-all`` will run all compiler tests. For; running the test suite, please refer to :doc:`TestingGuide`. #. If you are building LLVM/Clang on an ARM board with 1G of memory or less,; please use ``gold`` rather then GNU ``ld``. In any case it is probably a good; idea to set up a swap partition, too. .. code-block:: bash. $ sudo ln -sf /usr/bin/ld /usr/bin/ld.gold. #. ARM development boards can be unstable and you may experience that cores; are disappearing, caches being flushed on every big.LITTLE switch, and; other similar issues. To help ease the effect of this, set the Linux; scheduler to ""performance"" on **all** cores using this little script:. .. code-block:: bash. # The code below requires the package 'cpufrequtils' to be installed.; for ((cpu=0; cpu<`grep -c proc /proc/cpuinfo`; cpu++)); do; sudo cpufreq-set -c $cpu -g performance; done. Remember to turn that off after the build, or you may risk burning your; CPU. Most modern kernels don't need that, so only use it if you have; problems. #. Running the build on SD cards is ok, but they are more prone to failures; than good quality USB sticks, and those are more prone to failures than; external hard-drives (those are also a lot faster). So, at least, you; should consider to buy a fast USB stick. On systems with a fast eMMC,; that's a good option too. #. Make sure you have a decent power supply (dozens of dollars worth) that can; provide *at least* 4 amperes, this is especially important if you use USB; devices with your board. Externally powered USB/SATA harddrives are even; better than having a good power supply.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst:3310,power,power,3310,interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst,3,['power'],"['power', 'powered']"
Energy Efficiency,"her_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2122,allocate,allocate,2122,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,1,['allocate'],['allocate']
Energy Efficiency,here an integral type for every pointer?; Yes. 58; NAD; Is there a limit on the number of digits processed by scanf and strtdo?; N/A. 59; NAD; Do types have to be completed?; Yes. 60; C89; Array initialization from a string literal; Yes. 61; NAD; Whitespace in scanf format string; N/A. 62; NAD; Can the rename function be defined to fail?; N/A. 63; Dup; Floating-point representation precision requirements; Duplicate of 56. 64; NAD; Null pointer constants; Yes. 65; C89; Questions on locales; N/A. 66; NAD; Another question on locales; N/A. 67; NAD; Integer and integral type confusion; Yes. 68; NAD; 'char' and signed vs unsigned integer types; Yes. 69; NAD; Questions about the representation of integer types; Yes. 70; NAD; Interchangeability of function arguments; Yes. 71; C89; Enumerated types; Yes. 72; NAD; Definition of object and pointer arithmetic; Unknown. 73; NAD; Definition of object and array access; Unknown. 74; NAD; Alignment and structure padding; Unknown. 75; NAD; Alignment of allocated memory; N/A. 76; Open; Pointers to the end of arrays; Not resolved. 77; NAD; Stability of addresses; Yes. 78; NAD; Uniqueness of addresses; Unknown. 79; NAD; Constancy of system library function addresses; N/A. 80; C89; Merging of string constants; Yes. 81; NAD; Left shift operator; Yes. 82; C89; Multiple varargs; Unknown. 83; C89; Use of library functions; N/A. 84; NAD; Incomplete type in function declaration; Yes. 85; C89; Returning from main; Yes. 86; NAD; Object-like macros in system headers; Yes. 87; NAD; Order of evaluation; Unknown. 88; NAD; Compatibility of incomplete types; Yes. 89; C89; Multiple definitions of macros; Yes. 90; NAD; Multibyte characters in formats; N/A. 91; NAD; Multibyte encodings; Yes. 92; Dup; Partial initialization of strings; Duplicate of 60. 93; C89; Reservation of identifiers; Yes. 94; NAD; Are constraints on function return the same as assignment?; Yes. 95; NAD; Is initialization as constrained as assignment?; Yes. 96; NAD; Arrays of incomple,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html:5877,allocate,allocated,5877,interpreter/llvm-project/clang/www/c_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html,2,['allocate'],['allocated']
Energy Efficiency,"hes the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:21726,power,powerpc,21726,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['power'],['powerpc']
Energy Efficiency,"hese five templates can be used with any classes, whether they have a v-table; or not. If you want to add support for these templates, see the document; :doc:`How to set up LLVM-style RTTI for your class hierarchy; <HowToSetUpLLVMStyleRTTI>`. .. _string_apis:. Passing strings (the ``StringRef`` and ``Twine`` classes); ---------------------------------------------------------. Although LLVM generally does not do much string manipulation, we do have several; important APIs which take strings. Two important examples are the Value class; -- which has names for instructions, functions, etc. -- and the ``StringMap``; class which is used extensively in LLVM and Clang. These are generic classes, and they need to be able to accept strings which may; have embedded null characters. Therefore, they cannot simply take a ``const; char *``, and taking a ``const std::string&`` requires clients to perform a heap; allocation which is usually unnecessary. Instead, many LLVM APIs use a; ``StringRef`` or a ``const Twine&`` for passing strings efficiently. .. _StringRef:. The ``StringRef`` class; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``StringRef`` data type represents a reference to a constant string (a; character array and a length) and supports the common operations available on; ``std::string``, but does not require heap allocation. It can be implicitly constructed using a C style null-terminated string, an; ``std::string``, or explicitly with a character pointer and length. For; example, the ``StringMap`` find function is declared as:. .. code-block:: c++. iterator find(StringRef Key);. and clients can call it using any one of:. .. code-block:: c++. Map.find(""foo""); // Lookup ""foo""; Map.find(std::string(""bar"")); // Lookup ""bar""; Map.find(StringRef(""\0baz"", 4)); // Lookup ""\0baz"". Similarly, APIs which need to return a string may return a ``StringRef``; instance, which can be used directly or converted to an ``std::string`` using; the ``str`` member function. See ``llvm/ADT/StringRef.h`` ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:8347,efficient,efficiently,8347,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficiently']
Energy Efficiency,"hey are variable length, inefficient to hash and compare when; long, expensive to copy, etc. StringMap is a specialized container designed to; cope with these issues. It supports mapping an arbitrary range of bytes to an; arbitrary other object. The StringMap implementation uses a quadratically-probed hash table, where the; buckets store a pointer to the heap allocated entries (and some other stuff).; The entries in the map must be heap allocated because the strings are variable; length. The string data (key) and the element object (value) are stored in the; same allocation with the string data immediately after the element object.; This container guarantees the ""``(char*)(&Value+1)``"" points to the key string; for a value. The StringMap is very fast for several reasons: quadratic probing is very cache; efficient for lookups, the hash value of strings in buckets is not recomputed; when looking up an element, StringMap rarely has to touch the memory for; unrelated objects when looking up a value (even when hash collisions happen),; hash table growth does not recompute the hash values for strings already in the; table, and each pair in the map is store in a single allocation (the string data; is stored in the same allocation as the Value of a pair). StringMap also provides query methods that take byte ranges, so it only ever; copies a string if a value is inserted into the table. StringMap iteration order, however, is not guaranteed to be deterministic, so; any uses which require that should instead use a std::map. .. _dss_indexmap:. llvm/ADT/IndexedMap.h; ^^^^^^^^^^^^^^^^^^^^^. IndexedMap is a specialized container for mapping small dense integers (or; values that can be mapped to small dense integers) to some other type. It is; internally implemented as a vector with a mapping function that maps the keys; to the dense integer range. This is useful for cases like virtual registers in the LLVM code generator: they; have a dense mapping that is offset by a compile-time",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:89377,efficient,efficient,89377,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"hich deserves a bit of explanation: if a; register class constraint allocates a register which is too small for the value; type operand provided as input, the input value will be split into multiple; registers, and all of them passed to the inline asm. However, this feature is often not as useful as you might think. Firstly, the registers are *not* guaranteed to be consecutive. So, on those; architectures that have instructions which operate on multiple consecutive; instructions, this is not an appropriate way to support them. (e.g. the 32-bit; SparcV8 has a 64-bit load, which instruction takes a single 32-bit register. The; hardware then loads into both the named register, and the next register. This; feature of inline asm would not be useful to support that.). A few of the targets provide a template string modifier allowing explicit access; to the second register of a two-register operand (e.g. MIPS ``L``, ``M``, and; ``D``). On such an architecture, you can actually access the second allocated; register (yet, still, not any subsequent ones). But, in that case, you're still; probably better off simply splitting the value into two separate operands, for; clarity. (e.g. see the description of the ``A`` constraint on X86, which,; despite existing only for use with this feature, is not really a good idea to; use). Indirect inputs and outputs; """""""""""""""""""""""""""""""""""""""""""""""""""""". Indirect output or input constraints can be specified by the ""``*``"" modifier; (which goes after the ""``=``"" in case of an output). This indicates that the asm; will write to or read from the contents of an *address* provided as an input; argument. (Note that in this way, indirect outputs act more like an *input* than; an output: just like an input, they consume an argument of the call expression,; rather than producing a return value. An indirect output constraint is an; ""output"" only in that the asm is expected to write to the contents of the input; memory location, instead of just read from it). Thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:215205,allocate,allocated,215205,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"hing Step 3, and compilation; should proceed as if VPlans had not been built. 2. Align Cost & Execute: each VPlan must support both estimating the cost and; generating the output IR code, such that the cost estimation evaluates the; to-be-generated code reliably. 3. Support vectorizing additional constructs:. a. Outer-loop vectorization. In particular, VPlan must be able to model the; control-flow of the output IR which may include multiple basic-blocks and; nested loops.; b. SLP vectorization.; c. Combinations of the above, including nested vectorization: vectorizing; both an inner loop and an outer-loop at the same time (each with its own; VF and UF), mixed vectorization: vectorizing a loop with SLP patterns; inside [4]_, (re)vectorizing input IR containing vector code.; d. Function vectorization [2]_. 4. Support multiple candidates efficiently. In particular, similar candidates; related to a range of possible VF's and UF's must be represented efficiently.; Potential versioning needs to be supported efficiently. 5. Support vectorizing idioms, such as interleaved groups of strided loads or; stores. This is achieved by modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruction; patterns. Definitions; ===========; The low-level design of VPlan comprises of the following classes. :LoopVectorizationPlanner:; A LoopVectorizationPlanner",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:3115,efficient,efficiently,3115,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['efficient'],['efficiently']
Energy Efficiency,"hing sorting;. - special mathematical functions like `Bessel`, `Erf`, `Gamma`, etc.;. - statistical functions, like common probability and cumulative; (quantile) distributions. - geometrical functions. For more details, see the reference documentation of **`TMath`** at; [<http://root.cern.ch/root/htmldoc/TMath.html>](https://root.cern/doc/master/namespaceTMath.html). ### Numerical Constants. `TMath` offers a wide range of constants in the form of inline functions. Notice that they are not defined as C/C++ preprocessor macros. This set of functions includes one or more definitions for the following constants:. * Pi.; * Base of natural logarithm.; * Velocity of light.; * Gravitational constant (G).; * Standard acceleration of gravity (g).; * Standard acceleration of Gravity.; * Plank's contant.; * Boltzmann's and Steffan-Boltzmann's constants.; * Avogadro's number.; * Universal gas constant.; * Molecular weight of dry air.; * Dry air gas constant.; * Euler-Mascheroni Constant.; * Elementary charge. ### Elementary Functions. A set of miscellaneous elementary mathematical functions is provided along with a set of basic trigonometrical functions. Some of this functions refer to basic mathematical functions like the square root, the power to a number of the calculus of a logarithm, while others are used for number treatment, like rounding. Although there are some functions that are not in the standard C math library (like `Factorial`), most of the functionality offered here is just a wrapper of the first ones. Nevertheless, some of the them also offer some security checks or a better precision, like the trigonometrical functions `ASin(x)`, `ACos(x)` or `ATan(x)`. ```{.cpp}; // Generate a vector with 10 random numbers; vector<double> v(10);; std::generate(v.begin(), v.end(), rand);. // Find the minimum value of the vector (iterator version); vector<double>::iterator it;; it = TMath::LocMin(v.begin(), v.end());; std::cout << *it << std::endl;. // The same with the old-style",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:7233,charge,charge,7233,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['charge'],['charge']
Energy Efficiency,"hing to happen. - **getResult()**: gets the result for the given node using the node name.; This node also performs the necessary code generation through recursive calls; to `translate()`. - **assembleCode()**: combines the generated code statements into the final; code body of the squashed function. These functions will appear again in this document with more contextual; examples. For detailed in-line documentation (code comments), please see:. > [roofit/roofitcore/src/RooFit/Detail/CodeSquashContext.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooFit/Detail/CodeSquashContext.cxx). ### b. RooFuncWrapper. > [roofit/roofitcore/inc/RooFuncWrapper.h](https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooFuncWrapper.h). This class wraps the generated C++ code in a RooFit object, so that it can be; used like other RooFit objects. It takes a function body as input and creates a callable function from it.; This allows users to evaluate the function and its derivatives efficiently. #### Helper Functions. - **loadParamsAndData()** extracts parameters and observables from the; provided data and prepares them for evaluation. - **declareAndDiffFunction()**: declare the function and create its; derivative. - **gradient()**: calculates the gradient of the function with respect to its; parameters. - **buildCode()**: generates the optimized code for evaluating the function; and its derivatives. - **dumpCode()**: prints the squashed code body to console (useful for; debugging). - **dumpGradient()**: prints the derivative code body to console (useful for; debugging). These functions will appear again in this document with more contextual; examples. For detailed in-line documentation (code comments), please see:. > [roofit/roofitcore/src/RooFuncWrapp9er.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooFuncWrapper.cxx). ## Appendix C - Helper functions discussed in this document. - **RooFit::Detail::CodeSqu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:33537,efficient,efficiently,33537,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['efficient'],['efficiently']
Energy Efficiency,"his; sequence to mark the initial set of live symbols. Notable use cases: marking nodes live, accessing/copying graph data that; will be pruned (e.g. metadata that's important for the JIT, but not needed; for the link process). #. Prune (dead-strip) the ``LinkGraph``. Removes all symbols and blocks not reachable from the initial set of live; symbols. This allows JITLink to remove unreachable symbols / content, including; overridden weak and redundant ODR definitions. #. Run post-prune passes. These passes are run on the graph after dead-stripping, but before memory; is allocated or nodes assigned their final target vmaddrs. Passes run at this stage benefit from pruning, as dead functions and data; have been stripped from the graph. However new content can still be added; to the graph, as target and working memory have not been allocated yet. Notable use cases: Building Global Offset Table (GOT), Procedure Linkage; Table (PLT), and Thread Local Variable (TLV) entries. #. Asynchronously allocate memory. Calls the ``JITLinkContext``'s ``JITLinkMemoryManager`` to allocate both; working and target memory for the graph. As part of this process the; ``JITLinkMemoryManager`` will update the addresses of all nodes; defined in the graph to their assigned target address. Note: This step only updates the addresses of nodes defined in this graph.; External symbols will still have null addresses. #. Phase 2. #. Run post-allocation passes. These passes are run on the graph after working and target memory have; been allocated, but before the ``JITLinkContext`` is notified of the; final addresses of the symbols in the graph. This gives these passes a; chance to set up data structures associated with target addresses before; any JITLink clients (especially ORC queries for symbol resolution) can; attempt to access them. Notable use cases: Setting up mappings between target addresses and; JIT data structures, such as a mapping between ``__dso_handle`` and; ``JITDylib*``. #. Notify the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:19231,allocate,allocate,19231,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocate']
Energy Efficiency,"hout jquery at all,; such mode used in `nobrowser` mode.; 4. Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; 5. Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE; 6. Fix error with time axes - time offset was not correctly interpreted. ## Changes in 3.3; 1. Use d3.time.scale for display of time scales; 2. Within JSRootCore.js script URL one could specify JSROOT; functionality to be loaded: '2d', '3d', 'io', 'load', 'onload'.; Old method with JSROOT.AssertPrerequisites will also work.; 3. With THttpServer JSROOT now provides simple control functionality.; One could publish commands and execute them from the browser; 4. One could open several ROOT files simultaneously; 5. Add 'simple' layout - drawing uses full space on the right side; 6. Allow to open ROOT files in online session (via url parameter); 7. One could monitor simultaneously objects from server and root files; 8. Implement 'autocol' draw option - when superimposing histograms,; their line colors will be automatically assigned; 9. Implement 'nostat' draw option - disabled stat drawing; 10. Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; 11. When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; 12. Item of 'Text' kind can be created. It is displayed as; plain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See httpcontrol.C macro for example.; 13. When using foreignObject, provide workaround for absolute positioning; problem ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:67509,monitor,monitor,67509,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitor']
Energy Efficiency,"hree new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.fram",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22173,adapt,adaptive,22173,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,4,"['adapt', 'efficient']","['adaptive', 'efficiently']"
Energy Efficiency,"hysics vector classes describe vectors in three and four dimensions; and their rotation algorithms. The classes were ported to root from; CLHEP see:. <http://www.cern.ch/clhep/manual/UserGuide/Vector/vector.html>. ## The Physics Vector Classes. In order to use the physics vector classes you will have to load the; Physics library:. ``` {.cpp}; gSystem.Load(""libPhysics.so"");; ```. There are four classes in this package. They are:. **`TVector3`** is a general three-vector. A **`TVector3`** may be; expressed in Cartesian, polar, or cylindrical coordinates. Methods; include dot and cross products, unit vectors and magnitudes, angles; between vectors, and rotations and boosts. There are also functions of; particular use to HEP, like pseudo-rapidity, projections, and transverse; part of a **`TVector3`**, and kinetic methods on 4-vectors such as; Invariant Mass of pairs or containers of particles`.`. **`TLorentzVector`** is a general four-vector class, which can be used; either for the description of position and time (`x`, `y`, `z`, `t`) or; momentum and energy (`px`, `py`, `pz`, `E`). **`TRotation`** is a class; describing a rotation of a **`TVector3`** object. **`TLorentzRotation`**; is a class to describe the Lorentz transformations including Lorentz; boosts and rotations. In addition, a **`TVector2`** is a basic; implementation of a vector in two dimensions and is not part of the; CLHEP translation. ## TVector3. ![](pictures/030001A9.png). **`TVector3`** is a general three-vector; class, which can be used for description of different vectors in 3D.; Components of three vectors:. - $x$, $y$, $z$ = basic components. - $\theta$ = azimuth angle. - $\phi$ = polar angle. - magnitude = $mag$ = $\sqrt{x^2 + y^2 + z^2}$. - transverse component = $perp$ = $\sqrt{x^2 + y^2}$. Using the **`TVector3`** class, you should remember that it contains; only common features of three vectors and lacks methods specific for; some particular vector values. For example, it has no translated; f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md:1088,energy,energy,1088,documentation/users-guide/PhysicsVectors.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md,1,['energy'],['energy']
Energy Efficiency,"i.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.powi`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. Generally, the only supported type for the exponent is the one matching; with the C type ``int``. ::. declare float @llvm.powi.f32.i32(float %Val, i32 %power); declare double @llvm.powi.f64.i16(double %Val, i16 %power); declare x86_fp80 @llvm.powi.f80.i32(x86_fp80 %Val, i32 %power); declare fp128 @llvm.powi.f128.i32(fp128 %Val, i32 %power); declare ppc_fp128 @llvm.powi.ppcf128.i32(ppc_fp128 %Val, i32 %power). Overview:; """""""""""""""""". The '``llvm.powi.*``' intrinsics return the first operand raised to the; specified (positive or negative) power. The order of evaluation of; multiplications is not defined. When a vector of floating-point type is; used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The second argument is an integer power, and the first is a value to; raise to that power. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.sin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sin`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.sin.f32(float %Val); declare double @llvm.sin.f64(double %Val); declare x86_fp80 @llvm.sin.f80(x86_fp80 %Val); declare fp128 @llvm.sin.f128(fp128 %Val); declare ppc_fp128 @llvm.sin.ppcf128(ppc_fp128 %Val). Overview:; """""""""""""""""". The '``llvm.sin.*``' intrinsics return the sine of the operand. Arguments:; """""""""""""""""""". The argument and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``sin``' function but without; trapping or setting ``errno``. When specified with the fast-m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:558619,power,power,558619,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['power'],['power']
Energy Efficiency,"i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umin.*``' intrinsics do an unsigned; integer ``MIN`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmax:. '``llvm.vector.reduce.fmax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmax.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmax.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:658096,reduce,reduce,658096,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"i:; cmp r0, r1; movle r0, r1; bx lr. //===---------------------------------------------------------------------===//. Implement long long ""X-3"" with instructions that fold the immediate in. These; were disabled due to badness with the ARM carry flag on subtracts. //===---------------------------------------------------------------------===//. More load / store optimizations:; 1) Better representation for block transfer? This is from Olden/power:. 	fldd d0, [r4]; 	fstd d0, [r4, #+32]; 	fldd d0, [r4, #+8]; 	fstd d0, [r4, #+40]; 	fldd d0, [r4, #+16]; 	fstd d0, [r4, #+48]; 	fldd d0, [r4, #+24]; 	fstd d0, [r4, #+56]. If we can spare the registers, it would be better to use fldm and fstm here.; Need major register allocator enhancement though. 2) Can we recognize the relative position of constantpool entries? i.e. Treat. 	ldr r0, LCPI17_3; 	ldr r1, LCPI17_4; 	ldr r2, LCPI17_5. as; 	ldr r0, LCPI17; 	ldr r1, LCPI17+4; 	ldr r2, LCPI17+8. Then the ldr's can be combined into a single ldm. See Olden/power. Note for ARM v4 gcc uses ldmia to load a pair of 32-bit values to represent a; double 64-bit FP constant:. 	adr	r0, L6; 	ldmia	r0, {r0-r1}. 	.align 2; L6:; 	.long	-858993459; 	.long	1074318540. 3) struct copies appear to be done field by field; instead of by words, at least sometimes:. struct foo { int x; short s; char c1; char c2; };; void cpy(struct foo*a, struct foo*b) { *a = *b; }. llvm code (-O2); ldrb r3, [r1, #+6]; ldr r2, [r1]; ldrb r12, [r1, #+7]; ldrh r1, [r1, #+4]; str r2, [r0]; strh r1, [r0, #+4]; strb r3, [r0, #+6]; strb r12, [r0, #+7]; gcc code (-O2); ldmia r1, {r1-r2}; stmia r0, {r1-r2}. In this benchmark poor handling of aggregate copies has shown up as; having a large effect on size, and possibly speed as well (we don't have; a good way to measure on ARM). //===---------------------------------------------------------------------===//. * Consider this silly example:. double bar(double x) {; double r = foo(3.1);; return x+r;; }. _bar:; stmfd sp!, {r4, r5, r7, l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:3476,power,power,3476,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['power'],['power']
Energy Efficiency,"ially spilled to the call stack which is in the private; address space, and partially spilled to the local address space. DWARF mentions; address spaces, for example as an argument to the ``DW_OP_xderef*`` operations.; A new section that defines address spaces is added (see; :ref:`amdgpu-dwarf-address-spaces`). A new attribute ``DW_AT_LLVM_address_space`` is added to pointer and reference; types (see :ref:`amdgpu-dwarf-type-modifier-entries`). This allows the compiler; to specify which address space is being used to represent the pointer or; reference type. DWARF uses the concept of an address in many expression operations but does not; define how it relates to address spaces. For example,; ``DW_OP_push_object_address`` pushes the address of an object. Other contexts; implicitly push an address on the stack before evaluating an expression. For; example, the ``DW_AT_use_location`` attribute of the; ``DW_TAG_ptr_to_member_type``. The expression belongs to a source language type; which may apply to objects allocated in different kinds of storage. Therefore,; it is desirable that the expression that uses the address can do so without; regard to what kind of storage it specifies, including the address space of a; memory location description. For example, a pointer to member value may want to; be applied to an object that may reside in any address space. The DWARF ``DW_OP_xderef*`` operations allow a value to be converted into an; address of a specified address space which is then read. But it provides no; way to create a memory location description for an address in the non-default; address space. For example, AMDGPU variables can be allocated in the local; address space at a fixed address. The ``DW_OP_LLVM_form_aspace_address`` (see; :ref:`amdgpu-dwarf-memory-location-description-operations`) operation is defined; to create a memory location description from an address and address space. If; can be used to specify the location of a variable that is allocated in a; speci",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:18804,allocate,allocated,18804,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency,"ibly binned by adding GenBinned(tagname); to generate(). In that case all component pdfs labeled with pdf->setAttribute(tagname) will be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calcu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6694,reduce,reduce,6694,roofit/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html,2,['reduce'],['reduce']
Energy Efficiency,"ibute; which can be applied to a bit-field. This attribute helps to map a bit-field; back to a particular type that may be better-suited to representing the bit-; field but cannot be used for other reasons and will impact the debug; information generated for the bit-field. This is most useful when mapping a; bit-field of basic integer type back to a ``bool`` or an enumeration type,; e.g.,. .. code-block:: c++. enum E { Apple, Orange, Pear };; struct S {; [[clang::preferred_type(E)]] unsigned FruitKind : 2;; };. When viewing ``S::FruitKind`` in a debugger, it will behave as if the member; was declared as type ``E`` rather than ``unsigned``. - Clang now warns you that the ``_Alignas`` attribute on declaration specifiers; is ignored, changed from the former incorrect suggestion to move it past; declaration specifiers. (`#58637 <https://github.com/llvm/llvm-project/issues/58637>`_). - Clang now introduced ``[[clang::coro_only_destroy_when_complete]]`` attribute; to reduce the size of the destroy functions for coroutines which are known to; be destroyed after having reached the final suspend point. - Clang now introduced ``[[clang::coro_return_type]]`` and ``[[clang::coro_wrapper]]``; attributes. A function returning a type marked with ``[[clang::coro_return_type]]``; should be a coroutine. A non-coroutine function marked with ``[[clang::coro_wrapper]]``; is still allowed to return the such a type. This is helpful for analyzers to recognize coroutines from the function signatures. - Clang now supports ``[[clang::code_align(N)]]`` as an attribute which can be; applied to a loop and specifies the byte alignment for a loop. This attribute; accepts a positive integer constant initialization expression indicating the; number of bytes for the minimum alignment boundary. Its value must be a power; of 2, between 1 and 4096(inclusive). .. code-block:: c++. void Array(int *array, size_t n) {; [[clang::code_align(64)]] for (int i = 0; i < n; ++i) array[i] = 0;; }. template<int A>; v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:21280,reduce,reduce,21280,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['reduce'],['reduce']
Energy Efficiency,"ic performs the signed-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.smax <int_vector_reduce_smax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MIN`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smax.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 -128, i8 -128, i8 -128, i8 -128>; %reduction = call i8 @llvm.vector.reduce.smax.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smax.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_smin:. '``llvm.vp.reduce.smin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:764805,reduce,reduce,764805,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ic, and defines a DW_AT_address_class attribute. With the removal of; DW_AT_segment in DWARF 6, it is unclear how the address class is intended to; be used as the term is not used elsewhere. Should these be replaced by this; proposal's more complete address space? Or are they intended to represent; source language memory spaces such as in OpenCL?. .. _amdgpu-dwarf-memory-spaces:. A.2.14 Memory Spaces; ~~~~~~~~~~~~~~~~~~~~. .. note::. This is a new section after DWARF Version 5 section 2.12 Segmented Addresses. DWARF memory spaces are used for source languages that have the concept of; memory spaces. They are used in the ``DW_AT_LLVM_memory_space`` attribute for; pointer type, reference type, variable, formal parameter, and constant debugger; information entries. Each DWARF memory space is conceptually a separate source language memory space; with its own lifetime and aliasing rules. DWARF memory spaces are used to; specify the source language memory spaces that pointer type and reference type; values refer, and to specify the source language memory space in which variables; are allocated. Although DWARF memory space identifiers are source language specific,; ``DW_MSPACE_LLVM_none`` is a common memory space supported by all source; languages, and defined as the source language default memory space. The set of currently defined DWARF memory spaces, together with source language; mappings, is given in :ref:`amdgpu-dwarf-source-language-memory-spaces-table`. Vendor defined source language memory spaces may be defined using codes in the; range ``DW_MSPACE_LLVM_lo_user`` to ``DW_MSPACE_LLVM_hi_user``. .. table:: Source language memory spaces; :name: amdgpu-dwarf-source-language-memory-spaces-table. =========================== ============ ============== ============== ==============; Memory Space Name Meaning C/C++ OpenCL CUDA/HIP; =========================== ============ ============== ============== ==============; ``DW_MSPACE_LLVM_none`` generic *default* generic *defa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:150955,allocate,allocated,150955,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency,icBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngi,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338573,reduce,reduce,338573,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"ices indicating the position at which to insert the value in a; similar manner as indices in a '``extractvalue``' instruction. The value; to insert must have the same type as the value identified by the; indices. Semantics:; """""""""""""""""""". The result is an aggregate of the same type as ``val``. Its value is; that of ``val`` except that the value at the position specified by the; indices is that of ``elt``. Example:; """""""""""""""". .. code-block:: llvm. %agg1 = insertvalue {i32, float} undef, i32 1, 0 ; yields {i32 1, float undef}; %agg2 = insertvalue {i32, float} %agg1, float %val, 1 ; yields {i32 1, float %val}; %agg3 = insertvalue {i32, {float}} undef, float %val, 1, 0 ; yields {i32 undef, {float %val}}. .. _memoryops:. Memory Access and Addressing Operations; ---------------------------------------. A key design point of an SSA-based representation is how it represents; memory. In LLVM, no memory locations are in SSA form, which makes things; very simple. This section describes how to read, write, and allocate; memory in LLVM. .. _i_alloca:. '``alloca``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = alloca [inalloca] <type> [, <ty> <NumElements>] [, align <alignment>] [, addrspace(<num>)] ; yields type addrspace(num)*:result. Overview:; """""""""""""""""". The '``alloca``' instruction allocates memory on the stack frame of the; currently executing function, to be automatically released when this; function returns to its caller. If the address space is not explicitly; specified, the object is allocated in the alloca address space from the; :ref:`datalayout string<langref_datalayout>`. Arguments:; """""""""""""""""""". The '``alloca``' instruction allocates ``sizeof(<type>)*NumElements``; bytes of memory on the runtime stack, returning a pointer of the; appropriate type to the program. If ""NumElements"" is specified, it is; the number of elements allocated, otherwise ""NumElements"" is defaulted; to be one. If a constant alignment is specified, the value result of the; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:408808,allocate,allocate,408808,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocate']
Energy Efficiency,"iciently aligned, it is returned unchanged.; The builtin ``__builtin_is_aligned`` returns whether the first argument is; aligned to a multiple of the second argument.; All of these builtins expect the alignment to be expressed as a number of bytes. These builtins can be used for all integer types as well as (non-function); pointer types. For pointer types, these builtins operate in terms of the integer; address of the pointer and return a new pointer of the same type (including; qualifiers such as ``const``) with an adjusted address.; When aligning pointers up or down, the resulting value must be within the same; underlying allocation or one past the end (see C17 6.5.6p8, C++ [expr.add]).; This means that arbitrary integer values stored in pointer-type variables must; not be passed to these builtins. For those use cases, the builtins can still be; used, but the operation must be performed on the pointer cast to ``uintptr_t``. If Clang can determine that the alignment is not a power of two at compile time,; it will result in a compilation failure. If the alignment argument is not a; power of two at run time, the behavior of these builtins is undefined. Non-standard C++11 Attributes; =============================. Clang's non-standard C++11 attributes live in the ``clang`` attribute; namespace. Clang supports GCC's ``gnu`` attribute namespace. All GCC attributes which; are accepted with the ``__attribute__((foo))`` syntax are also accepted as; ``[[gnu::foo]]``. This only extends to attributes which are specified by GCC; (see the list of `GCC function attributes; <https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html>`_, `GCC variable; attributes <https://gcc.gnu.org/onlinedocs/gcc/Variable-Attributes.html>`_, and; `GCC type attributes; <https://gcc.gnu.org/onlinedocs/gcc/Type-Attributes.html>`_). As with the GCC; implementation, these attributes must appertain to the *declarator-id* in a; declaration, which means they must go either at the start of the declaratio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:153117,power,power,153117,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['power'],['power']
Energy Efficiency,"icro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a group. :program:`llvm-mca`'s scheduler internally groups instructions into three sets:. * WaitSet: a set of instructions whose operands are not ready.; * ReadySet: a set of instructions ready to execute.; * IssuedSet: a set of instru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:37206,schedul,scheduling,37206,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"ics:; """""""""""""""""""". The '``llvm.vp.reduce.mul``' intrinsic performs the integer ``MUL`` reduction; (:ref:`llvm.vector.reduce.mul <int_vector_reduce_mul>`) of the vector operand ``val``; on each enabled lane, multiplying it by the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``1`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is the; start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.mul.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 1, i32 1, i32 1, i32 1>; %reduction = call i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %masked.a); %also.r = mul i32 %reduction, %start. .. _int_vp_reduce_fmul:. '``llvm.vp.reduce.fmul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmul.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fmul.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MUL`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:754476,reduce,reduce,754476,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"id @a(i32 %x) nounwind {; entry:; switch i32 %x, label %if.end [; i32 0, label %if.then; i32 1, label %if.then; i32 2, label %if.then; i32 3, label %if.then; i32 5, label %if.then; ]; if.then:; tail call void @foo() nounwind; ret void; if.end:; ret void; }; declare void @foo(). Generated code on x86-64 (other platforms give similar results):; a:; 	cmpl	$5, %edi; 	ja	LBB2_2; 	cmpl	$4, %edi; 	jne	LBB2_3; .LBB0_2:; 	ret; .LBB0_3:; 	jmp	foo # TAILCALL. If we wanted to be really clever, we could simplify the whole thing to; something like the following, which eliminates a branch:; 	xorl $1, %edi; 	cmpl	$4, %edi; 	ja	.LBB0_2; 	ret; .LBB0_2:; 	jmp	foo # TAILCALL. //===---------------------------------------------------------------------===//. We compile this:. int foo(int a) { return (a & (~15)) / 16; }. Into:. define i32 @foo(i32 %a) nounwind readnone ssp {; entry:; %and = and i32 %a, -16; %div = sdiv i32 %and, 16; ret i32 %div; }. but this code (X & -A)/A is X >> log2(A) when A is a power of 2, so this case; should be instcombined into just ""a >> 4"". We do get this at the codegen level, so something knows about it, but ; instcombine should catch it earlier:. _foo: ## @foo; ## %bb.0: ## %entry; 	movl	%edi, %eax; 	sarl	$4, %eax; 	ret. //===---------------------------------------------------------------------===//. This code (from GCC PR28685):. int test(int a, int b) {; int lt = a < b;; int eq = a == b;; if (lt); return 1;; return eq;; }. Is compiled to:. define i32 @test(i32 %a, i32 %b) nounwind readnone ssp {; entry:; %cmp = icmp slt i32 %a, %b; br i1 %cmp, label %return, label %if.end. if.end: ; preds = %entry; %cmp5 = icmp eq i32 %a, %b; %conv6 = zext i1 %cmp5 to i32; ret i32 %conv6. return: ; preds = %entry; ret i32 1; }. it could be:. define i32 @test__(i32 %a, i32 %b) nounwind readnone ssp {; entry:; %0 = icmp sle i32 %a, %b; %retval = zext i1 %0 to i32; ret i32 %retval; }. //===---------------------------------------------------------------------===//. This code ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:52916,power,power,52916,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['power'],['power']
Energy Efficiency,"ide; enqueued kernels.; =================== ============== ========= ==============================. .. .. table:: AMDHSA Code Object V2 Kernel Argument Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-argument-metadata-map-v2-table. ================= ============== ========= ================================; String Key Value Type Required? Description; ================= ============== ========= ================================; ""Name"" string Kernel argument name.; ""TypeName"" string Kernel argument type name.; ""Size"" integer Required Kernel argument size in bytes.; ""Align"" integer Required Kernel argument alignment in; bytes. Must be a power of two.; ""ValueKind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""ByValue""; The argument is copied; directly into the kernarg. ""GlobalBuffer""; A global address space pointer; to the buffer data is passed; in the kernarg. ""DynamicSharedPointer""; A group address space pointer; to dynamically allocated LDS; is passed in the kernarg. ""Sampler""; A global address space; pointer to a S# is passed in; the kernarg. ""Image""; A global address space; pointer to a T# is passed in; the kernarg. ""Pipe""; A global address space pointer; to an OpenCL pipe is passed in; the kernarg. ""Queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""HiddenGlobalOffsetX""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""HiddenGlobalOffsetY""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""HiddenGlobalOffsetZ""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""HiddenNone""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""HiddenPrintfBuffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenHos",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:123833,allocate,allocated,123833,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"ied as; option in the URL. Â Â Â Â Â Â Â Â Â Â Â Â Â ; chain.AddFile(""root:// .....?msd=CERN""). Â and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is; Â Â Â Â Â Â Â Â Â ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to mas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5375,monitor,monitoring,5375,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,4,['monitor'],['monitoring']
Energy Efficiency,"ients; Integration with IDEs; Use the LLVM 'BSD' License. Internal Design and Implementation:. A real-world, production quality compiler; A simple and hackable code base; A single unified parser for C, Objective C, C++,; and Objective C++; Conformance with C/C++/ObjC and their; variants. End-User Features. Fast compiles and Low Memory Use. A major focus of our work on clang is to make it fast, light and scalable.; The library-based architecture of clang makes it straight-forward to time and; profile the cost of each layer of the stack, and the driver has a number of; options for performance analysis. Many detailed benchmarks can be found online.; Compile time performance is important, but when using clang as an API, often; memory use is even more so: the less memory the code takes the more code you can; fit into memory at a time (useful for whole program analysis tools, for; example).; In addition to being efficient when pitted head-to-head against GCC in batch; mode, clang is built with a library based; architecture that makes it relatively easy to adapt it and build new tools; with it. This means that it is often possible to apply out-of-the-box thinking; and novel techniques to improve compilation in various ways. Expressive Diagnostics. In addition to being fast and functional, we aim to make Clang extremely user; friendly. As far as a command-line compiler goes, this basically boils down to; making the diagnostics (error and warning messages) generated by the compiler; be as useful as possible. There are several ways that we do this, but the; most important are pinpointing exactly what is wrong in the program,; highlighting related information so that it is easy to understand at a glance,; and making the wording as clear as possible.; Here is one simple example that illustrates the quality of Clang diagnostic:. $ clang -fsyntax-only t.c; t.c:7:39: error: invalid operands to binary expression ('int' and 'struct A'); return y + func(y ? ((SomeA.X + 40) + SomeA) / ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html:1293,efficient,efficient,1293,interpreter/llvm-project/clang/www/features.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html,4,"['adapt', 'efficient']","['adapt', 'efficient']"
Energy Efficiency,"iers. (`#58637 <https://github.com/llvm/llvm-project/issues/58637>`_). - Clang now introduced ``[[clang::coro_only_destroy_when_complete]]`` attribute; to reduce the size of the destroy functions for coroutines which are known to; be destroyed after having reached the final suspend point. - Clang now introduced ``[[clang::coro_return_type]]`` and ``[[clang::coro_wrapper]]``; attributes. A function returning a type marked with ``[[clang::coro_return_type]]``; should be a coroutine. A non-coroutine function marked with ``[[clang::coro_wrapper]]``; is still allowed to return the such a type. This is helpful for analyzers to recognize coroutines from the function signatures. - Clang now supports ``[[clang::code_align(N)]]`` as an attribute which can be; applied to a loop and specifies the byte alignment for a loop. This attribute; accepts a positive integer constant initialization expression indicating the; number of bytes for the minimum alignment boundary. Its value must be a power; of 2, between 1 and 4096(inclusive). .. code-block:: c++. void Array(int *array, size_t n) {; [[clang::code_align(64)]] for (int i = 0; i < n; ++i) array[i] = 0;; }. template<int A>; void func() {; [[clang::code_align(A)]] for(;;) { }; }. - Clang now introduced ``[[clang::coro_lifetimebound]]`` attribute.; All parameters of a function are considered to be lifetime bound if the function; returns a type annotated with ``[[clang::coro_lifetimebound]]`` and ``[[clang::coro_return_type]]``.; This analysis can be disabled for a function by annotating the function with ``[[clang::coro_disable_lifetimebound]]``. Improvements to Clang's diagnostics; -----------------------------------; - Clang constexpr evaluator now prints template arguments when displaying; template-specialization function calls.; - Clang contexpr evaluator now displays notes as well as an error when a constructor; of a base class is not called in the constructor of its derived class.; - Clang no longer emits ``-Wmissing-variable",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:22114,power,power,22114,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['power'],['power']
Energy Efficiency,"ies on the DWARF; expression stack. They can only be the final result of the evaluation of a DWARF; expression. However, by allowing a location description to be a first-class; entry on the DWARF expression stack it becomes possible to compose expressions; containing both values and location descriptions naturally. It allows objects to; be located in any kind of memory address space, in registers, be implicit; values, be undefined, or a composite of any of these. By extending DWARF carefully, all existing DWARF expressions can retain their; current semantic meaning. DWARF has implicit conversions that convert from a; value that represents an address in the default address space to a memory; location description. This can be extended to allow a default address space; memory location description to be implicitly converted back to its address; value. This allows all DWARF Version 5 expressions to retain their same meaning,; while enabling the ability to explicitly create memory location descriptions in; non-default address spaces and generalizing the power of composite location; descriptions to any kind of location description. For those familiar with the definition of location descriptions in DWARF Version; 5, the definitions in these extensions are presented differently, but does in; fact define the same concept with the same fundamental semantics. However, it; does so in a way that allows the concept to extend to support address spaces,; bit addressing, the ability for composite location descriptions to be composed; of any kind of location description, and the ability to support objects located; at multiple places. Collectively these changes expand the set of architectures; that can be supported and improves support for optimized code. Several approaches were considered, and the one presented, together with the; extensions it enables, appears to be the simplest and cleanest one that offers; the greatest improvement of DWARF's ability to support debugging optimized GP",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:6225,power,power,6225,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['power'],['power']
Energy Efficiency,"if something goes wrong though, how do you debug your; program?. Source level debugging uses formatted data that helps a debugger; translate from binary and the state of the machine back to the; source that the programmer wrote. In LLVM we generally use a format; called `DWARF <http://dwarfstd.org>`_. DWARF is a compact encoding; that represents types, source locations, and variable locations. The short summary of this chapter is that we'll go through the; various things you have to add to a programming language to; support debug info, and how you translate that into DWARF. Caveat: For now we can't debug via the JIT, so we'll need to compile; our program down to something small and standalone. As part of this; we'll make a few modifications to the running of the language and; how programs are compiled. This means that we'll have a source file; with a simple program written in Kaleidoscope rather than the; interactive JIT. It does involve a limitation that we can only; have one ""top level"" command at a time to reduce the number of; changes necessary. Here's the sample program we'll be compiling:. .. code-block:: python. def fib(x); if x < 3 then; 1; else; fib(x-1)+fib(x-2);. fib(10). Why is this a hard problem?; ===========================. Debug information is a hard problem for a few different reasons - mostly; centered around optimized code. First, optimization makes keeping source; locations more difficult. In LLVM IR we keep the original source location; for each IR level instruction on the instruction. Optimization passes; should keep the source locations for newly created instructions, but merged; instructions only get to keep a single location - this can cause jumping; around when stepping through optimized programs. Secondly, optimization; can move variables in ways that are either optimized out, shared in memory; with other variables, or difficult to track. For the purposes of this; tutorial we're going to avoid optimization (as you'll see with one of the; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst:1427,reduce,reduce,1427,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,1,['reduce'],['reduce']
Energy Efficiency,"ifier outputs (signal and background). IgnoreNegWeightsInTraining No False âˆ’ Events with negative weights are ignored in the training (but are included for testing and performance evaluation). NCycles No 200 âˆ’ Number of training cycles. HiddenLayers No N,N-1 âˆ’ Specification of hidden layer architecture (N stands for number of variables; any integers may also be used). ValidationFraction No 0.5 âˆ’ Fraction of events in training tree used for cross validation. LearningMethod No Stochastic Stochastic, Batch, SteepestDescent, RibierePolak, FletcherReeves, BFGS Learning method. Configuration options for setup and tuning of specific fitter :. Configuration options reference for fitting method: Simulated Annealing (SA). Option Array Default value Predefined values Description. MaxCalls No 100000 âˆ’ Maximum number of minimisation calls. InitialTemp No 1e+06 âˆ’ Initial temperature. MinTemp No 1e-06 âˆ’ Mimimum temperature. Eps No 1e-10 âˆ’ Epsilon. TempScale No 1 âˆ’ Temperature scale. AdaptiveSpeed No 1 âˆ’ Adaptive speed. TempAdaptiveStep No 0.009875 âˆ’ Step made in each generation temperature adaptive. UseDefaultScale No False âˆ’ Use default temperature scale for temperature minimisation algorithm. UseDefaultTemp No False âˆ’ Use default initial temperature. KernelTemp No IncAdaptive IncAdaptive, DecAdaptive, Sqrt, Log, Sin, Homo, Geo Temperature minimisation algorithm. Configuration options for setup and tuning of specific fitter :. Configuration options reference for fitting method: Monte Carlo sampling (MC). Option Array Default value Predefined values Description. SampleSize No 100000 âˆ’ Number of Monte Carlo events in toy sample. Sigma No -1 âˆ’ If > 0: new points are generated according to Gauss around best value and with Sigma in units of interval length. Seed No 100 âˆ’ Seed for the random generator (0 takes random seeds). Configuration options for setup and tuning of specific fitter :. Configuration options reference for fitting method: TMinuit (MT). Option Array Default value Predef",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:29510,Adapt,AdaptiveSpeed,29510,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['Adapt'],"['Adaptive', 'AdaptiveSpeed']"
Energy Efficiency,"igned-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.umin <int_vector_reduce_umin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umin.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umin.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_fmax:. '``llvm.vp.reduce.fmax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmax.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmax.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explici",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:771020,reduce,reduce,771020,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ild the plugin, and then call clang with the plugin from the; source tree:. .. code-block:: console. $ export BD=/path/to/build/directory; $ (cd $BD && make PrintFunctionNames ); $ clang++ -D_GNU_SOURCE -D_DEBUG -D__STDC_CONSTANT_MACROS \; -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS -D_GNU_SOURCE \; -I$BD/tools/clang/include -Itools/clang/include -I$BD/include -Iinclude \; tools/clang/tools/clang-check/ClangCheck.cpp -fsyntax-only \; -Xclang -load -Xclang $BD/lib/PrintFunctionNames.so -Xclang \; -plugin -Xclang print-fns. Also see the print-function-name plugin example's; `README <https://github.com/llvm/llvm-project/blob/main/clang/examples/PrintFunctionNames/README.txt>`_. Using the clang command line; ----------------------------. Using `-fplugin=plugin` on the clang command line passes the plugin; through as an argument to `-load` on the cc1 command line. If the plugin; class implements the ``getActionType`` method then the plugin is run; automatically. For example, to run the plugin automatically after the main AST; action (i.e. the same as using `-add-plugin`):. .. code-block:: c++. // Automatically run the plugin after the main AST action; PluginASTAction::ActionType getActionType() override {; return AddAfterMainAction;; }. Interaction with ``-clear-ast-before-backend``; ----------------------------------------------. To reduce peak memory usage of the compiler, plugins are recommended to run; *before* the main action, which is usually code generation. This is because; having any plugins that run after the codegen action automatically turns off; ``-clear-ast-before-backend``. ``-clear-ast-before-backend`` reduces peak; memory by clearing the Clang AST after generating IR and before running IR; optimizations. Use ``CmdlineBeforeMainAction`` or ``AddBeforeMainAction`` as; ``getActionType`` to run plugins while still benefitting from; ``-clear-ast-before-backend``. Plugins must make sure not to modify the AST,; otherwise they should run after the main action. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst:7338,reduce,reduce,7338,interpreter/llvm-project/clang/docs/ClangPlugins.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst,2,['reduce'],"['reduce', 'reduces']"
Energy Efficiency,"ile f(""tree2.root"",""recreate"");. //create the file, the Tree; TTree t2(""t2"",""a Tree with data from a fake Geant3"");; // declare a variable of the C structure type; Gctrak_t gstep;. // add the branches for a subset of gstep; t2.Branch(""vect"",gstep.vect,""vect[7]/F"");; t2.Branch(""getot"",&gstep.getot,""getot/F"");; t2.Branch(""gekin"",&gstep.gekin,""gekin/F"");; t2.Branch(""nmec"",&gstep.nmec,""nmec/I"");; t2.Branch(""lmec"",gstep.lmec,""lmec[nmec]/I"");; t2.Branch(""destep"",&gstep.destep,""destep/F"");; t2.Branch(""pid"",&gstep.pid,""pid/I"");. //Initialize particle parameters at first point; Float_t px,py,pz,p,charge=0;; Float_t vout[7];; Float_t mass = 0.137;; Bool_t newParticle = kTRUE;; gstep.step = 0.1;; gstep.destep = 0;; gstep.nmec = 0;; gstep.pid = 0;. //transport particles; for (Int_t i=0; i<10000; i++) {; //generate a new particle if necessary (Geant3 emulation); if (newParticle) {; px = gRandom->Gaus(0,.02);; py = gRandom->Gaus(0,.02);; pz = gRandom->Gaus(0,.02);; p = TMath::Sqrt(px*px+py*py+pz*pz);; charge = 1;; if (gRandom->Rndm() < 0.5) charge = -1;; gstep.pid += 1;; gstep.vect[0] = 0;; gstep.vect[1] = 0;; gstep.vect[2] = 0;; gstep.vect[3] = px/p;; gstep.vect[4] = py/p;; gstep.vect[5] = pz/p;; gstep.vect[6] = p*charge;; gstep.getot = TMath::Sqrt(p*p + mass*mass);; gstep.gekin = gstep.getot - mass;; newParticle = kFALSE;; }; // fill the Tree with current step parameters; t2.Fill();. //transport particle in magnetic field (Geant3 emulation); helixStep(gstep.step, gstep.vect, vout);; //make one step; //apply energy loss; gstep.destep = gstep.step*gRandom->Gaus(0.0002,0.00001);; gstep.gekin -= gstep.destep;; gstep.getot = gstep.gekin + mass;; gstep.vect[6]= charge*TMath::Sqrt(gstep.getot*gstep.getot; - mass*mass);; gstep.vect[0] = vout[0];; gstep.vect[1] = vout[1];; gstep.vect[2] = vout[2];; gstep.vect[3] = vout[3];; gstep.vect[4] = vout[4];; gstep.vect[5] = vout[5];; gstep.nmec = (Int_t)(5*gRandom->Rndm());; for (Int_t l=0; l<gstep.nmec; l++) gstep.lmec[l] = l;; if (gstep.gekin ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:46546,charge,charge,46546,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['charge'],['charge']
Energy Efficiency,"ile.; The fields are documented as follows:. .. _`__llvm_profile_data`: https://github.com/llvm/llvm-project/blob/7c3b67d2038cfb48a80299089f6a1308eee1df7f/compiler-rt/include/profile/InstrProfData.inc#L65-L95. ``NameRef``; The MD5 of the function's PGO name. PGO name has the format; ``[<filepath><delimiter>]<mangled-name>`` where ``<filepath>`` and; ``<delimiter>`` are provided for local-linkage functions to tell possibly; identical functions. .. _FuncHash:. ``FuncHash``; A checksum of the function's IR, taking control flow graph and instrumented; value sites into accounts. See `computeCFGHash`_ for details. .. _`computeCFGHash`: https://github.com/llvm/llvm-project/blob/7c3b67d2038cfb48a80299089f6a1308eee1df7f/llvm/lib/Transforms/Instrumentation/PGOInstrumentation.cpp#L616-L685. .. _`CounterPtr`:. ``CounterPtr``; The in-memory address difference between profile data and the start of corresponding; counters. Counter position is stored this way (as a link-time constant) to reduce; instrumented binary size compared with snapshotting the address of symbols directly.; See `commit a1532ed`_ for further information. .. _`commit a1532ed`: https://github.com/llvm/llvm-project/commit/a1532ed27582038e2d9588108ba0fe8237f01844. .. note::; ``CounterPtr`` might represent a different value for non-IRPGO use case. For; example, for `binary profile correlation`_, it represents the absolute address of counter.; When in doubt, check source code. .. _`BitmapPtr`:. ``BitmapPtr``; The in-memory address difference between profile data and the start address of; corresponding bitmap. .. note::; Similar to `CounterPtr`_, this field may represent a different value for non-IRPGO use case. ``FunctionPointer``; Records the function address when instrumented binary runs. This is used to; map the profiled callee address of indirect calls to the ``NameRef`` during; conversion from raw to indexed profiles. ``Values``; Represents value profiles in a two dimensional array. The number of elements; in t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst:7432,reduce,reduce,7432,interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,1,['reduce'],['reduce']
Energy Efficiency,"iled use:. ``` {.cpp}; root[] TThread *th = new TThread(""MyThread"", UserFun, UserArgs);; ```. You can pass arguments to the thread function using the; `UserArgs`-pointer. When you want to start a method of a class as a; thread, you have to give the pointer to the class instance as; `UserArgs`. 5. Running. ``` {.cpp}; root[] th->Run();; root[] TThread::Ps(); // like UNIX ps c.ommand;; ```. With the `mhs3` example, you should be able to see a canvas with two; pads on it. Both pads keep histograms updated and filled by three; different threads. With the `CalcPi` example, you should be able to see; two threads calculating Pi with the given number of intervals as; precision. ### TThread in More Details. Cling is not thread safe yet, and it will block the execution of the; threads until it has finished executing. #### Asynchronous Actions. Different threads can work simultaneously with the same object. Some; actions can be dangerous. For example, when two threads create a; histogram object, ROOT allocates memory and puts them to the same; collection. If it happens at the same time, the results are; undetermined. To avoid this problem, the user has to synchronize these; actions with:. ``` {.cpp}; TThread::Lock() // Locking the following part of code; ... // Create an object, etc...; TThread::UnLock() // Unlocking; ```. The code between `Lock()` and `UnLock()` will be performed; uninterrupted. No other threads can perform actions or access; objects/collections while it is being executed. The methods; `TThread::Lock() `and **`TThread::UnLock()`** internally use a global; `TMutex` instance for locking. The user may also define their own **`TMutex`** `MyMutex` instance and may; locally protect their asynchronous actions by calling `MyMutex.Lock()` and; `MyMutex.UnLock().`. #### Synchronous Actions: TCondition. To synchronize the actions of different threads you can use the; **`TCondition`** class, which provides a signaling mechanism. The; **`TCondition`** instance must be acce",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:6692,allocate,allocates,6692,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['allocate'],['allocates']
Energy Efficiency,"iler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1800,reduce,reduce,1800,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['reduce'],['reduce']
Energy Efficiency,"iles for reading.; There is button __""...""__ on the main JSROOT page, which starts file selection dialog.; If valid ROOT file is selected, JSROOT will be able to normally read content of such file. ## JSROOT with THttpServer. THttpServer provides http access to objects from running ROOT application.; JSROOT is used to implement the user interface in the web browsers. The layout of the main page coming from THttpServer is very similar to normal JSROOT page.; One could browse existing items and display them. A snapshot of running; server can be seen on the [demo page](https://root.cern/js/latest/httpserver.C/). One could also specify similar URL parameters to configure the displayed items and drawing options. It is also possible to display one single item from the THttpServer server like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hpxpy/draw.htm?opt=colz>. ## Data monitoring with JSROOT. ### Monitoring with http server. The best possibility to organize the monitoring of data from a running application; is to use THttpServer. In such case the client can always access the latest; changes and request only the items currently displayed in the browser.; To enable monitoring, one should activate the appropriate checkbox or; provide __monitoring__ parameter in the URL string like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hprof/draw.htm?monitoring=1000>. The parameter value is the update interval in milliseconds. ### JSON file-based monitoring. Solid file-based monitoring (without integration of THttpServer into application) can be; implemented in JSON format. There is the [TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class,; which is capable to convert any (beside TTree) ROOT object into JSON. Any ROOT application can use such class to; create JSON files for selected objects and write such files in a directory,; which can be accessed via web server. Then one can use JSROOT to read such files and display objects in a web br",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:30531,monitor,monitoring,30531,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency,"iles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:5411,reduce,reduce,5411,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['reduce'],['reduce']
Energy Efficiency,"imator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking.; Could be a viable option if cluster compression ratios turn out to change significantly in a single file. - Calculate the cluster compression ratio from column-based individual estimators.; More complex to implement and to recalculate the estimator on every fill,; requires additional state for every column.; One might reduce the additional state and complexity by only applying the fine-grained estimator for collections.; Such an estimator would react better to a sudden change in the amount of data written for collections / columns; that have substentially different compression ratios. Page Checksums; --------------. By default, RNTuple appends xxhash-3 64bit checksums to every compressed page.; Typically, checksums increase the data size in the region of a per mille.; As a side effect, page checksums allow for efficient ""same page merging"":; identical pages in the same cluster will be written only once.; On typical datasets, same page merging saves a few percent.; Conversely, turning off page checksums also disables the same page merging optimization.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:4460,reduce,reduce,4460,tree/ntuple/v7/doc/tuning.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md,2,"['efficient', 'reduce']","['efficient', 'reduce']"
Energy Efficiency,"ime optimizations (LTO) are applied); #. a.out.0.2.internalize.bc (After initial optimizations are applied); #. a.out.0.4.opt.bc (After an extensive set of optimizations); #. a.out.0.5.precodegen.bc (After LTO but before translating into machine code). Execute one of the following commands to identify the source of the problem:. #. ``opt ""-passes=lto<O3>"" a.out.0.2.internalize.bc``; #. ``llc a.out.0.5.precodegen.bc``. If one of these do crash, you should be able to reduce; this with :program:`llvm-reduce`; command line (use the bc file corresponding to the command above that failed):. .. code-block:: bash. llvm-reduce --test reduce.sh a.out.0.2.internalize.bc. Example of reduce.sh script. .. code-block:: bash. $ cat reduce.sh; #!/bin/bash -e. path/to/not --crash path/to/opt ""-passes=lto<O3>"" $1 -o temp.bc 2> err.log; grep -q ""It->second == &Insn"" err.log. Here we have grepped the failed assert message. Please run this, then file a bug with the instructions and reduced .bc file; that llvm-reduce emits. .. _miscompiling:. Miscompilations; ===============. If clang successfully produces an executable, but that executable doesn't run; right, this is either a bug in the code or a bug in the compiler. The first; thing to check is to make sure it is not using undefined behavior (e.g.; reading a variable before it is defined). In particular, check to see if the; program is clean under various `sanitizers; <https://github.com/google/sanitizers>`_ (e.g. ``clang; -fsanitize=undefined,address``) and `valgrind <http://valgrind.org/>`_. Many; ""LLVM bugs"" that we have chased down ended up being bugs in the program being; compiled, not LLVM. Once you determine that the program itself is not buggy, you should choose; which code generator you wish to compile the program with (e.g. LLC or the JIT); and optionally a series of LLVM passes to run. For example:. .. code-block:: bash. bugpoint -run-llc [... optzn passes ...] file-to-test.bc --args -- [program arguments]. bugpoint will try ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:7910,reduce,reduce,7910,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduce']
Energy Efficiency,"imestamp``' intrinsic is used to implement temporal; profiling. Arguments:; """"""""""""""""""""; The arguments are the same as '``llvm.instrprof.increment``'. The ``index`` is; expected to always be zero. Semantics:; """"""""""""""""""""; Similar to the '``llvm.instrprof.increment``' intrinsic, but it stores a; timestamp representing when this function was executed for the first time. '``llvm.instrprof.cover``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.instrprof.cover(ptr <name>, i64 <hash>,; i32 <num-counters>, i32 <index>). Overview:; """""""""""""""""". The '``llvm.instrprof.cover``' intrinsic is used to implement coverage; instrumentation. Arguments:; """"""""""""""""""""; The arguments are the same as the first four arguments of; '``llvm.instrprof.increment``'. Semantics:; """"""""""""""""""""; Similar to the '``llvm.instrprof.increment``' intrinsic, but it stores zero to; the profiling variable to signify that the function has been covered. We store; zero because this is more efficient on some targets. '``llvm.instrprof.value.profile``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.instrprof.value.profile(ptr <name>, i64 <hash>,; i64 <value>, i32 <value_kind>,; i32 <index>). Overview:; """""""""""""""""". The '``llvm.instrprof.value.profile``' intrinsic can be emitted by a; frontend for use with instrumentation based profiling. This will be; lowered by the ``-instrprof`` pass to find out the target values,; instrumented expressions take in a program at runtime. Arguments:; """""""""""""""""""". The first argument is a pointer to a global variable containing the; name of the entity being instrumented. ``name`` should generally be the; (mangled) function name for a set of counters. The second argument is a hash value that can be used by the consumer; of the profile data to detect changes to the instrumented source. It; is an error if ``hash`` differs between two instances of; ``llvm.instrprof.*`` that refer to the sam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:530224,efficient,efficient,530224,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency,"improved. Now it supports sending RDataFrame tasks to a [Dask](https://dask.org/) scheduler. Through Dask, RDataFrame can be also scaled to a cluster of machines managed through a batch system like HTCondor or Slurm. Here is an example:. ```python; import ROOT; from dask.distributed import Client; RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame. # In a Python script the Dask client needs to be initalized in a context; # Jupyter notebooks / Python session don't need this; if __name__ == ""__main__"":; client = Client(""SCHEDULER_ADDRESS""); df = RDataFrame(""mytree"",""myfile.root"", daskclient=client); # Proceed as usual; df.Define(""x"",""someoperation"").Histo1D(""x""); ```. Other notable additions and improvements include:. - Enable triggering multiple distributed computation graphs through `RunGraphs`. This also allows sending both Spark and Dask jobs at the same time through a single function call.; - Greatly reduce distributed tasks processing overhead in TTree-based analyses by refactoring the translation from task metadata to RDataFrame object on the workers.; - Refactor triggering of the computation graph in the distributed tasks, so that it now runs with the Python GIL released. This allows interoperability with frameworks like Dask that run different Python threads along the main processing one.; - Set minimum Python version to use this tool to 3.7. This allows using more modern Python functionality in distributed RDataFrame code and is in line with the Python support provided by Spark and Dask.; - Add support for the following operations:; - `DefinePerSample`; - `HistoND`; - `Redefine`; - Make sure a user-provided `npartitions` parameter to a distributed RDataFrame constructor always takes precedence over the value computed by default.; - Improve support for friend trees in distributed executions, now any kind of friendship layout between the main tree and the friend tree(s) is expected to work.; - Add support for TChain data sources with no tree name an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:11255,reduce,reduce,11255,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['reduce'],['reduce']
Energy Efficiency,"imulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:36231,schedul,scheduling,36231,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"in TPaletteAxis drawing - draw label, avoid too large ticks.; 3. Fix error with col drawing - bin with maximum value got wrong color; 4. Test for existing jquery.js, jquery-ui.js and d3.js libraries, reuse when provided; 5. Fix several I/O problems; now one could read files, produced in Geant4; 6. Implement 'e2' drawing option for TH1 class,; use by default 'e' option when TH1 has non-empty fSumw2; 7. Reuse statistic from histogram itself, when no axis selection done; 8. Support log/lin z scale for color drawing; 9. Implement interactive z-scale selection on TPaletteAxis; 10. Allow to redraw item with other draw options (before one should clear drawings); 11. Several improvements in THttpServer user interface - repair hierarchy reload,; hide unsupported context menu entries, status line update. ## Changes in 3.4; 1. Support usage of minimized versions of .js and .css files.; Minimized scripts used by default on web servers.; 2. Implement JSROOT.extend instead of jQuery.extend, reduce; usage of jquery.js in core JSROOT classes; 3. Implement main graphics without jquery at all,; such mode used in `nobrowser` mode.; 4. Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; 5. Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE; 6. Fix error with time axes - time offset was not correctly interpreted. ## Changes in 3.3; 1. Use d3.time.scale for display of time scales; 2. Within JSRootCore.js script URL one could specify JSROOT; functionality to be loaded: '2d', '3d', 'io', 'load', 'onload'.; Old method with JSROOT.AssertPrerequisites will also work.; 3. With THttpServer JSROOT now provides simple control functionality.; One could publish commands and execute them from the browser; 4. One could open several ROOT files simultaneously; 5. Add 'simple' layout - drawing uses full space on the right side; 6. Allow to open ROOT files in o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:66453,reduce,reduce,66453,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['reduce'],['reduce']
Energy Efficiency,"inal pointer. Note again, however, that; dependence does not survive a store, so ARC does not guarantee the; continued validity of the return value past the end of the; full-expression. .. _arc.optimization.object_lifetime:. No object lifetime extension; ----------------------------. If, in the formal computation history of the program, an object ``X``; has been deallocated by the time of an observable side-effect, then; ARC must cause ``X`` to be deallocated by no later than the occurrence; of that side-effect, except as influenced by the re-ordering of the; destruction of objects. .. admonition:: Rationale. This rule is intended to prohibit ARC from observably extending the; lifetime of a retainable object, other than as specified in this; document. Together with the rule limiting the transformation of; releases, this rule requires ARC to eliminate retains and release; only in pairs. ARC's power to reorder the destruction of objects is critical to its; ability to do any optimization, for essentially the same reason that; it must retain the power to decrease the lifetime of an object.; Unfortunately, while it's generally poor style for the destruction; of objects to have arbitrary side-effects, it's certainly possible.; Hence the caveat. .. _arc.optimization.precise:. Precise lifetime semantics; --------------------------. In general, ARC maintains an invariant that a retainable object pointer held in; a ``__strong`` object will be retained for the full formal lifetime of the; object. Objects subject to this invariant have :arc-term:`precise lifetime; semantics`. By default, local variables of automatic storage duration do not have precise; lifetime semantics. Such objects are simply strong references which hold; values of retainable object pointer type, and these values are still fully; subject to the optimizations on values under local control. .. admonition:: Rationale. Applying these precise-lifetime semantics strictly would be prohibitive.; Many useful optimiz",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:83108,power,power,83108,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,2,['power'],['power']
Energy Efficiency,include_directories(; ${LLVM_MAIN_SRC_DIR}/lib/Target/PowerPC; ${LLVM_BINARY_DIR}/lib/Target/PowerPC; ). set(LLVM_LINK_COMPONENTS; CodeGenTypes; Core; Exegesis; MC; PowerPC; Support; TargetParser; ). add_llvm_library(LLVMExegesisPowerPC; DISABLE_LLVM_LINK_LLVM_DYLIB; STATIC; Target.cpp. DEPENDS; intrinsics_gen; PowerPCCommonTableGen; ); ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/PowerPC/CMakeLists.txt:54,Power,PowerPC,54,interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/PowerPC/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/lib/PowerPC/CMakeLists.txt,4,['Power'],"['PowerPC', 'PowerPCCommonTableGen']"
Energy Efficiency,include_directories(include). set(LLVM_LINK_COMPONENTS; AllTargetsAsmParsers; AllTargetsMCAs # CustomBehaviour and InstrPostProcess; AllTargetsDescs; AllTargetsDisassemblers; AllTargetsInfos; MCA; MC; MCParser; Support; TargetParser; ). add_llvm_tool(llvm-mca; llvm-mca.cpp; CodeRegion.cpp; CodeRegionGenerator.cpp; PipelinePrinter.cpp; Views/BottleneckAnalysis.cpp; Views/DispatchStatistics.cpp; Views/InstructionInfoView.cpp; Views/InstructionView.cpp; Views/RegisterFileStatistics.cpp; Views/ResourcePressureView.cpp; Views/RetireControlUnitStatistics.cpp; Views/SchedulerStatistics.cpp; Views/SummaryView.cpp; Views/TimelineView.cpp; ). set(LLVM_MCA_SOURCE_DIR ${CURRENT_SOURCE_DIR}); ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/CMakeLists.txt:566,Schedul,SchedulerStatistics,566,interpreter/llvm-project/llvm/tools/llvm-mca/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/CMakeLists.txt,1,['Schedul'],['SchedulerStatistics']
Energy Efficiency,"indirection; operator is the pointee type of the subexpression. In order to determine the; type, we need to get the instance of ``PointerType`` that best captures the; typedef information in the program. If the type of the expression is literally; a ``PointerType``, we can return that, otherwise we have to dig through the; typedefs to find the pointer type. For example, if the subexpression had type; ""``foo*``"", we could return that type as the result. If the subexpression had; type ""``bar``"", we want to return ""``foo*``"" (note that we do *not* want; ""``int*``""). In order to provide all of this, ``Type`` has a; ``getAsPointerType()`` method that checks whether the type is structurally a; ``PointerType`` and, if so, returns the best one. If not, it returns a null; pointer. This structure is somewhat mystical, but after meditating on it, it will make; sense to you :). .. _QualType:. The ``QualType`` class; ----------------------. The ``QualType`` class is designed as a trivial value class that is small,; passed by-value and is efficient to query. The idea of ``QualType`` is that it; stores the type qualifiers (``const``, ``volatile``, ``restrict``, plus some; extended qualifiers required by language extensions) separately from the types; themselves. ``QualType`` is conceptually a pair of ""``Type*``"" and the bits; for these type qualifiers. By storing the type qualifiers as bits in the conceptual pair, it is extremely; efficient to get the set of qualifiers on a ``QualType`` (just return the field; of the pair), add a type qualifier (which is a trivial constant-time operation; that sets a bit), and remove one or more type qualifiers (just return a; ``QualType`` with the bitfield set to empty). Further, because the bits are stored outside of the type itself, we do not need; to create duplicates of types with different sets of qualifiers (i.e. there is; only a single heap allocated ""``int``"" type: ""``const int``"" and ""``volatile; const int``"" both point to the same heap a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:66610,efficient,efficient,66610,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"ine info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; ----------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6152,reduce,reduced,6152,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['reduce'],['reduced']
Energy Efficiency,"ing a single; DWARF operation that combines all lanes of the vector in one step. The DWARF; expression is more compact, and can be evaluated by a consumer far more; efficiently. An example that uses these operations is referenced in the; :ref:`amdgpu-dwarf-further-examples` appendix. See ``DW_OP_LLVM_select_bit_piece`` and ``DW_OP_LLVM_extend`` in; :ref:`amdgpu-dwarf-composite-location-description-operations`. 2.11 DWARF Operation to Access Call Frame Entry Registers; ---------------------------------------------------------. As described in; :ref:`amdgpu-dwarf-operation-to-create-vector-composite-location-descriptions`,; a DWARF expression involving the set of SIMT lanes active on entry to a; subprogram is required. The SIMT active lane mask may be held in a register that; is modified as the subprogram executes. However, its value may be saved on entry; to the subprogram. The Call Frame Information (CFI) already encodes such register saving, so it is; more efficient to provide an operation to return the location of a saved; register than have to generate a loclist to describe the same information. This; is now possible since; :ref:`amdgpu-dwarf-allow-location-description-on-the-dwarf-evaluation-stack`; allows location descriptions on the stack. See ``DW_OP_LLVM_call_frame_entry_reg`` in; :ref:`amdgpu-dwarf-general-location-description-operations` and; :ref:`amdgpu-dwarf-call-frame-information`. 2.12 Support for Source Languages Mapped to SIMT Hardware; ---------------------------------------------------------. If the source language is mapped onto the AMDGPU wavefronts in a SIMT manner,; then the variable DWARF location expressions must compute the location for a; single lane of the wavefront. Therefore, a DWARF operation is required to denote; the current lane, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_lane`` in :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:27438,efficient,efficient,27438,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['efficient'],['efficient']
Energy Efficiency,"ing at the body of the loop that the; container isn't being modified, which makes it easier to read the code and; understand what it does. While the second form of the loop is a few extra keystrokes, we do strongly; prefer it. ``#include <iostream>`` is Forbidden; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The use of ``#include <iostream>`` in library files is hereby **forbidden**,; because many common implementations transparently inject a `static constructor`_; into every translation unit that includes it. Note that using the other stream headers (``<sstream>`` for example) is not; problematic in this regard --- just ``<iostream>``. However, ``raw_ostream``; provides various APIs that are better performing for almost every use than; ``std::ostream`` style APIs. .. note::. New code should always use `raw_ostream`_ for writing, or the; ``llvm::MemoryBuffer`` API for reading files. .. _raw_ostream:. Use ``raw_ostream``; ^^^^^^^^^^^^^^^^^^^. LLVM includes a lightweight, simple, and efficient stream implementation in; ``llvm/Support/raw_ostream.h``, which provides all of the common features of; ``std::ostream``. All new code should use ``raw_ostream`` instead of; ``ostream``. Unlike ``std::ostream``, ``raw_ostream`` is not a template and can be forward; declared as ``class raw_ostream``. Public headers should generally not include; the ``raw_ostream`` header, but use forward declarations and constant references; to ``raw_ostream`` instances. Avoid ``std::endl``; ^^^^^^^^^^^^^^^^^^^. The ``std::endl`` modifier, when used with ``iostreams`` outputs a newline to; the output stream specified. In addition to doing this, however, it also; flushes the output stream. In other words, these are equivalent:. .. code-block:: c++. std::cout << std::endl;; std::cout << '\n' << std::flush;. Most of the time, you probably have no reason to flush the output stream, so; it's better to use a literal ``'\n'``. Don't use ``inline`` when defining a function in a class definition; ^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:55722,efficient,efficient,55722,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['efficient'],['efficient']
Energy Efficiency,"ing explicit namespace prefixes; makes the code **clearer**, because it is immediately obvious what facilities; are being used and where they are coming from. And **more portable**, because; namespace clashes cannot occur between LLVM code and other namespaces. The; portability rule is important because different standard library implementations; expose different symbols (potentially ones they shouldn't), and future revisions; to the C++ standard will add more symbols to the ``std`` namespace. As such, we; never use ``'using namespace std;'`` in LLVM. The exception to the general rule (i.e. it's not an exception for the ``std``; namespace) is for implementation files. For example, all of the code in the; LLVM project implements code that lives in the 'llvm' namespace. As such, it is; ok, and actually clearer, for the ``.cpp`` files to have a ``'using namespace; llvm;'`` directive at the top, after the ``#include``\s. This reduces; indentation in the body of the file for source editors that indent based on; braces, and keeps the conceptual context cleaner. The general form of this rule; is that any ``.cpp`` file that implements code in any namespace may use that; namespace (and its parents'), but should not use any others. Provide a Virtual Method Anchor for Classes in Headers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If a class is defined in a header file and has a vtable (either it has virtual; methods or it derives from classes with virtual methods), it must always have at; least one out-of-line virtual method in the class. Without this, the compiler; will copy the vtable and RTTI into every ``.o`` file that ``#include``\s the; header, bloating ``.o`` file sizes and increasing link times. Don't use default labels in fully covered switches over enumerations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``-Wswitch`` warns if a switch, without a default label, over an enumeration; does not cover every enumeration value. If you ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:50218,reduce,reduces,50218,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['reduce'],['reduces']
Energy Efficiency,"ing linked memory to the executing process. #. Phase 1. This phase is called immediately by the ``link`` function as soon as the; initial configuration (including the pass pipeline setup) is complete. #. Run pre-prune passes. These passes are called on the graph before it is pruned. At this stage; ``LinkGraph`` nodes still have their original vmaddrs. A mark-live pass; (supplied by the ``JITLinkContext``) will be run at the end of this; sequence to mark the initial set of live symbols. Notable use cases: marking nodes live, accessing/copying graph data that; will be pruned (e.g. metadata that's important for the JIT, but not needed; for the link process). #. Prune (dead-strip) the ``LinkGraph``. Removes all symbols and blocks not reachable from the initial set of live; symbols. This allows JITLink to remove unreachable symbols / content, including; overridden weak and redundant ODR definitions. #. Run post-prune passes. These passes are run on the graph after dead-stripping, but before memory; is allocated or nodes assigned their final target vmaddrs. Passes run at this stage benefit from pruning, as dead functions and data; have been stripped from the graph. However new content can still be added; to the graph, as target and working memory have not been allocated yet. Notable use cases: Building Global Offset Table (GOT), Procedure Linkage; Table (PLT), and Thread Local Variable (TLV) entries. #. Asynchronously allocate memory. Calls the ``JITLinkContext``'s ``JITLinkMemoryManager`` to allocate both; working and target memory for the graph. As part of this process the; ``JITLinkMemoryManager`` will update the addresses of all nodes; defined in the graph to their assigned target address. Note: This step only updates the addresses of nodes defined in this graph.; External symbols will still have null addresses. #. Phase 2. #. Run post-allocation passes. These passes are run on the graph after working and target memory have; been allocated, but before the ``JITLinkCon",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:18807,allocate,allocated,18807,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocated']
Energy Efficiency,"ing models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resou",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:36564,schedul,schedulers,36564,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['schedul'],"['scheduler', 'schedulers']"
Energy Efficiency,"ing the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umin.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umin.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_fmax:. '``llvm.vp.reduce.fmax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmax.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmax.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmax``' intrinsic performs the floating-point ``MAX``; reduction (",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:771167,reduce,reduce,771167,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ing with tools like `Clang Format`_. .. _Clang Format: https://clang.llvm.org/docs/ClangFormat.html. Language and Compiler Issues; ----------------------------. Treat Compiler Warnings Like Errors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Compiler warnings are often useful and help improve the code. Those that are; not useful, can be often suppressed with a small code change. For example, an; assignment in the ``if`` condition is often a typo:. .. code-block:: c++. if (V = getValue()) {; ...; }. Several compilers will print a warning for the code above. It can be suppressed; by adding parentheses:. .. code-block:: c++. if ((V = getValue())) {; ...; }. Write Portable Code; ^^^^^^^^^^^^^^^^^^^. In almost all cases, it is possible to write completely portable code. When; you need to rely on non-portable code, put it behind a well-defined and; well-documented interface. Do not use RTTI or Exceptions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In an effort to reduce code and executable size, LLVM does not use exceptions; or RTTI (`runtime type information; <https://en.wikipedia.org/wiki/Run-time_type_information>`_, for example,; ``dynamic_cast<>``). That said, LLVM does make extensive use of a hand-rolled form of RTTI that use; templates like :ref:`isa\<>, cast\<>, and dyn_cast\<> <isa>`.; This form of RTTI is opt-in and can be; :doc:`added to any class <HowToSetUpLLVMStyleRTTI>`. Prefer C++-style casts; ^^^^^^^^^^^^^^^^^^^^^^. When casting, use ``static_cast``, ``reinterpret_cast``, and ``const_cast``,; rather than C-style casts. There are two exceptions to this:. * When casting to ``void`` to suppress warnings about unused variables (as an; alternative to ``[[maybe_unused]]``). Prefer C-style casts in this instance. * When casting between integral types (including enums that are not strongly-; typed), functional-style casts are permitted as an alternative to; ``static_cast``. .. _static constructor:. Do not use Static Constructors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Static constructors ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:22269,reduce,reduce,22269,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['reduce'],['reduce']
Energy Efficiency,"ing, the compiler must be able to reason; about whether an instruction can be added to a packet. This decision can be; complex since the compiler has to examine all possible mappings of instructions; to functional units. Therefore to alleviate compilation-time complexity, the; VLIW packetizer parses the instruction classes of a target and generates tables; at compiler build time. These tables can then be queried by the provided; machine-independent API to determine if an instruction can be accommodated in a; packet. How the packetization tables are generated and used; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The packetizer reads instruction classes from a target's itineraries and creates; a deterministic finite automaton (DFA) to represent the state of a packet. A DFA; consists of three major elements: inputs, states, and transitions. The set of; inputs for the generated DFA represents the instruction being added to a; packet. The states represent the possible consumption of functional units by; instructions in a packet. In the DFA, transitions from one state to another; occur on the addition of an instruction to an existing packet. If there is a; legal mapping of functional units to instructions, then the DFA contains a; corresponding transition. The absence of a transition indicates that a legal; mapping does not exist and that the instruction cannot be added to the packet. To generate tables for a VLIW target, add *Target*\ GenDFAPacketizer.inc as a; target to the Makefile in the target directory. The exported API provides three; functions: ``DFAPacketizer::clearResources()``,; ``DFAPacketizer::reserveResources(MachineInstr *MI)``, and; ``DFAPacketizer::canReserveResources(MachineInstr *MI)``. These functions allow; a target packetizer to add an instruction to an existing packet and to check; whether an instruction can be added to a packet. See; ``llvm/CodeGen/DFAPacketizer.h`` for more information. Implementing a Native Assembler; ===================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:79905,consumption,consumption,79905,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['consumption'],['consumption']
Energy Efficiency,"ing-point code and floating-point registers for operations that are; not nominally floating-point. LLVM instructions that perform floating-point; operations or require access to floating-point registers may still cause; floating-point code to be generated. Also inhibits optimizations that create SIMD/vector code and registers from; scalar code such as vectorization or memcpy/memset optimization. This; includes integer vectors. Vector instructions present in IR may still cause; vector code to be generated.; ``noinline``; This attribute indicates that the inliner should never inline this; function in any situation. This attribute may not be used together; with the ``alwaysinline`` attribute.; ``nomerge``; This attribute indicates that calls to this function should never be merged; during optimization. For example, it will prevent tail merging otherwise; identical code sequences that raise an exception or terminate the program.; Tail merging normally reduces the precision of source location information,; making stack traces less useful for debugging. This attribute gives the; user control over the tradeoff between code size and debug information; precision.; ``nonlazybind``; This attribute suppresses lazy symbol binding for the function. This; may make calls to the function faster, at the cost of extra program; startup time if the function is not called during program startup.; ``noprofile``; This function attribute prevents instrumentation based profiling, used for; coverage or profile based optimization, from being added to a function. It; also blocks inlining if the caller and callee have different values of this; attribute.; ``skipprofile``; This function attribute prevents instrumentation based profiling, used for; coverage or profile based optimization, from being added to a function. This; attribute does not restrict inlining, so instrumented instruction could end; up in this function.; ``noredzone``; This attribute indicates that the code generator should not us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:91154,reduce,reduces,91154,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduces']
Energy Efficiency,"inite differences. \htmlonly; </div>; \endhtmlonly. ### AD Support essentially requires Code Generation. As we'll discuss in upcoming sections, *AD support* can be added using *C++; Code generation*.; These two terms may be used interchangeably in this document, since the term; *Code Generation* better helps visualize the transformation that is enabling; AD support. ## Current Status of Code Generation in RooFit. RooFit is an extensive toolkit.; The initiative to add AD support/ Code Generation has been started, but has; not yet achieved full coverage for the models defined/maintained in RooFit. ## How Clad enables AD support using Source Code Transformation. [Clad] is a C++ plugin for Clang. It implements a technique called Source Code; Transformation to enable AD support. Source Code Transformation takes the source code (that needs to be; differentiated) as the input and generates an output code that represents the; derivative of the input. This output code can be used instead of the input; code for more efficient compilation. For more technical details, please see the following paper:. > [Automatic Differentiation of Binned Likelihoods with RooFit and Clad](https://arxiv.org/abs/2304.02650). ## Overview on RooFit implementation details to access source code transformation AD. In RooFit jargon, what is meant by a ""RooFit class"" is a class inheriting from; RooAbsArg that represents a mathematical function, a PDF, or any other; transformation of inputs that are also represented by RooAbsArg objects.; Almost all final classes deriving from RooAbsArg have RooAbsReal as an; intermediate base class, which is the base class for all RooAbsArg that; represent real-valued nodes in the computation graph.; As such RooFit objects are so prevalent in practice, the names RooAbsArg and; RooAbsReal are used interchangeably in this guide. Users take these classes to build a computational graph that represents the; PDF (also called ""model"") that they want to use for fitting the data",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:2642,efficient,efficient,2642,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['efficient'],['efficient']
Energy Efficiency,"inline checks (-1 means never use callbacks). Its default value is 3500. Environment Variables; ---------------------. * ``warn_unimplemented`` -- Whether to warn on unimplemented functions. Its; default value is false.; * ``strict_data_dependencies`` -- Whether to propagate labels only when there is; explicit obvious data dependency (e.g., when comparing strings, ignore the fact; that the output of the comparison might be implicit data-dependent on the; content of the strings). This applies only to functions with ``custom`` category; in ABI list. Its default value is true.; * ``origin_history_size`` -- The limit of origin chain length. Non-positive values; mean unlimited. Its default value is 16.; * ``origin_history_per_stack_limit`` -- The limit of origin node's references count.; Non-positive values mean unlimited. Its default value is 20000.; * ``store_context_size`` -- The depth limit of origin tracking stack traces. Its; default value is 20.; * ``zero_in_malloc`` -- Whether to zero shadow space of new allocated memory. Its; default value is true.; * ``zero_in_free`` --- Whether to zero shadow space of deallocated memory. Its; default value is true. Example; =======. DataFlowSanitizer supports up to 8 labels, to achieve low CPU and code; size overhead. Base labels are simply 8-bit unsigned integers that are; powers of 2 (i.e. 1, 2, 4, 8, ..., 128), and union labels are created; by ORing base labels. The following program demonstrates label propagation by checking that; the correct labels are propagated. .. code-block:: c++. #include <sanitizer/dfsan_interface.h>; #include <assert.h>. int main(void) {; int i = 100;; int j = 200;; int k = 300;; dfsan_label i_label = 1;; dfsan_label j_label = 2;; dfsan_label k_label = 4;; dfsan_set_label(i_label, &i, sizeof(i));; dfsan_set_label(j_label, &j, sizeof(j));; dfsan_set_label(k_label, &k, sizeof(k));. dfsan_label ij_label = dfsan_get_label(i + j);. assert(ij_label & i_label); // ij_label has i_label; assert(ij_label & j_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst:10496,allocate,allocated,10496,interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst,1,['allocate'],['allocated']
Energy Efficiency,"inning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register allocation a second; time if the tentative V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue base address in the V#. The; result is a V# with a base address pointing to the beginning of the wavefront; scratch backing memory. The Private Segment Buffer is always requested, but the Private Segment; Wavefront Offset is only requested if it is used (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). .. _amdgpu-amdhsa-memory-model:. Memory Model; ~~~~~~~~~~~~. This section describes the mapping of the LLVM memory model onto AMDGPU machine; code (see :ref:`memmodel`). The AMDGPU backend supports the memory synchronization scopes specified in; :ref:`amdgpu-memory-scopes`. The code sequences used to implement the m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:200009,efficient,efficient,200009,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['efficient'],['efficient']
Energy Efficiency,"insertelement <2 x double> undef, double %B, i32 0; 	%tmp9 = shufflevector <2 x double> %tmp3,; <2 x double> %tmp7,; <2 x i32> < i32 0, i32 2 >; 	store <2 x double> %tmp9, <2 x double>* %r, align 16; 	ret void. ; CHECK: t2:; ; CHECK: 	 movl	8(%esp), %eax; ; CHECK-NEXT: 	movapd	(%eax), %xmm0; ; CHECK-NEXT: 	movhpd	12(%esp), %xmm0; ; CHECK-NEXT: 	movl	4(%esp), %eax; ; CHECK-NEXT: 	movapd	%xmm0, (%eax); ; CHECK-NEXT: 	ret; }. ""``CHECK-NEXT:``"" directives reject the input unless there is exactly one; newline between it and the previous directive. A ""``CHECK-NEXT:``"" cannot be; the first directive in a file. The ""CHECK-SAME:"" directive; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. Sometimes you want to match lines and would like to verify that matches happen; on the same line as the previous match. In this case, you can use ""``CHECK:``""; and ""``CHECK-SAME:``"" directives to specify this. If you specified a custom; check prefix, just use ""``<PREFIX>-SAME:``"". ""``CHECK-SAME:``"" is particularly powerful in conjunction with ""``CHECK-NOT:``""; (described below). For example, the following works like you'd expect:. .. code-block:: llvm. !0 = !DILocation(line: 5, scope: !1, inlinedAt: !2). ; CHECK: !DILocation(line: 5,; ; CHECK-NOT: column:; ; CHECK-SAME: scope: ![[SCOPE:[0-9]+]]. ""``CHECK-SAME:``"" directives reject the input if there are any newlines between; it and the previous directive. ""``CHECK-SAME:``"" is also useful to avoid writing matchers for irrelevant; fields. For example, suppose you're writing a test which parses a tool that; generates output like this:. .. code-block:: text. Name: foo; Field1: ...; Field2: ...; Field3: ...; Value: 1. Name: bar; Field1: ...; Field2: ...; Field3: ...; Value: 2. Name: baz; Field1: ...; Field2: ...; Field3: ...; Value: 1. To write a test that verifies ``foo`` has the value ``1``, you might first; write this:. .. code-block:: text. CHECK: Name: foo; CHECK: Value: 1{{$}}. However, this would be a bad test: if the value for ``foo`` changes, the test; wou",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:14496,power,powerful,14496,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['power'],['powerful']
Energy Efficiency,"inside $\mbox{FCN}$ will be performed approximately to the same; accuracy. The accuracy M expects is called *machine precision*; (MnMachinePrecision, see [api:epsmac]) and can be printed on demand; using std::cout. If the user fools M by making internal $\mbox{FCN}$; computations in single precision, M will interpret roundoff noise as; significant and will usually either fail to find a minimum, or give; incorrect values for the parameter errors. It is therefore recommended to make sure that all computations in; $\mbox{FCN}$, as well as all methods and functions called by; $\mbox{FCN}$, are done in double precision. If for some reason the; computations cannot be done to a precision comparable with that expected; by M , the user **must** inform M of this situation with setting a; different machine precision via the; MnMachinePrecision::setPrecision(double) method. With reduced precision, the user may find that certain features; sensitive to first and second differences ($\mbox{HESSE}$,; $\mbox{MINOS}$, $\mbox{CONTOURS}$) do not work properly, in; which case the calculations must be performed in higher precision. # How to use M #. [howto:howto]. ## The $\mbox{FCN}$ Function ##. [howto:fcn]. The user must always implement a derived class of FCNBase (the; ""$\mbox{FCN}$"") which calculates the function value to be minimized; or analyzed. ![](figures/fcnbase.png). Note that when M is being used through an intermediate package such as; HippoDraw @bib-HippoDraw, then the user's $\mbox{FCN}$ may be; supplied by the this package. The name of the user's class to implement the FCNBase interface may be; chosen freely (in documentation we give it the generic name; $\mbox{FCN}$). ### FCNBase::operator()(const std::vector$<$double$>$&) ###. The meaning of the vector of parameters std::vector$<$double$>$ in the; argument of FCNBase::operator() are of course defined by the user, who; uses the values of those parameters to calculate their function value. The; order and the position of th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:27777,reduce,reduced,27777,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['reduce'],['reduced']
Energy Efficiency,"instead of enumerating the libraries by hand; allows you to link them in a platform independent way. Also, if ROOT; library names change you will not need to change your Makefile. A batch program that does not have a graphic display, which creates,; fills, and saves histograms and trees, only needs to link the core; libraries (`libCore`, `libRIO`), `libHist` and `libTree`.; If ROOT needs access to other libraries, it loads them dynamically.; For example, if the **`TreeViewer`** is used, `libTreePlayer` and all; libraries `libTreePlayer` depends on are loaded also. The dependent; libraries are shown in the ROOT reference guide's library dependency; graph. The difference between reference guide `libHist` and; `libHistPainter` is that the former needs to be explicitly linked and; the latter will be loaded automatically at runtime when ROOT needs it,; by means of the Plugin Manager. plugin manager. In the Figure 1-2, the libraries represented by green boxes outside of; the core are loaded via the plugin manager plugin manager or; equivalent techniques, while the white ones are not. Of course, if one; wants to access a plugin library directly, it has to be explicitly; linked. An example of a plugin library is `libMinuit`. To create and; fill histograms you need to link `libHist.so`. If the code has a call; to fit the histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin class of which an object will be created; (e.g. **`TRFIOFile`**), the library to be loaded (in short; `lib",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:18458,green,green,18458,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['green'],['green']
Energy Efficiency,"instructions, treat the four memory operands in the same; way and in the same order. If the segment register is unspecified (regno = 0),; then no segment override is generated. ""Lea"" operations do not have a segment; register specified, so they only have 4 operands for their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the ability to perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the beh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92377,allocate,allocated,92377,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['allocate'],['allocated']
Energy Efficiency,"int ``ADD``; reduction (:ref:`llvm.vector.reduce.fadd <int_vector_reduce_fadd>`) of the; vector operand ``val`` on each enabled lane, adding it to the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``-0.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fadd.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float -0.0, float -0.0, float -0.0, float -0.0>; %also.r = call float @llvm.vector.reduce.fadd.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_mul:. '``llvm.vp.reduce.mul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.mul.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.mul.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``MUL`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:752386,reduce,reduce,752386,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"int"" string The name of a scalar or vector; type. Corresponds to the OpenCL; ``vec_type_hint`` attribute. ""RuntimeHandle"" string The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; =================== ============== ========= ==============================. .. .. table:: AMDHSA Code Object V2 Kernel Argument Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-argument-metadata-map-v2-table. ================= ============== ========= ================================; String Key Value Type Required? Description; ================= ============== ========= ================================; ""Name"" string Kernel argument name.; ""TypeName"" string Kernel argument type name.; ""Size"" integer Required Kernel argument size in bytes.; ""Align"" integer Required Kernel argument alignment in; bytes. Must be a power of two.; ""ValueKind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""ByValue""; The argument is copied; directly into the kernarg. ""GlobalBuffer""; A global address space pointer; to the buffer data is passed; in the kernarg. ""DynamicSharedPointer""; A group address space pointer; to dynamically allocated LDS; is passed in the kernarg. ""Sampler""; A global address space; pointer to a S# is passed in; the kernarg. ""Image""; A global address space; pointer to a T# is passed in; the kernarg. ""Pipe""; A global address space pointer; to an OpenCL pipe is passed in; the kernarg. ""Queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""HiddenGlobalOffsetX""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""HiddenGlobalOffsetY""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""HiddenGlobalOffsetZ""; The Op",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:123466,power,power,123466,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['power'],['power']
Energy Efficiency,"integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umin``' intrinsic performs the unsigned-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.umin <int_vector_reduce_umin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umin.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umin.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_fmax:. '``llvm.vp.reduce.fmax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmax.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmax.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:770550,reduce,reduce,770550,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"intended to improve the performance; of IDE-centric operations such as syntax highlighting and code completion while; a particular source file is being edited by the user. To minimize the amount; of reparsing required after a change to the file, a form of precompiled header; --- called a precompiled *preamble* --- is automatically generated by parsing; all of the headers in the source file, up to and including the last; ``#include``. When only the source file changes (and none of the headers it; depends on), reparsing of that source file can use the precompiled preamble and; start parsing after the ``#include``\ s, so parsing time is proportional to the; size of the source file (rather than all of its includes). However, the; compilation of that translation unit may already use a precompiled header: in; this case, Clang will create the precompiled preamble as a chained precompiled; header that refers to the original precompiled header. This drastically; reduces the time needed to serialize the precompiled preamble for use in; reparsing. Chained precompiled headers get their name because each precompiled header can; depend on one other precompiled header, forming a chain of dependencies. A; translation unit will then include the precompiled header that starts the chain; (i.e., nothing depends on it). This linearity of dependencies is important for; the semantic model of chained precompiled headers, because the most-recent; precompiled header can provide information that overrides the information; provided by the precompiled headers it depends on, just like a header file; ``B.h`` that includes another header ``A.h`` can modify the state produced by; parsing ``A.h``, e.g., by ``#undef``'ing a macro defined in ``A.h``. There are several ways in which chained precompiled headers generalize the AST; file model:. Numbering of IDs; Many different kinds of entities --- identifiers, declarations, types, etc.; --- have ID numbers that start at 1 or some other predefined constan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:24592,reduce,reduces,24592,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['reduce'],['reduces']
Energy Efficiency,"invariant.group.p0(ptr <ptr>). Overview:; """""""""""""""""". The '``llvm.strip.invariant.group``' intrinsic can be used when an invariant; established by ``invariant.group`` metadata no longer holds, to obtain a new pointer; value that does not carry the invariant information. It is an experimental; intrinsic, which means that its semantics might change in the future. Arguments:; """""""""""""""""""". The ``llvm.strip.invariant.group`` takes only one argument, which is a pointer; to the memory. Semantics:; """""""""""""""""""". Returns another pointer that aliases its argument but which has no associated; ``invariant.group`` metadata.; It does not read any memory and can be speculated. .. _constrainedfp:. Constrained Floating-Point Intrinsics; -------------------------------------. These intrinsics are used to provide special handling of floating-point; operations when specific rounding mode or floating-point exception behavior is; required. By default, LLVM optimization passes assume that the rounding mode is; round-to-nearest and that floating-point exceptions will not be monitored.; Constrained FP intrinsics are used to support non-default rounding modes and; accurately preserve exception behavior without compromising LLVM's ability to; optimize FP code when the default behavior is used. If any FP operation in a function is constrained then they all must be; constrained. This is required for correct LLVM IR. Optimizations that; move code around can create miscompiles if mixing of constrained and normal; operations is done. The correct way to mix constrained and less constrained; operations is to use the rounding mode and exception handling metadata to; mark constrained intrinsics as having LLVM's default behavior. Each of these intrinsics corresponds to a normal floating-point operation. The; data arguments and the return value are the same as the corresponding FP; operation. The rounding mode argument is a metadata string specifying what; assumptions, if any, the optimizer can make when tr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:867462,monitor,monitored,867462,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['monitor'],['monitored']
Energy Efficiency,"ion, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.or``' intrinsic performs the integer ``OR`` reduction; (:ref:`llvm.vector.reduce.or <int_vector_reduce_or>`) of the vector operand; ``val`` on each enabled lane, performing an '``or``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.or.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %masked.a); %also.r = or i32 %reduction, %start. .. _int_vp_reduce_xor:. '``llvm.vp.reduce.xor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.xor.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.xor.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``XOR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:760287,reduce,reduce,760287,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ion. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-multigrid-sync-arg"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the multigrid synchronization pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the default queue pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-completion-action"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the completion action pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-lds-size""=""min[,max]"" Min is the minimum number of bytes that will be allocated in the Local; Data Store at address zero. Variables are allocated within this frame; using absolute symbol metadata, primarily by the AMDGPULowerModuleLDS; pass. Optional max is the maximum number of bytes that will be allocated.; Note that min==max indicates that no further variables can be added to; the frame. This is an internal detail of how LDS variables are lowered,; language front ends should not set this attribute. ======================================= ==========================================================. Calling Conventions; -------------------. The AMDGPU backend supports the following calling conventions:. .. table:: AMDGPU Calling Conventions; :name: amdgpu-cc. =============================== ==========================================================; Calling Convention Description; =============================== ==========================================================; ``ccc`` The C calling convention. Used by default.; See :ref:`amdgpu-amdhsa-function-call-convention-non-kernel-functions`; for more details. ``fastcc`` The fast calling convention. Mostly the sa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:51489,allocate,allocated,51489,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"ion. This library is compiled multiple times for different [vector instruction set architectures](https://en.wikipedia.org/wiki/SIMD) and the optimal code is executed during runtime, as a result of an automatic hardware detection mechanism that this library contains. **As a result, fits can benefit by a speedup of 3x-16x.**. As of ROOT v6.26, RooBatchComputes also provides multithread and [CUDA](https://en.wikipedia.org/wiki/CUDA) instances of the computation functions, resulting in even greater improvements for fitting times. ### How to use; This library is an internal component of RooFit, so users are not supposed to actively interact with it. Instead, they can benefit from significantly faster times for fitting by calling `fitTo()` and providing a `BatchMode(""cpu"")` or a `BatchMode(""cuda"")` option.; ``` {.cpp}; // fit using the most efficient library that the computer's CPU can support; RooMyPDF.fitTo(data, BatchMode(""cpu""));. // fit using the CUDA library along with the most efficient library that the computer's CPU can support; RooMyPDF.fitTo(data, BatchMode(""cuda""));; ```; **Note: In case the system does not support vector instructions, the `RooBatchCompute::Cpu` option is guaranteed to work properly by using a generic CPU library. In contrast, users must first make sure that their system supports CUDA in order to use the `RooBatchCompute::Cuda` option. If this is not the case, an exception will be thrown.**. If `""cuda""` is selected, RooFit will launch CUDA kernels for computing likelihoods and potentially other intense computations. At the same time, the most efficient CPU library loaded will also handle parts of the computations in parallel with the GPU (or potentially, if it's faster, all of them), thus gaining full advantage of the available hardware. For this purpose `RooFitDriver`, a newly created RooFit class (in roofitcore) takes over the task of analyzing the computations and assigning each to the correct piece of hardware, taking into consideration th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md:2049,efficient,efficient,2049,roofit/doc/developers/batchcompute.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md,1,['efficient'],['efficient']
Energy Efficiency,"ion.htm>`_. Lanai; -----. * `Lanai Instruction Set Architecture <http://g.co/lanai/isa>`_. MIPS; ----. * `MIPS Processor Architecture <https://www.mips.com/products/>`_. * `MIPS 64-bit ELF Object File Specification <https://www.linux-mips.org/pub/linux/mips/doc/ABI/elf64-2.4.pdf>`_. PowerPC; -------. IBM - Official manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Power Instruction Set Architecture, Version 3.0B <https://openpowerfoundation.org/?resource_lib=power-isa-version-3-0>`_. * `POWER9 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power9-processor-users-manual>`_. * `Power Instruction Set Architecture, Version 2.07B <https://openpowerfoundation.org/?resource_lib=ibm-power-isa-version-2-07-b>`_. * `POWER8 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power8-processor-users-manual>`_. * `Power Instruction Set Architecture, Versions 2.03 through 2.06 (Internet Archive) <https://web.archive.org/web/20121124005736/https://www.power.org/technology-introduction/standards-specifications>`_. * `IBM AIX 7.2 POWER Assembly Reference <https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/assembler/alangref_kickoff.html>`_. * `IBM AIX/5L for POWER Assembly Reference <http://publibn.boulder.ibm.com/doc_link/en_US/a_doc_lib/aixassem/alangref/alangreftfrm.htm>`_. Embedded PowerPC Processors manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Book E: Enhanced PowerPC Architecture <https://www.nxp.com/docs/en/user-guide/BOOK_EUM.pdf>`_. * `EREF: A Programmer's Reference Manual for Freescale Embedded Processors (EREFRM) <https://www.nxp.com/files-static/32bit/doc/ref_manual/EREF_RM.pdf>`_. * `Signal Processing Engine (SPE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/SPEPEM.pdf>`_. * `Variable-Length Encoding (VLE) Programming Environments Manual: A Supplement to the EREF <https://www.nxp.com/docs/en/reference-manual/VLEPEM.pdf>`_. Other documents",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:2733,power,power,2733,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,1,['power'],['power']
Energy Efficiency,"ions can be handled by sending a reply to the commits mailing list. .. _revert_policy:. Patch reversion policy; ----------------------. As a community, we strongly value having the tip of tree in a good state while; allowing rapid iterative development. As such, we tend to make much heavier; use of reverts to keep the tree healthy than some other open source projects,; and our norms are a bit different. How should you respond if someone reverted your change?. * Remember, it is normal and healthy to have patches reverted. Having a patch; reverted does not necessarily mean you did anything wrong.; * We encourage explicitly thanking the person who reverted the patch for doing; the task on your behalf.; * If you need more information to address the problem, please follow up in the; original commit thread with the reverting patch author. When should you revert your own change?. * Any time you learn of a serious problem with a change, you should revert it.; We strongly encourage ""revert to green"" as opposed to ""fixing forward"". We; encourage reverting first, investigating offline, and then reapplying the; fixed patch - possibly after another round of review if warranted.; * If you break a buildbot in a way which can't be quickly fixed, please revert.; * If a test case that demonstrates a problem is reported in the commit thread,; please revert and investigate offline.; * If you receive substantial :ref:`post-commit review <post_commit_review>`; feedback, please revert and address said feedback before recommitting.; (Possibly after another round of review.); * If you are asked to revert by another contributor, please revert and discuss; the merits of the request offline (unless doing so would further destabilize; tip of tree). When should you revert someone else's change?. * In general, if the author themselves would revert the change per these; guidelines, we encourage other contributors to do so as a courtesy to the; author. This is one of the major cases where our norms ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:19378,green,green,19378,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['green'],['green']
Energy Efficiency,"ions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43447,schedul,schedule,43447,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['schedul'],"['schedule', 'scheduling']"
Energy Efficiency,"ions of GCC) is extremely inefficient and 2) the C++ standards; committee is likely to deprecate this container and/or change it significantly; somehow. In any case, please don't use it. .. _dss_bitvector:. BitVector; ^^^^^^^^^. The BitVector container provides a dynamic size set of bits for manipulation.; It supports individual bit setting/testing, as well as set operations. The set; operations take time O(size of bitvector), but operations are performed one word; at a time, instead of one bit at a time. This makes the BitVector very fast for; set operations compared to other containers. Use the BitVector when you expect; the number of set bits to be high (i.e. a dense set). .. _dss_smallbitvector:. SmallBitVector; ^^^^^^^^^^^^^^. The SmallBitVector container provides the same interface as BitVector, but it is; optimized for the case where only a small number of bits, less than 25 or so,; are needed. It also transparently supports larger bit counts, but slightly less; efficiently than a plain BitVector, so SmallBitVector should only be used when; larger counts are rare. At this time, SmallBitVector does not support set operations (and, or, xor), and; its operator[] does not provide an assignable lvalue. .. _dss_sparsebitvector:. SparseBitVector; ^^^^^^^^^^^^^^^. The SparseBitVector container is much like BitVector, with one major difference:; Only the bits that are set, are stored. This makes the SparseBitVector much; more space efficient than BitVector when the set is sparse, as well as making; set operations O(number of set bits) instead of O(size of universe). The; downside to the SparseBitVector is that setting and testing of random bits is; O(N), and on large SparseBitVectors, this can be slower than BitVector. In our; implementation, setting or testing bits in sorted order (either forwards or; reverse) is O(1) worst case. Testing and setting bits within 128 bits (depends; on size) of the current bit is also O(1). As a general statement,; testing/setting bits i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:97684,efficient,efficiently,97684,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficiently']
Energy Efficiency,"iour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disab",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20248,power,powerpc,20248,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['power'],['powerpc']
Energy Efficiency,"irely up to the backends and the programs that incorporate; the output of those backends. .. note::. The term ""parent class"" can refer to a class that is a parent of another; class, and also to a class from which a concrete record inherits. This; nonstandard use of the term arises because TableGen treats classes and; concrete records similarly. A backend processes some subset of the concrete records built by the; TableGen parser and emits the output files. These files are usually C++; ``.inc`` files that are included by the programs that require the data in; those records. However, a backend can produce any type of output files. For; example, it could produce a data file containing messages tagged with; identifiers and substitution parameters. In a complex use case such as the; LLVM code generator, there can be many concrete records and some of them can; have an unexpectedly large number of fields, resulting in large output files. In order to reduce the complexity of TableGen files, classes are used to; abstract out groups of record fields. For example, a few classes may; abstract the concept of a machine register file, while other classes may; abstract the instruction formats, and still others may abstract the; individual instructions. TableGen allows an arbitrary hierarchy of classes,; so that the abstract classes for two concepts can share a third superclass that; abstracts common ""sub-concepts"" from the two original concepts. In order to make classes more useful, a concrete record (or another class); can request a class as a parent class and pass *template arguments* to it.; These template arguments can be used in the fields of the parent class to; initialize them in a custom manner. That is, record or class ``A`` can; request parent class ``S`` with one set of template arguments, while record or class; ``B`` can request ``S`` with a different set of arguments. Without template; arguments, many more classes would be required, one for each combination of; the tem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:3826,reduce,reduce,3826,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"is ill-formed. An Objective-C object subscript expression is always an l-value. If the; expression appears on the left-hand side of a simple assignment operator; (=), the element is written as described below. If the expression; appears on the left-hand side of a compound assignment operator (e.g.; +=), the program is ill-formed, because the result of reading an element; is always an Objective-C object pointer and no binary operators are; legal on such pointers. If the expression appears in any other position,; the element is read as described below. It is an error to take the; address of a subscript expression, or (in C++) to bind a reference to; it. Programs can use object subscripting with Objective-C object pointers of; type ``id``. Normal dynamic message send rules apply; the compiler must; see *some* declaration of the subscripting methods, and will pick the; declaration seen first. Caveats; =======. Objects created using the literal or boxed expression syntax are not; guaranteed to be uniqued by the runtime, but nor are they guaranteed to; be newly-allocated. As such, the result of performing direct comparisons; against the location of an object literal (using ``==``, ``!=``, ``<``,; ``<=``, ``>``, or ``>=``) is not well-defined. This is usually a simple; mistake in code that intended to call the ``isEqual:`` method (or the; ``compare:`` method). This caveat applies to compile-time string literals as well.; Historically, string literals (using the ``@""...""`` syntax) have been; uniqued across translation units during linking. This is an; implementation detail of the compiler and should not be relied upon. If; you are using such code, please use global string constants instead; (``NSString * const MyConst = @""...""``) or use ``isEqual:``. Grammar Additions; =================. To support the new syntax described above, the Objective-C; ``@``-expression grammar has the following new productions:. ::. objc-at-expression : '@' (string-literal | encode-literal | selec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst:17232,allocate,allocated,17232,interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ObjectiveCLiterals.rst,1,['allocate'],['allocated']
Energy Efficiency,"is is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmaximum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmaximum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmaximum.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maximum.*``'; intrinsic. That is, this intrinsic propagates NaNs and +0.0 is considered; greater than -0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fminimum:. '``llvm.vector.reduce.fminimum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fminimum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fminimum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fminimum.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minimum.*``'; intrinsic. That is, this intrinsic propagates NaNs and -0.0 is considered less; than +0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. '``llvm.vector.insert``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. ; Insert fixed type into scalable type; declare <vscale x 4 x float> @llvm.vector.insert.nxv4f32.v4f32(<vscale x 4 x float> %vec, <4 x float> %subvec, i64 <idx>); declare <vscale x 2 x double> @llvm.vector.insert.nxv2f64.v2f64(<vscale x 2 x double> %vec, <2 x double> %subvec, i64 <idx>).",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:661662,reduce,reduce,661662,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"is is useful for cases where the number of; elements is known in advance; their actual initialization is expensive; and; they are sparsely used. This utility uses page-granular lazy initialization; when the element is accessed. When the number of used pages is small; significant memory savings can be achieved. The main advantage is that a ``PagedVector`` allows to delay the actual; allocation of the page until it's needed, at the extra cost of one pointer per; page and one extra indirection when accessing elements with their positional; index. In order to minimise the memory footprint of this container, it's important to; balance the PageSize so that it's not too small (otherwise the overhead of the; pointer per page might become too high) and not too big (otherwise the memory; is wasted if the page is not fully used). Moreover, while retaining the order of the elements based on their insertion; index, like a vector, iterating over the elements via ``begin()`` and ``end()``; is not provided in the API, due to the fact accessing the elements in order; would allocate all the iterated pages, defeating memory savings and the purpose; of the ``PagedVector``. Finally a ``materialized_begin()`` and ``materialized_end`` iterators are; provided to access the elements associated to the accessed pages, which could; speed up operations that need to iterate over initialized elements in a; non-ordered manner. .. _dss_vector:. <vector>; ^^^^^^^^. ``std::vector<T>`` is well loved and respected. However, ``SmallVector<T, 0>``; is often a better option due to the advantages listed above. std::vector is; still useful when you need to store more than ``UINT32_MAX`` elements or when; interfacing with code that expects vectors :). One worthwhile note about std::vector: avoid code like this:. .. code-block:: c++. for ( ... ) {; std::vector<foo> V;; // make use of V.; }. Instead, write this as:. .. code-block:: c++. std::vector<foo> V;; for ( ... ) {; // make use of V.; V.clear();; }. Doing",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:64304,allocate,allocate,64304,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocate']
Energy Efficiency,"is not really a good idea to; use). Indirect inputs and outputs; """""""""""""""""""""""""""""""""""""""""""""""""""""". Indirect output or input constraints can be specified by the ""``*``"" modifier; (which goes after the ""``=``"" in case of an output). This indicates that the asm; will write to or read from the contents of an *address* provided as an input; argument. (Note that in this way, indirect outputs act more like an *input* than; an output: just like an input, they consume an argument of the call expression,; rather than producing a return value. An indirect output constraint is an; ""output"" only in that the asm is expected to write to the contents of the input; memory location, instead of just read from it). This is most typically used for memory constraint, e.g. ""``=*m``"", to pass the; address of a variable as a value. It is also possible to use an indirect *register* constraint, but only on output; (e.g. ""``=*r``""). This will cause LLVM to allocate a register for an output; value normally, and then, separately emit a store to the address provided as; input, after the provided inline asm. (It's not clear what value this; functionality provides, compared to writing the store explicitly after the asm; statement, and it can only produce worse code, since it bypasses many; optimization passes. I would recommend not using it.). Call arguments for indirect constraints must have pointer type and must specify; the :ref:`elementtype <attr_elementtype>` attribute to indicate the pointer; element type. Clobber constraints; """""""""""""""""""""""""""""""""""""". A clobber constraint is indicated by a ""``~``"" prefix. A clobber does not; consume an input operand, nor generate an output. Clobbers cannot use any of the; general constraint code letters -- they may use only explicit register; constraints, e.g. ""``~{eax}``"". The one exception is that a clobber string of; ""``~{memory}``"" indicates that the assembly writes to arbitrary undeclared; memory locations -- not only the memory pointed to by a declared indirect; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:216439,allocate,allocate,216439,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocate']
Energy Efficiency,"is relatively simple;; they ultimately form a linked list of every clobber that dominates the; ``MemoryAccess`` that you're trying to optimize. In other words, the; ``definingAccess`` of a ``MemoryDef`` is always the nearest dominating; ``MemoryDef`` or ``MemoryPhi`` of said ``MemoryDef``. Use and Def optimization; ------------------------. ``MemoryUse``\ s keep a single operand, which is their defining or optimized; access.; Traditionally ``MemorySSA`` optimized ``MemoryUse``\ s at build-time, up to a; given threshold.; Specifically, the operand of every ``MemoryUse`` was optimized to point to the; actual clobber of said ``MemoryUse``. This can be seen in the above example; the; second ``MemoryUse`` in ``if.end`` has an operand of ``1``, which is a; ``MemoryDef`` from the entry block. This is done to make walking,; value numbering, etc, faster and easier.; As of `this revision <https://reviews.llvm.org/D121381>`_, the default was; changed to not optimize uses at build time, in order to provide the option to; reduce compile-time if the walking is not necessary in a pass. Most users call; the new API ``ensureOptimizedUses()`` to keep the previous behavior and do a; one-time optimization of ``MemoryUse``\ s, if this was not done before.; New pass users are recommended to call ``ensureOptimizedUses()``. Initially it was not possible to optimize ``MemoryDef``\ s in the same way, as we; restricted ``MemorySSA`` to one operand per access.; This was changed and ``MemoryDef``\ s now keep two operands.; The first one, the defining access, is; always the previous ``MemoryDef`` or ``MemoryPhi`` in the same basic block, or; the last one in a dominating predecessor if the current block doesn't have any; other accesses writing to memory. This is needed for walking Def chains.; The second operand is the optimized access, if there was a previous call on the; walker's ``getClobberingMemoryAccess(MA)``. This API will cache information; as part of ``MA``.; Optimizing all ``MemoryDef``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:11686,reduce,reduce,11686,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['reduce'],['reduce']
Energy Efficiency,"is ruleset is the ``LegalityQuery`` which describes the; instruction. We use a description rather than the instruction to both allow other; passes to determine legality without having to create an instruction and also to; limit the information available to the predicates to that which is safe to rely; on. Currently, the information available to the predicates that determine; legality contains:. * The opcode for the instruction. * The type of each type index (see ``type0``, ``type1``, etc.). * The size in bytes and atomic ordering for each MachineMemOperand. .. note::. An alternative worth investigating is to generalize the API to represent; actions using ``std::function`` that implements the action, instead of explicit; enum tokens (``Legal``, ``WidenScalar``, ...) that instruct it to call a; function. This would have some benefits, most notable being that Custom could; be removed. .. rubric:: Footnotes. .. [#legalizer-legacy-footnote] An API is broadly similar to; SelectionDAG/TargetLowering is available but is not recommended as a more; powerful API is available. Rule Processing and Declaring Rules; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The ``getActionDefinitionsBuilder`` function generates a ruleset for the given; opcode(s) that rules can be added to. If multiple opcodes are given, they are; all permanently bound to the same ruleset. The rules in a ruleset are executed; from top to bottom and will start again from the top if an instruction is; legalized as a result of the rules. If the ruleset is exhausted without; satisfying any rule, then it is considered unsupported. When it doesn't declare the instruction legal, each pass over the rules may; request that one type changes to another type. Sometimes this can cause multiple; types to change but we avoid this as much as possible as making multiple changes; can make it difficult to avoid infinite loops where, for example, narrowing one; type causes another to be too small and widening that type causes the first one;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:3730,power,powerful,3730,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,1,['power'],['powerful']
Energy Efficiency,"ist of available attributes, use:; **llvm-as < /dev/null | llc -march=xyz -mattr=help**. FLOATING POINT OPTIONS; ----------------------. .. option:: -disable-excess-fp-precision. Disable optimizations that may increase floating point precision. .. option:: -enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: -enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: -enable-unsafe-fp-math. Causes :program:`lli` to enable optimizations that may decrease floating point; precision. .. option:: -soft-float. Causes :program:`lli` to generate software floating point library calls instead of; equivalent hardware instructions. CODE GENERATION OPTIONS; -----------------------. .. option:: -code-model=model. Choose the code model from:. .. code-block:: text. default: Target default code model; tiny: Tiny code model; small: Small code model; kernel: Kernel code model; medium: Medium code model; large: Large code model. .. option:: -disable-post-RA-scheduler. Disable scheduling after register allocation. .. option:: -disable-spill-fusing. Disable fusing of spill code into instructions. .. option:: -jit-enable-eh. Exception handling should be enabled in the just-in-time compiler. .. option:: -join-liveintervals. Coalesce copies (default=true). .. option:: -nozero-initialized-in-bss. Don't place zero-initialized symbols into the BSS section. .. option:: -pre-RA-sched=scheduler. Instruction schedulers available (before register allocation):. .. code-block:: text. =default: Best scheduler for the target; =none: No scheduling: breadth first sequencing; =simple: Simple two pass scheduling: minimize critical path and maximize processor utilization; =simple-noitin: Simple two pass scheduling: Same as simple except using generic latency; =list-burr: Bottom-up register reduction list scheduling; =list-tdrr: Top-down register reduction list scheduling; =list-td: Top-down list scheduler. .. option:: -regalloc=allocator. Register allo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:3831,schedul,scheduler,3831,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,1,['schedul'],['scheduler']
Energy Efficiency,"ist::getKind`` function, mapping a string (and syntax) to a parsed; attribute ``AttributeList::Kind`` enumeration. ClangAttrDump; -------------. **Purpose**: Creates AttrDump.inc, which dumps information about an attribute.; It is used to implement ``ASTDumper::dumpAttr``. ClangDiagsDefs; --------------. Generate Clang diagnostics definitions. ClangDiagGroups; ---------------. Generate Clang diagnostic groups. ClangDiagsIndexName; -------------------. Generate Clang diagnostic name index. ClangCommentNodes; -----------------. Generate Clang AST comment nodes. ClangDeclNodes; --------------. Generate Clang AST declaration nodes. ClangStmtNodes; --------------. Generate Clang AST statement nodes. ClangSACheckers; ---------------. Generate Clang Static Analyzer checkers. ClangCommentHTMLTags; --------------------. Generate efficient matchers for HTML tag names that are used in documentation comments. ClangCommentHTMLTagsProperties; ------------------------------. Generate efficient matchers for HTML tag properties. ClangCommentHTMLNamedCharacterReferences; ----------------------------------------. Generate function to translate named character references to UTF-8 sequences. ClangCommentCommandInfo; -----------------------. Generate command properties for commands that are used in documentation comments. ClangCommentCommandList; -----------------------. Generate list of commands that are used in documentation comments. ArmNeon; -------. Generate arm_neon.h for clang. ArmNeonSema; -----------. Generate ARM NEON sema support for clang. ArmNeonTest; -----------. Generate ARM NEON tests for clang. AttrDocs; --------. **Purpose**: Creates ``AttributeReference.rst`` from ``AttrDocs.td``, and is; used for documenting user-facing attributes. General BackEnds; ================. Print Records; -------------. The TableGen command option ``--print-records`` invokes a simple backend; that prints all the classes and records defined in the source files. This is; the default backend opt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst:13359,efficient,efficient,13359,interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,1,['efficient'],['efficient']
Energy Efficiency,"ister.; - ``R``: An 8, 16, 32, or 64-bit ""legacy"" integer register -- one which has; existed since i386, and can be accessed without the REX prefix.; - ``f``: A 32, 64, or 80-bit '387 FPU stack pseudo-register.; - ``y``: A 64-bit MMX register, if MMX is enabled.; - ``v``: If SSE is enabled: a 32 or 64-bit scalar operand, or 128-bit vector; operand in a SSE register. If AVX is also enabled, can also be a 256-bit; vector operand in an AVX register. If AVX-512 is also enabled, can also be a; 512-bit vector operand in an AVX512 register. Otherwise, an error.; - ``Ws``: A symbolic reference with an optional constant addend or a label; reference.; - ``x``: The same as ``v``, except that when AVX-512 is enabled, the ``x`` code; only allocates into the first 16 AVX-512 registers, while the ``v`` code; allocates into any of the 32 AVX-512 registers.; - ``Y``: The same as ``x``, if *SSE2* is enabled, otherwise an error.; - ``A``: Special case: allocates EAX first, then EDX, for a single operand (in; 32-bit mode, a 64-bit integer operand will get split into two registers). It; is not recommended to use this constraint, as in 64-bit mode, the 64-bit; operand will get allocated only to RAX -- if two 32-bit operands are needed,; you're better off splitting it yourself, before passing it to the asm; statement. XCore:. - ``r``: A 32-bit integer register. .. _inline-asm-modifiers:. Asm template argument modifiers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In the asm template string, modifiers can be used on the operand reference, like; ""``${0:n}``"". The modifiers are, in general, expected to behave the same way they do in; GCC. LLVM's support is often implemented on an 'as-needed' basis, to support C; inline asm code which was supported by GCC. A mismatch in behavior between LLVM; and GCC likely indicates a bug in LLVM. Target-independent:. - ``c``: Print an immediate integer constant unadorned, without; the target-specific immediate punctuation (e.g. no ``$`` prefix).; - ``n``: Negate and pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:234259,allocate,allocates,234259,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocates']
Energy Efficiency,"it at a time. This makes the BitVector very fast for; set operations compared to other containers. Use the BitVector when you expect; the number of set bits to be high (i.e. a dense set). .. _dss_smallbitvector:. SmallBitVector; ^^^^^^^^^^^^^^. The SmallBitVector container provides the same interface as BitVector, but it is; optimized for the case where only a small number of bits, less than 25 or so,; are needed. It also transparently supports larger bit counts, but slightly less; efficiently than a plain BitVector, so SmallBitVector should only be used when; larger counts are rare. At this time, SmallBitVector does not support set operations (and, or, xor), and; its operator[] does not provide an assignable lvalue. .. _dss_sparsebitvector:. SparseBitVector; ^^^^^^^^^^^^^^^. The SparseBitVector container is much like BitVector, with one major difference:; Only the bits that are set, are stored. This makes the SparseBitVector much; more space efficient than BitVector when the set is sparse, as well as making; set operations O(number of set bits) instead of O(size of universe). The; downside to the SparseBitVector is that setting and testing of random bits is; O(N), and on large SparseBitVectors, this can be slower than BitVector. In our; implementation, setting or testing bits in sorted order (either forwards or; reverse) is O(1) worst case. Testing and setting bits within 128 bits (depends; on size) of the current bit is also O(1). As a general statement,; testing/setting bits in a SparseBitVector is O(distance away from last set bit). .. _dss_coalescingbitvector:. CoalescingBitVector; ^^^^^^^^^^^^^^^^^^^. The CoalescingBitVector container is similar in principle to a SparseBitVector,; but is optimized to represent large contiguous ranges of set bits compactly. It; does this by coalescing contiguous ranges of set bits into intervals. Searching; for a bit in a CoalescingBitVector is O(log(gaps between contiguous ranges)). CoalescingBitVector is a better choice than B",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:98154,efficient,efficient,98154,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"it. This document describes what you can do to increase the odds of; getting it fixed quickly. ðŸ”’ If you believe that the bug is security related, please follow :ref:`report-security-issue`. ðŸ”’. Basically you have to do two things at a minimum. First, decide whether the; bug `crashes the compiler`_ or if the compiler is `miscompiling`_ the program; (i.e., the compiler successfully produces an executable, but it doesn't run; right). Based on what type of bug it is, follow the instructions in the; linked section to narrow down the bug so that the person who fixes it will be; able to find the problem more easily. Once you have a reduced test-case, go to `the LLVM Bug Tracking System; <https://github.com/llvm/llvm-project/issues>`_ and fill out the form with the; necessary details (note that you don't need to pick a label, just use if you're; not sure). The bug description should contain the following information:. * All information necessary to reproduce the problem.; * The reduced test-case that triggers the bug.; * The location where you obtained LLVM (if not from our Git; repository). Thanks for helping us make LLVM better!. .. _crashes the compiler:. Crashing Bugs; =============. More often than not, bugs in the compiler cause it to crash---often due to; an assertion failure of some sort. The most important piece of the puzzle; is to figure out if it is crashing in the Clang front-end or if it is one of; the LLVM libraries (e.g. the optimizer or code generator) that has; problems. To figure out which component is crashing (the front-end, middle-end; optimizer, or backend code generator), run the ``clang`` command line as you; were when the crash occurred, but with the following extra command line; options:. * ``-emit-llvm -Xclang -disable-llvm-passes``: If ``clang`` still crashes when; passed these options (which disable the optimizer and code generator), then; the crash is in the front-end. Jump ahead to :ref:`front-end bugs; <frontend-crash>`. * ``-emit-llvm``: If ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:1220,reduce,reduced,1220,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduced']
Energy Efficiency,"itecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:35534,schedul,schedulers,35534,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['schedulers']
Energy Efficiency,"ith; ``""Scudo ERROR:""`` followed by a short summary of the problem that occurred as; well as the pointer(s) involved. Once again, Scudo is meant to be a mitigation,; and might not be the most useful of tools to help you root-cause the issue,; please consider `ASan <https://github.com/google/sanitizers/wiki/AddressSanitizer>`_; for this purpose. Here is a list of the current error messages and their potential cause:. - ``""corrupted chunk header""``: the checksum verification of the chunk header; has failed. This is likely due to one of two things: the header was; overwritten (partially or totally), or the pointer passed to the function is; not a chunk at all;. - ``""race on chunk header""``: two different threads are attempting to manipulate; the same header at the same time. This is usually symptomatic of a; race-condition or general lack of locking when performing operations on that; chunk;. - ``""invalid chunk state""``: the chunk is not in the expected state for a given; operation, eg: it is not allocated when trying to free it, or it's not; quarantined when trying to recycle it, etc. A double-free is the typical; reason this error would occur;. - ``""misaligned pointer""``: we strongly enforce basic alignment requirements, 8; bytes on 32-bit platforms, 16 bytes on 64-bit platforms. If a pointer passed; to our functions does not fit those, something is definitely wrong. - ``""allocation type mismatch""``: when the optional deallocation type mismatch; check is enabled, a deallocation function called on a chunk has to match the; type of function that was called to allocate it. Security implications of such; a mismatch are not necessarily obvious but situational at best;. - ``""invalid sized delete""``: when the C++14 sized delete operator is used, and; the optional check enabled, this indicates that the size passed when; deallocating a chunk is not congruent with the one requested when allocating; it. This is likely to be a `compiler issue <https://software.intel.com/en-us/for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:15712,allocate,allocated,15712,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['allocate'],['allocated']
Energy Efficiency,"itives in pad; Can be used when several histograms or several graphs superimposed; 9. Let configure ""&toolbar=vert"" in URL to change orientation of tool buttons; 10. Improve markers and error bars drawing for TH1/TProfile. ## Changes in 5.4.3; 1. Fix - draw functions also when histogram ""same"" option used (#159); 2. Fix - when draw histogram as markers improve optimization algorithm; 3. Fix - correct histogram Y-axis range selection in logarithmic scale; 4. Fix - for TH2 draw options allow combination ""colztext"" (#162); 5. Fix - PNG file generation with 3D drawings inside. ## Changes in 5.4.2; 1. Fix - take into account extra quotes in multipart http reply (#157); 2. Fix - display of labels on X axis with TProfile; 3. Fix - support time display in TMultiGraph; 4. Fix - correctly parse ""optstat"" and ""optfit"" in URL; 5. Fix - correctly update TGraph drawing when X range is changing; 6. Fix - return only TF1/TF2 object when searching function (#158). ## Changes in 5.4.1; 1. Fix - monitoring mode in draw.htm page; 2. Fix - zooming in colz palette; 3. Fix - support both 9.x and 10.x jsdom version in Node.js (#149); 4. Fix - draw axis main line with appropriate attributes (#150); 5. Fix - use axis color when drawing grids lines (#150); 6. Fix - when set pad logx/logy, reset existing user ranges in pad; 7. Fix - avoid too deep calling stack when drawing many graphs or histos (#154); 8. Fix - correctly (re)draw tooltips on canvas with many subpads. ## Changes in 5.4.0; 1. New supported classes:; - TDiamond; - TArc; - TCurlyLine; - TCurlyArc; - TCrown; 2. New draw options:; - ""RX"" and ""RY"" for TGraph to reverse axis; - ""noopt"" for TGraph to disable drawing optimization; - ""CPN"" for TCanvas to create color palette from N last colors; - ""line"" for TGraph2D; 3. New features:; - support LZ4 compression; - tooltips and zooming in TGraphPolar drawings; - TPavesText with multiple underlying paves; - implement all fill styles; - draw borders for TWbox; - draw all objects from TList/T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:35146,monitor,monitoring,35146,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitoring']
Energy Efficiency,"itly* encode. The trend; that we are seeing supports this greatly:. 1. Commodity processors are getting massive SIMD support:; * Intel/Amd MMX/MMX2; * AMD's 3Dnow!; * Intel's SSE/SSE2; * Sun's VIS; 2. SMP is becoming much more common, especially in the server space.; 3. Multiple processors on a die are right around the corner. If nothing else, not designing this in would severely limit our future; expansion of the project... > Also, this will require some reading on at least two other; > projects:; > -- Multiscalar architecture from Wisconsin; > -- Simultaneous multithreading architecture from Washington; >; > o Or forget all this and stick to a traditional instruction set?. Heh... :) Well, from a pure research point of view, it is almost more; attactive to go with the most extreme/different ISA possible. On one axis; you get safety and conservatism, and on the other you get degree of; influence that the results have. Of course the problem with pure research; is that often times there is no concrete product of the research... :). > BTW, on an unrelated note, after the meeting yesterday, I did remember; > that you had suggested doing instruction scheduling on SSA form instead; > of a dependence DAG earlier in the semester. When we talked about; > it yesterday, I didn't remember where the idea had come from but I; > remembered later. Just giving credit where its due... :) Thanks. . > Perhaps you can save the above as a file under RCS so you and I can; > continue to expand on this. I think it makes sense to do so when we get our ideas more formalized and; bounce it back and forth a couple of times... then I'll do a more formal; writeup of our goals and ideas. Obviously our first implementation will; not want to do all of the stuff that I pointed out above... be we will; want to design the project so that we do not artificially limit ourselves; at sometime in the future... Anyways, let me know what you think about these ideas... and if they sound; reasonable... -Chris. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:8674,schedul,scheduling,8674,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['schedul'],['scheduling']
Energy Efficiency,"itoring.; With such approach, a ROOT-based application creates and regularly updates content of a ROOT file, which can be accessed via normal web server. From the browser side, JSROOT could regularly read the specified objects and update their drawings. But such solution has three major caveats. First of all, one need to store the data of all objects, which only potentially could be displayed in the browser. In case of 10 objects it does not matter, but for 1000 or 100000 objects this will be a major performance penalty. With such big amount of data one will never achieve higher update rate. The second problem is I/O. To read the first object from the ROOT file, one need to perform several (about 5) file-reading operations via http protocol.; There is no http file locking mechanism (at least not for standard web servers),; therefore there is no guarantee that the file content is not changed/replaced between consequent read operations. Therefore, one should expect frequent I/O failures while trying to monitor data from ROOT binary files. There is a workaround for the problem - one could load the file completely and exclude many partial I/O operations by this. To achieve this with JSROOT, one should add ""+"" sign at the end of the file name. Of course, it only could work for small files. If somebody still wants to use monitoring of data from ROOT files, could try link like:. - <https://root.cern/js/latest/?nobrowser&file=../files/hsimple.root+&item=hpx;1&monitoring=2000>. In this particular case, the histogram is not changing. ## JSROOT API. JSROOT can be used in arbitrary HTML pages to display data, produced with or without ROOT-based applications. Many different examples of JSROOT API usage can be found on [JSROOT API examples](https://root.cern/js/latest/api.htm) page. ### Import JSROOT functionality. Major JSROOT functions are located in `main.mjs` module and can be imported like:. ```javascript; <script type='module'>; import { openFile, draw } from 'https://root.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:33276,monitor,monitor,33276,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitor']
Energy Efficiency,"ity happens more often than; legalization and legalization can require multiple passes over the rules. As a concrete example, consider the rule::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0);. and the instruction::. %2:_(s7) = G_ADD %0:_(s7), %1:_(s7). this doesn't meet the predicate for the :ref:`.legalFor() <legalfor>` as ``s7``; is not one of the listed types so it falls through to the; :ref:`.clampScalar() <clampscalar>`. It does meet the predicate for this rule; as the type is smaller than the ``s32`` and this rule instructs the legalizer; to change type 0 to ``s32``. It then restarts from the top. This time it does; satisfy ``.legalFor()`` and the resulting output is::. %3:_(s32) = G_ANYEXT %0:_(s7); %4:_(s32) = G_ANYEXT %1:_(s7); %5:_(s32) = G_ADD %3:_(s32), %4:_(s32); %2:_(s7) = G_TRUNC %5:_(s32). where the ``G_ADD`` is legal and the other instructions are scheduled for; processing by the legalizer. Rule Actions; """""""""""""""""""""""". There are various rule factories that append rules to a ruleset but they have a; few actions in common:. .. _legalfor:. * ``legalIf()``, ``legalFor()``, etc. declare an instruction to be legal if the; predicate is satisfied. * ``narrowScalarIf()``, ``narrowScalarFor()``, etc. declare an instruction to be illegal; if the predicate is satisfied and indicates that narrowing the scalars in one; of the types to a specific type would make it more legal. This action supports; both scalars and vectors. * ``widenScalarIf()``, ``widenScalarFor()``, etc. declare an instruction to be illegal; if the predicate is satisfied and indicates that widening the scalars in one; of the types to a specific type would make it more legal. This action supports; both scalars and vectors. * ``fewerElementsIf()``, ``fewerElementsFor()``, etc. declare an instruction to be; illegal if the predicate is satisfied and indicates reducing th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:5905,schedul,scheduled,5905,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,1,['schedul'],['scheduled']
Energy Efficiency,"ity vulnerabilities, and the implementation uses many; of the same mechanisms. There are two types of bad cast that may be forbidden: bad casts; from a base class to a derived class (which can be checked with; ``-fsanitize=cfi-derived-cast``), and bad casts from a pointer of; type ``void*`` or another unrelated type (which can be checked with; ``-fsanitize=cfi-unrelated-cast``). The difference between these two types of casts is that the first is defined; by the C++ standard to produce an undefined value, while the second is not; in itself undefined behavior (it is well defined to cast the pointer back; to its original type) unless the object is uninitialized and the cast is a; ``static_cast`` (see C++14 [basic.life]p5). If a program as a matter of policy forbids the second type of cast, that; restriction can normally be enforced. However it may in some cases be necessary; for a function to perform a forbidden cast to conform with an external API; (e.g. the ``allocate`` member function of a standard library allocator). Such; functions may be :ref:`ignored <cfi-ignorelist>`. For this scheme to work, all translation units containing the definition; of a virtual member function (whether inline or not), other than members; of :ref:`ignored <cfi-ignorelist>` types or types with public :doc:`LTO; visibility <LTOVisibility>`, must be compiled with ``-flto`` or ``-flto=thin``; enabled and be statically linked into the program. Non-Virtual Member Function Call Checking; =========================================. This scheme checks that non-virtual calls take place using an object of; the correct dynamic type; that is, the dynamic type of the called object; must be a derived class of the static type of the object used to make the; call. The checks are currently only introduced where the object is of a; polymorphic class type. This CFI scheme can be enabled on its own using; ``-fsanitize=cfi-nvcall``. For this scheme to work, all translation units containing the definition; of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst:6577,allocate,allocate,6577,interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,1,['allocate'],['allocate']
Energy Efficiency,"iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42985,schedul,scheduled,42985,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"ive-C object pointer shall; not be converted to ``void*``. As an exception, cast to ``intptr_t`` is; allowed because such casts are not transferring ownership. The :ref:`bridged; casts <arc.objects.operands.casts>` may be used to perform these conversions; where necessary. .. admonition:: Rationale. We cannot ensure the correct management of the lifetime of objects if they; may be freely passed around as unmanaged types. The bridged casts are; provided so that the programmer may explicitly describe whether the cast; transfers control into or out of ARC. However, the following exceptions apply. .. _arc.objects.restrictions.conversion.with.known.semantics:. Conversion to retainable object pointer type of expressions with known semantics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. :when-revised:`[beginning Apple 4.0, LLVM 3.1]`; :revision:`These exceptions have been greatly expanded; they previously applied; only to a much-reduced subset which is difficult to categorize but which; included null pointers, message sends (under the given rules), and the various; global constants.`. An unbridged conversion to a retainable object pointer type from a type other; than a retainable object pointer type is ill-formed, as discussed above, unless; the operand of the cast has a syntactic form which is known retained, known; unretained, or known retain-agnostic. An expression is :arc-term:`known retain-agnostic` if it is:. * an Objective-C string literal,; * a load from a ``const`` system global variable of :ref:`C retainable pointer; type <arc.misc.c-retainable>`, or; * a null pointer constant. An expression is :arc-term:`known unretained` if it is an rvalue of :ref:`C; retainable pointer type <arc.misc.c-retainable>` and it is:. * a direct call to a function, and either that function has the; ``cf_returns_not_retained`` attribute or it is an :ref:`audited; <arc.misc.c-retainable.audit>` function that does not have the; ``cf_returns_retained`` ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:25599,reduce,reduced,25599,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['reduce'],['reduced']
Energy Efficiency,"iven subtarget (details vary).; - ``r``, ``d``, ``y``: A 32 or 64-bit GPR register.; - ``f``: A 32 or 64-bit FPU register (``F0-F31``), or a 128-bit MSA register; (``W0-W31``). In the case of MSA registers, it is recommended to use the ``w``; argument modifier for compatibility with GCC.; - ``c``: A 32-bit or 64-bit GPR register suitable for indirect jump (always; ``25``).; - ``l``: The ``lo`` register, 32 or 64-bit.; - ``x``: Invalid. NVPTX:. - ``b``: A 1-bit integer register.; - ``c`` or ``h``: A 16-bit integer register.; - ``r``: A 32-bit integer register.; - ``l`` or ``N``: A 64-bit integer register.; - ``f``: A 32-bit float register.; - ``d``: A 64-bit float register. PowerPC:. - ``I``: An immediate signed 16-bit integer.; - ``J``: An immediate unsigned 16-bit integer, shifted left 16 bits.; - ``K``: An immediate unsigned 16-bit integer.; - ``L``: An immediate signed 16-bit integer, shifted left 16 bits.; - ``M``: An immediate integer greater than 31.; - ``N``: An immediate integer that is an exact power of 2.; - ``O``: The immediate integer constant 0.; - ``P``: An immediate integer constant whose negation is a signed 16-bit; constant.; - ``es``, ``o``, ``Q``, ``Z``, ``Zy``: A memory address operand, currently; treated the same as ``m``.; - ``r``: A 32 or 64-bit integer register.; - ``b``: A 32 or 64-bit integer register, excluding ``R0`` (that is:; ``R1-R31``).; - ``f``: A 32 or 64-bit float register (``F0-F31``),; - ``v``: For ``4 x f32`` or ``4 x f64`` types, a 128-bit altivec vector; register (``V0-V31``). - ``y``: Condition register (``CR0-CR7``).; - ``wc``: An individual CR bit in a CR register.; - ``wa``, ``wd``, ``wf``: Any 128-bit VSX vector register, from the full VSX; register set (overlapping both the floating-point and vector register files).; - ``ws``: A 32 or 64-bit floating-point register, from the full VSX register; set. RISC-V:. - ``A``: An address operand (using a general-purpose register, without an; offset).; - ``I``: A 12-bit signed integ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:229727,power,power,229727,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ization features are compiled out of Release builds to; reduce file size. This means that you need a Debug+Asserts or Release+Asserts; build to use these features. .. _datastructure:. Picking the Right Data Structure for a Task; ===========================================. LLVM has a plethora of data structures in the ``llvm/ADT/`` directory, and we; commonly use STL data structures. This section describes the trade-offs you; should consider when you pick one. The first step is a choose your own adventure: do you want a sequential; container, a set-like container, or a map-like container? The most important; thing when choosing a container is the algorithmic properties of how you plan to; access the container. Based on that, you should use:. * a :ref:`map-like <ds_map>` container if you need efficient look-up of a; value based on another value. Map-like containers also support efficient; queries for containment (whether a key is in the map). Map-like containers; generally do not support efficient reverse mapping (values to keys). If you; need that, use two maps. Some map-like containers also support efficient; iteration through the keys in sorted order. Map-like containers are the most; expensive sort, only use them if you need one of these capabilities. * a :ref:`set-like <ds_set>` container if you need to put a bunch of stuff into; a container that automatically eliminates duplicates. Some set-like; containers support efficient iteration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not support; efficient look-up based on a key. * a :ref:`string <ds_string>` container is a specialized sequential container or; reference structure that is used for character or byte arrays. * a :ref:`bit ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:55592,efficient,efficient,55592,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"ization**; Basic-Block Vectorization. **BDCE**; Bit-tracking dead code elimination. Some bit-wise instructions (shifts,; ands, ors, etc.) ""kill"" some of their input bits -- that is, they make it; such that those bits can be either zero or one without affecting control or; data flow of a program. The BDCE pass removes instructions that only; compute these dead bits. **BURS**; Bottom Up Rewriting System --- A method of instruction selection for code; generation. An example is the `BURG; <http://www.program-transformation.org/Transform/BURG>`_ tool. C; -. **CFI**; This abbreviation has two meanings.; Either:; Call Frame Information. Used in DWARF debug info and in C++ unwind info; to show how the function prolog lays out the stack frame. Or:; Control Flow Integrity. A general term for computer security techniques; that prevent a wide variety of malware attacks from redirecting the flow; of execution (the control flow) of a program. **CIE**; Common Information Entry. A kind of CFI used to reduce the size of FDEs.; The compiler creates a CIE which contains the information common across all; the FDEs. Each FDE then points to its CIE. **CSE**; Common Subexpression Elimination. An optimization that removes common; subexpression computation. For example ``(a+b)*(a+b)`` has two; subexpressions that are the same: ``(a+b)``. This optimization would; perform the addition only once and then perform the multiply (but only if; it's computationally correct/safe). D; -. **DAG**; Directed Acyclic Graph. .. _derived pointer:; .. _derived pointers:. **Derived Pointer**; A pointer to the interior of an object, such that a garbage collector is; unable to use the pointer for reachability analysis. While a derived pointer; is live, the corresponding object pointer must be kept in a root, otherwise; the collector might free the referenced object. With copying collectors,; derived pointers pose an additional hazard that they may be invalidated at; any `safe point`_. This term is used in opposi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst:1882,reduce,reduce,1882,interpreter/llvm-project/llvm/docs/Lexicon.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst,1,['reduce'],['reduce']
Energy Efficiency,"jects must be of the same class. For; the rest this class has the same properties as a **`TObjArray`**. ![The internal data structure of a TClonesArray](pictures/020001A8.jpg). The figure above shows the internal data structure of a; **`TClonesArray`**. The class is specially designed for repetitive data; analysis tasks, where in a loop many times the same objects, are created; and deleted. The only supported way to add objects to a; **`TClonesArray`** is via the `new` with placement method. The different; `Add()` methods of **`TObjArray`** and its base classes are not; supported. ### The Idea Behind TClonesArray. To reduce the very large number of new and delete calls in large loops; like this (O(100000) x O(10000) times new/delete):. ``` {.cpp}; TObjArray a(10000);; while (TEvent *ev = (TEvent *)next()) { // O(100000); for (int i = 0; i < ev->Ntracks; i++) { // O(10000); a[i] = new TTrack(x,y,z,...);; ...; }; ...; a.Delete();; }; ```. You better use a **`TClonesArray`** which reduces the number of; new/delete calls to only O(10000):. ``` {.cpp}; TClonesArray a(""TTrack"", 10000);; while (TEvent *ev = (TEvent *)next()) { // O(100000); for (int i = 0; i < ev->Ntracks; i++) { // O(10000); TTrack *track = (Track*)a.ConstructedAt(i);; track->Set(x,y,z,...);; ...; }; ...; a.Clear(); // Or Clear(""C"") if the track objects must be returned (via Track::Clear) to a default state.; }; ```. Considering that a pair of new/delete calls on average cost about 70 ms,; O(109) new/deletes will save about 19 hours. For the other collections,; see the class reference guide on the web and the test program; `$ROOTSYS/test/tcollex.cxx.`. ## Template Containers and STL. Some people dislike polymorphic containers because they are not truly; ""type safe"". In the end, the compiler leaves it the user to ensure that; the types are correct. This only leaves the other alternative: creating; a new class each time a new (container organization) / (contained; object) combination is needed. To say the le",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md:17293,reduce,reduces,17293,documentation/users-guide/CollectionClasses.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md,1,['reduce'],['reduces']
Energy Efficiency,"jects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.frame(Title(""Profile likelihood in parameter a"")) ;; pll->plotOn(framea) ;. // Construct 2D cumulative distribution function from p.d.f.; RooAbsReal* cdfxy = w::model.createCdf(RooArgSet(w::x,w::y),ScanNoCdf()) ;; TH2* hhcdf = cdfxy->createHistogram(""x,y"",40,40) ;; hhcdf->SetLineColor(kRed) ;. TCanvas* c = new TCanvas(""c"",""c"",650,650) ; c->Divide(2,2) ;; c->cd(1) ; hh->Draw(""surf"") ; c->cd(2) ; framex->Draw() ;; c->cd(3) ; f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22699,adapt,adaptive,22699,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,['adapt'],['adaptive']
Energy Efficiency,"k; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent submodule updates to a particular local; commit in the project mirror. ``UM3`` in this case is a commit of; some local umbrella repository state that is not a submodule update,; perhaps a ``README`` or project build script update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 <-'. The ``U*`` commits represent upstream commits to the monorepo main; branch. Each submodule update in the local ``UM*`` commits brought in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree *earlier* in the upstream clang history. We want the; ``local/zip`` branch to accurately represent the state of our umbrella; h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:24919,green,greened,24919,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['green'],['greened']
Energy Efficiency,"k` and; `Generator` are commonly referred to coroutine types. coroutine; ---------. By technical definition, a `coroutine` is a suspendable function. However,; programmers typically use `coroutine` to refer to an individual instance.; For example:. .. code-block:: c++. std::vector<Task> Coros; // Task is a coroutine type.; for (int i = 0; i < 3; i++); Coros.push_back(CoroTask()); // CoroTask is a coroutine function, which; // would return a coroutine type 'Task'. In practice, we typically say ""`Coros` contains 3 coroutines"" in the above; example, though this is not strictly correct. More technically, this should; say ""`Coros` contains 3 coroutine instances"" or ""Coros contains 3 coroutine; objects."". In this document, we follow the common practice of using `coroutine` to refer; to an individual `coroutine instance`, since the terms `coroutine instance` and; `coroutine object` aren't sufficiently defined in this case. coroutine frame; ---------------. The C++ Standard uses `coroutine state` to describe the allocated storage. In; the compiler, we use `coroutine frame` to describe the generated data structure; that contains the necessary information. The structure of coroutine frames; =================================. The structure of coroutine frames is defined as:. .. code-block:: c++. struct {; void (*__r)(); // function pointer to the `resume` function; void (*__d)(); // function pointer to the `destroy` function; promise_type; // the corresponding `promise_type`; ... // Any other needed information; }. In the debugger, the function's name is obtainable from the address of the; function. And the name of `resume` function is equal to the name of the; coroutine function. So the name of the coroutine is obtainable once the; address of the coroutine is known. Print promise_type; ==================. Every coroutine has a `promise_type`, which defines the behavior; for the corresponding coroutine. In other words, if two coroutines have the; same `promise_type`, they shoul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst:2530,allocate,allocated,2530,interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,1,['allocate'],['allocated']
Energy Efficiency,"kend was removed from the; trunk since LLVM 3.1 release. Another example of a code generator like this is a; (purely hypothetical) backend that converts LLVM to the GCC RTL form and uses; GCC to emit machine code for a target. This design also implies that it is possible to design and implement radically; different code generators in the LLVM system that do not make use of any of the; built-in components. Doing so is not recommended at all, but could be required; for radically different targets that do not fit into the LLVM machine; description model: FPGAs for example. .. _high-level design of the code generator:. The high-level design of the code generator; -------------------------------------------. The LLVM target-independent code generator is designed to support efficient and; quality code generation for standard register-based microprocessors. Code; generation in this model is divided into the following stages:. 1. `Instruction Selection`_ --- This phase determines an efficient way to; express the input LLVM code in the target instruction set. This stage; produces the initial code for the program in the target instruction set, then; makes use of virtual registers in SSA form and physical registers that; represent any required register assignments due to target constraints or; calling conventions. This step turns the LLVM code into a DAG of target; instructions. 2. `Scheduling and Formation`_ --- This phase takes the DAG of target; instructions produced by the instruction selection phase, determines an; ordering of the instructions, then emits the instructions as :raw-html:`<tt>`; `MachineInstr`_\s :raw-html:`</tt>` with that ordering. Note that we; describe this in the `instruction selection section`_ because it operates on; a `SelectionDAG`_. 3. `SSA-based Machine Code Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-schedul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:5225,efficient,efficient,5225,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['efficient'],['efficient']
Energy Efficiency,"l Attribute Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-attribute-metadata-map-v2-table. =================== ============== ========= ==============================; String Key Value Type Required? Description; =================== ============== ========= ==============================; ""ReqdWorkGroupSize"" sequence of If not 0, 0, 0 then all values; 3 integers must be >=1 and the dispatch; work-group size X, Y, Z must; correspond to the specified; values. Defaults to 0, 0, 0. Corresponds to the OpenCL; ``reqd_work_group_size``; attribute.; ""WorkGroupSizeHint"" sequence of The dispatch work-group size; 3 integers X, Y, Z is likely to be the; specified values. Corresponds to the OpenCL; ``work_group_size_hint``; attribute.; ""VecTypeHint"" string The name of a scalar or vector; type. Corresponds to the OpenCL; ``vec_type_hint`` attribute. ""RuntimeHandle"" string The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; =================== ============== ========= ==============================. .. .. table:: AMDHSA Code Object V2 Kernel Argument Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-argument-metadata-map-v2-table. ================= ============== ========= ================================; String Key Value Type Required? Description; ================= ============== ========= ================================; ""Name"" string Kernel argument name.; ""TypeName"" string Kernel argument type name.; ""Size"" integer Required Kernel argument size in bytes.; ""Align"" integer Required Kernel argument alignment in; bytes. Must be a power of two.; ""ValueKind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""ByValue""; The argument is copied; directly into the kernarg. ""GlobalBuffer""; A global address space pointer; t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:122664,allocate,allocates,122664,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocates']
Energy Efficiency,"l be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6886,efficient,efficient,6886,roofit/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html,2,['efficient'],['efficient']
Energy Efficiency,"l it to write; out a profile. This function returns 0 when it succeeds, and a non-zero value; otherwise. Calling this function multiple times appends profile data to an; existing on-disk raw profile. In C++ files, declare these as ``extern ""C""``. Using the profiling runtime without a filesystem; ------------------------------------------------. The profiling runtime also supports freestanding environments that lack a; filesystem. The runtime ships as a static archive that's structured to make; dependencies on a hosted environment optional, depending on what features; the client application uses. The first step is to export ``__llvm_profile_runtime``, as above, to disable; the default static initializers. Instead of calling the ``*_file()`` APIs; described above, use the following to save the profile directly to a buffer; under your control:. * Forward-declare ``uint64_t __llvm_profile_get_size_for_buffer(void)`` and; call it to determine the size of the profile. You'll need to allocate a; buffer of this size. * Forward-declare ``int __llvm_profile_write_buffer(char *Buffer)`` and call it; to copy the current counters to ``Buffer``, which is expected to already be; allocated and big enough for the profile. * Optionally, forward-declare ``void __llvm_profile_reset_counters(void)`` and; call it to reset the counters before entering a specific section to be; profiled. This is only useful if there is some setup that should be excluded; from the profile. In C++ files, declare these as ``extern ""C""``. Collecting coverage reports for the llvm project; ================================================. To prepare a coverage report for llvm (and any of its sub-projects), add; ``-DLLVM_BUILD_INSTRUMENTED_COVERAGE=On`` to the cmake configuration. Raw; profiles will be written to ``$BUILD_DIR/profiles/``. To prepare an html; report, run ``llvm/utils/prepare-code-coverage-artifact.py``. To specify an alternate directory for raw profiles, use; ``-DLLVM_PROFILE_DATA_DIR``. To change",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:17395,allocate,allocate,17395,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['allocate'],['allocate']
Energy Efficiency,"l on the efficiencies. For each statistical; option a corresponding static function esists taking as parameters; n, the number of total events, k, the number of; passed events and cl the desired confidence level and a; boolean flag specyfing if the upper (or lower) interval boundary; must be computed. Each statistics option can be set using the method; TEfficiency::SetStatisticOption; The major statistics options are (see class; documentation for a full description and examples):; ; Clopper_pearson (default) using the function; TEfficiency::ClopperPearson(n, k, cl). Bayesian methods using the function; TEfficiency::Bayesian(n, k, cl, alpha, beta).; In this case the alpha and beta parameters of the; beta prior distribution for the efficiency can be specified.; . Merging and combining different TEfficiency objects is; supported; (see the class; documentation):; . New TKDE class. New class for Kernel density estimation from Bartolomeu; Rabacal. The algorithm used is described in ""Cranmer KS, Kernel Estimation in High-Energy; Physics. Computer Physics Communications 136:198-207,2001"" -; e-Print Archive: hep ex/0011057 and more information can be found; also in ""Scott DW, Multivariate Density Estimation. Theory, Practice and Visualization. New York: Wiley"",; and ""Jann Ben -, Univariate kernel; density estimation document for KDENS "".; . New TSVDUnfold class; TSVDUnfold implements the singular value decomposition based; unfolding method proposed in NIM A372, 469 (1996); [hep-ph/9509307]. The regularisation is implemented as; a discrete minimum curvature condition. This minimal implementation of; TSVDUnfold provides unfolding of one-dimensional histograms with; equal number of, not necessarily equidistant, bins in the measured and; unfolded distributions. In addition to the unfolding itself,; TSVDUnfold provides. Propagation of covariance matrices from the measured to the unfolded; spectrum via GetUnfoldCovMatrix; Evaluation of covariance matrix due to finite statistics in ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v528/index.html:11239,Energy,Energy,11239,hist/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v528/index.html,1,['Energy'],['Energy']
Energy Efficiency,"l other options, such as std::multiset and; std::unordered_set. We never use containers like unordered_set because; they are generally very expensive (each insertion requires a malloc). std::multiset is useful if you're not interested in elimination of duplicates,; but has all the drawbacks of :ref:`std::set <dss_set>`. A sorted vector; (where you don't delete duplicate entries) or some other approach is almost; always better. .. _ds_map:. Map-Like Containers (std::map, DenseMap, etc); ---------------------------------------------. Map-like containers are useful when you want to associate data to a key. As; usual, there are a lot of different ways to do this. :). .. _dss_sortedvectormap:. A sorted 'vector'; ^^^^^^^^^^^^^^^^^. If your usage pattern follows a strict insert-then-query approach, you can; trivially use the same approach as :ref:`sorted vectors for set-like containers; <dss_sortedvectorset>`. The only difference is that your query function (which; uses std::lower_bound to get efficient log(n) lookup) should only compare the; key, not both the key and value. This yields the same advantages as sorted; vectors for sets. .. _dss_stringmap:. llvm/ADT/StringMap.h; ^^^^^^^^^^^^^^^^^^^^. Strings are commonly used as keys in maps, and they are difficult to support; efficiently: they are variable length, inefficient to hash and compare when; long, expensive to copy, etc. StringMap is a specialized container designed to; cope with these issues. It supports mapping an arbitrary range of bytes to an; arbitrary other object. The StringMap implementation uses a quadratically-probed hash table, where the; buckets store a pointer to the heap allocated entries (and some other stuff).; The entries in the map must be heap allocated because the strings are variable; length. The string data (key) and the element object (value) are stored in the; same allocation with the string data immediately after the element object.; This container guarantees the ""``(char*)(&Value+1)``"" poi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:88262,efficient,efficient,88262,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"l variables that can be shared in the parallel regions; are stored in the global memory. In `Cuda` mode local variables are not shared; between the threads and it is user responsibility to share the required data; between the threads in the parallel regions. Often, the optimizer is able to; reduce the cost of `Generic` mode to the level of `Cuda` mode, but the flag,; as well as other assumption flags, can be used for tuning. Features not supported or with limited support for Cuda devices; ---------------------------------------------------------------. - Cancellation constructs are not supported. - Doacross loop nest is not supported. - User-defined reductions are supported only for trivial types. - Nested parallelism: inner parallel regions are executed sequentially. - Debug information for OpenMP target regions is supported, but sometimes it may; be required to manually specify the address class of the inspected variables.; In some cases the local variables are actually allocated in the global memory,; but the debug info may be not aware of it. .. _OpenMP implementation details:. OpenMP 5.0 Implementation Details; =================================. The following table provides a quick overview over various OpenMP 5.0 features; and their implementation status. Please post on the; `Discourse forums (Runtimes - OpenMP category)`_ for more; information or if you want to help with the; implementation. +------------------------------+--------------------------------------------------------------+--------------------------+-----------------------------------------------------------------------+; |Category | Feature | Status | Reviews |; +==============================+==============================================================+==========================+=======================================================================+; | loop | support != in the canonical loop form | :good:`done` | D54441 |; +------------------------------+--------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst:2762,allocate,allocated,2762,interpreter/llvm-project/clang/docs/OpenMPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst,1,['allocate'],['allocated']
Energy Efficiency,"l). One of; the first requirements is its header files to be self-contained (section ""Missing; Includes""). ROOT header files were cleaned up from extra includes and the missing; includes were added. This could be considered as backward incompatibility (for good however). User; code may need to add extra includes, which were previously resolved indirectly; by including a ROOT header. For example:. * TBuffer.h - TObject.h doesn't include TBuffer.h anymore. Third party code,; replying on the definition of TBufer will need to include TBuffer.h, along; with TObject.h.; * TSystem.h - for some uses of gSystem.; * GeneticMinimizer.h; * ... Other improvements, which may cause compilation errors in third party code:. * If you get `std::type_info` from Rtypeinfo.h, `type_info` should be spelled; `std::type_info`. Also:. * `TPluginManager` was made thread-safe [ROOT-7927].; * On MacOSX, backtraces are now generated without external tools [ROOT-6667].; * The set of include paths considered by the interpreter has been reduced to the bare minimum. ### Containers. * A pseudo-container (generator) was created, `ROOT::TSeq<T>`. This template is inspired by the xrange built-in function of Python. See the example [here](https://root.cern.ch/doc/master/cnt001__basictseq_8C.html). ### Meta Library. Add a new mode for `TClass::SetCanSplit` (2) which indicates that this class and any derived class should not be split. This included a rework the mechanism checking the base classes. Instead of using `InheritsFrom`, which lead in some cases, including the case where the class derived from an STL collection, to spurrious autoparsing (to look at the base class of the collection!), we use a custom walk through the tree of base classes that checks their value of `fCanSplit`. This also has the side-effect of allowing the extension of the concept 'base class that prevent its derived class from being split' to any user class. This fixes [ROOT-7972]. ### Dictionaries. * Add the -excludePath option to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:3168,reduce,reduced,3168,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['reduce'],['reduced']
Energy Efficiency,"l. VarTransform No None âˆ’ List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False âˆ’ Print method-specific help message. CreateMVAPdfs No False âˆ’ Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False âˆ’ Events with negative weights are ignored in the training (but are included for testing and performance evaluation). TrainingMethod No BP BP, GA, BFGS Train with Back-Propagation (BP), BFGS Algorithm (BFGS), or Genetic Algorithm (GA - slower and worse). LearningRate No 0.02 âˆ’ ANN learning rate parameter. DecayRate No 0.01 âˆ’ Decay rate for learning parameter. TestRate No 10 âˆ’ Test for overtraining performed at each #th epochs. EpochMonitoring No False âˆ’ Provide epoch-wise monitoring plots according to TestRate (caution: causes big ROOT output file!). Sampling No 1 âˆ’ Only 'Sampling' (randomly selected) events are trained each epoch. SamplingEpoch No 1 âˆ’ Sampling is used for the first 'SamplingEpoch' epochs, afterwards, all events are taken for training. SamplingImportance No 1 âˆ’ The sampling weights of events in epochs which successful (worse estimator than before) are multiplied with SamplingImportance, else they are divided. SamplingTraining No True âˆ’ The training sample is sampled. SamplingTesting No False âˆ’ The testing sample is sampled. ResetStep No 50 âˆ’ How often BFGS should reset history. Tau No 3 âˆ’ LineSearch size step. BPMode No sequential sequential, batch Back-propagation learning mode: sequential or batch. BatchSize No -1 âˆ’ Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events. ConvergenceImprove No 1e-30 âˆ’ Minimum improvement which counts as improvement (<0 means automatic convergence check is turned off). Converge",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:22615,monitor,monitoring,22615,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['monitor'],['monitoring']
Energy Efficiency,"l4) == 1. bool4 foo(bool4 a) {; bool4 v;; v = a;; return v;; }. Boolean vectors are a Clang extension of the ext vector type. Boolean vectors; are intended, though not guaranteed, to map to vector mask registers. The size; parameter of a boolean vector type is the number of bits in the vector. The; boolean vector is dense and each bit in the boolean vector is one vector; element. The semantics of boolean vectors borrows from C bit-fields with the following; differences:. * Distinct boolean vectors are always distinct memory objects (there is no; packing).; * Only the operators `?:`, `!`, `~`, `|`, `&`, `^` and comparison are allowed on; boolean vectors.; * Casting a scalar bool value to a boolean vector type means broadcasting the; scalar value onto all lanes (same as general ext_vector_type).; * It is not possible to access or swizzle elements of a boolean vector; (different than general ext_vector_type). The size and alignment are both the number of bits rounded up to the next power; of two, but the alignment is at most the maximum vector alignment of the; target. Vector Literals; ---------------. Vector literals can be used to create vectors from a set of scalars, or; vectors. Either parentheses or braces form can be used. In the parentheses; form the number of literal values specified must be one, i.e. referring to a; scalar value, or must match the size of the vector type being created. If a; single scalar literal value is specified, the scalar literal value will be; replicated to all the components of the vector type. In the brackets form any; number of literals can be specified. For example:. .. code-block:: c++. typedef int v4si __attribute__((__vector_size__(16)));; typedef float float4 __attribute__((ext_vector_type(4)));; typedef float float2 __attribute__((ext_vector_type(2)));. v4si vsi = (v4si){1, 2, 3, 4};; float4 vf = (float4)(1.0f, 2.0f, 3.0f, 4.0f);; vector int vi1 = (vector int)(1); // vi1 will be (1, 1, 1, 1).; vector int vi2 = (vector int){1}; //",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:17692,power,power,17692,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['power'],['power']
Energy Efficiency,"l>`) of the; vector operand ``val`` on each enabled lane, multiplying it by the scalar; `start_value``. Disabled lanes are treated as containing the neutral value; ``1.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to the starting value. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fmul; <int_vector_reduce_fmul>`) for more detail on the semantics. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmul.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float 1.0, float 1.0, float 1.0, float 1.0>; %also.r = call float @llvm.vector.reduce.fmul.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_and:. '``llvm.vp.reduce.and.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.and.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:756674,reduce,reduce,756674,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"lag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fmul operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fmul(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result * input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, one (``1.0``) can be used, as it is the neutral; value of floating point multiplication. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fmul.v4f32(float 1.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_and:. '``llvm.vector.reduce.and.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scala",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:654766,reduce,reduce,654766,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"lane if it is not; active (namely it is divergent). The DWARF operation expression for each region; conceptually inherits the value of the immediately enclosing region and modifies; it according to the semantics of the region. For an ``IF/THEN/ELSE`` region the divergent program location is at the start of; the region for the ``THEN`` region since it is executed first. For the ``ELSE``; region the divergent program location is at the end of the ``IF/THEN/ELSE``; region since the ``THEN`` region has completed. The lane PC artificial variable is assigned at each region transition. It uses; the immediately enclosing region's DWARF procedure to compute the program; location for each lane assuming they are divergent, and then modifies the result; by inserting the current program location for each lane that the ``EXEC`` mask; indicates is active. By having separate DWARF procedures for each region, they can be reused to; define the value for any nested region. This reduces the total size of the DWARF; operation expressions. The following provides an example using pseudo LLVM MIR. .. code::; :number-lines:. $lex_start:; DEFINE_DWARF %__uint_64 = DW_TAG_base_type[; DW_AT_name = ""__uint64"";; DW_AT_byte_size = 8;; DW_AT_encoding = DW_ATE_unsigned;; ];; DEFINE_DWARF %__active_lane_pc = DW_TAG_dwarf_procedure[; DW_AT_name = ""__active_lane_pc"";; DW_AT_location = [; DW_OP_regx PC;; DW_OP_LLVM_extend 64, 64;; DW_OP_regval_type EXEC, %uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DEFINE_DWARF %__divergent_lane_pc = DW_TAG_dwarf_procedure[; DW_AT_name = ""__divergent_lane_pc"";; DW_AT_location = [; DW_OP_LLVM_undefined;; DW_OP_LLVM_extend 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; a;; %1 = EXEC;; DBG_VALUE %1, $noreg, %__lex_1_save_exec;; %2 = c1;; $lex_1_start:; EXEC = %1 & %2;; $lex_1_then:; DEFINE_DWARF %__divergent_lane_pc_1_then = DW_TAG_dwarf_procedure[; DW_AT",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:104162,reduce,reduces,104162,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['reduce'],['reduces']
Energy Efficiency,"lass object;; TBranch *branch = tree->Branch(branchname, &object, bufsize, splitlevel); Clarify the ownership rules of user objects in a TTree. This clarification (and the improved auto-add-to-directory behavior; of the TH1*) allows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 =",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:1222,allocate,allocated,1222,tree/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html,2,['allocate'],['allocated']
Energy Efficiency,"lass.; ```{.cpp}; // create the adaptive integrator with the 51 point rule; ROOT::Math::GSLIntegrator ig(ROOT::Math::Integration::kADAPTIVE, ROOT::Math::Integration::kGAUSS51);; ig.SetRelTolerance(1.E-6); // set relative tolerance; ig.SetAbsTolerance(1.E-6); // set absoulte tolerance; ```. The algorithm is controlled by the given absolute and relative tolerance. The iterations are continued until the following condition is satisfied; $$; absErr <= max ( epsAbs, epsRel * Integral); $$; Where *absErr* is an estimate of the absolute error (it can be retrieved with `GSLIntegrator::Error()`) and *Integral* is the estimate of the function integral; (it can be obtained with `GSLIntegrator::Result()`). The possible integration algorithm types to use with the GSLIntegrator are the following. More information is provided in the `GSL` users documentation.; * `ROOT::Math::Integration::kNONADAPTIVE` : based on `gsl_integration_qng`. It is a non-adaptive procedure which uses fixed Gauss-Kronrod-Patterson abscissae; to sample the integrand at a maximum of 87 points. It is provided for fast integration of smooth functions.; * `ROOT::Math::Integration::kADAPTIVE`: based on `gsl_integration_qag`. It is an adaptiva Gauss-Kronrod integration algorithm, the integration region is divided into subintervals, and on each; iteration the subinterval with the largest estimated error is bisected. It is possible to specify the integration rule as an extra enumeration parameter. The possible rules are; * `Integration::kGAUSS15` : 15 points Gauss-Konrod rule (value = 1); * `Integration::kGAUSS21` : 21 points Gauss-Konrod rule (value = 2); * `Integration::kGAUSS31` : 31 points Gauss-Konrod rule (value = 3); * `Integration::kGAUSS41` : 41 points Gauss-Konrod rule (value = 4); * `Integration::kGAUSS51` : 51 points Gauss-Konrod rule (value = 5); * `Integration::kGAUSS61` : 61 points Gauss-Konrod rule (value = 6); 	 The higher-order rules give better accuracy for smooth functions, while lower-order rul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:56292,adapt,adaptive,56292,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['adapt'],['adaptive']
Energy Efficiency,"lated dylib is allocated within; 4Gb). Finally, it is natural to make the memory manager responsible for; transferring memory to the target address space and applying memory protections,; since the memory manager must know how to communicate with the executor, and; since sharing and protection assignment can often be efficiently managed (in; the common case of running across processes on the same machine for security); via the host operating system's virtual memory management APIs. To satisfy these requirements ``JITLinkMemoryManager`` adopts the following; design: The memory manager itself has just two virtual methods for asynchronous; operations (each with convenience overloads for calling synchronously):. .. code-block:: c++. /// Called when allocation has been completed.; using OnAllocatedFunction =; unique_function<void(Expected<std::unique_ptr<InFlightAlloc>)>;. /// Called when deallocation has completed.; using OnDeallocatedFunction = unique_function<void(Error)>;. /// Call to allocate memory.; virtual void allocate(const JITLinkDylib *JD, LinkGraph &G,; OnAllocatedFunction OnAllocated) = 0;. /// Call to deallocate memory.; virtual void deallocate(std::vector<FinalizedAlloc> Allocs,; OnDeallocatedFunction OnDeallocated) = 0;. The ``allocate`` method takes a ``JITLinkDylib*`` representing the target; simulated dylib, a reference to the ``LinkGraph`` that must be allocated for,; and a callback to run once an ``InFlightAlloc`` has been constructed.; ``JITLinkMemoryManager`` implementations can (optionally) use the ``JD``; argument to manage a per-simulated-dylib memory pool (since code model; constraints are typically imposed on a per-dylib basis, and not across; dylibs) [2]_. The ``LinkGraph`` describes the object file that we need to; allocate memory for. The allocator must allocate working memory for all of; the Blocks defined in the graph, assign address space for each Block within the; executing processes memory, and update the Blocks' addresses to reflect t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:27062,allocate,allocate,27062,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocate']
Energy Efficiency,"lding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyon",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43059,schedul,scheduled,43059,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"le ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.array_delete**: an interface on top of C++'s ``delete[]``.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.array_delete(arr); >>>. `argc/argv`; -----------. C/C++'s ``main`` function can take the number of command line arguments; (``argc``) and their values (``argv``) as function arguments.; A common idiom has these values subsequently passed on to the entry point of; e.g. a framework or library.; Since the type of ``argv`` in particular (``char*[]``) is clunky to work with; in Python, the low level module contains two convenient helper functions,; ``ll.argc()`` and ``ll.argv()``, that convert the command line arguments as; provided by Python's ``sys`` module, into typed values that are can be passed; to by C/C++. .. _`ctypes module`: https://docs.python.org/3/library/ctypes.html; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:10748,allocate,allocates,10748,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,1,['allocate'],['allocates']
Energy Efficiency,"le location is used. It may be possible to use existing DWARF to incrementally build the composite; location description, possibly using the DWARF operations for control flow to; create a loop. However, for the AMDGPU that would require loop iteration of 64.; A concern is that the resulting DWARF would have a significant size and would be; reasonably common as it is needed for every vector register that is spilled in a; function. AMDGPU can have up to 512 vector registers. Another concern is the; time taken to evaluate such non-trivial expressions repeatedly. To avoid these issues, a composite location description that can be created as a; masked select is proposed. In addition, an operation that creates a composite; location description that is a vector on another location description is needed.; These operations generate the composite location description using a single; DWARF operation that combines all lanes of the vector in one step. The DWARF; expression is more compact, and can be evaluated by a consumer far more; efficiently. An example that uses these operations is referenced in the; :ref:`amdgpu-dwarf-further-examples` appendix. See ``DW_OP_LLVM_select_bit_piece`` and ``DW_OP_LLVM_extend`` in; :ref:`amdgpu-dwarf-composite-location-description-operations`. 2.11 DWARF Operation to Access Call Frame Entry Registers; ---------------------------------------------------------. As described in; :ref:`amdgpu-dwarf-operation-to-create-vector-composite-location-descriptions`,; a DWARF expression involving the set of SIMT lanes active on entry to a; subprogram is required. The SIMT active lane mask may be held in a register that; is modified as the subprogram executes. However, its value may be saved on entry; to the subprogram. The Call Frame Information (CFI) already encodes such register saving, so it is; more efficient to provide an operation to return the location of a saved; register than have to generate a loclist to describe the same information. This; is now ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:26631,efficient,efficiently,26631,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['efficient'],['efficiently']
Energy Efficiency,"le:. .. code-block:: c++. Instruction *I = .. ;; I->eraseFromParent();. This unlinks the instruction from its containing basic block and deletes it. If; you'd just like to unlink the instruction from its containing basic block but; not delete it, you can use the ``removeFromParent()`` method. .. _schanges_replacing:. Replacing an Instruction with another Value; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Replacing individual instructions; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Including ""`llvm/Transforms/Utils/BasicBlockUtils.h; <https://llvm.org/doxygen/BasicBlockUtils_8h_source.html>`_"" permits use of two; very useful replace functions: ``ReplaceInstWithValue`` and; ``ReplaceInstWithInst``. .. _schanges_deleting_sub:. Deleting Instructions; """""""""""""""""""""""""""""""""""""""""". * ``ReplaceInstWithValue``. This function replaces all uses of a given instruction with a value, and then; removes the original instruction. The following example illustrates the; replacement of the result of a particular ``AllocaInst`` that allocates memory; for a single integer with a null pointer to an integer. .. code-block:: c++. AllocaInst* instToReplace = ...;; BasicBlock::iterator ii(instToReplace);. ReplaceInstWithValue(ii, Constant::getNullValue(PointerType::getUnqual(Type::Int32Ty)));. * ``ReplaceInstWithInst``. This function replaces a particular instruction with another instruction,; inserting the new instruction into the basic block at the location where the; old instruction was, and replacing any uses of the old instruction with the; new instruction. The following example illustrates the replacement of one; ``AllocaInst`` with another. .. code-block:: c++. AllocaInst* instToReplace = ...;; BasicBlock::iterator ii(instToReplace);. ReplaceInstWithInst(instToReplace->getParent(), ii,; new AllocaInst(Type::Int32Ty, 0, ""ptrToReplacedInt""));. Replacing multiple uses of Users and Values; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". You can use ``Value::replaceAllUsesWith`` and ``User::replaceUsesOfWit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:119200,allocate,allocates,119200,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocates']
Energy Efficiency,"le; are interested in and watching the flow of the project as a whole. Contibutions to the project are made through :ref:`GitHub Pull Requests <github-reviews>`.; You can subscribe to notification for areas of the codebase by joining; one of the `pr-subscribers-* <https://github.com/orgs/llvm/teams?query=pr-subscribers>`_; GitHub teams. This `mapping <https://github.com/llvm/llvm-project/blob/main/.github/new-prs-labeler.yml>`_; indicates which team is associated with a particular paths in the repository. You can also subscribe to the ""commits"" mailing list for a subproject you're interested in,; such as `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_, `cfe-commits; <http://lists.llvm.org/mailman/listinfo/cfe-commits>`_, or `lldb-commits; <http://lists.llvm.org/mailman/listinfo/lldb-commits>`_. Missing features and bugs are tracked through our `GitHub issue tracker <https://github.com/llvm/llvm-project/issues>`_; and assigned labels. We recommend that active developers monitor incoming issues.; You can subscribe for notification for specific components by joining; one of the `issue-subscribers-* <https://github.com/orgs/llvm/teams?query=issue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLV",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:3015,monitor,monitor,3015,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['monitor'],['monitor']
Energy Efficiency,"leases. Annual Release Schedule; -----------------------. Here is the annual release schedule for LLVM. This is meant to be a; guide, and release managers are not required to follow this exactly.; Releases should be tagged on Tuesdays. =============================== =========================; Release Approx. Date; =============================== =========================; *release branch: even releases* *4th Tue in January*; *release branch: odd releases* *4th Tue in July*; X.1.0-rc1 3 days after branch.; X.1.0-rc2 2 weeks after branch.; X.1.0-rc3 4 weeks after branch; **X.1.0-final** **6 weeks after branch**; **X.1.1** **8 weeks after branch**; **X.1.2** **10 weeks after branch**; **X.1.3** **12 weeks after branch**; **X.1.4** **14 weeks after branch**; **X.1.5** **16 weeks after branch**; **X.1.6 (if necessary)** **18 weeks after branch**; =============================== =========================. Release Process Summary; -----------------------. * Announce release schedule to the LLVM community and update the website. Do; this at least 3 weeks before the -rc1 release. * Create release branch and begin release process. * Send out release candidate sources for first round of testing. Testing lasts; 6 weeks. During the first round of testing, any regressions found should be; fixed. Patches are merged from mainline into the release branch. Also, all; features need to be completed during this time. Any features not completed at; the end of the first round of testing will be removed or disabled for the; release. * Generate and send out the second release candidate sources. Only *critical*; bugs found during this testing phase will be fixed. Any bugs introduced by; merged patches will be fixed. If so a third round of testing is needed. * The release notes are updated. * Finally, release!. * Announce bug fix release schedule to the LLVM community and update the website. * Do bug-fix releases every two weeks until X.1.5 or X.1.6 (if necessary). Release Process; =========",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:2090,schedul,schedule,2090,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['schedul'],['schedule']
Energy Efficiency,"lections), significantly increasing the speed; and the memory footprint when the number of datasets is very large.; Accept '.' in user names.; Add switch to control caching of the files read on MacOsX. A call to; fcntl(fd, F_NOCACHE, 1) is done after opening the file.; Add export of the envs ROOTPROOFCLIENT and ROOTPROOFLITE when; appropriate. These allow to steer building and/or enabling of PAR files; in PROOF-INF/BUILD.sh and/or PROOF-INF/SETUP.C, improving transparency; between normal ROOT and PROOF. The example PAR; 'tutorials/proof/event.par' has been modified to check the two; variables.; Fix a few issues in SQL PROOF monitoring: in; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.Â  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.Â  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:4218,monitor,monitoring,4218,proof/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html,2,['monitor'],['monitoring']
Energy Efficiency,"lement-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, one (``1.0``) can be used, as it is the neutral; value of floating point multiplication. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fmul.v4f32(float 1.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_and:. '``llvm.vector.reduce.and.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:655483,reduce,reduce,655483,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"lementation available at all times for an Analysis Group to be used.; Only default implementation can derive from ``ImmutablePass``. Here we declare; that the `BasicAliasAnalysis; <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass is the default; implementation for the interface. Pass Statistics; ===============. The `Statistic <https://llvm.org/doxygen/Statistic_8h_source.html>`_ class is; designed to be an easy way to expose various success metrics from passes.; These statistics are printed at the end of a run, when the :option:`-stats`; command line option is enabled on the command line. See the :ref:`Statistics; section <Statistic>` in the Programmer's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analyses are available already, which analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:40970,schedul,schedules,40970,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,2,"['efficient', 'schedul']","['efficiently', 'schedules']"
Energy Efficiency,"lementations. .. _various alias analysis implementations:. Available ``AliasAnalysis`` implementations; -------------------------------------------. This section lists the various implementations of the ``AliasAnalysis``; interface. All of these :ref:`chain <aliasanalysis-chaining>` to other; alias analysis implementations. The ``-basic-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^. The ``-basic-aa`` pass is an aggressive local analysis that *knows* many; important facts:. * Distinct globals, stack allocations, and heap allocations can never alias.; * Globals, stack allocations, and heap allocations never alias the null pointer.; * Different fields of a structure do not alias.; * Indexes into arrays with statically differing subscripts cannot alias.; * Many common standard C library functions `never access memory or only read; memory`_.; * Pointers that obviously point to constant globals ""``pointToConstantMemory``"".; * Function calls can not modify or references stack allocations if they never; escape from the function that allocates them (a common case for automatic; arrays). The ``-globalsmodref-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This pass implements a simple context-sensitive mod/ref and alias analysis for; internal global variables that don't ""have their address taken"". If a global; does not have its address taken, the pass knows that no pointers alias the; global. This pass also keeps track of functions that it knows never access; memory or never read memory. This allows certain optimizations (e.g. GVN) to; eliminate call instructions entirely. The real power of this pass is that it provides context-sensitive mod/ref; information for call instructions. This allows the optimizer to know that calls; to a function do not clobber or read the value of the global, allowing loads and; stores to be eliminated. .. note::. This pass is somewhat limited in its scope (only support non-address taken; globals), but is very quick analysis. The ``-steens-aa`` pass; ^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:24446,allocate,allocates,24446,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['allocate'],['allocates']
Energy Efficiency,"lements in array are used for the drawing.; One could specify index for any array dimension (-1 means last element in the array). For instance, dump last element from `event.fTracks` array:. - [opt=event.fTracks[-1].fBits>>dump](https://root.cern/js/latest/?file=https://root.cern/files/event/event_0.root&item=EventTree&opt=event.fTracks[-1].fBits>>dump). For any array or collection kind one could extract its size with expression:. - [opt=event.fTracks.@size](https://root.cern/js/latest/?file=https://root.cern/files/event/event_0.root&item=EventTree&opt=event.fTracks.@size;num:3000). At the end of expression one can add several parameters with the syntax:. <draw_expession>;par1name:par1value;par2name:par2value. Following parameters are supported:; - ""first"" - id of the first entry to process; - ""entries"" - number of entries to process; - ""monitor"" - periodically show intermediate draw results (interval in milliseconds); - ""maxrange"" - maximal number of ranges in single HTTP request; - ""accum"" - number of accumulated values before creating histogram; - ""htype"" - last letter in histogram type like ""I"", ""F"", ""D"", ""S"", ""L"", ""C""; - ""hbins"" - number of bins on each histogram axis; - ""drawopt"" - drawing option for produced histogram; - ""graph"" - draw into TGraph object. Example - [opt=event.fTracks[].fTriggerBits;entries:1000;first:200;maxrange:25](https://root.cern/js/latest/?file=https://root.cern/files/event/event_0.root&item=EventTree&opt=event.fTracks[].fTriggerBits;entries:1000;first:200;maxrange:25). ## Geometry viewer. JSROOT implements display of TGeo objects like:. - [file=rootgeom.root&item=simple1](https://root.cern/js/latest/?file=../files/geom/rootgeom.root&item=simple1); - [file=building.root&item=geom&opt=z](https://root.cern/js/latest/?nobrowser&file=../files/geom/building.root&item=geom;1&opt=z). Following classes are supported by geometry viewer:; - TGeoVolume; - TGeoNode; - TGeoManager (master volume will be displayed); - TEveGeoShapeExtract (used in EVE)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:18472,monitor,monitor,18472,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitor']
Energy Efficiency,"lems in; RooFit 3.00 and will be converted on the fly to the new dataset structure; in memory. User code that explicitly uses RooTreeData pointers should; be changed to RooAbsData pointers. This change should be transparent; for all uses, with the exception of the RooTreeData::tree() method.; Explicit access to tree implementation can still be obtained; through the RooTreeDataStore::tree() method. (A pointer to the datastore; can be obtained through the RooAbsData::store() method.); Note that in future releases it is no longer guaranteed that all datasets are implemented; with a plain TTree implementation, so any user code that uses the tree; implementation directly should implement checks that the implementation; is indeed tree-based (data->store()->InheritsFrom(RooTreeDataStore::Class())==true)). In future release additional implementations of RooAbsDataStore will; be provided that will support new dataset functionality such as the; ability to construct 'joint' dataset from two input datasets without; the need to copy the input data and 'filtered' datasets that represent; a reduced view (in dimensions or by selecting events) of a dataset; without the need to copy content. Various workspace improvements. A number of smaller and larger improvements has been made to the RooWorkspace class. Direct interactive access to contents from CINT -; One can now directly access the contents of any RooWorkspace; on the ROOT commandline through CINT if the RooWorkspace::exportToCint() call is made.; In CINT, all workspace objects will appear as correctly typed references to workspace objects in; a C++ namespace with the same name as the RooWorkspace object. Given e.g. a workspace w, with a Gaussian p.d.f gauss in terms of variables; x,m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each refe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:15938,reduce,reduced,15938,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,['reduce'],['reduced']
Energy Efficiency,"ler, a new kind of statement is available in Objective-C. It is; written ``@autoreleasepool`` followed by a *compound-statement*, i.e. by a new; scope delimited by curly braces. Upon entry to this block, the current state; of the autorelease pool is captured. When the block is exited normally,; whether by fallthrough or directed control flow (such as ``return`` or; ``break``), the autorelease pool is restored to the saved state, releasing all; the objects in it. When the block is exited with an exception, the pool is not; drained. ``@autoreleasepool`` may be used in non-ARC translation units, with equivalent; semantics. A program is ill-formed if it refers to the ``NSAutoreleasePool`` class. .. admonition:: Rationale. Autorelease pools are clearly important for the compiler to reason about, but; it is far too much to expect the compiler to accurately reason about control; dependencies between two calls. It is also very easy to accidentally forget; to drain an autorelease pool when using the manual API, and this can; significantly inflate the process's high-water-mark. The introduction of a; new scope is unfortunate but basically required for sane interaction with the; rest of the language. Not draining the pool during an unwind is apparently; required by the Objective-C exceptions implementation. .. _arc.misc.externally_retained:. Externally-Retained Variables; -----------------------------. In some situations, variables with strong ownership are considered; externally-retained by the implementation. This means that the variable is; retained elsewhere, and therefore the implementation can elide retaining and; releasing its value. Such a variable is implicitly ``const`` for safety. In; contrast with ``__unsafe_unretained``, an externally-retained variable still; behaves as a strong variable outside of initialization and destruction. For; instance, when an externally-retained variable is captured in a block the value; of the variable is retained and released on block ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:91562,drain,drain,91562,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['drain'],['drain']
Energy Efficiency,"letion or suspended. The `coro.end`_ intrinsic marks the point where; a coroutine needs to return control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is building the coroutine frame. The; def-use chains are analyzed to determine which objects need be kept alive across; suspend points. In the coroutine shown in the previous section, use of virtual register; `%inc` is separated from the definition by a suspend point, therefore, it; cannot reside on the stack frame since the latter goes away once the coroutine; is suspended and control is returned back to the caller. An i32 slot is; allocated in the coroutine frame and `%inc` is spilled and reloaded from that; slot as needed. We also store addresses of the resume and destroy functions so that the; `coro.resume` and `coro.destroy` intrinsics can resume and destroy the coroutine; when its identity cannot be determined statically at compile time. For our; example, the coroutine frame will be:. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32 }. After resume and destroy parts are outlined, function `f` will contain only the; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, pt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:14251,allocate,allocated,14251,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['allocate'],['allocated']
Energy Efficiency,"lette;. ##### Front; draw the front box of a Cartesian lego plot;. ##### Back; draw the back box of a Cartesian lego plot;. ##### Bar; change the bar attributes: the width and offset. #### Rebinning Tab. The Rebinning tab has two different layouts. One is for a histogram; that is not drawn from an ntuple; the other one is available for a; histogram, which is drawn from an ntuple. In this case, the rebin; algorithm can create a rebinned histogram from the original data i.e.; the ntuple. To see the differences do for example:. ``` {.cpp}; TFile f (""hsimple.root"");; hpxpy->Draw(""Lego2""); // non ntuple histogram; ntuple->Draw(""px:py"","""",""Lego2""); // ntuple histogram; ```. #### Non-ntuple histogram:. Rebin with sliders (one for the x, one for the y-axis) and the number; of bins (shown in the field below them can be changed to any number,; which divides the number of bins of the original histogram. Selecting; the Apply button will delete the origin histogram and will replace it; by the rebinned one on the screen. Selecting the Ignore the origin; histogram will be restored. ![](pictures/03000049.png). #### Histogram drawn from an ntuple. ##### Rebin; \index{histogram!rebin}; with the sliders the number of bins can be enlarged by a factor of; 2,3,4,5 (moving to the right) or reduced by a factor of $\frac{1}{2}$,; $\frac{1}{3}$, $\frac{1}{4}$, $\frac{1}{5}$. ##### BinOffset; with the BinOffset slider the origin of the histogram can; be changed within one binwidth. Using this slider the effect of; binning the data into bins can be made visible (=\> statistical; fluctuations). ##### Axis Range; with a double slider that gives the possibility for; zooming. It is also possible to set the upper and lower limit in; fields below the slider. ##### Delayed drawing; all the binning sliders can be set to delay draw mode.; Then the changes on the histogram are only updated, when the Slider is; released. This should be activated if the redrawing of the histogram; is too time consuming.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md:76918,reduce,reduced,76918,documentation/users-guide/Histograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md,1,['reduce'],['reduced']
Energy Efficiency,"level down, printing the path to the deepest physical node holding; this point. It also computes the closest distance to any boundary. \image html geometry010.png ""Random points"" width=500px. A method to check the validity of a given geometry is shooting random; points. This can be called with the method; TGeoVolume::RandomPoints() and it draws a volume with the current; visualization settings. Random points are generated in the bounding box; of the drawn volume. The points are drawn with the color of their; deepest container. Only points inside visible nodes are drawn. \image html geometry011.png ""Random rays"" width=500px. A ray tracing method can be called TGeoVolume::RandomRays(). This; shoots rays from a given point in the local reference frame with random; directions. The intersections with displayed nodes appear as segments; having the color of the touched node. \anchor GP04; ## The Drawing Package. \image html geometry012.png. The modeller provides a powerful drawing; package, supporting several different options of visualization. A; library separated from the main one provides all functionality being; linked with the underlying ROOT visualization system. This library is; dynamically loaded by the plug-in manager only when drawing features are; requested. The geometrical structures that can be visualized are volumes; and volume hierarchies. The main component of the visualization system is volume primitive; painting in a ROOT pad. Starting from this one, several specific options; or subsystems are available, like: X3D viewing using hidden line and; surface removal algorithms, OpenGL viewing\* or ray tracing. The method TGeoManager::GetGeomPainter() loads the painting library in; memory. This is generally not needed since it is called automatically by; TGeoVolume::Draw() as well as by few other methods setting; visualization attributes. \anchor GP04a; ### Drawing Volumes and Hierarchies of Volumes. The first thing one would like to do after building some geome",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:96957,power,powerful,96957,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['power'],['powerful']
Energy Efficiency,"lex objects (matrices or vectors); Danger: For example, when the following snippet:. ~~~ {.cpp}; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; ~~~. runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. #### 2. Use ""two-address instructions"". ~~~ {.cpp}; void TMatrixD::operator += (const TMatrixD &B);; ~~~. as much as possible.; That is, to add two matrices, it's much more efficient to write. ~~~ {.cpp}; A += B;; ~~~. than. ~~~ {.cpp}; TMatrixD C = A + B;; ~~~. (if both operand should be preserved, `TMatrixD C = A; C += B;`; is still better). #### 3. Use glorified constructors when returning of an object seems inevitable:. ~~~ {.cpp}; TMatrixD A(TMatrixD::kTransposed,B);; TMatrixD C(A,TMatrixD::kTransposeMult,B);; ~~~. like in the following snippet (from `$ROOTSYS/test/vmatrix.cxx`); that verifies that for an orthogonal matrix T, T'T = TT' = E. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTransposeMult,haar);; TMatrixD hht(haar,TMatrixD::kMult,haar_t);; TMatrixD hht1 = haar; hht1 *= haar_t;; VerifyMatrixIdentity(unit,hth);; VerifyMatrixIdentity(unit,hht);; VerifyMatrixIdentity(unit,hht1);; ~~~. #### 4. Accessing row/col/diagonal of a matrix without much fuss. (and without moving a lot of stuff around):. ~~~ {.cpp}; TMatrixD m(n,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:15850,efficient,efficient,15850,math/matrix/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md,1,['efficient'],['efficient']
Energy Efficiency,"liance on global state during the destruction of the elements was decreased (removing use of `TObject::SetDtorOnly`). ### Global resources. Several tweaks to if and when, resources held by the global ROOT object (TROOT, TApplication) are deleted. When the default TApplication is replaced by a user provide TApplication, do not call EndOfProcessCleanups and co. and thus do not delete TFiles, TSockets or TColors that have already been created. In EndOfProcessCleanups, we now delete the objects held in TROOT's TDirectory part. If the libCling library is unloaded, this now induces an immediate tear down of the ROOT resources; consequently objects might be deleted sooner in the process tear down process on some platforms. TObject instances allocated as part of an array and made part of a collection, as for example the TCanvas instances into the global list of instances, are not longer deleted if the content of the collection is deleted. Technically the element of the array are now treated by collections as if they have been allocated on the stack. This fixes the issue described at [ROOT-7846]. ### Code Cleanups. Several definition where moved from the global or ROOT namespace to the ROOT::Internal namespace as they are not intended to be used outside of ROOT, including: `gROOTLocal` and related functions, `TSchemaHelper`, `TSchemaMatch`, `TSchemaType`, `RStl`, `ROOT::TROOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility requirement. This includes `TCollectionProxyInfo`, `TSchemaRuleSet`. ## Interpreter. ROOT can now dump the context of STL collections, for instance `map<string,int>`. A few ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:5231,allocate,allocated,5231,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['allocate'],['allocated']
Energy Efficiency,"light = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45883,allocate,allocate,45883,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['allocate'],['allocate']
Energy Efficiency,"like this:. .. csv-table:: Virtual Table Layout for A, B, C; :header: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15. A::offset-to-top, &A::rtti, &A::f1, &A::f2, B::offset-to-top, &B::rtti, &B::f1, &B::f2, &B::f3, &B::f4, &B::f5, &B::f6, C::offset-to-top, &C::rtti, &C::f1, &C::f2. Notice that each address point for A is separated by 4 words. This lets us; emit a compressed bit vector for A that looks like this:. .. csv-table::; :header: 2, 6, 10, 14. 1, 1, 0, 1. At call sites, the compiler will strengthen the alignment requirements by; using a different rotate count. For example, on a 64-bit machine where the; address points are 4-word aligned (as in A from our example), the ``rol``; instruction may look like this:. .. code-block:: none. dd2: 48 c1 c1 3b rol $0x3b,%rcx. Padding to Powers of 2; ~~~~~~~~~~~~~~~~~~~~~~. Of course, this alignment scheme works best if the address points are; in fact aligned correctly. To make this more likely to happen, we insert; padding between virtual tables that in many cases aligns address points to; a power of 2. Specifically, our padding aligns virtual tables to the next; highest power of 2 bytes; because address points for specific base classes; normally appear at fixed offsets within the virtual table, this normally; has the effect of aligning the address points as well. This scheme introduces tradeoffs between decreased space overhead for; instructions and bit vectors and increased overhead in the form of padding. We; therefore limit the amount of padding so that we align to no more than 128; bytes. This number was found experimentally to provide a good tradeoff. Eliminating Bit Vector Checks for All-Ones Bit Vectors; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If the bit vector is all ones, the bit vector check is redundant; we simply; need to check that the address is in range and well aligned. This is more; likely to occur if the virtual tables are padded. Forward-Edge CFI for Virtual Calls by Interleaving V",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:8646,power,power,8646,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['power'],['power']
Energy Efficiency,"link-time, but it is the extra time required that concerns me. Link-time; > optimization is severely time-constrained. If we were to reimplement any of these optimizations, I assume that we; could do them a translation unit at a time, just as GCC does now. This; would lead to a pipeline like this:. Static optimizations, xlation unit at a time:; .c --GCC--> .llvm --llvmopt--> .llvm . Link time optimizations:; .llvm --llvm-ld--> .llvm --llvm-link-opt--> .llvm . Of course, many optimizations could be shared between llvmopt and; llvm-link-opt, but the wouldn't need to be shared... Thus compile time; could be faster, because we are using a ""smarter"" IR (SSA based). > BTW, about SGI, ""borrowing"" SSA-based optimizations from one compiler and; > putting it into another is not necessarily easier than re-doing it.; > Optimization code is usually heavily tied in to the specific IR they use. Understood. The only reason that I brought this up is because SGI's IR is; more similar to LLVM than it is different in many respects (SSA based,; relatively low level, etc), and could be easily adapted. Also their; optimizations are written in C++ and are actually somewhat; structured... of course it would be no walk in the park, but it would be; much less time consuming to adapt, say, SSA-PRE than to rewrite it. > But your larger point is valid that adding SSA based optimizations is; > feasible and should be fun. (Again, link time cost is the issue.). Assuming linktime cost wasn't an issue, the question is: ; Does using GCC's backend buy us anything?. > It also occurs to me that GCC is probably doing quite a bit of back-end; > optimization (step 16 in your list). Do you have a breakdown of that?. Not really. The irritating part of GCC is that it mixes it all up and; doesn't have a clean separation of concerns. A lot of the ""back end; optimization"" happens right along with other data optimizations (ie, CSE; of machine specific things). As far as REAL back end optimizations go, it looks som",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt:1333,adapt,adapted,1333,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,1,['adapt'],['adapted']
Energy Efficiency,"list of external functions in ``module.bc``; 2. Link ``module.bc`` with ``libdevice.compute_XX.YY.bc``; 3. Internalize all functions not in list from (1); 4. Eliminate all unused internal functions; 5. Run ``NVVMReflect`` pass; 6. Run standard optimization pipeline. .. note::. ``linkonce`` and ``linkonce_odr`` linkage types are not suitable for the; libdevice functions. It is possible to link two IR modules that have been; linked against libdevice using different reflection variables. Since the ``NVVMReflect`` pass replaces conditionals with constants, it will; often leave behind dead code of the form:. .. code-block:: llvm. entry:; ..; br i1 true, label %foo, label %bar; foo:; ..; bar:; ; Dead code; .. Therefore, it is recommended that ``NVVMReflect`` is executed early in the; optimization pipeline before dead-code elimination. The NVPTX TargetMachine knows how to schedule ``NVVMReflect`` at the beginning; of your pass manager; just use the following code when setting up your pass; manager and the PassBuilder will use ``registerPassBuilderCallbacks`` to let; NVPTXTargetMachine::registerPassBuilderCallbacks add the pass to the; pass manager:. .. code-block:: c++. std::unique_ptr<TargetMachine> TM = ...;; PassBuilder PB(TM);; ModulePassManager MPM;; PB.parsePassPipeline(MPM, ...);. Reflection Parameters; ---------------------. The libdevice library currently uses the following reflection parameters to; control code generation:. ==================== ======================================================; Flag Description; ==================== ======================================================; ``__CUDA_FTZ=[0,1]`` Use optimized code paths that flush subnormals to zero; ==================== ======================================================. The value of this flag is determined by the ""nvvm-reflect-ftz"" module flag.; The following sets the ftz flag to 1. .. code-block:: llvm. !llvm.module.flag = !{!0}; !0 = !{i32 4, !""nvvm-reflect-ftz"", i32 1}. (``i32 4`` indic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst:9927,schedul,schedule,9927,interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,1,['schedul'],['schedule']
Energy Efficiency,"lit where the implication is stored in the state; (similarly to nullability implications in TrustNonnullChecker); may produce much better results.; (Difficulty: Medium). Improve C++ support; ; Handle construction as part of aggregate initialization.; Aggregates; are objects that can be brace-initialized without calling a; constructor (that is, ; CXXConstructExpr does not occur in the AST),; but potentially calling; constructors for their fields and base classes; These; constructors of sub-objects need to know what object they are constructing.; Moreover, if the aggregate contains; references, lifetime extension needs to be properly modeled. One can start untangling this problem by trying to replace the; current ad-hoc ; ParentMap lookup in ; CXXConstructionKind::NonVirtualBase branch of; ExprEngine::VisitCXXConstructExpr(); with proper support for the feature.; (Difficulty: Medium) . Handle array constructors.; When an array of objects is allocated (say, using the; operator new[] or defining a stack array),; constructors for all elements of the array are called.; We should model (potentially some of) such evaluations,; and the same applies for destructors called from; operator delete[].; See tests cases in handle_constructors_with_new_array.cpp.; . Constructing an array requires invoking multiple (potentially unknown); amount of constructors with the same construct-expression.; Apart from the technical difficulties of juggling program points around; correctly to avoid accidentally merging paths together, we'll have to; be a judge on when to exit the loop and how to widen it.; Given that the constructor is going to be a default constructor,; a nice 95% solution might be to execute exactly one constructor and; then default-bind the resulting LazyCompoundVal to the whole array;; it'll work whenever the default constructor doesn't touch global state; but only initializes the object to various default values.; But if, say, we're making an array of strings,; depending on t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html:2615,allocate,allocated,2615,interpreter/llvm-project/clang/www/analyzer/open_projects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html,2,['allocate'],['allocated']
Energy Efficiency,"lity and it supports only dense layer. The new features of `MethodDL` are:. - Support training and evaluation of Convolutional layer on GPU; - Several ML optimizers are now included and they can be used in addition to SGD. These are ADAM (the new default), ADAGRAD,; RMSPROP, ADADELTA. A new option, *Optimizer* has been added in the option string used to define the training strategy options.; - Add support for regression in MethodDL; - Use single precision (float) types as the fundamental type for the neural network architecture. Double precision could be enabled, but it will require recompiling TMVA. ; - Support inference (network evaluation) in batch mode in addition to single event. Batch mode evaluation is now the default when used within the `TMVA::Factory` class (i.e. when calling; `Factory::TestAllMethod()` or `Factory::EvaluateAllMethods()`; - Support splitting the overall training data in Train and Validation data. The train data is used for finding the optimal network weight and the validation data is used to monitor the validation; error. The weights which are giving a minimal validation error will be stored. For the splitting a new option, *ValidationSize* has been added to the global options for `MethodDL`.; The same option is also available in the `PyKeras` method of `PyMVA`; - The fast tanh implementation from VDT is now used as activation function when training the network on CPU.; - Using `Cblas` from the GSL library is supported for CPU training when no other Blas libraries are found. However, it is strongly recommended, to use an optimized Blas implementation such as `libopenblas`, that is; available in cvmfs.; - Add several performance optimizations for both CPU and GPU versions of `MethodDL`. . ### Other New TMVA Features. - Add a new option to the `DataLoader` to switch off computation of correlation matrix. The new option is called *CalcCorrelations* and it should be used when a large number of input variables are; provided, otherwise TMVA will",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:14407,monitor,monitor,14407,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['monitor'],['monitor']
Energy Efficiency,"ll call; MCJIT::finalizeObject to complete the remapping process. Final Preparations; ==================. When MCJIT::finalizeObject is called, MCJIT calls; RuntimeDyld::resolveRelocations. This function will attempt to locate any; external symbols and then apply all relocations for the object. External symbols are resolved by calling the memory manager's; getPointerToNamedFunction method. The memory manager will return the; address of the requested symbol in the target address space. (Note, this; may not be a valid pointer in the host process.) RuntimeDyld will then; iterate through the list of relocations it has stored which are associated; with this symbol and invoke the resolveRelocation method which, through an; format-specific implementation, will apply the relocation to the loaded; section memory. Next, RuntimeDyld::resolveRelocations iterates through the list of; sections and for each section iterates through a list of relocations that; have been saved which reference that symbol and call resolveRelocation for; each entry in this list. The relocation list here is a list of; relocations for which the symbol associated with the relocation is located; in the section associated with the list. Each of these locations will; have a target location at which the relocation will be applied that is; likely located in a different section. .. image:: MCJIT-resolve-relocations.png. Once relocations have been applied as described above, MCJIT calls; RuntimeDyld::getEHFrameSection, and if a non-zero result is returned; passes the section data to the memory manager's registerEHFrames method.; This allows the memory manager to call any desired target-specific; functions, such as registering the EH frame information with a debugger. Finally, MCJIT calls the memory manager's finalizeMemory method. In this; method, the memory manager will invalidate the target code cache, if; necessary, and apply final permissions to the memory pages it has; allocated for code and data memory.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:8685,allocate,allocated,8685,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,1,['allocate'],['allocated']
Energy Efficiency,"ll of links to slides, video, and sometimes code. When deciding between creating a type hierarchy (with either tagged or virtual; dispatch) and using templates or concepts-based polymorphism, consider whether; there is some refinement of an abstract base class which is a semantically; meaningful type on an interface boundary. If anything more refined than the; root abstract interface is meaningless to talk about as a partial extension of; the semantic model, then your use case likely fits better with polymorphism and; you should avoid using virtual dispatch. However, there may be some exigent; circumstances that require one technique or the other to be used. If you do need to introduce a type hierarchy, we prefer to use explicitly; closed type hierarchies with manual tagged dispatch and/or RTTI rather than the; open inheritance model and virtual dispatch that is more common in C++ code.; This is because LLVM rarely encourages library consumers to extend its core; types, and leverages the closed and tag-dispatched nature of its hierarchies to; generate significantly more efficient code. We have also found that a large; amount of our usage of type hierarchies fits better with tag-based pattern; matching rather than dynamic dispatch across a common interface. Within LLVM we; have built custom helpers to facilitate this design. See this document's; section on :ref:`isa and dyn_cast <isa>` and our :doc:`detailed document; <HowToSetUpLLVMStyleRTTI>` which describes how you can implement this; pattern for use with the LLVM helpers. .. _abi_breaking_checks:. ABI Breaking Checks; -------------------. Checks and asserts that alter the LLVM C++ ABI are predicated on the; preprocessor symbol `LLVM_ENABLE_ABI_BREAKING_CHECKS` -- LLVM; libraries built with `LLVM_ENABLE_ABI_BREAKING_CHECKS` are not ABI; compatible LLVM libraries built without it defined. By default,; turning on assertions also turns on `LLVM_ENABLE_ABI_BREAKING_CHECKS`; so a default +Asserts build is not ABI compat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:132703,efficient,efficient,132703,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"lloca`` into; SSA form need only add a call to ``@llvm.gcroot`` for those variables which; are pointers into the GC heap. It is also important to mark intermediate values with ``llvm.gcroot``. For; example, consider ``h(f(), g())``. Beware leaking the result of ``f()`` in the; case that ``g()`` triggers a collection. Note, that stack variables must be; initialized and marked with ``llvm.gcroot`` in function's prologue. The ``%metadata`` argument can be used to avoid requiring heap objects to have; 'isa' pointers or tag bits. [Appel89_, Goldberg91_, Tolmach94_] If specified,; its value will be tracked along with the location of the pointer in the stack; frame. Consider the following fragment of Java code:. .. code-block:: java. {; Object X; // A null-initialized reference to an object; ...; }. This block (which may be located in the middle of a function or in a loop nest),; could be compiled to this LLVM code:. .. code-block:: llvm. Entry:; ;; In the entry block for the function, allocate the; ;; stack space for X, which is an LLVM pointer.; %X = alloca %Object*. ;; Tell LLVM that the stack space is a stack root.; ;; Java has type-tags on objects, so we pass null as metadata.; %tmp = bitcast %Object** %X to i8**; call void @llvm.gcroot(i8** %tmp, i8* null); ... ;; ""CodeBlock"" is the block corresponding to the start; ;; of the scope above.; CodeBlock:; ;; Java null-initializes pointers.; store %Object* null, %Object** %X. ... ;; As the pointer goes out of scope, store a null value into; ;; it, to indicate that the value is no longer live.; store %Object* null, %Object** %X; ... Reading and writing references in the heap; ------------------------------------------. Some collectors need to be informed when the mutator (the program that needs; garbage collection) either reads a pointer from or writes a pointer to a field; of a heap object. The code fragments inserted at these points are called *read; barriers* and *write barriers*, respectively. The amount of code that n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:12089,allocate,allocate,12089,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['allocate'],['allocate']
Energy Efficiency,"llvm-exegesis - LLVM Machine Instruction Benchmark; ==================================================. .. program:: llvm-exegesis. SYNOPSIS; --------. :program:`llvm-exegesis` [*options*]. DESCRIPTION; -----------. :program:`llvm-exegesis` is a benchmarking tool that uses information available; in LLVM to measure host machine instruction characteristics like latency,; throughput, or port decomposition. Given an LLVM opcode name and a benchmarking mode, :program:`llvm-exegesis`; generates a code snippet that makes execution as serial (resp. as parallel) as; possible so that we can measure the latency (resp. inverse throughput/uop decomposition); of the instruction.; The code snippet is jitted and, unless requested not to, executed on the; host subtarget. The time taken (resp. resource usage) is measured using; hardware performance counters. The result is printed out as YAML; to the standard output. The main goal of this tool is to automatically (in)validate the LLVM's TableDef; scheduling models. To that end, we also provide analysis of the results. :program:`llvm-exegesis` can also benchmark arbitrary user-provided code; snippets. SUPPORTED PLATFORMS; -------------------. :program:`llvm-exegesis` currently only supports X86 (64-bit only), ARM (AArch64; only), MIPS, and PowerPC (PowerPC64LE only) on Linux for benchmarking. Not all; benchmarking functionality is guaranteed to work on every platform.; :program:`llvm-exegesis` also has a separate analysis mode that is supported; on every platform that LLVM is. SNIPPET ANNOTATIONS; -------------------. :program:`llvm-exegesis` supports benchmarking arbitrary snippets of assembly.; However, benchmarking these snippets often requires some setup so that they; can execute properly. :program:`llvm-exegesis` has five annotations and some; additional utilities to help with setup so that snippets can be benchmarked; properly. * `LLVM-EXEGESIS-DEFREG <register name>` - Adding this annotation to the text; assembly snippet to be be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:993,schedul,scheduling,993,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['schedul'],['scheduling']
Energy Efficiency,"llvm-exegesis --mode=analysis \; --benchmarks-file=/tmp/benchmarks.yaml \; --analysis-clusters-output-file=/tmp/clusters.csv \; --analysis-inconsistencies-output-file=/tmp/inconsistencies.html. This will group the instructions into clusters with the same performance; characteristics. The clusters will be written out to `/tmp/clusters.csv` in the; following format:. .. code-block:: none. cluster_id,opcode_name,config,sched_class; ...; 2,ADD32ri8_DB,,WriteALU,1.00; 2,ADD32ri_DB,,WriteALU,1.01; 2,ADD32rr,,WriteALU,1.01; 2,ADD32rr_DB,,WriteALU,1.00; 2,ADD32rr_REV,,WriteALU,1.00; 2,ADD64i32,,WriteALU,1.01; 2,ADD64ri32,,WriteALU,1.01; 2,MOVSX64rr32,,BSWAP32r_BSWAP64r_MOVSX64rr32,1.00; 2,VPADDQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSUBDYrr_VPSUBQYrr_VPSUBWYrr,1.02; 2,VPSUBQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSUBDYrr_VPSUBQYrr_VPSUBWYrr,1.01; 2,ADD64ri8,,WriteALU,1.00; 2,SETBr,,WriteSETCC,1.01; ... :program:`llvm-exegesis` will also analyze the clusters to point out; inconsistencies in the scheduling information. The output is an html file. For; example, `/tmp/inconsistencies.html` will contain messages like the following :. .. image:: llvm-exegesis-analysis.png; :align: center. Note that the scheduling class names will be resolved only when; :program:`llvm-exegesis` is compiled in debug mode, else only the class id will; be shown. This does not invalidate any of the analysis results though. OPTIONS; -------. .. option:: --help. Print a summary of command line options. .. option:: --opcode-index=<LLVM opcode index>. Specify the opcode to measure, by index. Specifying `-1` will result; in measuring every existing opcode. See example 1 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --opcode-name=<opcode name 1>,<opcode name 2>,... Specify the opcode to measure, by name. Several opcodes can be specified as; a comma-separated list. See example 1 for details.; Either `opcode-index`, `opcode-nam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:8757,schedul,scheduling,8757,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['schedul'],['scheduling']
Energy Efficiency,"llvm-extract - extract a function from an LLVM module; =====================================================. .. program:: llvm-extract. SYNOPSIS; --------. :program:`llvm-extract` [*options*] **--func** *function-name* [*filename*]. DESCRIPTION; -----------. The :program:`llvm-extract` command takes the name of a function and extracts; it from the specified LLVM bitcode file. It is primarily used as a debugging; tool to reduce test cases from larger programs that are triggering a bug. In addition to extracting the bitcode of the specified function,; :program:`llvm-extract` will also remove unreachable global variables,; prototypes, and unused types. The :program:`llvm-extract` command reads its input from standard input if; filename is omitted or if filename is ``-``. The output is always written to; standard output, unless the **-o** option is specified (see below). OPTIONS; -------. **--alias** *alias-name*. Extract the alias named *function-name* from the LLVM bitcode. May be; specified multiple times to extract multiple alias at once. **--ralias** *alias-regular-expr*. Extract the alias matching *alias-regular-expr* from the LLVM bitcode.; All alias matching the regular expression will be extracted. May be; specified multiple times. **--bb** *basic-block-specifier*. Extract basic blocks(s) specified in *basic-block-specifier*. May be; specified multiple times. Each <function:bb[;bb]> specifier pair will create; a function. If multiple basic blocks are specified in one pair, the first; block in the sequence should dominate the rest. **--delete**. Delete specified Globals from Module. **-f**. Enable binary output on terminals. Normally, :program:`llvm-extract` will; refuse to write raw bitcode output if the output stream is a terminal. With; this option, :program:`llvm-extract` will write raw bitcode regardless of the; output device. **--func** *function-name*. Extract the function named *function-name* from the LLVM bitcode. May be; specified multiple times to ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-extract.rst:425,reduce,reduce,425,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-extract.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-extract.rst,1,['reduce'],['reduce']
Energy Efficiency,"llvm-ifs - shared object stubbing tool; ======================================. .. program:: llvm-ifs. SYNOPSIS; --------. :program:`llvm-ifs` [*options*] *inputs*. DESCRIPTION; -----------. :program:`llvm-ifs` is a tool that jointly produces human readable text-based; stubs (.ifs files) for shared objects and linkable shared object stubs; (.so files) from either ELF shared objects or text-based stubs. The text-based; stubs is useful for monitoring ABI changes of the shared object. The linkable; shared object stubs can be used to avoid unnecessary relinks when the ABI of; shared libraries does not change. IFS FORMATS; -----------. Here is an example of the text representation (IFS) of a shared object produced; by the :program:`llvm-ifs`:. ::. --- !ifs-v1; IFSVersion: 3.0; SoName: libtest.so /* Optional */; Target: x86_64-unknown-linux-gnu /* Optional, format 1, same format as llvm target triple */; Target: { Arch: x86_64, Endianness: little, Bitwidth: 64 } /* Optional, format 2 */; NeededLibs:; - libc.so.6; Symbols:; - { Name: sym0, Type: Notype }; - { Name: sym1, Type: Object, Size: 0 }; - { Name: sym2, Type: Func, Weak: false }; - { Name: sym3, Type: TLS }; - { Name: sym4, Type: Unknown, Warning: foo }; ... * ``IFSVersion``: Version of the IFS file for reader compatibility. * ``SoName`` (optional): Name of the shared object file that is being stubbed. * ``Target`` (optional): The architecture, endianness and bitwise information of; this shared object. It can be either in explicit format or in implicit LLVM; triple format. It can be optional and can be overridden from command line; options. * ``NeededLibs``: The list of the external shared objects that this library depends on. * ``Symbols``: A collection of all data needed to link objects for each symbol, sorted by name in ascending order. + ``Name``: Symbol name. + ``Type``: Whether the symbol is an object, function, no-type, thread local storage, or unknown. Symbol types not explicitly supported are mapped as unkn",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-ifs.rst:442,monitor,monitoring,442,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-ifs.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-ifs.rst,1,['monitor'],['monitoring']
Energy Efficiency,"llvm-mca - LLVM Machine Code Analyzer; =====================================. .. program:: llvm-mca. SYNOPSIS; --------. :program:`llvm-mca` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-mca` is a performance analysis tool that uses information; available in LLVM (e.g. scheduling models) to statically measure the performance; of machine code in a specific CPU. Performance is measured in terms of throughput as well as processor resource; consumption. The tool currently works for processors with a backend for which; there is a scheduling model available in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:286,schedul,scheduling,286,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,3,"['consumption', 'schedul']","['consumption', 'scheduling']"
Energy Efficiency,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:5,reduce,reduce,5,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,6,['reduce'],"['reduce', 'reducer']"
Energy Efficiency,llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rus,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338207,reduce,reduce,338207,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llv,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338031,reduce,reduce,338031,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"loat sequential_fmul(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result * input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, one (``1.0``) can be used, as it is the neutral; value of floating point multiplication. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fmul.v4f32(float 1.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_and:. '``llvm.vector.reduce.and.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:655181,reduce,reduce,655181,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,lobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helper.h; llvm/tools/llvm-xray/llvm-xray.cpp; llvm/tools/llvm-xray/trie-node.h; llvm/tools/llvm-xray/xray-account.h; llvm/tools/llvm-xray/xray-color-helper.cpp; llvm/tools/llvm-xray/xray-color-helper.h; llvm/tools/llvm-xray/xray-converter.cpp; llvm/tools/llvm-xray/xr,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:339045,reduce,reduce,339045,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,lock-scope extern declarations; Unknown. 1840; drafting; Non-deleted explicit specialization of deleted function template; Not resolved. 1841; CD6; < following template injected-class-name; Unknown. 1842; open; Unevaluated operands and â€œcarries a dependencyâ€; Not resolved. 1843; CD4; Bit-field in conditional operator with throw operand; Unknown. 1844; open; Defining â€œimmediate contextâ€; Not resolved. 1845; drafting; Point of instantiation of a variable template specialization; Not resolved. 1846; CD4; Declaring explicitly-defaulted implicitly-deleted functions; Unknown. 1847; CD4; Clarifying compatibility during partial ordering; Unknown. 1848; CD4; Parenthesized constructor and destructor declarators; Unknown. 1849; CD6; Variable templates and the ODR; Unknown. 1850; CD4; Differences between definition context and point of instantiation; Unknown. 1851; CD4; decltype(auto) in new-expressions; Unknown. 1852; CD4; Wording issues regarding decltype(auto); Unknown. 1853; dup; Defining â€œallocated storageâ€; Unknown. 1854; drafting; Disallowing use of implicitly-deleted functions; Not resolved. 1855; dup; Out-of-lifetime access to nonstatic data members; Unknown. 1856; open; Indirect nested classes of class templates; Not resolved. 1857; CD5; Additional questions about bits; Unknown. 1858; CD4; Comparing pointers to union members; Unknown. 1859; CD5; UTF-16 in char16_t string literals; Unknown. 1860; C++17; What is a â€œdirect member?â€; Unknown. 1861; CD4; Values of a bit-field; Unknown. 1862; CD5; Determining â€œcorresponding membersâ€ for friendship; Unknown. 1863; CD4; Requirements on thrown object type to support std::current_exception(); Unknown. 1864; NAD; List-initialization of array objects; Unknown. 1865; CD4; Pointer arithmetic and multi-level qualification conversions; Unknown. 1866; CD4; Initializing variant members with non-trivial destructors; Unknown. 1867; NAD; Function/expression ambiguity with qualified parameter name; Unknown. 1868; drafting; Meaning of â€œplac,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:125862,allocate,allocated,125862,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,2,['allocate'],['allocated']
Energy Efficiency,"lock:: text. bb.0.entry:; successors: %bb.1.then(32), %bb.2.else(16). .. _bb-liveins:. Live In Registers; ^^^^^^^^^^^^^^^^^. The machine basic block's live in registers have to be specified before any of; the instructions:. .. code-block:: text. bb.0.entry:; liveins: $edi, $esi. The list of live in registers and successors can be empty. The language also; allows multiple live in register and successor lists - they are combined into; one list by the parser. Miscellaneous Attributes; ^^^^^^^^^^^^^^^^^^^^^^^^. The attributes ``IsAddressTaken``, ``IsLandingPad``,; ``IsInlineAsmBrIndirectTarget`` and ``Alignment`` can be specified in brackets; after the block's definition:. .. code-block:: text. bb.0.entry (address-taken):; <instructions>; bb.2.else (align 4):; <instructions>; bb.3(landing-pad, align 4):; <instructions>; bb.4 (inlineasm-br-indirect-target):; <instructions>. .. TODO: Describe the way the reference to an unnamed LLVM IR block can be; preserved. ``Alignment`` is specified in bytes, and must be a power of two. .. _mir-instructions:. Machine Instructions; --------------------. A machine instruction is composed of a name,; :ref:`machine operands <machine-operands>`,; :ref:`instruction flags <instruction-flags>`, and machine memory operands. The instruction's name is usually specified before the operands. The example; below shows an instance of the X86 ``RETQ`` instruction with a single machine; operand:. .. code-block:: text. RETQ $eax. However, if the machine instruction has one or more explicitly defined register; operands, the instruction's name has to be specified after them. The example; below shows an instance of the AArch64 ``LDPXpost`` instruction with three; defined register operands:. .. code-block:: text. $sp, $fp, $lr = LDPXpost $sp, 2. The instruction names are serialized using the exact definitions from the; target's ``*InstrInfo.td`` files, and they are case sensitive. This means that; similar instruction names like ``TSTri`` and ``tSTRi`` repres",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst:10947,power,power,10947,interpreter/llvm-project/llvm/docs/MIRLangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst,1,['power'],['power']
Energy Efficiency,locks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/ll,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338525,reduce,reduce,338525,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, tw",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31570,schedul,scheduler,31570,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"low the code generator to make use of some instructions which; would otherwise not be usable (such as ``fsin`` on X86). .. option:: --stats. Print statistics recorded by code-generation passes. .. option:: --time-passes. Record the amount of time needed for each pass and print a report to standard; error. .. option:: --load=<dso_path>. Dynamically load ``dso_path`` (a path to a dynamically shared object) that; implements an LLVM target. This will permit the target name to be used with; the :option:`-march` option so that code can be generated for that target. .. option:: -meabi=[default|gnu|4|5]. Specify which EABI version should conform to. Valid EABI versions are *gnu*,; *4* and *5*. Default value (*default*) depends on the triple. .. option:: -stack-size-section. Emit the .stack_sizes section which contains stack size metadata. The section; contains an array of pairs of function symbol values (pointer size) and stack; sizes (unsigned LEB128). The stack size values only include the space allocated; in the function prologue. Functions with dynamic stack allocations are not; included. .. option:: -remarks-section. Emit the __remarks (MachO) section which contains metadata about remark; diagnostics. Tuning/Configuration Options; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. option:: --print-after-isel. Print generated machine code after instruction selection (useful for debugging). .. option:: --regalloc=<allocator>. Specify the register allocator to use.; Valid register allocators are:. *basic*. Basic register allocator. *fast*. Fast register allocator. It is the default for unoptimized code. *greedy*. Greedy register allocator. It is the default for optimized code. *pbqp*. Register allocator based on 'Partitioned Boolean Quadratic Programming'. .. option:: --spiller=<spiller>. Specify the spiller to use for register allocators that support it. Currently; this option is used only by the linear scan register allocator. The default; ``spiller`` is *local*. Valid spillers are:. *si",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst:5002,allocate,allocated,5002,interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,1,['allocate'],['allocated']
Energy Efficiency,"lowed automatically for these objects:. * objects of dynamic storage duration created in other memory, such as; that returned by ``malloc``; * union members. .. admonition:: Rationale. ARC must perform special operations when initializing an object and; when destroying it. In many common situations, ARC knows when an; object is created and when it is destroyed and can ensure that these; operations are performed correctly. Otherwise, however, ARC requires; programmer cooperation to establish its initialization invariants; because it is infeasible for ARC to dynamically infer whether they; are intact. For example, there is no syntactic difference in C between; an assignment that is intended by the programmer to initialize a variable; and one that is intended to replace the existing value stored there,; but ARC must perform one operation or the other. ARC chooses to always; assume that objects are initialized (except when it is in charge of; initializing them) because the only workable alternative would be to; ban all code patterns that could potentially be used to access; uninitialized memory, and that would be too limiting. In practice,; this is rarely a problem because programmers do not generally need to; work with objects for which the requirements are not handled; automatically. Note that dynamically-allocated Objective-C++ arrays of; nontrivially-ownership-qualified type are not ABI-compatible with non-ARC; code because the non-ARC code will consider the element type to be POD.; Such arrays that are ``new[]``'d in ARC translation units cannot be; ``delete[]``'d in non-ARC translation units and vice-versa. .. _arc.ownership.restrictions.pass_by_writeback:. Passing to an out parameter by writeback; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If the argument passed to a parameter of type ``T __autoreleasing *`` has type; ``U oq *``, where ``oq`` is an ownership qualifier, then the argument is a; candidate for :arc-term:`pass-by-writeback`` if:. * ``oq`` is ``__strong",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:47686,charge,charge,47686,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['charge'],['charge']
Energy Efficiency,"lowering it into a sequence of branches that guard scalar store operations. Memory Use Markers; ------------------. This class of intrinsics provides information about the; :ref:`lifetime of memory objects <objectlifetime>` and ranges where variables; are immutable. .. _int_lifestart:. '``llvm.lifetime.start``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.lifetime.start(i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.lifetime.start``' intrinsic specifies the start of a memory; object's lifetime. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is variable sized. The second argument is a pointer; to the object. Semantics:; """""""""""""""""""". If ``ptr`` is a stack-allocated object and it points to the first byte of; the object, the object is initially marked as dead.; ``ptr`` is conservatively considered as a non-stack-allocated object if; the stack coloring algorithm that is used in the optimization pipeline cannot; conclude that ``ptr`` is a stack-allocated object. After '``llvm.lifetime.start``', the stack object that ``ptr`` points is marked; as alive and has an uninitialized value.; The stack object is marked as dead when either; :ref:`llvm.lifetime.end <int_lifeend>` to the alloca is executed or the; function returns. After :ref:`llvm.lifetime.end <int_lifeend>` is called,; '``llvm.lifetime.start``' on the stack object can be called again.; The second '``llvm.lifetime.start``' call marks the object as alive, but it; does not change the address of the object. If ``ptr`` is a non-stack-allocated object, it does not point to the first; byte of the object or it is a stack object that is already alive, it simply; fills all bytes of the object with ``poison``. .. _int_lifeend:. '``llvm.lifetime.end``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.lifetime.end(i64 <size>, ptr nocapture <ptr>). Overview:; """"""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:861692,allocate,allocated,861692,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['allocate'],['allocated']
Energy Efficiency,"lows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:1498,allocate,allocated,1498,tree/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html,2,['allocate'],['allocated']
Energy Efficiency,"loyment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; in Numba's compilation chain. Examples; --------. The following, non-exhaustive, set of examples gives an idea of the; current level of support.; More examples can be found in the `test suite`_. C++ free (global) functions can be called and overloads will be selected, or; a template will be instantiated, based on the provided types.; Exact type matches are fully supported, there is some support for typedefs; add implicit conversions for builtin types, there is no support for; conversions of custom types or default arguments. - **Basic usage**: To use ``cppyy`` in Numba JITed code, simply import; ``cppyy.numba_ext``, after which further use is transparent and the same; as when otherwise using ``cppyy`` in Python.; Example:. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext # enables numba to work with cppyy; >>> import math; >>> @numba.jit(nopython=True); ... def cpp_sqrt(x):; ... return cppyy.gbl.sqrt(x) # direct use, no extr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:2958,reduce,reduce,2958,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,1,['reduce'],['reduce']
Energy Efficiency,"lps declare and; initialize the results variable, so that it can be available globally; (throughout the function body). - Input: `str` (the string to add to the global scope).; - Output: Adds the given string to the string block that will be emitted at; the top of the squashed function. - **RooFit::Detail::CodeSquashContext::assembleCode()**: combines the generated; code statements into the final code body of the squashed function. - Input: `returnExpr` (he string representation of what the squashed function; should return, usually the head node).; - Output: The final body of the function. - **RooFit::Detail::CodeSquashContext::beginLoop()**: The code squashing task; will automatically build a For loop around the indented statements that follow; this function. - Input: `in` (a pointer to the calling class, used to determine the loop; dependent variables).; - Output: A scope for iterating over vector observables. - **RooFit::Detail::CodeSquashContext::buildArg()**: helps convert RooFit; objects into arrays or other C++ representations for efficient computation. - Input: `in` (the list to convert to array).; - Output: Name of the array that stores the input list in the squashed code. - **RooFit::Detail::CodeSquashContext::buildCall()**: Creates a string; representation of the function to be called and its arguments. - Input: A function with name `funcname`, passing some arguments.; - Output: A string representation of the function to be called. - **RooFit::Detail::makeValidVarName()**: It helps fetch and save a valid name; from the name of the respective RooFit class. - Input: `in` (the input string).; - Output: A new string that is a valid variable name. - **RooFuncWrapper::buildCode()**: Generates the optimized code for evaluating; the function and its derivatives. - Input: `head` (starting mathematical expression).; - Output: code for evaluating the function. - **RooFuncWrapper::declareAndDiffFunction()**: Declare the function and create; its derivative. - Inputs: `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:36807,efficient,efficient,36807,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['efficient'],['efficient']
Energy Efficiency,"ls all bytes of the object with ``poison``. .. _int_lifeend:. '``llvm.lifetime.end``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.lifetime.end(i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.lifetime.end``' intrinsic specifies the end of a memory object's; lifetime. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is variable sized. The second argument is a pointer; to the object. Semantics:; """""""""""""""""""". If ``ptr`` is a stack-allocated object and it points to the first byte of the; object, the object is dead.; ``ptr`` is conservatively considered as a non-stack-allocated object if; the stack coloring algorithm that is used in the optimization pipeline cannot; conclude that ``ptr`` is a stack-allocated object. Calling ``llvm.lifetime.end`` on an already dead alloca is no-op. If ``ptr`` is a non-stack-allocated object or it does not point to the first; byte of the object, it is equivalent to simply filling all bytes of the object; with ``poison``. '``llvm.invariant.start``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The memory object can belong to any address space. ::. declare ptr @llvm.invariant.start.p0(i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.invariant.start``' intrinsic specifies that the contents of; a memory object will not change. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is variable sized. The second argument is a pointer; to the object. Semantics:; """""""""""""""""""". This intrinsic indicates that until an ``llvm.invariant.end`` that uses; the return value, the referenced memory location is constant and; unchanging. '``llvm.invariant.end``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The memory object can belong to any address space.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:863446,allocate,allocated,863446,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,ls/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llv,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337401,reduce,reduce,337401,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"lse âˆ’ Events with negative weights are ignored in the training (but are included for testing and performance evaluation). NCycles No 200 âˆ’ Number of training cycles. HiddenLayers No N,N-1 âˆ’ Specification of hidden layer architecture (N stands for number of variables; any integers may also be used). ValidationFraction No 0.5 âˆ’ Fraction of events in training tree used for cross validation. LearningMethod No Stochastic Stochastic, Batch, SteepestDescent, RibierePolak, FletcherReeves, BFGS Learning method. Configuration options for setup and tuning of specific fitter :. Configuration options reference for fitting method: Simulated Annealing (SA). Option Array Default value Predefined values Description. MaxCalls No 100000 âˆ’ Maximum number of minimisation calls. InitialTemp No 1e+06 âˆ’ Initial temperature. MinTemp No 1e-06 âˆ’ Mimimum temperature. Eps No 1e-10 âˆ’ Epsilon. TempScale No 1 âˆ’ Temperature scale. AdaptiveSpeed No 1 âˆ’ Adaptive speed. TempAdaptiveStep No 0.009875 âˆ’ Step made in each generation temperature adaptive. UseDefaultScale No False âˆ’ Use default temperature scale for temperature minimisation algorithm. UseDefaultTemp No False âˆ’ Use default initial temperature. KernelTemp No IncAdaptive IncAdaptive, DecAdaptive, Sqrt, Log, Sin, Homo, Geo Temperature minimisation algorithm. Configuration options for setup and tuning of specific fitter :. Configuration options reference for fitting method: Monte Carlo sampling (MC). Option Array Default value Predefined values Description. SampleSize No 100000 âˆ’ Number of Monte Carlo events in toy sample. Sigma No -1 âˆ’ If > 0: new points are generated according to Gauss around best value and with Sigma in units of interval length. Seed No 100 âˆ’ Seed for the random generator (0 takes random seeds). Configuration options for setup and tuning of specific fitter :. Configuration options reference for fitting method: TMinuit (MT). Option Array Default value Predefined values Description. ErrorLevel No 1 âˆ’ TMinuit: error level: 0.5=lo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:29619,adapt,adaptive,29619,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['adapt'],['adaptive']
Energy Efficiency,"lso, whenever a new instruction is; added in the .td files, all the relevant switch cases should be modified; accordingly. Instead, the same functionality could be achieved with TableGen and; some support from the .td files for a fraction of maintenance cost. ``InstrMapping`` Class Overview; ===============================. TableGen uses relationship models to map instructions with each other. These; models are described using ``InstrMapping`` class as a base. Each model sets; various fields of the ``InstrMapping`` class such that they can uniquely; describe all the instructions using that model. TableGen parses all the relation; models and uses the information to construct relation tables which relate; instructions with each other. These tables are emitted in the; ``XXXInstrInfo.inc`` file along with the functions to query them. Following; is the definition of ``InstrMapping`` class defined in Target.td file:. .. code-block:: text. class InstrMapping {; // Used to reduce search space only to the instructions using this; // relation model.; string FilterClass;. // List of fields/attributes that should be same for all the instructions in; // a row of the relation table. Think of this as a set of properties shared; // by all the instructions related by this relationship.; list<string> RowFields = [];. // List of fields/attributes that are same for all the instructions; // in a column of the relation table.; list<string> ColFields = [];. // Values for the fields/attributes listed in 'ColFields' corresponding to; // the key instruction. This is the instruction that will be transformed; // using this relation model.; list<string> KeyCol = [];. // List of values for the fields/attributes listed in 'ColFields', one for; // each column in the relation table. These are the instructions a key; // instruction will be transformed into.; list<list<string> > ValueCols = [];; }. Sample Example; --------------. Let's say that we want to have a function; ``int getPredOpcode(uint16_t ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUseInstrMappings.rst:1564,reduce,reduce,1564,interpreter/llvm-project/llvm/docs/HowToUseInstrMappings.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUseInstrMappings.rst,1,['reduce'],['reduce']
Energy Efficiency,"lticlass ro_signed_pats<string T, string Rm, dag Base, dag Offset, dag Extend,; dag address, ValueType sty> {; def : Pat<(i32 (!cast<SDNode>(""sextload"" # sty) address)),; (!cast<Instruction>(""LDRS"" # T # ""w_"" # Rm # ""_RegOffset""); Base, Offset, Extend)>;. def : Pat<(i64 (!cast<SDNode>(""sextload"" # sty) address)),; (!cast<Instruction>(""LDRS"" # T # ""x_"" # Rm # ""_RegOffset""); Base, Offset, Extend)>;; }. defm : ro_signed_pats<""B"", Rm, Base, Offset, Extend,; !foreach(decls.pattern, address,; !subst(SHIFT, imm_eq0, decls.pattern)),; i8>;. See the :doc:`TableGen Programmer's Reference <./ProgRef>` for an in-depth; description of TableGen. .. _backend:; .. _backends:. TableGen backends; =================. TableGen files have no real meaning without a backend. The default operation; when running ``*-tblgen`` is to print the information in a textual format, but; that's only useful for debugging the TableGen files themselves. The power; in TableGen is, however, to interpret the source files into an internal; representation that can be generated into anything you want. Current usage of TableGen is to create huge include files with tables that you; can either include directly (if the output is in the language you're coding),; or be used in pre-processing via macros surrounding the include of the file. Direct output can be used if the backend already prints a table in C format; or if the output is just a list of strings (for error and warning messages).; Pre-processed output should be used if the same information needs to be used; in different contexts (like Instruction names), so your backend should print; a meta-information list that can be shaped into different compile-time formats. See :doc:`TableGen BackEnds <./BackEnds>` for a list of available; backends, and see the :doc:`TableGen Backend Developer's Guide <./BackGuide>`; for information on how to write and debug a new backend. Tools and Resources; ===================. In addition to this documentation, a list of tools and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/index.rst:10761,power,power,10761,interpreter/llvm-project/llvm/docs/TableGen/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/index.rst,1,['power'],['power']
Energy Efficiency,"lting semantics provides a new notion of ""cycle iteration"" even for; irreducible cycles. But this allows a natural loop to have a heart in a; node other than its header, which has interesting consequences on the; meaning of a loop iteration in terms of convergence. For now, we disallow; this situation since its practical application is very rare. .. _llvm.experimental.convergence.anchor:. ``llvm.experimental.convergence.anchor``; ----------------------------------------. .. code-block:: llvm. token @llvm.experimental.convergence.anchor() convergent readnone. This intrinsic produces an initial convergence token that is independent from; any ""outer scope"". The set of threads executing converged dynamic instances of; this intrinsic is implementation-defined. It is an error to pass a ``convergencectrl`` operand bundle at a; call to this intrinsic. .. note::. The expectation is that all threads within a group that ""happen to be active; at the same time"" will execute converged dynamic instances, so that programs; can detect the maximal set of threads that can communicate efficiently within; some local region of the program. .. _convergence_uncontrolled:. Uncontrolled Convergent Operations; ==================================. Convergent operations with an explicit ``convergencectrl`` operand bundle are; called *controlled convergent operations*. All other convergent operations are; said to be *uncontrolled*. An uncontrolled convergent operation is said to have *implicit convergence; control* determined by the ``convergent`` attribute alone. The semantics of the; ``convergent`` attribute as implemented in LLVM differs from the documented; semantics. The implementation tries to follow common intuition about convergent; operations, which remains under-specified. As such, it is not possible to fully; translate implicit convergence control into explicit convergence control tokens,; and these two modes cannot be mixed in the same function. If a function contains a controlled conv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:27067,efficient,efficiently,27067,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,1,['efficient'],['efficiently']
Energy Efficiency,"lue of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fmul operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fmul(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result * input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:653370,reduce,reduce,653370,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,lvm-mca/Views; - `20`; - `19`; - `1`; - :part:`95%`; * - llvm/tools/llvm-microsoft-demangle-fuzzer; - `2`; - `2`; - `0`; - :good:`100%`; * - llvm/tools/llvm-ml; - `3`; - `1`; - `2`; - :part:`33%`; * - llvm/tools/llvm-modextract; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/tools/llvm-mt; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-nm; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-objcopy; - `3`; - `2`; - `1`; - :part:`66%`; * - llvm/tools/llvm-objdump; - `15`; - `10`; - `5`; - :part:`66%`; * - llvm/tools/llvm-opt-fuzzer; - `2`; - `0`; - `2`; - :none:`0%`; * - llvm/tools/llvm-opt-report; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-pdbutil; - `47`; - `15`; - `32`; - :part:`31%`; * - llvm/tools/llvm-profdata; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-profgen; - `11`; - `6`; - `5`; - :part:`54%`; * - llvm/tools/llvm-rc; - `12`; - `6`; - `6`; - :part:`50%`; * - llvm/tools/llvm-readobj; - `19`; - `3`; - `16`; - :part:`15%`; * - llvm/tools/llvm-reduce; - `7`; - `6`; - `1`; - :part:`85%`; * - llvm/tools/llvm-reduce/deltas; - `40`; - `39`; - `1`; - :part:`97%`; * - llvm/tools/llvm-rtdyld; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-rust-demangle-fuzzer; - `2`; - `2`; - `0`; - :good:`100%`; * - llvm/tools/llvm-shlib; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/tools/llvm-sim; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-size; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-special-case-list-fuzzer; - `2`; - `2`; - `0`; - :good:`100%`; * - llvm/tools/llvm-split; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-stress; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-strings; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/tools/llvm-symbolizer; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-tapi-diff; - `3`; - `3`; - `0`; - :good:`100%`; * - llvm/tools/llvm-tli-checker; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-undname; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/tools/ll,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst:86159,reduce,reduce,86159,interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,1,['reduce'],['reduce']
Energy Efficiency,"lvm.memset.element.unordered.atomic.*``' intrinsic is a specialization of the; '``llvm.memset.*``' intrinsic. It differs in that the ``dest`` is treated as an array; with elements that are exactly ``element_size`` bytes, and the assignment to that array; uses uses a sequence of :ref:`unordered atomic <ordering>` store operations; that are a positive integer multiple of the ``element_size`` in size. Arguments:; """""""""""""""""""". The first three arguments are the same as they are in the :ref:`@llvm.memset <int_memset>`; intrinsic, with the added constraint that ``len`` is required to be a positive integer; multiple of the ``element_size``. If ``len`` is not a positive integer multiple of; ``element_size``, then the behaviour of the intrinsic is undefined. ``element_size`` must be a compile-time constant positive power of two no greater than; target-specific atomic access size limit. The ``dest`` input pointer must have the ``align`` parameter attribute specified. It; must be a power of two no less than the ``element_size``. Caller guarantees that; the destination pointer is aligned to that boundary. Semantics:; """""""""""""""""""". The '``llvm.memset.element.unordered.atomic.*``' intrinsic sets the ``len`` bytes of; memory starting at the destination location to the given ``value``. The memory is; set with a sequence of store operations where each access is guaranteed to be a; multiple of ``element_size`` bytes wide and aligned at an ``element_size`` boundary. The order of the assignment is unspecified. Only one write is issued to the; destination buffer per element. It is well defined to have concurrent reads and; writes to the destination provided those reads and writes are unordered atomic; when specified. This intrinsic does not provide any additional ordering guarantees over those; provided by a set of unordered stores to the destination. Lowering:; """""""""""""""""". In the most general case call to the '``llvm.memset.element.unordered.atomic.*``' is; lowered to a call to the symbol `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:964846,power,power,964846,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"lvm.org/>`_ is a front-end that uses a LLVM; license. Clang works by taking the source language (e.g. C++) and translating it; into an intermediate representation that is then received by the compiler back; end (i.e., the LLVM backend). Its library-based architecture makes it relatively; easy to adapt Clang and build new tools based on it. Cling inherits a number of; features from LLVM and Clang, such as: fast compiling and low memory use,; efficient C++ parsing, extremely clear and concise diagnostics, Just-In-Time; compilation, pluggable optimizers, and support for `GCC <https://gcc.gnu.org/>`_; extensions. Interpreters allow for exploration of software development at the rate of human; thought. Nevertheless, interpreter code can be slower than compiled code due to; the fact that translating code at run time adds to the overhead and therefore; causes the execution speed to be slower. This issue is overcome by exploiting; the *Just-In-Time* (`JIT; <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_) compilation method,; which allows an efficient memory management (for example, by evaluating whether; a certain part of the source code is executed often, and then compile this part,; therefore reducing the overall execution time). With the JIT approach, the developer types the code in Cling's command; prompt. The input code is then lowered to Clang, where is compiled and; eventually transformed in order to attach specific behavior. Clang compiles then; the input into an AST representation, that is then lowered to LLVM IR, an; `intermediate language; <https://en.wikipedia.org/wiki/Common_Intermediate_Language>`_ that is not; understood by the computer. LLVMâ€™s just-in-time compilation infrastructure; translates then the intermediate code into machine language (eg. Intel x86 or; NVPTX) when required for use. Cling's JIT compiler relies on LLVM's project; `ORC <https://llvm.org/docs/ORCv2.html>`_ (On Request Compilation) Application; Programming Interfaces (APIs).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst:1429,efficient,efficient,1429,interpreter/cling/docs/chapters/implementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst,1,['efficient'],['efficient']
Energy Efficiency,"lvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:656655,reduce,reduce,656655,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,lvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338155,reduce,reduce,338155,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"ly inside; this loop. Programs written in LLVM IR are always in SSA form but not necessarily; in LCSSA. To achieve the latter, for each value that is live across the; loop boundary, single entry PHI nodes are inserted to each of the exit blocks; [#lcssa-construction]_ in order to ""close"" these values inside the loop.; In particular, consider the following loop:. .. code-block:: C. c = ...;; for (...) {; if (c); X1 = ...; else; X2 = ...; X3 = phi(X1, X2); // X3 defined; }. ... = X3 + 4; // X3 used, i.e. live; // outside the loop. In the inner loop, the X3 is defined inside the loop, but used; outside of it. In Loop Closed SSA form, this would be represented as follows:. .. code-block:: C. c = ...;; for (...) {; if (c); X1 = ...; else; X2 = ...; X3 = phi(X1, X2);; }; X4 = phi(X3);. ... = X4 + 4;. This is still valid LLVM; the extra phi nodes are purely redundant,; but all LoopPass'es are required to preserve them.; This form is ensured by the LCSSA (:ref:`-lcssa <passes-lcssa>`); pass and is added automatically by the LoopPassManager when; scheduling a LoopPass.; After the loop optimizations are done, these extra phi nodes; will be deleted by :ref:`-instcombine <passes-instcombine>`. Note that an exit block is outside of a loop, so how can such a phi ""close""; the value inside the loop since it uses it outside of it ? First of all,; for phi nodes, as; `mentioned in the LangRef <https://llvm.org/docs/LangRef.html#id311>`_:; ""the use of each incoming value is deemed to occur on the edge from the; corresponding predecessor block to the current block"". Now, an; edge to an exit block is considered outside of the loop because; if we take that edge, it leads us clearly out of the loop. However, an edge doesn't actually contain any IR, so in source code,; we have to choose a convention of whether the use happens in; the current block or in the respective predecessor. For LCSSA's purpose,; we consider the use happens in the latter (so as to consider the; use inside) [#point-of-u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:11904,schedul,scheduling,11904,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['schedul'],['scheduling']
Energy Efficiency,"ly three types of records; are sent: 'summary' (derived from what was currently posted), 'dataset',; with entries per dataset processed in the query, and 'files', with; entries per file processed in the query. In SQL terms, each of this; records corresponds to a different table. Sending of any of the three; records can be toggled independently.; In TProofMgr, add 'ping' functionality to test in non-blocking way if; a PROOF service is listening at a given port of a given host.; Improvements. In PROOF-Bench, file generation, add the possibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once up.; In XrdProofd, move the check for the username after authentication.; This is because authentication may run some credentials-to-user mapping; which can modify the requested username. This way we really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:1872,monitor,monitoring,1872,proof/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html,2,['monitor'],['monitoring']
Energy Efficiency,"ly. When a compilation is successful (there are no errors), the driver; checks the bit and emits an ""unused argument"" warning for any arguments; which were never accessed. This is conservative (the argument may not; have been used to do what the user wanted) but still catches the most; obvious cases. Relation to GCC Driver Concepts; -------------------------------. For those familiar with the gcc driver, this section provides a brief; overview of how things from the gcc driver map to the clang driver. - **Driver Driver**. The driver driver is fully integrated into the clang driver. The; driver simply constructs additional Actions to bind the architecture; during the *Pipeline* phase. The tool chain specific argument; translation is responsible for handling ``-Xarch_``. The one caveat is that this approach requires ``-Xarch_`` not be used; to alter the compilation itself (for example, one cannot provide; ``-S`` as an ``-Xarch_`` argument). The driver attempts to reject; such invocations, and overall there isn't a good reason to abuse; ``-Xarch_`` to that end in practice. The upside is that the clang driver is more efficient and does little; extra work to support universal builds. It also provides better error; reporting and UI consistency. - **Specs**. The clang driver has no direct correspondent for ""specs"". The; majority of the functionality that is embedded in specs is in the; Tool specific argument translation routines. The parts of specs which; control the compilation pipeline are generally part of the *Pipeline*; stage. - **Toolchains**. The gcc driver has no direct understanding of tool chains. Each gcc; binary roughly corresponds to the information which is embedded; inside a single ToolChain. The clang driver is intended to be portable and support complex; compilation environments. All platform and tool chain specific code; should be protected behind either abstract or well defined interfaces; (such as whether the platform supports use as a driver driver).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:15869,efficient,efficient,15869,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['efficient'],['efficient']
Energy Efficiency,"lysis.html>`_ pass is the default; implementation for the interface. Pass Statistics; ===============. The `Statistic <https://llvm.org/doxygen/Statistic_8h_source.html>`_ class is; designed to be an easy way to expose various success metrics from passes.; These statistics are printed at the end of a run, when the :option:`-stats`; command line option is enabled on the command line. See the :ref:`Statistics; section <Statistic>` in the Programmer's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analyses are available already, which analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:41144,reduce,reduce,41144,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['reduce'],['reduce']
Energy Efficiency,"m of prefix that; specifies the byte count. It can be used:. * as the value of a debugging information entry attribute that is encoded using; class ``exprloc`` (see :ref:`amdgpu-dwarf-classes-and-forms`),. * as the operand to certain operation expression operations,. * as the operand to certain call frame information operations (see; :ref:`amdgpu-dwarf-call-frame-information`),. * and in location list entries (see; :ref:`amdgpu-dwarf-location-list-expressions`). .. _amdgpu-dwarf-vendor-extensions-operations:. A.2.5.4.0 Vendor Extension Operations; #####################################. 1. ``DW_OP_LLVM_user``. ``DW_OP_LLVM_user`` encodes a vendor extension operation. It has at least one; operand: a ULEB128 constant identifying a vendor extension operation. The; remaining operands are defined by the vendor extension. The vendor extension; opcode 0 is reserved and cannot be used by any vendor extension. *The DW_OP_user encoding space can be understood to supplement the space; defined by DW_OP_lo_user and DW_OP_hi_user that is allocated by the standard; for the same purpose.*. .. _amdgpu-dwarf-stack-operations:. A.2.5.4.1 Stack Operations; ##########################. .. note::. This section replaces DWARF Version 5 section 2.5.1.3. The following operations manipulate the DWARF stack. Operations that index the; stack assume that the top of the stack (most recently added entry) has index 0.; They allow the stack entries to be either a value or location description. If any stack entry accessed by a stack operation is an incomplete composite; location description (see; :ref:`amdgpu-dwarf-composite-location-description-operations`), then the DWARF; expression is ill-formed. .. note::. These operations now support stack entries that are values and location; descriptions. .. note::. If it is desired to also make them work with incomplete composite location; descriptions, then would need to define that the composite location storage; specified by the incomplete composite locati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:68261,allocate,allocated,68261,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency,"m the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3502,reduce,reduce,3502,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['reduce'],['reduce']
Energy Efficiency,m-pdbutil/PrettyExternalSymbolDumper.cpp; llvm/tools/llvm-pdbutil/PrettyTypeDumper.cpp; llvm/tools/llvm-pdbutil/TypeReferenceTracker.h; llvm/tools/llvm-pdbutil/YAMLOutputStyle.h; llvm/tools/llvm-profgen/CallContext.h; llvm/tools/llvm-profgen/CSPreInliner.cpp; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337100,reduce,reduce,337100,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,m-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337663,reduce,reduce,337663,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,m-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337925,reduce,reduce,337925,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"m.experimental.constrained.fcmp``' will only raise an exception; if either operand is a SNAN. The signaling comparison operation; performed by '``llvm.experimental.constrained.fcmps``' will raise an; exception if either operand is a NAN (QNAN or SNAN). Such an exception; does not preclude a result being produced (e.g. exception might only; set a flag), therefore the distinction between ordered and unordered; comparisons is also relevant for the; '``llvm.experimental.constrained.fcmps``' intrinsic. '``llvm.experimental.constrained.fmuladd``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.experimental.constrained.fmuladd(<type> <op1>, <type> <op2>,; <type> <op3>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.fmuladd``' intrinsic represents; multiply-add expressions that can be fused if the code generator determines; that (a) the target instruction set has support for a fused operation,; and (b) that the fused operation is more efficient than the equivalent,; separate pair of mul and add instructions. Arguments:; """""""""""""""""""". The first three arguments to the '``llvm.experimental.constrained.fmuladd``'; intrinsic must be floating-point or vector of floating-point values.; All three arguments must have identical types. The fourth and fifth arguments specify the rounding mode and exception behavior; as described above. Semantics:; """""""""""""""""""". The expression:. ::. %0 = call float @llvm.experimental.constrained.fmuladd.f32(%a, %b, %c,; metadata <rounding mode>,; metadata <exception behavior>). is equivalent to the expression:. ::. %0 = call float @llvm.experimental.constrained.fmul.f32(%a, %b,; metadata <rounding mode>,; metadata <exception behavior>); %1 = call float @llvm.experimental.constrained.fadd.f32(%0, %c,; metadata <rounding mode>,; metadata <exception behavior>). except that it is unspecified whether rounding will be performed betw",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:888061,efficient,efficient,888061,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency,"m.vector.reduce.fmax <int_vector_reduce_fmax>` intrinsic (and thus the; '``llvm.maxnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmax.v4f32(float %float, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float QNAN, float QNAN, float QNAN, float QNAN>; %reduction = call float @llvm.vector.reduce.fmax.v4f32(<4 x float> %masked.a); %also.r = call float @llvm.maxnum.f32(float %reduction, float %start). .. _int_vp_reduce_fmin:. '``llvm.vp.reduce.fmin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmin.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmin.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explici",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:773894,reduce,reduce,773894,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"m.vp.reduce.smax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smax``' intrinsic performs the signed-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.smax <int_vector_reduce_smax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MIN`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smax.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 -128, i8 -128, i8 -128, i8 -128>; %reduction = call i8 @llvm.vector.reduce.smax.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smax.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_smin:. '``llvm.vp.reduce.smin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:763877,reduce,reduce,763877,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"m.vp.reduce.smin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smin``' intrinsic performs the signed-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.smin <int_vector_reduce_smin>`) of the; vector operand ``val`` on each enabled lane, and taking the minimum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MAX`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smin.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. '``llvm.vp.reduce.umax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:765942,reduce,reduce,765942,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like to add a CustomBehaviour class for a target that doesn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :program:`llvm-mca` comes with several Views such as the Timeline View and; Summary View. These Views are generic and can work with most (if not all); targets. I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:45919,schedul,scheduling,45919,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"make the memory manager responsible for; transferring memory to the target address space and applying memory protections,; since the memory manager must know how to communicate with the executor, and; since sharing and protection assignment can often be efficiently managed (in; the common case of running across processes on the same machine for security); via the host operating system's virtual memory management APIs. To satisfy these requirements ``JITLinkMemoryManager`` adopts the following; design: The memory manager itself has just two virtual methods for asynchronous; operations (each with convenience overloads for calling synchronously):. .. code-block:: c++. /// Called when allocation has been completed.; using OnAllocatedFunction =; unique_function<void(Expected<std::unique_ptr<InFlightAlloc>)>;. /// Called when deallocation has completed.; using OnDeallocatedFunction = unique_function<void(Error)>;. /// Call to allocate memory.; virtual void allocate(const JITLinkDylib *JD, LinkGraph &G,; OnAllocatedFunction OnAllocated) = 0;. /// Call to deallocate memory.; virtual void deallocate(std::vector<FinalizedAlloc> Allocs,; OnDeallocatedFunction OnDeallocated) = 0;. The ``allocate`` method takes a ``JITLinkDylib*`` representing the target; simulated dylib, a reference to the ``LinkGraph`` that must be allocated for,; and a callback to run once an ``InFlightAlloc`` has been constructed.; ``JITLinkMemoryManager`` implementations can (optionally) use the ``JD``; argument to manage a per-simulated-dylib memory pool (since code model; constraints are typically imposed on a per-dylib basis, and not across; dylibs) [2]_. The ``LinkGraph`` describes the object file that we need to; allocate memory for. The allocator must allocate working memory for all of; the Blocks defined in the graph, assign address space for each Block within the; executing processes memory, and update the Blocks' addresses to reflect this; assignment. Block content should be copied to working memory",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:27093,allocate,allocate,27093,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocate']
Energy Efficiency,"maller; changes increases the odds that any of the work will be committed to the main; repository. To address these problems, LLVM uses an incremental development style and we; require contributors to follow this practice when making a large/invasive; change. Some tips:. * Large/invasive changes usually have a number of secondary changes that are; required before the big change can be made (e.g. API cleanup, etc). These; sorts of changes can often be done before the major change is done,; independently of that work. * The remaining inter-related work should be decomposed into unrelated sets of; changes if possible. Once this is done, define the first increment and get; consensus on what the end goal of the change is. * Each change in the set can be stand alone (e.g. to fix a bug), or part of a; planned series of changes that works towards the development goal. * Each change should be kept as small as possible. This simplifies your work; (into a logical progression), simplifies code review and reduces the chance; that you will get negative feedback on the change. Small increments also; facilitate the maintenance of a high quality code base. * Often, an independent precursor to a big change is to add a new API and slowly; migrate clients to use the new API. Each change to use the new API is often; ""obvious"" and can be committed without review. Once the new API is in place; and used, it is much easier to replace the underlying implementation of the; API. This implementation change is logically separate from the API; change. If you are interested in making a large change, and this scares you, please make; sure to first `discuss the change/gather consensus`_ then ask about the best way; to go about making the change. Attribution of Changes; ----------------------. When contributors submit a patch to an LLVM project, other developers with; commit access may commit it for the author once appropriate (based on the; progression of code review, etc.). When doing so, it is impo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:28858,reduce,reduces,28858,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['reduce'],['reduces']
Energy Efficiency,"manipulating VPlans must not modify the input IR.; In particular, if the best option is not to vectorize at all, the; vectorization process terminates before reaching Step 3, and compilation; should proceed as if VPlans had not been built. 2. Align Cost & Execute: each VPlan must support both estimating the cost and; generating the output IR code, such that the cost estimation evaluates the; to-be-generated code reliably. 3. Support vectorizing additional constructs:. a. Outer-loop vectorization. In particular, VPlan must be able to model the; control-flow of the output IR which may include multiple basic-blocks and; nested loops.; b. SLP vectorization.; c. Combinations of the above, including nested vectorization: vectorizing; both an inner loop and an outer-loop at the same time (each with its own; VF and UF), mixed vectorization: vectorizing a loop with SLP patterns; inside [4]_, (re)vectorizing input IR containing vector code.; d. Function vectorization [2]_. 4. Support multiple candidates efficiently. In particular, similar candidates; related to a range of possible VF's and UF's must be represented efficiently.; Potential versioning needs to be supported efficiently. 5. Support vectorizing idioms, such as interleaved groups of strided loads or; stores. This is achieved by modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:2945,efficient,efficiently,2945,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['efficient'],['efficiently']
Energy Efficiency,"mapped into a different one depending on; the current instruction set. Instruction Aliases; ^^^^^^^^^^^^^^^^^^^. The most general phase of alias processing occurs while matching is happening:; it provides new forms for the matcher to match along with a specific instruction; to generate. An instruction alias has two parts: the string to match and the; instruction to generate. For example:. ::. def : InstAlias<""movsx $src, $dst"", (MOVSX16rr8W GR16:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX16rm8W GR16:$dst, i8mem:$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX32rr8 GR32:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX32rr16 GR32:$dst, GR16 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr8 GR64:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr16 GR64:$dst, GR16 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr32 GR64:$dst, GR32 :$src)>;. This shows a powerful example of the instruction aliases, matching the same; mnemonic in multiple different ways depending on what operands are present in; the assembly. The result of instruction aliases can include operands in a; different order than the destination instruction, and can use an input multiple; times, for example:. ::. def : InstAlias<""clrb $reg"", (XOR8rr GR8 :$reg, GR8 :$reg)>;; def : InstAlias<""clrw $reg"", (XOR16rr GR16:$reg, GR16:$reg)>;; def : InstAlias<""clrl $reg"", (XOR32rr GR32:$reg, GR32:$reg)>;; def : InstAlias<""clrq $reg"", (XOR64rr GR64:$reg, GR64:$reg)>;. This example also shows that tied operands are only listed once. In the X86; backend, XOR8rr has two input GR8's and one output GR8 (where an input is tied; to the output). InstAliases take a flattened operand list without duplicates; for tied operands. The result of an instruction alias can also use immediates; and fixed physical registers which are added as simple immediate operands in the; result, for example:. ::. // Fixed Immediate operand.; def : InstAlias<""aad"", (AAD8i8 10)>;. // Fixe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:84202,power,powerful,84202,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['power'],['powerful']
Energy Efficiency,"mation`. For AMDGPU, the Common Information Entry (CIE) fields have the following values:. 1. ``augmentation`` string contains the following null-terminated UTF-8 string:. ::. [amd:v0.0]. The ``vX.Y`` specifies the major X and minor Y version number of the AMDGPU; extensions used in this CIE or to the FDEs that use it. The version number; conforms to [SEMVER]_. 2. ``address_size`` for the ``Global`` address space is defined in; :ref:`amdgpu-dwarf-address-space-identifier`. 3. ``segment_selector_size`` is 0 as AMDGPU does not use a segment selector. 4. ``code_alignment_factor`` is 4 bytes. .. TODO::. Add to :ref:`amdgpu-processor-table` table. 5. ``data_alignment_factor`` is 4 bytes. .. TODO::. Add to :ref:`amdgpu-processor-table` table. 6. ``return_address_register`` is ``PC_32`` for 32-bit processes and ``PC_64``; for 64-bit processes defined in :ref:`amdgpu-dwarf-register-identifier`. 7. ``initial_instructions`` Since a subprogram X with fewer registers can be; called from subprogram Y that has more allocated, X will not change any of; the extra registers as it cannot access them. Therefore, the default rule; for all columns is ``same value``. For AMDGPU the register number follows the numbering defined in; :ref:`amdgpu-dwarf-register-identifier`. For AMDGPU the instructions are variable size. A consumer can subtract 1 from; the return address to get the address of a byte within the call site; instructions. See DWARF Version 5 section 6.4.4. Accelerated Access; ------------------. See DWARF Version 5 section 6.1. Lookup By Name Section Header; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. See DWARF Version 5 section 6.1.1.4.1 and :ref:`amdgpu-dwarf-lookup-by-name`. For AMDGPU the lookup by name section header table:. ``augmentation_string_size`` (uword). Set to the length of the ``augmentation_string`` value which is always a; multiple of 4. ``augmentation_string`` (sequence of UTF-8 characters). Contains the following UTF-8 string null padded to a multiple of 4 bytes:. ::. [amdg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:112011,allocate,allocated,112011,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"max.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umin.*``' intrinsics do an unsigned; integer ``MIN`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmax:. '``llvm.vector.reduce.fmax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmax.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmax.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmin:. '``llvm.vector.reduce.fmin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmin.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:658668,reduce,reduce,658668,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:36642,schedul,scheduling,36642,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"me time. One of the great; things about creating your own language is that you get to decide what; is good or bad. In this tutorial we'll assume that it is okay to use; this as a way to show some interesting parsing techniques. At the end of this tutorial, we'll run through an example Kaleidoscope; application that `renders the Mandelbrot set <#kicking-the-tires>`_. This gives an; example of what you can build with Kaleidoscope and its feature set. User-defined Operators: the Idea; ================================. The ""operator overloading"" that we will add to Kaleidoscope is more; general than in languages like C++. In C++, you are only allowed to; redefine existing operators: you can't programmatically change the; grammar, introduce new operators, change precedence levels, etc. In this; chapter, we will add this capability to Kaleidoscope, which will let the; user round out the set of operators that are supported. The point of going into user-defined operators in a tutorial like this; is to show the power and flexibility of using a hand-written parser.; Thus far, the parser we have been implementing uses recursive descent; for most parts of the grammar and operator precedence parsing for the; expressions. See `Chapter 2 <LangImpl02.html>`_ for details. By; using operator precedence parsing, it is very easy to allow; the programmer to introduce new operators into the grammar: the grammar; is dynamically extensible as the JIT runs. The two specific features we'll add are programmable unary operators; (right now, Kaleidoscope has no unary operators at all) as well as; binary operators. An example of this is:. ::. # Logical unary not.; def unary!(v); if v then; 0; else; 1;. # Define > with the same precedence as <.; def binary> 10 (LHS RHS); RHS < LHS;. # Binary ""logical or"", (note that it does not ""short circuit""); def binary| 5 (LHS RHS); if LHS then; 1; else if RHS then; 1; else; 0;. # Define = with slightly lower precedence than relationals.; def binary= 9 (LHS RH",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst:1903,power,power,1903,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,1,['power'],['power']
Energy Efficiency,"me; histograms in `SlaveBegin()` and adds them to the instance `fOutput`,; which is of the class `TList` [^6]. The final processing in; `Terminate()` allows to access histograms and store, display or save; them as pictures. This is shown in the example via the `TList`; `fOutput`. See the commented listing below for more details; most of the; text is actually comments generated automatically by; `TTree::MakeSelector`. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/MySelector.C; ```. ### *For power-users:* Multi-core processing with `PROOF lite` ###. The processing of n-tuples via a selector function of type `TSelector`; through `TChain::Process()`, as described at the end of the previous; section, offers an additional advantage in particular for very large; data sets: on distributed systems or multi-core architectures, portions; of data can be processed in parallel, thus significantly reducing the; execution time. On modern computers with multi-core CPUs or; hardware-threading enabled, this allows a much faster turnaround of; analyses, since all the available CPU power is used. On distributed systems, a PROOF server and worker nodes have to be set; up, as described in detail in the ROOT documentation. On a single; computer with multiple cores, `PROOF lite` can be used instead. Try the; following little macro, `RunMySelector.C`, which contains two extra; lines compared to the example above (adjust the number of workers; according to the number of CPU cores):. ``` {.cpp}; {// set up a TChain; TChain *ch=new TChain(""cond_data"", ""My Chain for Example N-Tuple"");; ch->Add(""conductivity_experiment*.root"");; // eventually, start Proof Lite on cores; TProof::Open(""workers=4"");; ch->SetProof();; ch->Process(""MySelector.C+"");}; ```. The first command, `TProof::Open(const char*)` starts a local PROOF; server (if no arguments are specified, all cores will be used), and the; command `ch->SetProof();` enables processing of the chain using PROOF.; Now, when issuing the command `ch->Process(""M",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:9436,power,power,9436,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['power'],['power']
Energy Efficiency,"mean sigma=msig_sigma ] = 1; RooEfficiency::effSigPdf[ cat=cut effFunc=effSig ] = 0.899817; RooFormulaVar::effSig[ actualVars=(pt,as,ms,ss) formula=""0.5*@1*(1+TMath::Erf((@0-@2)/@3))"" ] = 0.899817; RooProdPdf::bkg[ ptBkgPdf * mllBkgPdf * effBkgPdf|pt ] = 0.267845; RooExponential::ptBkgPdf[ x=pt c=pbkg_slope ] = 0.449329; RooPolynomial::mllBkgPdf[ x=mll coefList=(mbkg_slope) ] = 0.775; RooEfficiency::effBkgPdf[ cat=cut effFunc=effBkg ] = 0.76916; RooFormulaVar::effBkg[ actualVars=(pt,ab,mb,sb) formula=""0.5*@1*(1+TMath::Erf((@0-@2)/@3))"" ] = 0.76916. The workspace factory can now access all objects in the generic object store of the workspace, e.g. TMatrixDSym* cov ; RooWorkspace w(""w"") ;; w.import(*cov,""cov"") ;; w.factory(""MultiVarGaussian::mvg({x[-10,10],y[-10,10]},{3,5},cov)"") ;. The workspace factory now correctly identifies and matches typedef-ed names in factory constructor; specifications.; All objects created by the factory and inserted by the workspace get a string attribute ""factory_tag"",; that contains the reduced factory string that was used to create that object, e.g. RooWorkspace w(""w"") ;; w.factory(""Gaussian::g(x[-10,10],m[0],s[3])"") ;; cout << w.pdf(""g"")->getStringAttribute(""factory_tag"") << endl ;; RooGaussian::g(x,m,s). Previously all factory orders that would create objects with names of objects that already existed always; resulted in an error. Now, this will only happen if the factory tag of the existing object is different; from the tag of the existing object. w.factory(""Gaussian::g(x[-10,10],m[0],s[3])"") ;; w.factory(""Chebychev::g(x[-10,10],{0,1,2})"") ; // Now OK, x has identical spec, existing x will be used. Improvements to functions and pdfs. Addition to, reorganization of morphing operator classes. The existing class RooLinearMorph which; implements 'Alex Read' morphing has been renamed RooIntegralMorph. A new class RooMomentMorph; has been added (contribution from Max Baak and Stefan Gadatsch) that implements a different morphing algorithm ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:5240,reduce,reduced,5240,roofit/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html,2,['reduce'],['reduced']
Energy Efficiency,"member and later. For example, if you specify -march=i486, the compiler is; allowed to generate instructions that are valid on i486 and later processors,; but which may not exist on earlier ones. Code Generation Options; ~~~~~~~~~~~~~~~~~~~~~~~. .. option:: -O0, -O1, -O2, -O3, -Ofast, -Os, -Oz, -Og, -O, -O4. Specify which optimization level to use:. :option:`-O0` Means ""no optimization"": this level compiles the fastest and; generates the most debuggable code. :option:`-O1` Somewhere between :option:`-O0` and :option:`-O2`. :option:`-O2` Moderate level of optimization which enables most; optimizations. :option:`-O3` Like :option:`-O2`, except that it enables optimizations that; take longer to perform or that may generate larger code (in an attempt to; make the program run faster). :option:`-Ofast` Enables all the optimizations from :option:`-O3` along; with other aggressive optimizations that may violate strict compliance with; language standards. :option:`-Os` Like :option:`-O2` with extra optimizations to reduce code; size. :option:`-Oz` Like :option:`-Os` (and thus :option:`-O2`), but reduces code; size further. :option:`-Og` Like :option:`-O1`. In future versions, this option might; disable different optimizations in order to improve debuggability. :option:`-O` Equivalent to :option:`-O1`. :option:`-O4` and higher. Currently equivalent to :option:`-O3`. .. option:: -g, -gline-tables-only, -gmodules. Control debug information output. Note that Clang debug information works; best at :option:`-O0`. When more than one option starting with `-g` is; specified, the last one wins:. :option:`-g` Generate debug information. :option:`-gline-tables-only` Generate only line table debug information. This; allows for symbolicated backtraces with inlining information, but does not; include any information about variables, their locations or types. :option:`-gmodules` Generate debug information that contains external; references to types defined in Clang modules or precompiled he",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:11180,reduce,reduce,11180,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['reduce'],['reduce']
Energy Efficiency,"memory, or; * the shadow memory tag is actually a short granule size, the value being loaded; is in bounds of the granule and the pointer tag is equal to the last byte of; the granule. Pointer tags between 1 to `TG-1` are possible and are as likely as any other; tag. This means that these tags in memory have two interpretations: the full; tag interpretation (where the pointer tag is between 1 and `TG-1` and the; last byte of the granule is ordinary data) and the short tag interpretation; (where the pointer tag is stored in the granule). When HWASAN detects an error near a memory tag between 1 and `TG-1`, it; will show both the memory tag and the last byte of the granule. Currently,; it is up to the user to disambiguate the two possibilities. Instrumentation; ===============. Memory Accesses; ---------------; In the majority of cases, memory accesses are prefixed with a call to; an outlined instruction sequence that verifies the tags. The code size; and performance overhead of the call is reduced by using a custom calling; convention that. * preserves most registers, and; * is specialized to the register containing the address, and the type and; size of the memory access. Currently, the following sequence is used:. .. code-block:: none. // int foo(int *a) { return *a; }; // clang -O2 --target=aarch64-linux-android30 -fsanitize=hwaddress -S -o - load.c; [...]; foo:; stp x30, x20, [sp, #-16]!; adrp x20, :got:__hwasan_shadow // load shadow address from GOT into x20; ldr x20, [x20, :got_lo12:__hwasan_shadow]; bl __hwasan_check_x0_2_short_v2 // call outlined tag check; // (arguments: x0 = address, x20 = shadow base;; // ""2"" encodes the access type and size); ldr w0, [x0] // inline load; ldp x30, x20, [sp], #16; ret. [...]; __hwasan_check_x0_2_short_v2:; sbfx x16, x0, #4, #52 // shadow offset; ldrb w16, [x20, x16] // load shadow tag; cmp x16, x0, lsr #56 // extract address tag, compare with shadow tag; b.ne .Ltmp0 // jump to short tag handler on mismatch; .Ltmp1:; ret; .Ltm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:3408,reduce,reduced,3408,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['reduce'],['reduced']
Energy Efficiency,"ment for; ``alloca``. SmallVector has grown a few other minor advantages over std::vector, causing; ``SmallVector<Type, 0>`` to be preferred over ``std::vector<Type>``. #. std::vector is exception-safe, and some implementations have pessimizations; that copy elements when SmallVector would move them. #. SmallVector understands ``std::is_trivially_copyable<Type>`` and uses realloc aggressively. #. Many LLVM APIs take a SmallVectorImpl as an out parameter (see the note; below). #. SmallVector with N equal to 0 is smaller than std::vector on 64-bit; platforms, since it uses ``unsigned`` (instead of ``void*``) for its size; and capacity. .. note::. Prefer to use ``ArrayRef<T>`` or ``SmallVectorImpl<T>`` as a parameter type. It's rarely appropriate to use ``SmallVector<T, N>`` as a parameter type.; If an API only reads from the vector, it should use :ref:`ArrayRef; <dss_arrayref>`. Even if an API updates the vector the ""small size"" is; unlikely to be relevant; such an API should use the ``SmallVectorImpl<T>``; class, which is the ""vector header"" (and methods) without the elements; allocated after it. Note that ``SmallVector<T, N>`` inherits from; ``SmallVectorImpl<T>`` so the conversion is implicit and costs nothing. E.g. .. code-block:: c++. // DISCOURAGED: Clients cannot pass e.g. raw arrays.; hardcodedContiguousStorage(const SmallVectorImpl<Foo> &In);; // ENCOURAGED: Clients can pass any contiguous storage of Foo.; allowsAnyContiguousStorage(ArrayRef<Foo> In);. void someFunc1() {; Foo Vec[] = { /* ... */ };; hardcodedContiguousStorage(Vec); // Error.; allowsAnyContiguousStorage(Vec); // Works.; }. // DISCOURAGED: Clients cannot pass e.g. SmallVector<Foo, 8>.; hardcodedSmallSize(SmallVector<Foo, 2> &Out);; // ENCOURAGED: Clients can pass any SmallVector<Foo, N>.; allowsAnySmallSize(SmallVectorImpl<Foo> &Out);. void someFunc2() {; SmallVector<Foo, 8> Vec;; hardcodedSmallSize(Vec); // Error.; allowsAnySmallSize(Vec); // Works.; }. Even though it has ""``Impl``"" in the name",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:61919,allocate,allocated,61919,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"ment. The; ``acquire`` and ``acq_rel`` orderings aren't valid on ``store`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic stores. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemporal`` does not have any; defined semantics for atomic stores. The optional constant ``align`` argument specifies the alignment of the; operation (that is, the alignment of the memory address). It is the; responsibility of the code emitter to ensure that the alignment information is; correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address space. Access of the high bytes can interfere with debugging tools, so; should not be accessed if the function has the ``sanitize_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. An omitted ``align`` argument means that the operation has the; ABI alignment for the target. The optional ``!nontemporal`` metadata must reference a single metadata; name ``<nontemp_node>`` corresponding to a metadata node with one ``i32`` entry; of value 1. The existence of the ``!nontemporal`` metadata on the instruction; tells the optimizer and code generator that this load is not expected to; be reused in the cache. The code generato",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:421296,efficient,efficient,421296,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency,"mentation), and that; ``ctypes.c_bool`` is a C ``_Bool`` type, not C++ ``bool``. `Memory`; --------. C++ has three ways of allocating heap memory (``malloc``, ``new``, and; ``new[]``) and three corresponding ways of deallocation (``free``,; ``delete``, and ``delete[]``).; Direct use of ``malloc`` and ``new`` should be avoided for C++ classes, as; these may override ``operator new`` to control their own allocation.; However these low-level allocators can be necessary for builtin types on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.array_delete**: an interface on top of C++'s ``delete[]``.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.array_delete(arr); >>>. `argc/argv`; -----------. C/C++'s ``main`` function can take the numbe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:10035,allocate,allocates,10035,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,1,['allocate'],['allocates']
Energy Efficiency,"ments from [src, src + nelem - 1] in tableSrc to; // [dst, dst + nelem - 1] in tableDst; void copy(int dst, int src, int nelem) {; __builtin_wasm_table_copy(tableDst, tableSrc, dst, src, nelem);; }. Builtin Functions; =================. Clang supports a number of builtin library functions with the same syntax as; GCC, including things like ``__builtin_nan``, ``__builtin_constant_p``,; ``__builtin_choose_expr``, ``__builtin_types_compatible_p``,; ``__builtin_assume_aligned``, ``__sync_fetch_and_add``, etc. In addition to; the GCC builtins, Clang supports a number of builtins that GCC does not, which; are listed here. Please note that Clang does not and will not support all of the GCC builtins; for vector operations. Instead of using builtins, you should use the functions; defined in target-specific header files like ``<xmmintrin.h>``, which define; portable wrappers for these. Many of the Clang versions of these functions are; implemented directly in terms of :ref:`extended vector support; <langext-vectors>` instead of builtins, in order to reduce the number of; builtins that we need to implement. ``__builtin_alloca``; --------------------. ``__builtin_alloca`` is used to dynamically allocate memory on the stack. Memory; is automatically freed upon function termination. **Syntax**:. .. code-block:: c++. __builtin_alloca(size_t n). **Example of Use**:. .. code-block:: c++. void init(float* data, size_t nbelems);; void process(float* data, size_t nbelems);; int foo(size_t n) {; auto mem = (float*)__builtin_alloca(n * sizeof(float));; init(mem, n);; process(mem, n);; /* mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca`` is meant to be used to allocate a dynamic amount of memory; on the stack. This amount is subject to stack allocation limits. Query for this feature with ``__has_builtin(__builtin_alloca)``. ``__builtin_alloca_with_align``; -------------------------------. ``__builtin_alloca_with_align`` is used to dynamically allocate m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:96784,reduce,reduce,96784,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['reduce'],['reduce']
Energy Efficiency,"meration-values-table`; defines the values. Used by CP to set up; ``COMPUTE_PGM_RSRC2.TIDIG_CMP_CNT``.; 13 1 bit ENABLE_EXCEPTION_ADDRESS_WATCH Must be 0. Wavefront starts execution; with address watch; exceptions enabled which; are generated when L1 has; witnessed a thread access; an *address of; interest*. CP is responsible for; filling in the address; watch bit in; ``COMPUTE_PGM_RSRC2.EXCP_EN_MSB``; according to what the; runtime requests.; 14 1 bit ENABLE_EXCEPTION_MEMORY Must be 0. Wavefront starts execution; with memory violation; exceptions exceptions; enabled which are generated; when a memory violation has; occurred for this wavefront from; L1 or LDS; (write-to-read-only-memory,; mis-aligned atomic, LDS; address out of range,; illegal address, etc.). CP sets the memory; violation bit in; ``COMPUTE_PGM_RSRC2.EXCP_EN_MSB``; according to what the; runtime requests.; 23:15 9 bits GRANULATED_LDS_SIZE Must be 0. CP uses the rounded value; from the dispatch packet,; not this value, as the; dispatch may contain; dynamically allocated group; segment memory. CP writes; directly to; ``COMPUTE_PGM_RSRC2.LDS_SIZE``. Amount of group segment; (LDS) to allocate for each; work-group. Granularity is; device specific:. GFX6; roundup(lds-size / (64 * 4)); GFX7-GFX11; roundup(lds-size / (128 * 4)). 24 1 bit ENABLE_EXCEPTION_IEEE_754_FP Wavefront starts execution; _INVALID_OPERATION with specified exceptions; enabled. Used by CP to set up; ``COMPUTE_PGM_RSRC2.EXCP_EN``; (set from bits 0..6). IEEE 754 FP Invalid; Operation; 25 1 bit ENABLE_EXCEPTION_FP_DENORMAL FP Denormal one or more; _SOURCE input operands is a; denormal number; 26 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Division by; _DIVISION_BY_ZERO Zero; 27 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP FP Overflow; _OVERFLOW; 28 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Underflow; _UNDERFLOW; 29 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Inexact; _INEXACT; 30 1 bit ENABLE_EXCEPTION_INT_DIVIDE_BY Integer Divis",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:174018,allocate,allocated,174018,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"minism caused by iterating unordered containers of pointers. .. code-block:: c. void test() {; int a = 1, b = 2;; std::unordered_set<int *> UnorderedPtrSet = {&a, &b};. for (auto i : UnorderedPtrSet) // warn; f(i);; }. .. _alpha-nondeterminism-PointerSorting:. alpha.nondeterminism.PointerSorting (C++); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for non-determinism caused by sorting of pointers. .. code-block:: c. void test() {; int a = 1, b = 2;; std::vector<int *> V = {&a, &b};; std::sort(V.begin(), V.end()); // warn; }. alpha.WebKit; ^^^^^^^^^^^^. .. _alpha-webkit-UncountedCallArgsChecker:. alpha.webkit.UncountedCallArgsChecker; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; The goal of this rule is to make sure that lifetime of any dynamically allocated ref-countable object passed as a call argument spans past the end of the call. This applies to call to any function, method, lambda, function pointer or functor. Ref-countable types aren't supposed to be allocated on stack so we check arguments for parameters of raw pointers and references to uncounted types. Here are some examples of situations that we warn about as they *might* be potentially unsafe. The logic is that either we're able to guarantee that an argument is safe or it's considered if not a bug then bug-prone. .. code-block:: cpp. RefCountable* provide_uncounted();; void consume(RefCountable*);. // In these cases we can't make sure callee won't directly or indirectly call `deref()` on the argument which could make it unsafe from such point until the end of the call. void foo1() {; consume(provide_uncounted()); // warn; }. void foo2() {; RefCountable* uncounted = provide_uncounted();; consume(uncounted); // warn; }. Although we are enforcing member variables to be ref-counted by `webkit.NoUncountedMemberChecker` any method of the same class still has unrestricted access to these. Since from a caller's perspective we can't guarantee a particular member won't get modified by callee (directly or indirectly) w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:81237,allocate,allocated,81237,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['allocate'],['allocated']
Energy Efficiency,"ml) class,; which is capable to convert any (beside TTree) ROOT object into JSON. Any ROOT application can use such class to; create JSON files for selected objects and write such files in a directory,; which can be accessed via web server. Then one can use JSROOT to read such files and display objects in a web browser. There is a demonstration page showing such functionality: <https://root.cern/js/latest/demo/update_draw.htm>.; This demo page reads in cycle 20 json files and displays them. If one has a web server which already provides such JSON file, one could specify the URL to this file like:. <https://root.cern/js/latest/demo/update_draw.htm?addr=../httpserver.C/Canvases/c1/root.json.gz>. Here the same problem with [Cross-Origin Request](https://developer.mozilla.org/en/http_access_control) can appear. If the web server configuration cannot be changed, just copy JSROOT to the web server itself. ### Binary file-based monitoring (not recommended). Theoretically, one could use binary ROOT files to implement monitoring.; With such approach, a ROOT-based application creates and regularly updates content of a ROOT file, which can be accessed via normal web server. From the browser side, JSROOT could regularly read the specified objects and update their drawings. But such solution has three major caveats. First of all, one need to store the data of all objects, which only potentially could be displayed in the browser. In case of 10 objects it does not matter, but for 1000 or 100000 objects this will be a major performance penalty. With such big amount of data one will never achieve higher update rate. The second problem is I/O. To read the first object from the ROOT file, one need to perform several (about 5) file-reading operations via http protocol.; There is no http file locking mechanism (at least not for standard web servers),; therefore there is no guarantee that the file content is not changed/replaced between consequent read operations. Therefore, one should e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:32257,monitor,monitoring,32257,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency,"mlining the process of; reducing a test-case. If the test accepts any arguments (excluding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. Itâ€™s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduceâ€™s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the toolâ€™s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that donâ€™t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as â€œaâ€, â€œbâ€, â€œcâ€, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpointâ€™s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numerous features and options, but some of them also work in unexpected ways; and most of the time the user ends up using a custom script. Pruning and; simplifying the interface will be worth considering ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:2974,reduce,reduce,2974,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md,1,['reduce'],['reduce']
Energy Efficiency,"model. One specialty of experimental physics are the inevitable uncertainties; affecting each measurement, and visualisation tools have to include; these. In subsequent analysis, the statistical nature of the errors must; be handled properly. As the last step, measurements are compared to models, and free model; parameters need to be determined in this process. See Figure [1.1](#f11) for an; example of a function (model) fit to data points. Several standard methods are; available, and a data analysis tool should provide easy access to more; than one of them. Means to quantify the level of agreement between; measurements and model must also be available.; <!--; [f11]: figures/examplefit.png ""f11""; <a name=""f11""></a>. ![Measured data points with error bars and fitted quadratic; function.\label{f11}][f11]-->. Quite often, the data volume to be analyzed is large - think of; fine-granular measurements accumulated with the aid of computers. A; usable tool therefore must contain easy-to-use and efficient methods for; storing and handling data. In Quantum mechanics, models typically only predict the probability; density function (""pdf"") of measurements depending on a number of; parameters, and the aim of the experimental analysis is to extract the; parameters from the observed distribution of frequencies at which; certain values of the measurement are observed. Measurements of this; kind require means to generate and visualize frequency distributions,; so-called histograms, and stringent statistical treatment to extract the; model parameters from purely statistical distributions. Simulation of expected data is another important aspect in data; analysis. By repeated generation of ""pseudo-data"", which are analysed in; the same manner as intended for the real data, analysis procedures can; be validated or compared. In many cases, the distribution of the; measurement errors is not precisely known, and simulation offers the; possibility to test the effects of different assumptio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/Introduction.md:1965,efficient,efficient,1965,documentation/primer/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/Introduction.md,1,['efficient'],['efficient']
Energy Efficiency,"most; significant challenge to propagate. The simplest technique would be to define a; new ABI such that the intended call target is passed into the called function; and checked in the entry. Unfortunately, new ABIs are quite expensive to deploy; in C and C++. While the target function could be passed in TLS, we would still; require complex logic to handle a mixture of functions compiled with and; without this extra logic (essentially, making the ABI backwards compatible).; Currently, we suggest using retpolines here and will continue to investigate; ways of mitigating this. ##### Optimizations, Alternatives, and Tradeoffs. Merely accumulating predicate state involves significant cost. There are; several key optimizations we employ to minimize this and various alternatives; that present different tradeoffs in the generated code. First, we work to reduce the number of instructions used to track the state:; * Rather than inserting a `cmovCC` instruction along every conditional edge in; the original program, we track each set of condition flags we need to capture; prior to entering each basic block and reuse a common `cmovCC` sequence for; those.; * We could further reuse suffixes when there are multiple `cmovCC`; instructions required to capture the set of flags. Currently this is; believed to not be worth the cost as paired flags are relatively rare and; suffixes of them are exceedingly rare.; * A common pattern in x86 is to have multiple conditional jump instructions; that use the same flags but handle different conditions. Naively, we could; consider each fallthrough between them an ""edge"" but this causes a much more; complex control flow graph. Instead, we accumulate the set of conditions; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:20821,reduce,reduce,20821,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['reduce'],['reduce']
Energy Efficiency,"mp = X + ""."" + Twine(i);; foo(Tmp);. ... because the temporaries are destroyed before the call. That said, Twine's; are much more efficient than intermediate std::string temporaries, and they work; really well with StringRef. Just be aware of their limitations. .. _dss_smallstring:. llvm/ADT/SmallString.h; ^^^^^^^^^^^^^^^^^^^^^^. SmallString is a subclass of :ref:`SmallVector <dss_smallvector>` that adds some; convenience APIs like += that takes StringRef's. SmallString avoids allocating; memory in the case when the preallocated space is enough to hold its data, and; it calls back to general heap allocation when required. Since it owns its data,; it is very safe to use and supports full mutation of the string. Like SmallVector's, the big downside to SmallString is their sizeof. While they; are optimized for small strings, they themselves are not particularly small.; This means that they work great for temporary scratch buffers on the stack, but; should not generally be put into the heap: it is very rare to see a SmallString; as the member of a frequently-allocated heap data structure or returned; by-value. .. _dss_stdstring:. std::string; ^^^^^^^^^^^. The standard C++ std::string class is a very general class that (like; SmallString) owns its underlying data. sizeof(std::string) is very reasonable; so it can be embedded into heap data structures and returned by-value. On the; other hand, std::string is highly inefficient for inline editing (e.g.; concatenating a bunch of stuff together) and because it is provided by the; standard library, its performance characteristics depend a lot of the host; standard library (e.g. libc++ and MSVC provide a highly optimized string class,; GCC contains a really slow implementation). The major disadvantage of std::string is that almost every operation that makes; them larger can allocate memory, which is slow. As such, it is better to use; SmallVector or Twine as a scratch buffer, but then use std::string to persist; the result. ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:75771,allocate,allocated,75771,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"mpile these two functions to the same thing:. #include <stdlib.h>; void f(int a, int b, int *P) {; *P = (a-b)>=0?(a-b):(b-a);; }; void g(int a, int b, int *P) {; *P = abs(a-b);; }. Further, they should compile to something better than:. _g:; subf r2, r4, r3; subfic r3, r2, 0; cmpwi cr0, r2, -1; bgt cr0, LBB2_2 ; entry; LBB2_1: ; entry; mr r2, r3; LBB2_2: ; entry; stw r2, 0(r5); blr. GCC produces:. _g:; subf r4,r4,r3; srawi r2,r4,31; xor r0,r2,r4; subf r0,r2,r0; stw r0,0(r5); blr. ... which is much nicer. This theoretically may help improve twolf slightly (used in dimbox.c:142?). ===-------------------------------------------------------------------------===. PR5945: This: ; define i32 @clamp0g(i32 %a) {; entry:; %cmp = icmp slt i32 %a, 0; %sel = select i1 %cmp, i32 0, i32 %a; ret i32 %sel; }. Is compile to this with the PowerPC (32-bit) backend:. _clamp0g:; cmpwi cr0, r3, 0; li r2, 0; blt cr0, LBB1_2; ; %bb.1: ; %entry; mr r2, r3; LBB1_2: ; %entry; mr r3, r2; blr. This could be reduced to the much simpler:. _clamp0g:; srawi r2, r3, 31; andc r3, r3, r2; blr. ===-------------------------------------------------------------------------===. int foo(int N, int ***W, int **TK, int X) {; int t, i;; ; for (t = 0; t < N; ++t); for (i = 0; i < 4; ++i); W[t / X][i][t % X] = TK[i][t];; ; return 5;; }. We generate relatively atrocious code for this loop compared to gcc. We could also strength reduce the rem and the div:; http://www.lcs.mit.edu/pubs/pdf/MIT-LCS-TM-600.pdf. ===-------------------------------------------------------------------------===. We generate ugly code for this:. void func(unsigned int *ret, float dx, float dy, float dz, float dw) {; unsigned code = 0;; if(dx < -dw) code |= 1;; if(dx > dw) code |= 2;; if(dy < -dw) code |= 4;; if(dy > dw) code |= 8;; if(dz < -dw) code |= 16;; if(dz > dw) code |= 32;; *ret = code;; }. ===-------------------------------------------------------------------------===. %struct.B = type { i8, [3 x i8] }. define void @bar(%struct.B* ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:4310,reduce,reduced,4310,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,2,['reduce'],['reduced']
Energy Efficiency,"mpile with; ``-DINSTALL_GWP_ASAN_STUBS`` and link against the GWP-ASan library! For; performance reasons, we strongly recommend static linkage of the GWP-ASan; library. Guarded Allocation Pool; -----------------------. The core of GWP-ASan is the guarded allocation pool. Each sampled allocation is; backed using its own *guarded* slot, which may consist of one or more accessible; pages. Each guarded slot is surrounded by two *guard* pages, which are mapped as; inaccessible. The collection of all guarded slots makes up the *guarded; allocation pool*. Buffer Underflow/Overflow Detection; -----------------------------------. We gain buffer-overflow and buffer-underflow detection through these guard; pages. When a memory access overruns the allocated buffer, it will touch the; inaccessible guard page, causing memory exception. This exception is caught and; handled by the internal crash handler. Because each allocation is recorded with; metadata about where (and by what thread) it was allocated and deallocated, we; can provide information that will help identify the root cause of the bug. Allocations are randomly selected to be either left- or right-aligned to provide; equal detection of both underflows and overflows. Use after Free Detection; ------------------------. The guarded allocation pool also provides use-after-free detection. Whenever a; sampled allocation is deallocated, we map its guarded slot as inaccessible. Any; memory accesses after deallocation will thus trigger the crash handler, and we; can provide useful information about the source of the error. Please note that the use-after-free detection for a sampled allocation is; transient. To keep memory overhead fixed while still detecting bugs, deallocated; slots are randomly reused to guard future allocations. Usage; =====. GWP-ASan already ships by default in the; `Scudo Hardened Allocator <https://llvm.org/docs/ScudoHardenedAllocator.html>`_,; so building with ``-fsanitize=scudo`` is the quickest and easies",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:3962,allocate,allocated,3962,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['allocate'],['allocated']
Energy Efficiency,"mpiler front-end will communicate with LLVM by creating a module in the; LLVM intermediate representation (IR) format. Assuming you want to write your; language's compiler in the language itself (rather than C++), there are 3; major ways to tackle generating LLVM IR from a front-end:. 1. **Call into the LLVM libraries code using your language's FFI (foreign; function interface).**. * *for:* best tracks changes to the LLVM IR, .ll syntax, and .bc format. * *for:* enables running LLVM optimization passes without a emit/parse; overhead. * *for:* adapts well to a JIT context. * *against:* lots of ugly glue code to write. 2. **Emit LLVM assembly from your compiler's native language.**. * *for:* very straightforward to get started. * *against:* the .ll parser is slower than the bitcode reader when; interfacing to the middle end. * *against:* it may be harder to track changes to the IR. 3. **Emit LLVM bitcode from your compiler's native language.**. * *for:* can use the more-efficient bitcode reader when interfacing to the; middle end. * *against:* you'll have to re-engineer the LLVM IR object model and bitcode; writer in your language. * *against:* it may be harder to track changes to the IR. If you go with the first option, the C bindings in include/llvm-c should help; a lot, since most languages have strong support for interfacing with C. The; most common hurdle with calling C from managed code is interfacing with the; garbage collector. The C interface was designed to require very little memory; management, and so is straightforward in this regard. What support is there for a higher level source language constructs for building a compiler?; --------------------------------------------------------------------------------------------; Currently, there isn't much. LLVM supports an intermediate representation; which is useful for code representation but will not support the high level; (abstract syntax tree) representation needed by most compilers. There are no; facilities",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:4313,efficient,efficient,4313,interpreter/llvm-project/llvm/docs/FAQ.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst,1,['efficient'],['efficient']
Energy Efficiency,"mpl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; and how long to keep them around for. Because the lifetime of the pass object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of distribution, and for regulating the resident code size when; running on the target system. Therefore, it becomes desirable to selectively; use some passes, while omitting others and maintain the flexibility to change; configurations later on. You want to be able to do all this, and, provide; feedback to the user. This is where pass registration comes into play. The fundamental mechanisms for pass registration are the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:47644,allocate,allocated,47644,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['allocate'],['allocated']
Energy Efficiency,"mplex``) and vectors; (``__attribute((vector_size(16)))``) are treated as arrays. Bytecode Execution; ==================. Bytecode is executed using a stack-based interpreter. The execution; context consists of an ``InterpStack``, along with a chain of; ``InterpFrame`` objects storing the call frames. Frames are built by; call instructions and destroyed by return instructions. They perform; one allocation to reserve space for all locals in a single block.; These objects store all the required information to emit stack traces; whenever evaluation fails. Memory Organisation; ===================. Memory management in the interpreter relies on 3 data structures: ``Block``; objects which store the data and associated inline metadata, ``Pointer``; objects which refer to or into blocks, and ``Descriptor`` structures which; describe blocks and subobjects nested inside blocks. Blocks; ------. Blocks contain data interleaved with metadata. They are allocated either; statically in the code generator (globals, static members, dummy parameter; values etc.) or dynamically in the interpreter, when creating the frame; containing the local variables of a function. Blocks are associated with a; descriptor that characterises the entire allocation, along with a few; additional attributes:. * ``IsStatic`` indicates whether the block has static duration in the; interpreter, i.e. it is not a local in a frame. * ``DeclID`` identifies each global declaration (it is set to an invalid; and irrelevant value for locals) in order to prevent illegal writes and; reads involving globals and temporaries with static storage duration. Static blocks are never deallocated, but local ones might be deallocated; even when there are live pointers to them. Pointers are only valid as; long as the blocks they point to are valid, so a block with pointers to; it whose lifetime ends is kept alive until all pointers to it go out of; scope. Since the frame is destroyed on function exit, such blocks are; turned into ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst:4346,allocate,allocated,4346,interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,1,['allocate'],['allocated']
Energy Efficiency,"mproving performance especially for TTree::Map() by about 35%. This has been achieved with a better caching strategy for request stringsÂ (especially avoiding to recalculateÂ the auth base64 encoding), and with aÂ drastic optimization inÂ readingÂ the response headers.; Fixes in the counting of the bytes read. TWebSystem. New implementation of TSystem allowing to use TSystem::AccessPathName() and GetPathInfo() to check if a web file exists and to get its size. Directory browsing is not available yet. NETX; ; TXNetFile. Several fixes and optimisations, mainly in the use of the cache; Fix an offset issue affecting the use of the cache with files in archives. TXNetSystem. A few optimizations in the use of retry mechanism, path locality checks, file online checks. XROOTD. Import a new version of XROOTD (20091202-0509); ; Fixes in bulk prepare and sync readv operations; Add support for 'make install' / 'make uninstall' and; other improvements in configure.classic; Several improvements / fixes:; ; reduced memory and CPU consumption;; extreme cp optimizations;; windows porting; new cache policies on the client side; new listingÂ features implemented recently in the 'cns' module.; optimizations in cmsd and cnsd (performance improvements); support for openssl 1.0.0 (required by Fedora 12). Support for if/else if/else/fi constructs; Several portability fixes; ; Support 32-bit builds with icc on 64-bit platforms; Improved detection of libreadline and lib(n)curses. Increase the flexibility for configuring with an external xrootd; ; Add standard switches to disentangle lib and inc dirs; Â  Â  Â  --with-xrootd-incdir=<path_to dir_containing_XrdVersion.hh>; Â  Â  Â  --with-xrootd-libdir=<path_to_dir_containing_xrootd_plugins_and_libs>; ; When; passing a global xrootd dir with --with-xrootd, check both; src/XrdVersion.hh and include/xrootd/XrdVersion.hh so that both build; and install distributions are supported. Fix a problem with the xrootd build when running make via 'sudo' (issue #47644). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v526/index.html:1070,reduce,reduced,1070,net/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v526/index.html,4,"['consumption', 'reduce']","['consumption', 'reduced']"
Energy Efficiency,"n !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the delay. To illustrate, consider this pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6. Imagine that th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:32803,schedul,schedulers,32803,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['schedul'],['schedulers']
Energy Efficiency,"n array semantics.; **Overhead per element**: none, except possible over sizing of `fCont`. ## TClonesArray An Array of Identical Objects. A **`TClonesArray`** is an array of identical (clone) objects. The; memory for the objects stored in the array is allocated only once in the; lifetime of the clones array. All objects must be of the same class. For; the rest this class has the same properties as a **`TObjArray`**. ![The internal data structure of a TClonesArray](pictures/020001A8.jpg). The figure above shows the internal data structure of a; **`TClonesArray`**. The class is specially designed for repetitive data; analysis tasks, where in a loop many times the same objects, are created; and deleted. The only supported way to add objects to a; **`TClonesArray`** is via the `new` with placement method. The different; `Add()` methods of **`TObjArray`** and its base classes are not; supported. ### The Idea Behind TClonesArray. To reduce the very large number of new and delete calls in large loops; like this (O(100000) x O(10000) times new/delete):. ``` {.cpp}; TObjArray a(10000);; while (TEvent *ev = (TEvent *)next()) { // O(100000); for (int i = 0; i < ev->Ntracks; i++) { // O(10000); a[i] = new TTrack(x,y,z,...);; ...; }; ...; a.Delete();; }; ```. You better use a **`TClonesArray`** which reduces the number of; new/delete calls to only O(10000):. ``` {.cpp}; TClonesArray a(""TTrack"", 10000);; while (TEvent *ev = (TEvent *)next()) { // O(100000); for (int i = 0; i < ev->Ntracks; i++) { // O(10000); TTrack *track = (Track*)a.ConstructedAt(i);; track->Set(x,y,z,...);; ...; }; ...; a.Clear(); // Or Clear(""C"") if the track objects must be returned (via Track::Clear) to a default state.; }; ```. Considering that a pair of new/delete calls on average cost about 70 ms,; O(109) new/deletes will save about 19 hours. For the other collections,; see the class reference guide on the web and the test program; `$ROOTSYS/test/tcollex.cxx.`. ## Template Containers and STL. Some peopl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md:16925,reduce,reduce,16925,documentation/users-guide/CollectionClasses.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md,1,['reduce'],['reduce']
Energy Efficiency,"n called. .. _int_call_preallocated_teardown:. '``llvm.call.preallocated.teardown``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.call.preallocated.teardown(token %setup_token). Overview:; """""""""""""""""". The '``llvm.call.preallocated.teardown``' intrinsic cleans up the stack; created by a '``llvm.call.preallocated.setup``'. Semantics:; """""""""""""""""""". The token argument must be a '``llvm.call.preallocated.setup``'. The '``llvm.call.preallocated.teardown``' intrinsic cleans up the stack; allocated by the corresponding '``llvm.call.preallocated.setup``'. Exactly; one of this or the preallocated call must be called to prevent stack leaks.; It is undefined behavior to call both a '``llvm.call.preallocated.teardown``'; and the preallocated call for a given '``llvm.call.preallocated.setup``'. For example, if the stack is allocated for a preallocated call by a; '``llvm.call.preallocated.setup``', then an initializer function called on an; allocated argument throws an exception, there should be a; '``llvm.call.preallocated.teardown``' in the exception handler to prevent; stack leaks. Following the nesting rules in '``llvm.call.preallocated.setup``', nested; calls to '``llvm.call.preallocated.setup``' and; '``llvm.call.preallocated.teardown``' are allowed but must be properly; nested. Example:; """""""""""""""". .. code-block:: llvm. %cs = call token @llvm.call.preallocated.setup(i32 1); %x = call ptr @llvm.call.preallocated.arg(token %cs, i32 0) preallocated(i32); invoke void @constructor(ptr %x) to label %conta unwind label %contb; conta:; call void @foo1(ptr preallocated(i32) %x) [""preallocated""(token %cs)]; ret void; contb:; %s = catchswitch within none [label %catch] unwind to caller; catch:; %p = catchpad within %s []; call void @llvm.call.preallocated.teardown(token %cs); ret void. Standard C/C++ Library Intrinsics; ---------------------------------. LLVM provides intrinsics for a few important standard C/C++ library; functions. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:541089,allocate,allocated,541089,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"n instance; ofÂ TProofDataSetManagerFile; managing the <sandbox>/datasets; area is created. The directive 'Proof.DataSetManager' can be used to; modify the settings forÂ TProofDataSetManagerFile or to load a; different dataset manager; for example, to '/pool/datasets' as area for; the dataset information, the following directive can be added to the; xrootd config file; xpd.putrc Proof.DataSetManager file dir:/pool/datasets. Interface to TProofMgr::GetSessionLogs() in the dialog; box. The graphics layout of the logbox has been re-designed, with new; buttons to grep the logs and to save them to a file. It is also; possible to choose the range of lines to be displayed and the subset of; nodes.; ; Support for connection control base on the UNIX group; (new directive 'xpd.allowedgroups; <grp1>,<grp2>, ...'). Improvements:. ; In the case of mismatch between the expected and actual; number of processed events, send back to the client the list of failed; packets.; Implement the classic strategy of the TPacketizer in; TPacketizerAdaptive; the strategy can be changed from adaptive; (default) to TPacketizer with: ""PROOF_PacketizerStrategy"" parameter to; PROOF; The max workers per node can now be also set in the; xrootd config file with. Â  Â  Â  Â xpd.putrcÂ ; Packetizer.MaxWorkersPerNode: <desired number>. Make fCacheDir and fPackageDir controllable via directive; . Fixes. ; Two memory leaks in TProofServ affecting repeated runs; withing the same session. Fix a problem cleaning-up the input list on the workers; ; The type of ""PROOF_MaxSlavesPerNode"",; Â ""PROOF_ForceLocal"" and; Â ""PROOF_PacketAsAFraction"" parameters has been changed from; Long_t to Int_t.Â ; TProofCondor plug-in:; ; Adapt the signatures of the main constructors of; TProofCondor and TProofPEAC; (and of the related plug-in handlers) to the one of TProof.; Add the possibility to trigger the load of a generic; TProof-derived plug-in via; a directive the xrootd config file 'xpd.proofplugin', e.g.; 'xpd.proofplugin condor:'. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v520/index.html:1583,adapt,adaptive,1583,proof/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v520/index.html,3,"['Adapt', 'adapt']","['Adapt', 'adaptive']"
Energy Efficiency,"n isolation (1 for isolated); Float_t m_Eta offset= 0 type= 5 Eta coordinate; Float_t m_Phi offset= 0 type= 5 Phi coordinate; Float_t m_PT offset= 0 type= 5 Transverse energy; Int_t m_Trigger offset= 0 type= 3 Result of trigger...; ```. However, when we try to use a specific class we get a warning because; the class is not in the dictionary. We can create a class using; `gROOT->GetClass()` which makes a fake class from the `StreamerInfo`. ``` {.cpp}; // Build a 'fake' class; root[] gROOT->GetClass(""ATLFMuon""); (const class TClass*)0x87e5c08; // The fake class has a StreamerInfo; root[] gROOT->GetClass(""ATLFMuon"")->GetStreamerInfo()->ls(); StreamerInfo for class: ATLFMuon, version=1; BASE TObject offset= 0 type=66 Basic ROOT object; BASE TAtt3D offset= 0 type= 0 3D attributes; Int_t m_KFcode offset= 16 type= 3 Muon KF-code; Int_t m_MCParticle offset= 20 type= 3 Muon position in MCParticles list; Int_t m_KFmother offset= 24 type= 3 Muon mother KF-code; Int_t m_UseFlag offset= 28 type= 3 Muon energy usage flag; Int_t m_Isolated offset= 32 type= 3 Muon isolation; Float_t m_Eta offset= 36 type= 5 Eta coordinate; Float_t m_Phi offset= 40 type= 5 Phi coordinate; Float_t m_PT offset= 44 type= 5 Transverse energy; Int_t m_Trigger offset= 48 type= 3 Result of trigger; i= 0, TObject type= 66, offset= 0, len=1, method=0; i= 1, TAtt3D type= 0, offset= 0, len=1, method=142684688; i= 2, m_KFcode type= 23, offset= 16, len=5, method=0; i= 3, m_Eta type= 25, offset= 36, len=3, method=0; i= 4, m_Trigger type= 3, offset= 48, len=1, method=0; ```. `MakeProject` has three parameters:. ``` {.cpp}; MakeProject(const char *dirname,const char *classes,Option_t *option); ```. The first is the directory name in which to place the generated header; files. The second parameter is the name of the classes to include in the; project. By default, all classes are included. It recognizes the wild; card character \*, for example, ""ATLF\*"" includes all classes beginning; with ATLF. The third parameter is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:87099,energy,energy,87099,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,2,['energy'],['energy']
Energy Efficiency,"n make then materials/mixtures; based on these radionuclides and use them in a geometry. ``` {.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ```. One can make materials or mixtures from radionuclides:. ``` {.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ```. The following properties of radionuclides can be currently accessed via; getters in the **`TGeoElementRN`** class:. Atomic number and charge (from the base class **`TGeoElement`**). - Isomeric number (`ISO`); - ENDF code - following the convention: `ENDF=10000*Z+100*A+ISO`; - Isomeric energy level [`MeV`]; - Mass excess [`MeV`]; - Half life [`s`]; - Spin/Parity - can be retrieved with: `TGeoElementRN::GetTitle()`; - Hynalation and ingestion toxicities; - List of decays - `TGeoElementRN::GetDecays()`. The radioactive decays of a radionuclide are represented by the class; **`TGeoDecayChannel`** and they are stored in a **`TObjArray`**. Decay; provides:. - Decay mode; - Variation of isomeric number; - `Q` value for the decay [`GeV`]; - Parent element; - Daughter element. Radionuclides are linked one to each other via their decays, until the; last element in the decay chain which must be stable. One can iterate; decay chains using the iterator **`TGeoElemIter`**:. ``` {.cpp}; root[] TGeoElemIter next(c14);; root[] TGeoElementRN *elem;; root[] while ((elem=next())) next.Print();; 6-C-014 (100% BetaMinus) T1/2=1.81e+11; 7-N-014 stable; ```. To create a radioactive material based on a radionuclide, one should; use the constructor:. ``` {.cpp}; TGeoMaterial(const char *name, TGeoElement *elem, Double_t density); ```. To create a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:18688,energy,energy,18688,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['energy'],['energy']
Energy Efficiency,"n options for MVA method :. Configuration options reference for MVA method: PDERS. Option Array Default value Predefined values Description. V No False âˆ’ Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None âˆ’ List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False âˆ’ Print method-specific help message. CreateMVAPdfs No False âˆ’ Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False âˆ’ Events with negative weights are ignored in the training (but are included for testing and performance evaluation). VolumeRangeMode No Adaptive Unscaled, MinMax, RMS, Adaptive, kNN Method to determine volume size. KernelEstimator No Box Box, Sphere, Teepee, Gauss, Sinc3, Sinc5, Sinc7, Sinc9, Sinc11, Lanczos2, Lanczos3, Lanczos5, Lanczos8, Trim Kernel estimation function. DeltaFrac No 3 âˆ’ nEventsMin/Max for minmax and rms volume range. NEventsMin No 100 âˆ’ nEventsMin for adaptive volume range. NEventsMax No 200 âˆ’ nEventsMax for adaptive volume range. MaxVIterations No 150 âˆ’ MaxVIterations for adaptive volume range. InitialScale No 0.99 âˆ’ InitialScale for adaptive volume range. GaussSigma No 0.1 âˆ’ Width (wrt volume size) of Gaussian kernel estimator. NormTree No False âˆ’ Normalize binary search tree. Configuration options for MVA method :. Configuration options reference for MVA method: FDA. Option Array Default value Predefined values Description. V No False âˆ’ Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:4386,Adapt,Adaptive,4386,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['Adapt'],['Adaptive']
Energy Efficiency,"n three dimensions. To show; a set of points in Parallel Coordinates, a set of parallel lines is; drawn, typically vertical and equally spaced. A point in n-dimensional; space is represented as a polyline with vertices on the parallel axes.; The position of the vertex on the i-th axis corresponds to the i-th; coordinate of the point. The three following figures show some very; simple examples:. ![The Parallel Coordinates representation of the six dimensional point `(-5,3,4,2,0,1)`.](pictures/para1.png). ![The line `y = -3x+20` and a circle in Parallel Coordinates.](pictures/para2.png). The Parallel Coordinates technique is good at: spotting irregular; events, seeing the data trend, finding correlations and clusters. Its; main weakness is the cluttering of the output. Because each â€œpointâ€ in; the multidimensional space is represented as a line, the output is very; quickly opaque and therefore it is difficult to see the data clusters.; Most of the work done about Parallel Coordinates is to find techniques; to reduce the outputâ€™s cluttering. The Parallel Coordinates plots in; ROOT have been implemented as a new plotting option â€œPARAâ€ in the; `TTree::Draw()method`. To demonstrate how the Parallel Coordinates; works in ROOT we will use the tree produced by the following; â€œpseudo C++â€ code:. ``` {.cpp}; void parallel_example() {; TNtuple *nt = new TNtuple(""nt"",""Demo ntuple"",""x:y:z:u:v:w:a:b:c"");; for (Int_t i=0; i<3000; i++) {; nt->Fill( rnd, rnd, rnd, rnd, rnd, rnd, rnd, rnd, rnd );; nt->Fill( s1x, s1y, s1z, s2x, s2y, s2z, rnd, rnd, rnd );; nt->Fill( rnd, rnd, rnd, rnd, rnd, rnd, rnd, s3y, rnd );; nt->Fill( s2x-1, s2y-1, s2z, s1x+.5, s1y+.5, s1z+.5, rnd, rnd, rnd );; nt->Fill( rnd, rnd, rnd, rnd, rnd, rnd, rnd, rnd, rnd );; nt->Fill( s1x+1, s1y+1, s1z+1, s3x-2, s3y-2, s3z-2, rnd, rnd, rnd );; nt->Fill( rnd, rnd, rnd, rnd, rnd, rnd, s3x, rnd, s3z );; nt->Fill( rnd, rnd, rnd, rnd, rnd, rnd, rnd, rnd, rnd );; }; ```. The data set generated has:. - 9 variables: x, y, z, u, v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:96695,reduce,reduce,96695,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['reduce'],['reduce']
Energy Efficiency,"n. Implementing a Native Assembler; ===============================. Though you're probably reading this because you want to write or maintain a; compiler backend, LLVM also fully supports building a native assembler.; We've tried hard to automate the generation of the assembler from the .td files; (in particular the instruction syntax and encodings), which means that a large; part of the manual and repetitive data entry can be factored and shared with the; compiler. Instruction Parsing; -------------------. .. note::. To Be Written. Instruction Alias Processing; ----------------------------. Once the instruction is parsed, it enters the MatchInstructionImpl function.; The MatchInstructionImpl function performs alias processing and then does actual; matching. Alias processing is the phase that canonicalizes different lexical forms of the; same instructions down to one representation. There are several different kinds; of alias that are possible to implement and they are listed below in the order; that they are processed (which is in order from simplest/weakest to most; complex/powerful). Generally you want to use the first alias mechanism that; meets the needs of your instruction, because it will allow a more concise; description. Mnemonic Aliases; ^^^^^^^^^^^^^^^^. The first phase of alias processing is simple instruction mnemonic remapping for; classes of instructions which are allowed with two different mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for example X86 has:. ::. def : MnemonicAlias<""cbw"", ""cbtw"">;; def : MnemonicAlias<""smovq"", ""movsq"">;; def : MnemonicAlias<""fldcww"", ""fldcw"">;; def : MnemonicAlias<""fucompi"", ""fucomip"">;; def : MnemonicAlias<""ud2a"", ""ud2"">;. ... and many others. With a MnemonicAlias definition, th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:81957,power,powerful,81957,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['power'],['powerful']
Energy Efficiency,"n. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.add``' intrinsic performs the integer ``ADD`` reduction; (:ref:`llvm.vector.reduce.add <int_vector_reduce_add>`) of the vector operand; ``val`` on each enabled lane, adding it to the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``0`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is equal; to ``start_value``. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.add.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> zeroinitializer; %reduction = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %masked.a); %also.r = add i32 %reduction, %start. .. _int_vp_reduce_fadd:. '``llvm.vp.reduce.fadd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fadd.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fadd.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``ADD`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:750264,reduce,reduce,750264,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"n; supports writing them out to disk.; Designing the libraries with clean and simple APIs allows these high-level; policy decisions to be determined in the client, instead of forcing ""one true; way"" in the implementation of any of these libraries. Getting this right is; hard, and we don't always get it right the first time, but we fix any problems; when we realize we made a mistake. Integration with IDEs. We believe that Integrated Development Environments (IDE's) are a great way; to pull together various pieces of the development puzzle, and aim to make clang; work well in such an environment. The chief advantage of an IDE is that they; typically have visibility across your entire project and are long-lived; processes, whereas stand-alone compiler tools are typically invoked on each; individual file in the project, and thus have limited scope.; There are many implications of this difference, but a significant one has to; do with efficiency and caching: sharing an address space across different files; in a project, means that you can use intelligent caching and other techniques to; dramatically reduce analysis/compilation time.; A further difference between IDEs and batch compiler is that they often; impose very different requirements on the front-end: they depend on high; performance in order to provide a ""snappy"" experience, and thus really want; techniques like ""incremental compilation"", ""fuzzy parsing"", etc. Finally, IDEs; often have very different requirements than code generation, often requiring; information that a codegen-only frontend can throw away. Clang is; specifically designed and built to capture this information. Use the LLVM 'Apache 2' License. We actively intend for clang (and LLVM as a whole) to be used for; commercial projects, not only as a stand-alone compiler but also as a library; embedded inside a proprietary application. We feel that the license encourages; contributors to pick up the source and work with it, and believe that those; individu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html:9844,reduce,reduce,9844,interpreter/llvm-project/clang/www/features.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html,2,['reduce'],['reduce']
Energy Efficiency,nMPToLLVMIRTranslation.cpp; mlir/lib/Target/LLVMIR/Dialect/ROCDL/ROCDLToLLVMIRTranslation.cpp; mlir/lib/Target/LLVMIR/Dialect/X86Vector/X86VectorToLLVMIRTranslation.cpp; mlir/lib/Target/SPIRV/SPIRVBinaryUtils.cpp; mlir/lib/Target/SPIRV/TranslateRegistration.cpp; mlir/lib/Target/SPIRV/Deserialization/Deserialization.cpp; mlir/lib/Target/SPIRV/Deserialization/DeserializeOps.cpp; mlir/lib/Target/SPIRV/Deserialization/Deserializer.cpp; mlir/lib/Target/SPIRV/Serialization/Serialization.cpp; mlir/lib/Target/SPIRV/Serialization/SerializeOps.cpp; mlir/lib/Target/SPIRV/Serialization/Serializer.cpp; mlir/lib/Tools/mlir-lsp-server/LSPServer.cpp; mlir/lib/Tools/mlir-lsp-server/LSPServer.h; mlir/lib/Tools/mlir-lsp-server/MlirLspServerMain.cpp; mlir/lib/Tools/mlir-lsp-server/MLIRServer.h; mlir/lib/Tools/mlir-lsp-server/lsp/Logging.cpp; mlir/lib/Tools/mlir-lsp-server/lsp/Protocol.cpp; mlir/lib/Tools/mlir-lsp-server/lsp/Transport.cpp; mlir/lib/Tools/mlir-lsp-server/lsp/Transport.h; mlir/lib/Tools/mlir-reduce/MlirReduceMain.cpp; mlir/lib/Tools/PDLL/AST/Context.cpp; mlir/lib/Tools/PDLL/AST/Diagnostic.cpp; mlir/lib/Tools/PDLL/AST/NodePrinter.cpp; mlir/lib/Tools/PDLL/AST/TypeDetail.h; mlir/lib/Tools/PDLL/AST/Types.cpp; mlir/lib/Tools/PDLL/CodeGen/CPPGen.cpp; mlir/lib/Tools/PDLL/ODS/Context.cpp; mlir/lib/Tools/PDLL/ODS/Dialect.cpp; mlir/lib/Tools/PDLL/ODS/Operation.cpp; mlir/lib/Tools/PDLL/Parser/Parser.cpp; mlir/lib/Transforms/Canonicalizer.cpp; mlir/lib/Transforms/ControlFlowSink.cpp; mlir/lib/Transforms/CSE.cpp; mlir/lib/Transforms/Inliner.cpp; mlir/lib/Transforms/LocationSnapshot.cpp; mlir/lib/Transforms/LoopInvariantCodeMotion.cpp; mlir/lib/Transforms/PassDetail.h; mlir/lib/Transforms/SCCP.cpp; mlir/lib/Transforms/StripDebugInfo.cpp; mlir/lib/Transforms/SymbolDCE.cpp; mlir/lib/Transforms/SymbolPrivatize.cpp; mlir/lib/Transforms/Utils/ControlFlowSinkUtils.cpp; mlir/lib/Transforms/Utils/DialectConversion.cpp; mlir/lib/Transforms/Utils/FoldUtils.cpp; mlir/lib/Transforms/Utils/GreedyPat,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:400338,reduce,reduce,400338,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"name ${tname}). set(tutorial_name tutorial-${tname}-py). list(FIND pyexp_fail ${tutorial_name} index); if(index EQUAL -1); set(py_will_fail """"); else(); set(py_will_fail ${PYTESTS_WILLFAIL}); endif(). # Test if this tutorial is requiring any fixture; unset(python_deps); foreach(fixtureList ${fixtureLists}); if(${t} IN_LIST ${fixtureList}); string(REPLACE ""requires_"" """" fixture ${fixtureList}); list(APPEND python_deps ${fixture}); list(APPEND labels python_runtime_deps); endif(); endforeach(). ROOT_ADD_TEST(${tutorial_name}; COMMAND ${Python3_EXECUTABLE} ${setThreadPoolSize} ${thisTestPoolSize} ${CMAKE_CURRENT_SOURCE_DIR}/${t}; PASSRC ${rc} FAILREGEX ""Error in"" "": error:"" ""segmentation violation""; LABELS ${labels}; DEPENDS ${${tname}-depends}; ENVIRONMENT ${TUTORIAL_ENV}; PYTHON_DEPS ${python_deps}; ${py_will_fail}). if(${t} IN_LIST multithreaded); # Makes sure that this doesn't run in parallel with other multithreaded tutorials, and that cmake doesn't start too; # many other tests. That we use 4 processors is actually a lie, because IMT takes whatever it finds.; # However, even this poor indication of MT behaviour is a good hint for cmake to reduce congestion.; set_tests_properties(${tutorial_name} PROPERTIES RESOURCE_LOCK multithreaded PROCESSORS ${NProcessors}); endif(). if(${t} IN_LIST distrdf_spark_tutorials); # Create a resource lock for the creation of a Spark cluster. This is also used in roottest.; # Also signal 4 processors to cmake to give the tutorial some room (it uses 2 cores).; set_tests_properties(${tutorial_name} PROPERTIES RESOURCE_LOCK spark_resource_lock PROCESSORS ${NProcessors}); endif(). if(${t} IN_LIST distrdf_dask_tutorials); # Create a resource lock for the creation of a Dask cluster. This is also used in roottest.; # Also signal 4 processors to cmake to give the tutorial some room (it uses 2 cores).; set_tests_properties(${tutorial_name} PROPERTIES RESOURCE_LOCK dask_resource_lock PROCESSORS ${NProcessors}); endif(). endforeach(); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/CMakeLists.txt:34895,reduce,reduce,34895,tutorials/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/CMakeLists.txt,1,['reduce'],['reduce']
Energy Efficiency,"name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] Total number of buffer entries. [1] [2] [3] [4]; JALU01 0 0 20; JFPU01 17 18 18; JLSAGU 0 0 12. Retire Control Unit - number of cycles where we saw N instructions retired:; [# retired], [# cycles]; 0, 109 (17.9%); 1, 102 (16.7%); 2, 399 (65.4%). Total ROB Entries: 64; Max Used ROB Entries: 35 ( 54.7% ); Average Used ROB Entries per cy: 32 ( 50.0% ). Register File statistics:; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #1 -- JFpuPRF:; Number of physical registers: 72; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #2 -- JIntegerPRF:; Number of physical registers: 64; Total number of mappings created: 0; Max number of mappings used: 0. If we look at the *Dynamic Dispatch Stall Cycles* table, we see the counter for; SCHEDQ reports 272 cycles. This counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:30631,schedul,scheduler,30631,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"namically; matched to a Block copy operation, allows recovery of the referenced; allocated memory. The ``__block`` Storage Qualifier; =================================. In addition to the new Block type we also introduce a new storage; qualifier, :block-term:`__block`, for local variables. [testme: a; __block declaration within a block literal] The ``__block`` storage; qualifier is mutually exclusive to the existing local storage; qualifiers auto, register, and static. [testme] Variables qualified by; ``__block`` act as if they were in allocated storage and this storage; is automatically recovered after last use of said variable. An; implementation may choose an optimization where the storage is; initially automatic and only ""moved"" to allocated (heap) storage upon; a Block_copy of a referencing Block. Such variables may be mutated as; normal variables are. In the case where a ``__block`` variable is a Block one must assume; that the ``__block`` variable resides in allocated storage and as such; is assumed to reference a Block that is also in allocated storage; (that it is the result of a ``Block_copy`` operation). Despite this; there is no provision to do a ``Block_copy`` or a ``Block_release`` if; an implementation provides initial automatic storage for Blocks. This; is due to the inherent race condition of potentially several threads; trying to update the shared variable and the need for synchronization; around disposing of older values and copying new ones. Such; synchronization is beyond the scope of this language specification. Control Flow; ============. The compound statement of a Block is treated much like a function body; with respect to control flow in that goto, break, and continue do not; escape the Block. Exceptions are treated *normally* in that when; thrown they pop stack frames until a catch clause is found. Objective-C Extensions; ======================. Objective-C extends the definition of a Block reference type to be; that also of id. A variable ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:7733,allocate,allocated,7733,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,2,['allocate'],['allocated']
Energy Efficiency,"nce for MVA method: Boost. Option Array Default value Predefined values Description. V No False âˆ’ Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None âˆ’ List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False âˆ’ Print method-specific help message. CreateMVAPdfs No False âˆ’ Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False âˆ’ Events with negative weights are ignored in the training (but are included for testing and performance evaluation). Boost_Num No 100 âˆ’ Number of times the classifier is boosted. Boost_MonitorMethod No True âˆ’ Write monitoring histograms for each boosted classifier. Boost_DetailedMonitoring No False âˆ’ Produce histograms for detailed boost-wise monitoring. Boost_Type No AdaBoost AdaBoost, Bagging, HighEdgeGauss, HighEdgeCoPara Boosting type for the classifiers. Boost_BaggedSampleFraction No 0.6 âˆ’ Relative size of bagged event sample to original size of the data sample (used whenever bagging is used). Boost_MethodWeightType No ByError ByError, Average, ByROC, ByOverlap, LastMethod How to set the final weight of the boosted classifiers. Boost_RecalculateMVACut No True âˆ’ Recalculate the classifier MVA Signallike cut at every boost iteration. Boost_AdaBoostBeta No 1 âˆ’ The ADA boost parameter that sets the effect of every boost step on the events' weights. Boost_Transform No step step, linear, log, gauss Type of transform applied to every boosted method linear, log, step. Boost_RandomSeed No 0 âˆ’ Seed for random number generator used for bagging. Configuration options for MVA method :. Configuration options ref",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:16658,monitor,monitoring,16658,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['monitor'],['monitoring']
Energy Efficiency,"nce, a loop in a; function with the `mustprogress` attribute can be assumed to terminate if; it does not interact with the environment in an observable way, and; terminating loops without side-effects can be removed. If a `mustprogress`; function does not satisfy this contract, the behavior is undefined. This; attribute does not apply transitively to callees, but does apply to call; sites within the function. Note that `willreturn` implies `mustprogress`.; ``""warn-stack-size""=""<threshold>""``; This attribute sets a threshold to emit diagnostics once the frame size is; known should the frame size exceed the specified value. It takes one; required integer value, which should be a non-negative integer, and less; than `UINT_MAX`. It's unspecified which threshold will be used when; duplicate definitions are linked together with differing values.; ``vscale_range(<min>[, <max>])``; This function attribute indicates `vscale` is a power-of-two within a; specified range. `min` must be a power-of-two that is greater than 0. When; specified, `max` must be a power-of-two greater-than-or-equal to `min` or 0; to signify an unbounded maximum. The syntax `vscale_range(<val>)` can be; used to set both `min` and `max` to the same value. Functions that don't; include this attribute make no assumptions about the value of `vscale`.; ``""nooutline""``; This attribute indicates that outlining passes should not modify the; function. Call Site Attributes; ----------------------. In addition to function attributes the following call site only; attributes are supported:. ``vector-function-abi-variant``; This attribute can be attached to a :ref:`call <i_call>` to list; the vector functions associated to the function. Notice that the; attribute cannot be attached to a :ref:`invoke <i_invoke>` or a; :ref:`callbr <i_callbr>` instruction. The attribute consists of a; comma separated list of mangled names. The order of the list does; not imply preference (it is logically a set). The compiler is free; to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:111146,power,power-of-two,111146,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power-of-two']
Energy Efficiency,nctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helpe,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338785,reduce,reduce,338785,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"nd bugs; <frontend-crash>`. * ``-emit-llvm``: If ``clang`` crashes with this option (which disables; the code generator), you found a middle-end optimizer bug. Jump ahead to; :ref:`middle-end bugs <middleend-crash>`. * Otherwise, you have a backend code generator crash. Jump ahead to :ref:`code; generator bugs <backend-crash>`. .. _frontend-crash:. Front-end bugs; --------------. On a ``clang`` crash, the compiler will dump a preprocessed file and a script; to replay the ``clang`` command. For example, you should see something like. .. code-block:: text. PLEASE ATTACH THE FOLLOWING FILES TO THE BUG REPORT:; Preprocessed source(s) and associated run script(s) are located at:; clang: note: diagnostic msg: /tmp/foo-xxxxxx.c; clang: note: diagnostic msg: /tmp/foo-xxxxxx.sh. The `creduce <https://github.com/csmith-project/creduce>`_ tool helps to; reduce the preprocessed file down to the smallest amount of code that still; replicates the problem. You're encouraged to use creduce to reduce the code; to make the developers' lives easier. The; ``clang/utils/creduce-clang-crash.py`` script can be used on the files; that clang dumps to help with automating creating a test to check for the; compiler crash. `cvise <https://github.com/marxin/cvise>`_ is an alternative to ``creduce``. .. _middleend-crash:. Middle-end optimization bugs; ----------------------------. If you find that a bug crashes in the optimizer, compile your test-case to a; ``.bc`` file by passing ""``-emit-llvm -O1 -Xclang -disable-llvm-passes -c -o; foo.bc``"". The ``-O1`` is important because ``-O0`` adds the ``optnone``; function attribute to all functions and many passes don't run on ``optnone``; functions. Then run:. .. code-block:: bash. opt -O3 foo.bc -disable-output. If this doesn't crash, please follow the instructions for a :ref:`front-end; bug <frontend-crash>`. If this does crash, then you should be able to debug this with the following; :doc:`bugpoint <Bugpoint>` command:. .. code-block:: bash. bugpoi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:3179,reduce,reduce,3179,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduce']
Energy Efficiency,"nd the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4922,monitor,monitoring,4922,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,1,['monitor'],['monitoring']
Energy Efficiency,"nd x86-64 and x32 (see below).; - OSX 64 bit on x86-64. More platforms are expected to be available later; the lack of support; stems from Cling and Clang/LLVM not being ported to these platforms yet. To aleviate the pain for Windows users who want to try ROOT 6 we provide; a recipe on how to run ROOT 6 in a VM on Windows. Building ROOT also requires a C++11 compatible compiler, so one needs to either have installed gcc >= 4.8 or Clang >= 3.4. On most lecagy platforms these newer compilers are available via a special install.; See the [build prerequisites](https://root.cern/install/dependencies/) page. Despite that, an additional platform as been added: the [x32; psAPI](https://sites.google.com/site/x32abi/), called linuxx32gcc. It is; a regular x86-64 ABI but with shorter pointers (4 bytes instead of 8).; This reduces the addressable memory per process to 4GB - but that is; usally sufficient. The advantages are reduced memory consumption (due to; the smaller pointers) and increased performance compared to 32 bit; applications due to the availability of the 64 bit instructions. The; Clang developers mailing list archive [contains a good; comparison](http://clang-developers.42468.n3.nabble.com/Re-PATCH-add-x32-psABI-support-td4024297.html). To build and run binaries compiled in x32, toolchain support is needed.; That is available in the in binutils (2.22), GCC (4.8), glibc (2.16),; Linux kernel (3.4) and even GDB (7.5). These versions are not available; in regular distributions yet (except for [this beta Gentoo; distro](http://dev.gentoo.org/~vapier/x32/stage3-amd64-x32-20120605.tar.xz); built in x32); once they are, building and running x86-64 and x32; side-by-side will be possible. ## Build System; ROOT 6.00/00 can be built either using the classic ""./configure;make"" method or using CMake.; The CMake system has been completed for this version and should be functionally equivalent; to the classic one. The [detailed instructions](https://root.cern/install/build_from_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md:1145,reduce,reduced,1145,core/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md,2,"['consumption', 'reduce']","['consumption', 'reduced']"
Energy Efficiency,"nd x86_64). Significant amount of; work is needed to support other registers and even more so, allocatable; registers. .. _int_stacksave:. '``llvm.stacksave``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.stacksave.p0(); declare ptr addrspace(5) @llvm.stacksave.p5(). Overview:; """""""""""""""""". The '``llvm.stacksave``' intrinsic is used to remember the current state; of the function stack, for use with; :ref:`llvm.stackrestore <int_stackrestore>`. This is useful for; implementing language features like scoped automatic variable sized; arrays in C99. Semantics:; """""""""""""""""""". This intrinsic returns an opaque pointer value that can be passed to; :ref:`llvm.stackrestore <int_stackrestore>`. When an; ``llvm.stackrestore`` intrinsic is executed with a value saved from; ``llvm.stacksave``, it effectively restores the state of the stack to; the state it was in when the ``llvm.stacksave`` intrinsic executed. In; practice, this pops any :ref:`alloca <i_alloca>` blocks from the stack; that were allocated after the ``llvm.stacksave`` was executed. The; address space should typically be the; :ref:`alloca address space <alloca_addrspace>`. .. _int_stackrestore:. '``llvm.stackrestore``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.stackrestore.p0(ptr %ptr); declare void @llvm.stackrestore.p5(ptr addrspace(5) %ptr). Overview:; """""""""""""""""". The '``llvm.stackrestore``' intrinsic is used to restore the state of; the function stack to the state it was in when the corresponding; :ref:`llvm.stacksave <int_stacksave>` intrinsic executed. This is; useful for implementing language features like scoped automatic; variable sized arrays in C99. The address space should typically be; the :ref:`alloca address space <alloca_addrspace>`. Semantics:; """""""""""""""""""". See the description for :ref:`llvm.stacksave <int_stacksave>`. .. _int_get_dynamic_area_offset:. '``llvm.get.dynamic.area.offset``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:520360,allocate,allocated,520360,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"nd(""/DoSomething"", ""SomeFunction()"", ""rootsys/icons/ed_execute.png"");; ```. In example usage of images from `$ROOTSYS/icons` directory is shown. One could prepend `button;`; string to the icon name to let browser show command as extra button. In last case one could hide command element from elements list:. ```cpp; serv->Hide(""/DoSomething"");; ```. One can find example of command interface usage in [tutorials/http/httpcontrol.C](https://github.com/root-project/root/blob/master/tutorials/http/httpcontrol.C) macro. ## Customize user interface. JSROOT is used to implement UI for the THttpServer. Default webpage shows list of registered objects on the left side and drawing area on the right side - [see example](https://root.cern/js/latest/httpserver.C/). JSROOT allows to configure different parameters via URL - like monitoring interval or name of displayed items [item=Files/job1.root/hpxpy&opt=colz&monitoring=1000](https://root.cern/js/latest/httpserver.C/?item=Files/job1.root/hpxpy&opt=colz&monitoring=1000). Some of such parameters can be configured already on the server:. ```cpp; serv->SetItemField(""/"", ""_monitoring"", ""1000""); // monitoring interval in ms; serv->SetItemField(""/"", ""_drawitem"", ""Files/job1.root/hpxpy""); // item to draw; serv->SetItemField(""/"", ""_drawopt"", ""colz"");; ```. In such case URL parameters are not required - specified item will be displayed automatically when web page is opened.; One also can configure to display several items at once. For that one also can configure layout of the drawing area:. ```cpp; serv->SetItemField(""/"", ""_layout"", ""grid2x2""); // layout for drawing area; serv->SetItemField(""/"", ""_drawitem"", ""[Files/job1.root/hpxpy,Files/job1.root/hpx]""); // items; serv->SetItemField(""/"", ""_drawopt"", ""[colz,hist]""); // options; ```. One also can change appearance of hierarchy browser on the left side of the web page:. ```cpp; serv->SetItemField(""/"", ""_browser"", ""off""); // allowed ""fix"" (default), ""float"", ""no"", ""off""; serv->SetItemField(""/"", ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:6827,monitor,monitoring,6827,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['monitor'],['monitoring']
Energy Efficiency,"nd*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets inf",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4841,monitor,monitoring,4841,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,1,['monitor'],['monitoring']
Energy Efficiency,"nd.; Today, only Aarch64 and X86_64 are supported. .. _OpenWork:. Limitations and Half Baked Ideas; ================================. Mixing References and Raw Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Support for languages which allow unmanaged pointers to garbage collected; objects (i.e. pass a pointer to an object to a C routine) in the abstract; machine model. At the moment, the best idea on how to approach this; involves an intrinsic or opaque function which hides the connection between; the reference value and the raw pointer. The problem is that having a; ptrtoint or inttoptr cast (which is common for such use cases) breaks the; rules used for inferring base pointers for arbitrary references when; lowering out of the abstract model to the explicit physical model. Note; that a frontend which lowers directly to the physical model doesn't have; any problems here. Objects on the Stack; ^^^^^^^^^^^^^^^^^^^^. As noted above, the explicit lowering supports objects allocated on the; stack provided the collector can find a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes du",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:34906,allocate,allocated,34906,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['allocate'],['allocated']
Energy Efficiency,"ndom Number Distributions. The **`TRandom`** base class provides functions, which can be used by; all the other derived classes for generating random variates according; to predefined distributions. In the simplest cases, like in the case of; the exponential distribution, the non-uniform random number is obtained; by applying appropriate transformations. In the more complicated cases,; random variates are obtained using acceptance-rejection methods, which; require several random numbers. ``` {.cpp}; TRandom3 r;; // generate a gaussian distributed number with:; // mu=0, sigma=1 (default values); double x1 = r.Gaus();; double x2 = r.Gaus(10,3); // use mu = 10, sigma = 3;; ```. The following table shows the various distributions that can be; generated using methods of the **`TRandom`** classes. More information; is available in the reference documentation for **`TRandom`**. In; addition, random numbers distributed according to a user defined; function, in a limited interval, or to a user defined histogram, can be; generated in a very efficient way using **`TF1::`**GetRandom() or; **`TH1::`**GetRandom(). +-------------------------------------------+--------------------------------+; | Distributions | Description |; +-------------------------------------------+--------------------------------+; | `Double_t Uniform(Double_t x1,Double_t x2 | Uniform random numbers between |; | )` | `x1,x2` |; +-------------------------------------------+--------------------------------+; | `Double_t Gaus(Double_t mu,Double_t sigma | Gaussian random numbers. |; | )` | |; | | Default values: `mu=0`, |; | | `sigma=1` |; +-------------------------------------------+--------------------------------+; | `Double_t Exp(Double_t tau)` | Exponential random numbers |; | | with mean tau. |; +-------------------------------------------+--------------------------------+; | `Double_t Landau(Double_t mean,Double_t s | Landau distributed random |; | igma)` | numbers. |; | | |; | | Default values: `mean=0`,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:15950,efficient,efficient,15950,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['efficient'],['efficient']
Energy Efficiency,"ne vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a TBrowser) held; by the manager class will be filled with TGeoOverlap objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing both candidate node names and a letter; (x-extrusion, o-overlap) representing the type. Double-clicking an; overlap item in a TBrowser produces a picture of the overlap; containing only the two overlapping nodes (one in blue and one in green); and having the critical vertices represented by red points. The picture; can be rotated/zoomed or drawn in X3d as any other view. Calling; gGeoManager->PrintOverlaps() prints the list of overlaps. \anchor GP03b; ### Graphical Checking Methods. \image html geometry009.png ""Safety computation checking"" width=500px. In order to check a given point, `CheckPoint(x,y,z)` method of; TGeoManager draws the daughters of the volume containing the point; one level down, printing the path to the deepest physical node holding; this point. It also computes the closest distance to any boundary. \image html geometry010.png ""Random points"" width=500px. A method to check the validity of a given geometry is shooting random; points. This can be called with the method; TGeoVolume::RandomPoints() and it draws a volume with the current; visualization settings. Random points are generated in the bounding box; of the drawn volume. The points are drawn with the co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:95526,green,green,95526,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['green'],['green']
Energy Efficiency,"nes are treated as containing the neutral value ``0`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is equal; to ``start_value``. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.add.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> zeroinitializer; %reduction = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %masked.a); %also.r = add i32 %reduction, %start. .. _int_vp_reduce_fadd:. '``llvm.vp.reduce.fadd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fadd.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fadd.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``ADD`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fadd``' intrinsic performs the floating-point ``ADD``; reduction (:ref:`llvm.vector.reduce.fadd <int_vector_reduce_fadd>`) of the; vector operand ``val`` on each enabled lane, adding it to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:750532,reduce,reduce,750532,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"nfo*) that are; handled in that range, and an associated action that should take place. Actions; typically pass control to a *landing pad*. A landing pad corresponds roughly to the code found in the ``catch`` portion of; a ``try``/``catch`` sequence. When execution resumes at a landing pad, it; receives an *exception structure* and a *selector value* corresponding to the; *type* of exception thrown. The selector is then used to determine which *catch*; should actually process the exception. LLVM Code Generation; ====================. From a C++ developer's perspective, exceptions are defined in terms of the; ``throw`` and ``try``/``catch`` statements. In this section we will describe the; implementation of LLVM exception handling in terms of C++ examples. Throw; -----. Languages that support exception handling typically provide a ``throw``; operation to initiate the exception process. Internally, a ``throw`` operation; breaks down into two steps. #. A request is made to allocate exception space for an exception structure.; This structure needs to survive beyond the current activation. This structure; will contain the type and value of the object being thrown. #. A call is made to the runtime to raise the exception, passing the exception; structure as an argument. In C++, the allocation of the exception structure is done by the; ``__cxa_allocate_exception`` runtime function. The exception raising is handled; by ``__cxa_throw``. The type of the exception is represented using a C++ RTTI; structure. Try/Catch; ---------. A call within the scope of a *try* statement can potentially raise an; exception. In those circumstances, the LLVM C++ front-end replaces the call with; an ``invoke`` instruction. Unlike a call, the ``invoke`` has two potential; continuation points:. #. where to continue when the call succeeds as per normal, and. #. where to continue if the call raises an exception, either by a throw or the; unwinding of a throw. The term used to define the place where ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:6244,allocate,allocate,6244,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,1,['allocate'],['allocate']
Energy Efficiency,"nformation to the new; value, then deleting the old value. This method cannot be overridden by alias; analysis implementations. The ``addEscapingUse`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``addEscapingUse`` method is used when the uses of a pointer value have; changed in ways that may invalidate precomputed analysis information.; Implementations may either use this callback to provide conservative responses; for points whose uses have change since analysis time, or may recompute some or; all of their internal state to continue providing accurate responses. In general, any new use of a pointer value is considered an escaping use, and; must be reported through this callback, *except* for the uses below:. * A ``bitcast`` or ``getelementptr`` of the pointer; * A ``store`` through the pointer (but not a ``store`` *of* the pointer); * A ``load`` through the pointer. Efficiency Issues; -----------------. From the LLVM perspective, the only thing you need to do to provide an efficient; alias analysis is to make sure that alias analysis **queries** are serviced; quickly. The actual calculation of the alias analysis results (the ""run""; method) is only performed once, but many (perhaps duplicate) queries may be; performed. Because of this, try to move as much computation to the run method; as possible (within reason). Limitations; -----------. The AliasAnalysis infrastructure has several limitations which make writing a; new ``AliasAnalysis`` implementation difficult. There is no way to override the default alias analysis. It would be very useful; to be able to do something like ""``opt -my-aa -O2``"" and have it use ``-my-aa``; for all passes which need AliasAnalysis, but there is currently no support for; that, short of changing the source code and recompiling. Similarly, there is; also no way of setting a chain of analyses as the default. There is no way for transform passes to declare that they preserve; ``AliasAnalysis`` implementations. The ``AliasAnalysis`` interfac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:16545,efficient,efficient,16545,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['efficient'],['efficient']
Energy Efficiency,"ng `fWebHistogram.GetObject()`, the function `GetObject` will; automatically invoke the script `GetWebHistogram.C` via the interpreter.; An example of a `GetWebHistogram.C` script is shown below:. ``` {.cpp}; void GetWebHistogram() {; TFile *f=TFile::Open(""http://root.cern.ch/files/pippa.root"");; f->cd(""DM/CJ"");; TH1 *h6 = (TH1*)gDirectory->Get(""h6"");; h6->SetDirectory(0);; delete f;; TRef::SetObject(h6);; }; ```. In the above example, a call to `fWebHistogram.GetObject()` executes the; script with the function `GetWebHistogram`. This script connects a file; with histograms: `pippa.root` on the ROOT Web site and returns the; object `h6` to **`TRef`**`::GetObject`. ``` {.cpp}; TRef fWebHistogram; //EXEC:GetWebHistogram(); ```. Note that if the definition of the `TRef fWebHistogram` had been changed; the compiled or interpreted function `GetWebHistogram()` would have been; called instead of the Cling script `GetWebHistogram.C.`. ### Array of TRef. When storing multiple **`TRef`**s, it is more efficient to use a; **`TRefArray`**. The efficiency is due to having a single pointer `fPID`; for all `TRefs` in the array. It has a dynamic compact table of; `fUniqueIDs`. We recommend that you use a **`TRefArray`** rather then a; collection of `TRefs`. Example:. - Suppose a `TObjArray *mytracks` containing a list of `Track`; objects. - Suppose a `TRefArray *pions` containing pointers to the pion tracks; in `mytracks`. This list is created with statements like:; `pions->Add(track);`. - Suppose a `TRefArray *muons` containing pointers to the muon tracks; in `mytracks`. The 3 arrays `mytracks`,` pions` and `muons` may be written separately. ## Schema Evolution. Schema evolution is a problem faced by long-lived data. When a schema; changes, existing persistent data can become inaccessible unless the; system provides a mechanism to access data created with previous; versions of the schema. In the lifetime of collaboration, the class; definitions (i.e. the schema) are likely to change",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:66806,efficient,efficient,66806,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['efficient'],['efficient']
Energy Efficiency,"ng a definition for the existing; function declared in the header:. .. code-block:: c++. // Foo.cpp; #include ""Foo.h""; namespace llvm {; int foo(char *s) { // Mismatch between ""const char *"" and ""char *""; }; } // namespace llvm. This error will not be caught until the build is nearly complete, when the; linker fails to find a definition for any uses of the original function. If the; function were instead defined with a namespace qualifier, the error would have; been caught immediately when the definition was compiled. Class method implementations must already name the class and new overloads; cannot be introduced out of line, so this recommendation does not apply to them. .. _early exits:. Use Early Exits and ``continue`` to Simplify Code; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When reading code, keep in mind how much state and how many previous decisions; have to be remembered by the reader to understand a block of code. Aim to; reduce indentation where possible when it doesn't make it more difficult to; understand the code. One great way to do this is by making use of early exits; and the ``continue`` keyword in long loops. Consider this code that does not; use an early exit:. .. code-block:: c++. Value *doSomething(Instruction *I) {; if (!I->isTerminator() &&; I->hasOneUse() && doOtherThing(I)) {; ... some long code ....; }. return 0;; }. This code has several problems if the body of the ``'if'`` is large. When; you're looking at the top of the function, it isn't immediately clear that this; *only* does interesting things with non-terminator instructions, and only; applies to things with the other predicates. Second, it is relatively difficult; to describe (in comments) why these predicates are important because the ``if``; statement makes it difficult to lay out the comments. Third, when you're deep; within the body of the code, it is indented an extra level. Finally, when; reading the top of the function, it isn't clear what the result is if the; pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:35453,reduce,reduce,35453,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['reduce'],['reduce']
Energy Efficiency,"ng data to Rfot fitting; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; r[""x""]<<TVectorD(n, x1);; r[""y""]<<TVectorD(n, y1);; //creating a R data frame; r<<""ds<-data.frame(x=x,y=y)"";; //fitting x and y to X^power using Nonlinear Least Squares; r<<""m <- nls(y ~ I(x^power),data = ds, start = list(power = 1),trace = T)"";; //getting the exponent; Double_t power;; r[""summary(m)$coefficients[1]""]>>power;. TF1 *f_fitted=new TF1(""f_fitted"",""pow(x,[0])"",0,1);; f_fitted->SetParameter(0,power);; //plotting the fitted function; TGraph *gr3 = new TGraph(f_fitted);; gr3->SetMarkerColor(kGreen);; gr3->SetMarkerStyle(8);; gr3->SetMarkerSize(1);. mg->Add(gr3);; mg->Draw(""ap"");. //displaying basic results; TPaveText *pt = new TPaveText(0.1,0.6,0.5,0.9,""brNDC"");; pt->SetFillColor(18);; pt->SetTextAlign(12);; pt->AddText(""Fitting x^power "");; pt->AddText("" \""Blue\"" Points with gaussian noise to be fitted"");; pt->AddText("" \""Red\"" Known function x^3"");; TString fmsg;; fmsg.Form("" \""Green\"" Fitted function with power=%.4lf"",power);; pt->AddText(fmsg);; pt->Draw();; c1->Update();; return c1;; }; ~~~; In the first image you can see the blue dots which are the function `x^3` with gaussian noise, the red dots correspond to; the original function and the green ones correspond to the fitted function. \image html R_image1.png. ## Global Minimization in R using the package DEoptim; DEoptim is a R package for Differential Evolution Minimization that lets you do global; Minimization.; To install this package you just need to run:. ~~~{.cxx}; #include<TRInterface.h>; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; r<<""install.packages('DEoptim',repos='http://cran.rstudio.com/')"";; ~~~. Then create a macro named GlobalMinimization.C with the next code. ~~~{.cxx}; #include<TRInterface.h>; #include<TBenchmark.h>; #include<math.h>; #include<stdlib.h>; //In the next function the *double pointer should be changed by a TVectorD datatype,; //because the pointer has no meaning in the R ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:16685,power,power,16685,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['power'],['power']
Energy Efficiency,"ng rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23592,adapt,adapter,23592,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['adapt'],['adapter']
Energy Efficiency,"ngth to store real and imaginary; coefficients; - **`sizex,sizey`**: basic dimensions of the source and dest spectra; - **`type`**: type of transform; - `TRANSFORM2_HAAR`; - `TRANSFORM2_WALSH`; - `TRANSFORM2_COS`; - `TRANSFORM2_SIN`; - `TRANSFORM2_FOURIER`; - `TRANSFORM2_HARTLEY`; - `TRANSFORM2_FOURIER_WALSH`; - `TRANSFORM2_FOURIER_HAAR`; - `TRANSFORM2_WALSH_HAAR`; - `TRANSFORM2_COS_WALSH`; - `TRANSFORM2_COS_HAAR`; - `TRANSFORM2_SIN_WALSH`; - `TRANSFORM2_SIN_HAAR`; - **`direction`**: transform direction (forward, inverse); - **`degree`**: applies only for mixed transforms. An example of the 2-dimensional Cosine transform of data from Figure 5.6 is; given in Figure 6.7. One can notice that the data are concentrated again; around the beginning of the coordinate system. This allows to apply; filtration, enhancement and compression techniques in the transform; domain. ![2-dimensional Cosine transform of data from Figure 5.6](figures/image208.png). In some cases, when the spectrum is smooth, the cosine transforms are very; efficient. In Figures 6.8, 6.9 we show original spectrum and transformed; coefficients using Cosine transform, respectively. ![Original spectrum](figures/image210.png). ![Transformed coefficients using Cosine transform](figures/image212.png). Similarly to 1-dimensional case we have also implemented the functions for zonal filtration, Gauss filtration and enhancement.; The zonal filtration function using classic transforms has the form of. ```{.cpp}; char *Filter2Zonal(const float **source,; float **dest,; int sizex,; int sizey,; int type,; int degree,; int xmin,; int xmax,; int ymin,; int ymax,; float filter_coeff);; ```. This function transforms the source spectrum. The calling program should; fill in the input parameters. Then it sets transformed coefficients in the; given region to the given; `filter_coeff` and transforms it back. Filtered data are written into the dest; spectrum. Function parameters:. - **`source`**: pointer to the matrix of source ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:67439,efficient,efficient,67439,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['efficient'],['efficient']
Energy Efficiency,"nication that is conspicuously marked or otherwise; designated in writing by the copyright owner as ""Not a Contribution."". ""Contributor"" shall mean Licensor and any individual or Legal Entity; on behalf of whom a Contribution has been received by Licensor and; subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of; this License, each Contributor hereby grants to You a perpetual,; worldwide, non-exclusive, no-charge, royalty-free, irrevocable; copyright license to reproduce, prepare Derivative Works of,; publicly display, publicly perform, sublicense, and distribute the; Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of; this License, each Contributor hereby grants to You a perpetual,; worldwide, non-exclusive, no-charge, royalty-free, irrevocable; (except as stated in this section) patent license to make, have made,; use, offer to sell, sell, import, and otherwise transfer the Work,; where such license applies only to those patent claims licensable; by such Contributor that are necessarily infringed by their; Contribution(s) alone or by combination of their Contribution(s); with the Work to which such Contribution(s) was submitted. If You; institute patent litigation against any entity (including a; cross-claim or counterclaim in a lawsuit) alleging that the Work; or a Contribution incorporated within the Work constitutes direct; or contributory patent infringement, then any patent licenses; granted to You under this License for that Work shall terminate; as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the; Work or Derivative Works thereof in any medium, with or without; modifications, and in Source or Object form, provided that You; meet the following conditions:. (a) You must give any other recipients of the Work or; Derivative Works a copy of this License; and. (b) You must cause",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT:3943,charge,charge,3943,interpreter/llvm-project/clang/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT,5,['charge'],['charge']
Energy Efficiency,"nitizer. It's experimental, so expect problems. For example, when building with gcc,; manipulations in global variables in llvm will abort the build. Such checks can be disabled using environment variables. Check the address; sanitizer documentation or the link below for details. In clang, which allows to blacklist functions, the build will continue. See [core/sanitizer](https://github.com/root-project/root/tree/master/core/sanitizer) for information. ### Optimization of ROOT header files. Many (but intentionally not all) unused includes were removed from ROOT header files. For instance, `#include ""TObjString.h""` and; `#include ""ThreadLocalStorage.h""` were removed from `TClass.h`. Or `#include ""TDatime.h""` was removed from; `TDirectory.h` header file . Or `#include ""TDatime.h""` was removed from `TFile.h`.; This change may cause errors during compilation of ROOT-based code. To fix it, provide missing the includes; where they are really required.; This improves compile times and reduces code inter-dependency; see https://github.com/include-what-you-use/include-what-you-use/blob/master/docs/WhyIWYU.md for a good overview of the motivation. Even more includes will be ""hidden"" when ROOT configured with `-Ddev=ON` build option.; In that case ROOT uses `#ifdef R__LESS_INCLUDES` to replace unused includes by class forward declarations.; Such `dev` builds can be used to verify that ROOT-based code really includes all necessary ROOT headers. ## RDataFrame. - Starting from this version, when `RSnapshotOptions.fMode` is `""UPDATE""` (i.e. the output file is opened in ""UPDATE""; mode), Snapshot will refuse to write out a TTree if one with the same name is already present in the output file.; Users can set the new flag `RSnapshotOption::fOverwriteIfExists` to `true` to force the deletion of the TTree that is; already present and the writing of a new TTree with the same name. See; [ROOT-10573](https://sft.its.cern.ch/jira/browse/ROOT-10573) for more details.; - RDataFrame changed its",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md:8717,reduce,reduces,8717,README/ReleaseNotes/v622/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md,1,['reduce'],['reduces']
Energy Efficiency,"nments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the delay. To illustrate, consider this pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6. Imagine that the SUB32rr were moved forward to give us the following MIR:. .. code-block:: text. %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; %1:gr32 = ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:32827,schedul,scheduling,32827,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['schedul'],['scheduling']
Energy Efficiency,"now always reports `kEntryBeyondEnd` after an event loop correctly completes. In previous versions, it could sometime return `kEntryNotFound` even for well-behaved event loops.; - Add `TEntryList::AddSubList` to specifically add a sub-list to the main list of entries. Consequently, add also a new option `""sync""` in `TChain::SetEntryList` to connect the sub-trees of the chain to the sub-lists of the entry list in lockstep (PR [#8660](https://github.com/root-project/root/pull/8660)).; - Add `TEntryList::EnterRange` to add all entries in a certain range `[start, end)` to the entry list (PR [#8740](https://github.com/root-project/root/pull/8740)). ## RNTuple. ROOT's experimental successor of TTree has been upgraded to the version 1 of the binary format specification. Compared to the v0 format, the header is ~40% smaller and the footer ~100% smaller (after zstd compression). More details in PR [#8897](https://github.com/root-project/root/pull/8897).; RNTuple is still experimental and is scheduled to become production grade in 2024. Thus, we appreciate feedback and suggestions for improvement. If you have been trying RNTuple for a while, these are the other important changes that you will notice:. - Support for aligned friends (PR [#6979](https://github.com/root-project/root/pull/6979)). Refer to the `RNTupleReader::OpenFriends()` function.; - Cluster and page sizes in `RNTupleWriteOptions` now refer to their target size in bytes (as opposed to the number of entries). Defaults are 64 kB for the page size and 50 MB for the cluster size (PR [#8703](https://github.com/root-project/root/pull/8703)).; - Storing objects of user-defined classes via `TClass` now also includes members inherited from all the base classes (PR [#8552](https://github.com/root-project/root/pull/8552)).; - Support for RFields whose type is a typedef to some other type. ## RDataFrame. ### New features. - Add [`Redefine`](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a4e882a949c8a1022a3",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:6272,schedul,scheduled,6272,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['schedul'],['scheduled']
Energy Efficiency,"ns from functions called indirectly; ----------------------------------------. If a function is called indirectly, the return jump table is constructed for the; equivalence class of functions instead of a single function. Cross-DSO calls; ---------------; Consider two instrumented DSOs, `A` and `B`. `A` defines `f()` and `B` calls it. This case will be handled similarly to the cross-DSO scheme using the slow path callback. Non-goals; ---------. RCFI does not protect `RET` instructions:; * in non-instrumented DSOs,; * in instrumented DSOs for functions that are called from non-instrumented DSOs,; * embedded into other instructions (e.g. `0f4fc3 cmovg %ebx,%eax`). .. _SafeStack: https://clang.llvm.org/docs/SafeStack.html; .. _RFG: https://xlab.tencent.com/en/2016/11/02/return-flow-guard; .. _Intel CET: https://software.intel.com/en-us/blogs/2016/06/09/intel-release-new-technology-specifications-protect-rop-attacks. Hardware support; ================. We believe that the above design can be efficiently implemented in hardware.; A single new instruction added to an ISA would allow to perform the forward-edge CFI check; with fewer bytes per check (smaller code size overhead) and potentially more; efficiently. The current software-only instrumentation requires at least; 32-bytes per check (on x86_64).; A hardware instruction may probably be less than ~ 12 bytes.; Such instruction would check that the argument pointer is in-bounds,; and is properly aligned, and if the checks fail it will either trap (in monolithic scheme); or call the slow path function (cross-DSO scheme).; The bit vector lookup is probably too complex for a hardware implementation. .. code-block:: none. // This instruction checks that 'Ptr'; // * is aligned by (1 << kAlignment) and; // * is inside [kRangeBeg, kRangeBeg+(kRangeSize<<kAlignment)); // and if the check fails it jumps to the given target (slow path).; //; // 'Ptr' is a register, pointing to the virtual function table; // or to the function whic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:27878,efficient,efficiently,27878,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['efficient'],['efficiently']
Energy Efficiency,"ns of :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` (including global data). Implementing a ``FunctionPass`` is usually straightforward (See the :ref:`Hello; World <writing-an-llvm-pass-basiccode>` pass for example).; ``FunctionPass``\ es may override three virtual methods to do their work. All; of these methods should return ``true`` if they modified the program, or; ``false`` if they didn't. .. _writing-an-llvm-pass-doInitialization-mod:. The ``doInitialization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Module &M);. The ``doInitialization`` method is allowed to do most of the things that; ``FunctionPass``\ es are not allowed to do. They can add and remove functions,; get pointers to functions, etc. The ``doInitialization`` method is designed to; do simple initialization type of stuff that does not depend on the functions; being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). A good example of how this method should be used is the `LowerAllocations; <https://llvm.org/doxygen/LowerAllocations_8cpp-source.html>`_ pass. This pass; converts ``malloc`` and ``free`` instructions into platform dependent; ``malloc()`` and ``free()`` function calls. It uses the ``doInitialization``; method to get a reference to the ``malloc`` and ``free`` functions that it; needs, adding prototypes to the module if necessary. .. _writing-an-llvm-pass-runOnFunction:. The ``runOnFunction`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnFunction(Function &F) = 0;. The ``runOnFunction`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. .. _writing-an-llvm-pass-doFinalization-mod:. The ``doFinalization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:18874,schedul,scheduled,18874,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['schedul'],['scheduled']
Energy Efficiency,"nse (``nsw``).; * The successive addition of each offset (without adding the base address) does; not wrap the pointer index type in a signed sense (``nsw``).; * The successive addition of the current address, interpreted as an unsigned; number, and each offset, interpreted as a signed number, does not wrap the; unsigned address space and remains *in bounds* of the allocated object.; As a corollary, if the added offset is non-negative, the addition does not; wrap in an unsigned sense (``nuw``).; * In cases where the base is a vector of pointers, the ``inbounds`` keyword; applies to each of the computations element-wise. Note that ``getelementptr`` with all-zero indices is always considered to be; ``inbounds``, even if the base pointer does not point to an allocated object.; As a corollary, the only pointer in bounds of the null pointer in the default; address space is the null pointer itself. These rules are based on the assumption that no allocated object may cross; the unsigned address space boundary, and no allocated object may be larger; than half the pointer index type space. If the ``inrange`` keyword is present before any index, loading from or; storing to any pointer derived from the ``getelementptr`` has undefined; behavior if the load or store would access memory outside of the bounds of; the element selected by the index marked as ``inrange``. The result of a; pointer comparison or ``ptrtoint`` (including ``ptrtoint``-like operations; involving memory) involving a pointer derived from a ``getelementptr`` with; the ``inrange`` keyword is undefined, with the exception of comparisons; in the case where both operands are in the range of the element selected; by the ``inrange`` keyword, inclusive of the address one past the end of; that element. Note that the ``inrange`` keyword is currently only allowed; in constant ``getelementptr`` expressions. The getelementptr instruction is often confusing. For some more insight; into how it works, see :doc:`the getelemen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:438713,allocate,allocated,438713,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['allocate'],['allocated']
Energy Efficiency,"nsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.ldexp`` on any; floating point or vector of floating point type. Not all targets support; all types however. ::. declare float @llvm.ldexp.f32.i32(float %Val, i32 %Exp); declare double @llvm.ldexp.f64.i32(double %Val, i32 %Exp); declare x86_fp80 @llvm.ldexp.f80.i32(x86_fp80 %Val, i32 %Exp); declare fp128 @llvm.ldexp.f128.i32(fp128 %Val, i32 %Exp); declare ppc_fp128 @llvm.ldexp.ppcf128.i32(ppc_fp128 %Val, i32 %Exp); declare <2 x float> @llvm.ldexp.v2f32.v2i32(<2 x float> %Val, <2 x i32> %Exp). Overview:; """""""""""""""""". The '``llvm.ldexp.*``' intrinsics perform the ldexp function. Arguments:; """""""""""""""""""". The first argument and the return value are :ref:`floating-point; <t_floating>` or :ref:`vector <t_vector>` of floating-point values of; the same type. The second argument is an integer with the same number; of elements. Semantics:; """""""""""""""""""". This function multiplies the first argument by 2 raised to the second; argument's power. If the first argument is NaN or infinite, the same; value is returned. If the result underflows a zero with the same sign; is returned. If the result overflows, the result is an infinity with; the same sign. .. _int_frexp:. '``llvm.frexp.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.frexp`` on any; floating point or vector of floating point type. Not all targets support; all types however. ::. declare { float, i32 } @llvm.frexp.f32.i32(float %Val); declare { double, i32 } @llvm.frexp.f64.i32(double %Val); declare { x86_fp80, i32 } @llvm.frexp.f80.i32(x86_fp80 %Val); declare { fp128, i32 } @llvm.frexp.f128.i32(fp128 %Val); declare { ppc_fp128, i32 } @llvm.frexp.ppcf128.i32(ppc_fp128 %Val); declare { <2 x float>, <2 x i32> } @llvm.frexp.v2f32.v2i32(<2 x float> %Val). Overview:; """""""""""""""""". The '``llvm.frexp.*``' intrinsics perform the frexp function. Arguments:; """""""""""""""""""". T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:565522,power,power,565522,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"nsics return the square root of the specified value. Arguments:; """""""""""""""""""". The argument and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``sqrt``' function but without; trapping or setting ``errno``. For types specified by IEEE-754, the result; matches a conforming libm implementation. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. '``llvm.powi.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.powi`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. Generally, the only supported type for the exponent is the one matching; with the C type ``int``. ::. declare float @llvm.powi.f32.i32(float %Val, i32 %power); declare double @llvm.powi.f64.i16(double %Val, i16 %power); declare x86_fp80 @llvm.powi.f80.i32(x86_fp80 %Val, i32 %power); declare fp128 @llvm.powi.f128.i32(fp128 %Val, i32 %power); declare ppc_fp128 @llvm.powi.ppcf128.i32(ppc_fp128 %Val, i32 %power). Overview:; """""""""""""""""". The '``llvm.powi.*``' intrinsics return the first operand raised to the; specified (positive or negative) power. The order of evaluation of; multiplications is not defined. When a vector of floating-point type is; used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The second argument is an integer power, and the first is a value to; raise to that power. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.sin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sin`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.sin.f32(float %Val); declare double @llvm.sin.f64(double",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:558130,power,power,558130,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"nsigned b); { return std::make_pair(a + b, a + b < a); }; bool no_overflow(unsigned a, unsigned b); { return !full_add(a, b).second; }. Should compile to:. __Z11no_overflowjj:; add r4,r3,r4; subfc r3,r3,r4; li r3,0; adde r3,r3,r3; blr. (or better) not:. __Z11no_overflowjj:; add r2, r4, r3; cmplw cr7, r2, r3; mfcr r2; rlwinm r2, r2, 29, 31, 31; xori r3, r2, 1; blr . //===---------------------------------------------------------------------===//. We compile some FP comparisons into an mfcr with two rlwinms and an or. For; example:; #include <math.h>; int test(double x, double y) { return islessequal(x, y);}; int test2(double x, double y) { return islessgreater(x, y);}; int test3(double x, double y) { return !islessequal(x, y);}. Compiles into (all three are similar, but the bits differ):. _test:; 	fcmpu cr7, f1, f2; 	mfcr r2; 	rlwinm r3, r2, 29, 31, 31; 	rlwinm r2, r2, 31, 31, 31; 	or r3, r2, r3; 	blr . GCC compiles this into:. _test:; 	fcmpu cr7,f1,f2; 	cror 30,28,30; 	mfcr r3; 	rlwinm r3,r3,31,1; 	blr; ; which is more efficient and can use mfocr. See PR642 for some more context. //===---------------------------------------------------------------------===//. void foo(float *data, float d) {; long i;; for (i = 0; i < 8000; i++); data[i] = d;; }; void foo2(float *data, float d) {; long i;; data--;; for (i = 0; i < 8000; i++) {; data[1] = d;; data++;; }; }. These compile to:. _foo:; 	li r2, 0; LBB1_1:	; bb; 	addi r4, r2, 4; 	stfsx f1, r3, r2; 	cmplwi cr0, r4, 32000; 	mr r2, r4; 	bne cr0, LBB1_1	; bb; 	blr ; _foo2:; 	li r2, 0; LBB2_1:	; bb; 	addi r4, r2, 4; 	stfsx f1, r3, r2; 	cmplwi cr0, r4, 32000; 	mr r2, r4; 	bne cr0, LBB2_1	; bb; 	blr . The 'mr' could be eliminated to folding the add into the cmp better. //===---------------------------------------------------------------------===//; Codegen for the following (low-probability) case deteriorated considerably ; when the correctness fixes for unordered comparisons went in (PR 642, 58871).; It should be possible to recov",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:10225,efficient,efficient,10225,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,2,['efficient'],['efficient']
Energy Efficiency,"nslation is included without limitation in; the term ""modification"".) Each licensee is addressed as ""you"". Activities other than copying, distribution and modification are not; covered by this License; they are outside its scope. The act of; running the Program is not restricted, and the output from the Program; is covered only if its contents constitute a work based on the; Program (independent of having been made by running the Program).; Whether that is true depends on what the Program does. 1. You may copy and distribute verbatim copies of the Program's; source code as you receive it, in any medium, provided that you; conspicuously and appropriately publish on each copy an appropriate; copyright notice and disclaimer of warranty; keep intact all the; notices that refer to this License and to the absence of any warranty;; and give any other recipients of the Program a copy of this License; along with the Program. You may charge a fee for the physical act of transferring a copy, and; you may at your option offer warranty protection in exchange for a fee. 2. You may modify your copy or copies of the Program or any portion; of it, thus forming a work based on the Program, and copy and; distribute such modifications or work under the terms of Section 1; above, provided that you also meet all of these conditions:. a) You must cause the modified files to carry prominent notices; stating that you changed the files and the date of any change. b) You must cause any work that you distribute or publish, that in; whole or in part contains or is derived from the Program or any; part thereof, to be licensed as a whole at no charge to all third; parties under the terms of this License. c) If the modified program normally reads commands interactively; when run, you must cause it, when started running for such; interactive use in the most ordinary way, to print or display an; announcement including an appropriate copyright notice and a; notice that there is no warranty (or else, s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt:4365,charge,charge,4365,misc/rootql/LICENSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt,4,['charge'],['charge']
Energy Efficiency,"nstruction allocates ``sizeof(<type>)*NumElements``; bytes of memory on the runtime stack, returning a pointer of the; appropriate type to the program. If ""NumElements"" is specified, it is; the number of elements allocated, otherwise ""NumElements"" is defaulted; to be one. If a constant alignment is specified, the value result of the; allocation is guaranteed to be aligned to at least that boundary. The; alignment may not be greater than ``1 << 32``. The alignment is only optional when parsing textual IR; for in-memory IR,; it is always present. If not specified, the target can choose to align the; allocation on any convenient boundary compatible with the type. '``type``' may be any sized type. Structs containing scalable vectors cannot be used in allocas unless all; fields are the same scalable vector type (e.g. ``{<vscale x 2 x i32>,; <vscale x 2 x i32>}`` contains the same type while ``{<vscale x 2 x i32>,; <vscale x 2 x i64>}`` doesn't). Semantics:; """""""""""""""""""". Memory is allocated; a pointer is returned. The allocated memory is; uninitialized, and loading from uninitialized memory produces an undefined; value. The operation itself is undefined if there is insufficient stack; space for the allocation.'``alloca``'d memory is automatically released; when the function returns. The '``alloca``' instruction is commonly used; to represent automatic variables that must have an address available. When; the function returns (either with the ``ret`` or ``resume`` instructions),; the memory is reclaimed. Allocating zero bytes is legal, but the returned; pointer may not be unique. The order in which memory is allocated (ie.,; which way the stack grows) is not specified. Note that '``alloca``' outside of the alloca address space from the; :ref:`datalayout string<langref_datalayout>` is meaningful only if the; target has assigned it a semantics. If the returned pointer is used by :ref:`llvm.lifetime.start <int_lifestart>`,; the returned object is initially dead.; See :ref:`llvm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:410450,allocate,allocated,410450,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"nt hierarchy display (former dtree) with jQuery; 7. Fix several problems in drawing optimization; 8. Implement dragging objects from hierarchy browser into existing canvas; to superimpose several objects; 9. Implement col2 and col3 draw options, using html5 canvas; 10. Support 'p' and 'p0' draw options for TH1 class. ## Development of version 3.0. ### November 2014; 1. Better font size and position in pave stats; 2. Resize/move of element only inside correspondent pad; 3. Adjust of frame size when Y-axis exceed pad limits; 4. Correct values in tooltip for THStack; 5. Exclude drawing of markers from TGraph outside visible range; 6. Drawing of canvas without TFrame object; 7. Many other small bug fixes and improvements, thanks to Maximilian Dietrich. ### October 2014; 1. Add ""shortcut icon""; 2. Add demo of online THttpServer - shell script copies data from; running httpserver.C macro on Apache webserver; 3. Evaluate 'monitoring' parameter for online server like:; <http://localhost:8080/?monitoring=1000>; Parameter defines how often displayed objects should be updated.; 4. Implement 'opt' and 'opts' URL parameters for main page.; 5. Show progress with scripts loading in the browser window; 6. When one appends ""+"" to the filename, its content read completely with first I/O operation.; 7. Implement JS custom streamer for TCanvas, restore aspect ratio when drawing; 8. Major redesign of drawing classes. Resize and update of TCanvas are implemented.; All major draw functions working with HTML element id as first argument.; 9. Extract 3D drawings into separate JSRoot3DPainter.js script; 10. Use newest three.min.js (r68) for 3D drawings, solves problem with Firefox.; 11. Introduce generic list of draw functions for all supported classes.; 12. Add possibility to 'expand' normal objects in the hierarchy browser.; For instance, this gives access to single elements of canvas,; when whole canvas cannot be drawn.; 13. Correct usage of colors map, provided with TCanvas.; 14. Introdu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:70590,monitor,monitoring,70590,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,2,['monitor'],['monitoring']
Energy Efficiency,"nt volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TGeo objects; - intensive use of HTML Worker to offload computation tasks and keep interactivity; - enable more details when changing camera position/zoom; - better and faster build of composite shapes; 2. Improvements in histograms 3D drawing; - all lego options: lego1..lego4, combined with 'fb', 'bb', '0' or 'z'; - support axis labels on lego plots; - support lego plots for TH1; 3. Improvements in all 3D graphics; - upgrade three.js to r79; - use of THREE.BufferGeometry for all components; - significant (up to factor 10) performance improvement; 4. Implement box and hbox draw options for TH1 class; 5. Implement drawing of axes ticks on opposite side (when fTickx/y specified); 6. Preliminary support of candle plot (many options to be implemented); 7. Update draw attributes (fill/line/position) when monitor objects. ## Changes in 4.5.3; 1. Fix - position of TFrame in canvas/pad; 2. Fix - use histogram fMinimum/fMaximum when creating color palette; 3. Fix - correctly draw empty th2 bins when zmin<0 is specified; 4. Fix - limit th2 text output size; 5. Fix - use histogram fMinimum/fMaximum when drawing z axis in lego plot; 6. Fix - error in TGeoCtub shape creation; 7. Fix - error in pcon/pgon shapes when Rmin===0. ## Changes in 4.5.1; 1. Fix - correctly handle ^2..^9 in TFormula equations; 2. Fix - support TMath::Gaus in TFormula; 3. Fix - correctly display ^2 and ^3 in SVG text output; 4. Fix - do not show tooltips for empty TProfile bins; 5. Fix - statbox toggling was not working on subpads; 6. Fix - positioning of 3D objects in Webkit browsers in complex layouts; 7. Fix - difference in TF1 between ROOT5/6 (#54). ## Changes in 4.5.0; 1. Zooming with mouse wheel; 2. Context menus for many different objects attributes are provided; 3. Context menu for every drawn ob",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:53646,monitor,monitor,53646,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['monitor'],['monitor']
Energy Efficiency,"nt. Example:; """""""""""""""". .. code-block:: text. fence acquire ; yields void; fence syncscope(""singlethread"") seq_cst ; yields void; fence syncscope(""agent"") seq_cst ; yields void. .. _i_cmpxchg:. '``cmpxchg``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. cmpxchg [weak] [volatile] ptr <pointer>, <ty> <cmp>, <ty> <new> [syncscope(""<target-scope>"")] <success ordering> <failure ordering>[, align <alignment>] ; yields { ty, i1 }. Overview:; """""""""""""""""". The '``cmpxchg``' instruction is used to atomically modify memory. It; loads a value in memory and compares it to a given value. If they are; equal, it tries to store a new value into the memory. Arguments:; """""""""""""""""""". There are three arguments to the '``cmpxchg``' instruction: an address; to operate on, a value to compare to the value currently be at that; address, and a new value to place at that address if the compared values; are equal. The type of '<cmp>' must be an integer or pointer type whose; bit width is a power of two greater than or equal to eight and less; than or equal to a target-specific size limit. '<cmp>' and '<new>' must; have the same type, and the type of '<pointer>' must be a pointer to; that type. If the ``cmpxchg`` is marked as ``volatile``, then the; optimizer is not allowed to modify the number or order of execution of; this ``cmpxchg`` with other :ref:`volatile operations <volatile>`. The success and failure :ref:`ordering <ordering>` arguments specify how this; ``cmpxchg`` synchronizes with other atomic operations. Both ordering parameters; must be at least ``monotonic``, the failure ordering cannot be either; ``release`` or ``acq_rel``. A ``cmpxchg`` instruction can also take an optional; "":ref:`syncscope <syncscope>`"" argument. Note: if the alignment is not greater or equal to the size of the `<value>`; type, the atomic operation is likely to require a lock and have poor; performance. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:426326,power,power,426326,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"nt.unordered.atomic.*``' intrinsic is a specialization; of the '``llvm.memmove.*``' intrinsic. It differs in that the ``dest`` and; ``src`` are treated as arrays with elements that are exactly ``element_size``; bytes, and the copy between buffers uses a sequence of; :ref:`unordered atomic <ordering>` load/store operations that are a positive; integer multiple of the ``element_size`` in size. Arguments:; """""""""""""""""""". The first three arguments are the same as they are in the; :ref:`@llvm.memmove <int_memmove>` intrinsic, with the added constraint that; ``len`` is required to be a positive integer multiple of the ``element_size``.; If ``len`` is not a positive integer multiple of ``element_size``, then the; behaviour of the intrinsic is undefined. ``element_size`` must be a compile-time constant positive power of two no; greater than a target-specific atomic access size limit. For each of the input pointers the ``align`` parameter attribute must be; specified. It must be a power of two no less than the ``element_size``. Caller; guarantees that both the source and destination pointers are aligned to that; boundary. Semantics:; """""""""""""""""""". The '``llvm.memmove.element.unordered.atomic.*``' intrinsic copies ``len`` bytes; of memory from the source location to the destination location. These locations; are allowed to overlap. The memory copy is performed as a sequence of load/store; operations where each access is guaranteed to be a multiple of ``element_size``; bytes wide and aligned at an ``element_size`` boundary. The order of the copy is unspecified. The same value may be read from the source; buffer many times, but only one write is issued to the destination buffer per; element. It is well defined to have concurrent reads and writes to both source; and destination provided those reads and writes are unordered atomic when; specified. This intrinsic does not provide any additional ordering guarantees over those; provided by a set of unordered loads from the source location",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:961720,power,power,961720,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"nt_lane_pc;; DW_OP_addrx &lex_1_end;; DW_OP_stack_value;; DW_OP_LLVM_extend 64, 64;; DW_OP_call_ref %__lex_1_save_exec;; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-ac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:108213,allocate,allocate,108213,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocate']
Energy Efficiency,"nt_t natoms);; ~~~. or:. ~~~{.cpp}; void AddElement(TGeoMaterial* mat, Double_t weight);; void AddElement(TGeoElement* elem, Double_t weight);; void AddElement(TGeoElement* elem, Int_t natoms);; void AddElement(Double_t a, Double_t z, Double_t weight); ~~~. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ~~~. The following properties of radionuclides can be cu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:4868,energy,energy,4868,geom/geom/doc/materials.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md,1,['energy'],['energy']
Energy Efficiency,"ntegrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return integral; values for each value of the parameters. A new tutorial macro rf903_numintcache.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of this feature. Representation of function and p.d.f. derivatives; A new class has been added that can represent the derivative of any p.d.f or funct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:6148,power,power,6148,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,['power'],['power']
Energy Efficiency,ntext.h; llvm/tools/llvm-profgen/CSPreInliner.cpp; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llv,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337305,reduce,reduce,337305,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,ntics/unparse-with-symbols.h; flang/lib/Common/default-kinds.cpp; flang/lib/Common/Fortran-features.cpp; flang/lib/Common/Fortran.cpp; flang/lib/Common/idioms.cpp; flang/lib/Decimal/big-radix-floating-point.h; flang/lib/Decimal/binary-to-decimal.cpp; flang/lib/Decimal/decimal-to-binary.cpp; flang/lib/Evaluate/call.cpp; flang/lib/Evaluate/character.h; flang/lib/Evaluate/check-expression.cpp; flang/lib/Evaluate/common.cpp; flang/lib/Evaluate/complex.cpp; flang/lib/Evaluate/constant.cpp; flang/lib/Evaluate/expression.cpp; flang/lib/Evaluate/fold-character.cpp; flang/lib/Evaluate/fold-complex.cpp; flang/lib/Evaluate/fold-designator.cpp; flang/lib/Evaluate/fold-implementation.h; flang/lib/Evaluate/fold-logical.cpp; flang/lib/Evaluate/fold-real.cpp; flang/lib/Evaluate/fold-reduction.cpp; flang/lib/Evaluate/fold-reduction.h; flang/lib/Evaluate/fold.cpp; flang/lib/Evaluate/formatting.cpp; flang/lib/Evaluate/host.cpp; flang/lib/Evaluate/host.h; flang/lib/Evaluate/initial-image.cpp; flang/lib/Evaluate/int-power.h; flang/lib/Evaluate/integer.cpp; flang/lib/Evaluate/intrinsics-library.cpp; flang/lib/Evaluate/intrinsics.cpp; flang/lib/Evaluate/logical.cpp; flang/lib/Evaluate/real.cpp; flang/lib/Evaluate/shape.cpp; flang/lib/Evaluate/static-data.cpp; flang/lib/Evaluate/tools.cpp; flang/lib/Evaluate/type.cpp; flang/lib/Evaluate/variable.cpp; flang/lib/Frontend/CompilerInstance.cpp; flang/lib/Frontend/FrontendAction.cpp; flang/lib/Frontend/FrontendOptions.cpp; flang/lib/Frontend/TextDiagnostic.cpp; flang/lib/Frontend/TextDiagnosticBuffer.cpp; flang/lib/Frontend/TextDiagnosticPrinter.cpp; flang/lib/FrontendTool/ExecuteCompilerInvocation.cpp; flang/lib/Lower/Allocatable.cpp; flang/lib/Lower/Bridge.cpp; flang/lib/Lower/CallInterface.cpp; flang/lib/Lower/Coarray.cpp; flang/lib/Lower/ComponentPath.cpp; flang/lib/Lower/ConvertExpr.cpp; flang/lib/Lower/ConvertType.cpp; flang/lib/Lower/ConvertVariable.cpp; flang/lib/Lower/DumpEvaluateExpr.cpp; flang/lib/Lower/IntervalSet.h; flang/lib/Lower,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:116883,power,power,116883,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['power'],['power']
Energy Efficiency,"nto code. It keeps track of the results of various; expressions to avoid redundant calculations. - **Loop Scopes()**: `beginloop()` and `endloop()` are used to create a scope; for iterating over vector observables (collections of data). This is; especially useful when dealing with data that comes in sets or arrays. - **addToGlobalScope()**: helps add code statements to the global scope; (e.g., to declare variables). - **addToCodeBody()**: adds the input string to the squashed code body. If a; class implements a translate function that wants to emit something to the; squashed code body, it must call this function with the code it wants to; emit. In case of loops, it automatically determines if the code needs to be; stored inside or outside the scope of that loop. - **makeValidVarName()**: takes a string (e.g., a variable name) and converts; it into a valid C++ variable name by replacing any forbidden characters with; underscores. - **buildArg()**: helps convert RooFit objects into arrays or other C++; representations for efficient computation. - **addResult()**: adds (or overwrites) the string representing the result of; a node. > For each `translate()` function, it is important to call `addResult()` since; this is what enables the squashing to happen. - **getResult()**: gets the result for the given node using the node name.; This node also performs the necessary code generation through recursive calls; to `translate()`. - **assembleCode()**: combines the generated code statements into the final; code body of the squashed function. These functions will appear again in this document with more contextual; examples. For detailed in-line documentation (code comments), please see:. > [roofit/roofitcore/src/RooFit/Detail/CodeSquashContext.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooFit/Detail/CodeSquashContext.cxx). ### b. RooFuncWrapper. > [roofit/roofitcore/inc/RooFuncWrapper.h](https://github.com/root-project/root/blob/master/roofit/r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:32290,efficient,efficient,32290,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['efficient'],['efficient']
Energy Efficiency,"ntrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.cttz`` on any; integer bit width, or any vector of integer elements. Not all targets; support all bit widths or vector types, however. ::. declare i42 @llvm.cttz.i42 (i42 <src>, i1 <is_zero_poison>); declare <2 x i32> @llvm.cttz.v2i32(<2 x i32> <src>, i1 <is_zero_poison>). Overview:; """""""""""""""""". The '``llvm.cttz``' family of intrinsic functions counts the number of; trailing zeros. Arguments:; """""""""""""""""""". The first argument is the value to be counted. This argument may be of; any integer type, or a vector with integer element type. The return; type must match the first argument type. The second argument is a constant flag that indicates whether the intrinsic; returns a valid result if the first argument is zero. If the first; argument is zero and the second argument is true, the result is poison.; Historically some architectures did not provide a defined result for zero; values as efficiently, and many algorithms are now predicated on avoiding; zero-value inputs. Semantics:; """""""""""""""""""". The '``llvm.cttz``' intrinsic counts the trailing (least significant); zeros in a variable, or within each element of a vector. If ``src == 0``; then the result is the size in bits of the type of ``src`` if; ``is_zero_poison == 0`` and ``poison`` otherwise. For example,; ``llvm.cttz(2) = 1``. .. _int_overflow:. .. _int_fshl:. '``llvm.fshl.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.fshl`` on any; integer bit width or any vector of integer elements. Not all targets; support all bit widths or vector types, however. ::. declare i8 @llvm.fshl.i8 (i8 %a, i8 %b, i8 %c); declare i64 @llvm.fshl.i64(i64 %a, i64 %b, i64 %c); declare <2 x i32> @llvm.fshl.v2i32(<2 x i32> %a, <2 x i32> %b, <2 x i32> %c). Overview:; """""""""""""""""". The '``llvm.fshl``' family of intrinsic functions performs a funnel shift left:; the first two v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:595909,efficient,efficiently,595909,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficiently']
Energy Efficiency,"ntroduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ~~~. The following properties of radionuclides can be currently accessed via; getters in the TGeoElementRN class:. Atomic number and charge (from the base class TGeoElement). - Isomeric number (`ISO`); - ENDF code - following the convention: `ENDF=10000*Z+100*A+ISO`; - Isomeric energy level [`MeV`]; - Mass excess [`MeV`]; - Half life [`s`]; - Spin/Parity - can be retrieved with: `TGeoElementRN::GetTitle()`; - Hynalation and ingestion toxicities; - List of decays - `TGeoElementRN::GetDecays()`. The radioactive decays of a radionuclide are represented by the class; TGeoDecayChannel and they are stored in a TObjArray. Decay; provides:. - Decay mode; - Variation of isomeric number; - `Q` value for the decay [`GeV`]; - Parent element; - Daughter element. Radionuclides are linked one to each other via their decays, until the; last element in the decay chain which must be stable. One can iterate; decay chains using the iterator TGeoElemIter:. ~~~{.cpp}; root[] TGeoElemIter next(c14);; root[] TGeoElementRN *elem;; root[] while ((elem=next())) next.Print();; 6-C-014 (100% BetaMinus) T1/2=1.81e+11; 7-N-014 stable; ~~~. To create a radio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:5967,charge,charge,5967,geom/geom/doc/materials.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md,1,['charge'],['charge']
Energy Efficiency,"ntrol compilation; and installation of the library. Activities other than copying, distribution and modification are not; covered by this License; they are outside its scope. The act of; running a program using the Library is not restricted, and output from; such a program is covered only if its contents constitute a work based; on the Library (independent of the use of the Library in a tool for; writing it). Whether that is true depends on what the Library does; and what the program that uses the Library does.; ; 1. You may copy and distribute verbatim copies of the Library's; complete source code as you receive it, in any medium, provided that; you conspicuously and appropriately publish on each copy an; appropriate copyright notice and disclaimer of warranty; keep intact; all the notices that refer to this License and to the absence of any; warranty; and distribute a copy of this License along with the; Library. You may charge a fee for the physical act of transferring a copy,; and you may at your option offer warranty protection in exchange for a; fee.; ; 2. You may modify your copy or copies of the Library or any portion; of it, thus forming a work based on the Library, and copy and; distribute such modifications or work under the terms of Section 1; above, provided that you also meet all of these conditions:. a) The modified work must itself be a software library. b) You must cause the files modified to carry prominent notices; stating that you changed the files and the date of any change. c) You must cause the whole of the work to be licensed at no; charge to all third parties under the terms of this License. d) If a facility in the modified Library refers to a function or a; table of data to be supplied by an application program that uses; the facility, other than as an argument passed when the facility; is invoked, then you must make a good faith effort to ensure that,; in the event an application does not supply such function or; table, the facility still",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt:8223,charge,charge,8223,LGPL2_1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt,1,['charge'],['charge']
Energy Efficiency,"ntrol this merging:; ; NoIndex : all the TTreeIndex object are dropped.; DropIndexOnError : if any of the underlying TTree object do no have a TTreeIndex,; they are all dropped.; AsIsIndexOnError [default]: In case of missing TTreeIndex, the resulting TTree index has gaps.; BuildIndexOnError : If any of the underlying TTree object do no have a TTreeIndex,; all TTreeIndex are 'ignored' and the mising piece are rebuilt. Previously the index were kept only if the first files had an index and if there was any missing index,; the resulting index had gaps (the default was similar to AsIsIndexOnError). The new default is BuildIndexOnError ; i.e.; we now attempt by default to build the missing indices. In TBranch CopyAddress (and hence indirectly in the fast cloning); avoid having to read the first entry just to get the address set; and do the address setting directly. In TTree::CopyAddress when copying the addresses of a branch created by a leaflist; and where the memory buffer was allocated automatically (as opposed to set by the user); avoid deleting the memory allocated by the tree each time CopyAddress is called.; (This effectively prevented cloning more than once a TTree with a branch created by a leaflist.). Warning: The TTreeCache is no longer enabled by default in a TChain to align the behavior with a TTree. You need to call; TTree::SetCacheSize to enable the TTreeCache.; Correct and clarify the relationship between AutoFlush and AutoSave:; ; Both the AutoFlush and AutoSave interval can be specified in; terms of bytes (a negative value for fAutoFlush or fAutoSave); or in terms of the number of entries (positive values).; An AutoFlush is always done with an AutoSave.; If the interval specified for AutoSave is less than that for; AutoFlush, the AutoSave interval is used for both.; If the AutoFlush interval is less than the AutoSave interval,; the AutoSave interval is adjusted to the largest integer; multiple of the AutoFlush interval that is less than or equal; to th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:2591,allocate,allocated,2591,tree/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html,4,['allocate'],['allocated']
Energy Efficiency,"nts the forward and backward links that are expected; by the ``ilist<T>`` (and analogous containers) in the default manner. ``ilist_node<T>``\ s are meant to be embedded in the node type ``T``, usually; ``T`` publicly derives from ``ilist_node<T>``. .. _dss_ilist_sentinel:. Sentinels; ^^^^^^^^^. ``ilist``\ s have another specialty that must be considered. To be a good; citizen in the C++ ecosystem, it needs to support the standard container; operations, such as ``begin`` and ``end`` iterators, etc. Also, the; ``operator--`` must work correctly on the ``end`` iterator in the case of; non-empty ``ilist``\ s. The only sensible solution to this problem is to allocate a so-called *sentinel*; along with the intrusive list, which serves as the ``end`` iterator, providing; the back-link to the last element. However conforming to the C++ convention it; is illegal to ``operator++`` beyond the sentinel and it also must not be; dereferenced. These constraints allow for some implementation freedom to the ``ilist`` how to; allocate and store the sentinel. The corresponding policy is dictated by; ``ilist_traits<T>``. By default a ``T`` gets heap-allocated whenever the need; for a sentinel arises. While the default policy is sufficient in most cases, it may break down when; ``T`` does not provide a default constructor. Also, in the case of many; instances of ``ilist``\ s, the memory overhead of the associated sentinels is; wasted. To alleviate the situation with numerous and voluminous; ``T``-sentinels, sometimes a trick is employed, leading to *ghostly sentinels*. Ghostly sentinels are obtained by specially-crafted ``ilist_traits<T>`` which; superpose the sentinel with the ``ilist`` instance in memory. Pointer; arithmetic is used to obtain the sentinel, which is relative to the ``ilist``'s; ``this`` pointer. The ``ilist`` is augmented by an extra pointer, which serves; as the back-link of the sentinel. This is the only field in the ghostly; sentinel which can be legally accessed. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:69557,allocate,allocate,69557,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocate']
Energy Efficiency,"nts to the container. .. _ds_sequential:. Sequential Containers (std::vector, std::list, etc); ---------------------------------------------------. There are a variety of sequential containers available for you, based on your; needs. Pick the first in this section that will do what you want. .. _dss_arrayref:. llvm/ADT/ArrayRef.h; ^^^^^^^^^^^^^^^^^^^. The ``llvm::ArrayRef`` class is the preferred class to use in an interface that; accepts a sequential list of elements in memory and just reads from them. By; taking an ``ArrayRef``, the API can be passed a fixed size array, an; ``std::vector``, an ``llvm::SmallVector`` and anything else that is contiguous; in memory. .. _dss_fixedarrays:. Fixed Size Arrays; ^^^^^^^^^^^^^^^^^. Fixed size arrays are very simple and very fast. They are good if you know; exactly how many elements you have, or you have a (low) upper bound on how many; you have. .. _dss_heaparrays:. Heap Allocated Arrays; ^^^^^^^^^^^^^^^^^^^^^. Heap allocated arrays (``new[]`` + ``delete[]``) are also simple. They are good; if the number of elements is variable, if you know how many elements you will; need before the array is allocated, and if the array is usually large (if not,; consider a :ref:`SmallVector <dss_smallvector>`). The cost of a heap allocated; array is the cost of the new/delete (aka malloc/free). Also note that if you; are allocating an array of a type with a constructor, the constructor and; destructors will be run for every element in the array (re-sizable vectors only; construct those elements actually used). .. _dss_tinyptrvector:. llvm/ADT/TinyPtrVector.h; ^^^^^^^^^^^^^^^^^^^^^^^^. ``TinyPtrVector<Type>`` is a highly specialized collection class that is; optimized to avoid allocation in the case when a vector has zero or one; elements. It has two major restrictions: 1) it can only hold values of pointer; type, and 2) it cannot hold a null pointer. Since this container is highly specialized, it is rarely used. .. _dss_smallvector:. llvm/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:58350,allocate,allocated,58350,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"numba/numba-examples/blob/master/examples/physics/lennard_jones/numba_scalar_impl.py>`_. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext; ...; >>> cppyy.cppdef(""""""; ... #include <vector>; ... struct Atom {; ... float x;; ... float y;; ... float z;; ... };; ...; ... std::vector<Atom> atoms = {{1, 2, 3}, {2, 3, 4}, {3, 4, 5}, {4, 5, 6}, {5, 6, 7}};; ... """"""); ...; >>> @numba.njit; >>> def lj_numba_scalar(r):; ... sr6 = (1./r)**6; ... pot = 4.*(sr6*sr6 - sr6); ... return pot. >>> @numba.njit; >>> def distance_numba_scalar(atom1, atom2):; ... dx = atom2.x - atom1.x; ... dy = atom2.y - atom1.y; ... dz = atom2.z - atom1.z; ...; ... r = (dx * dx + dy * dy + dz * dz) ** 0.5; ...; ... return r; ...; >>> def potential_numba_scalar(cluster):; ... energy = 0.0; ... for i in range(cluster.size() - 1):; ... for j in range(i + 1, cluster.size()):; ... r = distance_numba_scalar(cluster[i], cluster[j]); ... e = lj_numba_scalar(r); ... energy += e; ...; ... return energy; ...; >>> print(""Total lennard jones potential ="", potential_numba_scalar(cppyy.gbl.atoms)); Total lennard jones potential = -0.5780277345740283. Overhead; --------. The main overhead of JITing Numba traces is in the type annotation in Numba; itself, optimization of the IR and assembly by the backend less so.; (There is also a non-negligible cost to Numba initialization, which is why; ``cppyy`` does not provide automatic extension hooks.); The use of ``cppyy`` bound C++, which relies on the same Numba machinery,; does not change that, since the reflection-based lookups are in C++ and; comparatively very fast.; For example, there is no appreciable difference in wall clock time to JIT a; trace using Numba's included math functions (from module ``math`` or; ``numpy``) or one that uses C++ bound ones whether from the standard library; or a templated versions from e.g. Eigen.; Use of very complex template expressions may change this balance, but in; principle, wherever it makes sense ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:9081,energy,energy,9081,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,1,['energy'],['energy']
Energy Efficiency,"ny other language frontends have; been written using LLVM, and an incomplete list is available at; `projects with LLVM <https://llvm.org/ProjectsWithLLVM/>`_. I'd like to write a self-hosting LLVM compiler. How should I interface with the LLVM middle-end optimizers and back-end code generators?; ----------------------------------------------------------------------------------------------------------------------------------------; Your compiler front-end will communicate with LLVM by creating a module in the; LLVM intermediate representation (IR) format. Assuming you want to write your; language's compiler in the language itself (rather than C++), there are 3; major ways to tackle generating LLVM IR from a front-end:. 1. **Call into the LLVM libraries code using your language's FFI (foreign; function interface).**. * *for:* best tracks changes to the LLVM IR, .ll syntax, and .bc format. * *for:* enables running LLVM optimization passes without a emit/parse; overhead. * *for:* adapts well to a JIT context. * *against:* lots of ugly glue code to write. 2. **Emit LLVM assembly from your compiler's native language.**. * *for:* very straightforward to get started. * *against:* the .ll parser is slower than the bitcode reader when; interfacing to the middle end. * *against:* it may be harder to track changes to the IR. 3. **Emit LLVM bitcode from your compiler's native language.**. * *for:* can use the more-efficient bitcode reader when interfacing to the; middle end. * *against:* you'll have to re-engineer the LLVM IR object model and bitcode; writer in your language. * *against:* it may be harder to track changes to the IR. If you go with the first option, the C bindings in include/llvm-c should help; a lot, since most languages have strong support for interfacing with C. The; most common hurdle with calling C from managed code is interfacing with the; garbage collector. The C interface was designed to require very little memory; management, and so is straightforward in ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:3879,adapt,adapts,3879,interpreter/llvm-project/llvm/docs/FAQ.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst,1,['adapt'],['adapts']
Energy Efficiency,"o I = BB->begin(); I != BB->end(); ++I); ... use I ... The problem with this construct is that it evaluates ""``BB->end()``"" every time; through the loop. Instead of writing the loop like this, we strongly prefer; loops to be written so that they evaluate it once before the loop starts. A; convenient way to do this is like so:. .. code-block:: c++. BasicBlock *BB = ...; for (auto I = BB->begin(), E = BB->end(); I != E; ++I); ... use I ... The observant may quickly point out that these two loops may have different; semantics: if the container (a basic block in this case) is being mutated, then; ""``BB->end()``"" may change its value every time through the loop and the second; loop may not in fact be correct. If you actually do depend on this behavior,; please write the loop in the first form and add a comment indicating that you; did it intentionally. Why do we prefer the second form (when correct)? Writing the loop in the first; form has two problems. First it may be less efficient than evaluating it at the; start of the loop. In this case, the cost is probably minor --- a few extra; loads every time through the loop. However, if the base expression is more; complex, then the cost can rise quickly. I've seen loops where the end; expression was actually something like: ""``SomeMap[X]->end()``"" and map lookups; really aren't cheap. By writing it in the second form consistently, you; eliminate the issue entirely and don't even have to think about it. The second (even bigger) issue is that writing the loop in the first form hints; to the reader that the loop is mutating the container (a fact that a comment; would handily confirm!). If you write the loop in the second form, it is; immediately obvious without even looking at the body of the loop that the; container isn't being modified, which makes it easier to read the code and; understand what it does. While the second form of the loop is a few extra keystrokes, we do strongly; prefer it. ``#include <iostream>`` is Forbidden",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:53978,efficient,efficient,53978,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['efficient'],['efficient']
Energy Efficiency,"o a directory without any version (which would be; ``lib/aarch64-none-linux-android`` in our example). Clang will now look for; directories for lower versions and use the newest version it finds instead,; e.g. if you have ``lib/aarch64-none-linux-android21`` and; ``lib/aarch64-none-linux-android29``, ``-target aarch64-none-linux-android23``; will use the former and ``-target aarch64-none-linux-android30`` will use the; latter. Falling back to a versionless directory will now emit a warning, and; the fallback will be removed in Clang 19. Windows Support; ^^^^^^^^^^^^^^^; - Fixed an assertion failure that occurred due to a failure to propagate; ``MSInheritanceAttr`` attributes to class template instantiations created; for explicit template instantiation declarations. - The ``-fno-auto-import`` option was added for MinGW targets. The option both; affects code generation (inhibiting generating indirection via ``.refptr``; stubs for potentially auto imported symbols, generating smaller and more; efficient code) and linking (making the linker error out on such cases).; If the option only is used during code generation but not when linking,; linking may succeed but the resulting executables may expose issues at; runtime. - Clang now passes relevant LTO options to the linker (LLD) in MinGW mode. LoongArch Support; ^^^^^^^^^^^^^^^^^; - Added builtins support for all LSX (128-bits SIMD) and LASX (256-bits SIMD); instructions.; - Added builtins support for approximate calculation instructions that were; introduced in LoongArch Reference Manual V1.10.; - Made ``-mcmodel=`` compatible with LoongArch gcc that accepted ``normal``,; ``medium`` and ``extreme``.; - The ``model`` attribute was now supported for overriding the default code; model used to access global variables. The following values were supported:; ``normal``, ``medium`` and ``extreme``. *Example Code*:. .. code-block:: c. int var __attribute((model(""extreme"")));. - Default to ``-fno-direct-access-external-data`` for ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:63038,efficient,efficient,63038,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['efficient'],['efficient']
Energy Efficiency,"o different layouts. One is for a histogram,; which is not drawn from an ntuple. The other one is available for a; histogram, which is drawn from an ntuple. In this case, the rebin; algorithm can create a rebinned histogram from the original data i.e.; the ntuple. ![](pictures/03000045.png). To see the differences do:. ``` {.cpp}; TFile f(""hsimple.root"");; hpx->Draw(""BAR1""); // non ntuple histogram; ntuple->Draw(""px"");// ntuple histogram; ```. #### Non ntuple histogram. Rebin with a slider and the number of bins (shown in the field below; the slider). The number of bins can be changed to any number, which; divides the number of bins of the original histogram. A click on the; Apply button will delete the origin histogram and will replace it by; the rebinned one on the screen. A click on the Ignore button will; restore the origin histogram. #### Histogram drawn from an ntuple. ##### Rebin; \index{histogram!rebin}; with the slider, the number of bins can be enlarged by a factor; of 2, 3, 4, 5 (moving to the right) or reduced by a factor of; $\frac{1}{2}$, $\frac{1}{3}$, $\frac{1}{4}$, $\frac{1}{5}$. ##### BinOffset with a BinOffset slider; the origin of the histogram can be; changed within one binwidth. Using this slider the effect of binning; the data into bins can be made visible (statistical fluctuations). ##### Axis Range; with a double slider it is possible to zoom into the; specified axis range. It is also possible to set the upper and lower; limit in fields below the slider. ##### Delayed drawing; all the Binning sliders can set to delay draw mode.; Then the changes on the histogram are only updated, when the Slider is; released. This should be activated if the redrawing of the histogram; is time consuming. ### TH2Editor. ![](pictures/03000047.png). #### Style Tab:. ##### Title; set the title of the histogram. ##### Histogram; change the draw options of the histogram. ##### Plot; draw a 2D or 3D plot of the histogram; according to the dimension,; the drawing pos",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md:73813,reduce,reduced,73813,documentation/users-guide/Histograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md,1,['reduce'],['reduced']
Energy Efficiency,"o do this can; only start such queries from itself. Using alias analysis results; ============================. There are several different ways to use alias analysis results. In order of; preference, these are:. Using the ``MemoryDependenceAnalysis`` Pass; -------------------------------------------. The ``memdep`` pass uses alias analysis to provide high-level dependence; information about memory-using instructions. This will tell you which store; feeds into a load, for example. It uses caching and other techniques to be; efficient, and is used by Dead Store Elimination, GVN, and memcpy optimizations. .. _AliasSetTracker:. Using the ``AliasSetTracker`` class; -----------------------------------. Many transformations need information about alias **sets** that are active in; some scope, rather than information about pairwise aliasing. The; `AliasSetTracker <https://llvm.org/doxygen/classllvm_1_1AliasSetTracker.html>`__; class is used to efficiently build these Alias Sets from the pairwise alias; analysis information provided by the ``AliasAnalysis`` interface. First you initialize the AliasSetTracker by using the ""``add``"" methods to add; information about various potentially aliasing instructions in the scope you are; interested in. Once all of the alias sets are completed, your pass should; simply iterate through the constructed alias sets, using the ``AliasSetTracker``; ``begin()``/``end()`` methods. The ``AliasSet``\s formed by the ``AliasSetTracker`` are guaranteed to be; disjoint, calculate mod/ref information and volatility for the set, and keep; track of whether or not all of the pointers in the set are Must aliases. The; AliasSetTracker also makes sure that sets are properly folded due to call; instructions, and can provide a list of pointers in each set. As an example user of this, the `Loop Invariant Code Motion; <doxygen/structLICM.html>`_ pass uses ``AliasSetTracker``\s to calculate alias; sets for each loop nest. If an ``AliasSet`` in a loop is not mod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:20157,efficient,efficiently,20157,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['efficient'],['efficiently']
Energy Efficiency,"o generate instructions that are valid on i486 and later processors,; but which may not exist on earlier ones. Code Generation Options; ~~~~~~~~~~~~~~~~~~~~~~~. .. option:: -O0, -O1, -O2, -O3, -Ofast, -Os, -Oz, -Og, -O, -O4. Specify which optimization level to use:. :option:`-O0` Means ""no optimization"": this level compiles the fastest and; generates the most debuggable code. :option:`-O1` Somewhere between :option:`-O0` and :option:`-O2`. :option:`-O2` Moderate level of optimization which enables most; optimizations. :option:`-O3` Like :option:`-O2`, except that it enables optimizations that; take longer to perform or that may generate larger code (in an attempt to; make the program run faster). :option:`-Ofast` Enables all the optimizations from :option:`-O3` along; with other aggressive optimizations that may violate strict compliance with; language standards. :option:`-Os` Like :option:`-O2` with extra optimizations to reduce code; size. :option:`-Oz` Like :option:`-Os` (and thus :option:`-O2`), but reduces code; size further. :option:`-Og` Like :option:`-O1`. In future versions, this option might; disable different optimizations in order to improve debuggability. :option:`-O` Equivalent to :option:`-O1`. :option:`-O4` and higher. Currently equivalent to :option:`-O3`. .. option:: -g, -gline-tables-only, -gmodules. Control debug information output. Note that Clang debug information works; best at :option:`-O0`. When more than one option starting with `-g` is; specified, the last one wins:. :option:`-g` Generate debug information. :option:`-gline-tables-only` Generate only line table debug information. This; allows for symbolicated backtraces with inlining information, but does not; include any information about variables, their locations or types. :option:`-gmodules` Generate debug information that contains external; references to types defined in Clang modules or precompiled headers instead; of emitting redundant debug type information into every object file. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:11262,reduce,reduces,11262,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['reduce'],['reduces']
Energy Efficiency,"o in your register allocator ``.cpp`` file, define a creator function in the; form:. .. code-block:: c++. FunctionPass *createMyRegisterAllocator() {; return new MyRegisterAllocator();; }. Note that the signature of this function should match the type of; ``RegisterRegAlloc::FunctionPassCtor``. In the same file add the ""installing""; declaration, in the form:. .. code-block:: c++. static RegisterRegAlloc myRegAlloc(""myregalloc"",; ""my register allocator help string"",; createMyRegisterAllocator);. Note the two spaces prior to the help string produces a tidy result on the; :option:`-help` query. .. code-block:: console. $ llc -help; ...; -regalloc - Register allocator to use (default=linearscan); =linearscan - linear scan register allocator; =local - local register allocator; =simple - simple register allocator; =myregalloc - my register allocator help string; ... And that's it. The user is now free to use ``-regalloc=myregalloc`` as an; option. Registering instruction schedulers is similar except use the; ``RegisterScheduler`` class. Note that the; ``RegisterScheduler::FunctionPassCtor`` is significantly different from; ``RegisterRegAlloc::FunctionPassCtor``. To force the load/linking of your register allocator into the; :program:`llc`/:program:`lli` tools, add your creator function's global; declaration to ``Passes.h`` and add a ""pseudo"" call line to; ``llvm/Codegen/LinkAllCodegenComponents.h``. Creating new registries; -----------------------. The easiest way to get started is to clone one of the existing registries; we; recommend ``llvm/CodeGen/RegAllocRegistry.h``. The key things to modify are; the class name and the ``FunctionPassCtor`` type. Then you need to declare the registry. Example: if your pass registry is; ``RegisterMyPasses`` then define:. .. code-block:: c++. MachinePassRegistry<RegisterMyPasses::FunctionPassCtor> RegisterMyPasses::Registry;. And finally, declare the command line option for your passes. Example:. .. code-block:: c++. cl::opt<RegisterMyPa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:50710,schedul,schedulers,50710,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['schedul'],['schedulers']
Energy Efficiency,"o not insert macro definition of `__ROOTCLING__` into the pch. ### Interpreter Library. * llvm / clang have been updated to r274612.; * The GCC5 ABI is now supported [ROOT-7947].; * Exceptions are now caught in the interactive ROOT session, instead of terminating ROOT.; * A ValuePrinter for tuple and pair has been added to visualise the content of these entities at the prompt.; * When interpreting dereferences of invalid pointers, cling will now complain (throw, actually) instead of crash.; * Resolve memory hoarding in some case of looking up functions [ROOT-8145]. ## Parallelism. * Three methods have been added to manage implicit multi-threading in ROOT: `ROOT::EnableImplicitMT(numthreads)`, `ROOT::DisableImplicitMT` and `ROOT::IsImplicitMTEnabled`. They can be used to enable, disable and check the status of the global implicit multi-threading in ROOT, respectively.; * Even if the default reduce function specified in the invocation of the `MapReduce` method of `TProcessExecutor` returns a pointer to a `TObject`, the return value of `MapReduce` is properly casted to the type returned by the map function.; * Add a new class named `TThreadExecutor` implementing a MapReduce framework sharing `TProcessExecutor` interface and based in tbb.; * Add a new class named `TExecutor` defining the MapReduce interface for `TProcessExecutor` and `TThreadExecutor`, who inherit from it.; * Remove all `TPool` signatures accepting collections as an argument with the exception of std::vector and initializer_lists. ; * Extend `TThreadExecutor` functionality offering parallel reduction given a binary operator as a reduction function.; * Add a new class named `TThreadedObject` which helps making objects thread private and merging them.; * Add tutorials showing how to fill randomly histograms using the `TProcessExecutor` and `TThreadExecutor` classes.; * Add tutorial showing how to fill randomly histograms from multiple threads.; * Add the `ROOT::TSpinMutex` class, a spin mutex compliant wi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:5953,reduce,reduce,5953,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['reduce'],['reduce']
Energy Efficiency,"o provide space to save the frame; pointer in the PowerPC linkage area of the caller frame. Other details of; PowerPC ABI can be found at `PowerPC ABI; <http://developer.apple.com/documentation/DeveloperTools/Conceptual/LowLevelABI/Articles/32bitPowerPC.html>`_\; . Note: This link describes the 32 bit ABI. The 64 bit ABI is similar except; space for GPRs are 8 bytes wide (not 4) and r13 is reserved for system use. Frame Layout; ^^^^^^^^^^^^. The size of a PowerPC frame is usually fixed for the duration of a function's; invocation. Since the frame is fixed size, all references into the frame can be; accessed via fixed offsets from the stack pointer. The exception to this is; when dynamic alloca or variable sized arrays are present, then a base pointer; (r31) is used as a proxy for the stack pointer and stack pointer is free to grow; or shrink. A base pointer is also used if llvm-gcc is not passed the; -fomit-frame-pointer flag. The stack pointer is always aligned to 16 bytes, so; that space allocated for altivec vectors will be properly aligned. An invocation frame is laid out as follows (low memory at top):. :raw-html:`<table border=""1"" cellspacing=""0"">`; :raw-html:`<tr>`; :raw-html:`<td>Linkage<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Parameter area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Dynamic area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Locals area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Saved registers area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr style=""border-style: none hidden none hidden;"">`; :raw-html:`<td><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Previous Frame<br><br></td>`; :raw-html:`</tr>`; :raw-html:`</table>`. The *linkage* area is used by a callee to save special registers prior to; allocating its own frame. Only three entries are relevant to LLVM. The first; entry is the previous stack pointer (sp), aka link. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:95749,allocate,allocated,95749,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['allocate'],['allocated']
Energy Efficiency,"o:. define i32 @foo(i8 zeroext %i) nounwind readnone ssp noredzone {; entry:; %conv = zext i8 %i to i32; %shl = shl i32 %conv, 8; %shl5 = shl i32 %conv, 16; %shl9 = shl i32 %conv, 24; %or = or i32 %shl9, %conv; %or6 = or i32 %or, %shl5; %or10 = or i32 %or6, %shl; ret i32 %or10; }. it would be better as:. unsigned int bar(unsigned char i) {; unsigned int j=i | (i << 8); ; return j | (j<<16);; }. aka:. define i32 @bar(i8 zeroext %i) nounwind readnone ssp noredzone {; entry:; %conv = zext i8 %i to i32; %shl = shl i32 %conv, 8; %or = or i32 %shl, %conv; %shl5 = shl i32 %or, 16; %or6 = or i32 %shl5, %or; ret i32 %or6; }. or even i*0x01010101, depending on the speed of the multiplier. The best way to; handle this is to canonicalize it to a multiply in IR and have codegen handle; lowering multiplies to shifts on cpus where shifts are faster. //===---------------------------------------------------------------------===//. We do a number of simplifications in simplify libcalls to strength reduce; standard library functions, but we don't currently merge them together. For; example, it is useful to merge memcpy(a,b,strlen(b)) -> strcpy. This can only; be done safely if ""b"" isn't modified between the strlen and memcpy of course. //===---------------------------------------------------------------------===//. We compile this program: (from GCC PR11680); http://gcc.gnu.org/bugzilla/attachment.cgi?id=4487. Into code that runs the same speed in fast/slow modes, but both modes run 2x; slower than when compile with GCC (either 4.0 or 4.2):. $ llvm-g++ perf.cpp -O3 -fno-exceptions; $ time ./a.out fast; 1.821u 0.003s 0:01.82 100.0%	0+0k 0+0io 0pf+0w. $ g++ perf.cpp -O3 -fno-exceptions; $ time ./a.out fast; 0.821u 0.001s 0:00.82 100.0%	0+0k 0+0io 0pf+0w. It looks like we are making the same inlining decisions, so this may be raw; codegen badness or something else (haven't investigated). //===---------------------------------------------------------------------===//. Divisibility by const",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:18510,reduce,reduce,18510,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['reduce'],['reduce']
Energy Efficiency,"o; be present in the ``PATH`` environment variable. Clang uses ``llvm-spirv``; with `the widely adopted assembly syntax package; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator/#build-with-spirv-tools>`_. `The versioning; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator/releases>`_ of; ``llvm-spirv`` is aligned with Clang major releases. The same applies to the; main development branch. It is therefore important to ensure the ``llvm-spirv``; version is in alignment with the Clang version. For troubleshooting purposes; ``llvm-spirv`` can be `tested in isolation; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator#test-instructions>`_. Example usage for OpenCL kernel compilation:. .. code-block:: console. $ clang --target=spirv32 -c test.cl; $ clang --target=spirv64 -c test.cl. Both invocations of Clang will result in the generation of a SPIR-V binary file; `test.o` for 32 bit and 64 bit respectively. This file can be imported; by an OpenCL driver that support SPIR-V consumption or it can be compiled; further by offline SPIR-V consumer tools. Converting to SPIR-V produced with the optimization levels other than `-O0` is; currently available as an experimental feature and it is not guaranteed to work; in all cases. Clang also supports integrated generation of SPIR-V without use of ``llvm-spirv``; tool as an experimental feature when ``-fintegrated-objemitter`` flag is passed in; the command line. .. code-block:: console. $ clang --target=spirv32 -fintegrated-objemitter -c test.cl. Note that only very basic functionality is supported at this point and therefore; it is not suitable for arbitrary use cases. This feature is only enabled when clang; build is configured with ``-DLLVM_EXPERIMENTAL_TARGETS_TO_BUILD=SPIRV`` option. Linking is done using ``spirv-link`` from `the SPIRV-Tools project; <https://github.com/KhronosGroup/SPIRV-Tools#linker>`_. Similar to other external; linkers, Clang will expect ``spirv-link`` to be installed separately and to be; pre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:166949,consumption,consumption,166949,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['consumption'],['consumption']
Energy Efficiency,"o; enable the function to be lazily compiled but still called directly after; compilation). .. code-block:: c++. StringRef FunctionName = ""foo"";; std::vector<ExecutorAddr> CallSitesForFunction;. auto RecordCallSites =; [&](LinkGraph &G) -> Error {; for (auto *B : G.blocks()); for (auto &E : B.edges()); if (E.getKind() == CallEdgeKind &&; E.getTarget().hasName() &&; E.getTraget().getName() == FunctionName); CallSitesForFunction.push_back(B.getFixupAddress(E));; return Error::success();; };. Memory Management with JITLinkMemoryManager; -------------------------------------------. JIT linking requires allocation of two kinds of memory: working memory in the; JIT process and target memory in the execution process (these processes and; memory allocations may be one and the same, depending on how the user wants; to build their JIT). It also requires that these allocations conform to the; requested code model in the target process (e.g. MachO/x86-64's Small code; model requires that all code and data for a simulated dylib is allocated within; 4Gb). Finally, it is natural to make the memory manager responsible for; transferring memory to the target address space and applying memory protections,; since the memory manager must know how to communicate with the executor, and; since sharing and protection assignment can often be efficiently managed (in; the common case of running across processes on the same machine for security); via the host operating system's virtual memory management APIs. To satisfy these requirements ``JITLinkMemoryManager`` adopts the following; design: The memory manager itself has just two virtual methods for asynchronous; operations (each with convenience overloads for calling synchronously):. .. code-block:: c++. /// Called when allocation has been completed.; using OnAllocatedFunction =; unique_function<void(Expected<std::unique_ptr<InFlightAlloc>)>;. /// Called when deallocation has completed.; using OnDeallocatedFunction = unique_function<void(Erro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:26078,allocate,allocated,26078,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocated']
Energy Efficiency,"o; quickly test clang on their projects. Flexible; --------. The driver was designed to be flexible and easily accommodate new uses; as we grow the clang and LLVM infrastructure. As one example, the driver; can easily support the introduction of tools which have an integrated; assembler; something we hope to add to LLVM in the future. Similarly, most of the driver functionality is kept in a library which; can be used to build other tools which want to implement or accept a gcc; like interface. Low Overhead; ------------. The driver should have as little overhead as possible. In practice, we; found that the gcc driver by itself incurred a small but meaningful; overhead when compiling many small files. The driver doesn't do much; work compared to a compilation, but we have tried to keep it as; efficient as possible by following a few simple principles:. - Avoid memory allocation and string copying when possible.; - Don't parse arguments more than once.; - Provide a few simple interfaces for efficiently searching arguments. Simple; ------. Finally, the driver was designed to be ""as simple as possible"", given; the other goals. Notably, trying to be completely compatible with the; gcc driver adds a significant amount of complexity. However, the design; of the driver attempts to mitigate this complexity by dividing the; process into a number of independent stages instead of a single; monolithic task. Internal Design and Implementation; ==================================. .. contents::; :local:; :depth: 1. Internals Introduction; ----------------------. In order to satisfy the stated goals, the driver was designed to; completely subsume the functionality of the gcc executable; that is, the; driver should not need to delegate to gcc to perform subtasks. On; Darwin, this implies that the Clang driver also subsumes the gcc; driver-driver, which is used to implement support for building universal; images (binaries and object files). This also implies that the driver; should be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:2134,efficient,efficiently,2134,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['efficient'],['efficiently']
Energy Efficiency,"oArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsReal::createProfile() rather; than constructing a RooProfileLL object directly as the former will efficiently; recast a profile of a profile into a single profile object. Multivariate Gaussian modeling of parameters estimates from a fit; You can now construct a multivariate Gaussian p.d.f on the parameters of a model that; represents the result of a fit, from any RooFitResult object. RooAbsPdf* paramPdf = fitresult->createHessePdf(RooArgSet(a,b)) ;. The returned object is an instance of the newly added class RooMultiVarGaussian, that can; model correlated Gaussian distributions in an arbitrary number of dimensions, given a; vector of mean values and a covariance matrix. Class RooMultivarGaussian implements analytical; integration as well as analytical partial integrals over the first 31 dimensions (if you have; that many) and implements in effect internal generation strategy for its observables. A new tutorial macro rf608_fitresultaspdf.C has been added to illustrate the use MV Gaussians constructed from a RooFitResult; Improved functionality",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:9999,efficient,efficiently,9999,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,['efficient'],['efficiently']
Energy Efficiency,"oStats::HistFactory::Measurement` object is now switched on by default, and the associated getter and setter functions are deprecated. They will be removed in ROOT 6.36. If you want to fit the model as well instead of just exporting it to a RooWorkspace, please do so with your own code as demonstrated in the `hf001` tutorial. ### Deprecations. * The `RooStats::MarkovChain::GetAsDataSet` and `RooStats::MarkovChain::GetAsDataHist` functions are deprecated and will be removed in ROOT 6.36. The same functionality can be implemented by calling `RooAbsData::reduce` on the Markov Chain's `RooDataSet*` (obtained using `MarkovChain::GetAsConstDataSet`) and then obtaining its binned clone(for `RooDataHist`). An example in Python would be:. ```py; mcInt = mc.GetInterval() # Obtain the MCMCInterval from a configured MCMCCalculator; mkc = mcInt.GetChain() # Obtain the MarkovChain; mkcData = mkc.GetAsConstDataSet(); mcIntParams = mcInt.GetParameters(). chainDataset = mkcData.reduce(SelectVars=mcIntParams, EventRange=(mcInt.GetNumBurnInSteps(), mkc.Size())); chainDataHist = chainDataset.binnedClone(); ```. * The following methods related to the RooAbsArg interface are deprecated and will be removed in ROOT 6.36.; They should be replaced with the suitable alternatives interfaces:. - `RooAbsArg::getDependents()`: use `getObservables()`; - `RooAbsArg::dependentOverlaps()`: use `observableOverlaps()`; - `RooAbsArg::checkDependents()`: use `checkObservables()`; - `RooAbsArg::recursiveCheckDependents()`: use `recursiveCheckObservables()`. ## Graphics Backends. ## 2D Graphics Libraries. ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## PyROOT. ### Typesafe `TTree::SetBranchAddress()` for array inputs. If you call `TTree::SetBranchAddress` with NumPy array or `array.array` inputs, ROOT will now check if the array type matches with the column type.; If it doesn't, `SetBranchAddre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md:6159,reduce,reduce,6159,README/ReleaseNotes/v634/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md,1,['reduce'],['reduce']
Energy Efficiency,"oat>* S1; // #2: implicit loading of libA. No full descriptor required.; root [] if (gFile) S1->doIt(); // #3: implicit loading of libA. Full descriptor required.; root [] gSystem->Load(""libA""); // #4: explicit loading of libA. No full descriptor required.; root [] do(); // #5: error: implicit loading of libA is currently unsupported. ```. This pattern is not only used in the ROOT prompt but in I/O hotspots such as; `ShowMembers` and `TClass::IsA`. A naive implementation of this feature would require inclusion of all reachable; library descriptors (aka header files) at ROOT startup time. Of course this is; not feasible and ROOT inserts a set of optimizations to fence itself from the; costly full header inclusion. Unfortunately, several of them are home-grown and; in a few cases inaccurate (eg line #5) causing a noticeable technical debt. Here we will briefly describe the three common layers of optimizations: ROOT PCH,; ROOTMAP and RDICT. The ROOT precompiled header (PCH) reduces the CPU and memory cost for ROOT's; most used libraries. The precompiled header technology is well-understood since; decades [[4]]. It is an efficient on-disk representation of the state of the; compiler after parsing a set of headers. It can be loaded before starting the; next instance to avoid doing redundant work. At build time, rootcling (ROOT's; dictionary generator) creates such PCH file which is attached at ROOT startup; time. Its major drawback is the fact that if third-party users want to include; their libraries, they have to recompile it every time there is a change. RDICT files store some useful information (in particular about class offsets) in; ROOT files to avoid the potentially expensive call to the interpreter if the; information is not the PCH. For example, ROOT's libGeom and other third-party; code. This is done to circumvent the costly call to `ShowMembers` which will; require parsing. ROOTMAP files reduce parsing for code which is not in the PCH. Consider; `foo::bar` and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:5902,reduce,reduces,5902,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['reduce'],['reduces']
Energy Efficiency,obalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/func-id-helper.cpp; llvm/tools/llvm-xray/func-id-helper.h; llvm/tools/llvm-xray/llvm-xray.cpp; llvm/too,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338835,reduce,reduce,338835,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"object-metadata-v3`,; :ref:`amdgpu-amdhsa-code-object-metadata-v4` and; :ref:`amdgpu-amdhsa-code-object-metadata-v5` for the map keys defined for the; ``amdhsa`` OS. .. _amdgpu-symbols:. Symbols; -------. Symbols include the following:. .. table:: AMDGPU ELF Symbols; :name: amdgpu-elf-symbols-table. ===================== ================== ================ ==================; Name Type Section Description; ===================== ================== ================ ==================; *link-name* ``STT_OBJECT`` - ``.data`` Global variable; - ``.rodata``; - ``.bss``; *link-name*\ ``.kd`` ``STT_OBJECT`` - ``.rodata`` Kernel descriptor; *link-name* ``STT_FUNC`` - ``.text`` Kernel entry point; *link-name* ``STT_OBJECT`` - SHN_AMDGPU_LDS Global variable in LDS; ===================== ================== ================ ==================. Global variable; Global variables both used and defined by the compilation unit. If the symbol is defined in the compilation unit then it is allocated in the; appropriate section according to if it has initialized data or is readonly. If the symbol is external then its section is ``STN_UNDEF`` and the loader; will resolve relocations using the definition provided by another code object; or explicitly defined by the runtime. If the symbol resides in local/group memory (LDS) then its section is the; special processor specific section name ``SHN_AMDGPU_LDS``, and the; ``st_value`` field describes alignment requirements as it does for common; symbols. .. TODO::. Add description of linked shared object symbols. Seems undefined symbols; are marked as STT_NOTYPE. Kernel descriptor; Every HSA kernel has an associated kernel descriptor. It is the address of the; kernel descriptor that is used in the AQL dispatch packet used to invoke the; kernel, not the kernel entry point. The layout of the HSA kernel descriptor is; defined in :ref:`amdgpu-amdhsa-kernel-descriptor`. Kernel entry point; Every HSA kernel also has a symbol for its machine code entry ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:78304,allocate,allocated,78304,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"objects that are all of the same type. The format of a TClonesArray object; is given in \ref tclonesarray. There are two great advantages in the use of TClonesArray over TObjArray when the objects; all will be of the same class:. 1. Memory for the objects will be allocated only once for the entire array, rather; than the per-object allocation for TObjArray. This can be done because all the; objects are the same size.; 2. In the case of TObjArray, the stored objects are written sequentially. However,; in a TClonesArray, by default, each object is split one level deep into its base; class(es) and data members, and each of these members is written sequentially for; all objects in the array before the next member is written. This has two advantages:; 1. Greater compression can be achieved when similar data is consecutive.; 2. The object's data members can easily be split into different TTree branches; (TTrees are discussed below). ### TTree. A TTree is a highly specialized container class for efficient storage and retrieval of user data.; The use of TTrees is discussed in detail in the; [Trees chapter of the Root Manual](https://root.cern/manual/trees/). Here we discuss in particular how a TTree is stored in a ROOTIO file. A TTree object is split into one or more branches (class TBranch), each of which may have its own; (sub)branches, recursively to any depth. Each TBranch contains an array of zero or more leaves; (class TLeaf), each corresponding to a basic variable type or a class object that has not been split.; The TLeaf object does not actually contain variable values, only information about the variables.; The actual data on each branch is physically stored in basket objects (class TBasket). The user; can set the basket size on a per TBranch basis. The default basket size is 32000 bytes.; This should be viewed as an approximate number. There is one TTree data record per file for each tree in the file, corresponding to a TTree; class object. The TTree class object ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:13399,efficient,efficient,13399,io/doc/TFile/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md,1,['efficient'],['efficient']
Energy Efficiency,"oc() "", shape=""box""];; noaloc [label="" SetValueNoAlloc() "", shape=""box""];; right [label="" 1. RValue Structure \n (a temporary value)"", shape=""box""];; left2 [label="" 2. LValue Structure \n (a variable with \n an address)"", shape=""box""];; left3 [label="" 3. Built-In Type \n (int, float, etc.)"", shape=""box""];; output [label="" move to 'Assign' step "", shape=""box""];. synth -> mem;; mem -> withaloc [label=""Yes""];; mem -> noaloc [label=""No""];; withaloc -> right;; noaloc -> left2;; noaloc -> left3;; right -> output;; left2 -> output;; left3 -> output;; }; output -> assign; }. Where is the captured result stored?; ------------------------------------. ``LastValue`` holds the last result of the value printing. It is a class member; because it can be accessed even after subsequent inputs. **Note:** If no value printing happens, then it is in an invalid state. Improving Efficiency and User Experience; ----------------------------------------. The Value object is essentially used to create a mapping between an expression; 'type' and the allocated 'memory'. Built-in types (bool, char, int,; float, double, etc.) are copyable. Their memory allocation size is known; and the Value object can introduce a small-buffer optimization.; In case of objects, the ``Value`` class provides reference-counted memory; management. The implementation maps the type as written and the Clang Type to be able to use; the preprocessor to synthesize the relevant cast operations. For example,; ``X(char, Char_S)``, where ``char`` is the type from the language's type system; and ``Char_S`` is the Clang builtin type which represents it. This mapping helps; to import execution results from the interpreter in a compiled program and vice; versa. The ``Value.h`` header file can be included at runtime and this is why it; has a very low token count and was developed with strict constraints in mind. This also enables the user to receive the computed 'type' back in their code; and then transform the type into something ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangRepl.rst:8873,allocate,allocated,8873,interpreter/llvm-project/clang/docs/ClangRepl.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangRepl.rst,1,['allocate'],['allocated']
Energy Efficiency,"ocks. The copy operation ``Block_copy()`` is styled as a function that takes; an arbitrary Block reference and returns a Block reference of the same; type. The release operation, ``Block_release()``, is styled as a; function that takes an arbitrary Block reference and, if dynamically; matched to a Block copy operation, allows recovery of the referenced; allocated memory. The ``__block`` Storage Qualifier; =================================. In addition to the new Block type we also introduce a new storage; qualifier, :block-term:`__block`, for local variables. [testme: a; __block declaration within a block literal] The ``__block`` storage; qualifier is mutually exclusive to the existing local storage; qualifiers auto, register, and static. [testme] Variables qualified by; ``__block`` act as if they were in allocated storage and this storage; is automatically recovered after last use of said variable. An; implementation may choose an optimization where the storage is; initially automatic and only ""moved"" to allocated (heap) storage upon; a Block_copy of a referencing Block. Such variables may be mutated as; normal variables are. In the case where a ``__block`` variable is a Block one must assume; that the ``__block`` variable resides in allocated storage and as such; is assumed to reference a Block that is also in allocated storage; (that it is the result of a ``Block_copy`` operation). Despite this; there is no provision to do a ``Block_copy`` or a ``Block_release`` if; an implementation provides initial automatic storage for Blocks. This; is due to the inherent race condition of potentially several threads; trying to update the shared variable and the need for synchronization; around disposing of older values and copying new ones. Such; synchronization is beyond the scope of this language specification. Control Flow; ============. The compound statement of a Block is treated much like a function body; with respect to control flow in that goto, break, and continue do",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:7499,allocate,allocated,7499,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['allocate'],['allocated']
Energy Efficiency,"of Python2 from the ROOT codebase in preparation for 6.32/00; * [[#13851](https://github.com/root-project/root/issues/13851)] - Test crash with GCC 13 and C++20; * [[#13834](https://github.com/root-project/root/issues/13834)] - Can't open TBrowser locally after upgrading macos â€œApple M2 14.0 (23A344)â€; * [[#13825](https://github.com/root-project/root/issues/13825)] - builtin libpng too old; * [[#13815](https://github.com/root-project/root/issues/13815)] - Cling (rightfully) confused about forward-declared template specializations; * [[#13697](https://github.com/root-project/root/issues/13697)] - Unexpected behaviour of KSTest with toys (""X"" option) for identical histograms; * [[#13659](https://github.com/root-project/root/issues/13659)] - rootprint/rootls missing recursive traversal; * [[#13623](https://github.com/root-project/root/issues/13623)] - Add directory wildcarding in TChain; * [[#13531](https://github.com/root-project/root/issues/13531)] - Huge RAM consumption of the hadd command for input files with several directories ; * [[#13511](https://github.com/root-project/root/issues/13511)] - TMapFile can't work ; * [[#13497](https://github.com/root-project/root/issues/13497)] - Assertion failure in TMVA with `vector iterators incompatible` error on Windows; * [[#13441](https://github.com/root-project/root/issues/13441)] - error in root-generated code for cubic spline (TSpline3); * [[#13421](https://github.com/root-project/root/issues/13421)] - [MSVC] ROOT builds under msvc option /permissive- with error C4576; * [[#13359](https://github.com/root-project/root/issues/13359)] - Bug in TFileMerger class for a single input file and a selective list of objects to be merged in output file; * [[#13288](https://github.com/root-project/root/issues/13288)] - [cling] long double type incorrectly parsed by interpreter; * [[#13155](https://github.com/root-project/root/issues/13155)] - TMVA doesn't compile with pytorch 2.0.1; * [[#13130](https://github.com/root-project/root/i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:38217,consumption,consumption,38217,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['consumption'],['consumption']
Energy Efficiency,"of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create the TDF with MakeCsvDataFrame(""f.csv""). The data types of the CSV columns are automatically inferred. You can also specify if you want to use a different delimiter or if your file does not have headers.; - Users can now configure Snapshot to use different file open modes (""RECREATE"" or ""UPDATE""), compression level, compression algorithm, TTree split-level and autoflush settings; - Users can now access multi-threading slot and entry number as pre-defined columns ""tdfslot_"" and ""tdfentry_"". Especially useful for pyROOT users.; - Users can now specify filters and definitions as strings containing multiple C++ expressions, e.g. ""static int a = 0; return ++a"". Especially useful for pyROOT users.; - Histograms can be initialised by *models*, which allow to create ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:12845,adapt,adaptor,12845,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['adapt'],['adaptor']
Energy Efficiency,"of the 900; instructions processed, there were 900 mappings created. Since this dot-product; example utilized only floating point registers, the JFPuPRF was responsible for; creating the 900 mappings. However, we see that the pipeline only used a; maximum of 35 of 72 available register slots at any given time. We can conclude; that the floating point PRF was the only register file used for the example, and; that it was never resource constrained. The register file statistics are; displayed by using the command option ``-all-stats`` or; ``-register-file-stats``. In this example, we can conclude that the IPC is mostly limited by data; dependencies, and not by resource pressure. Instruction Flow; ^^^^^^^^^^^^^^^^; This section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34138,schedul,schedulers,34138,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['schedulers']
Energy Efficiency,"of those files will be; loaded along with this AST file. For chained precompiled headers, the language options, target architecture and; predefines buffer data is taken from the end of the chain, since they have to; match anyway. .. _pchinternals-sourcemgr:. Source Manager Block; ^^^^^^^^^^^^^^^^^^^^. The source manager block contains the serialized representation of Clang's; :ref:`SourceManager <SourceManager>` class, which handles the mapping from; source locations (as represented in Clang's abstract syntax tree) into actual; column/line positions within a source file or macro instantiation. The AST; file's representation of the source manager also includes information about all; of the headers that were (transitively) included when building the AST file. The bulk of the source manager block is dedicated to information about the; various files, buffers, and macro instantiations into which a source location; can refer. Each of these is referenced by a numeric ""file ID"", which is a; unique number (allocated starting at 1) stored in the source location. Clang; serializes the information for each kind of file ID, along with an index that; maps file IDs to the position within the AST file where the information about; that file ID is stored. The data associated with a file ID is loaded only when; required by the front end, e.g., to emit a diagnostic that includes a macro; instantiation history inside the header itself. The source manager block also contains information about all of the headers; that were included when building the AST file. This includes information about; the controlling macro for the header (e.g., when the preprocessor identified; that the contents of the header dependent on a macro like; ``LLVM_CLANG_SOURCEMANAGER_H``). .. _pchinternals-preprocessor:. Preprocessor Block; ^^^^^^^^^^^^^^^^^^. The preprocessor block contains the serialized representation of the; preprocessor. Specifically, it contains all of the macros that have been; defined by the end ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:10433,allocate,allocated,10433,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['allocate'],['allocated']
Energy Efficiency,"oint operations may flush `denormal; <https://en.wikipedia.org/wiki/Denormal_number>`_ inputs and/or outputs to 0.; Operations on denormal numbers are often much slower than the same operations; on normal numbers. * ``-fcuda-approx-transcendentals`` (default: off) When this is enabled, the; compiler may emit calls to faster, approximate versions of transcendental; functions, instead of using the slower, fully IEEE-compliant versions. For; example, this flag allows clang to emit the ptx ``sin.approx.f32``; instruction. This is implied by ``-ffast-math``. Standard library support; ========================. In clang and nvcc, most of the C++ standard library is not supported on the; device side. ``<math.h>`` and ``<cmath>``; ----------------------------. In clang, ``math.h`` and ``cmath`` are available and `pass; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/math_h.cu>`_; `tests; <https://github.com/llvm/llvm-test-suite/blob/main/External/CUDA/cmath.cu>`_; adapted from libc++'s test suite. In nvcc ``math.h`` and ``cmath`` are mostly available. Versions of ``::foof``; in namespace std (e.g. ``std::sinf``) are not available, and where the standard; calls for overloads that take integral arguments, these are usually not; available. .. code-block:: c++. #include <math.h>; #include <cmath.h>. // clang is OK with everything in this function.; __device__ void test() {; std::sin(0.); // nvcc - ok; std::sin(0); // nvcc - error, because no std::sin(int) override is available.; sin(0); // nvcc - same as above. sinf(0.); // nvcc - ok; std::sinf(0.); // nvcc - no such function; }. ``<std::complex>``; ------------------. nvcc does not officially support ``std::complex``. It's an error to use; ``std::complex`` in ``__device__`` code, but it often works in ``__host__; __device__`` code due to nvcc's interpretation of the ""wrong-side rule"" (see; below). However, we have heard from implementers that it's possible to get; into situations where nvcc will omit a call to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:6001,adapt,adapted,6001,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,1,['adapt'],['adapted']
Energy Efficiency,"oint point based on rho,z,phi coordinates (cylindrical using z); * ROOT::Math::RhoEtaPhiPoint point based on rho,eta,phi coordinates (cylindrical using eta instead of z). ### Vector3D. Type definitions for vectors in three dimensions, based on ROOT::Math::DisplacementVector3D, are defined by `Math/Vector3D.h`:. * ROOT::Math::XYZVector vector based on x,y,z coordinates (cartesian); * ROOT::Math::Polar3DVector vector based on r,theta,phi coordinates (polar); * ROOT::Math::RhoZPhiVector vector based on rho, z,phi coordinates (cylindrical); * ROOT::Math::RhoEtaPhiVector vector based on rho,eta,phi coordinates (cylindrical using eta instead of z). ### LorentzVector. Type definitions for Lorentz vectors in four dimensions, based on ROOT::Math::LorentzVector, are defined by `Math/Vector4D.h`:. * ROOT::Math::XYZTVector vector based on x,y,z,t coordinates (cartesian); * ROOT::Math::PtEtaPhiEVector vector based on pt (rho),eta,phi and E (t) coordinates; * ROOT::Math::PtEtaPhiMVector vector based on pt (rho),eta,phi and M (t) coordinates; * ROOT::Math::PxPyPzMVector vector based on px,py,pz and M (mass) coordinates; * ROOT::Math::PxPyPzEVector vector based on px,py,pz and E (energy) coordinates. The metric used for any such LorentzVector is (-,-,-,+). \anchor GenVectorOperations; ## Operations. ### Constructors and Assignment. A vector can be constructed from its coordinate representation:. ~~~{.cpp}; ROOT::Math::PtEtaPhiMVector v1(10. /*pt*/, 0.1 /*eta*/, 0.24 /*phi*/, 5 /*M*/);; ~~~. In addition, the vector classes can be constructed from any object that implements the; accessors x(), y() and z(). This can be a vector using a different coordinate; system, or even an object from a different package as long as it implements the required signatures.; One such vector type is CLHEP's `Hep3Vector`:. ~~~{.cpp}; XYZVector v1(1,2,3);; RhoEtaPhiVector r2(v1);; CLHEP::Hep3Vector q(1,2,3);; XYZVector v3(q); ~~~. ### Arithmetic Operations. The following operations are possible between ve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:6048,energy,energy,6048,math/genvector/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md,1,['energy'],['energy']
Energy Efficiency,"ointerSub (C); """"""""""""""""""""""""""""""""""""""""""""""""""; Check for pointer subtractions on two pointers pointing to different memory chunks. .. code-block:: c. void test() {; int x, y;; int d = &y - &x; // warn; }. .. _alpha-core-SizeofPtr:. alpha.core.SizeofPtr (C); """"""""""""""""""""""""""""""""""""""""""""""""; Warn about unintended use of ``sizeof()`` on pointer expressions. .. code-block:: c. struct s {};. int test(struct s *p) {; return sizeof(p);; // warn: sizeof(ptr) can produce an unexpected result; }. .. _alpha-core-StackAddressAsyncEscape:. alpha.core.StackAddressAsyncEscape (C); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check that addresses to stack memory do not escape the function that involves dispatch_after or dispatch_async.; This checker is a part of ``core.StackAddressEscape``, but is temporarily disabled until some false positives are fixed. .. code-block:: c. dispatch_block_t test_block_inside_block_async_leak() {; int x = 123;; void (^inner)(void) = ^void(void) {; int y = x;; ++y;; };; void (^outer)(void) = ^void(void) {; int z = x;; ++z;; inner();; };; return outer; // warn: address of stack-allocated block is captured by a; // returned block; }. .. _alpha-core-StdVariant:. alpha.core.StdVariant (C++); """"""""""""""""""""""""""""""""""""""""""""""""""""""; Check if a value of active type is retrieved from an ``std::variant`` instance with ``std::get``.; In case of bad variant type access (the accessed type differs from the active type); a warning is emitted. Currently, this checker does not take exception handling into account. .. code-block:: cpp. void test() {; std::variant<int, char> v = 25;; char c = stg::get<char>(v); // warn: ""int"" is the active alternative; }. .. _alpha-core-TestAfterDivZero:. alpha.core.TestAfterDivZero (C); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for division by variable that is later compared against 0.; Either the comparison is useless or there is division by zero. .. code-block:: c. void test(int x) {; var = 77 / x;; if (x == 0) { } // warn; }. alpha.cplusplus; ^^^^^^^^^^^^^^^. ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:51602,allocate,allocated,51602,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['allocate'],['allocated']
Energy Efficiency,"ointeraliasing>` section for more; information. If the ``inbounds`` keyword is present, the result value of a; ``getelementptr`` with any non-zero indices is a; :ref:`poison value <poisonvalues>` if one of the following rules is violated:. * The base pointer has an *in bounds* address of an allocated object, which; means that it points into an allocated object, or to its end. Note that the; object does not have to be live anymore; being in-bounds of a deallocated; object is sufficient.; * If the type of an index is larger than the pointer index type, the; truncation to the pointer index type preserves the signed value.; * The multiplication of an index by the type size does not wrap the pointer; index type in a signed sense (``nsw``).; * The successive addition of each offset (without adding the base address) does; not wrap the pointer index type in a signed sense (``nsw``).; * The successive addition of the current address, interpreted as an unsigned; number, and each offset, interpreted as a signed number, does not wrap the; unsigned address space and remains *in bounds* of the allocated object.; As a corollary, if the added offset is non-negative, the addition does not; wrap in an unsigned sense (``nuw``).; * In cases where the base is a vector of pointers, the ``inbounds`` keyword; applies to each of the computations element-wise. Note that ``getelementptr`` with all-zero indices is always considered to be; ``inbounds``, even if the base pointer does not point to an allocated object.; As a corollary, the only pointer in bounds of the null pointer in the default; address space is the null pointer itself. These rules are based on the assumption that no allocated object may cross; the unsigned address space boundary, and no allocated object may be larger; than half the pointer index type space. If the ``inrange`` keyword is present before any index, loading from or; storing to any pointer derived from the ``getelementptr`` has undefined; behavior if the load or stor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:438127,allocate,allocated,438127,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"oject/blob/main/compiler-rt/lib/sanitizer_common/sanitizer_allocator_combined.h>`_.; It aims at providing additional mitigation against heap based vulnerabilities,; while maintaining good performance. Scudo is currently the default allocator in; `Fuchsia <https://fuchsia.dev/>`_, and in `Android <https://www.android.com/>`_; since Android 11. The name ""Scudo"" comes from the Italian word for; `shield <https://www.collinsdictionary.com/dictionary/italian-english/scudo>`_; (and Escudo in Spanish). Design; ======. Allocator; ---------; Scudo was designed with security in mind, but aims at striking a good balance; between security and performance. It was designed to be highly tunable and; configurable, and while we provide some default configurations, we encourage; consumers to come up with the parameters that will work best for their use; cases. The allocator combines several components that serve distinct purposes:. - the Primary allocator: fast and efficient, it services smaller allocation; sizes by carving reserved memory regions into blocks of identical size. There; are currently two Primary allocators implemented, specific to 32 and 64 bit; architectures. It is configurable via compile time options. - the Secondary allocator: slower, it services larger allocation sizes via the; memory mapping primitives of the underlying operating system. Secondary backed; allocations are surrounded by Guard Pages. It is also configurable via compile; time options. - the thread specific data Registry: defines how local caches operate for each; thread. There are currently two models implemented: the exclusive model where; each thread holds its own caches (using the ELF TLS); or the shared model; where threads share a fixed size pool of caches. - the Quarantine: offers a way to delay the deallocation operations, preventing; blocks to be immediately available for reuse. Blocks held will be recycled; once certain size criteria are reached. This is essentially a delayed freelist; which c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:1247,efficient,efficient,1247,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['efficient'],['efficient']
Energy Efficiency,"oken @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %size = call i32 @llvm.coro.size.i32(); %alloc = call ptr @malloc(i32 %size); %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); br label %loop; loop:; %n.val = phi i32 [ %n, %entry ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; call void @print(i32 %n.val); %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. The `entry` block establishes the coroutine frame. The `coro.size`_ intrinsic is; lowered to a constant representing the size required for the coroutine frame.; The `coro.begin`_ intrinsic initializes the coroutine frame and returns the; coroutine handle. The second parameter of `coro.begin` is given a block of memory; to be used if the coroutine frame needs to be allocated dynamically.; The `coro.id`_ intrinsic serves as coroutine identity useful in cases when the; `coro.begin`_ intrinsic get duplicated by optimization passes such as; jump-threading. The `cleanup` block destroys the coroutine frame. The `coro.free`_ intrinsic,; given the coroutine handle, returns a pointer of the memory block to be freed or; `null` if the coroutine frame was not allocated dynamically. The `cleanup`; block is entered when coroutine runs to completion by itself or destroyed via; call to the `coro.destroy`_ intrinsic. The `suspend` block contains code to be executed when coroutine runs to; completion or suspended. The `coro.end`_ intrinsic marks the point where; a coroutine needs to return control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:12666,allocate,allocated,12666,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['allocate'],['allocated']
Energy Efficiency,ols/llvm-microsoft-demangle-fuzzer; - `2`; - `2`; - `0`; - :good:`100%`; * - llvm/tools/llvm-ml; - `3`; - `1`; - `2`; - :part:`33%`; * - llvm/tools/llvm-modextract; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/tools/llvm-mt; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-nm; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-objcopy; - `3`; - `2`; - `1`; - :part:`66%`; * - llvm/tools/llvm-objdump; - `15`; - `10`; - `5`; - :part:`66%`; * - llvm/tools/llvm-opt-fuzzer; - `2`; - `0`; - `2`; - :none:`0%`; * - llvm/tools/llvm-opt-report; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-pdbutil; - `47`; - `15`; - `32`; - :part:`31%`; * - llvm/tools/llvm-profdata; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-profgen; - `11`; - `6`; - `5`; - :part:`54%`; * - llvm/tools/llvm-rc; - `12`; - `6`; - `6`; - :part:`50%`; * - llvm/tools/llvm-readobj; - `19`; - `3`; - `16`; - :part:`15%`; * - llvm/tools/llvm-reduce; - `7`; - `6`; - `1`; - :part:`85%`; * - llvm/tools/llvm-reduce/deltas; - `40`; - `39`; - `1`; - :part:`97%`; * - llvm/tools/llvm-rtdyld; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-rust-demangle-fuzzer; - `2`; - `2`; - `0`; - :good:`100%`; * - llvm/tools/llvm-shlib; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/tools/llvm-sim; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-size; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-special-case-list-fuzzer; - `2`; - `2`; - `0`; - :good:`100%`; * - llvm/tools/llvm-split; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-stress; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-strings; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/tools/llvm-symbolizer; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-tapi-diff; - `3`; - `3`; - `0`; - :good:`100%`; * - llvm/tools/llvm-tli-checker; - `1`; - `0`; - `1`; - :none:`0%`; * - llvm/tools/llvm-undname; - `1`; - `1`; - `0`; - :good:`100%`; * - llvm/tools/llvm-xray; - `19`; - `15`; - `4`; - :part:`78%`; * - llvm/tools/ll,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst:86223,reduce,reduce,86223,interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,1,['reduce'],['reduce']
Energy Efficiency,"omes. _foo:; lis r2, ha16(_a+3); lbz r2, lo16(_a+3)(r2); stb r2, 0(r3); blr. ===-------------------------------------------------------------------------===. We should compile these two functions to the same thing:. #include <stdlib.h>; void f(int a, int b, int *P) {; *P = (a-b)>=0?(a-b):(b-a);; }; void g(int a, int b, int *P) {; *P = abs(a-b);; }. Further, they should compile to something better than:. _g:; subf r2, r4, r3; subfic r3, r2, 0; cmpwi cr0, r2, -1; bgt cr0, LBB2_2 ; entry; LBB2_1: ; entry; mr r2, r3; LBB2_2: ; entry; stw r2, 0(r5); blr. GCC produces:. _g:; subf r4,r4,r3; srawi r2,r4,31; xor r0,r2,r4; subf r0,r2,r0; stw r0,0(r5); blr. ... which is much nicer. This theoretically may help improve twolf slightly (used in dimbox.c:142?). ===-------------------------------------------------------------------------===. PR5945: This: ; define i32 @clamp0g(i32 %a) {; entry:; %cmp = icmp slt i32 %a, 0; %sel = select i1 %cmp, i32 0, i32 %a; ret i32 %sel; }. Is compile to this with the PowerPC (32-bit) backend:. _clamp0g:; cmpwi cr0, r3, 0; li r2, 0; blt cr0, LBB1_2; ; %bb.1: ; %entry; mr r2, r3; LBB1_2: ; %entry; mr r3, r2; blr. This could be reduced to the much simpler:. _clamp0g:; srawi r2, r3, 31; andc r3, r3, r2; blr. ===-------------------------------------------------------------------------===. int foo(int N, int ***W, int **TK, int X) {; int t, i;; ; for (t = 0; t < N; ++t); for (i = 0; i < 4; ++i); W[t / X][i][t % X] = TK[i][t];; ; return 5;; }. We generate relatively atrocious code for this loop compared to gcc. We could also strength reduce the rem and the div:; http://www.lcs.mit.edu/pubs/pdf/MIT-LCS-TM-600.pdf. ===-------------------------------------------------------------------------===. We generate ugly code for this:. void func(unsigned int *ret, float dx, float dy, float dz, float dw) {; unsigned code = 0;; if(dx < -dw) code |= 1;; if(dx > dw) code |= 2;; if(dy < -dw) code |= 4;; if(dy > dw) code |= 8;; if(dz < -dw) code |= 16;; if(dz > dw) code ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:4149,Power,PowerPC,4149,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,1,['Power'],['PowerPC']
Energy Efficiency,"omposes a general `n x n` matrix `A` into `P A = L U`.; - TDecompBK: The Bunch-Kaufman diagonal pivoting method decomposes a real symmetric matrix `A`.; - TDecompChol: The Cholesky decomposition class, which decomposes a symmetric, positive definite matrix `A = U^T * U` where `U` is a upper triangular matrix.; - TDecompQRH: QR decomposition class.; - TDecompSVD: Single value decomposition class.; - TDecompSparse: Sparse symmetric decomposition class. ### Matrix Eigen analysis. With the `TMatrixDEigen` and `TMatrixDSymEigen` classes, you can compute eigenvalues and; eigenvectors for general dense and symmetric real matrices. ## Additional Notes. The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in %ROOT, they of course; can be stored in a %ROOT database. ### How to efficiently use this package. #### 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:. ~~~ {.cpp}; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; ~~~. runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:14655,efficient,efficient,14655,math/matrix/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md,1,['efficient'],['efficient']
Energy Efficiency,"on a loop nest the default behavior; is to automatically extend the representation of the loop counter to; 64 bits for the cases where the sizes of the collapsed loops are not; known at compile time. To prevent this conservative choice and use; at most 32 bits, compile your program with the; `-fopenmp-optimistic-collapse`. GPU devices support; ===================. Data-sharing modes; ------------------. Clang supports two data-sharing models for Cuda devices: `Generic` and `Cuda`; modes. The default mode is `Generic`. `Cuda` mode can give an additional; performance and can be activated using the `-fopenmp-cuda-mode` flag. In; `Generic` mode all local variables that can be shared in the parallel regions; are stored in the global memory. In `Cuda` mode local variables are not shared; between the threads and it is user responsibility to share the required data; between the threads in the parallel regions. Often, the optimizer is able to; reduce the cost of `Generic` mode to the level of `Cuda` mode, but the flag,; as well as other assumption flags, can be used for tuning. Features not supported or with limited support for Cuda devices; ---------------------------------------------------------------. - Cancellation constructs are not supported. - Doacross loop nest is not supported. - User-defined reductions are supported only for trivial types. - Nested parallelism: inner parallel regions are executed sequentially. - Debug information for OpenMP target regions is supported, but sometimes it may; be required to manually specify the address class of the inspected variables.; In some cases the local variables are actually allocated in the global memory,; but the debug info may be not aware of it. .. _OpenMP implementation details:. OpenMP 5.0 Implementation Details; =================================. The following table provides a quick overview over various OpenMP 5.0 features; and their implementation status. Please post on the; `Discourse forums (Runtimes - OpenMP cate",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst:2067,reduce,reduce,2067,interpreter/llvm-project/clang/docs/OpenMPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst,1,['reduce'],['reduce']
Energy Efficiency,"on for register R, then L is replaced; with the result of evaluating a ``DW_OP_bregx R, 0`` operation. This; computes the frame base memory location description in the target; architecture default address space. *This allows the more compact* ``DW_OP_reg*`` *to be used instead of*; ``DW_OP_breg* 0``\ *.*. .. note::. This rule could be removed and require the producer to create the required; location description directly using ``DW_OP_call_frame_cfa``,; ``DW_OP_breg*``, or ``DW_OP_LLVM_aspace_bregx``. This would also then; allow a target to implement the call frames within a large register. Otherwise, the DWARF is ill-formed if SL is not a memory location; description in any of the target architecture specific address spaces. The resulting L is the *frame base* for the subprogram or entry point. *Typically, E will use the* ``DW_OP_call_frame_cfa`` *operation or be a; stack pointer register plus or minus some offset.*. *The frame base for a subprogram is typically an address relative to the; first unit of storage allocated for the subprogram's stack frame. The*; ``DW_AT_frame_base`` *attribute can be used in several ways:*. 1. *In subprograms that need location lists to locate local variables, the*; ``DW_AT_frame_base`` *can hold the needed location list, while all; variables' location descriptions can be simpler ones involving the frame; base.*. 2. *It can be used in resolving ""up-level"" addressing within; nested routines. (See also* ``DW_AT_static_link``\ *, below)*. *Some languages support nested subroutines. In such languages, it is; possible to reference the local variables of an outer subroutine from within; an inner subroutine. The* ``DW_AT_static_link`` *and* ``DW_AT_frame_base``; *attributes allow debuggers to support this same kind of referencing.*. 3. If a ``DW_TAG_subprogram`` or ``DW_TAG_entry_point`` debugger information; entry is lexically nested, it may have a ``DW_AT_static_link`` attribute,; whose value is a DWARF expression E. The result of the attr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:158736,allocate,allocated,158736,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency,"on multiple times appends profile data to an; existing on-disk raw profile. In C++ files, declare these as ``extern ""C""``. Using the profiling runtime without a filesystem; ------------------------------------------------. The profiling runtime also supports freestanding environments that lack a; filesystem. The runtime ships as a static archive that's structured to make; dependencies on a hosted environment optional, depending on what features; the client application uses. The first step is to export ``__llvm_profile_runtime``, as above, to disable; the default static initializers. Instead of calling the ``*_file()`` APIs; described above, use the following to save the profile directly to a buffer; under your control:. * Forward-declare ``uint64_t __llvm_profile_get_size_for_buffer(void)`` and; call it to determine the size of the profile. You'll need to allocate a; buffer of this size. * Forward-declare ``int __llvm_profile_write_buffer(char *Buffer)`` and call it; to copy the current counters to ``Buffer``, which is expected to already be; allocated and big enough for the profile. * Optionally, forward-declare ``void __llvm_profile_reset_counters(void)`` and; call it to reset the counters before entering a specific section to be; profiled. This is only useful if there is some setup that should be excluded; from the profile. In C++ files, declare these as ``extern ""C""``. Collecting coverage reports for the llvm project; ================================================. To prepare a coverage report for llvm (and any of its sub-projects), add; ``-DLLVM_BUILD_INSTRUMENTED_COVERAGE=On`` to the cmake configuration. Raw; profiles will be written to ``$BUILD_DIR/profiles/``. To prepare an html; report, run ``llvm/utils/prepare-code-coverage-artifact.py``. To specify an alternate directory for raw profiles, use; ``-DLLVM_PROFILE_DATA_DIR``. To change the size of the profile merge pool, use; ``-DLLVM_PROFILE_MERGE_POOL_SIZE``. Drawbacks and limitations; ===================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:17586,allocate,allocated,17586,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['allocate'],['allocated']
Energy Efficiency,"on. Additions with respect to TEntryList ; Data members:; fSubLists: a container to hold the sublists; fEntry: the entry number if the list is used to hold subentries; fLastSubListQueried and fSubListIter: a pointer to the last sublist queried and an iterator to resume the loop from the last sublist queried (to speed up selection and insertion in TTree::Draw); Public methods:; Contains, Enter and Remove with subentry as argument; GetSubListForEntry: to return the sublist corresponding to the given entry; Protected methods:; AddEntriesAndSubLists: called by Add when adding two TEntryList arrays with sublists; ConvertToTEntryListArray: convert TEntryList to TEntryListArray; RemoveSubList: to remove the given sublist; RemoveSubListForEntry: to remove the sublist corresponding to the given entry; SetEntry: to get / set a sublist for the given entry. Others changes. Reduced the memory used by a TTree in half by refactoring the code reading and writing the TBasket data;; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch. Updated TBranchElement::Unroll to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit). This disabling is currently _not_ done automatically for backward compatibility reasons and because; ; Without TClass::SetCanSplit there was no way to; force the splitting (short of setting the split level lower); Some classes still requires a custom streamer solely to; read older data files (for example for file written before; the advent of StreamerInfo) and are such not necessary to; be used when writting (and schema evolution rules can not; yet be used in this case). Allowed removing branches when cloning a TNtuple. Added an option value (""cachedbranches"") to the Print() function of TTreeCache to be able to print the list of cached branches. Made the ownership of the TBra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html:2295,Reduce,Reduced,2295,tree/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html,1,['Reduce'],['Reduced']
Energy Efficiency,"on:: -code-model=model. Choose the code model from:. .. code-block:: text. default: Target default code model; tiny: Tiny code model; small: Small code model; kernel: Kernel code model; medium: Medium code model; large: Large code model. .. option:: -disable-post-RA-scheduler. Disable scheduling after register allocation. .. option:: -disable-spill-fusing. Disable fusing of spill code into instructions. .. option:: -jit-enable-eh. Exception handling should be enabled in the just-in-time compiler. .. option:: -join-liveintervals. Coalesce copies (default=true). .. option:: -nozero-initialized-in-bss. Don't place zero-initialized symbols into the BSS section. .. option:: -pre-RA-sched=scheduler. Instruction schedulers available (before register allocation):. .. code-block:: text. =default: Best scheduler for the target; =none: No scheduling: breadth first sequencing; =simple: Simple two pass scheduling: minimize critical path and maximize processor utilization; =simple-noitin: Simple two pass scheduling: Same as simple except using generic latency; =list-burr: Bottom-up register reduction list scheduling; =list-tdrr: Top-down register reduction list scheduling; =list-td: Top-down list scheduler. .. option:: -regalloc=allocator. Register allocator to use (default=linearscan). .. code-block:: text. =bigblock: Big-block register allocator; =linearscan: linear scan register allocator; =local: local register allocator; =simple: simple register allocator. .. option:: -relocation-model=model. Choose relocation model from:. .. code-block:: text. =default: Target default relocation model; =static: Non-relocatable code; =pic: Fully relocatable, position independent code; =dynamic-no-pic: Relocatable external references, non-relocatable code. .. option:: -spiller. Spiller to use (default=local). .. code-block:: text. =simple: simple spiller; =local: local spiller. .. option:: -x86-asm-syntax=syntax. Choose style of code to emit from X86 backend:. .. code-block:: text. =att: Emit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:4368,schedul,scheduler,4368,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,7,['schedul'],"['scheduler', 'scheduling']"
Energy Efficiency,"ons (which disable the optimizer and code generator), then; the crash is in the front-end. Jump ahead to :ref:`front-end bugs; <frontend-crash>`. * ``-emit-llvm``: If ``clang`` crashes with this option (which disables; the code generator), you found a middle-end optimizer bug. Jump ahead to; :ref:`middle-end bugs <middleend-crash>`. * Otherwise, you have a backend code generator crash. Jump ahead to :ref:`code; generator bugs <backend-crash>`. .. _frontend-crash:. Front-end bugs; --------------. On a ``clang`` crash, the compiler will dump a preprocessed file and a script; to replay the ``clang`` command. For example, you should see something like. .. code-block:: text. PLEASE ATTACH THE FOLLOWING FILES TO THE BUG REPORT:; Preprocessed source(s) and associated run script(s) are located at:; clang: note: diagnostic msg: /tmp/foo-xxxxxx.c; clang: note: diagnostic msg: /tmp/foo-xxxxxx.sh. The `creduce <https://github.com/csmith-project/creduce>`_ tool helps to; reduce the preprocessed file down to the smallest amount of code that still; replicates the problem. You're encouraged to use creduce to reduce the code; to make the developers' lives easier. The; ``clang/utils/creduce-clang-crash.py`` script can be used on the files; that clang dumps to help with automating creating a test to check for the; compiler crash. `cvise <https://github.com/marxin/cvise>`_ is an alternative to ``creduce``. .. _middleend-crash:. Middle-end optimization bugs; ----------------------------. If you find that a bug crashes in the optimizer, compile your test-case to a; ``.bc`` file by passing ""``-emit-llvm -O1 -Xclang -disable-llvm-passes -c -o; foo.bc``"". The ``-O1`` is important because ``-O0`` adds the ``optnone``; function attribute to all functions and many passes don't run on ``optnone``; functions. Then run:. .. code-block:: bash. opt -O3 foo.bc -disable-output. If this doesn't crash, please follow the instructions for a :ref:`front-end; bug <frontend-crash>`. If this does crash, then ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:3042,reduce,reduce,3042,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduce']
Energy Efficiency,"ons. .. option:: -o <filename>. Use ``<filename>`` as the output filename. See the summary above for more; details. .. option:: -mtriple=<target triple>. Specify a target triple string. .. option:: -march=<arch>. Specify the architecture for which to analyze the code. It defaults to the; host default target. .. option:: -mcpu=<cpuname>. Specify the processor for which to analyze the code. By default, the cpu name; is autodetected from the host. .. option:: -output-asm-variant=<variant id>. Specify the output assembly variant for the report generated by the tool.; On x86, possible values are [0, 1]. A value of 0 (vic. 1) for this flag enables; the AT&T (vic. Intel) assembly format for the code printed out by the tool in; the analysis report. .. option:: -print-imm-hex. Prefer hex format for numeric literals in the output assembly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store qu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:3452,schedul,scheduling,3452,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"ons; ... // M-partZ.cppm; module;; #include ""big.header.h""; export module M:partZ;; ... // M.cppm; export module M;; export import :partA;; export import :partB;; ...; export import :partZ;. // use.cpp; import M;; ... // use declarations from module M. When ``big.header.h`` is big enough and there are a lot of partitions,; the compilation of ``use.cpp`` may be slower than; the following style significantly:. .. code-block:: c++. module;; #include ""big.header.h""; export module m:big.header.wrapper;; export ... // export the needed declarations. // M-partA.cppm; export module M:partA;; import :big.header.wrapper;; ... // M-partB.cppm; export module M:partB;; import :big.header.wrapper;; ... // other partitions; ... // M-partZ.cppm; export module M:partZ;; import :big.header.wrapper;; ... // M.cppm; export module M;; export import :partA;; export import :partB;; ...; export import :partZ;. // use.cpp; import M;; ... // use declarations from module M. The key part of the tip is to reduce the duplications from the text includes. Known Problems; --------------. The following describes issues in the current implementation of modules.; Please see https://github.com/llvm/llvm-project/labels/clang%3Amodules for more issues; or file a new issue if you don't find an existing one.; If you're going to create a new issue for standard C++ modules,; please start the title with ``[C++20] [Modules]`` (or ``[C++23] [Modules]``, etc); and add the label ``clang:modules`` (if you have permissions for that). For higher level support for proposals, you could visit https://clang.llvm.org/cxx_status.html. Including headers after import is problematic; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. For example, the following example can be accept:. .. code-block:: c++. #include <iostream>; import foo; // assume module 'foo' contain the declarations from `<iostream>`. int main(int argc, char *argv[]); {; std::cout << ""Test\n"";; return 0;; }. but it will get rejected if we reverse the order of `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:21061,reduce,reduce,21061,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,1,['reduce'],['reduce']
Energy Efficiency,"ont starts execution; with address watch; exceptions enabled which; are generated when L1 has; witnessed a thread access; an *address of; interest*. CP is responsible for; filling in the address; watch bit in; ``COMPUTE_PGM_RSRC2.EXCP_EN_MSB``; according to what the; runtime requests.; 14 1 bit ENABLE_EXCEPTION_MEMORY Must be 0. Wavefront starts execution; with memory violation; exceptions exceptions; enabled which are generated; when a memory violation has; occurred for this wavefront from; L1 or LDS; (write-to-read-only-memory,; mis-aligned atomic, LDS; address out of range,; illegal address, etc.). CP sets the memory; violation bit in; ``COMPUTE_PGM_RSRC2.EXCP_EN_MSB``; according to what the; runtime requests.; 23:15 9 bits GRANULATED_LDS_SIZE Must be 0. CP uses the rounded value; from the dispatch packet,; not this value, as the; dispatch may contain; dynamically allocated group; segment memory. CP writes; directly to; ``COMPUTE_PGM_RSRC2.LDS_SIZE``. Amount of group segment; (LDS) to allocate for each; work-group. Granularity is; device specific:. GFX6; roundup(lds-size / (64 * 4)); GFX7-GFX11; roundup(lds-size / (128 * 4)). 24 1 bit ENABLE_EXCEPTION_IEEE_754_FP Wavefront starts execution; _INVALID_OPERATION with specified exceptions; enabled. Used by CP to set up; ``COMPUTE_PGM_RSRC2.EXCP_EN``; (set from bits 0..6). IEEE 754 FP Invalid; Operation; 25 1 bit ENABLE_EXCEPTION_FP_DENORMAL FP Denormal one or more; _SOURCE input operands is a; denormal number; 26 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Division by; _DIVISION_BY_ZERO Zero; 27 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP FP Overflow; _OVERFLOW; 28 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Underflow; _UNDERFLOW; 29 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Inexact; _INEXACT; 30 1 bit ENABLE_EXCEPTION_INT_DIVIDE_BY Integer Division by Zero; _ZERO (rcp_iflag_f32 instruction; only); 31 1 bit RESERVED Reserved, must be 0.; 32 **Total size 4 bytes.**; ======= ===============================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:174141,allocate,allocate,174141,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocate']
Energy Efficiency,"ookup; performance. See the subsection `How to manage symbol strings`_. 4. IR layers require ThreadSafeModule instances, rather than; std::unique_ptr<Module>s. ThreadSafeModule is a wrapper that ensures that; Modules that use the same LLVMContext are not accessed concurrently.; See `How to use ThreadSafeModule and ThreadSafeContext`_. 5. Symbol lookup is no longer handled by layers. Instead, there is a; ``lookup`` method on JITDylib that takes a list of JITDylibs to scan. .. code-block:: c++. ExecutionSession ES;; JITDylib &JD1 = ...;; JITDylib &JD2 = ...;. auto Sym = ES.lookup({&JD1, &JD2}, ES.intern(""_main""));. 6. The removeModule/removeObject methods are replaced by; ``ResourceTracker::remove``.; See the subsection `How to remove code`_. For code examples and suggestions of how to use the ORCv2 APIs, please see; the section `How-tos`_. How-tos; =======. How to manage symbol strings; ----------------------------. Symbol strings in ORC are uniqued to improve lookup performance, reduce memory; overhead, and allow symbol names to function as efficient keys. To get the; unique ``SymbolStringPtr`` for a string value, call the; ``ExecutionSession::intern`` method:. .. code-block:: c++. ExecutionSession ES;; /// ...; auto MainSymbolName = ES.intern(""main"");. If you wish to perform lookup using the C/IR name of a symbol you will also; need to apply the platform linker-mangling before interning the string. On; Linux this mangling is a no-op, but on other platforms it usually involves; adding a prefix to the string (e.g. '_' on Darwin). The mangling scheme is; based on the DataLayout for the target. Given a DataLayout and an; ExecutionSession, you can create a MangleAndInterner function object that; will perform both jobs for you:. .. code-block:: c++. ExecutionSession ES;; const DataLayout &DL = ...;; MangleAndInterner Mangle(ES, DL);. // ... // Portable IR-symbol-name lookup:; auto Sym = ES.lookup({&MainJD}, Mangle(""main""));. How to create JITDylibs and set up linkage rel",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:22099,reduce,reduce,22099,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,2,"['efficient', 'reduce']","['efficient', 'reduce']"
Energy Efficiency,"ool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analyzes instruction; dispatch events, as well as static/dynamic dispatch stall events. This view; is disabled by default. .. option:: -scheduler-stats. Enable extra scheduler statistics. This view collects and analyzes instruction; issue events. This view is disabled by default. .. option:: -retire-stats. Enable extra retire control unit statistics. This view is disabled by default. .. option:: -instruction-info. Enable the instruction info view. This is enabled by default. .. option:: -show-encoding. Enable the printing of instruction encodings within the instruction info view. .. option:: -show-barriers. Enable the printing of LoadBarrier and StoreBarrier flags within the; instruction info view. .. option:: -all-stats. Print all hardware statistics. This enables extra statistics related to the; dispatch logic, the hardware schedulers, the register file(s), and the retire; control unit. This option is disabled by default. .. option:: -all-views. Enable all the view. .. option:: -instruction-tables. Prints resource pressure information based on the static information; available from the processor model. This differs from the resource pressure; view be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:5511,schedul,scheduler,5511,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,ools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/t,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337817,reduce,reduce,337817,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"op before and after the call instruction. These no-ops are often; removed by the backend during dead machine instruction elimination. Before the abstract machine model is lowered to the explicit statepoint model; of relocations by the :ref:`RewriteStatepointsForGC` pass it is possible for; any derived pointer to get its base pointer and offset from the base pointer; by using the ``gc.get.pointer.base`` and the ``gc.get.pointer.offset``; intrinsics respectively. These intrinsics are inlined by the; :ref:`RewriteStatepointsForGC` pass and must not be used after this pass. .. _statepoint-stackmap-format:. Stack Map Format; ================. Locations for each pointer value which may need read and/or updated by; the runtime or collector are provided in a separate section of the; generated object file as specified in the PatchPoint documentation.; This special section is encoded per the; :ref:`Stack Map format <stackmap-format>`. The general expectation is that a JIT compiler will parse and discard this; format; it is not particularly memory efficient. If you need an alternate; format (e.g. for an ahead of time compiler), see discussion under; :ref: `open work items <OpenWork>` below. Each statepoint generates the following Locations:. * Constant which describes the calling convention of the call target. This; constant is a valid :ref:`calling convention identifier <callingconv>` for; the version of LLVM used to generate the stackmap. No additional compatibility; guarantees are made for this constant over what LLVM provides elsewhere w.r.t.; these identifiers.; * Constant which describes the flags passed to the statepoint intrinsic; * Constant which describes number of following deopt *Locations* (not; operands). Will be 0 if no ""deopt"" bundle is provided.; * Variable number of Locations, one for each deopt parameter listed in the; ""deopt"" operand bundle. At the moment, only deopt parameters with a bitwidth; of 64 bits or less are supported. Values of a type larger than 6",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:20411,efficient,efficient,20411,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['efficient'],['efficient']
Energy Efficiency,"operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smin``' intrinsic performs the signed-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.smin <int_vector_reduce_smin>`) of the; vector operand ``val`` on each enabled lane, and taking the minimum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MAX`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smin.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. '``llvm.vp.reduce.umax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:766733,reduce,reduce,766733,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"opt=save-temps"". These options enable LTO and save temporary files generated during compilation; for later analysis. On Windows, you should be using lld-link as the linker. Adjust your compilation ; flags as follows:; * Add ``/lldsavetemps`` to the linker flags.; * When linking from the compiler driver, add ``/link /lldsavetemps`` in order to forward that flag to the linker. Using the specified flags will generate four intermediate bytecode files:. #. a.out.0.0.preopt.bc (Before any link-time optimizations (LTO) are applied); #. a.out.0.2.internalize.bc (After initial optimizations are applied); #. a.out.0.4.opt.bc (After an extensive set of optimizations); #. a.out.0.5.precodegen.bc (After LTO but before translating into machine code). Execute one of the following commands to identify the source of the problem:. #. ``opt ""-passes=lto<O3>"" a.out.0.2.internalize.bc``; #. ``llc a.out.0.5.precodegen.bc``. If one of these do crash, you should be able to reduce; this with :program:`llvm-reduce`; command line (use the bc file corresponding to the command above that failed):. .. code-block:: bash. llvm-reduce --test reduce.sh a.out.0.2.internalize.bc. Example of reduce.sh script. .. code-block:: bash. $ cat reduce.sh; #!/bin/bash -e. path/to/not --crash path/to/opt ""-passes=lto<O3>"" $1 -o temp.bc 2> err.log; grep -q ""It->second == &Insn"" err.log. Here we have grepped the failed assert message. Please run this, then file a bug with the instructions and reduced .bc file; that llvm-reduce emits. .. _miscompiling:. Miscompilations; ===============. If clang successfully produces an executable, but that executable doesn't run; right, this is either a bug in the code or a bug in the compiler. The first; thing to check is to make sure it is not using undefined behavior (e.g.; reading a variable before it is defined). In particular, check to see if the; program is clean under various `sanitizers; <https://github.com/google/sanitizers>`_ (e.g. ``clang; -fsanitize=undefined,address`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:7377,reduce,reduce,7377,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,2,['reduce'],['reduce']
Energy Efficiency,"optimizer, compile your test-case to a; ``.bc`` file by passing ""``-emit-llvm -O1 -Xclang -disable-llvm-passes -c -o; foo.bc``"". The ``-O1`` is important because ``-O0`` adds the ``optnone``; function attribute to all functions and many passes don't run on ``optnone``; functions. Then run:. .. code-block:: bash. opt -O3 foo.bc -disable-output. If this doesn't crash, please follow the instructions for a :ref:`front-end; bug <frontend-crash>`. If this does crash, then you should be able to debug this with the following; :doc:`bugpoint <Bugpoint>` command:. .. code-block:: bash. bugpoint foo.bc -O3. Run this, then file a bug with the instructions and reduced .bc; files that bugpoint emits. If bugpoint doesn't reproduce the crash, ``llvm-reduce`` is an alternative; way to reduce LLVM IR. Create a script that repros the crash and run:. .. code-block:: bash. llvm-reduce --test=path/to/script foo.bc. which should produce reduced IR that reproduces the crash. Be warned the; ``llvm-reduce`` is still fairly immature and may crash. If none of the above work, you can get the IR before a crash by running the; ``opt`` command with the ``--print-before-all --print-module-scope`` flags to; dump the IR before every pass. Be warned that this is very verbose. .. _backend-crash:. Backend code generator bugs; ---------------------------. If you find a bug that crashes clang in the code generator, compile your; source file to a .bc file by passing ""``-emit-llvm -c -o foo.bc``"" to; clang (in addition to the options you already pass). Once your have; foo.bc, one of the following commands should fail:. #. ``llc foo.bc``; #. ``llc foo.bc -relocation-model=pic``; #. ``llc foo.bc -relocation-model=static``. If none of these crash, please follow the instructions for a :ref:`front-end; bug<frontend-crash>`. If one of these do crash, you should be able to reduce; this with one of the following :doc:`bugpoint <Bugpoint>` command lines (use; the one corresponding to the command above that failed):. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:4587,reduce,reduce,4587,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['reduce'],['reduce']
Energy Efficiency,"or assigning uninitialized values. void test() {; int x;; x |= 1; // warn: left expression is uninitialized; }. core.uninitialized.Branch; (C); Check for uninitialized values used as branch conditions. void test() {; int x;; if (x) // warn; return;; }. core.uninitialized.CapturedBlockVariable; (C); Check for blocks that capture uninitialized values. void test() {; int x;; ^{ int y = x; }(); // warn; }. core.uninitialized.UndefReturn; (C); Check for uninitialized values being returned to the caller. int test() {; int x;; return x; // warn; }. C++ Checkers. Name, DescriptionExample. cplusplus.NewDelete; (C++); Check for double-free, use-after-free and offset problems involving C++ ; delete. void f(int *p);. void testUseMiddleArgAfterDelete(int *p) {; delete p;; f(p); // warn: use after free; }. class SomeClass {; public:; void f();; };. void test() {; SomeClass *c = new SomeClass;; delete c;; c->f(); // warn: use after free; }. void test() {; int *p = (int *)__builtin_alloca(sizeof(int));; delete p; // warn: deleting memory allocated by alloca; }. void test() {; int *p = new int;; delete p;; delete p; // warn: attempt to free released; }. void test() {; int i;; delete &i; // warn: delete address of local; }. void test() {; int *p = new int[1];; delete[] (++p);; // warn: argument to 'delete[]' is offset by 4 bytes; // from the start of memory allocated by 'new[]'; }. cplusplus.NewDeleteLeaks; (C++); Check for memory leaks. Traces memory managed by new/; delete. void test() {; int *p = new int;; } // warn. Dead Code Checkers. Name, DescriptionExample. deadcode.DeadStores; (C); Check for values stored to variables that are never read afterwards. void test() {; int x;; x = 1; // warn; }. Nullability Checkers. Name, DescriptionExample. nullability.NullPassedToNonnull; (ObjC); Warns when a null pointer is passed to a pointer which has a; _Nonnull type. if (name != nil); return;; // Warning: nil passed to a callee that requires a non-null 1st parameter; NSString *greeting = ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html:5530,allocate,allocated,5530,interpreter/llvm-project/clang/www/analyzer/available_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/available_checks.html,2,['allocate'],['allocated']
Energy Efficiency,"or operand; ``val`` on each enabled lane, performing an '``xor``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %masked.a); %also.r = xor i32 %reduction, %start. .. _int_vp_reduce_smax:. '``llvm.vp.reduce.smax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smax``' intrinsic performs the signed-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.smax ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:762885,reduce,reduce,762885,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"or some number of; elements (N) **in the object itself**. Because of this, if the SmallVector is; dynamically smaller than N, no malloc is performed. This can be a big win in; cases where the malloc/free call is far more expensive than the code that; fiddles around with the elements. This is good for vectors that are ""usually small"" (e.g. the number of; predecessors/successors of a block is usually less than 8). On the other hand,; this makes the size of the SmallVector itself large, so you don't want to; allocate lots of them (doing so will waste a lot of space). As such,; SmallVectors are most useful when on the stack. In the absence of a well-motivated choice for the number of; inlined elements ``N``, it is recommended to use ``SmallVector<T>`` (that is,; omitting the ``N``). This will choose a default number of; inlined elements reasonable for allocation on the stack (for example, trying; to keep ``sizeof(SmallVector<T>)`` around 64 bytes). SmallVector also provides a nice portable and efficient replacement for; ``alloca``. SmallVector has grown a few other minor advantages over std::vector, causing; ``SmallVector<Type, 0>`` to be preferred over ``std::vector<Type>``. #. std::vector is exception-safe, and some implementations have pessimizations; that copy elements when SmallVector would move them. #. SmallVector understands ``std::is_trivially_copyable<Type>`` and uses realloc aggressively. #. Many LLVM APIs take a SmallVectorImpl as an out parameter (see the note; below). #. SmallVector with N equal to 0 is smaller than std::vector on 64-bit; platforms, since it uses ``unsigned`` (instead of ``void*``) for its size; and capacity. .. note::. Prefer to use ``ArrayRef<T>`` or ``SmallVectorImpl<T>`` as a parameter type. It's rarely appropriate to use ``SmallVector<T, N>`` as a parameter type.; If an API only reads from the vector, it should use :ref:`ArrayRef; <dss_arrayref>`. Even if an API updates the vector the ""small size"" is; unlikely to be relevant; such an A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:60809,efficient,efficient,60809,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"or, Fatal Verbosity level. VarTransform No None âˆ’ List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False âˆ’ Print method-specific help message. CreateMVAPdfs No False âˆ’ Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False âˆ’ Events with negative weights are ignored in the training (but are included for testing and performance evaluation). VolumeRangeMode No Adaptive Unscaled, MinMax, RMS, Adaptive, kNN Method to determine volume size. KernelEstimator No Box Box, Sphere, Teepee, Gauss, Sinc3, Sinc5, Sinc7, Sinc9, Sinc11, Lanczos2, Lanczos3, Lanczos5, Lanczos8, Trim Kernel estimation function. DeltaFrac No 3 âˆ’ nEventsMin/Max for minmax and rms volume range. NEventsMin No 100 âˆ’ nEventsMin for adaptive volume range. NEventsMax No 200 âˆ’ nEventsMax for adaptive volume range. MaxVIterations No 150 âˆ’ MaxVIterations for adaptive volume range. InitialScale No 0.99 âˆ’ InitialScale for adaptive volume range. GaussSigma No 0.1 âˆ’ Width (wrt volume size) of Gaussian kernel estimator. NormTree No False âˆ’ Normalize binary search tree. Configuration options for MVA method :. Configuration options reference for MVA method: FDA. Option Array Default value Predefined values Description. V No False âˆ’ Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None âˆ’ List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:4725,adapt,adaptive,4725,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['adapt'],['adaptive']
Energy Efficiency,"or.reduce.fmin.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with minimum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmaximum:. '``llvm.vector.reduce.fmaximum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmaximum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmaximum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmaximum.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maximum.*``'; intrinsic. That is, this intrinsic propagates NaNs and +0.0 is considered; greater than -0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fminimum:. '``llvm.vector.reduce.fminimum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fminimum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fminimum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fminimum.*``' intrinsics do a floating-point; ``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:660794,reduce,reduce,660794,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"or>(&I)) {; Value *LHS = BO->getOperand(0);; Value *RHS = BO->getOperand(1);; if (LHS != RHS) {; ...; }; }; }. When you have very, very small loops, this sort of structure is fine. But if it; exceeds more than 10-15 lines, it becomes difficult for people to read and; understand at a glance. The problem with this sort of code is that it gets very; nested very quickly. Meaning that the reader of the code has to keep a lot of; context in their brain to remember what is going immediately on in the loop,; because they don't know if/when the ``if`` conditions will have ``else``\s etc.; It is strongly preferred to structure the loop like this:. .. code-block:: c++. for (Instruction &I : BB) {; auto *BO = dyn_cast<BinaryOperator>(&I);; if (!BO) continue;. Value *LHS = BO->getOperand(0);; Value *RHS = BO->getOperand(1);; if (LHS == RHS) continue;. ...; }. This has all the benefits of using early exits for functions: it reduces nesting; of the loop, it makes it easier to describe why the conditions are true, and it; makes it obvious to the reader that there is no ``else`` coming up that they; have to push context into their brain for. If a loop is large, this can be a; big understandability win. Don't use ``else`` after a ``return``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. For similar reasons as above (reduction of indentation and easier reading), please; do not use ``'else'`` or ``'else if'`` after something that interrupts control; flow --- like ``return``, ``break``, ``continue``, ``goto``, etc. For example:. .. code-block:: c++. case 'J': {; if (Signed) {; Type = Context.getsigjmp_bufType();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_sigjmp_buf;; return QualType();; } else {; break; // Unnecessary.; }; } else {; Type = Context.getjmp_bufType();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_jmp_buf;; return QualType();; } else {; break; // Unnecessary.; }; }; }. It is better to write it like this:. .. code-block:: c++. case 'J':; if (Signed) {; Type = Con",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:38177,reduce,reduces,38177,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['reduce'],['reduces']
Energy Efficiency,"ord. * Add any fields to the record.; * Modify the values of fields according to local ``let`` statements.; * Define any ``defvar`` variables. 5. Make a pass over all the fields to resolve any inter-field references. 6. Add the record to the final record list. Because references between fields are resolved (step 5) after ``let`` bindings are; applied (step 3), the ``let`` statement has unusual power. For example:. .. code-block:: text. class C <int x> {; int Y = x;; int Yplus1 = !add(Y, 1);; int xplus1 = !add(x, 1);; }. let Y = 10 in {; def rec1 : C<5> {; }; }. def rec2 : C<5> {; let Y = 10;; }. In both cases, one where a top-level ``let`` is used to bind ``Y`` and one; where a local ``let`` does the same thing, the results are:. .. code-block:: text. def rec1 { // C; int Y = 10;; int Yplus1 = 11;; int xplus1 = 6;; }; def rec2 { // C; int Y = 10;; int Yplus1 = 11;; int xplus1 = 6;; }. ``Yplus1`` is 11 because the ``let Y`` is performed before the ``!add(Y,; 1)`` is resolved. Use this power wisely. Using Classes as Subroutines; ============================. As described in `Simple values`_, a class can be invoked in an expression; and passed template arguments. This causes TableGen to create a new anonymous; record inheriting from that class. As usual, the record receives all the; fields defined in the class. This feature can be employed as a simple subroutine facility. The class can; use the template arguments to define various variables and fields, which end; up in the anonymous record. Those fields can then be retrieved in the; expression invoking the class as follows. Assume that the field ``ret``; contains the final value of the subroutine. .. code-block:: text. int Result = ... CalcValue<arg>.ret ...;. The ``CalcValue`` class is invoked with the template argument ``arg``. It; calculates a value for the ``ret`` field, which is then retrieved at the; ""point of call"" in the initialization for the Result field. The anonymous; record created in this example serves no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:54956,power,power,54956,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['power'],['power']
Energy Efficiency,"oring Cerenkov; properties. Another hook for material shading properties is currently; not in use. Mixtures are materials made of several elements. They are; represented by the class TGeoMixture, deriving from; TGeoMaterial and defined by their number of components and the; density:. ~~~{.cpp}; TGeoMixture(const char *name,Int_t nel,Double_t rho);; ~~~. Elements have to be further defined one by one:. ~~~{.cpp}; void TGeoMixture::DefineElement(Int_t iel,Double_t a,Double_t z,; Double_t weigth);; void TGeoMixture::DefineElement(Int_t iel, TGeoElement *elem,; Double_t weight);; void TGeoMixture::DefineElement(Int_t iel, Int_t z, Int_t natoms);; ~~~. or:. ~~~{.cpp}; void AddElement(TGeoMaterial* mat, Double_t weight);; void AddElement(TGeoElement* elem, Double_t weight);; void AddElement(TGeoElement* elem, Int_t natoms);; void AddElement(Double_t a, Double_t z, Double_t weight); ~~~. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:4225,charge,charge,4225,geom/geom/doc/materials.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md,1,['charge'],['charge']
Energy Efficiency,"orkflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each reported issue:. * A security issue reporter (not necessarily an LLVM contributor) reports an issue.; * Within two business days, a member of the Security Group is put in charge of driving the issue to an acceptable resolution. This champion doesnâ€™t need to be the same person for each issue. This person can self-nominate.; * Members of the Security Group discuss in which circumstances (if any) an issue is relevant to security, and determine if it is a security issue.; * Negotiate an embargo date for public disclosure, with a default minimum time limit of ninety days.; * Security Group members can recommend that key experts be pulled in to specific issue discussions. The key expert can be pulled in unless there are objections from other Security Group members.; * Patches are written and reviewed.; * Backporting security patches from recent versions to old versions cannot always work. It is up to the Security Group to decide if such backporting should be done, and how far back.; * The Security Group figures out how the LLVM projectâ€™s own releases, as well as individual vendorsâ€™ releases, can be timed to patch the issue simultaneously.; * Embargo da",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:12280,charge,charge,12280,interpreter/llvm-project/llvm/docs/Security.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst,1,['charge'],['charge']
Energy Efficiency,"orrect way to build runtimes when putting together a toolchain.; It will build the builtins separately from the other runtimes to preserve; correct dependency ordering. If you want to build the runtimes using a system; compiler, see the `libc++ documentation <https://libcxx.llvm.org/BuildingLibcxx.html>`_.; Note: the list should not have duplicates with `LLVM_ENABLE_PROJECTS`.; The full list is:; ``compiler-rt;libc;libcxx;libcxxabi;libunwind;openmp``; To enable all of them, use:; ``LLVM_ENABLE_RUNTIMES=all``. **LLVM_ENABLE_RTTI**:BOOL; Build LLVM with run-time type information. Defaults to OFF. **LLVM_ENABLE_SPHINX**:BOOL; If specified, CMake will search for the ``sphinx-build`` executable and will make; the ``SPHINX_OUTPUT_HTML`` and ``SPHINX_OUTPUT_MAN`` CMake options available.; Defaults to OFF. **LLVM_ENABLE_THREADS**:BOOL; Build with threads support, if available. Defaults to ON. **LLVM_ENABLE_UNWIND_TABLES**:BOOL; Enable unwind tables in the binary. Disabling unwind tables can reduce the; size of the libraries. Defaults to ON. **LLVM_ENABLE_WARNINGS**:BOOL; Enable all compiler warnings. Defaults to ON. **LLVM_ENABLE_WERROR**:BOOL; Stop and fail the build, if a compiler warning is triggered. Defaults to OFF. **LLVM_ENABLE_Z3_SOLVER**:BOOL; If enabled, the Z3 constraint solver is activated for the Clang static analyzer.; A recent version of the z3 library needs to be available on the system. **LLVM_ENABLE_ZLIB**:STRING; Used to decide if LLVM tools should support compression/decompression with; zlib. Allowed values are ``OFF``, ``ON`` (default, enable if zlib is found),; and ``FORCE_ON`` (error if zlib is not found). **LLVM_ENABLE_ZSTD**:STRING; Used to decide if LLVM tools should support compression/decompression with; zstd. Allowed values are ``OFF``, ``ON`` (default, enable if zstd is found),; and ``FORCE_ON`` (error if zstd is not found). **LLVM_EXPERIMENTAL_TARGETS_TO_BUILD**:STRING; Semicolon-separated list of experimental targets to build and linked into; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:25600,reduce,reduce,25600,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['reduce'],['reduce']
Energy Efficiency,"ose commits are not uniformly distributed. They; tend to cluster strongly during US working hours. Looking at a couple; of recent (Nov 2021) working days, we routinely see ~10 commits per; hour during peek times, with occasional spikes as high as ~15 commits; per hour. Thus, as a rule of thumb, we should plan for our builder to; complete ~10-15 builds an hour. Resource Appropriately; At 10-15 builds per hour, we need to complete a new build on average every; 4 to 6 minutes. For anything except the fastest of hardware/build configs,; this is going to be well beyond the ability of a single machine. In buildbot; terms, we likely going to need multiple workers to build requests in parallel; under a single builder configuration. For some rough back of the envelope; numbers, if your build config takes e.g. 30 minutes, you will need something; on the order of 5-8 workers. If your build config takes ~2 hours, you'll; need something on the order of 20-30 workers. The rest of this section; focuses on how to reduce cycle times. Restrict what you build and test; Think hard about why you're setting up a bot, and restrict your build; configuration as much as you can. Basic functionality is probably; already covered by other bots, and you don't need to duplicate that; testing. You only need to be building and testing the *unique* parts; of the configuration. (e.g. For a multi-stage clang builder, you probably; don't need to be enabling every target or building all the various utilities.). It can sometimes be worthwhile splitting a single builder into two or more,; if you have multiple distinct purposes for the same builder. As an example,; if you want to both a) confirm that all of LLVM builds with your host; compiler, and b) want to do a multi-stage clang build on your target, you; may be better off with two separate bots. Splitting increases resource; consumption, but makes it easy for each bot to keep up with commit flow.; Additionally, splitting bots may assist in triage by na",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:9335,reduce,reduce,9335,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['reduce'],['reduce']
Energy Efficiency,"osed by the operating system `[1]`_ `[2]`_ or processor `[3]`_; to discover the address of the shadow call stack. .. _`[1]`: https://eyalitkin.wordpress.com/2017/09/01/cartography-lighting-up-the-shadows/; .. _`[2]`: https://www.blackhat.com/docs/eu-16/materials/eu-16-Goktas-Bypassing-Clangs-SafeStack.pdf; .. _`[3]`: https://www.vusec.net/projects/anc/. Unless care is taken when allocating the shadow call stack, it may be; possible for an attacker to guess its address using the addresses of; other allocations. Therefore, the address should be chosen to make this; difficult. One way to do this is to allocate a large guard region without; read/write permissions, randomly select a small region within it to be; used as the address of the shadow call stack and mark only that region as; read/write. This also mitigates somewhat against processor side channels.; The intent is that the Android runtime `will do this`_, but the platform will; first need to be `changed`_ to avoid using ``setrlimit(RLIMIT_AS)`` to limit; memory allocations in certain processes, as this also limits the number of; guard regions that can be allocated. .. _`will do this`: https://android-review.googlesource.com/c/platform/bionic/+/891622; .. _`changed`: https://android-review.googlesource.com/c/platform/frameworks/av/+/837745. The runtime will need the address of the shadow call stack in order to; deallocate it when destroying the thread. If the entire program is compiled; with ``SCSReg`` reserved, this is trivial: the address can be derived from the; value stored in ``SCSReg`` (e.g. by masking out the lower bits). If a guard; region is used, the address of the start of the guard region could then be; stored at the start of the shadow call stack itself. But if it is possible; for code compiled without reserving ``SCSReg`` to run on a thread managed by the; runtime, which is the case on Android for example, the address must be stored; somewhere else instead. On Android we store the address of the star",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ShadowCallStack.rst:6403,allocate,allocated,6403,interpreter/llvm-project/clang/docs/ShadowCallStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ShadowCallStack.rst,1,['allocate'],['allocated']
Energy Efficiency,"ot,; consider a :ref:`SmallVector <dss_smallvector>`). The cost of a heap allocated; array is the cost of the new/delete (aka malloc/free). Also note that if you; are allocating an array of a type with a constructor, the constructor and; destructors will be run for every element in the array (re-sizable vectors only; construct those elements actually used). .. _dss_tinyptrvector:. llvm/ADT/TinyPtrVector.h; ^^^^^^^^^^^^^^^^^^^^^^^^. ``TinyPtrVector<Type>`` is a highly specialized collection class that is; optimized to avoid allocation in the case when a vector has zero or one; elements. It has two major restrictions: 1) it can only hold values of pointer; type, and 2) it cannot hold a null pointer. Since this container is highly specialized, it is rarely used. .. _dss_smallvector:. llvm/ADT/SmallVector.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallVector<Type, N>`` is a simple class that looks and smells just like; ``vector<Type>``: it supports efficient iteration, lays out elements in memory; order (so you can do pointer arithmetic between elements), supports efficient; push_back/pop_back operations, supports efficient random access to its elements,; etc. The main advantage of SmallVector is that it allocates space for some number of; elements (N) **in the object itself**. Because of this, if the SmallVector is; dynamically smaller than N, no malloc is performed. This can be a big win in; cases where the malloc/free call is far more expensive than the code that; fiddles around with the elements. This is good for vectors that are ""usually small"" (e.g. the number of; predecessors/successors of a block is usually less than 8). On the other hand,; this makes the size of the SmallVector itself large, so you don't want to; allocate lots of them (doing so will waste a lot of space). As such,; SmallVectors are most useful when on the stack. In the absence of a well-motivated choice for the number of; inlined elements ``N``, it is recommended to use ``SmallVector<T>`` (that is,; omittin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:59526,efficient,efficient,59526,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,3,['efficient'],['efficient']
Energy Efficiency,"otected or; private members if you hide them in the display options. Inheritance; You can often access members of a class's base classes, just as if they are defined; in the derived class. A histogram,; for example, has a name, and you can access it using GetName() as defined in its base; class TNamed. If you want to see; all available members, and not just the ones defined in the current class, in the; display options. They will be prefixed with the name of; the class they are defined in. Class Charts; The class charts are shown in a tabbed box; click on the names ontop to select a tab. Inheritance; This chart shows the inheritance hierarchy for the current class. Arrows point to; base classes. You can click the classes to get to their reference page. Inherited Members; The second chart shows a list of all members of all base classes. You can see at what; level they are defined or at what level they are defined. Members that are accessible; (public) have a green background, protected ones have a yellow background, and private; members have a red background. Members with a dark gray background are re-implemented; or hidden by a derived class. Includes; The Includes chart shows which files are indirectly included by including the class's; header. Most headers will #include some files, so by #including that header you also; #include the #included files, and so on. A illegible chart often means you should; read a bit on the C++ trick known as ""forward declaration"". Including too many headers; has some nasty consequences, like compile time, additional dependencies, etc. Libraries; Each class is assumed to be in a library. That library might depend on other libraries.; The fourth chart shows the dependencies of these libraries. You will need to link against; all of these if you write your own program. Member Function Documentation; Each function should be documented by the developer of the class. The documentation can; contain HTML, pictures, and example code. It should ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/etc/html/HELP.html:7324,green,green,7324,etc/html/HELP.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/etc/html/HELP.html,2,['green'],['green']
Energy Efficiency,"ou receive it, in any medium, provided that you; conspicuously and appropriately publish on each copy an appropriate; copyright notice and disclaimer of warranty; keep intact all the; notices that refer to this License and to the absence of any warranty;; and give any other recipients of the Program a copy of this License; along with the Program. You may charge a fee for the physical act of transferring a copy, and; you may at your option offer warranty protection in exchange for a fee. 2. You may modify your copy or copies of the Program or any portion; of it, thus forming a work based on the Program, and copy and; distribute such modifications or work under the terms of Section 1; above, provided that you also meet all of these conditions:. a) You must cause the modified files to carry prominent notices; stating that you changed the files and the date of any change. b) You must cause any work that you distribute or publish, that in; whole or in part contains or is derived from the Program or any; part thereof, to be licensed as a whole at no charge to all third; parties under the terms of this License. c) If the modified program normally reads commands interactively; when run, you must cause it, when started running for such; interactive use in the most ordinary way, to print or display an; announcement including an appropriate copyright notice and a; notice that there is no warranty (or else, saying that you provide; a warranty) and that users may redistribute the program under; these conditions, and telling the user how to view a copy of this; License. (Exception: if the Program itself is interactive but; does not normally print such an announcement, your work based on; the Program is not required to print an announcement.). These requirements apply to the modified work as a whole. If; identifiable sections of that work are not derived from the Program,; and can be reasonably considered independent and separate works in; themselves, then this License, and its ter",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt:5068,charge,charge,5068,misc/rootql/LICENSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt,4,['charge'],['charge']
Energy Efficiency,"oup. Advertisement; -------------. * Try to advertise via similar meetups/user groups; * Advertise your meetup on the mailing lists (llvm-dev, cfe-dev, lldb-dev,; ...). Feel free to post to all of them, or at least to llvm-dev.; But as these mailing lists have high traffic and some LLVM developers are not; very active on them, you may reach more interested people using the mailing; feature from meetup.com.; * Advertise the meetup on Twitter and mention; `@llvmweekly <http://twitter.com/llvmweekly>`_ and; `@llvmorg <http://twitter.com/llvmorg>`_.; * Announce the next meetup in advance, and remind in one week or so. Tech talks; ----------. * Itâ€™s a great idea to have several talks scheduled for several upcoming; meetups to get the ball rolling.; * Keep looking for speakers far in advance, ideally you should have 2-3; speakers ready in the pipeline.; * Try to record the talks if possible. It adds visibility to the meetup and; just a good idea in general. Any modern smartphone or tablet should work, but; you can also get a camera. Though, it is recommended to get an external; microphone for better sound. Where to host the meetup?; -------------------------. * Look around for bars/cafÃ© with projectors.; * Talk to tech companies in the area.; * Some co-working spaces provide their facilities for non-profit (i.e., you do; not charge attendees any fees) meetups.; * Ask nearby universities or university departments. How to pick the date?; ---------------------. * Make sure you do not clash with the similar meetups in the city (e.g.,; C++ user groups).; * Prefer not to have a meetup the same week when the other similar meetups; happen (e.g., itâ€™s not a good idea to have LLVM meetup on Thursday after; C++ meetup on Wednesday).; * Meetups on weekends may attract people who live far away from the city,; but the people who live in the city may not attend.; * Make a poll, but beware that not every responder will join (we had ~20 votes; on the poll, while only ~8 people attended). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst:2900,charge,charge,2900,interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MeetupGuidelines.rst,1,['charge'],['charge']
Energy Efficiency,"ource spectrum. The calling program should fill; in the input parameters of the `one_dim_fit` structure. The fitted parameters; are written into structure pointed by `one_dim_fit` structure pointer; and fitted data are written into source spectrum. Function parameters:. - **`source`**: pointer to the vector of the source spectrum; - **`p`**: pointer to the `one_dim_fit` structure pointer; - **`size`**: length of the source spectrum. The `one_dim_fit` structure has the form of. ``` {.cpp}; class TSpectrumOneDimFit{. public:. int number_of_peaks; // input parameter, should be >0; int number_of_iterations; // input parameter, should be >0; int xmin; // first fitted channel; int xmax; // last fitted channel; double alpha; // convergence coefficient, input parameter, it should be a positive number and <=1; double chi; // here the function returns the resulting chi-square; int statistic_type; // type of statistics, possible values are:; // FIT1_OPTIM_CHI_COUNTS (chi square statistics with counts as weighting coefficients),; // FIT1_OPTIM_CHI_FUNC_VALUES (chi square statistics with function values as weighting coefficients); // FIT1_OPTIM_MAX_LIKELIHOOD; int alpha_optim; // optimization of convergence coefficients, possible values are:; // FIT1_ALPHA_HALVING,; // FIT1_ALPHA_OPTIMAL; int power; // possible values FIT1_FIT_POWER2,4,6,8,10,12; int fit_taylor; // order of Taylor expansion, possible values; // FIT1_TAYLOR_ORDER_FIRST, FIT1_TAYLOR_ORDER_SECOND. double position_init[MAX_NUMBER_OF_PEAKS1]; // initial values of peaks positions, input parameters; double position_calc[MAX_NUMBER_OF_PEAKS1]; // calculated values of fitted positions, output parameters; double position_err[MAX_NUMBER_OF_PEAKS1]; // position errors; bool fix_position[MAX_NUMBER_OF_PEAKS1]; // logical vector which allows to fix appropriate positions (not fit). However they are present in the estimated functional; double amp_init[MAX_NUMBER_OF_PEAKS1]; // initial values of peaks amplitudes, input parameters",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:42162,power,power,42162,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['power'],['power']
Energy Efficiency,"ow code coverage only for functions with region coverage greater than the; given threshold. .. option:: -region-coverage-lt=<N>. Show code coverage only for functions with region coverage less than the given; threshold. .. option:: -path-equivalence=<from>,<to>. Map the paths in the coverage data to local source file paths. This allows you; to generate the coverage data on one machine, and then use llvm-cov on a; different machine where you have the same files on a different path. Multiple; `-path-equivalence` arguments can be passed to specify different mappings. Each; argument consists of a source path `<from>` and its corresponding local path `<to>`.; The mappings are applied in the order they are specified. If multiple mappings can; be applied to a single path, the first mapping encountered is used. .. option:: -coverage-watermark=<high>,<low>. Set high and low watermarks for coverage in html format output. This allows you; to set the high and low watermark of coverage as desired, green when; coverage >= high, red when coverage < low, and yellow otherwise. Both high and; low should be between 0-100 and high > low. .. option:: -debuginfod. Use debuginfod to look up coverage mapping for binary IDs present in the; profile but not in any object given on the command line. Defaults to true if; debuginfod is compiled in and configured via the DEBUGINFOD_URLS environment; variable. .. option:: -debug-file-directory=<dir>. Provides local directories to search for objects corresponding to binary IDs in; the profile (as with debuginfod). Defaults to system build ID directories. .. option:: -check-binary-ids. Fail if an object file cannot be found for a binary ID present in the profile,; neither on the command line nor via binary ID lookup. .. program:: llvm-cov report. .. _llvm-cov-report:. REPORT COMMAND; --------------. SYNOPSIS; ^^^^^^^^. :program:`llvm-cov report` [*options*] -instr-profile *PROFILE* [*BIN*] [*-object BIN*]... [*-sources*] [*SOURCE*]... DESCRIPTION; ^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst:12874,green,green,12874,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,1,['green'],['green']
Energy Efficiency,"ow; the fitted function corresponds much better to the experimental values. ![Fit of the original experimental spectrum (with background)](figures/image180.png). We have also implemented the fitting function with matrix inversion; based on Stiefel-Hestens method of the solution of the system of linear; equations. The form of the function is as follows:. ```{.cpp}; char *Fit1Stiefel(float *source,; TSpectrumOneDimFit* p,; int size);; ```. This function fits the source spectrum. The calling program should fill; in the input parameters of the `one_dim_fit` structure. The fitted parameters; are written into structure pointed by `one_dim_fit` structure pointer; and fitted data are written into source spectrum. Function parameters:. - **`source`**: pointer to the vector of the source spectrum; - **`p`**: pointer to the `one_dim_fit` structure pointer; - **`size`**: length of the source spectrum. The structure `one_dim_fit` is the same as in awmi function. The; parameters power, `fit_taylor`, are not applicable for this function. The results for small number of fitted parameters are the same as with; awmi function. However, it converges faster. The example for data given; in Figure 5.1 is given in the following table:. | # of iterations | Chi awmi | Chi-Stiefel |; | ---------------- | ---------| ------------ |; | 1 | 924 | 89.042 |; | 5 | 773.15 | 0.96242 |; | 10 | 38.13 | 0.77041 |; | 50 | 0.90293 | 0.76873 |; | 100 | 0.76886 | 0.76873 |; | 500 | 0.76873 | 0.76873 |. ## 2-DIMENSIONAL SPECTRA. It is straightforward that for two-dimensional spectra one can write. $$; \Delta a_k^{(t+1)}=\alpha^{(t)}; \frac; {\sum_{i_1=1}^{N_1}\sum_{i_2=1}^{N_2}\frac{e_{i_1,i_2}^{(t)}}{y_{i_1,i_2}}; \frac{\partial f(i_1,i_2,a^{(t)})}{\partial a_k}}; {\sum_{i_1=1}^{N_1}\sum_{i_2=1}^{N_2}; \left[\frac{\partial f(i_1,i_2,a^{(t)})}{\partial a_k} \right]^2; \frac{1}{y_{i_1,i_2}}}; $$. In a similar way, for two-dimensional peaks we have chosen the peak shape; function of the following form:. $$; f(i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:46525,power,power,46525,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['power'],['power']
Energy Efficiency,"owed. What effect do address spaces have on GEPs?; -------------------------------------------. None, except that the address space qualifier on the second operand pointer type; always matches the address space qualifier on the result type. How is GEP different from ``ptrtoint``, arithmetic, and ``inttoptr``?; ---------------------------------------------------------------------. It's very similar; there are only subtle differences. With ptrtoint, you have to pick an integer type. One approach is to pick i64;; this is safe on everything LLVM supports (LLVM internally assumes pointers are; never wider than 64 bits in many places), and the optimizer will actually narrow; the i64 arithmetic down to the actual pointer size on targets which don't; support 64-bit arithmetic in most cases. However, there are some cases where it; doesn't do this. With GEP you can avoid this problem. Also, GEP carries additional pointer aliasing rules. It's invalid to take a GEP; from one object, address into a different separately allocated object, and; dereference it. IR producers (front-ends) must follow this rule, and consumers; (optimizers, specifically alias analysis) benefit from being able to rely on; it. See the `Rules`_ section for more information. And, GEP is more concise in common cases. However, for the underlying integer computation implied, there is no; difference. I'm writing a backend for a target which needs custom lowering for GEP. How do I do this?; -----------------------------------------------------------------------------------------. You don't. The integer computation implied by a GEP is target-independent.; Typically what you'll need to do is make your backend pattern-match expressions; trees involving ADD, MUL, etc., which are what GEP is lowered into. This has the; advantage of letting your code work correctly in more cases. GEP does use target-dependent parameters for the size and layout of data types,; which targets can customize. If you require support for add",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:10418,allocate,allocated,10418,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['allocate'],['allocated']
Energy Efficiency,"own code to generate hierarchical structure in HTML, replace dtree.js which is; extremely slow for complex hierarchies. Dramatically improve performance for; structures with large (~1000) number of items.; 19. Deliver to the server title of the objects, display it as hint in the browser.; 20. Better handling of special characters in the hierarchies - allows to display; symbols like ' or "" in the file structure. ### July 2014; 1. Migration to d3.v3.js and jQuery v2.1.1; 2. Fix errors in filling of histogram statbox; 3. Possibility of move and resize of statbox, title, color palete; 4. Remove many (not all) global variables; 5. Example with direct usage of JSRootIO graphics; 6. Example of inserting ROOT graphics from THttpServer into `<iframe></iframe>`. ### May 2014; 1. This JSRootIO code together with THttpServer class included; in ROOT repository. ### March 2014; 1. Introduce TBuffer class, which plays similar role; as TBuffer in native ROOT I/O. Simplifies I/O logic,; reduce duplication of code in many places, fix errors.; Main advantage - one could try to keep code synchronous with C++.; 2. Avoid objects cloning when object referenced several times.; 3. Treat special cases (collection, arrays) in one place.; This is major advantage, while any new classes need to be implemented only once.; 4. Object representation, produced by JSRootIO is similar to; objects, produced by TBufferJSON class. By this one can exchange; I/O engine and use same JavaSctript graphic for display.; 5. More clear functions to display different elements of the file.; In the future functions should be fully separated from I/O part; and organized in similar way as online part.; 6. Eliminate usage of gFile pointer in the I/O part.; 7. Provide TBufferJSON::JsonWriteMember method. It allows to stream any; selected data member of the class. Supported are:; basic data types, arrays of basic data types, TString, TArray classes.; Also any object as data member can be streamed.; 8. TRootSniffer do not ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:76972,reduce,reduce,76972,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['reduce'],['reduce']
Energy Efficiency,"p-allocated). This means that ``QualType`` is exactly the same size as a; pointer. .. _DeclarationName:. Declaration names; -----------------. The ``DeclarationName`` class represents the name of a declaration in Clang.; Declarations in the C family of languages can take several different forms.; Most declarations are named by simple identifiers, e.g., ""``f``"" and ""``x``"" in; the function declaration ``f(int x)``. In C++, declaration names can also name; class constructors (""``Class``"" in ``struct Class { Class(); }``), class; destructors (""``~Class``""), overloaded operator names (""``operator+``""), and; conversion functions (""``operator void const *``""). In Objective-C,; declaration names can refer to the names of Objective-C methods, which involve; the method name and the parameters, collectively called a *selector*, e.g.,; ""``setWidth:height:``"". Since all of these kinds of entities --- variables,; functions, Objective-C methods, C++ constructors, destructors, and operators; --- are represented as subclasses of Clang's common ``NamedDecl`` class,; ``DeclarationName`` is designed to efficiently represent any kind of name. Given a ``DeclarationName`` ``N``, ``N.getNameKind()`` will produce a value; that describes what kind of name ``N`` stores. There are 10 options (all of; the names are inside the ``DeclarationName`` class). ``Identifier``. The name is a simple identifier. Use ``N.getAsIdentifierInfo()`` to retrieve; the corresponding ``IdentifierInfo*`` pointing to the actual identifier. ``ObjCZeroArgSelector``, ``ObjCOneArgSelector``, ``ObjCMultiArgSelector``. The name is an Objective-C selector, which can be retrieved as a ``Selector``; instance via ``N.getObjCSelector()``. The three possible name kinds for; Objective-C reflect an optimization within the ``DeclarationName`` class:; both zero- and one-argument selectors are stored as a masked; ``IdentifierInfo`` pointer, and therefore require very little space, since; zero- and one-argument selectors are far more",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:69115,efficient,efficiently,69115,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['efficient'],['efficiently']
Energy Efficiency,"p.step = 0.1;; gstep.destep = 0;; gstep.nmec = 0;; gstep.pid = 0;. //transport particles; for (Int_t i=0; i<10000; i++) {; //generate a new particle if necessary (Geant3 emulation); if (newParticle) {; px = gRandom->Gaus(0,.02);; py = gRandom->Gaus(0,.02);; pz = gRandom->Gaus(0,.02);; p = TMath::Sqrt(px*px+py*py+pz*pz);; charge = 1;; if (gRandom->Rndm() < 0.5) charge = -1;; gstep.pid += 1;; gstep.vect[0] = 0;; gstep.vect[1] = 0;; gstep.vect[2] = 0;; gstep.vect[3] = px/p;; gstep.vect[4] = py/p;; gstep.vect[5] = pz/p;; gstep.vect[6] = p*charge;; gstep.getot = TMath::Sqrt(p*p + mass*mass);; gstep.gekin = gstep.getot - mass;; newParticle = kFALSE;; }; // fill the Tree with current step parameters; t2.Fill();. //transport particle in magnetic field (Geant3 emulation); helixStep(gstep.step, gstep.vect, vout);; //make one step; //apply energy loss; gstep.destep = gstep.step*gRandom->Gaus(0.0002,0.00001);; gstep.gekin -= gstep.destep;; gstep.getot = gstep.gekin + mass;; gstep.vect[6]= charge*TMath::Sqrt(gstep.getot*gstep.getot; - mass*mass);; gstep.vect[0] = vout[0];; gstep.vect[1] = vout[1];; gstep.vect[2] = vout[2];; gstep.vect[3] = vout[3];; gstep.vect[4] = vout[4];; gstep.vect[5] = vout[5];; gstep.nmec = (Int_t)(5*gRandom->Rndm());; for (Int_t l=0; l<gstep.nmec; l++) gstep.lmec[l] = l;; if (gstep.gekin < 0.001) newParticle = kTRUE;; if (TMath::Abs(gstep.vect[2]) > 30) newParticle = kTRUE;; }; //save the Tree header. The file will be automatically; // closed when going out of the function scope; t2.Write();; }; ```. #### Adding a Branch with a Fixed Length Array. At first, we create a tree and create branches for a subset of variables; in the C structure` Gctrak_t`. Then we add several types of branches.; The first branch reads seven floating-point values beginning at the; address of `'gstep.vect'`. You do not need to specify `&gstep.vect`,; because in C and C++ the array variable holds the address of the first; element. ``` {.cpp}; t2.Branch(""vect"",gstep.vect,""vect[7]/F",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:47215,charge,charge,47215,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['charge'],['charge']
Energy Efficiency,"p; serv->RegisterCommand(""/Process"", ""%arg1%"");; ```. When registering command, one could specify icon name which will be displayed with the command. ```cpp; serv->RegisterCommand(""/DoSomething"", ""SomeFunction()"", ""rootsys/icons/ed_execute.png"");; ```. In example usage of images from `$ROOTSYS/icons` directory is shown. One could prepend `button;`; string to the icon name to let browser show command as extra button. In last case one could hide command element from elements list:. ```cpp; serv->Hide(""/DoSomething"");; ```. One can find example of command interface usage in [tutorials/http/httpcontrol.C](https://github.com/root-project/root/blob/master/tutorials/http/httpcontrol.C) macro. ## Customize user interface. JSROOT is used to implement UI for the THttpServer. Default webpage shows list of registered objects on the left side and drawing area on the right side - [see example](https://root.cern/js/latest/httpserver.C/). JSROOT allows to configure different parameters via URL - like monitoring interval or name of displayed items [item=Files/job1.root/hpxpy&opt=colz&monitoring=1000](https://root.cern/js/latest/httpserver.C/?item=Files/job1.root/hpxpy&opt=colz&monitoring=1000). Some of such parameters can be configured already on the server:. ```cpp; serv->SetItemField(""/"", ""_monitoring"", ""1000""); // monitoring interval in ms; serv->SetItemField(""/"", ""_drawitem"", ""Files/job1.root/hpxpy""); // item to draw; serv->SetItemField(""/"", ""_drawopt"", ""colz"");; ```. In such case URL parameters are not required - specified item will be displayed automatically when web page is opened.; One also can configure to display several items at once. For that one also can configure layout of the drawing area:. ```cpp; serv->SetItemField(""/"", ""_layout"", ""grid2x2""); // layout for drawing area; serv->SetItemField(""/"", ""_drawitem"", ""[Files/job1.root/hpxpy,Files/job1.root/hpx]""); // items; serv->SetItemField(""/"", ""_drawopt"", ""[colz,hist]""); // options; ```. One also can change appearance of h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:6648,monitor,monitoring,6648,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['monitor'],['monitoring']
Energy Efficiency,"pace overhead for; instructions and bit vectors and increased overhead in the form of padding. We; therefore limit the amount of padding so that we align to no more than 128; bytes. This number was found experimentally to provide a good tradeoff. Eliminating Bit Vector Checks for All-Ones Bit Vectors; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If the bit vector is all ones, the bit vector check is redundant; we simply; need to check that the address is in range and well aligned. This is more; likely to occur if the virtual tables are padded. Forward-Edge CFI for Virtual Calls by Interleaving Virtual Tables; -----------------------------------------------------------------. Dimitar et. al. proposed a novel approach that interleaves virtual tables in [1]_.; This approach is more efficient in terms of space because padding and bit vectors are no longer needed.; At the same time, it is also more efficient in terms of performance because in the interleaved layout; address points of the virtual tables are consecutive, thus the validity check of a virtual; vtable pointer is always a range check. At a high level, the interleaving scheme consists of three steps: 1) split virtual table groups into; separate virtual tables, 2) order virtual tables by a pre-order traversal of the class hierarchy; and 3) interleave virtual tables. The interleaving scheme implemented in LLVM is inspired by [1]_ but has its own; enhancements (more in `Interleave virtual tables`_). .. [1] `Protecting C++ Dynamic Dispatch Through VTable Interleaving <https://cseweb.ucsd.edu/~lerner/papers/ivtbl-ndss16.pdf>`_. Dimitar Bounov, Rami GÃ¶khan KÄ±cÄ±, Sorin Lerner. Split virtual table groups into separate virtual tables; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. The Itanium C++ ABI glues multiple individual virtual tables for a class into a combined virtual table (virtual table group).; The interleaving scheme, however, can only work with individual virtual tables so it must split",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:9894,efficient,efficient,9894,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['efficient'],['efficient']
Energy Efficiency,"pace; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. For example:. ::. ADD8rr -> add, 8-bit register, 8-bit register; IMUL16rmi -> imul, 16-bit register, 16-bit memory, 16-bit immediate; IMUL16rmi8 -> imul, 16-bit register, 16-bit memory, 8-bit immediate; MOVSX32rm16 -> movsx, 32-bit register, 16-bit memory. The PowerPC backend; -------------------. The PowerPC code generator lives in the lib/Target/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:93320,allocate,allocate,93320,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['allocate'],['allocate']
Energy Efficiency,"package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject gene",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4668,Adapt,AdaptiveIntegratorMultiDim,4668,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,1,['Adapt'],['AdaptiveIntegratorMultiDim']
Energy Efficiency,"pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the scheduling model isn't always a viable; option though (maybe because the instruction is modeled incorrectly on; purpose or the instruction's behaviour is quite complex). The; CustomBehaviour class can be used in these cases to enforce proper; instruction modeling (often by customizing data dependencies and detecting; hazards that :program:`llvm-mca` has no way of knowing about). :program:`llvm-mca` comes with one generic and multiple target specific; CustomBehaviour classes. The generic class will be used if the ``-disable-cb``; flag is used or if a target specific CustomBehaviour class doesn't exist for; that target. (The generic class does nothing.) Currently, the CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:43986,schedul,scheduling,43986,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"peJIT class is a simple JIT built specifically for these; tutorials, available inside the LLVM source code; at `llvm-src/examples/Kaleidoscope/include/KaleidoscopeJIT.h; <https://github.com/llvm/llvm-project/blob/main/llvm/examples/Kaleidoscope/include/KaleidoscopeJIT.h>`_.; In later chapters we will look at how it works and extend it with; new features, but for now we will take it as given. Its API is very simple:; ``addModule`` adds an LLVM IR module to the JIT, making its functions; available for execution (with its memory managed by a ``ResourceTracker``); and; ``lookup`` allows us to look up pointers to the compiled code. We can take this simple API and change our code that parses top-level expressions to; look like this:. .. code-block:: c++. static ExitOnError ExitOnErr;; ...; static void HandleTopLevelExpression() {; // Evaluate a top-level expression into an anonymous function.; if (auto FnAST = ParseTopLevelExpr()) {; if (FnAST->codegen()) {; // Create a ResourceTracker to track JIT'd memory allocated to our; // anonymous expression -- that way we can free it after executing.; auto RT = TheJIT->getMainJITDylib().createResourceTracker();. auto TSM = ThreadSafeModule(std::move(TheModule), std::move(TheContext));; ExitOnErr(TheJIT->addModule(std::move(TSM), RT));; InitializeModuleAndPassManager();. // Search the JIT for the __anon_expr symbol.; auto ExprSymbol = ExitOnErr(TheJIT->lookup(""__anon_expr""));; assert(ExprSymbol && ""Function not found"");. // Get the symbol's address and cast it to the right type (takes no; // arguments, returns a double) so we can call it as a native function.; double (*FP)() = ExprSymbol.getAddress().toPtr<double (*)()>();; fprintf(stderr, ""Evaluated to %f\n"", FP());. // Delete the anonymous expression module from the JIT.; ExitOnErr(RT->remove());; }. If parsing and codegen succeed, the next step is to add the module containing; the top-level expression to the JIT. We do this by calling addModule, which; triggers code generation fo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:12841,allocate,allocated,12841,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['allocate'],['allocated']
Energy Efficiency,"pecific overload is selected, then use the; ``__overload__`` method to match a specific function signature.; An optional boolean second parameter can be used to restrict the selected; method to be const (if ``True``) or non-const (if ``False``).; The return value of which is a first-class callable object, that can be; stored to by-pass the overload resolution:. .. code-block:: python. >>> gf_double = global_function.__overload__('double'); >>> gf_double(1) # int implicitly promoted; 2.718281828459045; >>>. The ``__overload__`` method only does a lookup; it performs no (implicit); conversions and the types in the signature to match should be the fully; resolved ones (no typedefs).; To see all overloads available for selection, use ``help()`` on the function; or look at its ``__doc__`` string:. .. code-block:: python. >>> print(global_function.__doc__); int ::global_function(int); double ::global_function(double); >>>. For convenience, the ``:any:`` signature allows matching any overload, for; example to reduce a method to its ``const`` overload only, use:. .. code-block:: python. MyClass.some_method = MyClass.some_method.__overload__(':any:', True). `Overloads and exceptions`; --------------------------. Python error reporting is done using exceptions.; Failed argument conversion during overload resolution can lead to different; types of exceptions coming from respective attempted overloads.; The final error report issued if all overloads fail, is a summary of the; individual errors, but by Python language requirements it has to have a; single exception type.; If all the exception types match, that type is used, but if there is an; amalgam of types, the exception type chosen will be ``TypeError``.; For example, attempting to pass a too large value through ``uint8_t`` will; uniquely raise a ``ValueError``. .. code-block:: python. >>> cppyy.cppdef(""void somefunc(uint8_t) {}""); True; >>> cppyy.gbl.somefunc(2**16); Traceback (most recent call last):; File ""<stdin>"", line ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:9939,reduce,reduce,9939,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,1,['reduce'],['reduce']
Energy Efficiency,"pendentSizedArrayTypeMatcher<DependentSizedArrayType>...; Matches C++ arrays whose size is a value-dependent expression. Given; template<typename T, int Size>; class array {; T data[Size];; };; dependentSizedArrayType(); matches ""T data[Size]"". Matcher<Type>dependentSizedExtVectorTypeMatcher<DependentSizedExtVectorType>...; Matches C++ extended vector type where either the type or size is; dependent. Given; template<typename T, int Size>; class vector {; typedef T __attribute__((ext_vector_type(Size))) type;; };; dependentSizedExtVectorType(); matches ""T __attribute__((ext_vector_type(Size)))"". Matcher<Type>elaboratedTypeMatcher<ElaboratedType>...; Matches types specified with an elaborated type keyword or with a; qualified name. Given; namespace N {; namespace M {; class D {};; }; }; class C {};. class C c;; N::M::D d;. elaboratedType() matches the type of the variable declarations of both; c and d. Matcher<Type>enumTypeMatcher<EnumType>...; Matches enum types. Given; enum C { Green };; enum class S { Red };. C c;; S s;. enumType() matches the type of the variable declarations of both c and; s. Matcher<Type>functionProtoTypeMatcher<FunctionProtoType>...; Matches FunctionProtoType nodes. Given; int (*f)(int);; void g();; functionProtoType(); matches ""int (*f)(int)"" and the type of ""g"" in C++ mode.; In C mode, ""g"" is not matched because it does not contain a prototype. Matcher<Type>functionTypeMatcher<FunctionType>...; Matches FunctionType nodes. Given; int (*f)(int);; void g();; functionType(); matches ""int (*f)(int)"" and the type of ""g"". Matcher<Type>incompleteArrayTypeMatcher<IncompleteArrayType>...; Matches C arrays with unspecified size. Given; int a[] = { 2, 3 };; int b[42];; void f(int c[]) { int d[a[0]]; };; incompleteArrayType(); matches ""int a[]"" and ""int c[]"". Matcher<Type>injectedClassNameTypeMatcher<InjectedClassNameType>...; Matches injected class name types. Example matches S s, but not S<T> s.; (matcher = parmVarDecl(hasType(injectedClassNameType())));",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:47908,Green,Green,47908,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['Green'],['Green']
Energy Efficiency,"per functions are:. .. code-block:: c. /* Certain field types require runtime assistance when being copied to the; heap. The following function is used to copy fields of types: blocks,; pointers to byref structures, and objects (including; __attribute__((NSObject)) pointers. BLOCK_FIELD_IS_WEAK is orthogonal to; the other choices which are mutually exclusive. Only in a Block copy; helper will one see BLOCK_FIELD_IS_BYREF.; */; void _Block_object_assign(void *destAddr, const void *object, const int flags);. /* Similarly a compiler generated dispose helper needs to call back for each; field of the byref data structure. (Currently the implementation only; packs one field into the byref structure but in principle there could be; more). The same flags used in the copy helper should be used for each; call generated to this function:; */; void _Block_object_dispose(const void *object, const int flags);. Copyright; =========. Copyright 2008-2010 Apple, Inc.; Permission is hereby granted, free of charge, to any person obtaining a copy; of this software and associated documentation files (the ""Software""), to deal; in the Software without restriction, including without limitation the rights; to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; copies of the Software, and to permit persons to whom the Software is; furnished to do so, subject to the following conditions:. The above copyright notice and this permission notice shall be included in; all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; THE SOFTWARE.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst:30532,charge,charge,30532,interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,1,['charge'],['charge']
Energy Efficiency,"perand is known unretained or known; retain-agnostic, the conversion is treated as a ``__bridge`` cast. .. admonition:: Rationale. Bridging casts are annoying. Absent the ability to completely automate the; management of CF objects, however, we are left with relatively poor attempts; to reduce the need for a glut of explicit bridges. Hence these rules. We've so far consciously refrained from implicitly turning retained CF; results from function calls into ``__bridge_transfer`` casts. The worry is; that some code patterns --- for example, creating a CF value, assigning it; to an ObjC-typed local, and then calling ``CFRelease`` when done --- are a; bit too likely to be accidentally accepted, leading to mysterious behavior. For loads from ``const`` global variables of :ref:`C retainable pointer type; <arc.misc.c-retainable>`, it is reasonable to assume that global system; constants were initialized with true constants (e.g. string literals), but; user constants might have been initialized with something dynamically; allocated, using a global initializer. .. _arc.objects.restrictions.conversion-exception-contextual:. Conversion from retainable object pointer type in certain contexts; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. :when-revised:`[beginning Apple 4.0, LLVM 3.1]`. If an expression of retainable object pointer type is explicitly cast to a; :ref:`C retainable pointer type <arc.misc.c-retainable>`, the program is; ill-formed as discussed above unless the result is immediately used:. * to initialize a parameter in an Objective-C message send where the parameter; is not marked with the ``cf_consumed`` attribute, or; * to initialize a parameter in a direct call to an; :ref:`audited <arc.misc.c-retainable.audit>` function where the parameter is; not marked with the ``cf_consumed`` attribute. .. admonition:: Rationale. Consumed parameters are left out because ARC would naturally balance them; with a retain, which was judged too treacherous. Thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:29064,allocate,allocated,29064,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['allocate'],['allocated']
Energy Efficiency,"perimental.constrained.powi``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.experimental.constrained.powi(<type> <op1>, i32 <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.powi``' intrinsic returns the first operand; raised to the (positive or negative) power specified by the second operand. The; order of evaluation of multiplications is not defined. When a vector of; floating-point type is used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The first argument and the return value are floating-point numbers of the same; type. The second argument is a 32-bit signed integer specifying the power to; which the first argument should be raised. The third and fourth arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.experimental.constrained.ldexp``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type0>; @llvm.experimental.constrained.ldexp(<type0> <op1>, <type1> <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.ldexp``' performs the ldexp function. Arguments:; """""""""""""""""""". The first argument and the return value are :ref:`floating-point; <t_floating>` or :ref:`vector <t_vector>` of floating-point values of; the same type. The second argument is an integer with the same number; of elements. The third and fourth arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function multiplies the first argument by 2 raised to the second; argument's power. If the first argument is NaN or infinite, the same; value is returned. If the result underflows a zero with the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:892848,power,power,892848,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"perimental.constrained.sqrt``' intrinsic returns the square root; of the specified value, returning the same value as the libm '``sqrt``'; functions would, but without setting ``errno``. Arguments:; """""""""""""""""""". The first argument and the return type are floating-point numbers of the same; type. The second and third arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function returns the nonnegative square root of the specified value.; If the value is less than negative zero, a floating-point exception occurs; and the return value is architecture specific. '``llvm.experimental.constrained.pow``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.experimental.constrained.pow(<type> <op1>, <type> <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.pow``' intrinsic returns the first operand; raised to the (positive or negative) power specified by the second operand. Arguments:; """""""""""""""""""". The first two arguments and the return value are floating-point numbers of the; same type. The second argument specifies the power to which the first argument; should be raised. The third and fourth arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power,; returning the same values as the libm ``pow`` functions would, and; handles error conditions in the same way. '``llvm.experimental.constrained.powi``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.experimental.constrained.powi(<type> <op1>, i32 <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.powi``' intrinsic returns the first operand; raised to the (positive or negative) power specified by the second op",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:891294,power,power,891294,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"pick one. The first step is a choose your own adventure: do you want a sequential; container, a set-like container, or a map-like container? The most important; thing when choosing a container is the algorithmic properties of how you plan to; access the container. Based on that, you should use:. * a :ref:`map-like <ds_map>` container if you need efficient look-up of a; value based on another value. Map-like containers also support efficient; queries for containment (whether a key is in the map). Map-like containers; generally do not support efficient reverse mapping (values to keys). If you; need that, use two maps. Some map-like containers also support efficient; iteration through the keys in sorted order. Map-like containers are the most; expensive sort, only use them if you need one of these capabilities. * a :ref:`set-like <ds_set>` container if you need to put a bunch of stuff into; a container that automatically eliminates duplicates. Some set-like; containers support efficient iteration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not support; efficient look-up based on a key. * a :ref:`string <ds_string>` container is a specialized sequential container or; reference structure that is used for character or byte arrays. * a :ref:`bit <ds_bit>` container provides an efficient way to store and; perform set operations on sets of numeric id's, while automatically; eliminating duplicates. Bit containers require a maximum of 1 bit for each; identifier you want to store. Once the proper category of container is determined, you can fine tune the; memory use, constant factors, and cache behaviors of access by intelligently; picking a member of the category. Note that constant factors and c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:56034,efficient,efficient,56034,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"ping. Specifically, it can delete:. #. names for virtual registers; #. symbols for internal globals and functions; #. debug information. Note that this transformation makes code much less readable, so it should only; be used in situations where the 'strip' utility would be used, such as reducing; code size or making it harder to reverse engineer code. ``tailcallelim``: Tail Call Elimination; ---------------------------------------. This file transforms calls of the current function (self recursion) followed by; a return instruction with a branch to the entry of the function, creating a; loop. This pass also implements the following extensions to the basic; algorithm:. #. Trivial instructions between the call and return do not prevent the; transformation from taking place, though currently the analysis cannot; support moving any really useful instructions (only dead ones).; #. This pass transforms functions that are prevented from being tail recursive; by an associative expression to use an accumulator variable, thus compiling; the typical naive factorial or fib implementation into efficient code.; #. TRE is performed if the function returns void, if the return returns the; result returned by the call, or if the function returns a run-time constant; on all exits from the function. It is possible, though unlikely, that the; return returns something else (like constant 0), and can still be TRE'd. It; can be TRE'd if *all other* return instructions in the function return the; exact same value.; #. If it can prove that callees do not access their caller stack frame, they; are marked as eligible for tail call elimination (by the code generator). Utility Passes; ==============. This section describes the LLVM Utility Passes. ``deadarghaX0r``: Dead Argument Hacking (BUGPOINT USE ONLY; DO NOT USE); -----------------------------------------------------------------------. Same as dead argument elimination, but deletes arguments to functions which are; external. This is only for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:39359,efficient,efficient,39359,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['efficient'],['efficient']
Energy Efficiency,"placing the creation of a `ROOT::Math::GaussIntegrator` object with `ROOT::Math::GaussLegendreIntegrator`. #### ROOT::Math::GSLIntegrator. This is a wrapper for the *QUADPACK* integrator implemented in the GSL library. It supports several integration methods that can be chosen in construction time.; The default type is adaptive integration with singularity applying a Gauss-Kronrod 21-point integration rule. For a detail description of the GSL methods visit the GSL user guide; This class implements the best algorithms for numerical integration for one dimensional functions. We encourage the use it as the main option, bearing in mind that it uses code from the; GSL library, wich is provided in the *MathMore* library of ROOT. The interface to use is the same as above. We have now the possibility to specify a different integration algorithm in the constructor of the `ROOT::Math::GSLIntegrator` class.; ```{.cpp}; // create the adaptive integrator with the 51 point rule; ROOT::Math::GSLIntegrator ig(ROOT::Math::Integration::kADAPTIVE, ROOT::Math::Integration::kGAUSS51);; ig.SetRelTolerance(1.E-6); // set relative tolerance; ig.SetAbsTolerance(1.E-6); // set absoulte tolerance; ```. The algorithm is controlled by the given absolute and relative tolerance. The iterations are continued until the following condition is satisfied; $$; absErr <= max ( epsAbs, epsRel * Integral); $$; Where *absErr* is an estimate of the absolute error (it can be retrieved with `GSLIntegrator::Error()`) and *Integral* is the estimate of the function integral; (it can be obtained with `GSLIntegrator::Result()`). The possible integration algorithm types to use with the GSLIntegrator are the following. More information is provided in the `GSL` users documentation.; * `ROOT::Math::Integration::kNONADAPTIVE` : based on `gsl_integration_qng`. It is a non-adaptive procedure which uses fixed Gauss-Kronrod-Patterson abscissae; to sample the integrand at a maximum of 87 points. It is provided for fast integ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:55378,adapt,adaptive,55378,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['adapt'],['adaptive']
Energy Efficiency,"plement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5436,adapt,adaptively,5436,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,4,"['adapt', 'efficient']","['adaptively', 'efficient']"
Energy Efficiency,"pop.i8(i8 %MaskI); %MaskI64 = zext i8 %MaskIPopcnt to i64; %BNextInd = add i64 %BInd, %MaskI64. Other targets may support this intrinsic differently, for example, by lowering it into a sequence of branches that guard scalar store operations. Memory Use Markers; ------------------. This class of intrinsics provides information about the; :ref:`lifetime of memory objects <objectlifetime>` and ranges where variables; are immutable. .. _int_lifestart:. '``llvm.lifetime.start``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.lifetime.start(i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.lifetime.start``' intrinsic specifies the start of a memory; object's lifetime. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is variable sized. The second argument is a pointer; to the object. Semantics:; """""""""""""""""""". If ``ptr`` is a stack-allocated object and it points to the first byte of; the object, the object is initially marked as dead.; ``ptr`` is conservatively considered as a non-stack-allocated object if; the stack coloring algorithm that is used in the optimization pipeline cannot; conclude that ``ptr`` is a stack-allocated object. After '``llvm.lifetime.start``', the stack object that ``ptr`` points is marked; as alive and has an uninitialized value.; The stack object is marked as dead when either; :ref:`llvm.lifetime.end <int_lifeend>` to the alloca is executed or the; function returns. After :ref:`llvm.lifetime.end <int_lifeend>` is called,; '``llvm.lifetime.start``' on the stack object can be called again.; The second '``llvm.lifetime.start``' call marks the object as alive, but it; does not change the address of the object. If ``ptr`` is a non-stack-allocated object, it does not point to the first; byte of the object or it is a stack object that is already alive, it simply; fills all bytes of the object with ``poison``. .. _int_lifeend:. '``llvm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:861534,allocate,allocated,861534,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"port TGaxis; 14. Project now can be obtained via 'bower install jsroot'; 15. Support 'scat' and 'text' draw options for TH2; 16. Support in binary I/O zipped buffer bigger than 16M; 17. Correctly handle in binary I/O pointer on TArray object (like in THnSparseArrayChunk). ## Changes in 4.3; 1. Implement TGeoCtub, TGeoParaboloid and TGeoHype shapes; 2. Support TGeoTube with Rmin==0; 3. Exclude empty faces in TGeoArb8; 4. Improve TGeoSphere creation - handle all parameters combinations; 5. Introduce JSROOT.cleanup() function to safely clear all drawn objects; 6. Fix wrong resize method in 'tabs' and 'collapsible' layouts; 7. Fix canvas resize problem (issue #27); 8. Fix zero-height canvas when draw TGeo in collapsible layout; 9. Fix problem of simultaneous move TGeo drawings and canvas in flexible layout. ## Changes in 4.2; 1. Significant performance improvements in 3D drawings - TGeo/TH2/TH3; 2. Implement TGeoPara, TGeoGtra, TGeoXtru and TGeoEltu shapes; 3. Optimize (reduce vertices number) for others TGeo shapes; 4. Correct rotation/translation/scaling of TGeo nodes; 5. Workaround for axis reflection (not directly supported in three.js); 6. Support array of objects in I/O (like in TAxis3D); 7. Correct reading of multi-dim arrays like Double_t fXY[8][2];; 8. Provide canvas toolbar for actions like savepng or unzoom; 9. Implement JSROOT.resize() function to let resize drawing after changes in page layout; 10. Fix error with title display/update. ## Changes in 4.1; 1. Introduce object inspector - one could browse object members of any class; 2. Let draw sub-items from TCanvas list of primitives like sub-pad or TLatex; 3. Provide possibility to save drawn SVG canvas as PNG; 4. TGraph drawing optimization - limit number of drawn points; 5. Implement painter for TPolyMarker3D; 6. Improve drawing and update of TMultiGraph; 7. Reorganize 3D drawing of TH2/TH3 histograms, allow to mix 2D and 3D display together; 8. Support overlay of 3D graphic over SVG canvas (used for IE); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:58368,reduce,reduce,58368,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['reduce'],['reduce']
Energy Efficiency,"port of the embedded; profile.; From clang 9 a C++ mode is available for OpenCL (see; :ref:`C++ for OpenCL <cxx_for_opencl>`). OpenCL v3.0 support is complete but it remains in experimental state, see more; details about the experimental features and limitations in :doc:`OpenCLSupport`; page. OpenCL Specific Options; -----------------------. Most of the OpenCL build options from `the specification v2.0 section 5.8.4; <https://www.khronos.org/registry/cl/specs/opencl-2.0.pdf#200>`_ are available. Examples:. .. code-block:: console. $ clang -cl-std=CL2.0 -cl-single-precision-constant test.cl. Many flags used for the compilation for C sources can also be passed while; compiling for OpenCL, examples: ``-c``, ``-O<1-4|s>``, ``-o``, ``-emit-llvm``, etc. Some extra options are available to support special OpenCL features. .. option:: -cl-no-stdinc. Allows to disable all extra types and functions that are not native to the compiler.; This might reduce the compilation speed marginally but many declarations from the; OpenCL standard will not be accessible. For example, the following will fail to; compile. .. code-block:: console. $ echo ""bool is_wg_uniform(int i){return get_enqueued_local_size(i)==get_local_size(i);}"" > test.cl; $ clang -cl-std=CL2.0 -cl-no-stdinc test.cl; error: use of undeclared identifier 'get_enqueued_local_size'; error: use of undeclared identifier 'get_local_size'. More information about the standard types and functions is provided in :ref:`the; section on the OpenCL Header <opencl_header>`. .. _opencl_cl_ext:. .. option:: -cl-ext. Enables/Disables support of OpenCL extensions and optional features. All OpenCL; targets set a list of extensions that they support. Clang allows to amend this using; the ``-cl-ext`` flag with a comma-separated list of extensions prefixed with; ``'+'`` or ``'-'``. The syntax: ``-cl-ext=<(['-'|'+']<extension>[,])+>``, where; extensions can be either one of `the OpenCL published extensions; <https://www.khronos.org/registry/Ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:143100,reduce,reduce,143100,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduce']
Energy Efficiency,"portant to which multilib; selection flags Clang generates from command line options. Once a flag is; generated by a released version of Clang it may be used in ``multilib.yaml``; files that exist independently of the LLVM release cycle, and therefore; ceasing to generate the flag would be a breaking change and should be; avoided. However, an exception is the normalization of ``-march``.; ``-march`` for Arm architectures contains a list of enabled and disabled; extensions and this list is likely to grow. Therefore ``-march`` flags are; unstable. Incomplete interface; --------------------. The new multilib system does multilib selection based on only a limited set of; command line options, and limits which flags can be used for multilib; selection. This is in order to avoid committing to too large an interface.; Later LLVM versions can add support for multilib selection from more command; line options as needed. Extensible; ----------. It is likely that the configuration format will need to evolve in future to; adapt to new requirements.; Using a format like YAML that supports key-value pairs helps here as it's; trivial to add new keys alongside existing ones. Backwards compatibility; -----------------------. New versions of Clang should be able to use configuration written for earlier; Clang versions.; To avoid behaving in a way that may be subtly incorrect, Clang should be able; to detect if the configuration is too new and emit an error. Forwards compatibility; ----------------------. As an author of a multilib configuration, it should be possible to design the; configuration in such a way that it is likely to work well with future Clang; versions. For example, if a future version of Clang is likely to add support; for newer versions of an architecture and the architecture is known to be; designed for backwards compatibility then it should be possible to express; compatibility for such architecture versions in the multilib configuration. Not GNU spec files; ------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:10649,adapt,adapt,10649,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['adapt'],['adapt']
Energy Efficiency,"portions of the program that as they are excluded from the testcase.; These options allow you to choose the; static native code compiler, or a custom command, (see **--exec-command**); respectively. The interpreter and the JIT backends cannot currently; be used as the ""safe"" backends. **--exec-command** *command*. This option defines the command to use with the **--run-custom** and; **--safe-custom** options to execute the bitcode testcase. This can; be useful for cross-compilation. **--compile-command** *command*. This option defines the command to use with the **--compile-custom**; option to compile the bitcode testcase. The command should exit with a; failure exit code if the file is ""interesting"" and should exit with a; success exit code (i.e. 0) otherwise (this is the same as if it crashed on; ""interesting"" inputs). This can be useful for; testing compiler output without running any link or execute stages. To; generate a reduced unit test, you may add CHECK directives to the; testcase and pass the name of an executable compile-command script in this form:. .. code-block:: sh. #!/bin/sh; llc ""$@""; not FileCheck [bugpoint input file].ll < bugpoint-test-program.s. This script will ""fail"" as long as FileCheck passes. So the result; will be the minimum bitcode that passes FileCheck. **--safe-path** *path*. This option defines the path to the command to execute with the; **--safe-{int,jit,llc,custom}**; option. **--verbose-errors**\ =\ *{true,false}*. The default behavior of bugpoint is to print ""<crash>"" when it finds a reduced; test that crashes compilation. This flag prints the output of the crashing; program to stderr. This is useful to make sure it is the same error being; tracked down and not a different error that happens to crash the compiler as; well. Defaults to false. EXIT STATUS; -----------. If **bugpoint** succeeds in finding a problem, it will exit with 0. Otherwise,; if an error occurs, it will exit with a non-zero value. SEE ALSO; --------. :manpage:`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:5663,reduce,reduced,5663,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,1,['reduce'],['reduced']
Energy Efficiency,"positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a **`TBrowser`**) held; by the manager class will be filled with **`TGeoOverlap`** objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing both candidate node names and a letter; (x-extrusion, o-overlap) representing the type. Double-clicking an; overlap item in a **`TBrowser`** produces a picture of the overlap; containing only the two overlapping nodes (one in blue and one in green); and having the critical vertices represented by red points. The picture; can be rotated/zoomed or drawn in X3d as any other view. Calling; `gGeoManager->PrintOverlaps()` prints the list of overlaps. ### Graphical Checking Methods. ![Safety computation checking](pictures/030001E0.png). In order to check a given point, `CheckPoint(x,y,z)` method of; **`TGeoManager`** draws the daughters of the volume containing the point; one level down, printing the path to the deepest physical node holding; this point. It also computes the closest distance to any boundary. ![Random points](pictures/030001E1.png). A method to check the validity of a given geometry is shooting random; points. This can be called with the method; **`TGeoVolume`**`::RandomPoints()` and it draws a volume with the current; visualization settings. Random points are generated in the bounding box; of the drawn volume. The points are drawn with the color of their; deepest contai",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:135058,green,green,135058,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['green'],['green']
Energy Efficiency,pp; llvm/tools/llvm-pdbutil/PrettyTypeDumper.cpp; llvm/tools/llvm-pdbutil/TypeReferenceTracker.h; llvm/tools/llvm-pdbutil/YAMLOutputStyle.h; llvm/tools/llvm-profgen/CallContext.h; llvm/tools/llvm-profgen/CSPreInliner.cpp; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h;,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337139,reduce,reduce,337139,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"ppear at fixed offsets within the virtual table, this normally; has the effect of aligning the address points as well. This scheme introduces tradeoffs between decreased space overhead for; instructions and bit vectors and increased overhead in the form of padding. We; therefore limit the amount of padding so that we align to no more than 128; bytes. This number was found experimentally to provide a good tradeoff. Eliminating Bit Vector Checks for All-Ones Bit Vectors; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If the bit vector is all ones, the bit vector check is redundant; we simply; need to check that the address is in range and well aligned. This is more; likely to occur if the virtual tables are padded. Forward-Edge CFI for Virtual Calls by Interleaving Virtual Tables; -----------------------------------------------------------------. Dimitar et. al. proposed a novel approach that interleaves virtual tables in [1]_.; This approach is more efficient in terms of space because padding and bit vectors are no longer needed.; At the same time, it is also more efficient in terms of performance because in the interleaved layout; address points of the virtual tables are consecutive, thus the validity check of a virtual; vtable pointer is always a range check. At a high level, the interleaving scheme consists of three steps: 1) split virtual table groups into; separate virtual tables, 2) order virtual tables by a pre-order traversal of the class hierarchy; and 3) interleave virtual tables. The interleaving scheme implemented in LLVM is inspired by [1]_ but has its own; enhancements (more in `Interleave virtual tables`_). .. [1] `Protecting C++ Dynamic Dispatch Through VTable Interleaving <https://cseweb.ucsd.edu/~lerner/papers/ivtbl-ndss16.pdf>`_. Dimitar Bounov, Rami GÃ¶khan KÄ±cÄ±, Sorin Lerner. Split virtual table groups into separate virtual tables; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. The Itanium C++ ABI glues multiple individual virtua",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:9777,efficient,efficient,9777,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['efficient'],['efficient']
Energy Efficiency,"presenting the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this table. In the case of AMD; Jaguar, there are two register files, one for floating-point registers (JFpuPRF); and one for integer regist",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:32133,schedul,scheduler,32133,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"pression for the selector ``dealloc``. .. admonition:: Rationale. There are no legitimate reasons to call ``dealloc`` directly. A class may provide a method definition for an instance method named; ``dealloc``. This method will be called after the final ``release`` of the; object but before it is deallocated or any of its instance variables are; destroyed. The superclass's implementation of ``dealloc`` will be called; automatically when the method returns. .. admonition:: Rationale. Even though ARC destroys instance variables automatically, there are still; legitimate reasons to write a ``dealloc`` method, such as freeing; non-retainable resources. Failing to call ``[super dealloc]`` in such a; method is nearly always a bug. Sometimes, the object is simply trying to; prevent itself from being destroyed, but ``dealloc`` is really far too late; for the object to be raising such objections. Somewhat more legitimately, an; object may have been pool-allocated and should not be deallocated with; ``free``; for now, this can only be supported with a ``dealloc``; implementation outside of ARC. Such an implementation must be very careful; to do all the other work that ``NSObject``'s ``dealloc`` would, which is; outside the scope of this document to describe. The instance variables for an ARC-compiled class will be destroyed at some; point after control enters the ``dealloc`` method for the root class of the; class. The ordering of the destruction of instance variables is unspecified,; both within a single class and between subclasses and superclasses. .. admonition:: Rationale. The traditional, non-ARC pattern for destroying instance variables is to; destroy them immediately before calling ``[super dealloc]``. Unfortunately,; message sends from the superclass are quite capable of reaching methods in; the subclass, and those methods may well read or write to those instance; variables. Making such message sends from dealloc is generally discouraged,; since the subclass may well ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:88412,allocate,allocated,88412,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['allocate'],['allocated']
Energy Efficiency,"prove the readability of the; Parallel Coordinates output and to explore interactively the data set,; many techniques are available. We have implemented a few in ROOT. First; of all, in order to show better where the clusters on the various axes; are, a 1D histogram is associated to each axis. These histograms; (one per axis) are filled according to the number of lines passing; through the bins. ![The histogramâ€™s axis can be represented with colors or as bar charts.](pictures/para4.png). These histograms can be represented which colors (get from a palette; according to the bin contents) or as bar charts. Both representations; can be cumulated on the same plot. This technique allows seeing clearly; where the clusters are on an individual axis but it does not give any; hints about the correlations between the axes. Avery simple technique allows to make the clusters appearing:; Instead of painting solid lines we paint dotted lines. The cluttering of; each individual line is reduced and the clusters show clearly as we can; see on the next figure. The spacing between the dots is a parameter which; can be adjusted in order to get the best results. ![Using dotted lines is a very simple method to reduce the cluttering.](pictures/para5.png). Interactivity is a very important aspect of the Parallel Coordinates plots.; To really explore the data set it is essential to act directly with the; events and the axes. For instance, changing the axes order may show clusters; which were not visible in a different order. On the next figure the axes; order has been changed interactively. We can see that many more clusters; appear and all the â€œrandom spheresâ€ we put in the data set are now; clearly visible. Having moved the variables `u,v,w` after the variables; `x,y,z` the correlation between these two sets of variables is clear also. ![Axis order is very important to show clusters.](pictures/para6.png). To pursue further data sets exploration we have implemented the possibility; to defi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:99332,reduce,reduced,99332,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['reduce'],['reduced']
Energy Efficiency,"ption |; +---------------------------------+----------------+-------------------------------------------------+; | quarantine_size_kb | 0 | The size (in Kb) of quarantine used to delay |; | | | the actual deallocation of chunks. Lower value |; | | | may reduce memory usage but decrease the |; | | | effectiveness of the mitigation; a negative |; | | | value will fallback to the defaults. Setting |; | | | *both* this and thread_local_quarantine_size_kb |; | | | to zero will disable the quarantine entirely. |; +---------------------------------+----------------+-------------------------------------------------+; | quarantine_max_chunk_size | 0 | Size (in bytes) up to which chunks can be |; | | | quarantined. |; +---------------------------------+----------------+-------------------------------------------------+; | thread_local_quarantine_size_kb | 0 | The size (in Kb) of per-thread cache use to |; | | | offload the global quarantine. Lower value may |; | | | reduce memory usage but might increase |; | | | contention on the global quarantine. Setting |; | | | *both* this and quarantine_size_kb to zero will |; | | | disable the quarantine entirely. |; +---------------------------------+----------------+-------------------------------------------------+; | dealloc_type_mismatch | false | Whether or not we report errors on |; | | | malloc/delete, new/free, new/delete[], etc. |; +---------------------------------+----------------+-------------------------------------------------+; | delete_size_mismatch | true | Whether or not we report errors on mismatch |; | | | between sizes of new and delete. |; +---------------------------------+----------------+-------------------------------------------------+; | zero_contents | false | Whether or not we zero chunk contents on |; | | | allocation. |; +---------------------------------+----------------+-------------------------------------------------+; | pattern_fill_contents | false | Whether or not we fill chunk contents with a |;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:9503,reduce,reduce,9503,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['reduce'],['reduce']
Energy Efficiency,"puting resources. ROOT provides a very efficient storage system for data models, ; that demonstrated to scale at the Large Hadron Collider experiments: Exabytes ; of scientific data are written in columnar ROOT format.; ROOT comes with histogramming capabilities in an arbitrary number of ; dimensions, curve fitting, statistical modelling, minimization, to allow; the easy setup of a data analysis system that can query and process the data; interactively or in batch mode, as well as a general parallel processing; framework, RDataFrame, that can considerably speed up an analysis, taking ; full advantage of multi-core and distributed systems. ROOT is performance critical software written in C++ and enables rapid prototyping ; powered by a unique C++ compliant interpreter called Cling. ; Cling also enables performant C++ type introspection which is a building block of automatic ; interoperability with Python. Thanks to PyROOT, leveraging the cppyy technology, ; ROOT offers efficient, on-demand C++/Python interoperability in a uniform cross-language ; execution environment. ROOT fully embraces open-source, it's made with passion by its community,; for the benefit of its community. [![License: LGPL v2.1+](https://img.shields.io/badge/License-LGPL%20v2.1+-blue.svg)](https://www.gnu.org/licenses/lgpl.html); [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5060/badge)](https://bestpractices.coreinfrastructure.org/projects/5060). ## Contribution Guidelines; - [How to contribute](https://github.com/root-project/root/blob/master/CONTRIBUTING.md); - [Coding conventions](https://root.cern/coding-conventions); - [Meetings](https://root.cern/meetings). ## Cite; When citing ROOT, please use both the reference reported below and the DOI specific to your ROOT version available [on Zenodo](https://zenodo.org/badge/latestdoi/10994345) [![DOI](https://zenodo.org/badge/10994345.svg)](https://zenodo.org/badge/latestdoi/10994345). For example, you can copy-paste an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README.md:1537,efficient,efficient,1537,README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README.md,1,['efficient'],['efficient']
Energy Efficiency,"py <https://github.com/numba/numba-examples/blob/master/examples/physics/lennard_jones/numba_scalar_impl.py>`_. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext; ...; >>> cppyy.cppdef(""""""; ... #include <vector>; ... struct Atom {; ... float x;; ... float y;; ... float z;; ... };; ...; ... std::vector<Atom> atoms = {{1, 2, 3}, {2, 3, 4}, {3, 4, 5}, {4, 5, 6}, {5, 6, 7}};; ... """"""); ...; >>> @numba.njit; >>> def lj_numba_scalar(r):; ... sr6 = (1./r)**6; ... pot = 4.*(sr6*sr6 - sr6); ... return pot. >>> @numba.njit; >>> def distance_numba_scalar(atom1, atom2):; ... dx = atom2.x - atom1.x; ... dy = atom2.y - atom1.y; ... dz = atom2.z - atom1.z; ...; ... r = (dx * dx + dy * dy + dz * dz) ** 0.5; ...; ... return r; ...; >>> def potential_numba_scalar(cluster):; ... energy = 0.0; ... for i in range(cluster.size() - 1):; ... for j in range(i + 1, cluster.size()):; ... r = distance_numba_scalar(cluster[i], cluster[j]); ... e = lj_numba_scalar(r); ... energy += e; ...; ... return energy; ...; >>> print(""Total lennard jones potential ="", potential_numba_scalar(cppyy.gbl.atoms)); Total lennard jones potential = -0.5780277345740283. Overhead; --------. The main overhead of JITing Numba traces is in the type annotation in Numba; itself, optimization of the IR and assembly by the backend less so.; (There is also a non-negligible cost to Numba initialization, which is why; ``cppyy`` does not provide automatic extension hooks.); The use of ``cppyy`` bound C++, which relies on the same Numba machinery,; does not change that, since the reflection-based lookups are in C++ and; comparatively very fast.; For example, there is no appreciable difference in wall clock time to JIT a; trace using Numba's included math functions (from module ``math`` or; ``numpy``) or one that uses C++ bound ones whether from the standard library; or a templated versions from e.g. Eigen.; Use of very complex template expressions may change this balance, but in; principle, w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:9052,energy,energy,9052,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,1,['energy'],['energy']
Energy Efficiency,"quences to the above ones. However, these are still very marginally; slower, as there are fewer ports able to dispatch shift instructions in most; modern x86 processors than there are for `or` instructions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:34712,efficient,efficient,34712,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['efficient'],['efficient']
Energy Efficiency,"r Valls Pla, UJI, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, CERN/SFT, \; Zhe Zhang, UNL. ## Important Notice. The default compression algorithm used when writing ROOT files has been updated to use LZ4 in particular to improve read (decompression) performance. You can change this default for each file through (for example) the `TFile constructor` or `TFile::SetCompressionAlgorithm`. It should be noted that ROOT files written with LZ4 compression can not be read with older release of ROOT. Support for LZ4 was however back-ported to the patch branches of previous releases and the following tags (and later release in the same patch series) can read ROOT files written with LZ4 compression:. * v5.34/38; * v6.08/06 [not yet released]; * v6.10/08; * v6.12/02. ## Removed interfaces. ## Core Libraries; - Optimize away redundant deserialization of template specializations. This reduces the memory footprint for hsimple by around 30% while improving the runtime performance for various cases by around 15%.; - When ROOT is signaled with a SIGUSR2 (i.e. on Linux and MacOS X) it will now print a backtrace.; - Move RStringView.h to ROOT/RStringView.hxx and always include ROOT/RStringView.hxx instead of RStringView.h for backward compatibility; - In `TClingCallFunc`, support r-value reference parameters. This paves the way for the corresponding support in PyROOT (implemented now in the latest Cppyy).; - Included the new TSequentialExecutor in ROOT, sharing the interfaces of TExecutor.This should improve code economy when providing a fallback for TThreadExecutor/TProcessExecutor. ### Thread safety; - Resolved several race conditions, dead-locks, performance and order of initialization/destruction issues still lingering because of or despite the new read-write lock mechanism. ## Interpreter. - Enabled use of multi-threaded code from the interpreter.; - Previouslyl multi-threaded code could be run from the interpreter as long as ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:1815,reduce,reduces,1815,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['reduce'],['reduces']
Energy Efficiency,"r a JIT; compiler). The LLVM target-independent code generator consists of six main; components:. 1. `Abstract target description`_ interfaces which capture important properties; about various aspects of the machine, independently of how they will be used.; These interfaces are defined in ``include/llvm/Target/``. 2. Classes used to represent the `code being generated`_ for a target. These; classes are intended to be abstract enough to represent the machine code for; *any* target machine. These classes are defined in; ``include/llvm/CodeGen/``. At this level, concepts like ""constant pool; entries"" and ""jump tables"" are explicitly exposed. 3. Classes and algorithms used to represent code at the object file level, the; `MC Layer`_. These classes represent assembly level constructs like labels,; sections, and instructions. At this level, concepts like ""constant pool; entries"" and ""jump tables"" don't exist. 4. `Target-independent algorithms`_ used to implement various phases of native; code generation (register allocation, scheduling, stack frame representation,; etc). This code lives in ``lib/CodeGen/``. 5. `Implementations of the abstract target description interfaces`_ for; particular targets. These machine descriptions make use of the components; provided by LLVM, and can optionally provide custom target-specific passes,; to build complete code generators for a specific target. Target descriptions; live in ``lib/Target/``. 6. The target-independent JIT components. The LLVM JIT is completely target; independent (it uses the ``TargetJITInfo`` structure to interface for; target-specific issues. The code for the target-independent JIT lives in; ``lib/ExecutionEngine/JIT``. Depending on which part of the code generator you are interested in working on,; different pieces of this will be useful to you. In any case, you should be; familiar with the `target description`_ and `machine code representation`_; classes. If you want to add a backend for a new target, you will need",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:1965,schedul,scheduling,1965,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['schedul'],['scheduling']
Energy Efficiency,"r and the sequential container,; using the set-like container for uniquing and the sequential container for; iteration. The difference between SetVector and other sets is that the order of iteration; is guaranteed to match the order of insertion into the SetVector. This property; is really important for things like sets of pointers. Because pointer values; are non-deterministic (e.g. vary across runs of the program on different; machines), iterating over the pointers in the set will not be in a well-defined; order. The drawback of SetVector is that it requires twice as much space as a normal; set and has the sum of constant factors from the set-like container and the; sequential container that it uses. Use it **only** if you need to iterate over; the elements in a deterministic order. SetVector is also expensive to delete; elements out of (linear time), unless you use its ""pop_back"" method, which is; faster. ``SetVector`` is an adapter class that defaults to using ``std::vector`` and a; size 16 ``SmallSet`` for the underlying containers, so it is quite expensive.; However, ``""llvm/ADT/SetVector.h""`` also provides a ``SmallSetVector`` class,; which defaults to using a ``SmallVector`` and ``SmallSet`` of a specified size.; If you use this, and if your sets are dynamically smaller than ``N``, you will; save a lot of heap traffic. .. _dss_uniquevector:. llvm/ADT/UniqueVector.h; ^^^^^^^^^^^^^^^^^^^^^^^. UniqueVector is similar to :ref:`SetVector <dss_setvector>` but it retains a; unique ID for each element inserted into the set. It internally contains a map; and a vector, and it assigns a unique ID for each value inserted into the set. UniqueVector is very expensive: its cost is the sum of the cost of maintaining; both the map and vector, it has high complexity, high constant factors, and; produces a lot of malloc traffic. It should be avoided. .. _dss_immutableset:. llvm/ADT/ImmutableSet.h; ^^^^^^^^^^^^^^^^^^^^^^^. ImmutableSet is an immutable (functional) set implement",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:85602,adapt,adapter,85602,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['adapt'],['adapter']
Energy Efficiency,"r buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:36506,schedul,scheduling,36506,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"r class: PDF. Option Array Default value Predefined values Description. NSmooth No 0 âˆ’ Number of smoothing iterations for the input histograms. MinNSmooth No -1 âˆ’ Min number of smoothing iterations, for bins with most data. MaxNSmooth No -1 âˆ’ Max number of smoothing iterations, for bins with least data. NAvEvtPerBin No 50 âˆ’ Average number of events per PDF bin. Nbins No 0 âˆ’ Defined number of bins for the histogram from which the PDF is created. CheckHist No False âˆ’ Whether or not to check the source histogram of the PDF. PDFInterpol No Spline2 Spline0, Spline1, Spline2, Spline3, Spline5, KDE Interpolation method for reference histograms (e.g. Spline2 or KDE). KDEtype No Gauss Gauss KDE kernel type (1=Gauss). KDEiter No Nonadaptive Nonadaptive, Adaptive Number of iterations (1=non-adaptive, 2=adaptive). KDEFineFactor No 1 âˆ’ Fine tuning factor for Adaptive KDE: Factor to multyply the width of the kernel. KDEborder No None None, Renorm, Mirror Border effects treatment (1=no treatment , 2=kernel renormalization, 3=sample mirroring). Configuration options for Factory running :. Configuration options reference for class: Factory. Option Array Default value Predefined values Description. V No False âˆ’ Verbose flag. Color No True âˆ’ Flag for coloured screen output (default: True, if in batch mode: False). Transformations No âˆ’ List of transformations to test; formatting example: Transformations=I;D;P;U;G,D, for identity, decorrelation, PCA, Uniform and Gaussianisation followed by decorrelation transformations. Silent No False âˆ’ Batch mode: boolean silent flag inhibiting any output from TMVA after the creation of the factory class object (default: False). DrawProgressBar No True âˆ’ Draw progress bar to display training, testing and evaluation schedule (default: True). AnalysisType No Auto Classification, Regression, Multiclass, Auto Set the analysis type (Classification, Regression, Multiclass, Auto) (default: Auto). Page created on Mon Jul 29 00:06:19 2013 (Â© TMVA, 2006âˆ’2009). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:35269,schedul,schedule,35269,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['schedul'],['schedule']
Energy Efficiency,"r filePath[100];; SearchPath(NULL, ""file.dll"", NULL, 100, filePath, NULL);; return LoadLibrary(filePath); // warn; }. WinAPI.WideCharToMultiByte; (C); Buffer overrun while calling WideCharToMultiByte(). The size of; the input buffer equals the number of characters in the Unicode string, while; the size of the output buffer equals the number of bytes.; Source: ; MSDN: WideCharToMultiByte function. #include <windows.h>. void test() {; wchar_t ws[] = L""abc"";; char s[3];; WideCharToMultiByte(CP_UTF8, 0, ws, -1, s,; 3, NULL, NULL); // warn; }. optimization. Name, DescriptionExampleProgress. optimization.PassConstObjByValue; (C, C++); Optimization: It is more effective to pass constant parameter by reference to; avoid unnecessary object copying. struct A {};. void f(const struct A a); // warn. optimization.PostfixIncIter; (C++); Optimization: It is more effective to use prefix increment operator with; iterator.; Source: Scott Meyers ""More Effective C++"", item 6:; Distinguish between prefix and postfix forms of increment and decrement; operators. #include <vector>. void test() {; std::vector<int> v;; std::vector<int>::const_iterator it;; for(it = v.begin();; it != v.end(); it++) {}; // warn; }. optimization.MultipleCallsStrlen; (C); Optimization: multiple calls to strlen() for a string in an; expression. It is more effective to hold a value returned; from strlen() in a temporary variable. #include <string.h>. void test(const char* s) {; if (strlen(s) > 0 &&; strlen(s) < 7) {}; // warn; }. optimization.StrLengthCalculation; (C++); Optimization: it is more efficient to use string::length() to; calculate the length of an std::string. #include <string>; #include <string.h>. void test() {; std::string s;; if (strlen(s.c_str()) != 0) {}; // warn; }. optimization.EmptyContainerDetect; (C++); Optimization: It is more efficient to use containers empty(); method to identify an empty container. #include <list>. void test() {; std::list<int> l;; if (l.size() != 0) {}; // warn; }. ; . ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:28245,efficient,efficient,28245,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,4,['efficient'],['efficient']
Energy Efficiency,"r is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a group. :program:`llvm-mca`'s scheduler internally groups instructions into three sets:. * WaitSet: a set of instructions whose operands are not ready.; * ReadySet: a set of instructions ready to execute.; * IssuedSet: a set of instructions executing. Depending on the operands availability, instructions that are dispatched to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:37246,schedul,scheduler,37246,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['schedul'],"['scheduler', 'schedulers']"
Energy Efficiency,"r it does not have the; ``cf_returns_not_retained`` attribute but it does have a :ref:`selector; family <arc.method-families>` that implies a retained result. Furthermore:. * a comma expression is classified according to its right-hand side,; * a statement expression is classified according to its result expression, if; it has one,; * an lvalue-to-rvalue conversion applied to an Objective-C property lvalue is; classified according to the underlying message send, and; * a conditional operator is classified according to its second and third; operands, if they agree in classification, or else the other if one is known; retain-agnostic. If the cast operand is known retained, the conversion is treated as a; ``__bridge_transfer`` cast. If the cast operand is known unretained or known; retain-agnostic, the conversion is treated as a ``__bridge`` cast. .. admonition:: Rationale. Bridging casts are annoying. Absent the ability to completely automate the; management of CF objects, however, we are left with relatively poor attempts; to reduce the need for a glut of explicit bridges. Hence these rules. We've so far consciously refrained from implicitly turning retained CF; results from function calls into ``__bridge_transfer`` casts. The worry is; that some code patterns --- for example, creating a CF value, assigning it; to an ObjC-typed local, and then calling ``CFRelease`` when done --- are a; bit too likely to be accidentally accepted, leading to mysterious behavior. For loads from ``const`` global variables of :ref:`C retainable pointer type; <arc.misc.c-retainable>`, it is reasonable to assume that global system; constants were initialized with true constants (e.g. string literals), but; user constants might have been initialized with something dynamically; allocated, using a global initializer. .. _arc.objects.restrictions.conversion-exception-contextual:. Conversion from retainable object pointer type in certain contexts; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:28323,reduce,reduce,28323,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['reduce'],['reduce']
Energy Efficiency,"r local computer and it has the environment; properly set up. PoD and PROOF workflow; ----------------------. > The following operations are valid inside the `vaf-enter` environment. ### Start your PoD server. With PROOF on Demand, each user has the control of its own personal; PROOF cluster. The first thing to do is to start the PoD server and the; PROOF master like this:. vafctl --start. A successful output will be similar to:. ** Starting remote PoD server on dberzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session, remember to free the workers by stopping; your PoD server:. vafctl --stop. > PoD will stop the PROOF",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:11262,monitor,monitoring,11262,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,1,['monitor'],['monitoring']
Energy Efficiency,"r own init-like methods that do not; follow the standard Cocoa naming conventions.; Example. #ifndef __has_feature; #define __has_feature(x) 0 // Compatibility with non-clang compilers.; #endif. #ifndef NS_CONSUMES_SELF; #if __has_feature((attribute_ns_consumes_self)); #define NS_CONSUMES_SELF __attribute__((ns_consumes_self)); #else; #define NS_CONSUMES_SELF; #endif; #endif. @interface MyClass : NSObject; - initWith:(MyClass *)x;; - nonstandardInitWith:(MyClass *)x NS_CONSUMES_SELF NS_RETURNS_RETAINED;; @end. In this example, -nonstandardInitWith: has the same ownership; semantics as the init method -initWith:. The static analyzer will; observe that the method consumes the receiver, and then returns an object with; a +1 retain count.; The Foundation framework defines a macro NS_REPLACES_RECEIVER; which is functionally equivalent to the combination of NS_CONSUMES_SELF; and NS_RETURNS_RETAINED shown above.; Libkern Memory Management Annotations; Libkern; requires developers to inherit all heap allocated objects from OSObject; and to perform manual reference counting.; The reference counting model is very similar to MRR (manual retain-release) mode in; Objective-C; or to CoreFoundation reference counting.; Freshly-allocated objects start with a reference count of 1,; and calls to retain increment it,; while calls to release decrement it.; The object is deallocated whenever its reference count reaches zero.; Manually incrementing and decrementing reference counts is error-prone:; over-retains lead to leaks, and over-releases lead to uses-after-free.; The analyzer can help the programmer to check for unbalanced; retain/release calls.; The reference count checking is based on the principle of; locality: it should be possible to establish correctness; (lack of leaks/uses after free) by looking at each function body,; and the declarations (not the definitions) of all the functions it interacts; with.; In order to support such reasoning, it should be possible to summarize; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html:13735,allocate,allocated,13735,interpreter/llvm-project/clang/www/analyzer/annotations.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html,2,['allocate'],['allocated']
Energy Efficiency,"r their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the ability to perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92673,allocate,allocated,92673,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['allocate'],['allocated']
Energy Efficiency,"r which is read before the; source file is preprocessed. .. option:: -include <filename>. Adds an implicit #include into the predefines buffer which is read before the; source file is preprocessed. .. option:: -I<directory>. Add the specified directory to the search path for include files. .. option:: -F<directory>. Add the specified directory to the search path for framework include files. .. option:: -nostdinc. Do not search the standard system directories or compiler builtin directories; for include files. .. option:: -nostdlibinc. Do not search the standard system directories for include files, but do; search compiler builtin include directories. .. option:: -nobuiltininc. Do not search clang's builtin directory for include files. .. option:: -fkeep-system-includes. Usable only with :option:`-E`. Do not copy the preprocessed content of; ""system"" headers to the output; instead, preserve the #include directive.; This can greatly reduce the volume of text produced by :option:`-E` which; can be helpful when trying to produce a ""small"" reproduceable test case. This option does not guarantee reproduceability, however. If the including; source defines preprocessor symbols that influence the behavior of system; headers (for example, ``_XOPEN_SOURCE``) the operation of :option:`-E` will; remove that definition and thus can change the semantics of the included; header. Also, using a different version of the system headers (especially a; different version of the STL) may result in different behavior. Always verify; the preprocessed file by compiling it separately. ENVIRONMENT; -----------. .. envvar:: TMPDIR, TEMP, TMP. These environment variables are checked, in order, for the location to write; temporary files used during the compilation process. .. envvar:: CPATH. If this environment variable is present, it is treated as a delimited list of; paths to be added to the default system include path list. The delimiter is; the platform dependent delimiter, as used in the PATH ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:20086,reduce,reduce,20086,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['reduce'],['reduce']
Energy Efficiency,"r's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analyses are available already, which analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:41646,allocate,allocated,41646,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['allocate'],['allocated']
Energy Efficiency,"r(...) {; ...; }. Specifying a width/count of 1 disables the optimization, and is equivalent to; ``vectorize(disable)`` or ``interleave(disable)``. Vector predication is enabled by ``vectorize_predicate(enable)``, for example:. .. code-block:: c++. #pragma clang loop vectorize(enable); #pragma clang loop vectorize_predicate(enable); for(...) {; ...; }. This predicates (masks) all instructions in the loop, which allows the scalar; remainder loop (the tail) to be folded into the main vectorized loop. This; might be more efficient when vector predication is efficiently supported by the; target platform. Loop Unrolling; --------------. Unrolling a loop reduces the loop control overhead and exposes more; opportunities for ILP. Loops can be fully or partially unrolled. Full unrolling; eliminates the loop and replaces it with an enumerated sequence of loop; iterations. Full unrolling is only possible if the loop trip count is known at; compile time. Partial unrolling replicates the loop body within the loop and; reduces the trip count. If ``unroll(enable)`` is specified the unroller will attempt to fully unroll the; loop if the trip count is known at compile time. If the fully unrolled code size; is greater than an internal limit the loop will be partially unrolled up to this; limit. If the trip count is not known at compile time the loop will be partially; unrolled with a heuristically chosen unroll factor. .. code-block:: c++. #pragma clang loop unroll(enable); for(...) {; ...; }. If ``unroll(full)`` is specified the unroller will attempt to fully unroll the; loop if the trip count is known at compile time identically to; ``unroll(enable)``. However, with ``unroll(full)`` the loop will not be unrolled; if the loop count is not known at compile time. .. code-block:: c++. #pragma clang loop unroll(full); for(...) {; ...; }. The unroll count can be specified explicitly with ``unroll_count(_value_)`` where; _value_ is a positive integer. If this value is greater than the tri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:166417,reduce,reduces,166417,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['reduce'],['reduces']
Energy Efficiency,"r-use``. Similarly, sampling profiles; generated by external profilers must be converted and used with ``-fprofile-sample-use``; or ``-fauto-profile``. 2. Instrumentation profile data can be used for code coverage analysis and; optimization. 3. Sampling profiles can only be used for optimization. They cannot be used for; code coverage analysis. Although it would be technically possible to use; sampling profiles for code coverage, sample-based profiles are too; coarse-grained for code coverage purposes; it would yield poor results. 4. Sampling profiles must be generated by an external tool. The profile; generated by that tool must then be converted into a format that can be read; by LLVM. The section on sampling profilers describes one of the supported; sampling profile formats. Using Sampling Profilers; ^^^^^^^^^^^^^^^^^^^^^^^^. Sampling profilers are used to collect runtime information, such as; hardware counters, while your application executes. They are typically; very efficient and do not incur a large runtime overhead. The; sample data collected by the profiler can be used during compilation; to determine what the most executed areas of the code are. Using the data from a sample profiler requires some changes in the way; a program is built. Before the compiler can use profiling information,; the code needs to execute under the profiler. The following is the; usual build cycle when using sample profilers for optimization:. 1. Build the code with source line table information. You can use all the; usual build flags that you always build your application with. The only; requirement is that you add ``-gline-tables-only`` or ``-g`` to the; command line. This is important for the profiler to be able to map; instructions back to source line locations. .. code-block:: console. $ clang++ -O2 -gline-tables-only code.cc -o code. 2. Run the executable under a sampling profiler. The specific profiler; you use does not really matter, as long as its output can be converted; i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:92228,efficient,efficient,92228,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"r.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible, we create a list of items, or; Atoms, that are contained in the data for each name. First comes the type of; the data in each atom:. .. code-block:: c. enum AtomType; {; eAtomTypeNULL = 0u,; eAtomTypeDIEOffset = 1u, // DIE offset, check form for encoding; eAtomTypeCUOffset = 2u, // DIE offset of the compiler unit header that contains the item in question; eAtomTypeTag = 3u, // DW_TAG_xxx value, should be encoded as DW_FORM_data1 (if no tags exceed 255) or DW_FORM_data2; eAtomTypeNameFlags = 4u, // Flags from enum NameFlags; eAtomTypeTypeFlags = 5u, // Flags from enum TypeFlags; };. The enumeration values and their meanings are:. .. code-block:: none. eAtomTypeNULL - a termi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71688,efficient,efficiently,71688,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,2,['efficient'],"['efficient', 'efficiently']"
Energy Efficiency,"r4,r4,r3; srawi r2,r4,31; xor r0,r2,r4; subf r0,r2,r0; stw r0,0(r5); blr. ... which is much nicer. This theoretically may help improve twolf slightly (used in dimbox.c:142?). ===-------------------------------------------------------------------------===. PR5945: This: ; define i32 @clamp0g(i32 %a) {; entry:; %cmp = icmp slt i32 %a, 0; %sel = select i1 %cmp, i32 0, i32 %a; ret i32 %sel; }. Is compile to this with the PowerPC (32-bit) backend:. _clamp0g:; cmpwi cr0, r3, 0; li r2, 0; blt cr0, LBB1_2; ; %bb.1: ; %entry; mr r2, r3; LBB1_2: ; %entry; mr r3, r2; blr. This could be reduced to the much simpler:. _clamp0g:; srawi r2, r3, 31; andc r3, r3, r2; blr. ===-------------------------------------------------------------------------===. int foo(int N, int ***W, int **TK, int X) {; int t, i;; ; for (t = 0; t < N; ++t); for (i = 0; i < 4; ++i); W[t / X][i][t % X] = TK[i][t];; ; return 5;; }. We generate relatively atrocious code for this loop compared to gcc. We could also strength reduce the rem and the div:; http://www.lcs.mit.edu/pubs/pdf/MIT-LCS-TM-600.pdf. ===-------------------------------------------------------------------------===. We generate ugly code for this:. void func(unsigned int *ret, float dx, float dy, float dz, float dw) {; unsigned code = 0;; if(dx < -dw) code |= 1;; if(dx > dw) code |= 2;; if(dy < -dw) code |= 4;; if(dy > dw) code |= 8;; if(dz < -dw) code |= 16;; if(dz > dw) code |= 32;; *ret = code;; }. ===-------------------------------------------------------------------------===. %struct.B = type { i8, [3 x i8] }. define void @bar(%struct.B* %b) {; entry:; %tmp = bitcast %struct.B* %b to i32* ; <uint*> [#uses=1]; %tmp = load i32* %tmp ; <uint> [#uses=1]; %tmp3 = bitcast %struct.B* %b to i32* ; <uint*> [#uses=1]; %tmp4 = load i32* %tmp3 ; <uint> [#uses=1]; %tmp8 = bitcast %struct.B* %b to i32* ; <uint*> [#uses=2]; %tmp9 = load i32* %tmp8 ; <uint> [#uses=1]; %tmp4.mask17 = shl i32 %tmp4, i8 1 ; <uint> [#uses=1]; %tmp1415 = and i32 %tmp4.mask17, 21",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:4720,reduce,reduce,4720,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,2,['reduce'],['reduce']
Energy Efficiency,"r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27453,efficient,efficiently,27453,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['efficient'],['efficiently']
Energy Efficiency,"r::Plugin`` class provides the following methods:. * ``modifyPassConfig`` is called each time a LinkGraph is about to be linked. It; can be overridden to install JITLink *Passes* to run during the link process. .. code-block:: c++. void modifyPassConfig(MaterializationResponsibility &MR,; const Triple &TT,; jitlink::PassConfiguration &Config). * ``notifyLoaded`` is called before the link begins, and can be overridden to; set up any initial state for the given ``MaterializationResponsibility`` if; needed. .. code-block:: c++. void notifyLoaded(MaterializationResponsibility &MR). * ``notifyEmitted`` is called after the link is complete and code has been; emitted to the executor process. It can be overridden to finalize state; for the ``MaterializationResponsibility`` if needed. .. code-block:: c++. Error notifyEmitted(MaterializationResponsibility &MR). * ``notifyFailed`` is called if the link fails at any point. It can be; overridden to react to the failure (e.g. to deallocate any already allocated; resources). .. code-block:: c++. Error notifyFailed(MaterializationResponsibility &MR). * ``notifyRemovingResources`` is called when a request is made to remove any; resources associated with the ``ResourceKey`` *K* for the; ``MaterializationResponsibility``. .. code-block:: c++. Error notifyRemovingResources(ResourceKey K). * ``notifyTransferringResources`` is called if/when a request is made to; transfer tracking of any resources associated with ``ResourceKey``; *SrcKey* to *DstKey*. .. code-block:: c++. void notifyTransferringResources(ResourceKey DstKey,; ResourceKey SrcKey). Plugin authors are required to implement the ``notifyFailed``,; ``notifyRemovingResources``, and ``notifyTransferringResources`` methods in; order to safely manage resources in the case of resource removal or transfer,; or link failure. If no resources are managed by the plugin then these methods; can be implemented as no-ops returning ``Error::success()``. Plugin instances are added to an ``Objec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:3711,allocate,allocated,3711,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocated']
Energy Efficiency,"r<<""ds<-data.frame(x=x,y=y)"";; //fitting x and y to X^power using Nonlinear Least Squares; r<<""m <- nls(y ~ I(x^power),data = ds, start = list(power = 1),trace = T)"";; //getting the exponent; Double_t power;; r[""summary(m)$coefficients[1]""]>>power;. TF1 *f_fitted=new TF1(""f_fitted"",""pow(x,[0])"",0,1);; f_fitted->SetParameter(0,power);; //plotting the fitted function; TGraph *gr3 = new TGraph(f_fitted);; gr3->SetMarkerColor(kGreen);; gr3->SetMarkerStyle(8);; gr3->SetMarkerSize(1);. mg->Add(gr3);; mg->Draw(""ap"");. //displaying basic results; TPaveText *pt = new TPaveText(0.1,0.6,0.5,0.9,""brNDC"");; pt->SetFillColor(18);; pt->SetTextAlign(12);; pt->AddText(""Fitting x^power "");; pt->AddText("" \""Blue\"" Points with gaussian noise to be fitted"");; pt->AddText("" \""Red\"" Known function x^3"");; TString fmsg;; fmsg.Form("" \""Green\"" Fitted function with power=%.4lf"",power);; pt->AddText(fmsg);; pt->Draw();; c1->Update();; return c1;; }; ~~~; In the first image you can see the blue dots which are the function `x^3` with gaussian noise, the red dots correspond to; the original function and the green ones correspond to the fitted function. \image html R_image1.png. ## Global Minimization in R using the package DEoptim; DEoptim is a R package for Differential Evolution Minimization that lets you do global; Minimization.; To install this package you just need to run:. ~~~{.cxx}; #include<TRInterface.h>; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; r<<""install.packages('DEoptim',repos='http://cran.rstudio.com/')"";; ~~~. Then create a macro named GlobalMinimization.C with the next code. ~~~{.cxx}; #include<TRInterface.h>; #include<TBenchmark.h>; #include<math.h>; #include<stdlib.h>; //In the next function the *double pointer should be changed by a TVectorD datatype,; //because the pointer has no meaning in the R environment.; //This is a generalization of the RosenBrock function, with the min xi=1 and i>0.; Double_t GenRosenBrock(const TVectorD xx ); {; int length=xx.GetNo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:16698,power,power,16698,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,2,"['green', 'power']","['green', 'power']"
Energy Efficiency,"rParsedAttrKinds; ------------------------. **Purpose**: Creates AttrParsedAttrKinds.inc, which is used to implement the; ``AttributeList::getKind`` function, mapping a string (and syntax) to a parsed; attribute ``AttributeList::Kind`` enumeration. ClangAttrDump; -------------. **Purpose**: Creates AttrDump.inc, which dumps information about an attribute.; It is used to implement ``ASTDumper::dumpAttr``. ClangDiagsDefs; --------------. Generate Clang diagnostics definitions. ClangDiagGroups; ---------------. Generate Clang diagnostic groups. ClangDiagsIndexName; -------------------. Generate Clang diagnostic name index. ClangCommentNodes; -----------------. Generate Clang AST comment nodes. ClangDeclNodes; --------------. Generate Clang AST declaration nodes. ClangStmtNodes; --------------. Generate Clang AST statement nodes. ClangSACheckers; ---------------. Generate Clang Static Analyzer checkers. ClangCommentHTMLTags; --------------------. Generate efficient matchers for HTML tag names that are used in documentation comments. ClangCommentHTMLTagsProperties; ------------------------------. Generate efficient matchers for HTML tag properties. ClangCommentHTMLNamedCharacterReferences; ----------------------------------------. Generate function to translate named character references to UTF-8 sequences. ClangCommentCommandInfo; -----------------------. Generate command properties for commands that are used in documentation comments. ClangCommentCommandList; -----------------------. Generate list of commands that are used in documentation comments. ArmNeon; -------. Generate arm_neon.h for clang. ArmNeonSema; -----------. Generate ARM NEON sema support for clang. ArmNeonTest; -----------. Generate ARM NEON tests for clang. AttrDocs; --------. **Purpose**: Creates ``AttributeReference.rst`` from ``AttrDocs.td``, and is; used for documenting user-facing attributes. General BackEnds; ================. Print Records; -------------. The TableGen command option ``--print-re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst:13207,efficient,efficient,13207,interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,1,['efficient'],['efficient']
Energy Efficiency,"ral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``+QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the largest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``+Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>` intrinsic (and thus the; '``llvm.minnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmin.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float QNAN, float QNAN, float QNAN, float QNAN>; %reduction = call float @llvm.vector.reduce.fmin.v4f32(<4 x float> %masked.a); %also.r = call float @llvm.minnum.f32(float %reduction, float %start). .. _int_get_active_lane_mask:. '``llvm.get.active.lane.mask.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x i1> @llvm.get.active.lane.mask.v4i1.i32(i32 %base, i32 %n); declare <8 x i1> @llvm.get.active.lane.mask.v8i1.i64(i64 %base, i64 %n); declare <16 x i1> @llvm.get.active.lane.mask.v16i1.i64(i64 %base, i64 %n); declare <vscale x 16 x i1> @llvm.get.active.lane.mask.nxv16i1.i64(i64 %base, i64 %n). Overview:; """""""""""""""""". Create a mask representing ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:776261,reduce,reduce,776261,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ram representations, e.g. Object Files) are no longer added; directly to JIT classes or layers. Instead, they are added to ``JITDylib``; instances *by* layers. The ``JITDylib`` determines *where* the definitions; reside, the layers determine *how* the definitions will be compiled.; Linkage relationships between ``JITDylibs`` determine how inter-module; references are resolved, and symbol resolvers are no longer used. See the; section `Design Overview`_ for more details. Unless multiple JITDylibs are needed to model linkage relationships, ORCv1; clients should place all code in a single JITDylib.; MCJIT clients should use LLJIT (see `LLJIT and LLLazyJIT`_), and can place; code in LLJIT's default created main JITDylib (See; ``LLJIT::getMainJITDylib()``). 2. All JIT stacks now need an ``ExecutionSession`` instance. ExecutionSession; manages the string pool, error reporting, synchronization, and symbol; lookup. 3. ORCv2 uses uniqued strings (``SymbolStringPtr`` instances) rather than; string values in order to reduce memory overhead and improve lookup; performance. See the subsection `How to manage symbol strings`_. 4. IR layers require ThreadSafeModule instances, rather than; std::unique_ptr<Module>s. ThreadSafeModule is a wrapper that ensures that; Modules that use the same LLVMContext are not accessed concurrently.; See `How to use ThreadSafeModule and ThreadSafeContext`_. 5. Symbol lookup is no longer handled by layers. Instead, there is a; ``lookup`` method on JITDylib that takes a list of JITDylibs to scan. .. code-block:: c++. ExecutionSession ES;; JITDylib &JD1 = ...;; JITDylib &JD2 = ...;. auto Sym = ES.lookup({&JD1, &JD2}, ES.intern(""_main""));. 6. The removeModule/removeObject methods are replaced by; ``ResourceTracker::remove``.; See the subsection `How to remove code`_. For code examples and suggestions of how to use the ORCv2 APIs, please see; the section `How-tos`_. How-tos; =======. How to manage symbol strings; ----------------------------. Symbol string",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:21069,reduce,reduce,21069,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['reduce'],['reduce']
Energy Efficiency,"ram. ![The tree viewer](pictures/030000FE.png). ### Reading the Tree. The `tree1r` function shows how to read the tree and access each entry; and each leaf. We first define the variables to hold the read values. ``` {.cpp}; Float_t px, py, pz;; ```. Then we tell the tree to populate these variables when reading an entry.; We do this with the method `TTree::SetBranchAddress`. The first; parameter is the branch name, and the second is the address of the; variable where the branch data is to be placed. In this example, the; branch name is `px`. This name was given when the tree was written (see; `tree1w`). The second parameter is the address of the variable `px`. ``` {.cpp}; t1->SetBranchAddress(""px"",&px);; ```. #### GetEntry. Once the branches have been given the address, a specific entry can be; read into the variables with the method `TTree::GetEntry(n)`. It; reads all the branches for entry (n) and populates the given address; accordingly. By default, `GetEntry()` reuses the space allocated by the; previous object for each branch. You can force the previous object to be; automatically deleted if you call `mybranch.SetAutoDelete(kTRUE)`; (default is `kFALSE`). Consider the example in `$ROOTSYS/test/Event.h`. The top-level branch in; the tree `T` is declared with:. ``` {.cpp}; Event *event = 0;; // event must be null or point to a valid object;; // it must be initialized; T.SetBranchAddress(""event"",&event);; ```. When reading the Tree, one can choose one of these 3 options:. Option 1:. ``` {.cpp}; for (Int_t i = 0; i<nentries; i++) {; T.GetEntry(i);; //the object event has been filled at this point; }; ```. This is the default and recommended way to create an object of the class; `Event. `It will be pointed by `event`. At the following entries, `event` will be overwritten by the new data.; All internal members that are **`TObject`**\* are automatically deleted.; It is important that these members be in a valid state when `GetEntry`; is called. Pointers must be correct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:38885,allocate,allocated,38885,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['allocate'],['allocated']
Energy Efficiency,"ram; <http://www.pixelglow.com/graphviz/>`_ and add; ``/Applications/Graphviz.app/Contents/MacOS/`` (or wherever you install it) to; your path. The programs need not be present when configuring, building or; running LLVM and can simply be installed when needed during an active debug; session. ``SelectionDAG`` has been extended to make it easier to locate *interesting*; nodes in large complex graphs. From gdb, if you ``call DAG.setGraphColor(node,; ""color"")``, then the next ``call DAG.viewGraph()`` would highlight the node in; the specified color (choices of colors can be found at `colors; <http://www.graphviz.org/doc/info/colors.html>`_.) More complex node attributes; can be provided with ``call DAG.setGraphAttrs(node, ""attributes"")`` (choices can; be found at `Graph attributes <http://www.graphviz.org/doc/info/attrs.html>`_.); If you want to restart and clear all the current graph attributes, then you can; ``call DAG.clearGraphAttrs()``. Note that graph visualization features are compiled out of Release builds to; reduce file size. This means that you need a Debug+Asserts or Release+Asserts; build to use these features. .. _datastructure:. Picking the Right Data Structure for a Task; ===========================================. LLVM has a plethora of data structures in the ``llvm/ADT/`` directory, and we; commonly use STL data structures. This section describes the trade-offs you; should consider when you pick one. The first step is a choose your own adventure: do you want a sequential; container, a set-like container, or a map-like container? The most important; thing when choosing a container is the algorithmic properties of how you plan to; access the container. Based on that, you should use:. * a :ref:`map-like <ds_map>` container if you need efficient look-up of a; value based on another value. Map-like containers also support efficient; queries for containment (whether a key is in the map). Map-like containers; generally do not support efficient reverse mappi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:54646,reduce,reduce,54646,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['reduce'],['reduce']
Energy Efficiency,"rand's extra data. * Array (code 3): This field is an array of values. The array operand has no; extra data, but expects another operand to follow it, indicating the element; type of the array. When reading an array in an abbreviated record, the first; integer is a vbr6 that indicates the array length, followed by the encoded; elements of the array. An array may only occur as the last operand of an; abbreviation (except for the one final operand that gives the array's; type). * Char6 (code 4): This field should be emitted as a `char6-encoded value`_.; This operand type takes no extra data. Char6 encoding is normally used as an; array element type. * Blob (code 5): This field is emitted as a vbr6, followed by padding to a; 32-bit boundary (for alignment) and an array of 8-bit objects. The array of; bytes is further followed by tail padding to ensure that its total length is a; multiple of 4 bytes. This makes it very efficient for the reader to decode; the data without having to make a copy of it: it can use a pointer to the data; in the mapped in file and poke directly at it. A blob may only occur as the; last operand of an abbreviation. For example, target triples in LLVM modules are encoded as a record of the form; ``[TRIPLE, 'a', 'b', 'c', 'd']``. Consider if the bitstream emitted the; following abbrev entry:. ::. [0, Fixed, 4]; [0, Array]; [0, Char6]. When emitting a record with this abbreviation, the above entry would be emitted; as:. :raw-html:`<tt><blockquote>`; [4\ :sub:`abbrevwidth`, 2\ :sub:`4`, 4\ :sub:`vbr6`, 0\ :sub:`6`, 1\ :sub:`6`, 2\ :sub:`6`, 3\ :sub:`6`]; :raw-html:`</blockquote></tt>`. These values are:. #. The first value, 4, is the abbreviation ID for this abbreviation. #. The second value, 2, is the record code for ``TRIPLE`` records within LLVM IR; file ``MODULE_BLOCK`` blocks. #. The third value, 4, is the length of the array. #. The rest of the values are the char6 encoded values for ``""abcd""``. With this abbreviation, the triple is emitted w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:14580,efficient,efficient,14580,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['efficient'],['efficient']
Energy Efficiency,"rata <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0045d/IHI0045D_ABI_addenda.pdf>`_. * `Cortex-A57 Software Optimization Guide <http://infocenter.arm.com/help/topic/com.arm.doc.uan0015b/Cortex_A57_Software_Optimization_Guide_external.pdf>`_. * `Run-time ABI for the ARM Architecture <http://infocenter.arm.com/help/topic/com.arm.doc.ihi0043d/IHI0043D_rtabi.pdf>`_ This documents the __aeabi_* helper functions. Itanium (ia64); --------------. * `Itanium documentation <http://developer.intel.com/design/itanium2/documentation.htm>`_. Lanai; -----. * `Lanai Instruction Set Architecture <http://g.co/lanai/isa>`_. MIPS; ----. * `MIPS Processor Architecture <https://www.mips.com/products/>`_. * `MIPS 64-bit ELF Object File Specification <https://www.linux-mips.org/pub/linux/mips/doc/ABI/elf64-2.4.pdf>`_. PowerPC; -------. IBM - Official manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Power Instruction Set Architecture, Version 3.0B <https://openpowerfoundation.org/?resource_lib=power-isa-version-3-0>`_. * `POWER9 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power9-processor-users-manual>`_. * `Power Instruction Set Architecture, Version 2.07B <https://openpowerfoundation.org/?resource_lib=ibm-power-isa-version-2-07-b>`_. * `POWER8 Processor User's Manual <https://openpowerfoundation.org/?resource_lib=power8-processor-users-manual>`_. * `Power Instruction Set Architecture, Versions 2.03 through 2.06 (Internet Archive) <https://web.archive.org/web/20121124005736/https://www.power.org/technology-introduction/standards-specifications>`_. * `IBM AIX 7.2 POWER Assembly Reference <https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/assembler/alangref_kickoff.html>`_. * `IBM AIX/5L for POWER Assembly Reference <http://publibn.boulder.ibm.com/doc_link/en_US/a_doc_lib/aixassem/alangref/alangreftfrm.htm>`_. Embedded PowerPC Processors manuals and docs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * `Book E: Enhanced PowerPC Architecture <htt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst:2203,power,power-isa-version-,2203,interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompilerWriterInfo.rst,1,['power'],['power-isa-version-']
Energy Efficiency,"ration across all elements of the vector, returning a single; scalar result of the same element type. .. _int_vector_reduce_add:. '``llvm.vector.reduce.add.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.add.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.add.*``' intrinsics do an integer ``ADD``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fadd:. '``llvm.vector.reduce.fadd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fadd.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fadd.*``' intrinsics do a floating-point; ``ADD`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fadd operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fadd(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vecto",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:651252,reduce,reduce,651252,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"rder-table`. 9. Implicit Argument Ptr (2 SGPRs). The value is computed by adding an offset to Kernarg Segment Ptr to get the; global address space pointer to the first kernarg implicit argument. The input and result arguments are assigned in order in the following manner:. .. note::. There are likely some errors and omissions in the following description that; need correction. .. TODO::. Check the Clang source code to decipher how function arguments and return; results are handled. Also see the AMDGPU specific values used. * VGPR arguments are assigned to consecutive VGPRs starting at VGPR0 up to; VGPR31. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. .. TODO::. How are overly aligned structures allocated on the stack?. * SGPR arguments are assigned to consecutive SGPRs starting at SGPR0 up to; SGPR29. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. Note that decomposed struct type arguments may have some fields passed in; registers and some in memory. .. TODO::. So, a struct which can pass some fields as decomposed register arguments, will; pass the rest as decomposed stack elements? But an argument that will not start; in registers will not be decomposed and will be passed as a non-decomposed; stack value?. The following is not part of the AMDGPU function calling convention but; describes how the AMDGPU implements function calls:. 1. SGPR33 is used as a frame pointer (FP) if necessary. Like the SP it is an; unswizzled scratch address. It is only needed if runtime sized ``alloca``; are used, or for the reasons defined in ``SIFrameLowering``.; 2. Runtime stack alignment is supported. SGPR34 is used as a base pointer (BP); to access the incoming stack arguments in the function. The BP is needed; only when the function requires the runtime stack alignment",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:397357,allocate,allocated,397357,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"re both called UploadFiles and differ in the first argument,; which is used to pass the files to be uploaded. These can be given as a; list (of TFileInfo or TObjString), a directory or specified in a text; file.; Add support for paralell dataset verification. This is; implemented via a dedicated TSelector (TSelVerifyDataSet) which is run; over the list of files in the dataset via TPacketizerFile. The file; order is preserved using the recently introduced index in TFileInfo.; In TProofOutputFile, add switch to control the way histograms; are merged by TFileMerger, i.e. one-by-one or all-in-one-go. The; default is one-by-one which requires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the location of the; generated files via the third argument of TProofBench::MakeDataSet.; Several optimizations in the low level PROOF event loop; (TProofPlayer::Process),Â  allowing to reduce dramatically the; overhead introduced by the operations PROOF needs to perform during the; event loop. A measurement of the overhead can be obtained from a very; light computational task, for example, generating one random number and; filling one histogram; executing this task within a PROOF-Lite session; with 1 worker now takes only 1.8 times the time required by a straight; loop in the parent ROOT session; the same number before was about 13. ; In TDrawFeedback::Feedback, call method Draw() of objects not; identified as TH1 derivation. This allows user-defined objects; implementing Draw to be displayed via this utility class.; In TProof::LoadPackageOnClient, do not create a symlink; 'pack_name' to the package dir, but add directly the package dir to the; include path. This solves the longstanding annoying problem of failure; when a directory or file with the name of the package did already exist; in the local working directory. . Fixes; ; Fix merging issue affecting automatic datase",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:3524,reduce,reduce,3524,proof/doc/v534/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html,2,['reduce'],['reduce']
Energy Efficiency,"re just the extreme points of the contour (use the; MnContours::contour(...) method in order to get the points of the; contour and the ones of the $\mbox{MINOS}$ errors).; MnContours::operator() returns a; std::vector$<$std::pair$<$double,double$> >$ of (x,y) points. Using; MnPlot::operator() will generate a text graphics plot in the terminal. # M installation #. ## M releases ##. To follow the current release process the user is referred to the M; homepage @bib-C++MINUIT. M was reâ€“implemented in from 2002â€“2004, but the functionality is largely; compatible with the one of the version. The usage is different in the; sense that the reâ€“write from to was done by its signification and not; literally (with minor exceptions). Applications such as; $\mbox{MIGRAD}$ have a corresponding class MnMigrad, M ""commands""; became classes or methods of classes according to their purpose. Users; familiar with the version of M , who have not yet used releases from the; version, should however read this manual, in order to adapt to the; changes as well as to discover the new features and easier ways of using; old features. ## Install M using autoconf/make ##. For each release of M a tar.gz file is provided for downloading from the; M homepage @bib-C++MINUIT. For non-UNIX platforms please refer to the M; homepage. The necessary steps to follow are:. 1. download the tar.gz by clicking on it from the release page. 2. unzip it:. $ unzip Minuit-x.x.x.tar.gz. 3. untar it:. $ tar xvf Minuit-x.x.x.tar. 4. step down to the created Minuit-x.x.x directory:. $ cd Minuit-x.x.x/. 5. run the ""configure"" script:. $ ./configure. 6. run ""make"" to compile the source code:. $ make. 7. run ""make check"" to create the executable example:. $ make check. 8. run the executable example:. $ tests/MnTutorial/Quad4FMain.C. The output should look like that:. Minuit did successfully converge. # of function calls: 74; minimum function value: 1.12392e-09; minimum edm: 1.12392e-09; minimum internal state vector: LAVector ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:21997,adapt,adapt,21997,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['adapt'],['adapt']
Energy Efficiency,"re of the scalar to a 16-byte; aligned stack slot, followed by a load/vperm. We should probably just store it; to a scalar stack slot, then use lvsl/vperm to load it. If the value is already; in memory this is a big win. //===----------------------------------------------------------------------===//. extract_vector_elt of an arbitrary constant vector can be done with the ; following instructions:. vTemp = vec_splat(v0,2); // 2 is the element the src is in.; vec_ste(&destloc,0,vTemp);. We can do an arbitrary non-constant value by using lvsr/perm/ste. //===----------------------------------------------------------------------===//. If we want to tie instruction selection into the scheduler, we can do some; constant formation with different instructions. For example, we can generate; ""vsplti -1"" with ""vcmpequw R,R"" and 1,1,1,1 with ""vsubcuw R,R"", and 0,0,0,0 with; ""vsplti 0"" or ""vxor"", each of which use different execution units, thus could; help scheduling. This is probably only reasonable for a post-pass scheduler. //===----------------------------------------------------------------------===//. For this function:. void test(vector float *A, vector float *B) {; vector float C = (vector float)vec_cmpeq(*A, *B);; if (!vec_any_eq(*A, *B)); *B = (vector float){0,0,0,0};; *A = C;; }. we get the following basic block:. 	...; lvx v2, 0, r4; lvx v3, 0, r3; vcmpeqfp v4, v3, v2; vcmpeqfp. v2, v3, v2; bne cr6, LBB1_2 ; cond_next. The vcmpeqfp/vcmpeqfp. instructions currently cannot be merged when the; vcmpeqfp. result is used by a branch. This can be improved. //===----------------------------------------------------------------------===//. The code generated for this is truly aweful:. vector float test(float a, float b) {; return (vector float){ 0.0, a, 0.0, 0.0}; ; }. LCPI1_0: ; float; .space 4; .text; .globl _test; .align 4; _test:; mfspr r2, 256; oris r3, r2, 4096; mtspr 256, r3; lis r3, ha16(LCPI1_0); addi r4, r1, -32; stfs f1, -16(r1); addi r5, r1, -16; lfs f0, lo16(LCPI",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt:2945,schedul,scheduler,2945,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,2,['schedul'],['scheduler']
Energy Efficiency,"re two arguments to the ``store`` instruction: a value to store and an; address at which to store it. The type of the ``<pointer>`` operand must be a; pointer to the :ref:`first class <t_firstclass>` type of the ``<value>``; operand. If the ``store`` is marked as ``volatile``, then the optimizer is not; allowed to modify the number or order of execution of this ``store`` with other; :ref:`volatile operations <volatile>`. Only values of :ref:`first class; <t_firstclass>` types of known size (i.e. not containing an :ref:`opaque; structural type <t_opaque>`) can be stored. If the ``store`` is marked as ``atomic``, it takes an extra :ref:`ordering; <ordering>` and optional ``syncscope(""<target-scope>"")`` argument. The; ``acquire`` and ``acq_rel`` orderings aren't valid on ``store`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic stores. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemporal`` does not have any; defined semantics for atomic stores. The optional constant ``align`` argument specifies the alignment of the; operation (that is, the alignment of the memory address). It is the; responsibility of the code emitter to ensure that the alignment information is; correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address sp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:420565,power,power,420565,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"reachable code; 3 . Compute live ranges for CSE; 4 . [t] Jump threading (jumps to jumps with identical or inverse conditions); 5 . [t] CSE; 6 . *** Conversion to SSA ; 7 . [t] SSA Based DCE; 8 . *** Conversion to LLVM; 9 . UnSSA; 10. GCSE; 11. LICM; 12. Strength Reduction; 13. Loop unrolling; 14. [t] CSE; 15. [t] DCE; 16. Instruction combination, register movement, scheduling... etc. I've marked optimizations with a [t] to indicate things that I believe to; be relatively trivial to implement in LLVM itself. The time consuming; things to reimplement would be SSA based PRE, Strength reduction & loop; unrolling... these would be the major things we would miss out on if we; did LLVM creation from tree code [inlining and other high level; optimizations are done on the tree representation]. Given the lack of ""strong"" optimizations that would take a long time to; reimplement, I am leaning a bit more towards creating LLVM from the tree; code. Especially given that SGI has GPL'd their compiler, including many; SSA based optimizations that could be adapted (besides the fact that their; code looks MUCH nicer than GCC :). Even if we choose to do LLVM code emission from RTL, we will almost; certainly want to move LLVM emission from step 8 down until at least CSE; has been rerun... which causes me to wonder if the SSA generation code; will still work (due to global variable dependencies and stuff). I assume; that it can be made to work, but might be a little more involved than we; would like. I'm continuing to look at the Tree -> RTL code. It is pretty gross; because they do some of the translation a statement at a time, and some; of it a function at a time... I'm not quite clear why and how the; distinction is drawn, but it does not appear that there is a wonderful; place to attach extra info. Anyways, I'm proceeding with the RTL -> LLVM conversion phase for now. We; can talk about this more on Monday. Wouldn't it be nice if there were a obvious decision to be made? :). -Chris. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt:1483,adapt,adapted,1483,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt,1,['adapt'],['adapted']
Energy Efficiency,"reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:656967,reduce,reduce,656967,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ree values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrinsic may be used in a scheduling region. The iglp_opt intrinsic; cannot be combined with sched_barrier or sched_group_barrier. The iglp_opt strategy implementations are subject to change. llvm.amdgcn.atomic.cond.sub.u32 Provides direct access to flat_atomic_cond_sub_u32, global_atomic_cond_sub_u32; and ds_cond_sub_u32 based on address space on gfx12 targets. This; performs subtraction only if the memory value is greater than or; equal to the data value. llvm.amdgcn.s.getpc Provides access to the s_getpc_b64 instruction, but with the return value; sign-extended from the width of the underlying PC hardware register even on; processors wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:44699,schedul,scheduling,44699,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduling']
Energy Efficiency,"releasing LLVM ---; including sub-projects: e.g., ``clang`` and ``compiler-rt`` --- to the public.; It is the Release Manager's responsibility to ensure that a high quality build; of LLVM is released. If you're looking for the document on how to test the release candidates and; create the binary packages, please refer to the :doc:`ReleaseProcess` instead. .. _timeline:. Release Timeline; ================. LLVM is released on a time based schedule --- with major releases roughly; every 6 months. In between major releases there may be dot releases.; The release manager will determine if and when to make a dot release based; on feedback from the community. Typically, dot releases should be made if; there are large number of bug-fixes in the stable branch or a critical bug; has been discovered that affects a large number of users. Unless otherwise stated, dot releases will follow the same procedure as; major releases. Annual Release Schedule; -----------------------. Here is the annual release schedule for LLVM. This is meant to be a; guide, and release managers are not required to follow this exactly.; Releases should be tagged on Tuesdays. =============================== =========================; Release Approx. Date; =============================== =========================; *release branch: even releases* *4th Tue in January*; *release branch: odd releases* *4th Tue in July*; X.1.0-rc1 3 days after branch.; X.1.0-rc2 2 weeks after branch.; X.1.0-rc3 4 weeks after branch; **X.1.0-final** **6 weeks after branch**; **X.1.1** **8 weeks after branch**; **X.1.2** **10 weeks after branch**; **X.1.3** **12 weeks after branch**; **X.1.4** **14 weeks after branch**; **X.1.5** **16 weeks after branch**; **X.1.6 (if necessary)** **18 weeks after branch**; =============================== =========================. Release Process Summary; -----------------------. * Announce release schedule to the LLVM community and update the website. Do; this at least 3 weeks before the -rc1 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:1192,schedul,schedule,1192,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['schedul'],['schedule']
Energy Efficiency,"requires the unicode object to be encoded and by default,; UTF-8 is chosen.; This will give the expected result if all characters in the ``str`` are from; the ASCII set, but otherwise it is recommend to encode on the Python side and; pass the resulting ``bytes`` object instead. `std::wstring`; """""""""""""""""""""""""""". C++'s ""wide"" string, ``std::wstring``, is based on ``wchar_t``, a character; type that is not particularly portable as it can be 2 or 4 bytes in size,; depending on the platform.; cppyy supports ``std::wstring`` directly, using the ``wchar_t`` array; conversions provided by Python's C-API. `const char*`; """""""""""""""""""""""""". The C representation of text, ``const char*``, is problematic for two; reasons: it does not express ownership; and its length is implicit, namely up; to the first occurrence of ``'\0'``.; The first can, up to an extent, be ameliorated: there are a range of cases; where ownership can be inferred.; In particular, if the C string is set from a Python ``str``, it is the latter; that owns the memory and the bound proxy of the former that in turn owns the; (unconverted) ``str`` instance.; However, if the ``const char*``'s memory is allocated in C/C++, memory; management is by necessity fully manual.; Length, on the other hand, can only be known in the case of a fixed array.; However even then, the more common case is to use the fixed array as a; buffer, with the actual string still only extending up to the ``'\0'`` char,; so that is assumed.; (C++'s ``std::string`` suffers from none of these issues and should always be; preferred when you have a choice.). `char*`; """""""""""""". The C representation of a character array, ``char*``, has all the problems of; ``const char*``, but in addition is often used as ""data array of 8-bit int"". `character types`; """""""""""""""""""""""""""""""""". cppyy directly supports the following character types, both as single; variables and in array form: ``char``, ``signed char``, ``unsigned char``,; ``wchar_t``, ``char16_t``, and ``char32_t``. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst:3654,allocate,allocated,3654,bindings/pyroot/cppyy/cppyy/doc/source/strings.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst,1,['allocate'],['allocated']
Energy Efficiency,"respectively. The index expressions shall have integral or unscoped; enumeration type and shall not be uses of the comma operator unless; parenthesized. The first index expression shall evaluate to a; non-negative value less than ``R``, and the second index expression shall; evaluate to a non-negative value less than ``C``, or else the expression has; undefined behavior. If ``E1`` is a prvalue, the result is a prvalue with type; ``T`` and is the value of the element at the given row and column in the matrix.; Otherwise, the result is a glvalue with type ``cv T`` and with the same value; category as ``E1`` which refers to the element at the given row and column in; the matrix. Programs containing a single subscript expression into a matrix are ill-formed. **Note**: We considered providing an expression of the form; ``postfix-expression [expression]`` to access columns of a matrix. We think; that such an expression would be problematic once both column and row major; matrixes are supported: depending on the memory layout, either accessing columns; or rows can be done efficiently, but not both. Instead, we propose to provide; builtins to extract rows and columns from a matrix. This makes the operations; more explicit. Matrix Type Binary Operators; ----------------------------. Given two matrixes, the ``+`` and ``-`` operators perform element-wise addition; and subtraction, while the ``*`` operator performs matrix multiplication.; ``+``, ``-``, ``*``, and ``/`` can also be used with a matrix and a scalar; value, applying the operation to each element of the matrix. Earlier versions of this extension did not support division by a scalar.; You can test for the availability of this feature with; ``__has_extension(matrix_types_scalar_division)``. For the expression ``M1 BIN_OP M2`` where. * ``BIN_OP`` is one of ``+`` or ``-``, one of ``M1`` and ``M2`` is of matrix; type, and the other is of matrix type or real type; or; * ``BIN_OP`` is ``*``, one of ``M1`` and ``M2`` is of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MatrixTypes.rst:4821,efficient,efficiently,4821,interpreter/llvm-project/clang/docs/MatrixTypes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/MatrixTypes.rst,1,['efficient'],['efficiently']
Energy Efficiency,"response; matrix is composed of mutually shifted response functions by one; channel, however of the same shape. ![Original 1-dimensional spectrum](figures/image086.png). ![Response function (one peak)](figures/image088.png). The result after deconvolution is given in Figure 4.3. It substantially; improves the resolution in the spectrum. ![Result after deconvolution](figures/image090.png). We have developed a new high resolution deconvolution algorithm. We have; observed that the Gold deconvolution converges to its stable state; (solution). It is useless to increase the number of iterations, the; result obtained does not change. To continue decreasing the width of; peaks, we have found that when the solution reaches its stable state, it; is necessary to stop iterations, then to change the vector in a way and; repeat again the Gold deconvolution. We have found that in order to change the; particular solution we need to apply a non-linear boosting function to it.; The power function proved to give the best results. At the beginning the; function calculates exact solution of the Toeplitz system of linear; equations. $$ x^{(0)} = [x_e^2(0),x_e^2(1),...,x_e^2(N-1),]^T$$; where; $$ x_e=H^{'-1}y^{'}$$. Then it applies the Gold deconvolution algorithm to the solution and; carries out preset number of iterations. Then the power function with; the exponent equal to the boosting coefficient is applied to the; deconvolved data. These data are then used as initial estimate of the; solution of linear system of equations and again the Gold algorithm is; employed. The whole procedure is repeated `number_of_repetitions` times. The form of the high-resolution deconvolution function is. ```{.cpp}; char *Deconvolution1HighResolution(float *source,; const float *resp,; int size,; int number_of_iterations,; int number_of_repetitions,; double boost);; ```. This function calculates deconvolution from the source spectrum according; to the response spectrum. The result is placed in the vector ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:27921,power,power,27921,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['power'],['power']
Energy Efficiency,"responsible for checking if; the current stacklet has enough space for the function to execute; and if not,; call into the libgcc runtime to allocate more stack space. Segmented stacks are; enabled with the ``""split-stack""`` attribute on LLVM functions. The runtime functionality is `already there in libgcc; <http://gcc.gnu.org/wiki/SplitStacks>`_. Implementation Details; ======================. .. _allocating stacklets:. Allocating Stacklets; --------------------. As mentioned above, the function prologue checks if the current stacklet has; enough space. The current approach is to use a slot in the TCB to store the; current stack limit (minus the amount of space needed to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__morestack``, instead of returning, calls; into ``.LBB0_2``. This is possible since both, the size of the ``ret``; instruction and the PC of call to ``__morestack`` are known. When the function; body returns, control is transferred back to ``__morestack``. ``__morestack``; then de-allocates the new stacklet, restores the correct SP value, and does a; second return, which returns control to the correct caller. Variable S",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:1334,allocate,allocated,1334,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,1,['allocate'],['allocated']
Energy Efficiency,"return y;; }. //===---------------------------------------------------------------------===//. The loop unroller should partially unroll loops (instead of peeling them); when code growth isn't too bad and when an unroll count allows simplification; of some code within the loop. One trivial example is:. #include <stdio.h>; int main() {; int nRet = 17;; int nLoop;; for ( nLoop = 0; nLoop < 1000; nLoop++ ) {; if ( nLoop & 1 ); nRet += 2;; else; nRet -= 1;; }; return nRet;; }. Unrolling by 2 would eliminate the '&1' in both copies, leading to a net; reduction in code size. The resultant code would then also be suitable for; exit value computation. //===---------------------------------------------------------------------===//. We miss a bunch of rotate opportunities on various targets, including ppc, x86,; etc. On X86, we miss a bunch of 'rotate by variable' cases because the rotate; matching code in dag combine doesn't look through truncates aggressively ; enough. Here are some testcases reduces from GCC PR17886:. unsigned long long f5(unsigned long long x, unsigned long long y) {; return (x << 8) | ((y >> 48) & 0xffull);; }; unsigned long long f6(unsigned long long x, unsigned long long y, int z) {; switch(z) {; case 1:; return (x << 8) | ((y >> 48) & 0xffull);; case 2:; return (x << 16) | ((y >> 40) & 0xffffull);; case 3:; return (x << 24) | ((y >> 32) & 0xffffffull);; case 4:; return (x << 32) | ((y >> 24) & 0xffffffffull);; default:; return (x << 40) | ((y >> 16) & 0xffffffffffull);; }; }. //===---------------------------------------------------------------------===//. This (and similar related idioms):. unsigned int foo(unsigned char i) {; return i | (i<<8) | (i<<16) | (i<<24);; } . compiles into:. define i32 @foo(i8 zeroext %i) nounwind readnone ssp noredzone {; entry:; %conv = zext i8 %i to i32; %shl = shl i32 %conv, 8; %shl5 = shl i32 %conv, 16; %shl9 = shl i32 %conv, 24; %or = or i32 %shl9, %conv; %or6 = or i32 %or, %shl5; %or10 = or i32 %or6, %shl; ret i32 %or",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:16789,reduce,reduces,16789,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['reduce'],['reduces']
Energy Efficiency,"rformed for the current point.; Therefore, the first step is to convert the global current point and; direction in the local reference frame of the current volume and to; compute the distance to exit its shape from inside. The returned value; is again compared to the maximum allowed step (the proposed one) and in; case the distance is safe no other action is performed and the proposed; step is approved. In case the boundary is closer, the computed distance; is taken as maximum allowed step. For optimization purposed, for; particles starting very close to the current volume boundary (less than; 0.01 microns) and exiting the algorithm stops here. After computing the distance to exit the current node, the distance to; the daughter of the current volume which is crossed next is computed by; TGeoManager::FindNextDaughterBoundary(). This computes the; distance to all daughter candidates that can be possibly crossed by; using volume voxelization. The algorithm is efficient in average only in; case the number of daughters is greater than 4. For fewer nodes, a; simple loop is performed and the minimum distance (from a point outside; each shape) is taken and compared to the maximum allowed step. The step; value is again updated if `step<stepmax` . A special case is when the current node is declared as possibly; overlapping with something else. If this is the case, the distance is; computed for all possibly overlapping candidates, taking into account; the overlapping priorities (see also: "" Overlapping volumes ""). The global matrix describing the next crossed physical node is; systematically computed in case the value of the proposed step is; negative. In this case, one can subsequently call; TGeoManager::ComputeNormalFast() to get the normal vector to the; crossed surface, after propagating the current point with the; TGeoManager::GetStep() value. This propagation can be done like:. ~~~{.cpp}; Double_t *current_point = gGeoManager->GetCurrentPoint();; Double_t *current_dir = g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:123945,efficient,efficient,123945,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['efficient'],['efficient']
Energy Efficiency,"rforms; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42699,schedul,scheduled,42699,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"riate. These allow to steer building and/or enabling of PAR files; in PROOF-INF/BUILD.sh and/or PROOF-INF/SETUP.C, improving transparency; between normal ROOT and PROOF. The example PAR; 'tutorials/proof/event.par' has been modified to check the two; variables.; Fix a few issues in SQL PROOF monitoring: in; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.Â  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.Â  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:4384,Monitor,MonitorPerPacket,4384,proof/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html,1,['Monitor'],['MonitorPerPacket']
Energy Efficiency,"ric Coordinate System. The vector classes are based on a generic type of coordinate system,; expressed as a template parameter of the class. Various classes exist to; describe the various coordinates systems:. 2D coordinate system classes:. - **`ROOT::Math::Cartesian2D`**, based on (`x,y`);. - **`ROOT::Math::Polar2D`**, based on (`r,phi`);. 3D coordinate system classes:. - **`ROOT::Math::Cartesian3D`**, based on (`x,y,z`);. - **`ROOT::Math::Polar3D`**, based on (`r,theta,phi`);. - **`ROOT::Math::Cylindrical3D`**, based on (`rho,z,phi`). - **`ROOT::Math::CylindricalEta3D`**, based on (`rho,eta,phi`), where; `eta` is the pseudo-rapidity;. 4D coordinate system classes:. - **`ROOT::Math::PxPyPzE4D`**, based on based on (`px,py,pz,E`);. - **`ROOT::Math::PxPyPzM4D`**, based on based on (`px,py,pz,M`);. - **`ROOT::Math::PtEtaPhiE4D`**, based on based on (`pt,eta,phi,E`);. - **`ROOT::Math::PtEtaPhiM4D`**, based on based on (`pt,eta,phi,M`);. Users can define the vectors according to the coordinate type, which is; the most efficient for their use. Transformations between the various; coordinate systems are available through copy constructors or the; assignment (=) operator. For maximum flexibility and minimize memory; allocation, the coordinate system classes are templated on the scalar; type. To avoid exposing templated parameter to the users, typedefs are; defined for all types of vectors based on doubles. See in the examples; for all the possible types of vector classes, which can be constructed; by users with the available coordinate system types. #### Coordinate System Tag. The 2D and 3D points and vector classes can be associated to a tag; defining the coordinate system. This can be used to distinguish between; vectors of different coordinate systems like global or local vectors.; The coordinate system tag is a template parameter of the; **`ROOT::Math::`**`DisplacementVector3D` and; `ROOT::Math::PositionVector3D` (and also for 2D classes). A default tag; exists for user",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:71417,efficient,efficient,71417,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['efficient'],['efficient']
Energy Efficiency,"rical variable:; Int_t value;; tree->Branch(branchname, &value);. Introduce a way to create branch using directly; an object:; MyClass object;; TBranch *branch = tree->Branch(branchname, &object, bufsize, splitlevel); Clarify the ownership rules of user objects in a TTree. This clarification (and the improved auto-add-to-directory behavior; of the TH1*) allows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:1114,allocate,allocate,1114,tree/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html,4,['allocate'],"['allocate', 'allocated']"
Energy Efficiency,"ring """"; Int_t wid = embed->GetCanvasWindowId();; TCanvas *myc = new TCanvas(""myname"",10,10,wid);; embed->AdoptCanvas(myc);; // the TCanvas is adopted by the embedded canvas and will be; // destroyed by it; ```. ## The ROOT Graphics Editor (GED). Everything drawn in a ROOT canvas is an object. There are classes for; all objects, and they fall into hierarchies. In addition, the ROOT has; fully cross-platform GUI classes and provides all standard components; for an application environment with common â€˜look and feel'. The; object-oriented, event-driven programming model supports the modern; signals/slots communication mechanism. It handles user interface actions; and allows total independence of interacting objects and classes. This; mechanism uses the ROOT dictionary information and the Cling the C++; Interpreter to connect signals to slots methods. Therefore, all necessary elements for an object-oriented editor design; are in place. The editor complexity can be reduced by splitting it into; discrete units of so-called *`object`* *`editors`*. Any object editor; provides an object specific GUI. The main purpose of the ROOT graphics; editor is the organization of the object editors' appearance and the; task sequence between them. ### Object Editors. Every object editor follows a simple naming convention: to have as a; name the object class name concatenated with â€˜*`Editor`*' (e.g. for; **`TGraph`** objects the object editor is **`TGraphEditor`**). Thanks to; the signals/slots communication mechanism and to the method; `DistancetoPrimitive()` that computes a â€˜â€˜distance'' to an object from; the mouse position, it was possible to implement a signal method of the; canvas that says which is the selected object and to which pad it; belongs. Having this information the graphics editor loads the; corresponding object editor and the user interface is ready for use.; This way after a click on â€˜axis'â€”the axis editor is active; a click on a; â€˜pad' activates the pad editor, etc. The ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md:101891,reduce,reduced,101891,documentation/users-guide/WritingGUI.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md,1,['reduce'],['reduced']
Energy Efficiency,"rinsic performs the signed-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.smin <int_vector_reduce_smin>`) of the; vector operand ``val`` on each enabled lane, and taking the minimum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MAX`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smin.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. '``llvm.vp.reduce.umax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:766866,reduce,reduce,766866,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ritten by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26052,schedul,scheduler,26052,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"rk on C++20, C++23, C++2c, and C23 support:; There are still several C++20 features to complete, and work has begun on; supporting the latest language standards. Please see the; C++ status report page to find out what is; missing.; StringRef'ize APIs: A thankless but incredibly useful project is; StringRef'izing (converting to use llvm::StringRef instead of const; char * or std::string) various clang interfaces. This generally; simplifies the code and makes it more efficient.; Configuration Manager: Clang/LLVM works on a large number of; architectures and operating systems and can cross-compile to a similarly large; number of configurations, but the pitfalls of choosing the command-line; options, making sure the right sub-architecture is chosen and that the correct; optional elements of your particular system can be a pain. A tool that would investigate hosts and targets, and store the configuration; in files that can later be used by Clang itself to avoid command-line options,; especially the ones regarding which target options to use, would greatly alleviate; this problem. A simple tool, with little or no dependency on LLVM itself, that; will investigate a target architecture by probing hardware, software, libraries; and compiling and executing code to identify all properties that would be relevant; to command-line options (VFP, SSE, NEON, ARM vs. Thumb etc), triple settings etc.; The first stage is to build a CFLAGS for Clang that would produce code on the; current Host to the identified Target.; The second stage would be to produce a configuration file (that can be used; independently of the Host) so that Clang can read it and not need a gazillion; of command-line options. Such file should be simple JSON / INI or anything that; a text editor could change. If you hit a bug with Clang, it is very useful for us if you reduce the code; that demonstrates the problem down to something small. There are many ways to; do this; ask on Discourse,; Discord,; or for advice. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/OpenProjects.html:6707,reduce,reduce,6707,interpreter/llvm-project/clang/www/OpenProjects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/OpenProjects.html,2,['reduce'],['reduce']
Energy Efficiency,"rk written entirely by you; rather, the intent is to; exercise the right to control the distribution of derivative or; collective works based on the Program. In addition, mere aggregation of another work not based on the Program; with the Program (or with a work based on the Program) on a volume of; a storage or distribution medium does not bring the other work under; the scope of this License. 3. You may copy and distribute the Program (or a work based on it,; under Section 2) in object code or executable form under the terms of; Sections 1 and 2 above provided that you also do one of the following:. a) Accompany it with the complete corresponding machine-readable; source code, which must be distributed under the terms of Sections; 1 and 2 above on a medium customarily used for software interchange; or,. b) Accompany it with a written offer, valid for at least three; years, to give any third party, for a charge no more than your; cost of physically performing source distribution, a complete; machine-readable copy of the corresponding source code, to be; distributed under the terms of Sections 1 and 2 above on a medium; customarily used for software interchange; or,. c) Accompany it with the information you received as to the offer; to distribute corresponding source code. (This alternative is; allowed only for noncommercial distribution and only if you; received the program in object code or executable form with such; an offer, in accord with Subsection b above.). The source code for a work means the preferred form of the work for; making modifications to it. For an executable work, complete source; code means all the source code for all modules it contains, plus any; associated interface definition files, plus the scripts used to; control compilation and installation of the executable. However, as a; special exception, the source code distributed need not include; anything that is normally distributed (in either source or binary; form) with the major components (co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt:7393,charge,charge,7393,misc/rootql/LICENSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt,4,['charge'],['charge']
Energy Efficiency,"rm to pass off to a optimizer or backend. Because; validity analysis and code generation can largely be done on the fly, there is; not hard requirement that the front-end actually build up a full AST for all; the expressions and statements in the code. TCC and GCC are examples of; compilers that either build no real AST (in the former case) or build a stripped; down and simplified AST (in the later case) because they focus primarily on; codegen.; On the opposite side of the spectrum, some clients (like refactoring) want; highly detailed information about the original source code and want a complete; AST to describe it with. Refactoring wants to have information about macro; expansions, the location of every paren expression '(((x)))' vs 'x', full; position information, and much more. Further, refactoring wants to look; across the whole program to ensure that it is making transformations; that are safe. Making this efficient and getting this right requires a; significant amount of engineering and algorithmic work that simply are; unnecessary for a simple static compiler.; The beauty of the clang approach is that it does not restrict how you use it.; In particular, it is possible to use the clang preprocessor and parser to build; an extremely quick and light-weight on-the-fly code generator (similar to TCC); that does not build an AST at all. As an intermediate step, clang supports; using the current AST generation and semantic analysis code and having a code; generation client free the AST for each function after code generation. Finally,; clang provides support for building and retaining fully-fledged ASTs, and even; supports writing them out to disk.; Designing the libraries with clean and simple APIs allows these high-level; policy decisions to be determined in the client, instead of forcing ""one true; way"" in the implementation of any of these libraries. Getting this right is; hard, and we don't always get it right the first time, but we fix any problems; when we ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html:8018,efficient,efficient,8018,interpreter/llvm-project/clang/www/features.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html,2,['efficient'],['efficient']
Energy Efficiency,"rmance than pruning. (The; pruning mechanism needs to be revisited). MLP:; Introduced recognition of convergence via general ConvergenceTest-class for; interrupting computations when convergence is reached. This feature has is; used now in MethodMLP. Improved treatment of event-weights in BFGS training. Implemented random and importance sampling of events in DataSet. Implemented; the usage of this feature for MLP.; ; TMlpANN (interface to TMultiLayerPerceptron) now also uses event weights; and writes standalone C++ class. k-NN:; A new global knn search function has been added to NodekNN that searches for; k-nearest neighbor using event weights instead of raw event counts. ModulekNN; has been modified to allow searches using ""weight"" or ""count"" option, where; ""count"" is default. Added UseWeight option to MethodKNN to allow using of; ""weight"" or ""count"". ; (Work by Rustem Ospanov, CERN). . Likelihood (and general PDF treatment):; Adaptive smoothing the PDF class, allowing it to smooth between MinSmoothNum ; (for regions with more signal) and MaxSmoothNum (for regions with less signal). . Configuration of the PDF parameters from the option string moved to PDF class,; allowing the user to define all the PDF functionalities in every classifier; the PDF is used (i.e., also for the MVA PDFs). The reading of these variables; was removed from MethodBase and MethodLikelihood. This also allows improved ; (full) PDF configuration of MVA output via the ""CreateMvaPdf"" option.; (Work by Or Cohen, CERN & Weizmann); ; New generalisation methods:. ; MethodCompositeBase: combines more than one; classifier within one. MethodBoost: boosts/bags any classifier; type. A special booking procedure for it was added to; Factory class. MethodDT: a classifier composed of a single; decision tree, boosted using MethodBoost. Results are; compatible with BDT, but BDT remains the default for boosted; decision trees, because it has pruning (among other; additional features). . Other improvements . Imp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:3988,Adapt,Adaptive,3988,tmva/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html,1,['Adapt'],['Adaptive']
Energy Efficiency,"rmat). By providing code, you agree to transfer your copyright on the code to the ""ROOT project"".; Of course you will be duly credited: for sizable contributions your name will appear in the; [CREDITS](https://raw.githubusercontent.com/root-project/root/master/README/CREDITS); file shipped with every binary and source distribution.; The copyright transfer helps us with effectively defending the project in case of litigation. ## Your Commit. Each commit is a self-contained, _atomic_ change. This means that:; 1. **Each commit should be able to successfully build ROOT.**; Doing so makes traveling through the git history, for example during a `git bisect` much easier.; Ideally, the commit also should not depend on other commits to _run_ ROOT.; 2. **Each commit does not contain more than one independent change.**; This allows us to revert changes when needed, without affecting anything else. > [!TIP]; > During a code review, it may be useful to make smaller commits to track intermediate changes, and rebase after the PR; > is approved to ensure the above points are met and to reduce clutter. ### Your Commit Message. The commit summary (i.e. the first line of the commit message) should be preceded by the a tag indicating the scope of; ROOT that is affected by your commit, in square brackets. Most tags are self-describing (e.g., `[tree]` indicates a; change to TTree, `[RF]` indicates a change to RooFit). If you are unsure about which scope tags to use, we are happy to; point you in the right direction! See also the [commit log](https://github.com/root-project/root/commits/master/) for; examples. The summary itself should not exceed 50 characters (excluding the scope tag), be meaningful (i.e., it; describes the change) and should be written in the; [present imperative mood](https://git.kernel.org/pub/scm/git/git.git/tree/Documentation/SubmittingPatches?id=HEAD#n239); (e.g. `Add this awesome feature` instead of `Adds this awesome feature` or `Added this awesome feature`). The ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/CONTRIBUTING.md:2284,reduce,reduce,2284,CONTRIBUTING.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/CONTRIBUTING.md,1,['reduce'],['reduce']
Energy Efficiency,"rn the cosine of the operand. Arguments:; """""""""""""""""""". The argument and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``cos``' function but without; trapping or setting ``errno``. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. '``llvm.pow.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.pow`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.pow.f32(float %Val, float %Power); declare double @llvm.pow.f64(double %Val, double %Power); declare x86_fp80 @llvm.pow.f80(x86_fp80 %Val, x86_fp80 %Power); declare fp128 @llvm.pow.f128(fp128 %Val, fp128 %Power); declare ppc_fp128 @llvm.pow.ppcf128(ppc_fp128 %Val, ppc_fp128 Power). Overview:; """""""""""""""""". The '``llvm.pow.*``' intrinsics return the first operand raised to the; specified (positive or negative) power. Arguments:; """""""""""""""""""". The arguments and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``pow``' function but without; trapping or setting ``errno``. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. .. _int_exp:. '``llvm.exp.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.exp`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.exp.f32(float %Val); declare double @llvm.exp.f64(double %Val); declare x86_fp80 @llvm.exp.f80(x86_fp80 %Val); declare fp128 @llvm.exp.f128(fp128 %Val); declare ppc_fp128 @llvm.exp.ppcf128(ppc_fp128 %Val). Overview:; """""""""""""""""". The '``llvm.exp.*``' intrinsics compute the base-e exponential of the specified; value. Arguments:; """"""""""""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:561276,power,power,561276,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"rnal covariance matrix; designed for the interaction of the user. The result of the minimization; (internal covariance matrix) is converted into the user representable; format. It can also be used as input prior to the minimization. The size; of the covariance matrix is according to the number of variable; parameters (free and limited). ### MnUserCovariance(const std::vector$<$double$>$&, unsigned int nrow) ###. Construct from data, positions of the elements in the array are arranged; according to the packed storage format. The size of the array must be; $nrow*(nrow+1)/2$. The array must contain the upper triangular part of; the symmetric matrix packed sequentially, column by column, so that; arr(0) contains covar(0,0), arr(1) and arr(2) contain covar(0,1) and; covar(1,1) respectively, and so on. The number of rows (columns) has to; be specified. ### MnUserCovariance(unsigned int nrow) ###. Specify the number of rows (columns) at instantiation. It will allocate; an array of the length $nrow*(nrow+1)/2$ and initialize it to $0$.; Elements can then be set using the method operator()(unsigned int,; unsigned int). ### MnUserCovariance::operator()(unsigned int, unsigned int) ###. Individual elements can be accessed via the operator(), both for reading; and writing. ## MnUserParameters ##. [api:parameters] MnUserParameters is the main class for user interaction; with the parameters. It serves both as input to the minimization as well; as output as the result of the minimization is converted into the user; representable format in order to allow for further interaction.; Parameters for M can be added (defined) specifying a name, value and; initial uncertainty. ### add(...) ###. The method MnUserParameters::add(...) is overloaded for three kind of; parameters:. - add(const char\*, double, double) for adding a free variable; parameter. - add(const char\*, double, double, double, double) for adding a; variable parameter with limits (lower and upper). - add(const char\*, double)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:52724,allocate,allocate,52724,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['allocate'],['allocate']
Energy Efficiency,"rocess the one closed to the end of functions; first. This may simply CreateNewWater. //===---------------------------------------------------------------------===//. Eliminate copysign custom expansion. We are still generating crappy code with; default expansion + if-conversion. //===---------------------------------------------------------------------===//. Eliminate one instruction from:. define i32 @_Z6slow4bii(i32 %x, i32 %y) {; %tmp = icmp sgt i32 %x, %y; %retval = select i1 %tmp, i32 %x, i32 %y; ret i32 %retval; }. __Z6slow4bii:; cmp r0, r1; movgt r1, r0; mov r0, r1; bx lr; =>. __Z6slow4bii:; cmp r0, r1; movle r0, r1; bx lr. //===---------------------------------------------------------------------===//. Implement long long ""X-3"" with instructions that fold the immediate in. These; were disabled due to badness with the ARM carry flag on subtracts. //===---------------------------------------------------------------------===//. More load / store optimizations:; 1) Better representation for block transfer? This is from Olden/power:. 	fldd d0, [r4]; 	fstd d0, [r4, #+32]; 	fldd d0, [r4, #+8]; 	fstd d0, [r4, #+40]; 	fldd d0, [r4, #+16]; 	fstd d0, [r4, #+48]; 	fldd d0, [r4, #+24]; 	fstd d0, [r4, #+56]. If we can spare the registers, it would be better to use fldm and fstm here.; Need major register allocator enhancement though. 2) Can we recognize the relative position of constantpool entries? i.e. Treat. 	ldr r0, LCPI17_3; 	ldr r1, LCPI17_4; 	ldr r2, LCPI17_5. as; 	ldr r0, LCPI17; 	ldr r1, LCPI17+4; 	ldr r2, LCPI17+8. Then the ldr's can be combined into a single ldm. See Olden/power. Note for ARM v4 gcc uses ldmia to load a pair of 32-bit values to represent a; double 64-bit FP constant:. 	adr	r0, L6; 	ldmia	r0, {r0-r1}. 	.align 2; L6:; 	.long	-858993459; 	.long	1074318540. 3) struct copies appear to be done field by field; instead of by words, at least sometimes:. struct foo { int x; short s; char c1; char c2; };; void cpy(struct foo*a, struct foo*b) { *a = *b; }",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:2916,power,power,2916,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['power'],['power']
Energy Efficiency,"rocess.; In most UNIX systems, thread and process characteristics are grouped; into a single entity called a process. Sometimes, threads are called; ""lightweight processes''. Note: This introduction is adapted from the AIX 4.3 Programmer's Manual. ## Threads and Processes. In traditional single-threaded process systems, a process has a set of; properties. In multi-threaded systems, these properties are divided; between processes and threads. ### Process Properties. A process in a multi-threaded system is the changeable entity. It must; be considered as an execution frame. It has all traditional process; attributes, such as:. - Process ID, process group ID, user ID, and group ID. - Environment. - Working directory. A process also provides a common address space and common system; resources:. - File descriptors. - Signal actions. - Shared libraries. - Inter-process communication tools (such as message queues, pipes,; semaphores, or shared memory). ### Thread Properties. A thread is the schedulable entity. It has only those properties that; are required to ensure its independent flow of control. These include; the following properties:. - Stack. - Scheduling properties (such as policy or priority). - Set of pending and blocked signals. - Some thread-specific data (TSD). An example of thread-specific data is the error indicator, `errno`. In; multi-threaded systems, `errno` is no longer a global variable, but; usually a subroutine returning a thread-specific `errno` value. Some; other systems may provide other implementations of `errno`. With respect; to ROOT, a thread specific data is for example the ***`gPad`*** pointer,; which is treated in a different way, whether it is accessed from any; thread or the main thread. Threads within a process must not be considered as a group of processes; (even though in Linux each thread receives an own process id, so that it; can be scheduled by the kernel scheduler). All threads share the same; address space. This means that two poi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:1147,schedul,schedulable,1147,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['schedul'],['schedulable']
Energy Efficiency,"roducing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43587,schedul,scheduler,43587,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduler']
Energy Efficiency,rofgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h;,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337453,reduce,reduce,337453,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"rs containing; the referenced objects are saved in the table of references. When the; Tree header is saved (via `TTree::Write` for example), the branch is; saved, keeping the information with the pointers to the branches having; referenced objects. Enabling this optional table, allow; `TTree::Draw` to automatically load the branches needed to; dereference a **`TRef`** (or **`TRefArray`**) object. ### Autosave. `Autosave` gives the option to save all branch buffers every `n` byte.; We recommend using `Autosave` for large acquisitions. If the acquisition; fails to complete, you can recover the file and all the contents since; the last `Autosave`. To set the number of bytes between `Autosave` you; can use the `TTree::SetAutosave()` method. You can also call; **`TTree::Autosave` in the acquisition loop every `n `entry.**. ### Trees with Circular Buffers. When a **`TTree`** is memory resident, you set it up so that it retains; retain only the last few entries. For example, this can be very useful; for monitoring purpose. ``` {.cpp}; void TTree::SetCircular(Long64_t maxEntries);; ```. where `maxEntries` is the maximum number of entries to be kept in the; buffers. When the number of entries exceeds this value, the first; entries in the **`Tree`** are deleted and the buffers used again. An; example of a script using a circular buffer is shown below:. ``` {.cpp}; void circular() {; gROOT->cd(); //make sure that the Tree is memory resident; TTree *T = new TTree(""T"",""test circular buffers"");; TRandom r;; Float_t px,py,pz;; Double_t random;; UShort_t i;; T->Branch(""px"",&px,""px/F"");; T->Branch(""py"",&py,""py/F"");; T->Branch(""pz"",&pz,""pz/F"");; T->Branch(""random"",&random,""random/D"");; T->Branch(""i"",&i,""i/s"");; T->SetCircular(20000);; for (i = 0; i < 65000; i++) {; r.Rannor(px,py);; pz = px*px + py*py;; random = r.Rndm();; T->Fill();; }; T->Print();; }; ```. ### Size of TTree in the File. When writing a **`TTree`** to a file, if the file size reaches the value; stored in the `TTree::",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:13976,monitor,monitoring,13976,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['monitor'],['monitoring']
Energy Efficiency,"rs, list file; generators, and pretty-printers, which need more than the raw instructions and; the ability to print them. To provide this functionality the assembly text is marked up with annotations.; The markup is simple enough in syntax to be robust even in the case of version; mismatches between consumers and producers. That is, the syntax generally does; not carry semantics beyond ""this text has an annotation,"" so consumers can; simply ignore annotations they do not understand or do not care about. After calling ``LLVMCreateDisasm()`` to create a disassembler context the; optional output is enable with this call:. .. code-block:: c. LLVMSetDisasmOptions(DC, LLVMDisassembler_Option_UseMarkup);. Then subsequent calls to ``LLVMDisasmInstruction()`` will return output strings; with the marked up annotations. Instruction Annotations; =======================. .. _contextual markups:. Contextual markups; ------------------. Annotated assembly display will supply contextual markup to help clients more; efficiently implement things like pretty printers. Most markup will be target; independent, so clients can effectively provide good display without any target; specific knowledge. Annotated assembly goes through the normal instruction printer, but optionally; includes contextual tags on portions of the instruction string. An annotation; is any '<' '>' delimited section of text(1). .. code-block:: bat. annotation: '<' tag-name tag-modifier-list ':' annotated-text '>'; tag-name: identifier; tag-modifier-list: comma delimited identifier list. The tag-name is an identifier which gives the type of the annotation. For the; first pass, this will be very simple, with memory references, registers, and; immediates having the tag names ""mem"", ""reg"", and ""imm"", respectively. The tag-modifier-list is typically additional target-specific context, such as; register class. Clients should accept and ignore any tag-names or tag-modifiers they do not; understand, allowing the annotations t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkedUpDisassembly.rst:1564,efficient,efficiently,1564,interpreter/llvm-project/llvm/docs/MarkedUpDisassembly.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MarkedUpDisassembly.rst,1,['efficient'],['efficiently']
Energy Efficiency,"rt value, one (``1.0``) can be used, as it is the neutral; value of floating point multiplication. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fmul.v4f32(float 1.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_and:. '``llvm.vector.reduce.and.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:655597,reduce,reduce,655597,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"rt.f128(fp128 %Val); declare ppc_fp128 @llvm.sqrt.ppcf128(ppc_fp128 %Val). Overview:; """""""""""""""""". The '``llvm.sqrt``' intrinsics return the square root of the specified value. Arguments:; """""""""""""""""""". The argument and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``sqrt``' function but without; trapping or setting ``errno``. For types specified by IEEE-754, the result; matches a conforming libm implementation. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. '``llvm.powi.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.powi`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. Generally, the only supported type for the exponent is the one matching; with the C type ``int``. ::. declare float @llvm.powi.f32.i32(float %Val, i32 %power); declare double @llvm.powi.f64.i16(double %Val, i16 %power); declare x86_fp80 @llvm.powi.f80.i32(x86_fp80 %Val, i32 %power); declare fp128 @llvm.powi.f128.i32(fp128 %Val, i32 %power); declare ppc_fp128 @llvm.powi.ppcf128.i32(ppc_fp128 %Val, i32 %power). Overview:; """""""""""""""""". The '``llvm.powi.*``' intrinsics return the first operand raised to the; specified (positive or negative) power. The order of evaluation of; multiplications is not defined. When a vector of floating-point type is; used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The second argument is an integer power, and the first is a value to; raise to that power. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.sin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sin`` on any; floating-point or vector of floating-point type. No",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:558006,power,power,558006,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ruct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }. static const bool flow = true;; }. Flow mappings are subject to line wrapping according to the Output object; configuration. Sequence; ========. To be translated to or from a YAML sequence for your type T you must specialize; llvm::yaml::SequenceTraits on T and implement two methods:; ``size_t size(IO &io, T&)`` and; ``T::value_type& element(IO &io, T&, size_t indx)``. For example:. .. code-block:: c++. template <>; struct SequenceTraits<MySeq> {; static size_t size(IO &io, MySeq &list) { ... }; static MySeqEl &element(IO &io, MySeq &list, size_t index) { ... }; };. The size() method returns how many elements are currently in your sequence.; The element() method returns a reference to the i'th element in the sequence.; When parsing YAML, the element() method may be called with an index one bigger; than the current size. Your element() method should allocate space for one; more element (using default constructor if element is a C++ object) and returns; a reference to that new allocated space. Flow Sequence; -------------; A YAML ""flow sequence"" is a sequence that when written to YAML it uses the; inline notation (e.g [ foo, bar ] ). To specify that a sequence type should; be written in YAML as a flow sequence, your SequenceTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. template <>; struct SequenceTraits<MyList> {; static size_t size(IO &io, MyList &list) { ... }; static MyListEl &element(IO &io, MyList &list, size_t index) { ... }. // The existence of this member causes YAML I/O to use a flow sequence; static const bool flow = true;; };. With the above, if you used MyList as the data type in your native data; structures, then when converted to YAML, a flow sequence of integers; will be used (e.g. [ 10, -3, 4 ]). Flow sequences are subject to line wrapping according to the Output object; configuration. Utility Macros; --------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:25595,allocate,allocate,25595,interpreter/llvm-project/llvm/docs/YamlIO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst,2,['allocate'],"['allocate', 'allocated']"
Energy Efficiency,"ructor otherwise it returns the object as; is (unless a string is passed as the 2nd argument to the function in which case,; it also calls Clear(second_argument) on the object).; This allows to replace code like:. for (int i = 0; i < ev->Ntracks; i++) {; new(a[i]) TTrack(x,y,z,...);; ...; ...; }; ...; a.Delete(); // or a.Clear(""C""). with the simpler and more efficient:. for (int i = 0; i < ev->Ntracks; i++) {; TTrack *track = (TTrack*)a.ConstructedAt(i);; track->Set(x,y,z,....);; ...; ...; }; ...; a.Clear();. even in case where the TTrack class allocates memory. TClonesArray: update ExpandCreateFast to also reset the non-used slots; so that calling Clear (which does too much) is no longer necessary; when using ExpandCreateFast. New Thread Pool class. A first version of TThreadPool class has been introduced.; This class implements a Thread Pool pattern.; So far it supports only one type of queue - FIFO. Thread library. Reduces risk of internal dead lock by using a private internal lock to protect the internals of TThread, rather than using TThread::Lock. New header TThreadSlots.h to centralize and formalize the use of the TThread local memory slots amongst the ROOT packages. Global Variables. The global values gPad, gVirtualX, gInterpreter, gDirectory and gFile; are now all accessed via a static function of their respective class. The; access is made transparent via a CPP macro.; The access is now also made transparent from the CINT and python prompt.; gPad, gVirtualX and gInterpreter are now accessible even when their value; is zero and they now properly support tab completion.; See the important note in the I/O section on gDirectory and gFile which; are now thread local. Meta. The new interface TDictionary::GetDictionary(const char*) offers a; single entry point to query the type based on its name, conveniently combining; TDataType and TClass queries. It does name normalization (removing std etc). Add the ability to explicitly forbid (or allow) the splitting of a c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v532/index.html:2627,Reduce,Reduces,2627,core/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v532/index.html,1,['Reduce'],['Reduces']
Energy Efficiency,"runtime stack, returning a pointer of the; appropriate type to the program. If ""NumElements"" is specified, it is; the number of elements allocated, otherwise ""NumElements"" is defaulted; to be one. If a constant alignment is specified, the value result of the; allocation is guaranteed to be aligned to at least that boundary. The; alignment may not be greater than ``1 << 32``. The alignment is only optional when parsing textual IR; for in-memory IR,; it is always present. If not specified, the target can choose to align the; allocation on any convenient boundary compatible with the type. '``type``' may be any sized type. Structs containing scalable vectors cannot be used in allocas unless all; fields are the same scalable vector type (e.g. ``{<vscale x 2 x i32>,; <vscale x 2 x i32>}`` contains the same type while ``{<vscale x 2 x i32>,; <vscale x 2 x i64>}`` doesn't). Semantics:; """""""""""""""""""". Memory is allocated; a pointer is returned. The allocated memory is; uninitialized, and loading from uninitialized memory produces an undefined; value. The operation itself is undefined if there is insufficient stack; space for the allocation.'``alloca``'d memory is automatically released; when the function returns. The '``alloca``' instruction is commonly used; to represent automatic variables that must have an address available. When; the function returns (either with the ``ret`` or ``resume`` instructions),; the memory is reclaimed. Allocating zero bytes is legal, but the returned; pointer may not be unique. The order in which memory is allocated (ie.,; which way the stack grows) is not specified. Note that '``alloca``' outside of the alloca address space from the; :ref:`datalayout string<langref_datalayout>` is meaningful only if the; target has assigned it a semantics. If the returned pointer is used by :ref:`llvm.lifetime.start <int_lifestart>`,; the returned object is initially dead.; See :ref:`llvm.lifetime.start <int_lifestart>` and; :ref:`llvm.lifetime.end <int_lifeend>`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:410488,allocate,allocated,410488,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"rver QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions that can be hand-mitigated in ways that have lower; performance overhead while the remainder of the application receives automatic; protection. For both limiting the scope of mitigation or manually miti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48991,reduce,reduce,48991,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['reduce'],['reduce']
Energy Efficiency,"rview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ==========",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1247,reduce,reduce,1247,interpreter/llvm-project/llvm/docs/CFIVerify.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst,1,['reduce'],['reduce']
Energy Efficiency,"ry to instantiate the; templates.; * For each subexpression, be sure to call ``Sema::CheckPlaceholderExpr()``; to deal with ""weird"" expressions that don't behave well as subexpressions.; Then, determine whether you need to perform lvalue-to-rvalue conversions; (``Sema::DefaultLvalueConversions``) or the usual unary conversions; (``Sema::UsualUnaryConversions``), for places where the subexpression is; producing a value you intend to use.; * Your ``BuildXXX`` function will probably just return ``ExprError()`` at; this point, since you don't have an AST. That's perfectly fine, and; shouldn't impact your testing. #. Introduce an AST node for your new expression. This starts with declaring; the node in ``include/Basic/StmtNodes.td`` and creating a new class for your; expression in the appropriate ``include/AST/Expr*.h`` header. It's best to; look at the class for a similar expression to get ideas, and there are some; specific things to watch for:. * If you need to allocate memory, use the ``ASTContext`` allocator to; allocate memory. Never use raw ``malloc`` or ``new``, and never hold any; resources in an AST node, because the destructor of an AST node is never; called.; * Make sure that ``getSourceRange()`` covers the exact source range of your; expression. This is needed for diagnostics and for IDE support.; * Make sure that ``children()`` visits all of the subexpressions. This is; important for a number of features (e.g., IDE support, C++ variadic; templates). If you have sub-types, you'll also need to visit those; sub-types in ``RecursiveASTVisitor``.; * Add printing support (``StmtPrinter.cpp``) for your expression.; * Add profiling support (``StmtProfile.cpp``) for your AST node, noting the; distinguishing (non-source location) characteristics of an instance of; your expression. Omitting this step will lead to hard-to-diagnose; failures regarding matching of template declarations.; * Add serialization support (``ASTReaderStmt.cpp``, ``ASTWriterStmt.cpp``); for your",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:148275,allocate,allocate,148275,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,2,['allocate'],['allocate']
Energy Efficiency,"ry. The unswizzled SP can be used with buffer instructions as an unswizzled SGPR; offset with the scratch V# in SGPR0-3 to access the stack in a swizzled; manner. The unswizzled SP value can be converted into the swizzled SP value by:. | swizzled SP = unswizzled SP / wavefront size. This may be used to obtain the private address space address of stack; objects and to convert this address to a flat address by adding the flat; scratch aperture base address. The swizzled SP value is always 4 bytes aligned for the ``r600``; architecture and 16 byte aligned for the ``amdgcn`` architecture. .. note::. The ``amdgcn`` value is selected to avoid dynamic stack alignment for the; OpenCL language which has the largest base type defined as 16 bytes. On entry, the swizzled SP value is the address of the first function; argument passed on the stack. Other stack passed arguments are positive; offsets from the entry swizzled SP value. The function may use positive offsets beyond the last stack passed argument; for stack allocated local variables and register spill slots. If necessary,; the function may align these to greater alignment than 16 bytes. After these; the function may dynamically allocate space for such things as runtime sized; ``alloca`` local allocations. If the function calls another function, it will place any stack allocated; arguments after the last local allocation and adjust SGPR32 to the address; after the last local allocation. 9. All other registers are unspecified.; 10. Any necessary ``s_waitcnt`` has been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struct; arguments in C ABI. Callee is responsible for allocating stack memory and; copying the value of the struct if modified. Note that the backend still; supports byval for struct arguments. On exit from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:389362,allocate,allocated,389362,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"s ``dest`` as a copy of ``src``. It is undefined; behavior to call this function with an already initialized ``dest`` argument. Memory builtins; ---------------. Clang provides constant expression evaluation support for builtin forms of the; following functions from the C standard library headers; ``<string.h>`` and ``<wchar.h>``:. * ``memcpy``; * ``memmove``; * ``wmemcpy``; * ``wmemmove``. In each case, the builtin form has the name of the C library function prefixed; by ``__builtin_``. Constant evaluation support is only provided when the source and destination; are pointers to arrays with the same trivially copyable element type, and the; given size is an exact multiple of the element size that is no greater than; the number of elements accessible through the source and destination operands. Guaranteed inlined copy; ^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c. void __builtin_memcpy_inline(void *dst, const void *src, size_t size);. ``__builtin_memcpy_inline`` has been designed as a building block for efficient; ``memcpy`` implementations. It is identical to ``__builtin_memcpy`` but also; guarantees not to call any external functions. See LLVM IR `llvm.memcpy.inline; <https://llvm.org/docs/LangRef.html#llvm-memcpy-inline-intrinsic>`_ intrinsic; for more information. This is useful to implement a custom version of ``memcpy``, implement a; ``libc`` memcpy or work around the absence of a ``libc``. Note that the `size` argument must be a compile time constant. Note that this intrinsic cannot yet be called in a ``constexpr`` context. Guaranteed inlined memset; ^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c. void __builtin_memset_inline(void *dst, int value, size_t size);. ``__builtin_memset_inline`` has been designed as a building block for efficient; ``memset`` implementations. It is identical to ``__builtin_memset`` but also; guarantees not to call any external functions. See LLVM IR `llvm.memset.inline; <https://llvm.org/docs/LangRef.html#llvm-memset-inline-intrinsic>`_ ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:138182,efficient,efficient,138182,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['efficient'],['efficient']
Energy Efficiency,"s a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new class can be constructed only from a; ModelConfig; One can specify a TestStatSampler in the constructor (which implies a choice of a TestStatistic, or by default the tool will use the ToyMCSampler and the RatioOfProfiledLikelihoods; The interface of the new HybridCalculator class is now more uniform with the other calculator tools, which is different from the original; HybridCalculator's interface. Users wishing to run their old macro are advised to use ModelConfig, but if that is too time consuming one can jus",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:4399,green,green,4399,roofit/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html,2,['green'],['green']
Energy Efficiency,"s a runtime error to attempt to assign a reference to a; stack-based Block into any storage marked ``__weak``, including; ``__weak`` ``__block`` variables. C++ Extensions; ==============. Block literal expressions within functions are extended to allow const; use of C++ objects, pointers, or references held in automatic storage. As usual, within the block, references to captured variables become; const-qualified, as if they were references to members of a const; object. Note that this does not change the type of a variable of; reference type. For example, given a class Foo:. .. code-block:: c. Foo foo;; Foo &fooRef = foo;; Foo *fooPtr = &foo;. A Block that referenced these variables would import the variables as; const variations:. .. code-block:: c. const Foo block_foo = foo;; Foo &block_fooRef = fooRef;; Foo *const block_fooPtr = fooPtr;. Captured variables are copied into the Block at the instant of; evaluating the Block literal expression. They are also copied when; calling ``Block_copy()`` on a Block allocated on the stack. In both; cases, they are copied as if the variable were const-qualified, and; it's an error if there's no such constructor. Captured variables in Blocks on the stack are destroyed when control; leaves the compound statement that contains the Block literal; expression. Captured variables in Blocks on the heap are destroyed; when the reference count of the Block drops to zero. Variables declared as residing in ``__block`` storage may be initially; allocated in the heap or may first appear on the stack and be copied; to the heap as a result of a ``Block_copy()`` operation. When copied; from the stack, ``__block`` variables are copied using their normal; qualification (i.e. without adding const). In C++11, ``__block``; variables are copied as x-values if that is possible, then as l-values; if not; if both fail, it's an error. The destructor for any initial; stack-based version is called at the variable's normal end of scope. References to ``this`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:11843,allocate,allocated,11843,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['allocate'],['allocated']
Energy Efficiency,"s allocating thread local; memory to hold the exception, and calling into the EH runtime. The runtime; identifies frames with appropriate exception handling actions, and successively; resets the register context of the current thread to the most recently active; frame with actions to run. In LLVM, execution resumes at a ``landingpad``; instruction, which produces register values provided by the runtime. If a; function is only cleaning up allocated resources, the function is responsible; for calling ``_Unwind_Resume`` to transition to the next most recently active; frame after it is finished cleaning up. Eventually, the frame responsible for; handling the exception calls ``__cxa_end_catch`` to destroy the exception,; release its memory, and resume normal control flow. The Windows EH model does not use these successive register context resets.; Instead, the active exception is typically described by a frame on the stack.; In the case of C++ exceptions, the exception object is allocated in stack memory; and its address is passed to ``__CxxThrowException``. General purpose structured; exceptions (SEH) are more analogous to Linux signals, and they are dispatched by; userspace DLLs provided with Windows. Each frame on the stack has an assigned EH; personality routine, which decides what actions to take to handle the exception.; There are a few major personalities for C and C++ code: the C++ personality; (``__CxxFrameHandler3``) and the SEH personalities (``_except_handler3``,; ``_except_handler4``, and ``__C_specific_handler``). All of them implement; cleanups by calling back into a ""funclet"" contained in the parent function. Funclets, in this context, are regions of the parent function that can be called; as though they were a function pointer with a very special calling convention.; The frame pointer of the parent frame is passed into the funclet either using; the standard EBP register or as the first parameter register, depending on the; architecture. The funclet implem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:21388,allocate,allocated,21388,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,1,['allocate'],['allocated']
Energy Efficiency,"s and the result have the same vector of floating-point; type. The fourth operand is the vector mask and has the same number of elements; as the result vector type. The fifth operand is the explicit vector length of; the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.fmuladd``' intrinsic performs floating-point multiply-add (:ref:`llvm.fuladd <int_fmuladd>`); of the first, second, and third vector operand on each enabled lane. The result; on disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.fmuladd.v4f32(<4 x float> %a, <4 x float> %b, <4 x float> %c, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.fmuladd(<4 x float> %a, <4 x float> %b, <4 x float> %c); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_reduce_add:. '``llvm.vp.reduce.add.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.add.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.add.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``ADD`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:748274,reduce,reduce,748274,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"s are true, we can promote the loads and stores in the; loop of the pointer to use a temporary alloca'd variable. We then use the; :ref:`mem2reg <passes-mem2reg>` functionality to construct the appropriate; SSA form for the variable. ``loop-deletion``: Delete dead loops; ------------------------------------. This file implements the Dead Loop Deletion Pass. This pass is responsible for; eliminating loops with non-infinite computable trip counts that have no side; effects or volatile instructions, and do not contribute to the computation of; the function's return value. .. _passes-loop-extract:. ``loop-extract``: Extract loops into new functions; --------------------------------------------------. A pass wrapper around the ``ExtractLoop()`` scalar transformation to extract; each top-level loop into its own new function. If the loop is the *only* loop; in a given function, it is not touched. This is a pass most useful for; debugging via bugpoint. ``loop-reduce``: Loop Strength Reduction; ----------------------------------------. This pass performs a strength reduction on array references inside loops that; have as one or more of their components the loop induction variable. This is; accomplished by creating a new value to hold the initial value of the array; access for the first iteration, and then creating a new GEP instruction in the; loop to increment the value by the appropriate amount. .. _passes-loop-rotate:. ``loop-rotate``: Rotate Loops; -----------------------------. A simple loop rotation transformation. A summary of it can be found in; :ref:`Loop Terminology for Rotated Loops <loop-terminology-loop-rotate>`. .. _passes-loop-simplify:. ``loop-simplify``: Canonicalize natural loops; ---------------------------------------------. This pass performs several transformations to transform natural loops into a; simpler form, which makes subsequent analyses and transformations simpler and; more effective. A summary of it can be found in; :ref:`Loop Terminology, Loop",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:25894,reduce,reduce,25894,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['reduce'],['reduce']
Energy Efficiency,"s being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositories depending on region and load. GitHub has one important advantage over GitLab and; BitBucket: it offers read-write **SVN** access to the repository; (https://github.com/blog/626-announcing-svn-support).; This would enable people to continue working post-migration as though our code; were still canonically in an SVN repository. In addition, there are already multiple LLVM mirrors on GitHub, indicating that; part of our community has already settled there. On Managing Revision Numbers with Git; -------------------------------------. The current SVN repository hosts all the LLVM sub-projects alongside each other.; A single revision number (e.g. r123456) thus identifies a consistent version of; all LLVM sub-projects. Git does not use sequential integer revision number but instead uses a hash to; identify each commit. The loss of a sequential integer revision number has been a sticking point in; past discussions about Git:. - ""The 'branch' I most",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:3371,monitor,monitor,3371,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['monitor'],['monitor']
Energy Efficiency,"s can be enabled through `RField<float>::SetHalfPrecision()`. On reading, values of such fields are represented as regular, 32-bit floats.; - A new `RNTupleInspector` utility class has been added, to provide information about the on-disk metadata of an RNTuple.; - A new `RNTupleParallelWriter` class has been added, providing (initial) support for parallel writing of RNTuples.; - A new static method `RFieldBase::Check()` has been added, which produces a support status report of a type with regards to RNTuple I/O.; - A new internal `RNTupleMerger` class has been added, enabling the merging of different page sources into one page sink. This also means that RNTuples can be merged through `hadd`.; - Zero-copy bulk reading has been added, with extra optimizations for `ROOT::RVec` fields.; - It is now possible to use the `RNTupleView` with an external address with type erasure, e.g.:; ```cpp; std::shared_ptr<void> data{new float()};; auto view = reader->GetView(""pt"", data);; ```; This enables use cases such as reading one specific entry of one specific field into a previously allocated memory location.; - Further integration with [RDataFrame](#rdataframe): it is now possible to create RDataFrame for chains of RNTuples. This addition also comes with improvements to the multi-threaded work scheduling.; - Many additional bug fixes and improvements. Please, report any issues regarding the above mentioned features should you encounter them. RNTuple is still in pre-production. The on-disk format is scheduled to be finalized by the end of 2024. Thus, we appreciate feedback and suggestions for improvement. ## Histogram Libraries. - Implement the FLT_MAX mechanism for `THStack::GetMaximum()` and `THStack::GetMiniumum()`.; - Print a warning when the range given to `TAxis::SetRange` is invalid.; - Fix projection name in `TH3` as requested [here](https://root-forum.cern.ch/t/project3d-letter-d-in-name-option/57612). ## Parallelism; - The ROOT::Experimental::TFuture template has been r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:6066,allocate,allocated,6066,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['allocate'],['allocated']
Energy Efficiency,"s container is highly specialized, it is rarely used. .. _dss_smallvector:. llvm/ADT/SmallVector.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallVector<Type, N>`` is a simple class that looks and smells just like; ``vector<Type>``: it supports efficient iteration, lays out elements in memory; order (so you can do pointer arithmetic between elements), supports efficient; push_back/pop_back operations, supports efficient random access to its elements,; etc. The main advantage of SmallVector is that it allocates space for some number of; elements (N) **in the object itself**. Because of this, if the SmallVector is; dynamically smaller than N, no malloc is performed. This can be a big win in; cases where the malloc/free call is far more expensive than the code that; fiddles around with the elements. This is good for vectors that are ""usually small"" (e.g. the number of; predecessors/successors of a block is usually less than 8). On the other hand,; this makes the size of the SmallVector itself large, so you don't want to; allocate lots of them (doing so will waste a lot of space). As such,; SmallVectors are most useful when on the stack. In the absence of a well-motivated choice for the number of; inlined elements ``N``, it is recommended to use ``SmallVector<T>`` (that is,; omitting the ``N``). This will choose a default number of; inlined elements reasonable for allocation on the stack (for example, trying; to keep ``sizeof(SmallVector<T>)`` around 64 bytes). SmallVector also provides a nice portable and efficient replacement for; ``alloca``. SmallVector has grown a few other minor advantages over std::vector, causing; ``SmallVector<Type, 0>`` to be preferred over ``std::vector<Type>``. #. std::vector is exception-safe, and some implementations have pessimizations; that copy elements when SmallVector would move them. #. SmallVector understands ``std::is_trivially_copyable<Type>`` and uses realloc aggressively. #. Many LLVM APIs take a SmallVectorImpl as an out parameter (see the note",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:60315,allocate,allocate,60315,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocate']
Energy Efficiency,"s doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37098,reduce,reduce,37098,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['reduce'],['reduce']
Energy Efficiency,"s for how to create targeted debug; info tests for arbitrary transformations. For more on the philosophy behind LLVM debugging information, see; :doc:`SourceLevelDebugging`. Rules for updating debug locations; ==================================. .. _WhenToPreserveLocation:. When to preserve an instruction location; ----------------------------------------. A transformation should preserve the debug location of an instruction if the; instruction either remains in its basic block, or if its basic block is folded; into a predecessor that branches unconditionally. The APIs to use are; ``IRBuilder``, or ``Instruction::setDebugLoc``. The purpose of this rule is to ensure that common block-local optimizations; preserve the ability to set breakpoints on source locations corresponding to; the instructions they touch. Debugging, crash logs, and SamplePGO accuracy; would be severely impacted if that ability were lost. Examples of transformations that should follow this rule include:. * Instruction scheduling. Block-local instruction reordering should not drop; source locations, even though this may lead to jumpy single-stepping; behavior. * Simple jump threading. For example, if block ``B1`` unconditionally jumps to; ``B2``, *and* is its unique predecessor, instructions from ``B2`` can be; hoisted into ``B1``. Source locations from ``B2`` should be preserved. * Peephole optimizations that replace or expand an instruction, like ``(add X; X) => (shl X 1)``. The location of the ``shl`` instruction should be the same; as the location of the ``add`` instruction. * Tail duplication. For example, if blocks ``B1`` and ``B2`` both; unconditionally branch to ``B3`` and ``B3`` can be folded into its; predecessors, source locations from ``B3`` should be preserved. Examples of transformations for which this rule *does not* apply include:. * LICM. E.g., if an instruction is moved from the loop body to the preheader,; the rule for :ref:`dropping locations<WhenToDropLocation>` applies. In add",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst:1500,schedul,scheduling,1500,interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,1,['schedul'],['scheduling']
Energy Efficiency,"s from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release to set the packet kind to ensure the packet contents are; visible to the kernel agent. AQL defines a doorbell signal mechanism to; notify the kernel agent that the AQL queue has be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:150322,allocate,allocated,150322,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"s in most contexts unusable, because the input; can't be changed, other than loading a different bin in the dataset. Furthermore, there was actually a constructor that took a `RooAbsArg x`, but it; was simply ignored. To fix all these problems, the existing constructors were replaced by a new one; that takes the observable explicitly. Since the old constructors resulted in wrong computation graphs that caused; trouble with the new CPU evaluation backend, they had to be removed without; deprecation. Please adapt your code if necessary. ### Renaming of some RooFit classes. The `RooPower` was renamed to `RooPowerSum`, and `RooExpPoly` was renamed to `RooLegacyExpPoly`. This was a necessary change, because the names of these classes introduced in ROOT 6.28 collided with some classes in CMS combine, which were around already long before. Therefore, the classes had to be renamed to not cause any problems for CMS. In the unlikeliy case where you should have used these new classes for analysis already, please adapt your code to the new names and re-create your workspaces. ## RDataFrame. * The `RDataFrame` constructors that take in input one or more file names (or globs thereof) will now infer the format of the dataset, either `TTree` or `RNTuple`, that is stored in the first input file. When multiple files are specified, it is assumed that all other files contain a coherent dataset of the same format and with the same schema, exactly as it used to happen with `TChain`. This automatic inference further contributes towards a zero-code-change experience when moving from processing a `TTree` to processing an `RNTuple` dataset while using an `RDataFrame`. It also introduces a backwards-incompatible behaviour, i.e. now the constructor needs to open one file in order to infer the dataset type. This means that if the file does not exist, the constructor will throw an exception. Previously, an exception would be thrown only at a JIT-ting time, before the start of the computations.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:14375,adapt,adapt,14375,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['adapt'],['adapt']
Energy Efficiency,"s not require register allocation, instruction selection, or any of the other; standard components provided by the system. As such, it only implements these; two interfaces, and does its own thing. Note that C backend was removed from the; trunk since LLVM 3.1 release. Another example of a code generator like this is a; (purely hypothetical) backend that converts LLVM to the GCC RTL form and uses; GCC to emit machine code for a target. This design also implies that it is possible to design and implement radically; different code generators in the LLVM system that do not make use of any of the; built-in components. Doing so is not recommended at all, but could be required; for radically different targets that do not fit into the LLVM machine; description model: FPGAs for example. .. _high-level design of the code generator:. The high-level design of the code generator; -------------------------------------------. The LLVM target-independent code generator is designed to support efficient and; quality code generation for standard register-based microprocessors. Code; generation in this model is divided into the following stages:. 1. `Instruction Selection`_ --- This phase determines an efficient way to; express the input LLVM code in the target instruction set. This stage; produces the initial code for the program in the target instruction set, then; makes use of virtual registers in SSA form and physical registers that; represent any required register assignments due to target constraints or; calling conventions. This step turns the LLVM code into a DAG of target; instructions. 2. `Scheduling and Formation`_ --- This phase takes the DAG of target; instructions produced by the instruction selection phase, determines an; ordering of the instructions, then emits the instructions as :raw-html:`<tt>`; `MachineInstr`_\s :raw-html:`</tt>` with that ordering. Note that we; describe this in the `instruction selection section`_ because it operates on; a `SelectionDAG`_. 3. `SS",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:5014,efficient,efficient,5014,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['efficient'],['efficient']
Energy Efficiency,"s on a well-defined (by; the C++ standard) behavior. Currently, this comes with a constant performance; overhead which we go in details bellow. ROOT uses the global module index (GMI) to avoid the performance overhead. ROOT; only preloads the set of C++ modules which are not present in the GMI. The; example becomes equivalent to:. ```cpp; // ROOT prompt; root [] import Foo.*; // Preload Foo if it is not in the GMI.; root [] S *s; // #1: does not require a definition.; root [] foo::bar *baz1; // #2: does not require a definition.; root [] foo::bar baz2; // #3: requires a definition.; root [] TCanvas* c = new TCanvas(); // #4 requires a definition; ```. Line #4 forces cling to send ROOT a callback that TCanvas in unknown but; the GMI resolves it to module Gpad, loads it and returns the control to cling. ### Performance; This section compares ROOT PCH technology with C++ Modules which is important but; unfair comparison. As we noted earlier, PCH is very efficient, it cannot be; extended to the experimentsâ€™ software stacks because of its design constraints.; On the contrary, the C++ Modules can be used in third-party code where the PCH; is not available. The comparisons are to give a good metric when we are ready to switch ROOT to use; C++ Modules by default. However, since it is essentially the same technology,; optimizations of C++ Modules also affect the PCH. We have a few tricks up in; the sleeves to but they come with given trade-offs. #### Preloading of C++ Modules. The main focus for the technology preview was not in performance until recently.; We have invested some resources in optimizations and we would like to show you; (probably outdated) performance results:. * Memory footprint -- mostly due to importing all C++ Modules at startup; we see overhead which depends on the number of preloaded modules. For; ROOT it is between 40-60 MB depending on the concrete configuration.; When the workload increases we notice that the overall memory performance; decreases in ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:17444,efficient,efficient,17444,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['efficient'],['efficient']
Energy Efficiency,"s passed; in `'filename'`. ``` {.cpp}; {; gROOT->Reset();; TFile *f = new TFile(""basic2.root"",""RECREATE"");; TH1F *h1 = new TH1F(""h1"",""x distribution"",100,-4,4);; TTree *T = new TTree(""ntuple"",""data from ascii file"");; Long64_t nlines = T->ReadFile(""basic.dat"",""x:y:z"");; printf("" found %lld pointsn"",nlines);; T->Draw(""x"",""z>2"");; T->Write();; }; ```. If `branchDescriptor` is set to an empty string (the default), it is; assumed that the **`Tree`** descriptor is given in the first line of the; file with a syntax like: `A/D:Table[2]/F:Ntracks/I:astring/C`. Otherwise branchDescriptor must be specified with the above syntax.Lines; in the input file starting with ""\#"" are ignored. A **`TBranch`** object; is created for each variable in the expression. The total number of rows; read from the file is returned. ## Trees in Analysis. The methods `TTree::Draw`, `TTree::MakeClass` and; `TTree::MakeSelector` are available for data analysis using trees. The; **`TTree::Draw`** method is a powerful yet simple way to look and draw the; trees contents. It enables you to plot a variable (a leaf) with just one; line of code. However, the Draw method falls short once you want to look; at each entry and design more sophisticated acceptance criteria for your; analysis. For these cases, you can use `TTree::MakeClass`. It creates a; class that loops over the trees entries one by one. You can then expand; it to do the logic of your analysis. The `TTree::MakeSelector` is the recommended method for ROOT data; analysis. It is especially important for large data set in a parallel; processing configuration where the analysis is distributed over several; processors and you can specify which entries to send to each processor.; With `MakeClass` the user has control over the event loop, with; `MakeSelector `the tree is in control of the event loop. ## Simple Analysis Using TTree::Draw. We will use the tree in `cernstaff.root` that was made by the macro in; `$ROOTSYS/tutorials/tree/staff.C`. First, open",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:67701,power,powerful,67701,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['power'],['powerful']
Energy Efficiency,"s r2, ha16(.CPI_X_2); lfd f1, lo16(.CPI_X_2)(r2); lis r2, ha16(.CPI_X_3); lfd f2, lo16(.CPI_X_3)(r2); fmadd f1, f0, f1, f2; blr. It would be better to materialize .CPI_X into a register, then use immediates; off of the register to avoid the lis's. This is even more important in PIC ; mode. Note that this (and the static variable version) is discussed here for GCC:; http://gcc.gnu.org/ml/gcc-patches/2006-02/msg00133.html. Here's another example (the sgn function):; double testf(double a) {; return a == 0.0 ? 0.0 : (a > 0.0 ? 1.0 : -1.0);; }. it produces a BB like this:; LBB1_1: ; cond_true; lis r2, ha16(LCPI1_0); lfs f0, lo16(LCPI1_0)(r2); lis r2, ha16(LCPI1_1); lis r3, ha16(LCPI1_2); lfs f2, lo16(LCPI1_2)(r3); lfs f3, lo16(LCPI1_1)(r2); fsub f0, f0, f1; fsel f1, f0, f2, f3; blr . ===-------------------------------------------------------------------------===. PIC Code Gen IPO optimization:. Squish small scalar globals together into a single global struct, allowing the ; address of the struct to be CSE'd, avoiding PIC accesses (also reduces the size; of the GOT on targets with one). Note that this is discussed here for GCC:; http://gcc.gnu.org/ml/gcc-patches/2006-02/msg00133.html. ===-------------------------------------------------------------------------===. Fold add and sub with constant into non-extern, non-weak addresses so this:. static int a;; void bar(int b) { a = b; }; void foo(unsigned char *c) {; *c = a;; }. So that . _foo:; lis r2, ha16(_a); la r2, lo16(_a)(r2); lbz r2, 3(r2); stb r2, 0(r3); blr. Becomes. _foo:; lis r2, ha16(_a+3); lbz r2, lo16(_a+3)(r2); stb r2, 0(r3); blr. ===-------------------------------------------------------------------------===. We should compile these two functions to the same thing:. #include <stdlib.h>; void f(int a, int b, int *P) {; *P = (a-b)>=0?(a-b):(b-a);; }; void g(int a, int b, int *P) {; *P = abs(a-b);; }. Further, they should compile to something better than:. _g:; subf r2, r4, r3; subfic r3, r2, 0; cmpwi cr0, r2, -1;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:2659,reduce,reduces,2659,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,2,['reduce'],['reduces']
Energy Efficiency,"s the algorithmic properties of how you plan to; access the container. Based on that, you should use:. * a :ref:`map-like <ds_map>` container if you need efficient look-up of a; value based on another value. Map-like containers also support efficient; queries for containment (whether a key is in the map). Map-like containers; generally do not support efficient reverse mapping (values to keys). If you; need that, use two maps. Some map-like containers also support efficient; iteration through the keys in sorted order. Map-like containers are the most; expensive sort, only use them if you need one of these capabilities. * a :ref:`set-like <ds_set>` container if you need to put a bunch of stuff into; a container that automatically eliminates duplicates. Some set-like; containers support efficient iteration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not support; efficient look-up based on a key. * a :ref:`string <ds_string>` container is a specialized sequential container or; reference structure that is used for character or byte arrays. * a :ref:`bit <ds_bit>` container provides an efficient way to store and; perform set operations on sets of numeric id's, while automatically; eliminating duplicates. Bit containers require a maximum of 1 bit for each; identifier you want to store. Once the proper category of container is determined, you can fine tune the; memory use, constant factors, and cache behaviors of access by intelligently; picking a member of the category. Note that constant factors and cache behavior; can be a big deal. If you have a vector that usually only contains a few; elements (but could contain many), for example, it's much better to use; :ref:`SmallVector <dss_smallvect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:56226,efficient,efficient,56226,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"s the compiler to pretend there is a file at a; specific location. This way we 'mount' `/usr/include/module.modulemap`; non-invasively. The reasons why we need to extend the C++ modules support; beyond ROOT is described bellow.; * rootcling -cxxmodule creates a single artifact *Name.pcm* after the library; name. At a final stage, ROOT might be able to integrate the Name.pcm with the; shared library itself.; * Improved correctness in number of cases -- in a few cases ROOT is more; correct. In particular, when resolving global variables and function; declarations which are not part of the ROOT PCH.; * Enhanced symbol resolution mechanisms, bloom filters -- standard ROOT relies; on information in ROOTMAP files to react when the llvm JIT issues an; unresolved symbol callback. C++ Modules-aware ROOT relies on a behavior much; closer to the standard linker behavior. In particular, we start searching on; the LD_LIBRARY_PATH descending to the system libraries. The algorithm is very; efficient because it uses bloom filters[[5]]. This in turn allows ROOT symbol; to be extended to system libraries. ### Module Registration Approaches. The C++ modules system supports /*preloading*/ of all modules at startup time.; The current implementation of loading of C++ modules in clang has an overhead; and is between 40-60 MB depending on the ROOT configuration while there might; be 2x slowdown depending on the workflow. These issues are very likely to be; addressed by the LLVM community in midterm. Preloading of all C++ modules is semantically the closest to C++ behavior.; However, in order to achieve performance ROOT loads them on demand using; a global module index file. It has sufficient information to map a looked up; identifier to the module which contains the corresponding definition. Switching; back to preloading of all C++ modules is done by setting the `ROOT_USE_GMI`; environment variable to false.; ; ### Supported Platforms. We support all platforms with glibc++ versions: 5.2 onw",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:13584,efficient,efficient,13584,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['efficient'],['efficient']
Energy Efficiency,"s the loop decrement value used to decrement the loop; iteration counter. Semantics:; """""""""""""""""""". The '``llvm.loop.decrement.*``' intrinsics do a ``SUB`` of the loop iteration; counter with the given loop decrement value, and return false if the loop; should exit, this ``SUB`` is not allowed to wrap. The result is a condition; that is used by the conditional branch controlling the loop. Vector Reduction Intrinsics; ---------------------------. Horizontal reductions of vectors can be expressed using the following; intrinsics. Each one takes a vector operand as an input and applies its; respective operation across all elements of the vector, returning a single; scalar result of the same element type. .. _int_vector_reduce_add:. '``llvm.vector.reduce.add.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.add.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.add.*``' intrinsics do an integer ``ADD``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fadd:. '``llvm.vector.reduce.fadd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fadd.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fadd.*``' intrinsics do a floating-point; ``ADD`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the oper",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:650646,reduce,reduce,650646,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"s to; improve the quality of clang by self-testing. Some examples:. Improve the reliability of AST printing and serialization by; ensuring that the AST produced by clang on an input doesn't change; when it is reparsed or unserialized. Improve parser reliability and error generation by automatically; or randomly changing the input checking that clang doesn't crash and; that it doesn't generate excessive errors for small input; changes. Manipulating the input at both the text and token levels is; likely to produce interesting test cases. Continue work on C++20, C++23, C++2c, and C23 support:; There are still several C++20 features to complete, and work has begun on; supporting the latest language standards. Please see the; C++ status report page to find out what is; missing.; StringRef'ize APIs: A thankless but incredibly useful project is; StringRef'izing (converting to use llvm::StringRef instead of const; char * or std::string) various clang interfaces. This generally; simplifies the code and makes it more efficient.; Configuration Manager: Clang/LLVM works on a large number of; architectures and operating systems and can cross-compile to a similarly large; number of configurations, but the pitfalls of choosing the command-line; options, making sure the right sub-architecture is chosen and that the correct; optional elements of your particular system can be a pain. A tool that would investigate hosts and targets, and store the configuration; in files that can later be used by Clang itself to avoid command-line options,; especially the ones regarding which target options to use, would greatly alleviate; this problem. A simple tool, with little or no dependency on LLVM itself, that; will investigate a target architecture by probing hardware, software, libraries; and compiling and executing code to identify all properties that would be relevant; to command-line options (VFP, SSE, NEON, ARM vs. Thumb etc), triple settings etc.; The first stage is to build a CFLAGS for C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/OpenProjects.html:5326,efficient,efficient,5326,interpreter/llvm-project/clang/www/OpenProjects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/OpenProjects.html,2,['efficient'],['efficient']
Energy Efficiency,"s with negative weights in the BDT training (particular the boosting) : IgnoreInTraining; Boost With inverse boostweight; Pair events with negative and positive weights in traning sample and *annihilate* them (experimental!). NodePurityLimit No 0.5 âˆ’ In boosting/pruning, nodes with purity > NodePurityLimit are signal; background otherwise. SeparationType No GiniIndex CrossEntropy, GiniIndex, GiniIndexWithLaplace, MisClassificationError, SDivSqrtSPlusB, RegressionVariance Separation criterion for node splitting. DoBoostMonitor No False âˆ’ Create control plot with ROC integral vs tree number. UseFisherCuts No False âˆ’ Use multivariate splits using the Fisher criterion. MinLinCorrForFisher No 0.8 âˆ’ The minimum linear correlation between two variables demanded for use in Fisher criterion in node splitting. UseExclusiveVars No False âˆ’ Variables already used in fisher criterion are not anymore analysed individually for node splitting. DoPreselection No False âˆ’ and and apply automatic pre-selection for 100% efficient signal (bkg) cuts prior to training. RenormByClass No False âˆ’ Individually re-normalize each event class to the original size after boosting. SigToBkgFraction No 1 âˆ’ Sig to Bkg ratio used in Training (similar to NodePurityLimit, which cannot be used in real adaboost. PruneMethod No NoPruning NoPruning, ExpectedError, CostComplexity Note: for BDTs use small trees (e.g.MaxDepth=3) and NoPruning: Pruning: Method used for pruning (removal) of statistically insignificant branches . PruneStrength No 0 âˆ’ Pruning strength. PruningValFraction No 0.5 âˆ’ Fraction of events to use for optimizing automatic pruning. nEventsMin No 0 âˆ’ deprecated: Use MinNodeSize (in % of training events) instead. GradBaggingFraction No 0.6 âˆ’ deprecated: Use *BaggedSampleFraction* instead: Defines the fraction of events to be used in each iteration, e.g. when UseBaggedGrad=kTRUE. . UseNTrainEvents No 0 âˆ’ deprecated: Use *BaggedSampleFraction* instead: Number of randomly picked training events us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:14499,efficient,efficient,14499,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['efficient'],['efficient']
Energy Efficiency,"s(""VNAME"",ptrMed,rmin,rmax,; dz,phi1,phi2);. // See class TGeoManager for the rest of shapes.; // Making a volume with a given shape with a unique prototype; TGeoVolume *vol = gGeoManager->Volume(""VNAME"",""XXXX"",nmed,upar,; npar);. // Where XXXX stands for the first 4 letters of the specific shape; // classes, nmed is the medium number, upar is an Double_t * array; // of the shape parameters and npar is the number of parameters.; // This prototype allows (npar = 0) to define volumes with shape; // defined only at positioning time (volumes defined in this way; // need to be positioned using TGeoManager::Node() method); ```. #### Positioned Volumes (Nodes). Geometrical modeling is a difficult task when the number of different; geometrical objects is 106-108. This is more or less the case for; detector geometries of complex experiments, where a â€˜flat' CSG model; description cannot scale with the current CPU performances. This is the; reason why models like GEANT [1] introduced an additional dimension; (depth) in order to reduce the complexity of the problem. This concept; is also preserved by the ROOT modeller and introduces a pure geometrical; constraint between objects (volumes in our case) - containment. This; means in fact that any positioned volume has to be contained by another.; Now what means contained and positioned?. - We will say that a volume `contains` a point if this is inside the; shape associated to the volume. For instance, a volume having a box; shape will contain all points `P=(X,Y,Z)` verifying the conditions:; `Abs(Pi)dXi`. The points on the shape boundaries are considered as; inside the volume. The volume contains a daughter if it contains all; the points contained by the daughter.; - The definition of containment works of course only with points; defined in the local coordinate system of the considered volume.; `Positioning` a volume inside another have to introduce a; geometrical transformation between the two. If `M` defines this; transformation",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:65970,reduce,reduce,65970,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['reduce'],['reduce']
Energy Efficiency,"s) after the ROOT; command. Be warned: after finishing the execution of the script,; ROOT will normally enter a new session. - -q process command line script files and exit. For example if you would like to run a script `myMacro.C` in the; background, redirect the output into a file `myMacro.log`, and exit; after the script execution, use the following syntax:. ```; root -b -q myMacro.C > myMacro.log; ```. If you need to pass a parameter to the script use:. ```; root -b -q 'myMacro.C(3)' > myMacro.log; ```. Be mindful of the quotes, i.e. if you need to pass a string as a; parameter, the syntax is:. ```; root -b -q 'myMacro.C(""text"")' > myMacro.log; ```. You can build a shared library with ACLiC and then use this shared; library on the command line for a quicker execution (i.e. the compiled; speed rather than the interpreted speed). See also ""Cling the C++; Interpreter"". ```; root -b -q myMacro.so > myMacro.log; ```. ROOT has a powerful C/C++ interpreter giving you access to all available; ROOT classes, global variables, and functions via the command line. By; typing C++ statements at the prompt, you can create objects, call; functions, execute scripts, etc. For example:. ``` {.cpp}; root[] 1+sqrt(9); (const double)4.00000000000000000e+00; root[] for (int i = 0; i<4; i++) cout << ""Hello"" << i << endl; Hello 0; Hello 1; Hello 2; Hello 3; root[] .q; ```. To exit the ROOT session, type `.q`. ``` {.cpp}; root[] .q; ```. ## Using the GUI. The basic whiteboard on which an object is drawn in ROOT is called a; canvas (defined by the class **`TCanvas`**). Every object in the; canvas is a graphical object in the sense that you can grab it, resize; it, and change some characteristics using the mouse. The canvas area; can be divided in several sub areas, so-called pads; (the class **`TPad`**). A pad is a canvas sub area that can contain; other pads or graphical objects. At any one time, just one pad is the; so-called active pad. Any object at the moment of drawing will be; drawn",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md:4756,power,powerful,4756,documentation/users-guide/GettingStarted.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md,1,['power'],['powerful']
Energy Efficiency,"s). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectiv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:14707,reduce,reduce,14707,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,1,['reduce'],['reduce']
Energy Efficiency,"s, SourceLocations, SourceBuffer abstraction,; file system caching for input source files.; libast - Provides classes to represent the C AST, the C type system,; builtin functions, and various helpers for analyzing and manipulating the; AST (visitors, pretty printers, etc).; liblex - Lexing and preprocessing, identifier hash table, pragma; handling, tokens, and macro expansion.; libparse - Parsing. This library invokes coarse-grained 'Actions'; provided by the client (e.g. libsema builds ASTs) but knows nothing about; ASTs or other client-specific data structures.; libsema - Semantic Analysis. This provides a set of parser actions; to build a standardized AST for programs.; libcodegen - Lower the AST to LLVM IR for optimization & code; generation.; librewrite - Editing of text buffers (important for code rewriting; transformation, like refactoring).; libanalysis - Static analysis support.; clang - A driver program, client of the libraries at various; levels. As an example of the power of this library based design.... If you wanted to; build a preprocessor, you would take the Basic and Lexer libraries. If you want; an indexer, you would take the previous two and add the Parser library and; some actions for indexing. If you want a refactoring, static analysis, or; source-to-source compiler tool, you would then add the AST building and; semantic analyzer libraries.; For more information about the low-level implementation details of the; various clang libraries, please see the ; clang Internals Manual. Support Diverse Clients. Clang is designed and built with many grand plans for how we can use it. The; driving force is the fact that we use C and C++ daily, and have to suffer due to; a lack of good tools available for it. We believe that the C and C++ tools; ecosystem has been significantly limited by how difficult it is to parse and; represent the source code for these languages, and we aim to rectify this; problem in clang.; The problem with this goal is that different",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html:5875,power,power,5875,interpreter/llvm-project/clang/www/features.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html,2,['power'],['power']
Energy Efficiency,"s, and languages which can be conceptually lowered; into C (this covers a lot). * Support optimizations such as those that are common in C compilers. In; particular, GEP is a cornerstone of LLVM's `pointer aliasing; model <LangRef.html#pointeraliasing>`_. * Provide a consistent method for computing addresses so that address; computations don't need to be a part of load and store instructions in the IR. * Support non-C-like languages, to the extent that it doesn't interfere with; other goals. * Minimize target-specific information in the IR. Why do struct member indices always use ``i32``?; ------------------------------------------------. The specific type i32 is probably just a historical artifact, however it's wide; enough for all practical purposes, so there's been no need to change it. It; doesn't necessarily imply i32 address arithmetic; it's just an identifier which; identifies a field in a struct. Requiring that all struct indices be the same; reduces the range of possibilities for cases where two GEPs are effectively the; same but have distinct operand types. What's an uglygep?; ------------------. Some LLVM optimizers operate on GEPs by internally lowering them into more; primitive integer expressions, which allows them to be combined with other; integer expressions and/or split into multiple separate integer expressions. If; they've made non-trivial changes, translating back into LLVM IR can involve; reverse-engineering the structure of the addressing in order to fit it into the; static type of the original first operand. It isn't always possibly to fully; reconstruct this structure; sometimes the underlying addressing doesn't; correspond with the static type at all. In such cases the optimizer instead will; emit a GEP with the base pointer casted to a simple address-unit pointer, using; the name ""uglygep"". This isn't pretty, but it's just as valid, and it's; sufficient to preserve the pointer aliasing guarantees that GEP provides. Summary; =======. In sum",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:20308,reduce,reduces,20308,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['reduce'],['reduces']
Energy Efficiency,"s, linking them together into a tree; which is then linearized when the Twine is consumed. Twine is only safe to use; as the argument to a function, and should always be a const reference, e.g.:. .. code-block:: c++. void foo(const Twine &T);; ...; StringRef X = ...; unsigned i = ...; foo(X + ""."" + Twine(i));. This example forms a string like ""blarg.42"" by concatenating the values; together, and does not form intermediate strings containing ""blarg"" or ""blarg."". Because Twine is constructed with temporary objects on the stack, and because; these instances are destroyed at the end of the current statement, it is an; inherently dangerous API. For example, this simple variant contains undefined; behavior and will probably crash:. .. code-block:: c++. void foo(const Twine &T);; ...; StringRef X = ...; unsigned i = ...; const Twine &Tmp = X + ""."" + Twine(i);; foo(Tmp);. ... because the temporaries are destroyed before the call. That said, Twine's; are much more efficient than intermediate std::string temporaries, and they work; really well with StringRef. Just be aware of their limitations. .. _dss_smallstring:. llvm/ADT/SmallString.h; ^^^^^^^^^^^^^^^^^^^^^^. SmallString is a subclass of :ref:`SmallVector <dss_smallvector>` that adds some; convenience APIs like += that takes StringRef's. SmallString avoids allocating; memory in the case when the preallocated space is enough to hold its data, and; it calls back to general heap allocation when required. Since it owns its data,; it is very safe to use and supports full mutation of the string. Like SmallVector's, the big downside to SmallString is their sizeof. While they; are optimized for small strings, they themselves are not particularly small.; This means that they work great for temporary scratch buffers on the stack, but; should not generally be put into the heap: it is very rare to see a SmallString; as the member of a frequently-allocated heap data structure or returned; by-value. .. _dss_stdstring:. std::string; ^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:74830,efficient,efficient,74830,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"s. If you do use :option:`-Weverything` then we; advise that you address all new compiler diagnostics as they get added to Clang,; either by fixing everything they find or explicitly disabling that diagnostic; with its corresponding `Wno-` option. Note that when combined with :option:`-w` (which disables all warnings),; disabling all warnings wins. Controlling Static Analyzer Diagnostics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. While not strictly part of the compiler, the diagnostics from Clang's; `static analyzer <https://clang-analyzer.llvm.org>`_ can also be; influenced by the user via changes to the source code. See the available; `annotations <https://clang-analyzer.llvm.org/annotations.html>`_ and the; analyzer's `FAQ; page <https://clang-analyzer.llvm.org/faq.html#exclude_code>`_ for more; information. .. _usersmanual-precompiled-headers:. Precompiled Headers; -------------------. `Precompiled headers <https://en.wikipedia.org/wiki/Precompiled_header>`_; are a general approach employed by many compilers to reduce compilation; time. The underlying motivation of the approach is that it is common for; the same (and often large) header files to be included by multiple; source files. Consequently, compile times can often be greatly improved; by caching some of the (redundant) work done by a compiler to process; headers. Precompiled header files, which represent one of many ways to; implement this optimization, are literally files that represent an; on-disk cache that contains the vital information necessary to reduce; some of the work needed to process a corresponding header file. While; details of precompiled headers vary between compilers, precompiled; headers have been shown to be highly effective at speeding up program; compilation on systems with very large system headers (e.g., macOS). Generating a PCH File; ^^^^^^^^^^^^^^^^^^^^^. To generate a PCH file using Clang, one invokes Clang with the; `-x <language>-header` option. This mirrors the interface in GCC",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:45793,reduce,reduce,45793,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['reduce'],['reduce']
Energy Efficiency,s/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzze,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338311,reduce,reduce,338311,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,s/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/l,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337872,reduce,reduce,337872,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"s://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a1bc5b86a2a834bb06711fb535451146d) to the `RDataFrame` interface, which allows to get information about the dataset (subset of the output of Describe()).; - Add [`DefinePerSample`](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a29d77593e95c0f84e359a802e6836a0e), a method which makes it possible to define columns based on the sample and entry range being processed. It is also a useful way to register callbacks that should only be called when the input dataset/TTree changes.; - Add [`HistoND`](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a0c9956a0f48c26f8e4294e17376c7fea) action that fills a N-dimensional histogram.; - `Book` now supports just-in-time compilation, i.e. it can be called without passing the column types as template parameters (with some performance penalty, as usual).; - As an aid to `RDataSource` implementations with which collection sizes can be retrieved more efficiently than the full collection, `#var` can now be used as a short-hand notation for column name `R_rdf_sizeof_var`.; - Helpers have been added to export data from `RDataFrame` to RooFit datasets. See the ""RooFit Libraries"" section below for more details, or see [the tutorial](https://root.cern/doc/master/rf408__RDataFrameToRooFit_8C.html). ### Notable changes in behavior. - Using `Alias`, it is now possible to register homonymous aliases (alternative column names) in different branches of the computation graph, in line with the behavior of `Define` (until now, aliases were required to be unique in the whole computaton graph).; - The `Histo*D` methods now support the combination of scalar values and vector-like weight values. For each entry, the histogram is filled once for each weight, always with the same scalar value.; - The `Histo*D` methods do not work on columns of type `std::string` anymore. They used to fill the histogram with the integer value corresponding to each of the characters ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:8625,efficient,efficiently,8625,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['efficient'],['efficiently']
Energy Efficiency,"s; complete source code as you receive it, in any medium, provided that; you conspicuously and appropriately publish on each copy an; appropriate copyright notice and disclaimer of warranty; keep intact; all the notices that refer to this License and to the absence of any; warranty; and distribute a copy of this License along with the; Library. You may charge a fee for the physical act of transferring a copy,; and you may at your option offer warranty protection in exchange for a; fee.; ; 2. You may modify your copy or copies of the Library or any portion; of it, thus forming a work based on the Library, and copy and; distribute such modifications or work under the terms of Section 1; above, provided that you also meet all of these conditions:. a) The modified work must itself be a software library. b) You must cause the files modified to carry prominent notices; stating that you changed the files and the date of any change. c) You must cause the whole of the work to be licensed at no; charge to all third parties under the terms of this License. d) If a facility in the modified Library refers to a function or a; table of data to be supplied by an application program that uses; the facility, other than as an argument passed when the facility; is invoked, then you must make a good faith effort to ensure that,; in the event an application does not supply such function or; table, the facility still operates, and performs whatever part of; its purpose remains meaningful. (For example, a function in a library to compute square roots has; a purpose that is entirely well-defined independent of the; application. Therefore, Subsection 2d requires that any; application-supplied function or table used by this function must; be optional: if the application does not supply it, the square; root function must still compute square roots.). These requirements apply to the modified work as a whole. If; identifiable sections of that work are not derived from the Library,; and can be re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt:8870,charge,charge,8870,LGPL2_1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/LGPL2_1.txt,1,['charge'],['charge']
Energy Efficiency,"s_arrayref:. llvm/ADT/ArrayRef.h; ^^^^^^^^^^^^^^^^^^^. The ``llvm::ArrayRef`` class is the preferred class to use in an interface that; accepts a sequential list of elements in memory and just reads from them. By; taking an ``ArrayRef``, the API can be passed a fixed size array, an; ``std::vector``, an ``llvm::SmallVector`` and anything else that is contiguous; in memory. .. _dss_fixedarrays:. Fixed Size Arrays; ^^^^^^^^^^^^^^^^^. Fixed size arrays are very simple and very fast. They are good if you know; exactly how many elements you have, or you have a (low) upper bound on how many; you have. .. _dss_heaparrays:. Heap Allocated Arrays; ^^^^^^^^^^^^^^^^^^^^^. Heap allocated arrays (``new[]`` + ``delete[]``) are also simple. They are good; if the number of elements is variable, if you know how many elements you will; need before the array is allocated, and if the array is usually large (if not,; consider a :ref:`SmallVector <dss_smallvector>`). The cost of a heap allocated; array is the cost of the new/delete (aka malloc/free). Also note that if you; are allocating an array of a type with a constructor, the constructor and; destructors will be run for every element in the array (re-sizable vectors only; construct those elements actually used). .. _dss_tinyptrvector:. llvm/ADT/TinyPtrVector.h; ^^^^^^^^^^^^^^^^^^^^^^^^. ``TinyPtrVector<Type>`` is a highly specialized collection class that is; optimized to avoid allocation in the case when a vector has zero or one; elements. It has two major restrictions: 1) it can only hold values of pointer; type, and 2) it cannot hold a null pointer. Since this container is highly specialized, it is rarely used. .. _dss_smallvector:. llvm/ADT/SmallVector.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallVector<Type, N>`` is a simple class that looks and smells just like; ``vector<Type>``: it supports efficient iteration, lays out elements in memory; order (so you can do pointer arithmetic between elements), supports efficient; push_back/pop_back ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:58654,allocate,allocated,58654,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocated']
Energy Efficiency,"sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrinsic may be used in a scheduling region. The iglp_opt intrinsic; cannot be combined with sched_barrier o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:44201,schedul,scheduling,44201,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduling']
Energy Efficiency,"se existing items and display them. A snapshot of running; server can be seen on the [demo page](https://root.cern/js/latest/httpserver.C/). One could also specify similar URL parameters to configure the displayed items and drawing options. It is also possible to display one single item from the THttpServer server like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hpxpy/draw.htm?opt=colz>. ## Data monitoring with JSROOT. ### Monitoring with http server. The best possibility to organize the monitoring of data from a running application; is to use THttpServer. In such case the client can always access the latest; changes and request only the items currently displayed in the browser.; To enable monitoring, one should activate the appropriate checkbox or; provide __monitoring__ parameter in the URL string like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hprof/draw.htm?monitoring=1000>. The parameter value is the update interval in milliseconds. ### JSON file-based monitoring. Solid file-based monitoring (without integration of THttpServer into application) can be; implemented in JSON format. There is the [TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class,; which is capable to convert any (beside TTree) ROOT object into JSON. Any ROOT application can use such class to; create JSON files for selected objects and write such files in a directory,; which can be accessed via web server. Then one can use JSROOT to read such files and display objects in a web browser. There is a demonstration page showing such functionality: <https://root.cern/js/latest/demo/update_draw.htm>.; This demo page reads in cycle 20 json files and displays them. If one has a web server which already provides such JSON file, one could specify the URL to this file like:. <https://root.cern/js/latest/demo/update_draw.htm?addr=../httpserver.C/Canvases/c1/root.json.gz>. Here the same problem with [Cross-Origin Request](https://developer.mozilla.org/en/http",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:31027,monitor,monitoring,31027,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency,"se_min(T x, T y) return x or y, whichever is smaller integer and floating point types; T __builtin_elementwise_add_sat(T x, T y) return the sum of x and y, clamped to the range of integer types; representable values for the signed/unsigned integer type.; T __builtin_elementwise_sub_sat(T x, T y) return the difference of x and y, clamped to the range of integer types; representable values for the signed/unsigned integer type.; =========================================== ================================================================ =========================================. *Reduction Builtins*. Each builtin returns a scalar equivalent to applying the specified; operation(x, y) as recursive even-odd pairwise reduction to all vector; elements. ``operation(x, y)`` is repeatedly applied to each non-overlapping; even-odd element pair with indices ``i * 2`` and ``i * 2 + 1`` with; ``i in [0, Number of elements / 2)``. If the numbers of elements is not a; power of 2, the vector is widened with neutral elements for the reduction; at the end to the next power of 2. Example:. .. code-block:: c++. __builtin_reduce_add([e3, e2, e1, e0]) = __builtin_reduced_add([e3 + e2, e1 + e0]); = (e3 + e2) + (e1 + e0). Let ``VT`` be a vector type and ``ET`` the element type of ``VT``. ======================================= ================================================================ ==================================; Name Operation Supported element types; ======================================= ================================================================ ==================================; ET __builtin_reduce_max(VT a) return x or y, whichever is larger; If exactly one argument is integer and floating point types; a NaN, return the other argument. If both arguments are NaNs,; fmax() return a NaN.; ET __builtin_reduce_min(VT a) return x or y, whichever is smaller; If exactly one argument integer and floating point types; is a NaN, return the other argument. If both arguments are; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:26655,power,power,26655,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['power'],['power']
Energy Efficiency,"seen in OpenCL. An example; is:. .. code-block:: c++. typedef float float4 __attribute__((ext_vector_type(4)));; typedef float float2 __attribute__((ext_vector_type(2)));. float4 foo(float2 a, float2 b) {; float4 c;; c.xz = a;; c.yw = b;; return c;; }. Query for this feature with ``__has_attribute(ext_vector_type)``. Giving ``-maltivec`` option to clang enables support for AltiVec vector syntax; and functions. For example:. .. code-block:: c++. vector float foo(vector int a) {; vector int b;; b = vec_add(a, a) + a;; return (vector float)b;; }. NEON vector types are created using ``neon_vector_type`` and; ``neon_polyvector_type`` attributes. For example:. .. code-block:: c++. typedef __attribute__((neon_vector_type(8))) int8_t int8x8_t;; typedef __attribute__((neon_polyvector_type(16))) poly8_t poly8x16_t;. int8x8_t foo(int8x8_t a) {; int8x8_t v;; v = a;; return v;; }. GCC vector types are created using the ``vector_size(N)`` attribute. The; argument ``N`` specifies the number of bytes that will be allocated for an; object of this type. The size has to be multiple of the size of the vector; element type. For example:. .. code-block:: c++. // OK: This declares a vector type with four 'int' elements; typedef int int4 __attribute__((vector_size(4 * sizeof(int))));. // ERROR: '11' is not a multiple of sizeof(int); typedef int int_impossible __attribute__((vector_size(11)));. int4 foo(int4 a) {; int4 v;; v = a;; return v;; }. Boolean Vectors; ---------------. Clang also supports the ext_vector_type attribute with boolean element types in; C and C++. For example:. .. code-block:: c++. // legal for Clang, error for GCC:; typedef bool bool4 __attribute__((ext_vector_type(4)));; // Objects of bool4 type hold 8 bits, sizeof(bool4) == 1. bool4 foo(bool4 a) {; bool4 v;; v = a;; return v;; }. Boolean vectors are a Clang extension of the ext vector type. Boolean vectors; are intended, though not guaranteed, to map to vector mask registers. The size; parameter of a boolean vector t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:15965,allocate,allocated,15965,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['allocate'],['allocated']
Energy Efficiency,"ses; header file (e.g., as part of the class definition), and. - if/when your class is upstreamed to RooFit, expect to move into the; `RooFit::detail` namespace and their implementations into `MathFuncs.h`. \htmlonly; </div>; \endhtmlonly. *Overriding the Translate Function*: The `RooAbsArg::translate()` function; needs to be overridden to specify how the class is translating to C++ code; that is using the aforementioned free function. **Sample Steps**: To add Code Generation support to an existing RooFit class,; following is a sample set of steps (using the aforementioned approach of; extracting free functions in a separate file.). **1. Extract logic into a separate file** Implement what your class is; supposed to do as a free function in [MathFuncs].; This implementation must be compatible with the syntax supported by Clad. **2. Refactor evaluate():** Refactor the existing `RooAbsReal::evaluate()`; function to use the `MathFuncs.h` implementation. This is optional, but; can reduce code duplication and potential for bugs. This may require some; effort if an extensive caching infrastructure is used in your model. **3. Add translate():** RooFit classes are extended using a (typically) simple; `translate()` function that extracts the mathematically differentiable; properties out of the RooFit classes that make up the statistical model. The `translate()` function helps implement the Code Squashing logic that is; used to optimize numerical evaluations. It accomplishes this by using a small; subset of helper functions that are available in the; `RooFit::Detail::CodeSquashContext` and `RooFuncWrapper` classes; (see Appendix B). It converts a RooFit expression into a form that can be; efficiently evaluated by Clad. The `translate()` function returns an `std::string` representing the; underlying mathematical notation of the class as code, that can later be; concatenated into a single string representing the entire model. This string; of code is then just-in-time compiled by ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:7970,reduce,reduce,7970,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['reduce'],['reduce']
Energy Efficiency,"set with the method; `TFile::SetCompressionLevel`. The experience with this algorithm shows; that a compression level of 1.3 for raw data files and around two on; most DST files is the optimum. The choice of one for the default is a; compromise between the time it takes to read and write the object vs.; the disk space savings. To specify no compression, set the level to zero. We recommend using compression when the time spent in I/O is small; compared to the total processing time. If the I/O operation is increased; by a factor of 5 it is still a small percentage of the total time and it; may compress the data by a factor of 10. On the other hand if the time; spend on I/O is large, compression may have a large impact on the; program's performance. The compression factor, i.e. the savings of disk space, varies with the; type of data. A buffer with a same value array is compressed so that the; value is only written once. For example, a track has the mass of a pion; that it is always the same, and the charge of the pion that is either; positive or negative. For 1000 pions, the mass will be written only; once, and the charge only twice (positive and negative). When the data; is sparse, i.e. when there are many zeros, the compression factor is; also high. +---------------------+------------------+-------------------+-------------------+; | Compression level | Bytes | Write Time (sec) | Read Time (sec.) |; +---------------------+------------------+-------------------+-------------------+; | 0 | 1,004,998 | 4.77 | 0.07 |; +---------------------+------------------+-------------------+-------------------+; | 1 | 438,366 | 6.67 | 0.05 |; +---------------------+------------------+-------------------+-------------------+; | 5 | 429,871 | 7.03 | 0.06 |; +---------------------+------------------+-------------------+-------------------+; | 9 | 426,899 | 8.47 | 0.05 |; +---------------------+------------------+-------------------+-------------------+. The time to uncompress an objec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:92660,charge,charge,92660,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['charge'],['charge']
Energy Efficiency,set(LLVM_LINK_COMPONENTS; AllTargetsAsmParsers; AllTargetsCodeGens; AllTargetsDescs; AllTargetsInfos; Analysis; BitReader; BitWriter; CodeGen; CodeGenTypes; Core; IPO; IRReader; MC; MIRParser; Passes; Support; Target; TargetParser; TransformUtils; ). add_llvm_tool(llvm-reduce; DeltaManager.cpp; ReducerWorkItem.cpp; TestRunner.cpp; deltas/Delta.cpp; deltas/Utils.cpp; deltas/ReduceAliases.cpp; deltas/ReduceArguments.cpp; deltas/ReduceAttributes.cpp; deltas/ReduceBasicBlocks.cpp; deltas/ReduceDIMetadata.cpp; deltas/ReduceDPValues.cpp; deltas/ReduceFunctionBodies.cpp; deltas/ReduceFunctions.cpp; deltas/ReduceGlobalObjects.cpp; deltas/ReduceGlobalValues.cpp; deltas/ReduceGlobalVarInitializers.cpp; deltas/ReduceGlobalVars.cpp; deltas/ReduceInstructions.cpp; deltas/ReduceInstructionFlags.cpp; deltas/ReduceInvokes.cpp; deltas/ReduceMetadata.cpp; deltas/ReduceModuleData.cpp; deltas/ReduceMemoryOperations.cpp; deltas/ReduceOperandBundles.cpp; deltas/ReduceOpcodes.cpp; deltas/ReduceSpecialGlobals.cpp; deltas/ReduceOperands.cpp; deltas/ReduceOperandsSkip.cpp; deltas/ReduceOperandsToArgs.cpp; deltas/ReduceInstructionsMIR.cpp; deltas/ReduceInstructionFlagsMIR.cpp; deltas/ReduceIRReferences.cpp; deltas/ReduceVirtualRegisters.cpp; deltas/ReduceRegisterMasks.cpp; deltas/ReduceRegisterDefs.cpp; deltas/ReduceRegisterUses.cpp; deltas/ReduceUsingSimplifyCFG.cpp; deltas/RunIRPasses.cpp; deltas/SimplifyInstructions.cpp; deltas/StripDebugInfo.cpp; llvm-reduce.cpp. DEPENDS; intrinsics_gen; ); ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-reduce/CMakeLists.txt:270,reduce,reduce,270,interpreter/llvm-project/llvm/tools/llvm-reduce/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-reduce/CMakeLists.txt,37,"['Reduce', 'reduce']","['ReduceAliases', 'ReduceArguments', 'ReduceAttributes', 'ReduceBasicBlocks', 'ReduceDIMetadata', 'ReduceDPValues', 'ReduceFunctionBodies', 'ReduceFunctions', 'ReduceGlobalObjects', 'ReduceGlobalValues', 'ReduceGlobalVarInitializers', 'ReduceGlobalVars', 'ReduceIRReferences', 'ReduceInstructionFlags', 'ReduceInstructionFlagsMIR', 'ReduceInstructions', 'ReduceInstructionsMIR', 'ReduceInvokes', 'ReduceMemoryOperations', 'ReduceMetadata', 'ReduceModuleData', 'ReduceOpcodes', 'ReduceOperandBundles', 'ReduceOperands', 'ReduceOperandsSkip', 'ReduceOperandsToArgs', 'ReduceRegisterDefs', 'ReduceRegisterMasks', 'ReduceRegisterUses', 'ReduceSpecialGlobals', 'ReduceUsingSimplifyCFG', 'ReduceVirtualRegisters', 'ReducerWorkItem', 'reduce']"
Energy Efficiency,"shift should be eliminated. Testcase derived from gcc. //===---------------------------------------------------------------------===//. These compile into different code, one gets recognized as a switch and the; other doesn't due to phase ordering issues (PR6212):. int test1(int mainType, int subType) {; if (mainType == 7); subType = 4;; else if (mainType == 9); subType = 6;; else if (mainType == 11); subType = 9;; return subType;; }. int test2(int mainType, int subType) {; if (mainType == 7); subType = 4;; if (mainType == 9); subType = 6;; if (mainType == 11); subType = 9;; return subType;; }. //===---------------------------------------------------------------------===//. The following test case (from PR6576):. define i32 @mul(i32 %a, i32 %b) nounwind readnone {; entry:; %cond1 = icmp eq i32 %b, 0 ; <i1> [#uses=1]; br i1 %cond1, label %exit, label %bb.nph; bb.nph: ; preds = %entry; %tmp = mul i32 %b, %a ; <i32> [#uses=1]; ret i32 %tmp; exit: ; preds = %entry; ret i32 0; }. could be reduced to:. define i32 @mul(i32 %a, i32 %b) nounwind readnone {; entry:; %tmp = mul i32 %b, %a; ret i32 %tmp; }. //===---------------------------------------------------------------------===//. We should use DSE + llvm.lifetime.end to delete dead vtable pointer updates.; See GCC PR34949. Another interesting case is that something related could be used for variables; that go const after their ctor has finished. In these cases, globalopt (which; can statically run the constructor) could mark the global const (so it gets put; in the readonly section). A testcase would be:. #include <complex>; using namespace std;; const complex<char> should_be_in_rodata (42,-42);; complex<char> should_be_in_data (42,-42);; complex<char> should_be_in_bss;. Where we currently evaluate the ctors but the globals don't become const because; the optimizer doesn't know they ""become const"" after the ctor is done. See; GCC PR4131 for more examples. //===-------------------------------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:50527,reduce,reduced,50527,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['reduce'],['reduced']
Energy Efficiency,"sider (an initial list that we should continue; to modify). Note that I'm not trying to suggest actual solutions here,; but just various directions we can pursue:. a. A single-assignment VM, which we've both already been thinking about. b. A strongly-typed VM. One question is do we need the types to be; explicitly declared or should they be inferred by the dynamic compiler?. c. How do we get more high-level information into the VM while keeping; to a low-level VM design?. o Explicit array references as operands? An alternative is; to have just an array type, and let the index computations be; separate 3-operand instructions. o Explicit instructions to handle aliasing, e.g.s:; -- an instruction to say ""I speculate that these two values are not; aliased, but check at runtime"", like speculative execution in; EPIC?; -- or an instruction to check whether two values are aliased and; execute different code depending on the answer, somewhat like; predicated code in EPIC. o (This one is a difficult but powerful idea.); A ""thread-id"" field on every instruction that allows the static; compiler to generate a set of parallel threads, and then have; the runtime compiler and hardware do what they please with it.; This has very powerful uses, but thread-id on every instruction; is expensive in terms of instruction size and code size.; We would need to compactly encode it somehow. Also, this will require some reading on at least two other; projects:; -- Multiscalar architecture from Wisconsin; -- Simultaneous multithreading architecture from Washington. o Or forget all this and stick to a traditional instruction set?. BTW, on an unrelated note, after the meeting yesterday, I did remember; that you had suggested doing instruction scheduling on SSA form instead; of a dependence DAG earlier in the semester. When we talked about; it yesterday, I didn't remember where the idea had come from but I; remembered later. Just giving credit where its due... Perhaps you can save the above as a f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeas.txt:1983,power,powerful,1983,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeas.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeas.txt,1,['power'],['powerful']
Energy Efficiency,"signaling NaN, returns a quiet NaN. G_FMAXNUM_IEEE; ^^^^^^^^^^^^^^. Perform floating-point maximum on two values, following the IEEE-754 2008; definition. This differs from FMAXNUM in the handling of signaling NaNs. If one; input is a signaling NaN, returns a quiet NaN. G_FMINIMUM; ^^^^^^^^^^. NaN-propagating minimum that also treat -0.0 as less than 0.0. While; FMINNUM_IEEE follow IEEE 754-2008 semantics, FMINIMUM follows IEEE 754-2018; draft semantics. G_FMAXIMUM; ^^^^^^^^^^. NaN-propagating maximum that also treat -0.0 as less than 0.0. While; FMAXNUM_IEEE follow IEEE 754-2008 semantics, FMAXIMUM follows IEEE 754-2018; draft semantics. G_FADD, G_FSUB, G_FMUL, G_FDIV, G_FREM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Perform the specified floating point arithmetic. G_FMA; ^^^^^. Perform a fused multiply add (i.e. without the intermediate rounding step). G_FMAD; ^^^^^^. Perform a non-fused multiply add (i.e. with the intermediate rounding step). G_FPOW; ^^^^^^. Raise the first operand to the power of the second. G_FEXP, G_FEXP2; ^^^^^^^^^^^^^^^. Calculate the base-e or base-2 exponential of a value. G_FLOG, G_FLOG2, G_FLOG10; ^^^^^^^^^^^^^^^^^^^^^^^^^. Calculate the base-e, base-2, or base-10 respectively. G_FCEIL, G_FCOS, G_FSIN, G_FSQRT, G_FFLOOR, G_FRINT, G_FNEARBYINT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These correspond to the standard C functions of the same name. G_INTRINSIC_TRUNC; ^^^^^^^^^^^^^^^^^. Returns the operand rounded to the nearest integer not larger in magnitude than the operand. G_INTRINSIC_ROUND; ^^^^^^^^^^^^^^^^^. Returns the operand rounded to the nearest integer. G_LROUND, G_LLROUND; ^^^^^^^^^^^^^^^^^^^. Returns the source operand rounded to the nearest integer with ties away from; zero. See the LLVM LangRef entry on '``llvm.lround.*'`` for details on behaviour. .. code-block:: none. %rounded_32:_(s32) = G_LROUND %round_me:_(s64); %rounded_64:_(s64) = G_LLROUND %round_me:_(s64). Vector Specific Operations; -------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:12369,power,power,12369,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,1,['power'],['power']
Energy Efficiency,"signed int's are particularly common), but in this case, all; that will be added is an additional 'cast' instruction. I removed that; from the spec. > I agree with your comment that we don't need 'neg'. Removed. > There's a trade-off with the cast instruction:; > + it avoids having to define all the upcasts and downcasts that are; > valid for the operands of each instruction (you probably have; > thought of other benefits also); > - it could make the bytecode significantly larger because there could; > be a lot of cast operations. + You NEED casts to represent things like:; void foo(float);; ...; int x;; ...; foo(x);; in a language like C. Even in a Java like language, you need upcasts; and some way to implement dynamic downcasts.; + Not all forms of instructions take every type (for example you can't; shift by a floating point number of bits), thus SOME programs will need; implicit casts. To be efficient and to avoid your '-' point above, we just have to be; careful to specify that the instructions shall operate on all common; types, therefore casting should be relatively uncommon. For example all; of the arithmetic operations work on almost all data types. > Making the second arg. to 'shl' a ubyte seems good enough to me.; > 255 positions seems adequate for several generations of machines. Okay, that comment is removed. > and is more compact than uint. No, it isn't. Remember that the bytecode encoding saves value slots into; the bytecode instructions themselves, not constant values. This is; another case where we may introduce more cast instructions (but we will; also reduce the number of opcode variants that must be supported by a; virtual machine). Because most shifts are by constant values, I don't; think that we'll have to cast many shifts. :). > I still have some major concerns about including malloc and free in the; > language (either as builtin functions or instructions). Agreed. How about this proposal:. malloc/free are either built in functions or actual o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt:3051,efficient,efficient,3051,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,1,['efficient'],['efficient']
Energy Efficiency,"signed long long x, unsigned long long y, unsigned long long *prod);; bool __builtin_sadd_overflow (int x, int y, int *sum);; bool __builtin_saddl_overflow (long x, long y, long *sum);; bool __builtin_saddll_overflow(long long x, long long y, long long *sum);; bool __builtin_ssub_overflow (int x, int y, int *diff);; bool __builtin_ssubl_overflow (long x, long y, long *diff);; bool __builtin_ssubll_overflow(long long x, long long y, long long *diff);; bool __builtin_smul_overflow (int x, int y, int *prod);; bool __builtin_smull_overflow (long x, long y, long *prod);; bool __builtin_smulll_overflow(long long x, long long y, long long *prod);. Each builtin performs the specified mathematical operation on the; first two arguments and stores the result in the third argument. If; possible, the result will be equal to mathematically-correct result; and the builtin will return 0. Otherwise, the builtin will return; 1 and the result will be equal to the unique value that is equivalent; to the mathematically-correct result modulo two raised to the *k*; power, where *k* is the number of bits in the result type. The; behavior of these builtins is well-defined for all argument values. The first three builtins work generically for operands of any integer type,; including boolean types. The operands need not have the same type as each; other, or as the result. The other builtins may implicitly promote or; convert their operands before performing the operation. Query for this feature with ``__has_builtin(__builtin_add_overflow)``, etc. Floating point builtins; ---------------------------------------. ``__builtin_isfpclass``; -----------------------. ``__builtin_isfpclass`` is used to test if the specified floating-point values; fall into one of the specified floating-point classes. **Syntax**:. .. code-block:: c++. int __builtin_isfpclass(fp_type expr, int mask); int_vector __builtin_isfpclass(fp_vector expr, int mask). **Example of use**:. .. code-block:: c++. if (__builtin_isfpcla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:128769,power,power,128769,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['power'],['power']
Energy Efficiency,"simple library knowledge, it is possible to embed a; variety of other language-specific information into the LLVM IR. If you; have a specific need and run into a wall, please bring the topic up on; the llvm-dev list. At the very worst, you can always treat LLVM as if it; were a ""dumb code generator"" and implement the high-level optimizations; you desire in your front-end, on the language-specific AST. Tips and Tricks; ===============. There is a variety of useful tips and tricks that you come to know after; working on/with LLVM that aren't obvious at first glance. Instead of; letting everyone rediscover them, this section talks about some of these; issues. Implementing portable offsetof/sizeof; -------------------------------------. One interesting thing that comes up, if you are trying to keep the code; generated by your compiler ""target independent"", is that you often need; to know the size of some LLVM type or the offset of some field in an; llvm structure. For example, you might need to pass the size of a type; into a function that allocates memory. Unfortunately, this can vary widely across targets: for example the; width of a pointer is trivially target-specific. However, there is a; `clever way to use the getelementptr; instruction <http://nondot.org/sabre/LLVMNotes/SizeOf-OffsetOf-VariableSizedStructs.txt>`_; that allows you to compute this in a portable way. Garbage Collected Stack Frames; ------------------------------. Some languages want to explicitly manage their stack frames, often so; that they are garbage collected or to allow easy implementation of; closures. There are often better ways to implement these features than; explicit stack frames, but `LLVM does support; them, <http://nondot.org/sabre/LLVMNotes/ExplicitlyManagedStackFrames.txt>`_; if you want. It requires your front-end to convert the code into; `Continuation Passing; Style <http://en.wikipedia.org/wiki/Continuation-passing_style>`_ and; the use of tail calls (which LLVM also supports). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst:11879,allocate,allocates,11879,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,1,['allocate'],['allocates']
Energy Efficiency,"sing the newer, much faster,; gold linker. In addition we added the linker option ""-Wl,--no-undefined"",; so you will get an error if symbols are unresolved.; Explicit linking is required by newer distributions, like Ubuntu 11.10,; that require all dependent shared libs to be specified when linking. They; also have default options set to dead strip shared libs that don't resolve; any symbols (equivalent to the MacOS X build changes described above). Core Libraries; TClonesArray. Introduce TClonesArray::ConstructedAt which; always returns an already constructed object. If the slot is being used for the; first time, it calls the default constructor otherwise it returns the object as; is (unless a string is passed as the 2nd argument to the function in which case,; it also calls Clear(second_argument) on the object).; This allows to replace code like:. for (int i = 0; i < ev->Ntracks; i++) {; new(a[i]) TTrack(x,y,z,...);; ...; ...; }; ...; a.Delete(); // or a.Clear(""C""). with the simpler and more efficient:. for (int i = 0; i < ev->Ntracks; i++) {; TTrack *track = (TTrack*)a.ConstructedAt(i);; track->Set(x,y,z,....);; ...; ...; }; ...; a.Clear();. even in case where the TTrack class allocates memory. TClonesArray: update ExpandCreateFast to also reset the non-used slots; so that calling Clear (which does too much) is no longer necessary; when using ExpandCreateFast. New Thread Pool class. A first version of TThreadPool class has been introduced.; This class implements a Thread Pool pattern.; So far it supports only one type of queue - FIFO. Thread library. Reduces risk of internal dead lock by using a private internal lock to protect the internals of TThread, rather than using TThread::Lock. New header TThreadSlots.h to centralize and formalize the use of the TThread local memory slots amongst the ROOT packages. Global Variables. The global values gPad, gVirtualX, gInterpreter, gDirectory and gFile; are now all accessed via a static function of their respective class. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v532/index.html:2056,efficient,efficient,2056,core/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v532/index.html,2,['efficient'],['efficient']
Energy Efficiency,"single builder into two or more,; if you have multiple distinct purposes for the same builder. As an example,; if you want to both a) confirm that all of LLVM builds with your host; compiler, and b) want to do a multi-stage clang build on your target, you; may be better off with two separate bots. Splitting increases resource; consumption, but makes it easy for each bot to keep up with commit flow.; Additionally, splitting bots may assist in triage by narrowing attention to; relevant parts of the failing configuration. In general, we recommend Release build types with Assertions enabled. This; generally provides a good balance between build times and bug detection for; most buildbots. There may be room for including some debug info (e.g. with; `-gmlt`), but in general the balance between debug info quality and build; times is a delicate one. Use Ninja & LLD; Ninja really does help build times over Make, particularly for highly; parallel builds. LLD helps to reduce both link times and memory usage; during linking significantly. With a build machine with sufficient; parallelism, link times tend to dominate critical path of the build, and are; thus worth optimizing. Use CCache and NOT incremental builds; Using ccache materially improves average build times. Incremental builds; can be slightly faster, but introduce the risk of build corruption due to; e.g. state changes, etc... At this point, the recommendation is not to; use incremental builds and instead use ccache as the latter captures the; majority of the benefit with less risk of false positives. One of the non-obvious benefits of using ccache is that it makes the; builder less sensitive to which projects are being monitored vs built.; If a change triggers a build request, but doesn't change the build output; (e.g. doc changes, python utility changes, etc..), the build will entirely; hit in cache and the build request will complete in just the testing time. With multiple workers, it is tempting to try to configure",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:10836,reduce,reduce,10836,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['reduce'],['reduce']
Energy Efficiency,"size and NULL value. The ``DW_ASPACE_LLVM_none`` address space is the default target architecture; address space used in DWARF operations that do not specify an address space. It; therefore has to map to the global address space so that the ``DW_OP_addr*`` and; related operations can refer to addresses in the program code. The ``DW_ASPACE_AMDGPU_generic`` address space allows location expressions to; specify the flat address space. If the address corresponds to an address in the; local address space, then it corresponds to the wavefront that is executing the; focused thread of execution. If the address corresponds to an address in the; private address space, then it corresponds to the lane that is executing the; focused thread of execution for languages that are implemented using a SIMD or; SIMT execution model. .. note::. CUDA-like languages such as HIP that do not have address spaces in the; language type system, but do allow variables to be allocated in different; address spaces, need to explicitly specify the ``DW_ASPACE_AMDGPU_generic``; address space in the DWARF expression operations as the default address space; is the global address space. The ``DW_ASPACE_AMDGPU_local`` address space allows location expressions to; specify the local address space corresponding to the wavefront that is executing; the focused thread of execution. The ``DW_ASPACE_AMDGPU_private_lane`` address space allows location expressions; to specify the private address space corresponding to the lane that is executing; the focused thread of execution for languages that are implemented using a SIMD; or SIMT execution model. The ``DW_ASPACE_AMDGPU_private_wave`` address space allows location expressions; to specify the unswizzled private address space corresponding to the wavefront; that is executing the focused thread of execution. The wavefront view of private; memory is the per wavefront unswizzled backing memory layout defined in; :ref:`amdgpu-address-spaces`, such that address 0 corres",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:95260,allocate,allocated,95260,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"size argument, which can lead to buffer overflows.; set-xcode-analyzer now supports self-contained Xcode.app (Xcode 4.3 and later).; Contains a newer version of the analyzer than Xcode 4.3.; Misc. bug fixes and performance work. checker-260; built: January 25, 2012; highlights:; This is essentially the same as checker-259, but enables the following experimental checkers (please provide feedback):. Warns about unsafe uses of CFArrayCreate, CFSetCreate, and CFDictionaryCreate; Warns about unsafe uses of getpw, gets, which are sources of buffer overflows; Warns about unsafe uses of mktemp and mktemps, which can lead to insecure temporary files; Warns about unsafe uses of vfork, which is insecure to use; Warns about not checking the return values of setuid, setgid, seteuid, setegid, setreuid, setregid (another security issue). checker-259; built: January 25, 2012; highlights:. Contains a newer version of the analyzer than the one shipped in Xcode 4.2.; Significant performance optimizations to reduce memory usage of the analyzer.; Tweaks to scan-build to have it work more easily with Xcode projects using Clang.; Numerous bug fixes to better support code using ARC. checker-258; built: October 13, 2011; highlights:. Contains a newer version of the analyzer than the one shipped in Xcode 4.2.; Adds a new security checker for looking at correct uses of the Mac OS KeyChain API.; Supports ARC (please file bugs where you see issues); Major under-the-cover changes. This should result in more precise results in some cases, but this is laying the groundwork for major improvements. Please file bugs where you see regressions or issues. checker-257; built: May 25, 2011; highlights:. The analyzer is now far more aggressive with checking conformance with Core Foundation conventions. Any function that returns a CF type must now obey the Core Foundation naming conventions, or use the cf_returns_retained or cf_returns_not_retained annotations.; Fixed a serious regression where the analyzer ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:10038,reduce,reduce,10038,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,2,['reduce'],['reduce']
Energy Efficiency,"size can be optional, but if the; MD5 checksum is present it must be valid for all files. This is a problem if; using link time optimization to combine compilation units where some have MD5; checksums and some do not. Therefore, sSupport to allow MD5 checksums to be; optionally present in the line table is added. See :ref:`amdgpu-dwarf-line-number-information`. 2.18 Add the HIP Programing Language; ------------------------------------. The HIP programming language [:ref:`HIP <amdgpu-dwarf-HIP>`], which is supported; by the AMDGPU, is added. See :ref:`amdgpu-dwarf-language-names-table`. 2.19 Support for Source Language Optimizations that Result in Concurrent Iteration Execution; --------------------------------------------------------------------------------------------. A compiler can perform loop optimizations that result in the generated code; executing multiple iterations concurrently. For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of one iteration to hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SIMD; hardware to allow a single instruction to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:32997,schedul,schedules,32997,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['schedul'],['schedules']
Energy Efficiency,"size close to expected final size. Index; validity is always checked (if you are 100% sure and maximum performance; is needed you can use `UnCheckedAt()` instead of `At()` or; `operator[]`). If the stored objects are sort able the array can be; sorted using `Sort()`. Once sorted, efficient searching is possible via; the `BinarySearch()` method. The figure shows the internal data; structure of a **`TObjArray`**:. ![The internal data structure of a TObjArray](pictures/020001A7.jpg). Iterating can be done using a **`TIter`** iterator or via a simple for; loop:. ``` {.cpp}; for (int i = 0; i <= fArr.GetLast(); i++); if ((track = (TTrack*)fArr[i])) // or fArr.At(i); track->Draw();; ```. Main features of **`TObjArray`** are simple, well-known array semantics.; **Overhead per element**: none, except possible over sizing of `fCont`. ## TClonesArray An Array of Identical Objects. A **`TClonesArray`** is an array of identical (clone) objects. The; memory for the objects stored in the array is allocated only once in the; lifetime of the clones array. All objects must be of the same class. For; the rest this class has the same properties as a **`TObjArray`**. ![The internal data structure of a TClonesArray](pictures/020001A8.jpg). The figure above shows the internal data structure of a; **`TClonesArray`**. The class is specially designed for repetitive data; analysis tasks, where in a loop many times the same objects, are created; and deleted. The only supported way to add objects to a; **`TClonesArray`** is via the `new` with placement method. The different; `Add()` methods of **`TObjArray`** and its base classes are not; supported. ### The Idea Behind TClonesArray. To reduce the very large number of new and delete calls in large loops; like this (O(100000) x O(10000) times new/delete):. ``` {.cpp}; TObjArray a(10000);; while (TEvent *ev = (TEvent *)next()) { // O(100000); for (int i = 0; i < ev->Ntracks; i++) { // O(10000); a[i] = new TTrack(x,y,z,...);; ...; }; ...; a.Delete(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md:16236,allocate,allocated,16236,documentation/users-guide/CollectionClasses.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md,1,['allocate'],['allocated']
Energy Efficiency,"sk : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrinsic may be used in a scheduling region. The iglp_opt intrinsic; cannot be combined with sched_barrier or sched_group_barrier. The iglp_opt strategy implementations are subject to change. llvm.amdgcn.atomic.cond.sub.u32 Provides direct access to flat_atomic_cond_sub_u32, global_atomic_cond_sub_u32; and ds_cond_sub_u32 based on address space on gfx12 targets. This; performs subtraction only if the memory value is greater than or; equal to the data value. llvm.amdgcn.s.getpc Provides access to the s_getpc_b64 instruction, but with the return value; sign-extended from the width of the underlying PC hardware register even on; processors where the s_getpc_b64 instruction returns a zero-extended value. ===",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:44763,schedul,scheduling,44763,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduling']
Energy Efficiency,"smgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sle",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5260,monitor,monitoring,5260,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,1,['monitor'],['monitoring']
Energy Efficiency,"sn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :program:`llvm-mca` comes with several Views such as the Timeline View and; Summary View. These Views are generic and can work with most (if not all); targets. If you wish to add a new View to :program:`llvm-mca` and it does not; require any backend functionality that is not already exposed through MC layer; classes (MCSubtargetInfo, MCInstrInfo, etc.), please add it to the; `/tools/llvm-mca/View/` directory. However, if your new View is target specific; AND requires unexposed backend symbols or functionality, you can define it in; the `/lib/Target/<TargetName>/MCA/` directory. To enable this target specific View, you will have to use this target'",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:46425,schedul,schedule,46425,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['schedule']
Energy Efficiency,"so unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ----------------------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:1877,efficient,efficiently,1877,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst,1,['efficient'],['efficiently']
Energy Efficiency,"so; that the returned string was meaningless.; Reset; the list if dir entries in FreeDirectory.; Fix problem affecting repeated calls. The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; Now TMonaLisaWriter keeps internally track of every; activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; Additionally, it's now finalized the infrastructure able to; measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; Now, the hook for the Close() func triggers sending of a; packet containing various information about the performance related to; that file only.; Added support also for performance monitoring when writing. RGLITE: A ROOT GRID interface. RGLite plug-in - a ROOT plug-in module, which implements the ROOT Grid; interface and offers to ROOT users possibilities to perform a number of; operations using gLite middleware from within ROOT. Supported features:. Workload Management System operations:; ; job submission â€“ normal, DAG and parametric; jobs (gLite; WMProxy API), ; smart look-up algorithm for WMP-Endpoints, ; job status querying (gLite LB API), ; job output retrieving (Globus GridFTP). . File Catalog operations (gLite/LCG LFC API):; ; smart session manager, ; set/query the current working catalog directory, ; list files, directories and their stats, ; add/remove files in a catalog namespace, ; add/remove directories, ; add/remove replicas from a given file. . An executive logging. ; Support of an external XML configuration file with; according XML; schema. . Usage examples:. Job operations. // loading RGLite plug-in. TGrid::Connect(""glite"");; // submitting G",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html:3009,monitor,monitoring,3009,net/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html,2,['monitor'],['monitoring']
Energy Efficiency,"spatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31667,schedul,scheduler,31667,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,"splays the date and time when the mouse cursor; is moved over a time axis (implemented by Otto Schaile).; * Negative values were not painted with option ""TEXT"" for TH2Poly. ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ### Jupyter Notebook Integration; - When starting Jupyter server with `root --notebook arg1 arg2 ...`, extra arguments can be provided.; All these arguments delivered as is to jupyter executable and can be used for configuration.; Like server binding to specific host `root --notebook --ip=hostname`; - Remove `c.NotebookApp.ip = '*'` from default jupyter config. One has to provide ip address for server; binding using `root --notebook --ip=<hostaddr>` arguments; - Now Jupyter Notebooks will use JSROOT provided with ROOT installation. This allows to use notebooks; without internet connection (offline). ## JavaScript ROOT; - Provide monitoring capabilities for TGeoManager object. Now geomtry with some tracks can be displayed and; updated in web browser, using THttpServer monitoring capability like histogram objects. ## Tutorials; - Add the ""Legacy"" category collecting the old tutorials which do not represent any more best practices. ## Class Reference Guide; - Images in tutorials can now be displayed Ã  JavaScript thanks to the (js) option; added next to the directive `\macro_image`; - As the tutorial `palettes.C` is often hit when searching the keyword `palette`; in the reference guide, a direct link from this example to the full list of; predefined palettes given in `TColor` has been added.; - Revisited the TSpectrum2 documentation. All the static images have been replaced; by macros generating images at reference guide build time. These macros have; been added in the tutorial section of the reference guide.; - The Reference Guide can now be accessed directly from the ROOT prompt thanks to; a great extension (implemented",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md:6535,monitor,monitoring,6535,README/ReleaseNotes/v620/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md,1,['monitor'],['monitoring']
Energy Efficiency,"ss`` class; ------------------------. ``RegionPass`` is similar to :ref:`LoopPass <writing-an-llvm-pass-LoopPass>`,; but executes on each single entry single exit region in the function.; ``RegionPass`` processes regions in nested order such that the outer most; region is processed last. ``RegionPass`` subclasses are allowed to update the region tree by using the; ``RGPassManager`` interface. You may override three virtual methods of; ``RegionPass`` to implement your own region pass. All these methods should; return ``true`` if they modified the program, or ``false`` if they did not. The ``doInitialization(Region *, RGPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Region *, RGPassManager &RGM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``RPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &RGM) = 0;. The ``runOnRegion`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a true value should be; returned if the region is modified. ``RGPassManager`` interface should be used to; update region tree. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnRegion; <writing-an-llvm-pass-runOnRegion>` for every region in the program being; compiled. The ``MachineFunctionPass`` class; -----------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:23687,schedul,scheduled,23687,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['schedul'],['scheduled']
Energy Efficiency,"st argument and the return type are floating-point numbers of the same; type. The second and third arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function returns the nonnegative square root of the specified value.; If the value is less than negative zero, a floating-point exception occurs; and the return value is architecture specific. '``llvm.experimental.constrained.pow``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.experimental.constrained.pow(<type> <op1>, <type> <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.pow``' intrinsic returns the first operand; raised to the (positive or negative) power specified by the second operand. Arguments:; """""""""""""""""""". The first two arguments and the return value are floating-point numbers of the; same type. The second argument specifies the power to which the first argument; should be raised. The third and fourth arguments specify the rounding mode and exception; behavior as described above. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power,; returning the same values as the libm ``pow`` functions would, and; handles error conditions in the same way. '``llvm.experimental.constrained.powi``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.experimental.constrained.powi(<type> <op1>, i32 <op2>,; metadata <rounding mode>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.powi``' intrinsic returns the first operand; raised to the (positive or negative) power specified by the second operand. The; order of evaluation of multiplications is not defined. When a vector of; floating-point type is used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The first argument and the r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:891482,power,power,891482,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"st of the current error messages and their potential cause:. - ``""corrupted chunk header""``: the checksum verification of the chunk header; has failed. This is likely due to one of two things: the header was; overwritten (partially or totally), or the pointer passed to the function is; not a chunk at all;. - ``""race on chunk header""``: two different threads are attempting to manipulate; the same header at the same time. This is usually symptomatic of a; race-condition or general lack of locking when performing operations on that; chunk;. - ``""invalid chunk state""``: the chunk is not in the expected state for a given; operation, eg: it is not allocated when trying to free it, or it's not; quarantined when trying to recycle it, etc. A double-free is the typical; reason this error would occur;. - ``""misaligned pointer""``: we strongly enforce basic alignment requirements, 8; bytes on 32-bit platforms, 16 bytes on 64-bit platforms. If a pointer passed; to our functions does not fit those, something is definitely wrong. - ``""allocation type mismatch""``: when the optional deallocation type mismatch; check is enabled, a deallocation function called on a chunk has to match the; type of function that was called to allocate it. Security implications of such; a mismatch are not necessarily obvious but situational at best;. - ``""invalid sized delete""``: when the C++14 sized delete operator is used, and; the optional check enabled, this indicates that the size passed when; deallocating a chunk is not congruent with the one requested when allocating; it. This is likely to be a `compiler issue <https://software.intel.com/en-us/forums/intel-c-compiler/topic/783942>`_,; as was the case with Intel C++ Compiler, or some type confusion on the object; being deallocated;. - ``""RSS limit exhausted""``: the maximum RSS optionally specified has been; exceeded;. Several other error messages relate to parameter checking on the libc allocation; APIs and are fairly straightforward to understand. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:16286,allocate,allocate,16286,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['allocate'],['allocate']
Energy Efficiency,"start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmax.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmax``' intrinsic performs the floating-point ``MAX``; reduction (:ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>`) of the; vector operand ``val`` on each enabled lane, taking the maximum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``-QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the smallest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``-Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>` intrinsic (and thus the; '``llvm.maxnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:772189,reduce,reduce,772189,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmin.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmin``' intrinsic performs the floating-point ``MIN``; reduction (:ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``+QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the largest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``+Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>` intrinsic (and thus the; '``llvm.minnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:775063,reduce,reduce,775063,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"starting at minimal temperature (ie, from within a; local minimum), slowly increasing, and another one; starting at high temperature, slowly decreasing into a; minimum. Code developed and written by Kamil Bartlomiej; Kraszewski, Maciej Kruk and Krzysztof Danielowski from IFJ; and AGH/UJ, Krakow, Poland.; ; Cuts: Added printouts, quoting the explicit cut; application for given signal efficiency. In case of; transformations of the input variables, the full expressions; are given. Added warning to Fisher in case of variable; normalisation. ; ; Cuts: Added physical limits to min/max cuts if; smart option is used.; ; BDT: removed hard-coded weight file name; now,; paths and names of weight files are written as TObjStrings; into ROOT target file, and retrieved for plotting;; available weight files (corresponding to target used) can; be chosen from pop-up GUI.; ; BDT: Changes in handling negative weights in BDT; algorithm. Events with negative weights now get their; weight reduced (*= 1/boostweight) rather than increased; (*= boostweight) as the other events do. Otherwise these; events tend to receive increasingly stronger boosts,; because their effects on the separation gain are as if; background events were selected as signal and vice versa; (hence the events tend to be ""wanted"" in signal nodes, but; are boosted as if they were misclassified). In addition,; the separation indices are protected against negative S or; S+B returning 0.5 (no separation at all) in case that; occurs.; ; BDT: In addition there is a new BDT option to; ignore events with negative event weights for the; training. This option could be used as a cross check of a; ""worst case"" solution for Monte Carlo samples with; negative weights. Note that the results of the testing; phase still include these events and are hence objective.; ; BDT: Added randomised trees: similar to the; ""Random Forests"" technique of Leo Breiman and Adele; Cutler, it uses the ""bagging"" algorithm and bases the; determination of the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:2757,reduce,reduced,2757,tmva/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html,2,['reduce'],['reduced']
Energy Efficiency,"std::set <dss_set>`. A sorted vector; (where you don't delete duplicate entries) or some other approach is almost; always better. .. _ds_map:. Map-Like Containers (std::map, DenseMap, etc); ---------------------------------------------. Map-like containers are useful when you want to associate data to a key. As; usual, there are a lot of different ways to do this. :). .. _dss_sortedvectormap:. A sorted 'vector'; ^^^^^^^^^^^^^^^^^. If your usage pattern follows a strict insert-then-query approach, you can; trivially use the same approach as :ref:`sorted vectors for set-like containers; <dss_sortedvectorset>`. The only difference is that your query function (which; uses std::lower_bound to get efficient log(n) lookup) should only compare the; key, not both the key and value. This yields the same advantages as sorted; vectors for sets. .. _dss_stringmap:. llvm/ADT/StringMap.h; ^^^^^^^^^^^^^^^^^^^^. Strings are commonly used as keys in maps, and they are difficult to support; efficiently: they are variable length, inefficient to hash and compare when; long, expensive to copy, etc. StringMap is a specialized container designed to; cope with these issues. It supports mapping an arbitrary range of bytes to an; arbitrary other object. The StringMap implementation uses a quadratically-probed hash table, where the; buckets store a pointer to the heap allocated entries (and some other stuff).; The entries in the map must be heap allocated because the strings are variable; length. The string data (key) and the element object (value) are stored in the; same allocation with the string data immediately after the element object.; This container guarantees the ""``(char*)(&Value+1)``"" points to the key string; for a value. The StringMap is very fast for several reasons: quadratic probing is very cache; efficient for lookups, the hash value of strings in buckets is not recomputed; when looking up an element, StringMap rarely has to touch the memory for; unrelated objects when looking u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:88548,efficient,efficiently,88548,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficiently']
Energy Efficiency,"struct`` in order;. - otherwise, it is just the return type of the coroutine function. The first element of the result-type sequence must be a pointer type;; continuation functions will be coerced to this type. The rest of; the sequence are the 'yield types', and any suspends in the coroutine; must take arguments of these types. Arguments:; """""""""""""""""""". The first and second arguments are the expected size and alignment of; the buffer provided as the third argument. They must be constant. The fourth argument must be a reference to a global function, called; the 'continuation prototype function'. The type, calling convention,; and attributes of any continuation functions will be taken from this; declaration. The return type of the prototype function must match the; return type of the current function. The first parameter type must be; a pointer type. The second parameter type must be an integer type;; it will be used only as a boolean flag. The fifth argument must be a reference to a global function that will; be used to allocate memory. It may not fail, either by returning null; or throwing an exception. It must take an integer and return a pointer. The sixth argument must be a reference to a global function that will; be used to deallocate memory. It must take a pointer and return ``void``. Semantics:; """""""""""""""""""". A frontend should emit function attribute `presplitcoroutine` for the coroutine. 'llvm.coro.id.retcon.once' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare token @llvm.coro.id.retcon.once(i32 <size>, i32 <align>, ptr <buffer>,; ptr <prototype>,; ptr <alloc>, ptr <dealloc>). Overview:; """""""""""""""""". The '``llvm.coro.id.retcon.once``' intrinsic returns a token identifying a; unique-suspend returned-continuation coroutine. Arguments:; """""""""""""""""""". As for ``llvm.core.id.retcon``, except that the return type of the; continuation prototype must represent the normal return type of the continuation; (instead of matching the coroutine's return type). Sem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:41230,allocate,allocate,41230,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['allocate'],['allocate']
Energy Efficiency,"sule**: Takes a cppyy bound C++ object and returns its address as; a PyCapsule object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_cobject**: Takes a cppyy bound C++ object and returns its address as; a PyCObject object for Python2 and a PyCapsule object for Python3.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_ctypes**: Takes a cppyy bound C++ object and returns its address as; a ``ctypes.c_void_p`` object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. `ctypes`; --------. The `ctypes module`_ has been part of Python since version 2.5 and provides a; Python-side foreign function interface.; It is clunky to use and has very bad performance, but it is guaranteed to be; available.; It does not have a public C interface, only the Python one, but its internals; have been stable since its introduction, making it safe to use for tight and; efficient integration at the C level (with a few Python helpers to assure; lazy lookup). Objects from ``ctypes`` can be passed through arguments of functions that; take a pointer to a single C++ builtin, and ``ctypes`` pointers can be passed ; when a pointer-to-pointer is expected, e.g. for array out-parameters.; This leads to the following set of possible mappings:. ======================================== ========================================; C++ ctypes; ======================================== ========================================; by value (ex.: ``int``) ``.value`` (ex.: ``c_int(0).value``); by const reference (ex.: ``const int&``) ``.value`` (ex.: ``c_int(0).value``); by reference (ex.: ``int&``) direct (ex.: ``c_int(0)``); by pointer (ex.: ``int*``) direct (ex.: ``c_int(0)``); by ptr-ref (ex.: ``int*&``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **in** (ex.: ``int**``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **out*",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:7565,efficient,efficient,7565,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,1,['efficient'],['efficient']
Energy Efficiency,"sulting value will be equal to the starting value. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fmul; <int_vector_reduce_fmul>`) for more detail on the semantics. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmul.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float 1.0, float 1.0, float 1.0, float 1.0>; %also.r = call float @llvm.vector.reduce.fmul.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_and:. '``llvm.vp.reduce.and.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.and.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.and``' intrinsic performs the integer ``AND`` reduction; (:ref:`llvm.vector.reduce.and <int_vector_reduce_and>`) of the vector operand; ``val`` on each enabled lane, performing an '``and``' of that with with the; scala",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:756930,reduce,reduce,756930,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, lib",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:10352,reduce,reduce,10352,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['reduce'],['reduce']
Energy Efficiency,"t be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmul``' intrinsic performs the floating-point ``MUL``; reduction (:ref:`llvm.vector.reduce.fmul <int_vector_reduce_fmul>`) of the; vector operand ``val`` on each enabled lane, multiplying it by the scalar; `start_value``. Disabled lanes are treated as containing the neutral value; ``1.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to the starting value. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fmul; <int_vector_reduce_fmul>`) for more detail on the semantics. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmul.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float 1.0, float 1.0, float 1.0, float 1.0>; %also.r = call float @llvm.vector.reduce.fmul.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_and:. '``llvm.vp.reduce.and.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.and.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` red",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:756090,reduce,reduce,756090,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"t from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL. Â Â Â Â Â Â Â Â Â Â Â Â Â ; chain.AddFile(""root:// .....?msd=CERN""). Â and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is; Â Â Â Â Â Â Â Â Â ; <admin_path>/.xproofd.<port>/act",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:4626,monitor,monitoring,4626,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,2,['monitor'],['monitoring']
Energy Efficiency,"t from significantly faster times for fitting by calling `fitTo()` and providing a `BatchMode(""cpu"")` or a `BatchMode(""cuda"")` option.; ``` {.cpp}; // fit using the most efficient library that the computer's CPU can support; RooMyPDF.fitTo(data, BatchMode(""cpu""));. // fit using the CUDA library along with the most efficient library that the computer's CPU can support; RooMyPDF.fitTo(data, BatchMode(""cuda""));; ```; **Note: In case the system does not support vector instructions, the `RooBatchCompute::Cpu` option is guaranteed to work properly by using a generic CPU library. In contrast, users must first make sure that their system supports CUDA in order to use the `RooBatchCompute::Cuda` option. If this is not the case, an exception will be thrown.**. If `""cuda""` is selected, RooFit will launch CUDA kernels for computing likelihoods and potentially other intense computations. At the same time, the most efficient CPU library loaded will also handle parts of the computations in parallel with the GPU (or potentially, if it's faster, all of them), thus gaining full advantage of the available hardware. For this purpose `RooFitDriver`, a newly created RooFit class (in roofitcore) takes over the task of analyzing the computations and assigning each to the correct piece of hardware, taking into consideration the performance boost or penalty that may arise with every method of computing. #### Multithread computations; The CPU instance of the computing library can furthermore execute multithread computations. This also applies for computations handled by the CPU in the `""cuda""` mode. To use them, one needs to set the desired number of parallel tasks before calling `fitTo()` as shown below:; ``` {.cpp}; ROOT::EnableImplicitMT(nThreads);; RooMyPDF.fitTo(data, BatchMode(""cuda"")); // can also use ""cuda""; ```. ### User-made PDFs; The easiest and most efficient way of accelerating your PDFs is to request their addition to the official RooFit by submitting a ticket [here](https://git",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md:2648,efficient,efficient,2648,roofit/doc/developers/batchcompute.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/batchcompute.md,1,['efficient'],['efficient']
Energy Efficiency,"t is usually the call site itself rather than; the return address, i.e. one instruction earlier. When presenting the source; location for a return address frame, the symbolizing filter will subtract one; byte or one instruction length from the actual return address for the call; site, with the intent that the address logged can be translated directly to a; source location for the call site and not for the apparent return site; thereafter (which can be confusing). When inlined functions are involved, the; call site and the return site can appear to be in different functions at; entirely unrelated source locations rather than just a line away, making the; confusion of showing the return site rather the call site quite severe. Often the first frame in a backtrace (""frame zero"") identifies the precise; code location of a fault, trap, or asynchronous interrupt rather than a return; address. At other times, even the first frame is actually a return address; (for example, backtraces collected at the time of an object allocation and; reported later when the allocated object is used or misused). When a system; supports in-thread trap handling, there may also be frames after the first; that represent a precise interrupted code location rather than a return; address, presented as the ""caller"" of a trap handler function (for example,; signal handlers in POSIX systems). Return address frames are identified by the ``:ra`` suffix. Precise code; location frames are identified by the ``:pc`` suffix. Traditional practice has often been to collect backtraces as simple address; lists, losing the distinction between return address code locations and; precise code locations. Some such code applies the ""subtract one"" adjustment; described above to the address values before reporting them, and it's not; always clear or consistent whether this adjustment has been applied or not.; These ambiguous cases are supported by the ``bt`` and ``pc`` forms with no; ``:ra`` or ``:pc`` suffix, which indi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:11656,allocate,allocated,11656,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,1,['allocate'],['allocated']
Energy Efficiency,"t is; aligned to a multiple of the second argument.; All of these builtins expect the alignment to be expressed as a number of bytes. These builtins can be used for all integer types as well as (non-function); pointer types. For pointer types, these builtins operate in terms of the integer; address of the pointer and return a new pointer of the same type (including; qualifiers such as ``const``) with an adjusted address.; When aligning pointers up or down, the resulting value must be within the same; underlying allocation or one past the end (see C17 6.5.6p8, C++ [expr.add]).; This means that arbitrary integer values stored in pointer-type variables must; not be passed to these builtins. For those use cases, the builtins can still be; used, but the operation must be performed on the pointer cast to ``uintptr_t``. If Clang can determine that the alignment is not a power of two at compile time,; it will result in a compilation failure. If the alignment argument is not a; power of two at run time, the behavior of these builtins is undefined. Non-standard C++11 Attributes; =============================. Clang's non-standard C++11 attributes live in the ``clang`` attribute; namespace. Clang supports GCC's ``gnu`` attribute namespace. All GCC attributes which; are accepted with the ``__attribute__((foo))`` syntax are also accepted as; ``[[gnu::foo]]``. This only extends to attributes which are specified by GCC; (see the list of `GCC function attributes; <https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html>`_, `GCC variable; attributes <https://gcc.gnu.org/onlinedocs/gcc/Variable-Attributes.html>`_, and; `GCC type attributes; <https://gcc.gnu.org/onlinedocs/gcc/Type-Attributes.html>`_). As with the GCC; implementation, these attributes must appertain to the *declarator-id* in a; declaration, which means they must go either at the start of the declaration or; immediately after the name being declared. For example, this applies the GNU ``unused`` attribute to ``a`` an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:153225,power,power,153225,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['power'],['power']
Energy Efficiency,"t of this file, contact; * the Particle Data Group at pdg@lbl.gov.; *; * To process the images in this file:; * 1) ignore documentation lines that begin with an asterisk; * 2) in a FORTRAN program, process data lines with; * FORMAT (BN, A1, 4I8, 1X, E15.0, 2(1X, E8.0), 1X, A21); * 3) column 1 contains either ""M"" or ""W"" indicating mass or width; * 2 - 9 \ Monte Carlo particle numbers as described in the ""Review of; * 10 - 17 | Particle Physics"". Charge states appear, as appropriate,; * 18 - 25 | from left-to-right in the order -, 0, +, ++.; * 26 - 33 /; * 34 blank; * 35 - 49 central value of the mass or width (double precision); * 50 blank; * 51 - 58 positive error; * 59 blank; * 60 - 67 negative error; * 68 blank; * 69 - 89 particle name left-justified in the field and; * charge states right-justified in the field.; * This field is for ease of visual examination of the file and; * should not be taken as a standardized presentation of; * particle names.; *; * Particle ID(s) Value (GeV) Errors (GeV) Name Charges; M 22 0.E+00 +0.0E+00 -0.0E+00 gamma 0; W 22 0.E+00 +0.0E+00 -0.0E+00 gamma 0; M 24 8.0398E+01 +2.5E-02 -2.5E-02 W +; W 24 2.14E+00 +4.0E-02 -4.0E-02 W +; M 23 9.11876E+01 +2.1E-03 -2.1E-03 Z 0; W 23 2.4952E+00 +2.3E-03 -2.3E-03 Z 0; M 11 5.10998910E-04 +1.3E-11 -1.3E-11 e -; W 11 0.E+00 +0.0E+00 -0.0E+00 e -; M 13 1.05658367E-01 +4.0E-09 -4.0E-09 mu -; W 13 3.015937E-19 +2.9E-24 -2.9E-24 mu -; M 15 1.77684E+00 +1.7E-04 -1.7E-04 tau -; W 15 2.280E-12 +8.0E-15 -8.0E-15 tau -; M 2 2.4E-03 +9.0E-04 -9.0E-04 u +2/3; M 1 4.8E-03 +1.2E-03 -1.2E-03 d -1/3; M 3 1.04E-01 +2.6E-02 -3.4E-02 s -1/3; M 4 1.27E+00 +7.0E-02 -1.1E-01 c +2/3; M 5 4.68E+00 +1.7E-01 -7.0E-02 b -1/3; M 6 1.712E+02 +2.1E+00 -2.1E+00 t +2/3; M 211 1.3957018E-01 +3.5E-07 -3.5E-07 pi +; W 211 2.5452E-17 +5.0E-21 -5.0E-21 pi +; M 111 1.349766E-01 +6.0E-07 -6.0E-07 pi 0; W 111 7.9E-09 +6.0E-10 -6.0E-10 pi 0; M 221 5.47853E-01 +2.4E-05 -2.4E-05 eta 0; W 221 1.30E-06 +7.0E-08 -7.0E-08 eta 0; M 9000221 8.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/mc/mass_width_2008.mc.txt:1323,Charge,Charges,1323,tutorials/mc/mass_width_2008.mc.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/mc/mass_width_2008.mc.txt,1,['Charge'],['Charges']
Energy Efficiency,"t pointer to actually access the object if you do, unless the; object is managed outside of LLVM. Also as above, ptrtoint and inttoptr provide an alternative way to do this which; do not have this restriction. Can I do type-based alias analysis on LLVM IR?; ----------------------------------------------. You can't do type-based alias analysis using LLVM's built-in type system,; because LLVM has no restrictions on mixing types in addressing, loads or stores. LLVM's type-based alias analysis pass uses metadata to describe a different type; system (such as the C type system), and performs type-based aliasing on top of; that. Further details are in the; `language reference <LangRef.html#tbaa-metadata>`_. What happens if a GEP computation overflows?; --------------------------------------------. If the GEP lacks the ``inbounds`` keyword, the value is the result from; evaluating the implied two's complement integer computation. However, since; there's no guarantee of where an object will be allocated in the address space,; such values have limited meaning. If the GEP has the ``inbounds`` keyword, the result value is ``poison``; if the GEP overflows (i.e. wraps around the end of the address space). As such, there are some ramifications of this for inbounds GEPs: scales implied; by array/vector/pointer indices are always known to be ""nsw"" since they are; signed values that are scaled by the element size. These values are also; allowed to be negative (e.g. ""``gep i32, ptr %P, i32 -1``"") but the pointer; itself is logically treated as an unsigned value. This means that GEPs have an; asymmetric relation between the pointer base (which is treated as unsigned) and; the offset applied to it (which is treated as signed). The result of the; additions within the offset calculation cannot have signed overflow, but when; applied to the base pointer, there can be signed overflow. How can I tell if my front-end is following the rules?; ----------------------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:17611,allocate,allocated,17611,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['allocate'],['allocated']
Energy Efficiency,"t root**, simply type `.q` or `.quit` or `.exit`. - obtain the full **list of commands**, use `.?` or `.help`. - **access the shell** of the operating system, type `.!<OS_command>`;; try, e.g. `.!ls` or `.!pwd`. - **execute a macro**, enter `.x <file_name>`; in the above example,; you might have used `.x slits.C` at the ROOT prompt. - **load a macro**, type `.L <file_name>`; in the above example, you; might instead have used the command `.L slits.C` followed by the; function call `slits();`. Note that after loading a macro all; functions and procedures defined therein are available at the ROOT; prompt. - **compile a macro**, type `.L <file_name>+`; ROOT is able to manage; for you the `C++` compiler behind the scenes and to produce machine; code starting from your macro. One could decide to compile a macro; in order to obtain better performance or to get nearer to the; production environment. ## Plotting Measurements ##. To display measurements in ROOT, including errors, there exists a; powerful class `TGraphErrors` with different types of constructors. In; the example here, we use data from the file `ExampleData.txt` in text; format:. ``` {.cpp}; root [0] TGraphErrors gr(""ExampleData.txt"");; root [1] gr.Draw(""AP"");; ```. You should see the output shown in Figure [2.2](#f22). [f22]: figures/TGraphErrors_Example.png ""f22""; <a name=""f22""></a>. ![Visualisation of data points with errors using the class TGraphErrors. \label{f22}][f22]. Make sure the file `ExampleData.txt` is available in the directory from; which you started ROOT. Inspect this file now with your favourite; editor, or use the command `less ExampleData.txt` to inspect the file,; you will see that the format is very simple and easy to understand.; Lines beginning with `#` are ignored. It is very convenient to add some; comments about the type of data. The data itself consist of lines with; four real numbers each, representing the x- and y- coordinates and their; errors of each data point. The argument of the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:8888,power,powerful,8888,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['power'],['powerful']
Energy Efficiency,"t their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to you",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:1365,schedul,scheduling,1365,proof/doc/confman/ConfigProofPoD.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md,1,['schedul'],['scheduling']
Energy Efficiency,"t together tens, hundreds of peaks; simultaneously that sometimes represent thousands of parameters. - the calculation of the inversion matrix of such a size is; practically impossible. - the awmi method is based on the assumption that the off-diagonal; terms in the matrix A are equal to zero. $$; \Delta a_{k}^{(t+1)} = \alpha^{(t)}; \frac{; \sum_{i=1}^{N} \frac{e_{i}^{(t)}}{y_i}\frac{\partial f(i,a^{(t)})}{\partial a_k}; }{; \sum_{i=1}^{N} \left[ \frac{\partial f(i,a^{(t)})}{\partial a_k}\right]^2\frac{1}{y_i}; }; $$. where the error in the channel `i` is $e_{i}^{(t)} = y_i-f(i,a^{(t)}); k=1,2,...,M$ and; $\alpha^{(t)}=1$ if the process is convergent or $\alpha^{(t)}=0.5 \alpha^{(t-1)}$; if it is divergent. Another possibility is to optimize this coefficient. The error of `k`-th parameter estimate is. $$; \Delta a_k^{(e)}=; \sqrt{\frac; {\sum_{i=1}^{N}\frac{e_i^2}{y_i}}; {\sum_{i=1}^{N} \left[ \frac{\partial f(i,a^{(t)})}{\partial a_k}\right]^2\frac{1}{y_i}}; }; $$. Algorithm with higher powers `w=1,2,3...`:. $$; \Delta a_{k,w}^{(t+1)}=; \alpha^{(t)}; \frac; {\sum_{i=1}^{N} \frac{e_i}{y_i}\left[ \frac{\partial f(i,a^{(t)})}{\partial a_k}\right]^{2w-1}}; {\sum_{i=1}^{N} \left[ \frac{\partial f(i,a^{(t)})}{\partial a_k}\right]^{2w}\frac{1}{y_i}}; $$. We have implemented the non-symmetrical semi-empirical peak shape function. It contains the symmetrical Gaussian as well as non-symmetrical terms:. $$; f(i,a) =; \sum_{i=1}^{M} A(j); \left\{; exp\left[\frac{-(i-p(j))^2}{2\sigma^2}\right]; +\frac{1}{2}T.exp\left[\frac{(i-p(j))}{B\sigma}\right]; .erfc\left[\frac{(i-p(j))}{\sigma}+\frac{1}{2B}\right]; +\frac{1}{2}S.erfc\left[\frac{(i-p(j))}{\sigma}\right]; \right\}; $$. where `T, S` are relative amplitudes and `B` is a slope. Detailed description of the algorithm is given in [13]. The fitting function implementing the algorithm without matrix inversion; has the form of. ``` {.cpp}; char* Fit1Awmi(float *source,; TSpectrumOneDimFit *p,; int size);; ```. This function fits the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:39862,power,powers,39862,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['power'],['powers']
Energy Efficiency,"t values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42767,schedul,scheduled,42767,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"t()``, etc. are; satisfied if each type index matches one element in each of the independent; sets. So ``.legalForCartesianProduct({s16, s32}, {s32, s64})`` will accept; ``{s16, s32}``, ``{s16, s64}``, ``{s32, s32}``, and ``{s32, s64}``. Composite Rules; """""""""""""""""""""""""""""". There are some composite rules for common situations built out of the above facilities:. * ``widenScalarToNextPow2()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is not a power of 2 and selects a target type that is the next; largest power of 2. .. _clampscalar:. * ``minScalar()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is smaller than the given minimum and selects the minimum as the; target type. Similarly, there is also a ``maxScalar()`` for the maximum and a; ``clampScalar()`` to do both at once. * ``minScalarSameAs()`` is like ``minScalar()`` but the minimum is taken from another; type index. * ``moreElementsToNextMultiple()`` is like ``moreElementsToNextPow2()`` but is based on; multiples of X rather than powers of 2. .. _min-legalizerinfo:. Minimum Rule Set; ^^^^^^^^^^^^^^^^. GlobalISel's legalizer has a great deal of flexibility in how a given target; shapes the GMIR that the rest of the backend must handle. However, there are; a small number of requirements that all targets must meet. Before discussing the minimum requirements, we'll need some terminology:. Producer Type Set; The set of types which is the union of all possible types produced by at; least one legal instruction. Consumer Type Set; The set of types which is the union of all possible types consumed by at; least one legal instruction. Both sets are often identical but there's no guarantee of that. For example,; it's not uncommon to be unable to consume s64 but still be able to produce it; for a few specific instructions. Minimum Rules For Scalars; """""""""""""""""""""""""""""""""""""""""""""""""". * G_ANYEXT must be legal for all inputs from the producer type set and all larger; outputs from th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:10699,power,powers,10699,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,1,['power'],['powers']
Energy Efficiency,"t(table, index);; return Obj;; }. ``__builtin_wasm_table_size``; -----------------------------. This builtin function returns the size of the WebAssembly table.; Takes the table as an argument and returns an unsigned integer (``size_t``); with the current table size. .. code-block:: c++. typedef void (*__funcref funcref_t)();; static __funcref table[0];. size_t getSize() {; return __builtin_wasm_table_size(table);; }. ``__builtin_wasm_table_grow``; -----------------------------. This builtin function grows the WebAssembly table by a certain amount.; Currently, as all WebAssembly tables created in C/C++ are zero-sized,; this always needs to be called to grow the table. It takes three arguments. The first argument is the WebAssembly table; to grow. The second argument is the reference typed value to store in; the new table entries (the initialization value), and the third argument; is the amount to grow the table by. It returns the previous table size; or -1. It will return -1 if not enough space could be allocated. .. code-block:: c++. typedef void (*__funcref funcref_t)();; static __funcref table[0];. // grow returns the new table size or -1 on error.; int grow(__funcref fn, int delta) {; int prevSize = __builtin_wasm_table_grow(table, fn, delta);; if (prevSize == -1); return -1;; return prevSize + delta;; }. ``__builtin_wasm_table_fill``; -----------------------------. This builtin function sets all the entries of a WebAssembly table to a given; reference typed value. It takes four arguments. The first argument is; the WebAssembly table, the second argument is the index that starts the; range, the third argument is the value to set in the new entries, and; the fourth and the last argument is the size of the range. It returns; nothing. .. code-block:: c++. static __externref_t table[0];. // resets a table by setting all of its entries to a given value.; void reset(__externref_t Obj) {; int Size = __builtin_wasm_table_size(table);; __builtin_wasm_table_fill(table, 0,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:94072,allocate,allocated,94072,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['allocate'],['allocated']
Energy Efficiency,"t);; ...; int x;; ...; foo(x);; in a language like C. Even in a Java like language, you need upcasts; and some way to implement dynamic downcasts.; + Not all forms of instructions take every type (for example you can't; shift by a floating point number of bits), thus SOME programs will need; implicit casts. To be efficient and to avoid your '-' point above, we just have to be; careful to specify that the instructions shall operate on all common; types, therefore casting should be relatively uncommon. For example all; of the arithmetic operations work on almost all data types. > Making the second arg. to 'shl' a ubyte seems good enough to me.; > 255 positions seems adequate for several generations of machines. Okay, that comment is removed. > and is more compact than uint. No, it isn't. Remember that the bytecode encoding saves value slots into; the bytecode instructions themselves, not constant values. This is; another case where we may introduce more cast instructions (but we will; also reduce the number of opcode variants that must be supported by a; virtual machine). Because most shifts are by constant values, I don't; think that we'll have to cast many shifts. :). > I still have some major concerns about including malloc and free in the; > language (either as builtin functions or instructions). Agreed. How about this proposal:. malloc/free are either built in functions or actual opcodes. They provide; all of the type safety that the document would indicate, blah blah; blah. :). Now, because of all of the excellent points that you raised, an; implementation may want to override the default malloc/free behavior of; the program. To do this, they simply implement a ""malloc"" and; ""free"" function. The virtual machine will then be defined to use the user; defined malloc/free function (which return/take void*'s, not type'd; pointers like the builtin function would) if one is available, otherwise; fall back on a system malloc/free. Does this sound like a good compromise? ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt:3739,reduce,reduce,3739,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,1,['reduce'],['reduce']
Energy Efficiency,"t->get(i) ;; - hist->set(hist->weight() / sum);; + hist->set(i, hist->weight(i) / sum, 0.);; }; ```; - More const correctness. `calcTreeIndex()` doesn't rely on side effects, any more. Instead of overwriting the internal; coordinates with new values:; ```; // In a RooDataHist subclass:; _vars = externalCoordinates;; auto index = calcTreeIndex();. // Or from the outside:; auto index = dataHist.getIndex(externalCoordinates); // Side effect: Active bin is now `index`.; ```; coordinates are now passed into calcTreeIndex without side effects:; ```; // In a subclass:; auto index = calcTreeIndex(externalCoordinates, fast=<true/false>); // No side effect. // From the outside:; auto index = dataHist.getIndex(externalCoordinates); // No side effect; ```; This will allow for marking more functions const, or for lying less about const correctness. - RooDataHist now supports fits with RooFit's faster `BatchMode()`.; - Lower memory footprint. If weight errors are not needed, RooDataHist now allocates only 40% of the memory that the old implementation used. #### Fix bin volume correction logic in `RooDataHist::sum()`. The public member function `RooDataHist::sum()` has three overloads.; Two of these overloads accept a `sumSet` parameter to not sum over all variables.; These two overloads previously behaved inconsistently when the `correctForBinSize` or `inverseBinCor` flags were set.; If you use the `RooDataHist::sum()` function in you own classes, please check that it can still be used with its new logic.; The new and corrected bin correction behaviour is:. - `correctForBinSize`: multiply counts in each bin by the bin volume corresponding to the variables in `sumSet`; - `inverseBinCor`: divide counts in each bin by the bin volume corresponding to the variables *not* in `sumSet`. ### New fully parametrised Crystal Ball shape class. So far, the Crystal Ball distribution has been represented in RooFit only by the `RooCBShape` class, which has a Gaussian core and a single power-law t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:23143,allocate,allocates,23143,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['allocate'],['allocates']
Energy Efficiency,"t. Arguments:; """""""""""""""""""". The first argument specifies the address of a stack object that contains; the root pointer. The second pointer (which must be either a constant or; a global value address) contains the meta-data to be associated with the; root. Semantics:; """""""""""""""""""". At runtime, a call to this intrinsic stores a null pointer into the; ""ptrloc"" location. At compile-time, the code generator generates; information to allow the runtime to find the pointer at GC safe points.; The '``llvm.gcroot``' intrinsic may only be used in a function which; :ref:`specifies a GC algorithm <gc>`. .. _int_gcread:. '``llvm.gcread``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.gcread(ptr %ObjPtr, ptr %Ptr). Overview:; """""""""""""""""". The '``llvm.gcread``' intrinsic identifies reads of references from heap; locations, allowing garbage collector implementations that require read; barriers. Arguments:; """""""""""""""""""". The second argument is the address to read from, which should be an; address allocated from the garbage collector. The first object is a; pointer to the start of the referenced object, if needed by the language; runtime (otherwise null). Semantics:; """""""""""""""""""". The '``llvm.gcread``' intrinsic has the same semantics as a load; instruction, but may be replaced with substantially more complex code by; the garbage collector runtime, as needed. The '``llvm.gcread``'; intrinsic may only be used in a function which :ref:`specifies a GC; algorithm <gc>`. .. _int_gcwrite:. '``llvm.gcwrite``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.gcwrite(ptr %P1, ptr %Obj, ptr %P2). Overview:; """""""""""""""""". The '``llvm.gcwrite``' intrinsic identifies writes of references to heap; locations, allowing garbage collector implementations that require write; barriers (such as generational or reference counting collectors). Arguments:; """""""""""""""""""". The first argument is the reference to store, the second is the start of; the object to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:498063,allocate,allocated,498063,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"t...). If you add `$URLTOSTAGE` and/or; `$TREENAME` in the *shell\_command*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; yo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4742,monitor,monitoring,4742,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,1,['monitor'],['monitoring']
Energy Efficiency,"t; r<<""u <- new(MyFunctor)"";. //printing status; r<<""print(u$getStatus())"";. //printing values from Functor and Function; r<<""print(sprintf('value in R = %f',u$doEval( 1 )))"";; std::cout<<""value in ROOT = ""<<TMath::BesselY1(1)<<std::endl;. ////////////////////////////////////////////////////////////; //creating a MyFunctor's object and passing object to R's //; //environment, the status should be true because is not //; //using the default function //; ////////////////////////////////////////////////////////////; MyFunctor functor;; functor.setFunction(TMath::Erf);; r[""functor""]<<functor;; //printing the status that should be true; r<<""print(functor$getStatus())"";; r<<""print(sprintf('value in R = %f',functor$doEval( 1 )))"";; std::cout<<""value in ROOT = ""<<TMath::Erf(1)<<std::endl;; }; ~~~. ## Simple fitting in R and plot in ROOT; The next example creates an exponential fit.; The idea is to create a set of numbers x,y with noise from ROOT,; pass them to R and fit the data to `x^3`,; get the fitted coefficient(power) and plot the data,; the known function and the fitted function using ROOT's classes. ~~~{.cxx}; #include<TRInterface.h>; #include<TRandom.h>. TCanvas *SimpleFitting(){; TCanvas *c1 = new TCanvas(""c1"",""Curve Fitting"",700,500);; c1->SetGrid();. // draw a frame to define the range; TMultiGraph *mg = new TMultiGraph();. // create the first graph (points with gaussian noise); const Int_t n = 24;; Double_t x1[n] ;; Double_t y1[n] ;; //Generate the points along a X^3 with noise; TRandom rg;; rg.SetSeed(520);; for (Int_t i = 0; i < n; i++) {; x1[i] = rg.Uniform(0, 1);; y1[i] = TMath::Power(x1[i], 3) + rg.Gaus() * 0.06;; }. TGraph *gr1 = new TGraph(n,x1,y1);; gr1->SetMarkerColor(kBlue);; gr1->SetMarkerStyle(8);; gr1->SetMarkerSize(1);; mg->Add(gr1);. // create the second graph; TF1 *f_known=new TF1(""f_known"",""pow(x,3)"",0,1);; TGraph *gr2 = new TGraph(f_known);; gr2->SetMarkerColor(kRed);; gr2->SetMarkerStyle(8);; gr2->SetMarkerSize(1);; mg->Add(gr2);; //passing dat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:14699,power,power,14699,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['power'],['power']
Energy Efficiency,"t_t natoms);; ```. or:. ``` {.cpp}; void AddElement(TGeoMaterial* mat, Double_t weight);; void AddElement(TGeoElement* elem, Double_t weight);; void AddElement(TGeoElement* elem, Int_t natoms);; void AddElement(Double_t a, Double_t z, Double_t weight); ```. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. ### Radionuclides. A new class **`TGeoElementRN`** was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (**`TGeoElementTable`** class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ``` {.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ```. One can make materials or mixtures from radionuclides:. ``` {.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""C14"", c14, 2.0);; ```. The following properties of radionuclides can be cur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:17432,energy,energy,17432,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['energy'],['energy']
Energy Efficiency,"ta; resides. *Target architecture specific DWARF address spaces may correspond to hardware; supported facilities such as memory utilizing base address registers, scratchpad; memory, and memory with special interleaving. The size of addresses in these; address spaces may vary. Their access and allocation may be hardware managed; with each thread or group of threads having access to independent storage. For; these reasons they may have properties that do not allow them to be viewed as; part of the unified global virtual address space accessible by all threads.*. *It is target architecture specific whether multiple DWARF address spaces are; supported and how source language memory spaces map to target architecture; specific DWARF address spaces. A target architecture may map multiple source; language memory spaces to the same target architecture specific DWARF address; class. Optimization may determine that variable lifetime and access pattern; allows them to be allocated in faster scratchpad memory represented by a; different DWARF address space than the default for the source language memory; space.*. Although DWARF address space identifiers are target architecture specific,; ``DW_ASPACE_LLVM_none`` is a common address space supported by all target; architectures, and defined as the target architecture default address space. DWARF address space identifiers are used by:. * The ``DW_AT_LLVM_address_space`` attribute. * The DWARF expression operations: ``DW_OP_aspace_bregx``,; ``DW_OP_form_aspace_address``, ``DW_OP_aspace_implicit_pointer``, and; ``DW_OP_xderef*``. * The CFI instructions: ``DW_CFA_def_aspace_cfa`` and; ``DW_CFA_def_aspace_cfa_sf``. .. note::. Currently, DWARF defines address class values as being target architecture; specific, and defines a DW_AT_address_class attribute. With the removal of; DW_AT_segment in DWARF 6, it is unclear how the address class is intended to; be used as the term is not used elsewhere. Should these be replaced by this; proposal'",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:149068,allocate,allocated,149068,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['allocate'],['allocated']
Energy Efficiency,taManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/l,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337979,reduce,reduce,337979,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"table entries, so that addresses taken outside the module will pass; any verification done inside the module. In more concrete terms, suppose we have three functions ``f``, ``g``,; ``h`` which are all of the same type, and a function foo that returns their; addresses:. .. code-block:: none. f:; mov 0, %eax; ret. g:; mov 1, %eax; ret. h:; mov 2, %eax; ret. foo:; mov f, %eax; mov g, %edx; mov h, %ecx; ret. Our jump table will (conceptually) look like this:. .. code-block:: none. f:; jmp .Ltmp0 ; 5 bytes; int3 ; 1 byte; int3 ; 1 byte; int3 ; 1 byte. g:; jmp .Ltmp1 ; 5 bytes; int3 ; 1 byte; int3 ; 1 byte; int3 ; 1 byte. h:; jmp .Ltmp2 ; 5 bytes; int3 ; 1 byte; int3 ; 1 byte; int3 ; 1 byte. .Ltmp0:; mov 0, %eax; ret. .Ltmp1:; mov 1, %eax; ret. .Ltmp2:; mov 2, %eax; ret. foo:; mov f, %eax; mov g, %edx; mov h, %ecx; ret. Because the addresses of ``f``, ``g``, ``h`` are evenly spaced at a power of; 2, and function types do not overlap (unlike class types with base classes),; we can normally apply the `Alignment`_ and `Eliminating Bit Vector Checks; for All-Ones Bit Vectors`_ optimizations thus simplifying the check at each; call site to a range and alignment check. Shared library support; ======================. **EXPERIMENTAL**. The basic CFI mode described above assumes that the application is a; monolithic binary; at least that all possible virtual/indirect call; targets and the entire class hierarchy are known at link time. The; cross-DSO mode, enabled with **-f[no-]sanitize-cfi-cross-dso** relaxes; this requirement by allowing virtual and indirect calls to cross the; DSO boundary. Assuming the following setup: the binary consists of several; instrumented and several uninstrumented DSOs. Some of them may be; dlopen-ed/dlclose-d periodically, even frequently. - Calls made from uninstrumented DSOs are not checked and just work.; - Calls inside any instrumented DSO are fully protected.; - Calls between different instrumented DSOs are also protected, with; a performance pen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:18329,power,power,18329,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['power'],['power']
Energy Efficiency,"table is constructed for the; equivalence class of functions instead of a single function. Cross-DSO calls; ---------------; Consider two instrumented DSOs, `A` and `B`. `A` defines `f()` and `B` calls it. This case will be handled similarly to the cross-DSO scheme using the slow path callback. Non-goals; ---------. RCFI does not protect `RET` instructions:; * in non-instrumented DSOs,; * in instrumented DSOs for functions that are called from non-instrumented DSOs,; * embedded into other instructions (e.g. `0f4fc3 cmovg %ebx,%eax`). .. _SafeStack: https://clang.llvm.org/docs/SafeStack.html; .. _RFG: https://xlab.tencent.com/en/2016/11/02/return-flow-guard; .. _Intel CET: https://software.intel.com/en-us/blogs/2016/06/09/intel-release-new-technology-specifications-protect-rop-attacks. Hardware support; ================. We believe that the above design can be efficiently implemented in hardware.; A single new instruction added to an ISA would allow to perform the forward-edge CFI check; with fewer bytes per check (smaller code size overhead) and potentially more; efficiently. The current software-only instrumentation requires at least; 32-bytes per check (on x86_64).; A hardware instruction may probably be less than ~ 12 bytes.; Such instruction would check that the argument pointer is in-bounds,; and is properly aligned, and if the checks fail it will either trap (in monolithic scheme); or call the slow path function (cross-DSO scheme).; The bit vector lookup is probably too complex for a hardware implementation. .. code-block:: none. // This instruction checks that 'Ptr'; // * is aligned by (1 << kAlignment) and; // * is inside [kRangeBeg, kRangeBeg+(kRangeSize<<kAlignment)); // and if the check fails it jumps to the given target (slow path).; //; // 'Ptr' is a register, pointing to the virtual function table; // or to the function which we need to check. We may require an explicit; // fixed register to be used.; // 'kAlignment' is a 4-bit constant.; // 'kRangeSiz",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:28086,efficient,efficiently,28086,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['efficient'],['efficiently']
Energy Efficiency,"tainer if you need efficient look-up of a; value based on another value. Map-like containers also support efficient; queries for containment (whether a key is in the map). Map-like containers; generally do not support efficient reverse mapping (values to keys). If you; need that, use two maps. Some map-like containers also support efficient; iteration through the keys in sorted order. Map-like containers are the most; expensive sort, only use them if you need one of these capabilities. * a :ref:`set-like <ds_set>` container if you need to put a bunch of stuff into; a container that automatically eliminates duplicates. Some set-like; containers support efficient iteration through the elements in sorted order.; Set-like containers are more expensive than sequential containers. * a :ref:`sequential <ds_sequential>` container provides the most efficient way; to add elements and keeps track of the order they are added to the collection.; They permit duplicates and support efficient iteration, but do not support; efficient look-up based on a key. * a :ref:`string <ds_string>` container is a specialized sequential container or; reference structure that is used for character or byte arrays. * a :ref:`bit <ds_bit>` container provides an efficient way to store and; perform set operations on sets of numeric id's, while automatically; eliminating duplicates. Bit containers require a maximum of 1 bit for each; identifier you want to store. Once the proper category of container is determined, you can fine tune the; memory use, constant factors, and cache behaviors of access by intelligently; picking a member of the category. Note that constant factors and cache behavior; can be a big deal. If you have a vector that usually only contains a few; elements (but could contain many), for example, it's much better to use; :ref:`SmallVector <dss_smallvector>` than :ref:`vector <dss_vector>`. Doing so; avoids (relatively) expensive malloc/free calls, which dwarf the cost of adding; the ele",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:56356,efficient,efficient,56356,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,2,['efficient'],['efficient']
Energy Efficiency,"taining the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umax.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_umin:. '``llvm.vp.reduce.umin.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umin``' intrinsic performs the unsigned-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.umin <int_vector_reduce_umin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:769193,reduce,reduce,769193,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"tantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Lua File System License; ------. ### Included only if built with Lua support. https://github.com/keplerproject/luafilesystem/blob/master/LICENSE. > Copyright Â© 2003-2020 Kepler Project.; >; > Permission is hereby granted, free of charge, to any person; > obtaining a copy of this software and associated documentation; > files (the ""Software""), to deal in the Software without; > restriction, including without limitation the rights to use, copy,; > modify, merge, publish, distribute, sublicense, and/or sell copies; > of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be; > included in all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,; > EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF; > MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND; > NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS; > BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN; > ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN; > CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE; > SOFTWARE. LuaXML License; ------. ### Included only if built with Lua and LuaXML support. Version 1.8.0 (Lua 5.2), 2013-06-10 by Gerald Franz, eludi.net. Modified and extended 2015 by Bernhard Nortmann, https://github.com/n1t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:4828,charge,charge,4828,net/http/civetweb/LICENSE.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md,1,['charge'],['charge']
Energy Efficiency,"tate2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14302,efficient,efficient,14302,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,2,['efficient'],['efficient']
Energy Efficiency,"tcasted pointer to a function defined in the current module. The code; generator cannot determine the frame allocation offset of functions defined in; other modules. The ``fp`` argument to '``llvm.localrecover``' must be a frame pointer of a; call frame that is currently live. The return value of '``llvm.localaddress``'; is one way to produce such a value, but various runtimes also expose a suitable; pointer in platform-specific ways. The ``idx`` argument to '``llvm.localrecover``' indicates which alloca passed to; '``llvm.localescape``' to recover. It is zero-indexed. Semantics:; """""""""""""""""""". These intrinsics allow a group of functions to share access to a set of local; stack allocations of a one parent function. The parent function may call the; '``llvm.localescape``' intrinsic once from the function entry block, and the; child functions can use '``llvm.localrecover``' to access the escaped allocas.; The '``llvm.localescape``' intrinsic blocks inlining, as inlining changes where; the escaped allocas are allocated, which would break attempts to use; '``llvm.localrecover``'. '``llvm.seh.try.begin``' and '``llvm.seh.try.end``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.seh.try.begin(); declare void @llvm.seh.try.end(). Overview:; """""""""""""""""". The '``llvm.seh.try.begin``' and '``llvm.seh.try.end``' intrinsics mark; the boundary of a _try region for Windows SEH Asynchrous Exception Handling. Semantics:; """""""""""""""""""". When a C-function is compiled with Windows SEH Asynchrous Exception option,; -feh_asynch (aka MSVC -EHa), these two intrinsics are injected to mark _try; boundary and to prevent potential exceptions from being moved across boundary.; Any set of operations can then be confined to the region by reading their leaf; inputs via volatile loads and writing their root outputs via volatile stores. '``llvm.seh.scope.begin``' and '``llvm.seh.scope.end``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:515085,allocate,allocated,515085,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"ted projects. > 2. Design issues to consider (an initial list that we should continue; > to modify). Note that I'm not trying to suggest actual solutions here,; > but just various directions we can pursue:. Understood. :). > a. A single-assignment VM, which we've both already been thinking; > about. Yup, I think that this makes a lot of sense. I am still intrigued,; however, by the prospect of a minimally allocated VM representation... I; think that it could have definite advantages for certain applications; (think very small machines, like PDAs). I don't, however, think that our; initial implementations should focus on this. :). Here are some other auxiliary goals that I think we should consider:. 1. Primary goal: Support a high performance dynamic compilation; system. This means that we have an ""ideal"" division of labor between; the runtime and static compilers. Of course, the other goals of the; system somewhat reduce the importance of this point (f.e. portability; reduces performance, but hopefully not much); 2. Portability to different processors. Since we are most familiar with; x86 and solaris, I think that these two are excellent candidates when; we get that far...; 3. Support for all languages & styles of programming (general purpose; VM). This is the point that disallows java style bytecodes, where all; array refs are checked for bounds, etc...; 4. Support linking between different language families. For example, call; C functions directly from Java without using the nasty/slow/gross JNI; layer. This involves several subpoints:; A. Support for languages that require garbage collectors and integration; with languages that don't. As a base point, we could insist on; always using a conservative GC, but implement free as a noop, f.e. > b. A strongly-typed VM. One question is do we need the types to be; > explicitly declared or should they be inferred by the dynamic; > compiler?. B. This is kind of similar to another idea that I have: make OOP; constructs (virt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:3464,reduce,reduces,3464,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['reduce'],['reduces']
Energy Efficiency,"teger overflow.; Note: partially handled by Clang core; (search for 'overflow in expression' warning in Clang tests).; Source: ; CWE-190. #include <limits.h>. int f(int x);. void test() {; f(INT_MAX + 1); // warn; }. #include <limits.h>. int test() {; int x = INT_MAX / 2 + 1;; return x * 2; // warn; }. different.SignExtension; (C); Unexpected sign extension might take place.; Source: ; CWE-194. unsigned long long test(long long sll) {; unsigned long long ull = sll; // warn; return ull;; }. void f(unsigned int i);. void test(int si) {; f(si); // warn; }. unsigned int test(int i) {; return i;; }. different.NumericTruncation; (C); Numeric truncation might take place.; Source: ; CWE-197. unsigned long test(unsigned long long ull) {; unsigned long ul = ull; // warn; return ul;; }. void f(int i);. void test(long long sll) {; f(sll); // warn; }. int f();. short test(long long sll) {; short ss = f();; return ss;; }. different.MissingCopyCtorAssignOp; (C++); A class has dynamically allocated data members but do not define a copy; constructor/assignment operator.; Source: Scott Meyers ""Effective C++"", item 11: Prevent exceptions from; leaving destructors. class C {; int *p; // warn; public:; C() { p = new int; }; ~C() { delete p; }; };. WinAPI. Name, DescriptionExampleProgress. WinAPI.CreateProcess; (C); CreateProcess(): if the first parameter ; lpApplicationName is NULL then the executable name must be in the; white space-delimited string pointed to by lpCommandLine.; If the executable or path name has a space in it, there is a risk that a; different executable could be run because of the way the function parses; spaces.; Source: ; MSDN: CreateProcess function, Security Remarks. #include <windows.h>. void test() {; STARTUPINFO si;; PROCESS_INFORMATION pi;; CreateProcess(NULL, TEXT(""C:\\Program Files\\App -L -S""),; NULL, NULL, TRUE, 0, NULL, NULL, &si, Ï€);; // warn; }. WinAPI.LoadLibrary; (C); The SearchPath() function is used to retrieve a path to a DLL for; a subsequent Load",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:25540,allocate,allocated,25540,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,2,['allocate'],['allocated']
Energy Efficiency,"tegrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside the module will pass any verification done inside the module. Jump tables may call external functions, so their definitions need not; be available at LTO time. Note that if an externally defined function is; associated with a type identifier, there is no guarantee that its identity; within the module will be the same as its identity outside of the module,; as the former will be the jump table entry if a jump table is necessary. The `GlobalLayoutBuilder`_ class is responsible for laying out the globals; efficiently to minimize the sizes of the underlying bitsets. .. _control flow integrity design document: https://clang.llvm.org/docs/ControlFlowIntegrityDesign.html. :Example:. ::. target datalayout = ""e-p:32:32"". @a = internal global i32 0, !type !0; @b = internal global i32 0, !type !0, !type !1; @c = internal global i32 0, !type !1; @d = internal global [2 x i32] [i32 0, i32 0], !type !2. define void @e() !type !3 {; ret void; }. define void @f() {; ret void; }. declare void @g() !type !3. !0 = !{i32 0, !""typeid1""}; !1 = !{i32 0, !""typeid2""}; !2 = !{i32 4, !""typeid2""}; !3 = !{i32 0, !""typeid3""}. declare i1 @llvm.type.test(i8* %ptr, metadata %typeid) nounwind readnone. define i1 @foo(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid1""); ret i1 %x; }. define i1 @bar(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid2""); ret i1 %x; }. define i1 @baz(void ()* %p) {; %pi8 = bitcast ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:6623,efficient,efficiently,6623,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst,1,['efficient'],['efficiently']
Energy Efficiency,"ten to; provide coverage for the standard requirements (clang/test/CXX and; clang/test/C). The standards coverage is not structured in a way; that makes it easy to maintain as the standards change over time. No commercial; conformance test suite has a license model suitable for open source projects,; so we would appreciate help in improving the existing coverage we have both in; terms of layout of the tests as well as in coverage of the various standard; modes.; Complete the investigation into Clang's C and C++ Defect Report; conformance: Separate from (but related to) general conformance testing is; determining which C defect reports and; C++ defect reports Clang implements. These; lists currently have a number of entries marked as Unknown.; Completing the investigation involves adding test coverage for; C; and; C++; defect reports and updating the documentation accordingly.; Bug triage: Clang's ; issue trackercurrently has over 20,000 open issues, many of which are not; appropriately tagged, are no longer reproducible, could use a reduced test case,; or otherwise needs some manual interaction. We can always use help with; bug triage and; issue tracker maintenance. Improve build times with Clang: the time it takes Clang to process a; translation unit is very important to our users; the lower the build time, the; better the overall user experience. It would be good to improve Clang's; performance as well as to find ways to proactively alert us when we've; introduced a change that has significant negative impact on build times.; Complete support for the experimental constant expression interpreter; : Clang's production constant expression interpreter computes a constant; expression result by walking over AST nodes, performing calculations as it; goes. This does not have good performance properties, and so we've begun work; on an ; experimental constant expression interpreter that works by converting the; AST into bytecode that is interpreted. This effort has a long t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/OpenProjects.html:2781,reduce,reduced,2781,interpreter/llvm-project/clang/www/OpenProjects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/OpenProjects.html,2,['reduce'],['reduced']
Energy Efficiency,ter.h; TMVA/GeneticGenes.h; TMVA/GeneticPopulation.h; TMVA/GeneticRange.h; TMVA/GiniIndex.h; TMVA/GiniIndexWithLaplace.h; TMVA/HyperParameterOptimisation.h; TMVA/IFitterTarget.h; TMVA/IMethod.h; TMVA/Interval.h; TMVA/IPruneTool.h; TMVA/KDEKernel.h; TMVA/LDA.h; TMVA/LogInterval.h; TMVA/LossFunction.h; TMVA/MCFitter.h; TMVA/MethodANNBase.h; TMVA/MethodBase.h; TMVA/MethodBayesClassifier.h; TMVA/MethodBDT.h; TMVA/MethodBoost.h; TMVA/MethodCategory.h; TMVA/MethodCFMlpANN_def.h; TMVA/MethodCFMlpANN.h; TMVA/MethodCFMlpANN_Utils.h; TMVA/MethodCompositeBase.h; TMVA/MethodCrossValidation.h; TMVA/MethodCuts.h; TMVA/MethodDL.h; TMVA/MethodDNN.h; TMVA/MethodDT.h; TMVA/MethodFDA.h; TMVA/MethodFisher.h; TMVA/MethodHMatrix.h; TMVA/MethodKNN.h; TMVA/MethodLD.h; TMVA/MethodLikelihood.h; TMVA/MethodMLP.h; TMVA/MethodPDEFoam.h; TMVA/MethodPDERS.h; TMVA/MethodRuleFit.h; TMVA/MethodSVM.h; TMVA/MethodTMlpANN.h; TMVA/MinuitFitter.h; TMVA/MinuitWrapper.h; TMVA/MisClassificationError.h; TMVA/ModulekNN.h; TMVA/Monitoring.h; TMVA/MsgLogger.h; TMVA/NeuralNet.h; TMVA/Node.h; TMVA/NodekNN.h; TMVA/OptimizeConfigParameters.h; TMVA/Option.h; TMVA/OptionMap.h; TMVA/Pattern.h; TMVA/PDEFoamCell.h; TMVA/PDEFoamDecisionTreeDensity.h; TMVA/PDEFoamDecisionTree.h; TMVA/PDEFoamDensityBase.h; TMVA/PDEFoamDiscriminantDensity.h; TMVA/PDEFoamDiscriminant.h; TMVA/PDEFoamEventDensity.h; TMVA/PDEFoamEvent.h; TMVA/PDEFoam.h; TMVA/PDEFoamKernelBase.h; TMVA/PDEFoamKernelGauss.h; TMVA/PDEFoamKernelLinN.h; TMVA/PDEFoamKernelTrivial.h; TMVA/PDEFoamMultiTarget.h; TMVA/PDEFoamTargetDensity.h; TMVA/PDEFoamTarget.h; TMVA/PDEFoamVect.h; TMVA/PDF.h; TMVA/QuickMVAProbEstimator.h; TMVA/Ranking.h; TMVA/Reader.h; TMVA/RegressionVariance.h; TMVA/ResultsClassification.h; TMVA/Results.h; TMVA/ResultsMulticlass.h; TMVA/ResultsRegression.h; TMVA/ROCCalc.h; TMVA/ROCCurve.h; TMVA/RootFinder.h; TMVA/RuleCut.h; TMVA/RuleEnsemble.h; TMVA/RuleFitAPI.h; TMVA/RuleFit.h; TMVA/RuleFitParams.h; TMVA/Rule.h; TMVA/SdivSqrtSplusB.h; TMVA/SeparationBa,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt:2405,Monitor,Monitoring,2405,tmva/tmva/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/CMakeLists.txt,1,['Monitor'],['Monitoring']
Energy Efficiency,"termining whether an attribute appertains to the subject. For; instance, a ``NonBitField`` SubsetSubject appertains to a ``FieldDecl``, and; tests whether the given FieldDecl is a bit field. When a SubsetSubject is; specified in a SubjectList, a custom diagnostic parameter must also be provided. Diagnostic checking for attribute subject lists for declaration and statement; attributes is automated except when ``HasCustomParsing`` is set to ``1``. Documentation; ~~~~~~~~~~~~~; All attributes must have some form of documentation associated with them.; Documentation is table generated on the public web server by a server-side; process that runs daily. Generally, the documentation for an attribute is a; stand-alone definition in `include/clang/Basic/AttrDocs.td; <https://github.com/llvm/llvm-project/blob/main/clang/include/clang/Basic/AttrDocs.td>`_; that is named after the attribute being documented. If the attribute is not for public consumption, or is an implicitly-created; attribute that has no visible spelling, the documentation list can specify the; ``InternalOnly`` object. Otherwise, the attribute should have its documentation; added to AttrDocs.td. Documentation derives from the ``Documentation`` tablegen type. All derived; types must specify a documentation category and the actual documentation itself.; Additionally, it can specify a custom heading for the attribute, though a; default heading will be chosen when possible. There are four predefined documentation categories: ``DocCatFunction`` for; attributes that appertain to function-like subjects, ``DocCatVariable`` for; attributes that appertain to variable-like subjects, ``DocCatType`` for type; attributes, and ``DocCatStmt`` for statement attributes. A custom documentation; category should be used for groups of attributes with similar functionality.; Custom categories are good for providing overview information for the attributes; grouped under it. For instance, the consumed annotation attributes define a; c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:134672,consumption,consumption,134672,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['consumption'],['consumption']
Energy Efficiency,"ternal; representation that can be generated into anything you want. Current usage of TableGen is to create huge include files with tables that you; can either include directly (if the output is in the language you're coding),; or be used in pre-processing via macros surrounding the include of the file. Direct output can be used if the backend already prints a table in C format; or if the output is just a list of strings (for error and warning messages).; Pre-processed output should be used if the same information needs to be used; in different contexts (like Instruction names), so your backend should print; a meta-information list that can be shaped into different compile-time formats. See :doc:`TableGen BackEnds <./BackEnds>` for a list of available; backends, and see the :doc:`TableGen Backend Developer's Guide <./BackGuide>`; for information on how to write and debug a new backend. Tools and Resources; ===================. In addition to this documentation, a list of tools and resources for TableGen; can be found in TableGen's; `README <https://github.com/llvm/llvm-project/blob/main/llvm/utils/TableGen/README.md>`_. TableGen Deficiencies; =====================. Despite being very generic, TableGen has some deficiencies that have been; pointed out numerous times. The common theme is that, while TableGen allows; you to build domain specific languages, the final languages that you create; lack the power of other DSLs, which in turn increase considerably the size; and complexity of TableGen files. At the same time, TableGen allows you to create virtually any meaning of; the basic concepts via custom-made backends, which can pervert the original; design and make it very hard for newcomers to understand the evil TableGen; file. There are some in favor of extending the semantics even more, but making sure; backends adhere to strict rules. Others are suggesting we should move to less,; more powerful DSLs designed with specific purposes, or even reusing existing; DSLs.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/index.rst:12255,power,power,12255,interpreter/llvm-project/llvm/docs/TableGen/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/index.rst,2,['power'],"['power', 'powerful']"
Energy Efficiency,"ters. The main design goals for the; PROOF system are:. *Transparency* : there should be as little difference as possible; between a local ROOT based analysis session and a remote parallel PROOF; session, both being interactive and giving the same results. *Scalability* : the basic architecture should not put any implicit; limitations on the number of computers that can be used in parallel. *Adaptability* : the system should be able to adapt itself to variations; in the remote environment (changing load on the cluster nodes, network; interruptions, etc.). Being an extension of the ROOT system, PROOF is designed to work on; objects in ROOT data stores, though, for the time being, it mainly; addresses the case of **`TTree`** based object collections. PROOF is primarily meant as an interactive alternative to batch systems; for Central Analysis Facilities and departmental workgroups (Tier-2's).; However, thanks to a multi-tier architecture allowing multiple levels of; masters, it can be easily adapted to wide range virtual clusters; distributed over geographically separated domains and heterogeneous; machines (GRIDs). While pure interactivity might not always be possible when performing a; complicated analysis on a very large data set, PROOF still tries to give; the user the interactive experience with something we call ""interactive; batch"". With ""interactive batch"" the user can start very long running; queries, disconnect the client and at any time, any location and from; any computer reconnect to the query to monitor its progress or retrieve; the results. This feature gives it a distinct advantage over purely; batch based solutions, that only provide an answer once all sub-jobs; have been finished. ![The Multi-tier structure of a PROOF cluster](pictures/03000200.png). Details about the PROOF system and the way to use it can be found at; <PROOFWiki> [^1]. The PROOF development is a joint effort between CERN and MIT. [^1]: http://root.cern.ch/twiki/bin/view/ROOT/PROOF; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PROOF.md:1257,adapt,adapted,1257,documentation/users-guide/PROOF.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PROOF.md,2,"['adapt', 'monitor']","['adapted', 'monitor']"
Energy Efficiency,"ters; per element in the set (thus adding a large amount of per-element space; overhead). It offers guaranteed log(n) performance, which is not particularly; fast from a complexity standpoint (particularly if the elements of the set are; expensive to compare, like strings), and has extremely high constant factors for; lookup, insertion and removal. The advantages of std::set are that its iterators are stable (deleting or; inserting an element from the set does not affect iterators or pointers to other; elements) and that iteration over the set is guaranteed to be in sorted order.; If the elements in the set are large, then the relative overhead of the pointers; and malloc traffic is not a big deal, but if the elements of the set are small,; std::set is almost never a good choice. .. _dss_setvector:. llvm/ADT/SetVector.h; ^^^^^^^^^^^^^^^^^^^^. LLVM's ``SetVector<Type>`` is an adapter class that combines your choice of a; set-like container along with a :ref:`Sequential Container <ds_sequential>` The; important property that this provides is efficient insertion with uniquing; (duplicate elements are ignored) with iteration support. It implements this by; inserting elements into both a set-like container and the sequential container,; using the set-like container for uniquing and the sequential container for; iteration. The difference between SetVector and other sets is that the order of iteration; is guaranteed to match the order of insertion into the SetVector. This property; is really important for things like sets of pointers. Because pointer values; are non-deterministic (e.g. vary across runs of the program on different; machines), iterating over the pointers in the set will not be in a well-defined; order. The drawback of SetVector is that it requires twice as much space as a normal; set and has the sum of constant factors from the set-like container and the; sequential container that it uses. Use it **only** if you need to iterate over; the elements in a determi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:84329,adapt,adapter,84329,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,2,"['adapt', 'efficient']","['adapter', 'efficient']"
Energy Efficiency,tes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338475,reduce,reduce,338475,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"th operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umin``' intrinsic performs the unsigned-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.umin <int_vector_reduce_umin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umin.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umin.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_fmax:. '``llvm.vp.reduce.fmax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmax.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmax.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:770881,reduce,reduce,770881,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"th this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5153,efficient,efficient,5153,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst,1,['efficient'],['efficient']
Energy Efficiency,"that information used to optimize the program. If the condition is violated; during execution, the behavior is undefined. The argument itself is never; evaluated, so any side effects of the expression will be discarded. Query for this feature with ``__has_builtin(__builtin_assume)``. .. _langext-__builtin_assume_separate_storage:. ``__builtin_assume_separate_storage``; -------------------------------------. ``__builtin_assume_separate_storage`` is used to provide the optimizer with the; knowledge that its two arguments point to separately allocated objects. **Syntax**:. .. code-block:: c++. __builtin_assume_separate_storage(const volatile void *, const volatile void *). **Example of Use**:. .. code-block:: c++. int foo(int *x, int *y) {; __builtin_assume_separate_storage(x, y);; *x = 0;; *y = 1;; // The optimizer may optimize this to return 0 without reloading from *x.; return *x;; }. **Description**:. The arguments to this function are assumed to point into separately allocated; storage (either different variable definitions or different dynamic storage; allocations). The optimizer may use this fact to aid in alias analysis. If the; arguments point into the same storage, the behavior is undefined. Note that the; definition of ""storage"" here refers to the outermost enclosing allocation of any; particular object (so for example, it's never correct to call this function; passing the addresses of fields in the same struct, elements of the same array,; etc.). Query for this feature with ``__has_builtin(__builtin_assume_separate_storage)``. ``__builtin_offsetof``; ----------------------. ``__builtin_offsetof`` is used to implement the ``offsetof`` macro, which; calculates the offset (in bytes) to a given member of the given type. **Syntax**:. .. code-block:: c++. __builtin_offsetof(type-name, member-designator). **Example of Use**:. .. code-block:: c++. struct S {; char c;; int i;; struct T {; float f[2];; } t;; };. const int offset_to_i = __builtin_offsetof(struct S, i)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:100218,allocate,allocated,100218,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['allocate'],['allocated']
Energy Efficiency,"that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6372,efficient,efficient,6372,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,1,['efficient'],['efficient']
Energy Efficiency,"that you depend on it. Note that mem2reg only works on; variables in certain circumstances:. #. mem2reg is alloca-driven: it looks for allocas and if it can handle; them, it promotes them. It does not apply to global variables or heap; allocations.; #. mem2reg only looks for alloca instructions in the entry block of the; function. Being in the entry block guarantees that the alloca is only; executed once, which makes analysis simpler.; #. mem2reg only promotes allocas whose uses are direct loads and stores.; If the address of the stack object is passed to a function, or if any; funny pointer arithmetic is involved, the alloca will not be; promoted.; #. mem2reg only works on allocas of `first; class <../../LangRef.html#first-class-types>`_ values (such as pointers,; scalars and vectors), and only if the array size of the allocation is; 1 (or missing in the .ll file). mem2reg is not capable of promoting; structs or arrays to registers. Note that the ""sroa"" pass is; more powerful and can promote structs, ""unions"", and arrays in many; cases. All of these properties are easy to satisfy for most imperative; languages, and we'll illustrate it below with Kaleidoscope. The final; question you may be asking is: should I bother with this nonsense for my; front-end? Wouldn't it be better if I just did SSA construction; directly, avoiding use of the mem2reg optimization pass? In short, we; strongly recommend that you use this technique for building SSA form,; unless there is an extremely good reason not to. Using this technique; is:. - Proven and well tested: clang uses this technique; for local mutable variables. As such, the most common clients of LLVM; are using this to handle a bulk of their variables. You can be sure; that bugs are found fast and fixed early.; - Extremely Fast: mem2reg has a number of special cases that make it; fast in common cases as well as fully general. For example, it has; fast-paths for variables that are only used in a single block,; variables that ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:8644,power,powerful,8644,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['power'],['powerful']
Energy Efficiency,"the floating-point ``MUL``; reduction (:ref:`llvm.vector.reduce.fmul <int_vector_reduce_fmul>`) of the; vector operand ``val`` on each enabled lane, multiplying it by the scalar; `start_value``. Disabled lanes are treated as containing the neutral value; ``1.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to the starting value. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fmul; <int_vector_reduce_fmul>`) for more detail on the semantics. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmul.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float 1.0, float 1.0, float 1.0, float 1.0>; %also.r = call float @llvm.vector.reduce.fmul.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_and:. '``llvm.vp.reduce.and.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.and.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:756583,reduce,reduce,756583,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"the following code; (from http://gcc.gnu.org/bugzilla/show_bug.cgi?id=34653):; extern unsigned long table[];; unsigned long foo(unsigned char *p) {; unsigned long tag = *p;; return table[tag >> 4] + table[tag & 0xf];; }. Current code generated:; 	movzbl	(%rdi), %eax; 	movq	%rax, %rcx; 	andq	$240, %rcx; 	shrq	%rcx; 	andq	$15, %rax; 	movq	table(,%rax,8), %rax; 	addq	table(%rcx), %rax; 	ret. Issues:; 1. First movq should be movl; saves a byte.; 2. Both andq's should be andl; saves another two bytes. I think this was; implemented at one point, but subsequently regressed.; 3. shrq should be shrl; saves another byte.; 4. The first andq can be completely eliminated by using a slightly more; expensive addressing mode. //===---------------------------------------------------------------------===//. Consider the following (contrived testcase, but contains common factors):. #include <stdarg.h>; int test(int x, ...) {; int sum, i;; va_list l;; va_start(l, x);; for (i = 0; i < x; i++); sum += va_arg(l, int);; va_end(l);; return sum;; }. Testcase given in C because fixing it will likely involve changing the IR; generated for it. The primary issue with the result is that it doesn't do any; of the optimizations which are possible if we know the address of a va_list; in the current function is never taken:; 1. We shouldn't spill the XMM registers because we only call va_arg with ""int"".; 2. It would be nice if we could sroa the va_list.; 3. Probably overkill, but it'd be cool if we could peel off the first five; iterations of the loop. Other optimizations involving functions which use va_arg on floats which don't; have the address of a va_list taken:; 1. Conversely to the above, we shouldn't spill general registers if we only; call va_arg on ""double"".; 2. If we know nothing more than 64 bits wide is read from the XMM registers,; we can change the spilling code to reduce the amount of stack used by half. //===---------------------------------------------------------------------===//; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt:5988,reduce,reduce,5988,interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt,2,['reduce'],['reduce']
Energy Efficiency,"the future, we will extend pattern fragments to allow them to define multiple; values (e.g. the four operands of the `X86 addressing mode`_, which are; currently matched with custom C++ code). In addition, we'll extend fragments; so that a fragment can match multiple different patterns. * We don't automatically infer flags like ``isStore``/``isLoad`` yet. * We don't automatically generate the set of supported registers and operations; for the `Legalizer`_ yet. * We don't have a way of tying in custom legalized nodes yet. Despite these limitations, the instruction selector generator is still quite; useful for most of the binary and logical operations in typical instruction; sets. If you run into any problems or can't figure out how to do something,; please let Chris know!. .. _Scheduling and Formation:; .. _SelectionDAG Scheduling and Formation:. SelectionDAG Scheduling and Formation Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The scheduling phase takes the DAG of target instructions from the selection; phase and assigns an order. The scheduler can pick an order depending on; various constraints of the machines (i.e. order for minimal register pressure or; try to cover instruction latencies). Once an order is established, the DAG is; converted to a list of :raw-html:`<tt>` `MachineInstr`_\s :raw-html:`</tt>` and; the SelectionDAG is destroyed. Note that this phase is logically separate from the instruction selection phase,; but is tied to it closely in the code because it operates on SelectionDAGs. Future directions for the SelectionDAG; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Optional function-at-a-time selection. #. Auto-generate entire selector from ``.td`` file. .. _SSA-based Machine Code Optimizations:. SSA-based Machine Code Optimizations; ------------------------------------. To Be Written. Live Intervals; --------------. Live Intervals are the ranges (intervals) where a variable is *live*. They are; used by some `register allocator`_ passes to dete",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:53555,schedul,scheduling,53555,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['schedul'],['scheduling']
Energy Efficiency,"the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:1907,schedul,schedule,1907,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst,1,['schedul'],['schedule']
Energy Efficiency,"the model is generated with `batchsize=1`.; The Keras parser supports now in addition to the Dense layer the Conv2D layer, several activation functions (Relu, Selu, Sigmoid, Softmax, Tanh, LeakyRelu) and these other layers: BatchNormalization, Reshape, Convatenate, Add, Subtract, Multiply.; Models with Dropout layers are supported in case the Dropout is used only during training and not inference. For model having operators not yet supported in the Keras parser it is then reccomended to convert the Keras model to `ONNX` using the python `tf2onnx` tool. #### SOFIE PyTorch Parser. If using PyTorch it is recommended to save the model directly in `ONNX` format instad of the native `.pt` format by using the `torch.onnx.export` function of PyTorch. The support for parsing directly `.pt` files is limited to the Gemm, Conv, Relu, Selu, Sigmoid and Transpose operators. #### SOFIE RDataFrame Integration. The SOFIE inference is now integrated with RDataFrame, where a model can be evaluated on the columns of an input `TTree` with `RDataFrame` using the adapter functor class `SofieFunctor`.; Examples of using SOFIE with `RDataFrame` are the new tutorials (in the `tutorials/tmva` directory) `TMVA_SOFIE_RDataFrame.C` or `TMVA_SOFIE_RDataFrame.py`. `TMVA_SOFIE_RDataFrame_JIT.C` is an example where the SOFIE model is generated and compiled at runtime using ROOT Cling and evaluated using RDataFrame. #### RSofieReader. `RSofieReader` is a new class, which takes as input a model file (in ONNX, Keras, PyTorch or ROOT format) and generates and compiles the C++ code for the inference at run time using the ROOT JITing capabilities of CLING. An example of using this class is the tutorial `TMVA_SOFIE_RSofieReader.C`. ### TMVA Pythonizations. New Pythonizations are available for TMVA allowing to replace the option string passed to several `TMVA` functions such as the `TMVA::Factory` constructor, the `DataLoader::PrepareTrainingAndTestTree` and `Factory::BookMethod` using Python function argume",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:29311,adapt,adapter,29311,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['adapt'],['adapter']
Energy Efficiency,"the movb+andb+movzbl sequence. //===---------------------------------------------------------------------===//. For the following:; struct u1 {; float x, y;; };; float foo(struct u1 u) {; return u.x + u.y;; }. We currently generate:; 	movdqa	%xmm0, %xmm1; 	pshufd	$1, %xmm0, %xmm0 # xmm0 = xmm0[1,0,0,0]; 	addss	%xmm1, %xmm0; 	ret. We could save an instruction here by commuting the addss. //===---------------------------------------------------------------------===//. This (from PR9661):. float clamp_float(float a) {; if (a > 1.0f); return 1.0f;; else if (a < 0.0f); return 0.0f;; else; return a;; }. Could compile to:. clamp_float: # @clamp_float; movss .LCPI0_0(%rip), %xmm1; minss %xmm1, %xmm0; pxor %xmm1, %xmm1; maxss %xmm1, %xmm0; ret. with -ffast-math. //===---------------------------------------------------------------------===//. This function (from PR9803):. int clamp2(int a) {; if (a > 5); a = 5;; if (a < 0) ; return 0;; return a;; }. Compiles to:. _clamp2: ## @clamp2; pushq %rbp; movq %rsp, %rbp; cmpl $5, %edi; movl $5, %ecx; cmovlel %edi, %ecx; testl %ecx, %ecx; movl $0, %eax; cmovnsl %ecx, %eax; popq %rbp; ret. The move of 0 could be scheduled above the test to make it is xor reg,reg. //===---------------------------------------------------------------------===//. GCC PR48986. We currently compile this:. void bar(void);; void yyy(int* p) {; if (__sync_fetch_and_add(p, -1) == 1); bar();; }. into:; 	movl	$-1, %eax; 	lock; 	xaddl	%eax, (%rdi); 	cmpl	$1, %eax; 	je	LBB0_2. Instead we could generate:. 	lock; 	dec %rdi; 	je LBB0_2. The trick is to match ""fetch_and_add(X, -C) == C"". //===---------------------------------------------------------------------===//. unsigned t(unsigned a, unsigned b) {; return a <= b ? 5 : -5;; }. We generate:; 	movl	$5, %ecx; 	cmpl	%esi, %edi; 	movl	$-5, %eax; 	cmovbel	%ecx, %eax. GCC:; 	cmpl	%edi, %esi; 	sbbl	%eax, %eax; 	andl	$-10, %eax; 	addl	$5, %eax. //===---------------------------------------------------------------------===//; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:42526,schedul,scheduled,42526,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['schedul'],['scheduled']
Energy Efficiency,"the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.add``' intrinsic performs the integer ``ADD`` reduction; (:ref:`llvm.vector.reduce.add <int_vector_reduce_add>`) of the vector operand; ``val`` on each enabled lane, adding it to the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``0`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is equal; to ``start_value``. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.add.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> zeroinitializer; %reduction = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %masked.a); %also.r = add i32 %reduction, %start. .. _int_vp_reduce_fadd:. '``llvm.vp.reduce.fadd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fadd.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fadd.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``ADD`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:749838,reduce,reduce,749838,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Ord",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42912,schedul,scheduled,42912,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduled']
Energy Efficiency,"the value into a vector register, and then; remove the (dead) stores to the stack. //===----------------------------------------------------------------------===//. At the moment we always generate a lxsdx in preference to lfd, or stxsdx in; preference to stfd. When we have a reg-immediate addressing mode, this is a; poor choice, since we have to load the address into an index register. This; should be fixed for P7/P8. . //===----------------------------------------------------------------------===//. Right now, ShuffleKind 0 is supported only on BE, and ShuffleKind 2 only on LE.; However, we could actually support both kinds on either endianness, if we check; for the appropriate shufflevector pattern for each case ... this would cause; some additional shufflevectors to be recognized and implemented via the; ""swapped"" form. //===----------------------------------------------------------------------===//. There is a utility program called PerfectShuffle that generates a table of the; shortest instruction sequence for implementing a shufflevector operation on; PowerPC. However, this was designed for big-endian code generation. We could; modify this program to create a little endian version of the table. The table; is used in PPCISelLowering.cpp, PPCTargetLowering::LOWERVECTOR_SHUFFLE(). //===----------------------------------------------------------------------===//. Opportunies to use instructions from PPCInstrVSX.td during code gen; - Conversion instructions (Sections 7.6.1.5 and 7.6.1.6 of ISA 2.07); - Scalar comparisons (xscmpodp and xscmpudp); - Min and max (xsmaxdp, xsmindp, xvmaxdp, xvmindp, xvmaxsp, xvminsp). Related to this: we currently do not generate the lxvw4x instruction for either; v4f32 or v4i32, probably because adding a dag pattern to the recognizer requires; a single target type. This should probably be addressed in the PPCISelDAGToDAG logic. //===----------------------------------------------------------------------===//. Currently EXTRACT_VECTOR_E",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt:9179,Power,PowerPC,9179,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,1,['Power'],['PowerPC']
Energy Efficiency,"the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.xor``' intrinsic performs the integer ``XOR`` reduction; (:ref:`llvm.vector.reduce.xor <int_vector_reduce_xor>`) of the vector operand; ``val`` on each enabled lane, performing an '``xor``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %masked.a); %also.r = xor i32 %reduction, %start. .. _int_vp_reduce_smax:. '``llvm.vp.reduce.smax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:762627,reduce,reduce,762627,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"therwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fadd operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fadd(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, negative zero (``-0.0``) can be used, as it is; the neutral value of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.mul.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.mul.*``' intrinsics do an integer ``MUL``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:652574,reduce,reduce,652574,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"this ""C"" example, the front end compiler (Clang) will generate three GEP; instructions for the three indices through ""P"" in the assignment statement. The; function argument ``P`` will be the second operand of each of these GEP; instructions. The third operand indexes through that pointer. The fourth; operand will be the field offset into the ``struct munger_struct`` type, for; either the ``f1`` or ``f2`` field. So, in LLVM assembly the ``munge`` function; looks like:. .. code-block:: llvm. define void @munge(ptr %P) {; entry:; %tmp = getelementptr %struct.munger_struct, ptr %P, i32 1, i32 0; %tmp1 = load i32, ptr %tmp; %tmp2 = getelementptr %struct.munger_struct, ptr %P, i32 2, i32 1; %tmp3 = load i32, ptr %tmp2; %tmp4 = add i32 %tmp3, %tmp1; %tmp5 = getelementptr %struct.munger_struct, ptr %P, i32 0, i32 0; store i32 %tmp4, ptr %tmp5; ret void; }. In each case the second operand is the pointer through which the GEP instruction; starts. The same is true whether the second operand is an argument, allocated; memory, or a global variable. To make this clear, let's consider a more obtuse example:. .. code-block:: text. @MyVar = external global i32; ...; %idx1 = getelementptr i32, ptr @MyVar, i64 0; %idx2 = getelementptr i32, ptr @MyVar, i64 1; %idx3 = getelementptr i32, ptr @MyVar, i64 2. These GEP instructions are simply making address computations from the base; address of ``MyVar``. They compute, as follows (using C syntax):. .. code-block:: c++. idx1 = (char*) &MyVar + 0; idx2 = (char*) &MyVar + 4; idx3 = (char*) &MyVar + 8. Since the type ``i32`` is known to be four bytes long, the indices 0, 1 and 2; translate into memory offsets of 0, 4, and 8, respectively. No memory is; accessed to make these computations because the address of ``@MyVar`` is passed; directly to the GEP instructions. The obtuse part of this example is in the cases of ``%idx2`` and ``%idx3``. They; result in the computation of addresses that point to memory past the end of the; ``@MyVar`` global, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:3652,allocate,allocated,3652,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['allocate'],['allocated']
Energy Efficiency,"tifiedNamespaces.end();; });; LVStringRefs::size_type FirstNonNamespace = std::distance(Components.begin(), Iter);. //===----------------------------------------------------------------------===//; // Move all the printing support to a common module.; //===----------------------------------------------------------------------===//; Factor out printing functionality from the logical elements into a; common module. //===----------------------------------------------------------------------===//; // Refactor 'LVBinaryReader::processLines'.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125783#inline-1246155; https://reviews.llvm.org/D137156. During the traversal of the debug information sections, we created the; logical lines representing the disassembled instructions from the text; section and the logical lines representing the line records from the; debug line section. Using the ranges associated with the logical scopes,; we will allocate those logical lines to their logical scopes. Consider the case when any of those lines become orphans, causing; incorrect scope parent for disassembly or line records. //===----------------------------------------------------------------------===//; // Add support for '-ffunction-sections'.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125783#inline-1295012. Only linked executables are handled. It does not support relocatable; files compiled with -ffunction-sections. //===----------------------------------------------------------------------===//; // Add support for DWARF v5 .debug_names section.; // Add support for CodeView public symbols stream.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125783#inline-1294142. The ELF and CodeView readers use the public names information to create; the instructions (LVLineAssembler). Instead of relying on DWAR",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt:8128,allocate,allocate,8128,interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,2,['allocate'],['allocate']
Energy Efficiency,til/PrettyEnumDumper.cpp; llvm/tools/llvm-pdbutil/PrettyExternalSymbolDumper.cpp; llvm/tools/llvm-pdbutil/PrettyTypeDumper.cpp; llvm/tools/llvm-pdbutil/TypeReferenceTracker.h; llvm/tools/llvm-pdbutil/YAMLOutputStyle.h; llvm/tools/llvm-profgen/CallContext.h; llvm/tools/llvm-profgen/CSPreInliner.cpp; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVa,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337058,reduce,reduce,337058,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"ting point multiplication. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fmul.v4f32(float 1.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_and:. '``llvm.vector.reduce.and.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:655669,reduce,reduce,655669,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ting within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like to add a CustomBehaviour class for a target that doesn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :program:`llvm-mca` comes with several Views such as the Timeline View and; Summary View. These Views are generic and can work with most (if not all); targets. If you wish to add a new View to :program:`llvm-mca` and it does not; require any backend functionality that is not ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:46059,schedul,scheduling,46059,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,"tinguishing version number. If the Program; specifies a version number of this License which applies to it and ""any; later version"", you have the option of following the terms and conditions; either of that version or of any later version published by the Free; Software Foundation. If the Program does not specify a version number of; this License, you may choose any version ever published by the Free Software; Foundation. 10. If you wish to incorporate parts of the Program into other free; programs whose distribution conditions are different, write to the author; to ask for permission. For software which is copyrighted by the Free; Software Foundation, write to the Free Software Foundation; we sometimes; make exceptions for this. Our decision will be guided by the two goals; of preserving the free status of all derivatives of our free software and; of promoting the sharing and reuse of software generally. NO WARRANTY. 11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY; FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN; OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES; PROVIDE THE PROGRAM ""AS IS"" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED; OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF; MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS; TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE; PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,; REPAIR OR CORRECTION. 12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING; WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR; REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,; INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING; OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED; TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY; YOU OR THIRD PAR",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt:13823,CHARGE,CHARGE,13823,misc/rootql/LICENSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/rootql/LICENSE.txt,2,['CHARGE'],['CHARGE']
Energy Efficiency,"tion multiversioning, regcall/vectorcall.; I: ErichKeane. N: Eric Kidd; W: http://randomhacks.net/; D: llvm-config script. N: Anton Korobeynikov; E: anton at korobeynikov dot info; D: Mingw32 fixes, cross-compiling support, stdcall/fastcall calling conv.; D: x86/linux PIC codegen, aliases, regparm/visibility attributes; D: Switch lowering refactoring. N: Sumant Kowshik; E: kowshik@uiuc.edu; D: Author of the original C backend. N: Benjamin Kramer; E: benny.kra@gmail.com; D: Miscellaneous bug fixes. N: Michael Kuperstein; E: mkuper@google.com; D: Loop Vectorizer. N: Sundeep Kushwaha; E: sundeepk@codeaurora.org; D: Implemented DFA-based target independent VLIW packetizer. N: Christopher Lamb; E: christopher.lamb@gmail.com; D: aligned load/store support, parts of noalias and restrict support; D: vreg subreg infrastructure, X86 codegen improvements based on subregs; D: address spaces. N: Jim Laskey; E: jlaskey@apple.com; D: Improvements to the PPC backend, instruction scheduling; D: Debug and Dwarf implementation; D: Auto upgrade mangler; D: llvm-gcc4 svn wrangler. N: Chris Lattner; E: sabre@nondot.org; W: http://nondot.org/~sabre/; D: Primary architect of LLVM. N: Tanya Lattner (Tanya Brethour); E: tonic@nondot.org; W: http://nondot.org/~tonic/; D: The initial llvm-ar tool, converted regression testsuite to dejagnu; D: Modulo scheduling in the SparcV9 backend; D: Release manager (1.7+). N: Sylvestre Ledru; E: sylvestre@debian.org; W: http://sylvestre.ledru.info/; W: https://apt.llvm.org/; D: Debian and Ubuntu packaging; D: Continuous integration with jenkins. N: Andrew Lenharth; E: alenhar2@cs.uiuc.edu; W: http://www.lenharth.org/~andrewl/; D: Alpha backend; D: Sampling based profiling. N: Nick Lewycky; E: nicholas@mxc.ca; D: PredicateSimplifier pass. N: Tony Linthicum, et. al.; E: tlinth@codeaurora.org; D: Backend for Qualcomm's Hexagon VLIW processor. N: Bruno Cardoso Lopes; E: bruno.cardoso@gmail.com; I: bruno; W: http://brunocardoso.cc; D: Mips backend; D: Random ARM",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT:7157,schedul,scheduling,7157,interpreter/llvm-project/llvm/CREDITS.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT,1,['schedul'],['scheduling']
Energy Efficiency,"tion(0.2,0,0));; chamber->AddNode(wire_co,2,new TGeoTranslation(0.2,0,0));; ```. The 2 nodes that we have created inside chamber will both point to a; `wire_co` object, but will be completely distinct: `WIRE_CO_1` and; `WIRE_CO_2`. We will want now to place symmetrically 1000 chambers on a; pad, following a pattern of 20 rows and 50 columns. One way to do this; will be to replicate our chamber by positioning it 1000 times in; different positions of the pad. Unfortunately, this is far from being; the optimal way of doing what we want. Imagine that we would like to; find out which of the 1000 chambers is containing a `(x,y,z)` point; defined in the pad reference. You will never have to do that, since the; modeller will take care of it for you, but let's guess what it has to; do. The most simple algorithm will just loop over all daughters, convert; the point from mother to local reference and check if the current; chamber contains the point or not. This might be efficient for pads with; few chambers, but definitely not for 1000. Fortunately the modeller is; smarter than that and creates for each volume some optimization; structures called `voxels` to minimize the penalty having too many; daughters, but if you have 100 pads like this in your geometry you will; anyway lose a lot in your tracking performance. The way out when; volumes can be arranged according to simple patterns is the usage of; divisions. We will describe them in detail later on. Let's think now at; a different situation: instead of 1000 chambers of the same type, we may; have several types of chambers. Let's say all chambers are cylindrical; and have a wire inside, but their dimensions are different. However, we; would like all to be represented by a single volume family, since they; have the same properties. #### Volume Families. A volume family is represented by the class **`TGeoVolumeMulti`**. It; represents a class of volumes having the same shape type and each member; will be identified by the same",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:80266,efficient,efficient,80266,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['efficient'],['efficient']
Energy Efficiency,"tion(0.2,0,0));; chamber->AddNode(wire_co,2,new TGeoTranslation(0.2,0,0));; ~~~. The 2 nodes that we have created inside chamber will both point to a; `wire_co` object, but will be completely distinct: `WIRE_CO_1` and; `WIRE_CO_2`. We will want now to place symmetrically 1000 chambers on a; pad, following a pattern of 20 rows and 50 columns. One way to do this; will be to replicate our chamber by positioning it 1000 times in; different positions of the pad. Unfortunately, this is far from being; the optimal way of doing what we want. Imagine that we would like to; find out which of the 1000 chambers is containing a `(x,y,z)` point; defined in the pad reference. You will never have to do that, since the; modeller will take care of it for you, but let's guess what it has to; do. The most simple algorithm will just loop over all daughters, convert; the point from mother to local reference and check if the current; chamber contains the point or not. This might be efficient for pads with; few chambers, but definitely not for 1000. Fortunately the modeller is; smarter than that and creates for each volume some optimization; structures called `voxels` to minimize the penalty having too many; daughters, but if you have 100 pads like this in your geometry you will; anyway lose a lot in your tracking performance. The way out when; volumes can be arranged according to simple patterns is the usage of; divisions. We will describe them in detail later on. Let's think now at; a different situation: instead of 1000 chambers of the same type, we may; have several types of chambers. Let's say all chambers are cylindrical; and have a wire inside, but their dimensions are different. However, we; would like all to be represented by a single volume family, since they; have the same properties. \anchor GP01bh; #### Volume Families. A volume family is represented by the class TGeoVolumeMulti. It; represents a class of volumes having the same shape type and each member; will be identified b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:40709,efficient,efficient,40709,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['efficient'],['efficient']
Energy Efficiency,"tion. To fit a histogram with a predefined function, simply pass the name of; the function in the first parameter of `TH1::Fit`. For example,; this line fits histogram object `hist` with a Gaussian. ``` {.cpp}; root[] hist.Fit(""gaus"");; ```. The initial parameter values (and eventual limits) for pre-defined functions are set; automatically. For overriding the default limits values use the fit option `B`. The list of pre-defined functions that can be used with the `Fit` method is the following:. - ""`gaus`"" Gaussian function with 3 parameters:; `f(x) = p0*exp(-0.5*((x-p1)/p2)^2)`. - ""`expo`""An Exponential with 2 parameters: `f(x) = exp(p0+p1*x)`. - ""`pol`*`N`*"" A polynomial of degree *N*, where N is a number between 0 and 9:; `f(x) = p0 + p1*x + p2*x2 +...`. - ""`chebyshev`*`N`*"" A Chebyshev polynomial of degree *N*, where N is a number between 0 and 9:; `f(x) = p0 + p1*x + p2*(2*x2-1) +...`. - ""`landau`"" Landau function with mean and sigma. This function has; been adapted from the `CERNLIB` routine `G110 denlan` (see `TMath::Landau`). - ""`gausn`"" Normalized form of the gaussian function with 3 parameters; `f(x) = p0*exp(-0.5*((x-p1)/p2)^2)/(p2 *sqrt(2PI))`. ### Creating User-Defined Functions (TF1). You can create a **`TF1`** object and use it in the call the; `TH1::Fit`. The parameter in to the `Fit` method is the NAME of; the **`TF1`** object. There are three ways to create a **`TF1`**. - Using C++ expression using x with a fixed set of operators and; functions defined in **`TFormula`**. - Same as first one, with parameters. - Using a function that you have defined. This can be a free function or; a functor object or a particular member function of a class. #### Creating a TF1 with a Formula. Let's look at the first case. Here we call the **`TF1`** constructor; by giving it the formula: `sin(x)/x`. ``` {.cpp}; root[] TF1 *f1 = new TF1(""f1"",""sin(x)/x"",0,10); ```. You can also use a **`TF1`** object in the constructor of another; **`TF1`**. ``` {.cpp}; root[] TF1 *f2 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:5361,adapt,adapted,5361,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['adapt'],['adapted']
Energy Efficiency,"tion_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This suppression; mechanism should only be used for suppressing i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6605,reduce,reduces,6605,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['reduce'],['reduces']
Energy Efficiency,"tions print the requested elements; in the case of any; given select conditions (:option:`--select`), only those elements that; match them, will be printed. The **elements** value is a convenient; way to specify instructions, lines, scopes, symbols and types all at; once. .. code-block:: text. =elements: Instructions, lines, scopes, symbols and types.; =instructions: Assembler instructions for code sections.; =lines: Source lines referenced in the debug information.; =scopes: Lexical blocks (function, class, namespace, etc).; =symbols: Symbols (variable, member, parameter, etc).; =types: Types (pointer, reference, type alias, etc). The following options print information, collected during the creation; of the elements, such as: scope contributions to the debug information;; summary of elements created, printed or matched (:option:`--select`);; warnings produced during the view creation. .. code-block:: text. =sizes: Debug Information scopes contributions.; =summary: Summary of elements allocated, selected or printed.; =warnings: Warnings detected. Note: The **--print=sizes** option is ELF specific. .. _output_:. OUTPUT; ~~~~~~; The following options describe how to control the output generated when; printing the logical elements. .. option:: --output-file=<path>. Redirect the output to a file specified by <path>, where - is the; standard output stream. :program:`llvm-debuginfo-analyzer` has the concept of **split view**.; When redirecting the output from a complex binary format, it is; **divided** into individual files, each one containing the logical view; output for a single compilation unit. .. option:: --output-folder=<name>. The folder to write a file per compilation unit when **--output=split**; is specified. .. option:: --output-level=<level>. Only print elements up to the given **lexical level** value. The input; file is at lexical level zero and a compilation unit is at lexical level; one. .. option:: --output=<value[,value,...]>. With **value** being one of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst:10497,allocate,allocated,10497,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-debuginfo-analyzer.rst,1,['allocate'],['allocated']
Energy Efficiency,"tions to; be used. As the constant address space could only be modified on the host; side, a generic pointer loaded from the constant address space is safe to be; assumed as a global pointer since only the device global memory is visible; and managed on the host side. The vector and scalar L1 caches are invalidated; of volatile data before each kernel dispatch execution to allow constant; memory to change values between kernel dispatches. **Region**; The region address space uses the hardware Global Data Store (GDS). All; wavefronts executing on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:26028,allocate,allocated,26028,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"tive zero | 32 |; +-------+----------------------+---------------+; | pzero | Positive zero | 64 |; +-------+----------------------+---------------+; | psub | Positive subnormal | 128 |; +-------+----------------------+---------------+; | pnorm | Positive normal | 256 |; +-------+----------------------+---------------+; | pinf | Positive infinity | 512 |; +-------+----------------------+---------------+. ``alignstack(<n>)``; This indicates the alignment that should be considered by the backend when; assigning this parameter to a stack slot during calling convention; lowering. The enforcement of the specified alignment is target-dependent,; as target-specific calling convention rules may override this value. This; attribute serves the purpose of carrying language specific alignment; information that is not mapped to base types in the backend (for example,; over-alignment specification through language attributes). ``allocalign``; The function parameter marked with this attribute is the alignment in bytes of the; newly allocated block returned by this function. The returned value must either have; the specified alignment or be the null pointer. The return value MAY be more aligned; than the requested alignment, but not less aligned. Invalid (e.g. non-power-of-2); alignments are permitted for the allocalign parameter, so long as the returned pointer; is null. This attribute may only be applied to integer parameters. ``allocptr``; The function parameter marked with this attribute is the pointer; that will be manipulated by the allocator. For a realloc-like; function the pointer will be invalidated upon success (but the; same address may be returned), for a free-like function the; pointer will always be invalidated. ``readnone``; This attribute indicates that the function does not dereference that; pointer argument, even though it may read or write the memory that the; pointer points to if accessed through other pointers. If a function reads from or writes to a readnone p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:68323,allocate,allocated,68323,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"tml>`_,; using parameters that are Scudo specific. When dealing with the options string, it follows a syntax similar to ASan, where; distinct options can be assigned in the same string, separated by colons. For example, using the environment variable:. .. code:: console. SCUDO_OPTIONS=""delete_size_mismatch=false:release_to_os_interval_ms=-1"" ./a.out. Or using the function:. .. code:: cpp. extern ""C"" const char *__scudo_default_options() {; return ""delete_size_mismatch=false:release_to_os_interval_ms=-1"";; }. The following ""string"" options are available:. +---------------------------------+----------------+-------------------------------------------------+; | Option | Default | Description |; +---------------------------------+----------------+-------------------------------------------------+; | quarantine_size_kb | 0 | The size (in Kb) of quarantine used to delay |; | | | the actual deallocation of chunks. Lower value |; | | | may reduce memory usage but decrease the |; | | | effectiveness of the mitigation; a negative |; | | | value will fallback to the defaults. Setting |; | | | *both* this and thread_local_quarantine_size_kb |; | | | to zero will disable the quarantine entirely. |; +---------------------------------+----------------+-------------------------------------------------+; | quarantine_max_chunk_size | 0 | Size (in bytes) up to which chunks can be |; | | | quarantined. |; +---------------------------------+----------------+-------------------------------------------------+; | thread_local_quarantine_size_kb | 0 | The size (in Kb) of per-thread cache use to |; | | | offload the global quarantine. Lower value may |; | | | reduce memory usage but might increase |; | | | contention on the global quarantine. Setting |; | | | *both* this and quarantine_size_kb to zero will |; | | | disable the quarantine entirely. |; +---------------------------------+----------------+-------------------------------------------------+; | dealloc_type_mismatch | false | Wheth",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:8786,reduce,reduce,8786,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['reduce'],['reduce']
Energy Efficiency,"to 'CPU Time / number of threads' AND 'Compressed Throughput' is lower than expected; for your storage medium: this would imply that your CPU threads aren't decompressing data as fast as your storage; medium can provide it, and so decompression is the bottleneck.; The best way to decrease your runtime would be to utilise a system with a faster CPU, or make use; use of more threads when running, or use a compression algorithm with a higher decompression rate such as LZ4,; possibly at the cost of some extra file size. ### A note on caching. If your data is stored on a local disk, the system may cache some/all of the file in memory after it is; first read. If this is realistic of how your analysis will run - then there is no concern. However, if; you expect to only read files once in a while - and as such the files are unlikely to be in the cache -; consider clearing the cache before running rootreadspeed.; On Linux this can be done by running 'echo 3 > /proc/sys/vm/drop_caches' as a superuser,; or a specific file can be dropped from the cache with; `dd of=<FILENAME> oflag=nocache conv=notrunc,fdatasync count=0 > /dev/null 2>&1`. ### Known overhead of TTreeReader, RDataFrame. `rootreadspeed` is designed to read all data present in the specified branches, trees and files at the highest; possible speed. When the application bottleneck is not in the computations performed by analysis logic,; higher-level interfaces built on top of TTree such as TTreeReader and RDataFrame are known to add a significant; runtime overhead with respect to the runtimes reported by `rootreadspeed` (up to a factor 2). In realistic analysis; applications it has been observed that a large part of that overhead is compensated by the ability of TTreeReader and; RDataFrame to read branch values selectively, based on event cuts, and this overhead will be reduced significantly; when using RDataFrame in conjunction with RNTuple.; See also [this talk](https://indico.cern.ch/e/PPP138) (slides 16 to 19).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md:4721,reduce,reduced,4721,tree/readspeed/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md,1,['reduce'],['reduced']
Energy Efficiency,"to MCLabels as; appropriate. This translation layer is also responsible for expanding pseudo; ops used by the code generator into the actual machine instructions they; correspond to. The MCInsts that are generated by this are fed into the; instruction printer or the encoder. Finally, at your choosing, you can also implement a subclass of MCCodeEmitter; which lowers MCInst's into machine code bytes and relocations. This is; important if you want to support direct .o file emission, or would like to; implement an assembler for your target. Emitting function stack size information; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A section containing metadata on function stack sizes will be emitted when; ``TargetLoweringObjectFile::StackSizesSection`` is not null, and; ``TargetOptions::EmitStackSizeSection`` is set (-stack-size-section). The; section will contain an array of pairs of function symbol values (pointer size); and stack sizes (unsigned LEB128). The stack size values only include the space; allocated in the function prologue. Functions with dynamic stack allocations are; not included. VLIW Packetizer; ---------------. In a Very Long Instruction Word (VLIW) architecture, the compiler is responsible; for mapping instructions to functional-units available on the architecture. To; that end, the compiler creates groups of instructions called *packets* or; *bundles*. The VLIW packetizer in LLVM is a target-independent mechanism to; enable the packetization of machine instructions. Mapping from instructions to functional units; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Instructions in a VLIW target can typically be mapped to multiple functional; units. During the process of packetizing, the compiler must be able to reason; about whether an instruction can be added to a packet. This decision can be; complex since the compiler has to examine all possible mappings of instructions; to functional units. Therefore to alleviate compilation-time complexity, the; VLIW packetiz",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:78215,allocate,allocated,78215,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['allocate'],['allocated']
Energy Efficiency,"to add or remove global variables from the current Module.; #. ... *allowed* to maintain state across invocations of :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` (including global data). Implementing a ``CallGraphSCCPass`` is slightly tricky in some cases because it; has to handle SCCs with more than one node in it. All of the virtual methods; described below should return ``true`` if they modified the program, or; ``false`` if they didn't. The ``doInitialization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(CallGraph &CG);. The ``doInitialization`` method is allowed to do most of the things that; ``CallGraphSCCPass``\ es are not allowed to do. They can add and remove; functions, get pointers to functions, etc. The ``doInitialization`` method is; designed to do simple initialization type of stuff that does not depend on the; SCCs being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). .. _writing-an-llvm-pass-runOnSCC:. The ``runOnSCC`` method; ^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnSCC(CallGraphSCC &SCC) = 0;. The ``runOnSCC`` method performs the interesting work of the pass, and should; return ``true`` if the module was modified by the transformation, ``false``; otherwise. The ``doFinalization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(CallGraph &CG);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` for every SCC in the program being compiled. .. _writing-an-llvm-pass-FunctionPass:. The ``FunctionPass`` class; --------------------------. In contrast to ``ModulePass`` subclasses, `FunctionPass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ subclasses do have a; predictable, loca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:16254,schedul,scheduled,16254,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['schedul'],['scheduled']
Energy Efficiency,"to limit the number of attempts.; ``-reload``; If set to 1 (the default), the corpus directory is re-read periodically to; check for new inputs; this allows detection of new inputs that were discovered; by other fuzzing processes.; ``-jobs``; Number of fuzzing jobs to run to completion. Default value is 0, which runs a; single fuzzing process until completion. If the value is >= 1, then this; number of jobs performing fuzzing are run, in a collection of parallel; separate worker processes; each such worker process has its; ``stdout``/``stderr`` redirected to ``fuzz-<JOB>.log``.; ``-workers``; Number of simultaneous worker processes to run the fuzzing jobs to completion; in. If 0 (the default), ``min(jobs, NumberOfCpuCores()/2)`` is used.; ``-dict``; Provide a dictionary of input keywords; see Dictionaries_.; ``-use_counters``; Use `coverage counters`_ to generate approximate counts of how often code; blocks are hit; defaults to 1.; ``-reduce_inputs``; Try to reduce the size of inputs while preserving their full feature sets;; defaults to 1.; ``-use_value_profile``; Use `value profile`_ to guide corpus expansion; defaults to 0.; ``-only_ascii``; If 1, generate only ASCII (``isprint``+``isspace``) inputs. Defaults to 0.; ``-artifact_prefix``; Provide a prefix to use when saving fuzzing artifacts (crash, timeout, or; slow inputs) as ``$(artifact_prefix)file``. Defaults to empty.; ``-exact_artifact_path``; Ignored if empty (the default). If non-empty, write the single artifact on; failure (crash, timeout) as ``$(exact_artifact_path)``. This overrides; ``-artifact_prefix`` and will not use checksum in the file name. Do not use; the same path for several parallel processes.; ``-print_pcs``; If 1, print out newly covered PCs. Defaults to 0.; ``-print_final_stats``; If 1, print statistics at exit. Defaults to 0.; ``-detect_leaks``; If 1 (default) and if LeakSanitizer is enabled; try to detect memory leaks during fuzzing (i.e. not only at shut down).; ``-close_fd_mask``; Ind",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:13203,reduce,reduce,13203,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['reduce'],['reduce']
Energy Efficiency,"to the ``nonnull`` attribute on parameters and; return values. This metadata can only be applied to loads of a pointer type. The optional ``!dereferenceable`` metadata must reference a single metadata; name ``<deref_bytes_node>`` corresponding to a metadata node with one ``i64``; entry.; See ``dereferenceable`` metadata :ref:`dereferenceable <md_dereferenceable>`. The optional ``!dereferenceable_or_null`` metadata must reference a single; metadata name ``<deref_bytes_node>`` corresponding to a metadata node with one; ``i64`` entry.; See ``dereferenceable_or_null`` metadata :ref:`dereferenceable_or_null; <md_dereferenceable_or_null>`. The optional ``!align`` metadata must reference a single metadata name; ``<align_node>`` corresponding to a metadata node with one ``i64`` entry.; The existence of the ``!align`` metadata on the instruction tells the; optimizer that the value loaded is known to be aligned to a boundary specified; by the integer value in the metadata node. The alignment must be a power of 2.; This is analogous to the ''align'' attribute on parameters and return values.; This metadata can only be applied to loads of a pointer type. If the returned; value is not appropriately aligned at runtime, a poison value is returned; instead. The optional ``!noundef`` metadata must reference a single metadata name; ``<empty_node>`` corresponding to a node with no entries. The existence of; ``!noundef`` metadata on the instruction tells the optimizer that the value; loaded is known to be :ref:`well defined <welldefinedvalues>`.; If the value isn't well defined, the behavior is undefined. If the ``!noundef``; metadata is combined with poison-generating metadata like ``!nonnull``,; violation of that metadata constraint will also result in undefined behavior. Semantics:; """""""""""""""""""". The location of memory pointed to is loaded. If the value being loaded; is of scalar type then the number of bytes read does not exceed the; minimum number of bytes needed to hold all bits of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:417313,power,power,417313,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"to the `two_dim_fit` structure pointer, see manual; - **`sizex`**: length x of the source spectrum; - **`sizey`**: length y of the source spectrum. The `two_dim_fit` structure has the form of. ``` {.cpp}; class TSpectrumTwoDimFit{. public:. int number_of_peaks; // input parameter, should be>0; int number_of_iterations; // input parameter, should be >0; int xmin; // first fitted channel in x direction; int xmax; // last fitted channel in x direction; int ymin; // first fitted channel in y direction; int ymax; // last fitted channel in y direction; double alpha; // convergence coefficient, input parameter, it should be a positive number and <=1; double chi; // here the function returns resulting chi square; int statistic_type; // type of statistics, possible values are:; // FIT2_OPTIM_CHI_COUNTS (chi square statistics with counts as weighting coefficients),; // FIT2_OPTIM_CHI_FUNC_VALUES (chi square statistics with function values as weighting coefficients),; // FIT2_OPTIM_MAX_LIKELIHOOD; int alpha_optim; // optimization of convergence coefficients, possible values are:; // FIT2_ALPHA_HALVING, FIT2_ALPHA_OPTIMAL; int power; // possible values are: FIT21_FIT_POWER2,4,6,8,10,12; int fit_taylor; // order of Taylor expansion, possible values are:; // FIT2_TAYLOR_ORDER_FIRST,; // FIT2_TAYLOR_ORDER_SECOND; double position_init_x[MAX_NUMBER_OF_PEAKS2]; // initial values of x positions of 2D peaks, input parameters; double position_calc_x[MAX_NUMBER_OF_PEAKS2]; // calculated values of fitted x positions of 2D peaks, output parameters; double position_err_x[MAX_NUMBER_OF_PEAKS2]; // x position errors of 2D peaks; bool fix_position_x[MAX_NUMBER_OF_PEAKS2]; // logical vector which allows to fix the appropriate x positions of 2D peaks (not fit). However, they are present in the estimated functional; double position_init_y[MAX_NUMBER_OF_PEAKS2]; // initial values of y positions of 2D peaks, input parameters; double position_calc_y[MAX_NUMBER_OF_PEAKS2]; // calculated values of fitt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:49817,power,power,49817,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['power'],['power']
Energy Efficiency,"to the final visualization in form of highly ; customizable, publication-ready plots. It is reliable, performant and well supported,; easy to use and obtain, and strives to maximize the quantity and impact of scientific ; results obtained per unit cost, both of human effort and computing resources. ROOT provides a very efficient storage system for data models, ; that demonstrated to scale at the Large Hadron Collider experiments: Exabytes ; of scientific data are written in columnar ROOT format.; ROOT comes with histogramming capabilities in an arbitrary number of ; dimensions, curve fitting, statistical modelling, minimization, to allow; the easy setup of a data analysis system that can query and process the data; interactively or in batch mode, as well as a general parallel processing; framework, RDataFrame, that can considerably speed up an analysis, taking ; full advantage of multi-core and distributed systems. ROOT is performance critical software written in C++ and enables rapid prototyping ; powered by a unique C++ compliant interpreter called Cling. ; Cling also enables performant C++ type introspection which is a building block of automatic ; interoperability with Python. Thanks to PyROOT, leveraging the cppyy technology, ; ROOT offers efficient, on-demand C++/Python interoperability in a uniform cross-language ; execution environment. ROOT fully embraces open-source, it's made with passion by its community,; for the benefit of its community. [![License: LGPL v2.1+](https://img.shields.io/badge/License-LGPL%20v2.1+-blue.svg)](https://www.gnu.org/licenses/lgpl.html); [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5060/badge)](https://bestpractices.coreinfrastructure.org/projects/5060). ## Contribution Guidelines; - [How to contribute](https://github.com/root-project/root/blob/master/CONTRIBUTING.md); - [Coding conventions](https://root.cern/coding-conventions); - [Meetings](https://root.cern/meetings). ## Cite; When citing ROOT, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README.md:1286,power,powered,1286,README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README.md,1,['power'],['powered']
Energy Efficiency,"to two ""A"" constants.; - ``DB``: A 64-bit constant that can be split into two ""B"" constants. All ARM modes:. - ``Q``, ``Um``, ``Un``, ``Uq``, ``Us``, ``Ut``, ``Uv``, ``Uy``: Memory address; operand. Treated the same as operand ``m``, at the moment.; - ``Te``: An even general-purpose 32-bit integer register: ``r0,r2,...,r12,r14``; - ``To``: An odd general-purpose 32-bit integer register: ``r1,r3,...,r11``. ARM and ARM's Thumb2 mode:. - ``j``: An immediate integer between 0 and 65535 (valid for ``MOVW``); - ``I``: An immediate integer valid for a data-processing instruction.; - ``J``: An immediate integer between -4095 and 4095.; - ``K``: An immediate integer whose bitwise inverse is valid for a; data-processing instruction. (Can be used with template modifier ""``B``"" to; print the inverted value).; - ``L``: An immediate integer whose negation is valid for a data-processing; instruction. (Can be used with template modifier ""``n``"" to print the negated; value).; - ``M``: A power of two or an integer between 0 and 32.; - ``N``: Invalid immediate constraint.; - ``O``: Invalid immediate constraint.; - ``r``: A general-purpose 32-bit integer register (``r0-r15``).; - ``l``: In Thumb2 mode, low 32-bit GPR registers (``r0-r7``). In ARM mode, same; as ``r``.; - ``h``: In Thumb2 mode, a high 32-bit GPR register (``r8-r15``). In ARM mode,; invalid.; - ``w``: A 32, 64, or 128-bit floating-point/SIMD register in the ranges; ``s0-s31``, ``d0-d31``, or ``q0-q15``, respectively.; - ``t``: A 32, 64, or 128-bit floating-point/SIMD register in the ranges; ``s0-s31``, ``d0-d15``, or ``q0-q7``, respectively.; - ``x``: A 32, 64, or 128-bit floating-point/SIMD register in the ranges; ``s0-s15``, ``d0-d7``, or ``q0-q3``, respectively. ARM's Thumb1 mode:. - ``I``: An immediate integer between 0 and 255.; - ``J``: An immediate integer between -255 and -1.; - ``K``: An immediate integer between 0 and 255, with optional left-shift by; some amount.; - ``L``: An immediate integer between -7 and 7.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:225197,power,power,225197,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"to; express the input LLVM code in the target instruction set. This stage; produces the initial code for the program in the target instruction set, then; makes use of virtual registers in SSA form and physical registers that; represent any required register assignments due to target constraints or; calling conventions. This step turns the LLVM code into a DAG of target; instructions. 2. `Scheduling and Formation`_ --- This phase takes the DAG of target; instructions produced by the instruction selection phase, determines an; ordering of the instructions, then emits the instructions as :raw-html:`<tt>`; `MachineInstr`_\s :raw-html:`</tt>` with that ordering. Note that we; describe this in the `instruction selection section`_ because it operates on; a `SelectionDAG`_. 3. `SSA-based Machine Code Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:6229,schedul,scheduling,6229,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['schedul'],['scheduling']
Energy Efficiency,"tomating creating a test to check for the; compiler crash. `cvise <https://github.com/marxin/cvise>`_ is an alternative to ``creduce``. .. _middleend-crash:. Middle-end optimization bugs; ----------------------------. If you find that a bug crashes in the optimizer, compile your test-case to a; ``.bc`` file by passing ""``-emit-llvm -O1 -Xclang -disable-llvm-passes -c -o; foo.bc``"". The ``-O1`` is important because ``-O0`` adds the ``optnone``; function attribute to all functions and many passes don't run on ``optnone``; functions. Then run:. .. code-block:: bash. opt -O3 foo.bc -disable-output. If this doesn't crash, please follow the instructions for a :ref:`front-end; bug <frontend-crash>`. If this does crash, then you should be able to debug this with the following; :doc:`bugpoint <Bugpoint>` command:. .. code-block:: bash. bugpoint foo.bc -O3. Run this, then file a bug with the instructions and reduced .bc; files that bugpoint emits. If bugpoint doesn't reproduce the crash, ``llvm-reduce`` is an alternative; way to reduce LLVM IR. Create a script that repros the crash and run:. .. code-block:: bash. llvm-reduce --test=path/to/script foo.bc. which should produce reduced IR that reproduces the crash. Be warned the; ``llvm-reduce`` is still fairly immature and may crash. If none of the above work, you can get the IR before a crash by running the; ``opt`` command with the ``--print-before-all --print-module-scope`` flags to; dump the IR before every pass. Be warned that this is very verbose. .. _backend-crash:. Backend code generator bugs; ---------------------------. If you find a bug that crashes clang in the code generator, compile your; source file to a .bc file by passing ""``-emit-llvm -c -o foo.bc``"" to; clang (in addition to the options you already pass). Once your have; foo.bc, one of the following commands should fail:. #. ``llc foo.bc``; #. ``llc foo.bc -relocation-model=pic``; #. ``llc foo.bc -relocation-model=static``. If none of these crash, please follo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:4343,reduce,reduce,4343,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,2,['reduce'],['reduce']
Energy Efficiency,tor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337768,reduce,reduce,337768,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"torLength()``?). Result: VP usable for IR-level vectorizers (LV, VPlan, RegionVectorizer),; potential integration in Clang with builtins. 2. CodeGen support; ------------------. - VP intrinsics translate to first-class SDNodes; (eg ``llvm.vp.fdiv.* -> vp_fdiv``).; - VP legalization (legalize explicit vector length to mask (AVX512), legalize VP; SDNodes to pre-existing ones (SSE, NEON)). Result: Backend development based on VP SDNodes. 3. Lift InstSimplify/InstCombine/DAGCombiner to VP; --------------------------------------------------. - Introduce PredicatedInstruction, PredicatedBinaryOperator, .. helper classes; that match standard vector IR and VP intrinsics.; - Add a matcher context to PatternMatch and context-aware IR Builder APIs.; - Incrementally lift DAGCombiner to work on VP SDNodes as well as on regular; vector instructions.; - Incrementally lift InstCombine/InstSimplify to operate on VP as well as; regular IR instructions. Result: Optimization of VP intrinsics on par with standard vector instructions. 4. Deprecate llvm.masked.* / llvm.experimental.reduce.*; -------------------------------------------------------. - Modernize llvm.masked.* / llvm.experimental.reduce* by translating to VP.; - DCE transitional APIs. Result: VP has superseded earlier vector intrinsics. 5. Predicated IR Instructions; -----------------------------. - Vector instructions have an optional mask and vector length parameter. These; lower to VP SDNodes (from Stage 2).; - Phase out VP intrinsics, only keeping those that are not equivalent to; vectorized scalar instructions (reduce, shuffles, ..); - InstCombine/InstSimplify expect predication in regular Instructions (Stage (3); has laid the groundwork). Result: Native vector predication in IR. References; ==========. .. [MaskedIR] `llvm.masked.*` intrinsics,; https://llvm.org/docs/LangRef.html#masked-vector-load-and-store-intrinsics. .. [VPRFC] RFC: Prototype & Roadmap for vector predication in LLVM,; https://reviews.llvm.org/D57504; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VectorPredication.rst:2193,reduce,reduce,2193,interpreter/llvm-project/llvm/docs/Proposals/VectorPredication.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VectorPredication.rst,3,['reduce'],['reduce']
Energy Efficiency,"tore instructions,; and it is carefully designed not to have (or need) an ""address-of""; operator. Notice how the type of the @G/@H global variables is actually; ""i32\*"" even though the variable is defined as ""i32"". What this means is; that @G defines *space* for an i32 in the global data area, but its; *name* actually refers to the address for that space. Stack variables; work the same way, except that instead of being declared with global; variable definitions, they are declared with the `LLVM alloca; instruction <../../LangRef.html#alloca-instruction>`_:. .. code-block:: llvm. define i32 @example() {; entry:; %X = alloca i32 ; type of %X is i32*.; ...; %tmp = load i32, i32* %X ; load the stack value %X from the stack.; %tmp2 = add i32 %tmp, 1 ; increment it; store i32 %tmp2, i32* %X ; store it back; ... This code shows an example of how you can declare and manipulate a stack; variable in the LLVM IR. Stack memory allocated with the alloca; instruction is fully general: you can pass the address of the stack slot; to functions, you can store it in other variables, etc. In our example; above, we could rewrite the example to use the alloca technique to avoid; using a PHI node:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; %X = alloca i32 ; type of %X is i32*.; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; store i32 %X.0, i32* %X ; Update X; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; store i32 %X.1, i32* %X ; Update X; br label %cond_next. cond_next:; %X.2 = load i32, i32* %X ; Read X; ret i32 %X.2; }. With this, we have discovered a way to handle arbitrary mutable; variables without the need to create Phi nodes at all:. #. Each mutable variable becomes a stack allocation.; #. Each read of the variable becomes a load from the stack.; #. Each update of the variable becomes a store to the stack.; #. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:5309,allocate,allocated,5309,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['allocate'],['allocated']
Energy Efficiency,"toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfig instance. BayesianCalculator. Improve the way the class performs the numerical integration to; find the interval and/or the posterior function.; In case of complex; numerical calculation add the method SetScanOfPosterior(nbins) for; scanning the posterior function in a givn number of nbins; Add possibility to compute lower/upper limits using the method; SetLeftSideTailFraction(fraction); Add possibility to compute shortest interval using; SetShortestInterval. MCMCCalculator. Various improvements including possibility to compute; lower/central/upper limits using; SetLeftSideTailFraction(fraction). New Tutorials. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikel",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:7839,Adapt,Adaptive,7839,roofit/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html,1,['Adapt'],['Adaptive']
Energy Efficiency,"trongly curved distributions.; The old default behaviour was to interpolate the curve at the bin centres, which can still be enabled by setting the `useAverage` parameter of `RooPlot::residHist` or `RooPlot::pullHist` to `false`. ### Improved recovery from invalid parameters. When a function in RooFit is undefined (Poisson with negative mean, PDF with negative values, etc), RooFit can now pass information about the; ""badness"" of the violation to the minimiser. The minimiser can use this to compute a gradient to find its way out of the undefined region.; This can drastically improve its ability to recover when unstable fit models are used, for example RooPolynomial. For details, see the RooFit tutorial [rf612_recoverFromInvalidParameters.C](https://root.cern/doc/v624/rf612__recoverFromInvalidParameters_8C.html); and [arxiv:2012.02746](https://arxiv.org/abs/2012.02746). ### Modernised RooDataHist. RooDataHist was partially modernised to improve const-correctness, to reduce side effects as well as its memory footprint, and to make; it ready for RooFit's faster batch evaluations.; Derived classes that directly access protected members might need to be updated. This holds especially for direct accesses to `_curWeight`,; `_curWeightErrLo`, etc, which have been removed. (It doesn't make sense to write to these members from const functions when the same information; can be retrieved using an index access operator of an array.) All similar accesses in derived classes should be replaced by the getters `get_curWeight()`; or better `get_wgt(i)`, which were also supported in ROOT \<v6.24. More details on what happened:. - Reduced side effects. This code produces undefined behaviour because the side effect of `get(i)`, i.e., loading the new weight into `_curWeight`; is not guaranteed to happen before `weight()` is called:; ```; processEvent(dataHist.get(i), dataHist.weight()); // Dangerous! Order of evaluation is not guaranteed.; ```; With the modernised interface, one would use:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:20689,reduce,reduce,20689,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['reduce'],['reduce']
Energy Efficiency,"truction Selection is the process of translating LLVM code presented to the; code generator into target-specific machine instructions. There are several; well-known ways to do this in the literature. LLVM uses a SelectionDAG based; instruction selector. Portions of the DAG instruction selector are generated from the target; description (``*.td``) files. Our goal is for the entire instruction selector; to be generated from these ``.td`` files, though currently there are still; things that require custom C++ code. `GlobalISel <https://llvm.org/docs/GlobalISel/index.html>`_ is another; instruction selection framework. .. _SelectionDAG:. Introduction to SelectionDAGs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG provides an abstraction for code representation in a way that; is amenable to instruction selection using automatic techniques; (e.g. dynamic-programming based optimal pattern matching selectors). It is also; well-suited to other phases of code generation; in particular, instruction; scheduling (SelectionDAG's are very close to scheduling DAGs post-selection).; Additionally, the SelectionDAG provides a host representation where a large; variety of very-low-level (but target-independent) `optimizations`_ may be; performed; ones which require extensive information about the instructions; efficiently supported by the target. The SelectionDAG is a Directed-Acyclic-Graph whose nodes are instances of the; ``SDNode`` class. The primary payload of the ``SDNode`` is its operation code; (Opcode) that indicates what operation the node performs and the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:33844,schedul,scheduling,33844,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,2,['schedul'],['scheduling']
Energy Efficiency,"ts accessible through the source and destination operands. Guaranteed inlined copy; ^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c. void __builtin_memcpy_inline(void *dst, const void *src, size_t size);. ``__builtin_memcpy_inline`` has been designed as a building block for efficient; ``memcpy`` implementations. It is identical to ``__builtin_memcpy`` but also; guarantees not to call any external functions. See LLVM IR `llvm.memcpy.inline; <https://llvm.org/docs/LangRef.html#llvm-memcpy-inline-intrinsic>`_ intrinsic; for more information. This is useful to implement a custom version of ``memcpy``, implement a; ``libc`` memcpy or work around the absence of a ``libc``. Note that the `size` argument must be a compile time constant. Note that this intrinsic cannot yet be called in a ``constexpr`` context. Guaranteed inlined memset; ^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c. void __builtin_memset_inline(void *dst, int value, size_t size);. ``__builtin_memset_inline`` has been designed as a building block for efficient; ``memset`` implementations. It is identical to ``__builtin_memset`` but also; guarantees not to call any external functions. See LLVM IR `llvm.memset.inline; <https://llvm.org/docs/LangRef.html#llvm-memset-inline-intrinsic>`_ intrinsic; for more information. This is useful to implement a custom version of ``memset``, implement a; ``libc`` memset or work around the absence of a ``libc``. Note that the `size` argument must be a compile time constant. Note that this intrinsic cannot yet be called in a ``constexpr`` context. Atomic Min/Max builtins with memory ordering; --------------------------------------------. There are two atomic builtins with min/max in-memory comparison and swap.; The syntax and semantics are similar to GCC-compatible __atomic_* builtins. * ``__atomic_fetch_min``; * ``__atomic_fetch_max``. The builtins work with signed and unsigned integers and require to specify memory ordering.; The return value is the original value that was stored in ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:138929,efficient,efficient,138929,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['efficient'],['efficient']
Energy Efficiency,"ts as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.or``' intrinsic performs the integer ``OR`` reduction; (:ref:`llvm.vector.reduce.or <int_vector_reduce_or>`) of the vector operand; ``val`` on each enabled lane, performing an '``or``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.or.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %masked.a); %also.r = or i32 %reduction, %start. .. _int_vp_reduce_xor:. '``llvm.vp.reduce.xor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.xor.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.xor.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``XOR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:760612,reduce,reduce,760612,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ts of a NaN must be conserved, with two exceptions.; First, environments which use only a single canonical representation of NaN; must perform said canonicalization. Second, SNaNs must be quieted per the; usual methods. The canonicalization operation may be optimized away if:. - The input is known to be canonical. For example, it was produced by a; floating-point operation that is required by the standard to be canonical.; - The result is consumed only by (or fused with) other floating-point; operations. That is, the bits of the floating-point value are not examined. .. _int_fmuladd:. '``llvm.fmuladd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.fmuladd.f32(float %a, float %b, float %c); declare double @llvm.fmuladd.f64(double %a, double %b, double %c). Overview:; """""""""""""""""". The '``llvm.fmuladd.*``' intrinsic functions represent multiply-add; expressions that can be fused if the code generator determines that (a) the; target instruction set has support for a fused operation, and (b) that the; fused operation is more efficient than the equivalent, separate pair of mul; and add instructions. Arguments:; """""""""""""""""""". The '``llvm.fmuladd.*``' intrinsics each take three arguments: two; multiplicands, a and b, and an addend c. Semantics:; """""""""""""""""""". The expression:. ::. %0 = call float @llvm.fmuladd.f32(%a, %b, %c). is equivalent to the expression a \* b + c, except that it is unspecified; whether rounding will be performed between the multiplication and addition; steps. Fusion is not guaranteed, even if the target platform supports it.; If a fused multiply-add is required, the corresponding; :ref:`llvm.fma <int_fma>` intrinsic function should be used instead.; This never sets errno, just as '``llvm.fma.*``'. Examples:; """""""""""""""""". .. code-block:: llvm. %r2 = call float @llvm.fmuladd.f32(float %a, float %b, float %c) ; yields float:r2 = (a * b) + c. Hardware-Loop Intrinsics; ------------------------. LLVM support several intrinsi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:641689,efficient,efficient,641689,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency,"ts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3542,reduce,reduce,3542,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['reduce'],['reduce']
Energy Efficiency,"ts; ; In TProof::ClearPackages, use the manager to execute the command on; all known worker machines. Improves the consistency when re-istalling; packages. In TProof::GetDataSets, add support for option ':lite:'; this allows; to fill the map with only the summary information about the datasets; (the header of TFileCollections), significantly increasing the speed; and the memory footprint when the number of datasets is very large.; Accept '.' in user names.; Add switch to control caching of the files read on MacOsX. A call to; fcntl(fd, F_NOCACHE, 1) is done after opening the file.; Add export of the envs ROOTPROOFCLIENT and ROOTPROOFLITE when; appropriate. These allow to steer building and/or enabling of PAR files; in PROOF-INF/BUILD.sh and/or PROOF-INF/SETUP.C, improving transparency; between normal ROOT and PROOF. The example PAR; 'tutorials/proof/event.par' has been modified to check the two; variables.; Fix a few issues in SQL PROOF monitoring: in; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.Â  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:3718,monitor,monitoring,3718,proof/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html,2,['monitor'],['monitoring']
Energy Efficiency,"ts; are reasonably small, a ``SmallSet<Type, N>`` is a good choice. This set has; space for N elements in place (thus, if the set is dynamically smaller than N,; no malloc traffic is required) and accesses them with a simple linear search.; When the set grows beyond N elements, it allocates a more expensive; representation that guarantees efficient access (for most types, it falls back; to :ref:`std::set <dss_set>`, but for pointers it uses something far better,; :ref:`SmallPtrSet <dss_smallptrset>`. The magic of this class is that it handles small sets extremely efficiently, but; gracefully handles extremely large sets without loss of efficiency. .. _dss_smallptrset:. llvm/ADT/SmallPtrSet.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallPtrSet`` has all the advantages of ``SmallSet`` (and a ``SmallSet`` of; pointers is transparently implemented with a ``SmallPtrSet``). If more than N; insertions are performed, a single quadratically probed hash table is allocated; and grows as needed, providing extremely efficient access (constant time; insertion/deleting/queries with low constant factors) and is very stingy with; malloc traffic. Note that, unlike :ref:`std::set <dss_set>`, the iterators of ``SmallPtrSet``; are invalidated whenever an insertion occurs. Also, the values visited by the; iterators are not visited in sorted order. .. _dss_stringset:. llvm/ADT/StringSet.h; ^^^^^^^^^^^^^^^^^^^^. ``StringSet`` is a thin wrapper around :ref:`StringMap\<char\> <dss_stringmap>`,; and it allows efficient storage and retrieval of unique strings. Functionally analogous to ``SmallSet<StringRef>``, ``StringSet`` also supports; iteration. (The iterator dereferences to a ``StringMapEntry<char>``, so you; need to call ``i->getKey()`` to access the item of the StringSet.) On the; other hand, ``StringSet`` doesn't support range-insertion and; copy-construction, which :ref:`SmallSet <dss_smallset>` and :ref:`SmallPtrSet; <dss_smallptrset>` do support. .. _dss_denseset:. llvm/ADT/DenseSet.h; ^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:78966,allocate,allocated,78966,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,2,"['allocate', 'efficient']","['allocated', 'efficient']"
Energy Efficiency,"tting it into another is not necessarily easier than re-doing it.; > Optimization code is usually heavily tied in to the specific IR they use. Understood. The only reason that I brought this up is because SGI's IR is; more similar to LLVM than it is different in many respects (SSA based,; relatively low level, etc), and could be easily adapted. Also their; optimizations are written in C++ and are actually somewhat; structured... of course it would be no walk in the park, but it would be; much less time consuming to adapt, say, SSA-PRE than to rewrite it. > But your larger point is valid that adding SSA based optimizations is; > feasible and should be fun. (Again, link time cost is the issue.). Assuming linktime cost wasn't an issue, the question is: ; Does using GCC's backend buy us anything?. > It also occurs to me that GCC is probably doing quite a bit of back-end; > optimization (step 16 in your list). Do you have a breakdown of that?. Not really. The irritating part of GCC is that it mixes it all up and; doesn't have a clean separation of concerns. A lot of the ""back end; optimization"" happens right along with other data optimizations (ie, CSE; of machine specific things). As far as REAL back end optimizations go, it looks something like this:. 1. Instruction combination: try to make CISCy instructions, if available; 2. Register movement: try to get registers in the right places for the; architecture to avoid register to register moves. For example, try to get; the first argument of a function to naturally land in %o0 for sparc.; 3. Instruction scheduling: 'nuff said :); 4. Register class preferencing: ??; 5. Local register allocation; 6. global register allocation; 7. Spilling; 8. Local regalloc; 9. Jump optimization; 10. Delay slot scheduling; 11. Branch shorting for CISC machines; 12. Instruction selection & peephole optimization; 13. Debug info output. But none of this would be usable for LLVM anyways, unless we were using; GCC as a static compiler. -Chris. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt:2570,schedul,scheduling,2570,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,2,['schedul'],['scheduling']
Energy Efficiency,"ttp://www.students.uiuc.edu/~gaeke/; D: Portions of X86 static and JIT compilers; initial SparcV8 backend; D: Dynamic trace optimizer; D: FreeBSD/X86 compatibility fixes, the llvm-nm tool. N: Nicolas Geoffray; E: nicolas.geoffray@lip6.fr; W: http://www-src.lip6.fr/homepages/Nicolas.Geoffray/; D: PPC backend fixes for Linux. N: Louis Gerbarg; E: lgg@apple.com; D: Portions of the PowerPC backend. N: Saem Ghani; E: saemghani@gmail.com; D: Callgraph class cleanups. N: Mikhail Glushenkov; E: foldr@codedgers.com; D: Author of llvmc2. N: Dan Gohman; E: llvm@sunfishcode.online; D: Miscellaneous bug fixes; D: WebAssembly Backend. N: Renato Golin; E: rengolin@systemcall.eu; E: rengolin@gmail.com; D: ARM/AArch64 back-end improvements; D: Loop Vectorizer improvements; D: Regression and Test Suite improvements; D: Linux compatibility (GNU, musl, etc); D: Initial Linux kernel / Android support effort; I: rengolin. N: David Goodwin; E: david@goodwinz.net; D: Thumb-2 code generator. N: David Greene; E: greened@obbligato.org; D: Miscellaneous bug fixes; D: Register allocation refactoring. N: Gabor Greif; E: ggreif@gmail.com; D: Improvements for space efficiency. N: James Grosbach; E: grosbach@apple.com; I: grosbach; D: SjLj exception handling support; D: General fixes and improvements for the ARM back-end; D: MCJIT; D: ARM integrated assembler and assembly parser; D: Led effort for the backend formerly known as ARM64. N: Lang Hames; E: lhames@gmail.com; D: PBQP-based register allocator. N: Gordon Henriksen; E: gordonhenriksen@mac.com; D: Pluggable GC support; D: C interface; D: Ocaml bindings. N: Raul Fernandes Herbster; E: raul@dsc.ufcg.edu.br; D: JIT support for ARM. N: Paolo Invernizzi; E: arathorn@fastwebnet.it; D: Visual C++ compatibility fixes. N: Patrick Jenkins; E: patjenk@wam.umd.edu; D: Nightly Tester. N: Tony(Yanjun) Jiang; E: jtony@ca.ibm.com; D: PowerPC Backend Developer; D: Improvements to the PPC backend and miscellaneous bug fixes. N: Dale Johannesen; E: dalej@apple.c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT:4750,green,greened,4750,interpreter/llvm-project/llvm/CREDITS.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT,1,['green'],['greened']
Energy Efficiency,"turning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umin.*``' intrinsics do an unsigned; integer ``MIN`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmax:. '``llvm.vector.reduce.fmax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmax.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmax.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmax.*``' intrinsics do a floating-point; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.maxnum.*``'; intrinsic. That is, the result will always be a number unless all elements of; the vector are NaN. For a vector with maximum element magnitude 0.0 and; containing both +0.0 and -0.0 elements, the sign of the result is unspecified. If the intrinsic call has the ``nnan`` fast-math flag, then the operation can; assume that NaNs are not present in the input vector. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. .. _int_vector_reduce_fmin:. '``llvm.vector.reduce.fmin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fmin.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fmin.v2f64(<2 x dou",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:658745,reduce,reduce,658745,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"tvalue {i32, float} %agg1, float %val, 1 ; yields {i32 1, float %val}; %agg3 = insertvalue {i32, {float}} undef, float %val, 1, 0 ; yields {i32 undef, {float %val}}. .. _memoryops:. Memory Access and Addressing Operations; ---------------------------------------. A key design point of an SSA-based representation is how it represents; memory. In LLVM, no memory locations are in SSA form, which makes things; very simple. This section describes how to read, write, and allocate; memory in LLVM. .. _i_alloca:. '``alloca``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = alloca [inalloca] <type> [, <ty> <NumElements>] [, align <alignment>] [, addrspace(<num>)] ; yields type addrspace(num)*:result. Overview:; """""""""""""""""". The '``alloca``' instruction allocates memory on the stack frame of the; currently executing function, to be automatically released when this; function returns to its caller. If the address space is not explicitly; specified, the object is allocated in the alloca address space from the; :ref:`datalayout string<langref_datalayout>`. Arguments:; """""""""""""""""""". The '``alloca``' instruction allocates ``sizeof(<type>)*NumElements``; bytes of memory on the runtime stack, returning a pointer of the; appropriate type to the program. If ""NumElements"" is specified, it is; the number of elements allocated, otherwise ""NumElements"" is defaulted; to be one. If a constant alignment is specified, the value result of the; allocation is guaranteed to be aligned to at least that boundary. The; alignment may not be greater than ``1 << 32``. The alignment is only optional when parsing textual IR; for in-memory IR,; it is always present. If not specified, the target can choose to align the; allocation on any convenient boundary compatible with the type. '``type``' may be any sized type. Structs containing scalable vectors cannot be used in allocas unless all; fields are the same scalable vector type (e.g. ``{<vscale x 2 x i32>,; <vscale x 2 x i32>}`` contains",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:409325,allocate,allocated,409325,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"type of a branch in ROOT:. type size C++ identifier; ------------------ -------- --------------- ------------; signed integer 32 bit int I; 64 bit long L; unsigned integer 32 bit unsigned int i; 64 bit unsigned long l; floating point 32 bit float F; 64 bit double D; boolean - bool O. ### Processing N-tuples Spanning over Several Files ###. Usually n-tuples or trees span over many files and it would be difficult; to add them manually. ROOT thus kindly provides a helper class in the; form of `TChain`. Its usage is shown in the following macro which is; very similar to the previous example. The constructor of a `TChain`; takes the name of the `TTree` (or `TNuple`) as an argument. The files; are added with the function `Add(fileName)`, where one can also use; wild-cards as shown in the example. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/read_ntuple_with_chain.C; ```. ### *For the advanced user:* Processing trees with a selector script ###. Another very general and powerful way of processing a `TChain` is; provided via the method `TChain::Process()`. This method takes as; arguments an instance of a -- user-implemented-- class of type; `TSelector`, and -- optionally -- the number of entries and the first; entry to be processed. A template for the class `TSelector` is provided; by the method `TTree::MakeSelector`, as is shown in the little macro; `makeSelector.C` below. It opens the n-tuple `conductivity_experiment.root` from the example; above and creates from it the header file `MySelector.h` and a template; to insert your own analysis code, `MySelector.C`.; \newpage. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/makeMySelector.C; ```. The template contains the entry points `Begin()` and `SlaveBegin()`; called before processing of the `TChain` starts, `Process()` called for; every entry of the chain, and `SlaveTerminate()` and `Terminate()`; called after the last entry has been processed. Typically,; initialization like booking of histograms is performed in; `SlaveBegin()`, the analy",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:6392,power,powerful,6392,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['power'],['powerful']
Energy Efficiency,"uared acq_rel monotonic ; yields { i32, i1 }; %value_loaded = extractvalue { i32, i1 } %val_success, 0; %success = extractvalue { i32, i1 } %val_success, 1; br i1 %success, label %done, label %loop. done:; ... .. _i_atomicrmw:. '``atomicrmw``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. atomicrmw [volatile] <operation> ptr <pointer>, <ty> <value> [syncscope(""<target-scope>"")] <ordering>[, align <alignment>] ; yields ty. Overview:; """""""""""""""""". The '``atomicrmw``' instruction is used to atomically modify memory. Arguments:; """""""""""""""""""". There are three arguments to the '``atomicrmw``' instruction: an; operation to apply, an address whose value to modify, an argument to the; operation. The operation must be one of the following keywords:. - xchg; - add; - sub; - and; - nand; - or; - xor; - max; - min; - umax; - umin; - fadd; - fsub; - fmax; - fmin; - uinc_wrap; - udec_wrap. For most of these operations, the type of '<value>' must be an integer; type whose bit width is a power of two greater than or equal to eight; and less than or equal to a target-specific size limit. For xchg, this; may also be a floating point or a pointer type with the same size constraints; as integers. For fadd/fsub/fmax/fmin, this must be a floating point type. The; type of the '``<pointer>``' operand must be a pointer to that type. If; the ``atomicrmw`` is marked as ``volatile``, then the optimizer is not; allowed to modify the number or order of execution of this; ``atomicrmw`` with other :ref:`volatile operations <volatile>`. Note: if the alignment is not greater or equal to the size of the `<value>`; type, the atomic operation is likely to require a lock and have poor; performance. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. If unspecified, the alignment is assumed to be equal to the; size of the '<value>' type. Note that this default alignment assumption is; different from the alignment used for the load/store instruction",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:429795,power,power,429795,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"uccessful as; long no zero diagonal element is encountered. Therefore, the user could; perform decomposition and only after this step worry about the tolerance; number. If the matrix is flagged as being singular, operations with the; decomposition will fail and will return matrices or vectors that are; invalid. If one would like to monitor the tolerance parameter but not; have the code stop in case of a number smaller than `fTol`, one could; proceed as follows:. ``` {.cpp}; TVectorD b = ..;; TMatrixD a = ..;; .; TDecompLU lu(a);; Bool_t ok;; TVectorD x = lu.Solve(b,ok);; Int_t nr = 0;; while (!ok) {; lu.SetMatrix(a);; lu.SetTol(0.1*lu.GetTol());; if (nr++ > 10) break;; x = lu.Solve(b,ok);; }; if (x.IsValid()); cout << ""solved with tol ="" << lu.GetTol() << endl;; else; cout << ""solving failed "" << endl;; ```. The observant reader will notice that by scaling the complete matrix by; some small number the decomposition will detect a singular matrix. In; this case, the user will have to reduce the tolerance number by this; factor. (For CPU time saving we decided not to make this an automatic procedure). ### Condition number. The numerical accuracy of the solution `x` in `Ax = b` can be accurately; estimated by calculating the condition number `k` of matrix $A$, which is defined as:. $k = ||A||_{1}||A^{-1}||_{1}$ where $||A||_{1} = \underset{j}{max}(\sum_{i}|A_{ij}|)$. A good rule of thumb is that if the matrix condition number is 10n,; the accuracy in `x` is `15` - `n` digits for double precision. Hager devised an iterative method (W.W. Hager, Condition estimators,; SIAM J. Sci. Stat. Comp., 5 (1984), pp. 311-316) to; determine $||A^{-1}||_{1}$ without actually having to; calculate $A^{-1}$. It is used when calling `Condition()`. A code example below shows the usage of the condition number. The matrix $A$; is a (10x10) *Hilbert* matrix that is badly; conditioned as its determinant shows. We construct a vector `b` by; summing the matrix rows. Therefore, the components of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:41483,reduce,reduce,41483,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['reduce'],['reduce']
Energy Efficiency,"uce.xor.*``' intrinsics do a bitwise ``XOR``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smax:. '``llvm.vector.reduce.smax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smax.*``' intrinsics do a signed integer; ``MAX`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_smin:. '``llvm.vector.reduce.smin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.smin.*``' intrinsics do a signed integer; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umax:. '``llvm.vector.reduce.umax.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.umax.*``' intrinsics do an unsigned; integer ``MAX`` reduction of a vector, returning the result as a scalar. The; return type matches the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_umin:. '``llvm.vector.reduce.umin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:657159,reduce,reduce,657159,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"uctors for all elements of the array are called.; We should model (potentially some of) such evaluations,; and the same applies for destructors called from; operator delete[].; See tests cases in handle_constructors_with_new_array.cpp.; . Constructing an array requires invoking multiple (potentially unknown); amount of constructors with the same construct-expression.; Apart from the technical difficulties of juggling program points around; correctly to avoid accidentally merging paths together, we'll have to; be a judge on when to exit the loop and how to widen it.; Given that the constructor is going to be a default constructor,; a nice 95% solution might be to execute exactly one constructor and; then default-bind the resulting LazyCompoundVal to the whole array;; it'll work whenever the default constructor doesn't touch global state; but only initializes the object to various default values.; But if, say, we're making an array of strings,; depending on the implementation you might have to allocate a new buffer; for each string, and in this case default-binding won't cut it.; We might want to come up with an auxiliary analysis in order to perform; widening of these simple loops more precisely.; . Handle constructors that can be elided due to Named Return Value Optimization (NRVO); Local variables which are returned by values on all return statements; may be stored directly at the address for the return value,; eliding the copy or move constructor call.; Such variables can be identified using the AST call VarDecl::isNRVOVariable.; . Handle constructors of lambda captures; Variables which are captured by value into a lambda require a call to; a copy constructor.; This call is not currently modeled.; . Handle constructors for default arguments; Default arguments in C++ are recomputed at every call,; and are therefore local, and not static, variables.; See tests cases in handle_constructors_for_default_arguments.cpp.; . Default arguments are annoying because the initi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html:3699,allocate,allocate,3699,interpreter/llvm-project/clang/www/analyzer/open_projects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html,2,['allocate'],['allocate']
Energy Efficiency,"uctory material to Python is available from many; sources on the web, see e. g. http://docs.python.org. ## PyROOT ##. The access to ROOT classes and their methods in PyROOT is almost identical to C++; macros, except for the special language features of Python, most importantly dynamic; type declaration at the time of assignment. Coming back to our first example, simply; plotting a function in ROOT, the following C++ code:. ``` {.cpp}; TF1 *f1 = new TF1(""f2"",""[0]*sin([1]*x)/x"",0.,10.);; f1->SetParameter(0,1);; f1->SetParameter(1,1);; f1->Draw();; ```. in Python becomes:. ``` {.python}; import ROOT; f1 = ROOT.TF1(""f2"",""[0]*sin([1]*x)/x"",0.,10.); f1.SetParameter(0,1);; f1.SetParameter(1,1);; f1.Draw();; ```. A slightly more advanced example hands over data defined in the macro to the ROOT; class `TGraphErrors`. Note that a Python array can be used to pass data between; Python and ROOT. The first line in the Python script allows it to be executed; directly from the operating system, without the need to start the script from; python or the highly recommended powerful interactive shell ipython. The last line; in the python script is there to allow you to have a look at the graphical output; in the ROOT canvas before it disappears upon termination of the script. Here is the C++ version:. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/TGraphFit.C; ```. In Python it looks like this:. ``` {.python}; @ROOT_INCLUDE_FILE macros/TGraphFit.py; ```. Comparing the C++ and Python versions in these two examples, it now should be; clear how easy it is to convert any ROOT Macro in C++ to a Python version. As another example, let us revisit macro3 from Chapter 4. A straight-forward; Python version relying on the ROOT class `TMath`:. ``` {.python}; @ROOT_INCLUDE_FILE macros/macro3.py; ```. ### More Python- less C++ ###. You may have noticed already that there are some Python modules providing; functionality similar to ROOT classes, which fit more seamlessly into your; Python code. A more â€œpythonic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/root_in_python.md:1401,power,powerful,1401,documentation/primer/root_in_python.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/root_in_python.md,1,['power'],['powerful']
Energy Efficiency,"ucture allocated in memory accessible from both the; CPU and GPU. The structure is defined by the runtime and subject to change; between releases. For example, see [AMD-ROCm-github]_. .. _amdgpu-amdhsa-hsa-aql-queue:. HSA AQL Queue; ~~~~~~~~~~~~~. The HSA AQL queue structure is defined by an HSA compatible runtime (see; :ref:`amdgpu-os`) and subject to change between releases. For example, see; [AMD-ROCm-github]_. For some processors it contains fields needed to implement; certain language features such as the flat address aperture bases. It also; contains fields used by CP such as managing the allocation of scratch memory. .. _amdgpu-amdhsa-kernel-descriptor:. Kernel Descriptor; ~~~~~~~~~~~~~~~~~. A kernel descriptor consists of the information needed by CP to initiate the; execution of a kernel, including the entry point address of the machine code; that implements the kernel. Code Object V3 Kernel Descriptor; ++++++++++++++++++++++++++++++++. CP microcode requires the Kernel descriptor to be allocated on 64-byte; alignment. The fields used by CP for code objects before V3 also match those specified in; :ref:`amdgpu-amdhsa-kernel-descriptor-v3-table`. .. table:: Code Object V3 Kernel Descriptor; :name: amdgpu-amdhsa-kernel-descriptor-v3-table. ======= ======= =============================== ============================; Bits Size Field Name Description; ======= ======= =============================== ============================; 31:0 4 bytes GROUP_SEGMENT_FIXED_SIZE The amount of fixed local; address space memory; required for a work-group; in bytes. This does not; include any dynamically; allocated local address; space memory that may be; added when the kernel is; dispatched.; 63:32 4 bytes PRIVATE_SEGMENT_FIXED_SIZE The amount of fixed; private address space; memory required for a; work-item in bytes. When; this cannot be predicted,; code object v4 and older; sets this value to be; higher than the minimum; requirement.; 95:64 4 bytes KERNARG_SIZE The size of the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:158278,allocate,allocated,158278,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['allocate'],['allocated']
Energy Efficiency,"uding the input ll/bc file), they are; given via the following flag:; `--test_args=<test_arguments>`; If unspecified, the test is run as given. Itâ€™s worth noting that the input file; would be passed as a parameter to the test, similar how `-compile-custom`; currently operates. ### Implementation; The tool would behave similar to CReduceâ€™s functionality in that it would have a; list of passes that try to minimize the given test-case. We should be able to; modularize the toolâ€™s behavior, as well as making it easier to maintain and; expand. The first version of this redesign would try to:. * Discard functions, instructions and metadata that donâ€™t influence the; interesting-ness test; * Remove unused parameters from functions; * Eliminate unvisited conditional paths; * Rename variables to more regular ones (such as â€œaâ€, â€œbâ€, â€œcâ€, etc.). Once these passes are implemented, more meaningful reductions (such as type; reduction) would be added to the tool, to even further reduce IR. ## Background on historical bugpoint issues. ### Root Cause Analysis; Presently, bugpoint takes a long time to find the source problem in a given IR; file, mainly due to the fact that it tries to debug the input by running; various strategies to classify the bug, which in turn run multiple optimizer; and compilation passes over the input, taking up a lot of time. Furthermore,; when the IR crashes, it tries to reduce it by performing some sub-optimal; passes (e.g. a lot of unreachable blocks), and sometimes even fails to minimize; at all. ### ""Quirky"" Interface; Bugpointâ€™s current interface overwhelms and confuses the user, the help screen; alone ends up confusing rather providing guidance. And, not only are there; numerous features and options, but some of them also work in unexpected ways; and most of the time the user ends up using a custom script. Pruning and; simplifying the interface will be worth considering in order to make the tool; more useful in the general case and easier to maintain.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md:3398,reduce,reduce,3398,interpreter/llvm-project/llvm/docs/BugpointRedesign.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugpointRedesign.md,1,['reduce'],['reduce']
Energy Efficiency,"udo-register.; - ``y``: A 64-bit MMX register, if MMX is enabled.; - ``v``: If SSE is enabled: a 32 or 64-bit scalar operand, or 128-bit vector; operand in a SSE register. If AVX is also enabled, can also be a 256-bit; vector operand in an AVX register. If AVX-512 is also enabled, can also be a; 512-bit vector operand in an AVX512 register. Otherwise, an error.; - ``Ws``: A symbolic reference with an optional constant addend or a label; reference.; - ``x``: The same as ``v``, except that when AVX-512 is enabled, the ``x`` code; only allocates into the first 16 AVX-512 registers, while the ``v`` code; allocates into any of the 32 AVX-512 registers.; - ``Y``: The same as ``x``, if *SSE2* is enabled, otherwise an error.; - ``A``: Special case: allocates EAX first, then EDX, for a single operand (in; 32-bit mode, a 64-bit integer operand will get split into two registers). It; is not recommended to use this constraint, as in 64-bit mode, the 64-bit; operand will get allocated only to RAX -- if two 32-bit operands are needed,; you're better off splitting it yourself, before passing it to the asm; statement. XCore:. - ``r``: A 32-bit integer register. .. _inline-asm-modifiers:. Asm template argument modifiers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In the asm template string, modifiers can be used on the operand reference, like; ""``${0:n}``"". The modifiers are, in general, expected to behave the same way they do in; GCC. LLVM's support is often implemented on an 'as-needed' basis, to support C; inline asm code which was supported by GCC. A mismatch in behavior between LLVM; and GCC likely indicates a bug in LLVM. Target-independent:. - ``c``: Print an immediate integer constant unadorned, without; the target-specific immediate punctuation (e.g. no ``$`` prefix).; - ``n``: Negate and print immediate integer constant unadorned, without the; target-specific immediate punctuation (e.g. no ``$`` prefix).; - ``l``: Print as an unadorned label, without the target-specific label; punct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:234485,allocate,allocated,234485,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"ues for scientific; programming. We knew that there is no better way to learn a new; programming environment than to use it to write a program that can; solve a real problem. After a few weeks, we had our first; histogramming package in C++. A few weeks later we had a rewrite of; the same package using the, at that time, very new template features; of C++. Again, a few weeks later we had another rewrite of the package; without templates since we could only compile the version with; templates on one single platform using a specific compiler. Finally,; after about four months we had a histogramming package that was faster; and more efficient than the well-known FORTRAN based HBOOK; histogramming package. This gave us enough confidence in the new; technologies to decide to continue the development. Thus was born; ROOT. Since its first public release at the end of 1995, ROOT has; enjoyed an ever-increasing popularity. Currently it is being used in; all major High Energy and Nuclear Physics laboratories around the; world to monitor, to store and to analyse data. In the other sciences; as well as the medical and financial industries, many people are using; ROOT. We estimate the current user base to be around several thousand; people. In 1997, Eric Raymond analysed in his paper ""The Cathedral and; the Bazaar"" the development method that makes Linux such a success.; The essence of that method is: ""release early, release often and; listen to your customers"". This is precisely how ROOT is being; developed. Over the last five years, many of our ""customers"" became; co-developers. Here we would like to thank our main co-developers and; contributors:. **Masaharu Goto** wrote the C++ interpreter CINT that was an; essential part of ROOT before ROOT 6. Despite being 8 time zones ahead; of us, we have the feeling he has been sitting in the room next door; since 1995. **Andrei** and **Mihaela Gheata** (Alice collaboration) are co-authors; of the ROOT geometry classes and Virtual Monte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Preface.md:1211,monitor,monitor,1211,documentation/users-guide/Preface.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Preface.md,1,['monitor'],['monitor']
Energy Efficiency,"uests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:8080"");; ```. This will start civetweb-based http server on port 8080.; Then, one should be able to open address ""http://localhost:8080""; in any modern browser and browse objects created in application. By default, the server can access files, canvases and histograms via gROOT. All such objects can be displayed with JSRootIO graphics. At any time one could register other objects with the command:. ``` {.cpp}; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. If the object content is changing in the application, like for example histograms being continuously filled, one could enable the monitoring flag in the browser, then the object view will be regularly updated. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:3557,monitor,monitoring,3557,net/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md,1,['monitor'],['monitoring']
Energy Efficiency,"uild times and bug detection for; most buildbots. There may be room for including some debug info (e.g. with; `-gmlt`), but in general the balance between debug info quality and build; times is a delicate one. Use Ninja & LLD; Ninja really does help build times over Make, particularly for highly; parallel builds. LLD helps to reduce both link times and memory usage; during linking significantly. With a build machine with sufficient; parallelism, link times tend to dominate critical path of the build, and are; thus worth optimizing. Use CCache and NOT incremental builds; Using ccache materially improves average build times. Incremental builds; can be slightly faster, but introduce the risk of build corruption due to; e.g. state changes, etc... At this point, the recommendation is not to; use incremental builds and instead use ccache as the latter captures the; majority of the benefit with less risk of false positives. One of the non-obvious benefits of using ccache is that it makes the; builder less sensitive to which projects are being monitored vs built.; If a change triggers a build request, but doesn't change the build output; (e.g. doc changes, python utility changes, etc..), the build will entirely; hit in cache and the build request will complete in just the testing time. With multiple workers, it is tempting to try to configure a shared cache; between the workers. Experience to date indicates this is difficult to; well, and that having local per-worker caches gets most of the benefit; anyways. We don't currently recommend shared caches. CCache does depend on the builder hardware having sufficient IO to access; the cache with reasonable access times - i.e. a fast disk, or enough memory; for a RAM cache, etc.. For builders without, incremental may be your best; option, but is likely to require higher ongoing involvement from the; sponsor. Enable batch builds; As a last resort, you can configure your builder to batch build requests.; This makes the build failure ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:11560,monitor,monitored,11560,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['monitor'],['monitored']
Energy Efficiency,"uint NPar()`.; Example of creating a parametric function:. ```{.cpp}; #include ""Math/IFunction.h""; #include ""Math/IParamFunction.h"". class MyParametricFunction: public ROOT::Math::IParametricFunctionMultiDim; {; private:; const double* pars;. public:; double DoEvalPar(const double* x, const double* p) const; {; return p[0] * x[0] + sin(x[1]) + p[1];; }. unsigned int NDim() const; {; return 2;; }. ROOT::Math::IParametricFunctionMultiDim* Clone() const; {; return new MyParametricFunction();; }. const double* Parameters() const; {; return pars;; }. void SetParameters(const double* p); {; pars = p;; }. unsigned int NPar() const; {; return 2;; }; };; ```. * **`ROOT::Math::IParametricGradFunctionMultiDim`**:; Provides an interface for parametric gradient multi-dimensional functions. In addition to function evaluation it provides the gradient with respect to the parameters,; via the method `ParameterGradient()`. This interface is only used in case of some dedicated fitting algorithms, when is required or more efficient to provide derivatives with respect to the; parameters. Here is an example:. ```{.cpp}; #include ""Math/IFunction.h""; #include ""Math/IParamFunction.h"". class MyParametricGradFunction:; public ROOT::Math::IParametricGradFunctionMultiDim; {; private:; const double* pars;. public:; double DoEvalPar(const double* x, const double* p) const; {; return p[0] * x[0] + sin(x[1]) + p[1];; }. unsigned int NDim() const; {; return 2;; }. ROOT::Math::IParametricGradFunctionMultiDim* Clone() const; {; return new MyParametricGradFunction();; }. const double* Parameters() const; {; return pars;; }. void SetParameters(const double* p); {; pars = p;; }. unsigned int NPar() const; {; return 2;; }. double DoParameterDerivative(const double* x, const double* p,; unsigned int ipar) const; {; if ( ipar == 0 ); return sin(x[1]) + p[1];; else; return p[0] * x[0] + x[1] * cos(x[1]) + p[1];; }; };; ```. ### Wrapper Functions. To facilitate the user to insert their own type of function in ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:41111,efficient,efficient,41111,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['efficient'],['efficient']
Energy Efficiency,"ul>`) of the vector operand ``val``; on each enabled lane, multiplying it by the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``1`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is the; start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.mul.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 1, i32 1, i32 1, i32 1>; %reduction = call i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %masked.a); %also.r = mul i32 %reduction, %start. .. _int_vp_reduce_fmul:. '``llvm.vp.reduce.fmul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmul.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fmul.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MUL`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmul``' intrinsic performs the floating-point ``MUL``; reduction (:r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:754623,reduce,reduce,754623,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ularly useful for the staging buildmaster which is silent; otherwise. #. Send the buildbot-worker access name and the access password directly to; `Galina Kistanova <mailto:gkistanova@gmail.com>`_, and wait until she; lets you know that your changes are applied and buildmaster is; reconfigured. #. Make sure you can start the buildbot-worker and successfully connect; to the silent buildmaster. Then set up your buildbot-worker to start; automatically at the start up time. See the buildbot documentation; for help. You may want to restart your computer to see if it works. #. Check the status of your buildbot-worker on the `Waterfall Display (Staging); <http://lab.llvm.org/staging/#/waterfall>`_ to make sure it is; connected, and the `Workers Display (Staging); <http://lab.llvm.org/staging/#/workers>`_ to see if administrator; contact and worker information are correct. #. At this point, you have a working builder connected to the staging; buildmaster. You can now make sure it is reliably green and keeps; up with the build queue. No notifications will be sent, so you can; keep an unstable builder connected to staging indefinitely. #. (Optional) Once the builder is stable on the staging buildmaster with; several days of green history, you can choose to move it to the production; buildmaster to enable developer notifications. Please email `Galina; Kistanova <mailto:gkistanova@gmail.com>`_ for review and approval. To move a worker to production (once approved), stop your worker, edit the; buildbot.tac file to change the port number from 9994 to 9990 and start it; again. Best Practices for Configuring a Fast Builder; =============================================. As mentioned above, we generally have a strong preference for; builders which can build every commit as they come in. This section; includes best practices and some recommendations as to how to achieve; that end. The goal; In 2020, the monorepo had just under 35 thousand commits. This works; out to an average of 4 co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:7189,green,green,7189,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['green'],['green']
Energy Efficiency,"ules to nontrivial ownership qualifiers; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Nontrivially ownership-qualified types are considered non-trivial; to copy, destroy, and default-initialize. A dynamic object of nontrivially ownership-qualified type contingently; exists at a location if the memory is filled with a zero pattern, e.g.; by ``calloc`` or ``bzero``. Such an object can be safely accessed in; all of the cases above, but its memory can also be safely repurposed.; Assigning a null pointer into an l-value of ``__weak`` or; ``__strong``-qualified type accesses the dynamic object there (and thus; may have undefined behavior if no such object exists), but afterwards; the object's memory is guaranteed to be filled with a zero pattern; and thus may be either further accessed or repurposed as needed.; The upshot is that programs may safely initialize dynamically-allocated; memory for nontrivially ownership-qualified types by ensuring it is zero-initialized, and they may safely deinitialize memory before; freeing it by storing ``nil`` into any ``__strong`` or ``__weak``; references previously created in that memory. C/C++ compatibility for structs and unions with non-trivial members; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Structs and unions with non-trivial members are compatible in; different language modes (e.g. between Objective-C and Objective-C++,; or between ARC and non-ARC modes) under the following conditions:. - The types must be compatible ignoring ownership qualifiers according; to the baseline, non-ARC rules (e.g. C struct compatibility or C++'s; ODR). This condition implies a pairwise correspondence between; fields. Note that an Objective-C++ class with base classes, a user-provided; copy or move constructor, or a user-provided destructor is never; compatible with an Objective-C type. - If two fields correspond as above, and at least one of the fields is; ownership-qualified, then:. - the fields m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:60601,allocate,allocated,60601,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['allocate'],['allocated']
Energy Efficiency,"umber of alias queries. This can cause debugging techniques; involving pausing execution after a predetermined number of queries to be; unreliable. Many alias queries can be reformulated in terms of other alias queries. When; multiple ``AliasAnalysis`` queries are chained together, it would make sense to; start those queries from the beginning of the chain, with care taken to avoid; infinite looping, however currently an implementation which wants to do this can; only start such queries from itself. Using alias analysis results; ============================. There are several different ways to use alias analysis results. In order of; preference, these are:. Using the ``MemoryDependenceAnalysis`` Pass; -------------------------------------------. The ``memdep`` pass uses alias analysis to provide high-level dependence; information about memory-using instructions. This will tell you which store; feeds into a load, for example. It uses caching and other techniques to be; efficient, and is used by Dead Store Elimination, GVN, and memcpy optimizations. .. _AliasSetTracker:. Using the ``AliasSetTracker`` class; -----------------------------------. Many transformations need information about alias **sets** that are active in; some scope, rather than information about pairwise aliasing. The; `AliasSetTracker <https://llvm.org/doxygen/classllvm_1_1AliasSetTracker.html>`__; class is used to efficiently build these Alias Sets from the pairwise alias; analysis information provided by the ``AliasAnalysis`` interface. First you initialize the AliasSetTracker by using the ""``add``"" methods to add; information about various potentially aliasing instructions in the scope you are; interested in. Once all of the alias sets are completed, your pass should; simply iterate through the constructed alias sets, using the ``AliasSetTracker``; ``begin()``/``end()`` methods. The ``AliasSet``\s formed by the ``AliasSetTracker`` are guaranteed to be; disjoint, calculate mod/ref information and vo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:19736,efficient,efficient,19736,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['efficient'],['efficient']
Energy Efficiency,"umber of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:36768,schedul,scheduler,36768,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduler']
Energy Efficiency,umper.cpp; llvm/tools/llvm-pdbutil/MinimalTypeDumper.h; llvm/tools/llvm-pdbutil/PrettyBuiltinDumper.cpp; llvm/tools/llvm-pdbutil/PrettyEnumDumper.cpp; llvm/tools/llvm-pdbutil/PrettyExternalSymbolDumper.cpp; llvm/tools/llvm-pdbutil/PrettyTypeDumper.cpp; llvm/tools/llvm-pdbutil/TypeReferenceTracker.h; llvm/tools/llvm-pdbutil/YAMLOutputStyle.h; llvm/tools/llvm-profgen/CallContext.h; llvm/tools/llvm-profgen/CSPreInliner.cpp; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/del,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:336934,reduce,reduce,336934,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,umper.cpp; llvm/tools/llvm-pdbutil/TypeReferenceTracker.h; llvm/tools/llvm-pdbutil/YAMLOutputStyle.h; llvm/tools/llvm-profgen/CallContext.h; llvm/tools/llvm-profgen/CSPreInliner.cpp; llvm/tools/llvm-profgen/CSPreInliner.h; llvm/tools/llvm-profgen/llvm-profgen.cpp; llvm/tools/llvm-profgen/PerfReader.cpp; llvm/tools/llvm-profgen/PerfReader.h; llvm/tools/llvm-rc/ResourceScriptCppFilter.cpp; llvm/tools/llvm-rc/ResourceScriptCppFilter.h; llvm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGl,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337176,reduce,reduce,337176,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"unction, via pointer values not; *based* on the argument or return value. This guarantee only holds for; memory locations that are *modified*, by any means, during the execution of; the function. The attribute on a return value also has additional semantics; described below. The caller shares the responsibility with the callee for; ensuring that these requirements are met. For further details, please see; the discussion of the NoAlias response in :ref:`alias analysis <Must, May,; or No>`. Note that this definition of ``noalias`` is intentionally similar; to the definition of ``restrict`` in C99 for function arguments. For function return values, C99's ``restrict`` is not meaningful,; while LLVM's ``noalias`` is. Furthermore, the semantics of the ``noalias``; attribute on return values are stronger than the semantics of the attribute; when used on function arguments. On function return values, the ``noalias``; attribute indicates that the function acts like a system memory allocation; function, returning a pointer to allocated storage disjoint from the; storage for any other object accessible to the caller. .. _nocapture:. ``nocapture``; This indicates that the callee does not :ref:`capture <pointercapture>` the; pointer. This is not a valid attribute for return values.; This attribute applies only to the particular copy of the pointer passed in; this argument. A caller could pass two copies of the same pointer with one; being annotated nocapture and the other not, and the callee could validly; capture through the non annotated parameter. .. code-block:: llvm. define void @f(ptr nocapture %a, ptr %b) {; ; (capture %b); }. call void @f(ptr @glb, ptr @glb) ; well-defined. ``nofree``; This indicates that callee does not free the pointer argument. This is not; a valid attribute for return values. .. _nest:. ``nest``; This indicates that the pointer parameter can be excised using the; :ref:`trampoline intrinsics <int_trampoline>`. This is not a valid; attribute for return ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:59079,allocate,allocated,59079,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,unctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.cpp; llvm/tools/llvm-special-case-list-fuzzer/special-case-list-fuzzer.cpp; llvm/tools/llvm-strings/llvm-strings.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.cpp; llvm/tools/llvm-tapi-diff/DiffEngine.h; llvm/tools/llvm-tapi-diff/llvm-tapi-diff.cpp; llvm/tools/llvm-undname/llvm-undname.cpp; llvm/tools/llvm-xray/fu,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338731,reduce,reduce,338731,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"unning across processes on the same machine for security); via the host operating system's virtual memory management APIs. To satisfy these requirements ``JITLinkMemoryManager`` adopts the following; design: The memory manager itself has just two virtual methods for asynchronous; operations (each with convenience overloads for calling synchronously):. .. code-block:: c++. /// Called when allocation has been completed.; using OnAllocatedFunction =; unique_function<void(Expected<std::unique_ptr<InFlightAlloc>)>;. /// Called when deallocation has completed.; using OnDeallocatedFunction = unique_function<void(Error)>;. /// Call to allocate memory.; virtual void allocate(const JITLinkDylib *JD, LinkGraph &G,; OnAllocatedFunction OnAllocated) = 0;. /// Call to deallocate memory.; virtual void deallocate(std::vector<FinalizedAlloc> Allocs,; OnDeallocatedFunction OnDeallocated) = 0;. The ``allocate`` method takes a ``JITLinkDylib*`` representing the target; simulated dylib, a reference to the ``LinkGraph`` that must be allocated for,; and a callback to run once an ``InFlightAlloc`` has been constructed.; ``JITLinkMemoryManager`` implementations can (optionally) use the ``JD``; argument to manage a per-simulated-dylib memory pool (since code model; constraints are typically imposed on a per-dylib basis, and not across; dylibs) [2]_. The ``LinkGraph`` describes the object file that we need to; allocate memory for. The allocator must allocate working memory for all of; the Blocks defined in the graph, assign address space for each Block within the; executing processes memory, and update the Blocks' addresses to reflect this; assignment. Block content should be copied to working memory, but does not need; to be transferred to executor memory yet (that will be done once the content is; fixed up). ``JITLinkMemoryManager`` implementations can take full; responsibility for these steps, or use the ``BasicLayout`` utility to reduce; the task to allocating working and executor memory ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:27322,allocate,allocate,27322,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,2,['allocate'],"['allocate', 'allocated']"
Energy Efficiency,"untime provide :block-term:`copy` and; :block-term:`release` operations for Block references that create and,; in matched use, release allocated storage for referenced Blocks. The copy operation ``Block_copy()`` is styled as a function that takes; an arbitrary Block reference and returns a Block reference of the same; type. The release operation, ``Block_release()``, is styled as a; function that takes an arbitrary Block reference and, if dynamically; matched to a Block copy operation, allows recovery of the referenced; allocated memory. The ``__block`` Storage Qualifier; =================================. In addition to the new Block type we also introduce a new storage; qualifier, :block-term:`__block`, for local variables. [testme: a; __block declaration within a block literal] The ``__block`` storage; qualifier is mutually exclusive to the existing local storage; qualifiers auto, register, and static. [testme] Variables qualified by; ``__block`` act as if they were in allocated storage and this storage; is automatically recovered after last use of said variable. An; implementation may choose an optimization where the storage is; initially automatic and only ""moved"" to allocated (heap) storage upon; a Block_copy of a referencing Block. Such variables may be mutated as; normal variables are. In the case where a ``__block`` variable is a Block one must assume; that the ``__block`` variable resides in allocated storage and as such; is assumed to reference a Block that is also in allocated storage; (that it is the result of a ``Block_copy`` operation). Despite this; there is no provision to do a ``Block_copy`` or a ``Block_release`` if; an implementation provides initial automatic storage for Blocks. This; is due to the inherent race condition of potentially several threads; trying to update the shared variable and the need for synchronization; around disposing of older values and copying new ones. Such; synchronization is beyond the scope of this language specificat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:7295,allocate,allocated,7295,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['allocate'],['allocated']
Energy Efficiency,"upported for RooArgLists anymore, since hash-assisted finding by name hash can be ambiguous: a RooArgList is allowed to have different elements with the same name. If you want to do fast lookups by name, convert your RooArgList to a RooArgSet. * The function `RooFit::bindFunction()` now supports arbitrary many input variables when binding a Python function. * The `ExportOnly()` attribute of the `RooStats::HistFactory::Measurement` object is now switched on by default, and the associated getter and setter functions are deprecated. They will be removed in ROOT 6.36. If you want to fit the model as well instead of just exporting it to a RooWorkspace, please do so with your own code as demonstrated in the `hf001` tutorial. ### Deprecations. * The `RooStats::MarkovChain::GetAsDataSet` and `RooStats::MarkovChain::GetAsDataHist` functions are deprecated and will be removed in ROOT 6.36. The same functionality can be implemented by calling `RooAbsData::reduce` on the Markov Chain's `RooDataSet*` (obtained using `MarkovChain::GetAsConstDataSet`) and then obtaining its binned clone(for `RooDataHist`). An example in Python would be:. ```py; mcInt = mc.GetInterval() # Obtain the MCMCInterval from a configured MCMCCalculator; mkc = mcInt.GetChain() # Obtain the MarkovChain; mkcData = mkc.GetAsConstDataSet(); mcIntParams = mcInt.GetParameters(). chainDataset = mkcData.reduce(SelectVars=mcIntParams, EventRange=(mcInt.GetNumBurnInSteps(), mkc.Size())); chainDataHist = chainDataset.binnedClone(); ```. * The following methods related to the RooAbsArg interface are deprecated and will be removed in ROOT 6.36.; They should be replaced with the suitable alternatives interfaces:. - `RooAbsArg::getDependents()`: use `getObservables()`; - `RooAbsArg::dependentOverlaps()`: use `observableOverlaps()`; - `RooAbsArg::checkDependents()`: use `checkObservables()`; - `RooAbsArg::recursiveCheckDependents()`: use `recursiveCheckObservables()`. ## Graphics Backends. ## 2D Graphics Libraries. ## 3D G",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md:5741,reduce,reduce,5741,README/ReleaseNotes/v634/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v634/index.md,1,['reduce'],['reduce']
Energy Efficiency,urceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/too,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337717,reduce,reduce,337717,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"urn 1;; else; static_assert(!VarTempl<T>);; }. Turn Predicate Loops into Predicate Functions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. It is very common to write small loops that just compute a boolean value. There; are a number of ways that people commonly write these, but an example of this; sort of thing is:. .. code-block:: c++. bool FoundFoo = false;; for (unsigned I = 0, E = BarList.size(); I != E; ++I); if (BarList[I]->isFoo()) {; FoundFoo = true;; break;; }. if (FoundFoo) {; ...; }. Instead of this sort of loop, we prefer to use a predicate function (which may; be `static`_) that uses `early exits`_:. .. code-block:: c++. /// \returns true if the specified list has an element that is a foo.; static bool containsFoo(const std::vector<Bar*> &List) {; for (unsigned I = 0, E = List.size(); I != E; ++I); if (List[I]->isFoo()); return true;; return false;; }; ... if (containsFoo(BarList)) {; ...; }. There are many reasons for doing this: it reduces indentation and factors out; code which can often be shared by other code that checks for the same predicate.; More importantly, it *forces you to pick a name* for the function, and forces; you to write a comment for it. In this silly example, this doesn't add much; value. However, if the condition is complex, this can make it a lot easier for; the reader to understand the code that queries for this predicate. Instead of; being faced with the in-line details of how we check to see if the BarList; contains a foo, we can trust the function name and continue reading with better; locality. The Low-Level Issues; --------------------. Name Types, Functions, Variables, and Enumerators Properly; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Poorly-chosen names can mislead the reader and cause bugs. We cannot stress; enough how important it is to use *descriptive* names. Pick names that match; the semantics and role of the underlying entities, within reason. Avoid; abbreviations unless they are well known. Af",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:41277,reduce,reduces,41277,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['reduce'],['reduces']
Energy Efficiency,"urth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.and``' intrinsic performs the integer ``AND`` reduction; (:ref:`llvm.vector.reduce.and <int_vector_reduce_and>`) of the vector operand; ``val`` on each enabled lane, performing an '``and``' of that with with the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %masked.a); %also.r = and i32 %reduction, %start. .. _int_vp_reduce_or:. '``llvm.vp.reduce.or.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.or.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.or.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``OR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:758606,reduce,reduce,758606,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"us this code:. bb:		; preds = %bb2, %entry; 	%.rle = phi i32 [ 0, %entry ], [ %.rle6, %bb2 ]	; 	%i.05 = phi i32 [ 0, %entry ], [ %indvar.next, %bb2 ]; 	%1 = load i32* %cond, align 4; 	%2 = icmp eq i32 %1, 0; 	br i1 %2, label %bb2, label %bb1. bb1:		; preds = %bb; 	%3 = xor i32 %.rle, 234	; 	store i32 %3, i32* %res, align 4; 	br label %bb2. bb2:		; preds = %bb, %bb1; 	%.rle6 = phi i32 [ %3, %bb1 ], [ %.rle, %bb ]	; 	%indvar.next = add i32 %i.05, 1	; 	%exitcond = icmp eq i32 %indvar.next, %n; 	br i1 %exitcond, label %return, label %bb. DSE should sink partially dead stores to get the store out of the loop. Here's another partial dead case:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12395. //===---------------------------------------------------------------------===//. Scalar PRE hoists the mul in the common block up to the else:. int test (int a, int b, int c, int g) {; int d, e;; if (a); d = b * c;; else; d = b - c;; e = b * c + g;; return d + e;; }. It would be better to do the mul once to reduce codesize above the if.; This is GCC PR38204. //===---------------------------------------------------------------------===//; This simple function from 179.art:. int winner, numf2s;; struct { double y; int reset; } *Y;. void find_match() {; int i;; winner = 0;; for (i=0;i<numf2s;i++); if (Y[i].y > Y[winner].y); winner =i;; }. Compiles into (with clang TBAA):. for.body: ; preds = %for.inc, %bb.nph; %indvar = phi i64 [ 0, %bb.nph ], [ %indvar.next, %for.inc ]; %i.01718 = phi i32 [ 0, %bb.nph ], [ %i.01719, %for.inc ]; %tmp4 = getelementptr inbounds %struct.anon* %tmp3, i64 %indvar, i32 0; %tmp5 = load double* %tmp4, align 8, !tbaa !4; %idxprom7 = sext i32 %i.01718 to i64; %tmp10 = getelementptr inbounds %struct.anon* %tmp3, i64 %idxprom7, i32 0; %tmp11 = load double* %tmp10, align 8, !tbaa !4; %cmp12 = fcmp ogt double %tmp5, %tmp11; br i1 %cmp12, label %if.then, label %for.inc. if.then: ; preds = %for.body; %i.017 = trunc i64 %indvar to i32; br label %for.inc. for.inc: ; pre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:29658,reduce,reduce,29658,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['reduce'],['reduce']
Energy Efficiency,"use ICM, STCM, or CLM. --. We don't use ADD (LOGICAL) HIGH, SUBTRACT (LOGICAL) HIGH,; or COMPARE (LOGICAL) HIGH yet. --. DAGCombiner doesn't yet fold truncations of extended loads. Functions like:. unsigned long f (unsigned long x, unsigned short *y); {; return (x << 32) | *y;; }. therefore end up as:. sllg %r2, %r2, 32; llgh %r0, 0(%r3); lr %r2, %r0; br %r14. but truncating the load would give:. sllg %r2, %r2, 32; lh %r2, 0(%r3); br %r14. --. Functions like:. define i64 @f1(i64 %a) {; %and = and i64 %a, 1; ret i64 %and; }. ought to be implemented as:. lhi %r0, 1; ngr %r2, %r0; br %r14. but two-address optimizations reverse the order of the AND and force:. lhi %r0, 1; ngr %r0, %r2; lgr %r2, %r0; br %r14. CodeGen/SystemZ/and-04.ll has several examples of this. --. Out-of-range displacements are usually handled by loading the full; address into a register. In many cases it would be better to create; an anchor point instead. E.g. for:. define void @f4a(i128 *%aptr, i64 %base) {; %addr = add i64 %base, 524288; %bptr = inttoptr i64 %addr to i128 *; %a = load volatile i128 *%aptr; %b = load i128 *%bptr; %add = add i128 %a, %b; store i128 %add, i128 *%aptr; ret void; }. (from CodeGen/SystemZ/int-add-08.ll) we load %base+524288 and %base+524296; into separate registers, rather than using %base+524288 as a base for both. --. Dynamic stack allocations round the size to 8 bytes and then allocate; that rounded amount. It would be simpler to subtract the unrounded; size from the copy of the stack pointer and then align the result.; See CodeGen/SystemZ/alloca-01.ll for an example. --. If needed, we can support 16-byte atomics using LPQ, STPQ and CSDG. --. We might want to model all access registers and use them to spill; 32-bit values. --. We might want to use the 'overflow' condition of eg. AR to support; llvm.sadd.with.overflow.i32 and related instructions - the generated code; for signed overflow check is currently quite bad. This would improve; the results of using -ftrapv.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt:3254,allocate,allocate,3254,interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt,2,['allocate'],['allocate']
Energy Efficiency,"utable to another machine,; the ASan library will also need to be copied over. Symbolizing the Reports; =========================. To make AddressSanitizer symbolize its output; you need to set the ``ASAN_SYMBOLIZER_PATH`` environment variable to point to; the ``llvm-symbolizer`` binary (or make sure ``llvm-symbolizer`` is in your; ``$PATH``):. .. code-block:: console. % ASAN_SYMBOLIZER_PATH=/usr/local/bin/llvm-symbolizer ./a.out; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; 0x7f7ddab8c084 is located 4 bytes inside of 400-byte region [0x7f7ddab8c080,0x7f7ddab8c210); freed by thread T0 here:; #0 0x404704 in operator delete[](void*) ??:0; #1 0x403c53 in main example_UseAfterFree.cc:4; #2 0x7f7ddabcac4d in __libc_start_main ??:0; previously allocated by thread T0 here:; #0 0x404544 in operator new[](unsigned long) ??:0; #1 0x403c43 in main example_UseAfterFree.cc:2; #2 0x7f7ddabcac4d in __libc_start_main ??:0; ==9442== ABORTING. If that does not work for you (e.g. your process is sandboxed), you can use a; separate script to symbolize the result offline (online symbolization can be; force disabled by setting ``ASAN_OPTIONS=symbolize=0``):. .. code-block:: console. % ASAN_OPTIONS=symbolize=0 ./a.out 2> log; % projects/compiler-rt/lib/asan/scripts/asan_symbolize.py / < log | c++filt; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; ---------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:4282,allocate,allocated,4282,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['allocate'],['allocated']
Energy Efficiency,utes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/tools/llvm-reduce/deltas/ReduceModuleData.h; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandBundles.h; llvm/tools/llvm-reduce/deltas/ReduceOperands.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperands.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsSkip.h; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.cpp; llvm/tools/llvm-reduce/deltas/ReduceOperandsToArgs.h; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.cpp; llvm/tools/llvm-reduce/deltas/ReduceSpecialGlobals.h; llvm/tools/llvm-rust-demangle-fuzzer/DummyDemanglerFuzzer.cpp; llvm/tools/llvm-rust-demangle-fuzzer/llvm-rust-demangle-fuzzer.cpp; llvm/tools/llvm-shlib/libllvm.cpp; llvm/tools/llvm-special-case-list-fuzzer/DummySpecialCaseListFuzzer.c,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:338420,reduce,reduce,338420,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"v16p0(<16 x ptr> <ptrs>, i32 <alignment>, <16 x i1> <mask>, <16 x float> <passthru>); declare <2 x double> @llvm.masked.gather.v2f64.v2p1(<2 x ptr addrspace(1)> <ptrs>, i32 <alignment>, <2 x i1> <mask>, <2 x double> <passthru>); declare <8 x ptr> @llvm.masked.gather.v8p0.v8p0(<8 x ptr> <ptrs>, i32 <alignment>, <8 x i1> <mask>, <8 x ptr> <passthru>). Overview:; """""""""""""""""". Reads scalar values from arbitrary memory locations and gathers them into one vector. The memory locations are provided in the vector of pointers '``ptrs``'. The memory is accessed according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. The masked-off lanes in the result vector are taken from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is a vector of pointers which holds all memory addresses to read. The second operand is an alignment of the source addresses. It must be 0 or a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the vector of pointers and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.gather``' intrinsic is designed for conditional reading of multiple scalar values from arbitrary memory locations in a single IR operation. It is useful for targets that support vector masked gathers and allows vectorizing basic blocks with data and control divergence. Other targets may support this intrinsic differently, for example by lowering it into a sequence of scalar load operations.; The semantics of this operation are equivalent to a sequence of conditional scalar loads with subsequent gathering all loaded values into a single vector. The mask restricts memory access to certain lanes ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:849701,power,power,849701,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"value, and return a; false predicate if the loop should exit, and true otherwise.; This is emitted if the loop counter is not updated via a ``PHI`` node, which; can also be controlled with an option. Arguments:; """""""""""""""""""". The integer argument is the loop decrement value used to decrement the loop; iteration counter. Semantics:; """""""""""""""""""". The '``llvm.loop.decrement.*``' intrinsics do a ``SUB`` of the loop iteration; counter with the given loop decrement value, and return false if the loop; should exit, this ``SUB`` is not allowed to wrap. The result is a condition; that is used by the conditional branch controlling the loop. Vector Reduction Intrinsics; ---------------------------. Horizontal reductions of vectors can be expressed using the following; intrinsics. Each one takes a vector operand as an input and applies its; respective operation across all elements of the vector, returning a single; scalar result of the same element type. .. _int_vector_reduce_add:. '``llvm.vector.reduce.add.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %a); declare i64 @llvm.vector.reduce.add.v2i64(<2 x i64> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.add.*``' intrinsics do an integer ``ADD``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fadd:. '``llvm.vector.reduce.fadd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fadd.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fadd.*``' intrinsics do a floating-point; ``ADD`` reduction of a vector, returning the result as a scalar. The return type; matches the element-t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:650400,reduce,reduce,650400,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False âˆ’ Print method-specific help message. CreateMVAPdfs No False âˆ’ Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False âˆ’ Events with negative weights are ignored in the training (but are included for testing and performance evaluation). VolumeRangeMode No Adaptive Unscaled, MinMax, RMS, Adaptive, kNN Method to determine volume size. KernelEstimator No Box Box, Sphere, Teepee, Gauss, Sinc3, Sinc5, Sinc7, Sinc9, Sinc11, Lanczos2, Lanczos3, Lanczos5, Lanczos8, Trim Kernel estimation function. DeltaFrac No 3 âˆ’ nEventsMin/Max for minmax and rms volume range. NEventsMin No 100 âˆ’ nEventsMin for adaptive volume range. NEventsMax No 200 âˆ’ nEventsMax for adaptive volume range. MaxVIterations No 150 âˆ’ MaxVIterations for adaptive volume range. InitialScale No 0.99 âˆ’ InitialScale for adaptive volume range. GaussSigma No 0.1 âˆ’ Width (wrt volume size) of Gaussian kernel estimator. NormTree No False âˆ’ Normalize binary search tree. Configuration options for MVA method :. Configuration options reference for MVA method: FDA. Option Array Default value Predefined values Description. V No False âˆ’ Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None âˆ’ List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False âˆ’ Print method-specific help mes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:4783,adapt,adaptive,4783,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['adapt'],['adaptive']
Energy Efficiency,"ve:. $ clang -cc1 -ast-dump test.c. To view/dump CFG use debug.ViewCFG or debug.DumpCFG; checkers:. $ clang -cc1 -analyze -analyzer-checker=debug.ViewCFG test.c. ExplodedGraph (the state graph explored by the analyzer) can be; visualized with another debug checker:. $ clang -cc1 -analyze -analyzer-checker=debug.ViewExplodedGraph test.c. Or, equivalently, with -analyzer-viz-egraph-graphviz; option, which does the same thing - dumps the exploded graph in graphviz; .dot format.; You can convert .dot files into other formats - in; particular, converting to .svg and viewing in your web; browser might be more comfortable than using a .dot viewer:. $ dot -Tsvg ExprEngine-501e2e.dot -o ExprEngine-501e2e.svg. The -trim-egraph option removes all paths except those; leading to bug reports from the exploded graph dump. This is useful; because exploded graphs are often huge and hard to navigate.; Viewing ExplodedGraph is your most powerful tool for understanding; the analyzer's false positives, because it gives comprehensive information; on every decision made by the analyzer across all analysis paths.; There are more debug checkers available. To see all available debug checkers:. $ clang -cc1 -analyzer-checker-help | grep ""debug"". Debug Prints and Tricks; To view ""half-baked"" ExplodedGraph while debugging, jump to a frame; that has clang::ento::ExprEngine object and execute:. (gdb) p ViewGraph(0). To see the ProgramState while debugging use the following command. (gdb) p State->dump(). To see clang::Expr while debugging use the following command. If you; pass in a SourceManager object, it will also dump the corresponding line in the; source code. (gdb) p E->dump(). To dump AST of a method that the current ExplodedNode belongs; to:. (gdb) p C.getPredecessor()->getCodeDecl().getBody()->dump(). Making Your Checker Better. User facing documentation is important for adoption! Make sure the checker list is updated; at the homepage of the analyzer. Also ensure the description is clear ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html:22003,power,powerful,22003,interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,2,['power'],['powerful']
Energy Efficiency,"vect[kX] + (f1*vect[kPX] - f2*vect[kPY]);; vout[kY] = vect[kY] + (f1*vect[kPY] + f2*vect[kPX]);; vout[kZ] = vect[kZ] + (f1*vect[kPZ] + f3);; vout[kPX] = vect[kPX] + (f4*vect[kPX] - f5*vect[kPY]);; vout[kPY] = vect[kPY] + (f4*vect[kPY] + f5*vect[kPX]);; vout[kPZ] = vect[kPZ] + (f4*vect[kPZ] + f6);; }; ```. ### Writing the Tree. ``` {.cpp}; void tree2w() {; // write tree2 example; //create a Tree file tree2.root; TFile f(""tree2.root"",""recreate"");. //create the file, the Tree; TTree t2(""t2"",""a Tree with data from a fake Geant3"");; // declare a variable of the C structure type; Gctrak_t gstep;. // add the branches for a subset of gstep; t2.Branch(""vect"",gstep.vect,""vect[7]/F"");; t2.Branch(""getot"",&gstep.getot,""getot/F"");; t2.Branch(""gekin"",&gstep.gekin,""gekin/F"");; t2.Branch(""nmec"",&gstep.nmec,""nmec/I"");; t2.Branch(""lmec"",gstep.lmec,""lmec[nmec]/I"");; t2.Branch(""destep"",&gstep.destep,""destep/F"");; t2.Branch(""pid"",&gstep.pid,""pid/I"");. //Initialize particle parameters at first point; Float_t px,py,pz,p,charge=0;; Float_t vout[7];; Float_t mass = 0.137;; Bool_t newParticle = kTRUE;; gstep.step = 0.1;; gstep.destep = 0;; gstep.nmec = 0;; gstep.pid = 0;. //transport particles; for (Int_t i=0; i<10000; i++) {; //generate a new particle if necessary (Geant3 emulation); if (newParticle) {; px = gRandom->Gaus(0,.02);; py = gRandom->Gaus(0,.02);; pz = gRandom->Gaus(0,.02);; p = TMath::Sqrt(px*px+py*py+pz*pz);; charge = 1;; if (gRandom->Rndm() < 0.5) charge = -1;; gstep.pid += 1;; gstep.vect[0] = 0;; gstep.vect[1] = 0;; gstep.vect[2] = 0;; gstep.vect[3] = px/p;; gstep.vect[4] = py/p;; gstep.vect[5] = pz/p;; gstep.vect[6] = p*charge;; gstep.getot = TMath::Sqrt(p*p + mass*mass);; gstep.gekin = gstep.getot - mass;; newParticle = kFALSE;; }; // fill the Tree with current step parameters; t2.Fill();. //transport particle in magnetic field (Geant3 emulation); helixStep(gstep.step, gstep.vect, vout);; //make one step; //apply energy loss; gstep.destep = gstep.step*gRandom->Gaus(0.0002,0.0",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:46138,charge,charge,46138,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['charge'],['charge']
Energy Efficiency,"vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmax``' intrinsic performs the floating-point ``MAX``; reduction (:ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>`) of the; vector operand ``val`` on each enabled lane, taking the maximum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``-QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the smallest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``-Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>` intrinsic (and thus the; '``llvm.maxnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmax.v4f32(float %float, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float QNAN, float QNAN, float QNAN, float QNAN>; %reduction = call float @llvm.vector.reduce.fmax.v4f32(<4 x float> %masked.a); %also.r = call float @llvm.maxnum.f32(float %reduction, float %start). .. _int_vp_reduce_fmin:. '``llvm.vp.reduce.fmin.*``'",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:772906,reduce,reduce,772906,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"ved in ROOT 6.34:. * RooAbsTestStatistic; * RooAbsOptTestStatistic; * RooNLLVar; * RooChi2Var; * RooXYChi2Var. Please use the higher-level functions `RooAbsPdf::createNLL()` and `RooAbsPdf::createChi2()` if you want to create objects that represent test statistics. ### Change of RooParamHistFunc. The `RooParamHistFunc` didn't take any observable `RooRealVar` as constructor; argument. It assumes as observable the internal variables in the passed; RooDataHist. This means it was in most contexts unusable, because the input; can't be changed, other than loading a different bin in the dataset. Furthermore, there was actually a constructor that took a `RooAbsArg x`, but it; was simply ignored. To fix all these problems, the existing constructors were replaced by a new one; that takes the observable explicitly. Since the old constructors resulted in wrong computation graphs that caused; trouble with the new CPU evaluation backend, they had to be removed without; deprecation. Please adapt your code if necessary. ### Renaming of some RooFit classes. The `RooPower` was renamed to `RooPowerSum`, and `RooExpPoly` was renamed to `RooLegacyExpPoly`. This was a necessary change, because the names of these classes introduced in ROOT 6.28 collided with some classes in CMS combine, which were around already long before. Therefore, the classes had to be renamed to not cause any problems for CMS. In the unlikeliy case where you should have used these new classes for analysis already, please adapt your code to the new names and re-create your workspaces. ## RDataFrame. * The `RDataFrame` constructors that take in input one or more file names (or globs thereof) will now infer the format of the dataset, either `TTree` or `RNTuple`, that is stored in the first input file. When multiple files are specified, it is assumed that all other files contain a coherent dataset of the same format and with the same schema, exactly as it used to happen with `TChain`. This automatic inference further con",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:13869,adapt,adapt,13869,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['adapt'],['adapt']
Energy Efficiency,"very simple command, well known by now: fit the; function to the histogram. - Lines *42-46*: Retrieve the output from the fit. Here, we simply; print the fit result and access and print the covariance matrix of; the parameters. - Lines *54-end*: Plot the pseudo-data, the fitted function and the; signal and background components at the best-fit values. [f61]: figures/functions.png ""f61""; <a name=""f61""></a>. ![Fit of pseudo data: a signal shape over a background trend. This plot; is another example of how making a plot ""self-explanatory"" can help you; better displaying your results. \label{f61}][f61]. ## Toy Monte Carlo Experiments ##. Let us look at a simple example of a toy experiment comparing two; methods to fit a function to a histogram, the $\chi^{2}$. method and a method called ""binned log-likelihood fit"", both available in ROOT. As a very simple yet powerful quantity to check the quality of the fit; results, we construct for each pseudo-data set the so-called ""pull"", the; difference of the estimated and the true value of a parameter,; normalised to the estimated error on the parameter,; $\frac{(p_{estim} - p_{true})}{\sigma_{p}}$. If everything is OK, the; distribution of the pull values is a standard normal distribution, i.e.; a Gaussian distribution centred around zero with a standard deviation of one. The macro performs a rather big number of toy experiments, where a; histogram is repeatedly filled with Gaussian distributed numbers,; representing the pseudo-data in this example. Each time, a fit is; performed according to the selected method, and the pull is calculated; and filled into a histogram. Here is the code:. ``` {.cpp .numberLines}; @ROOT_INCLUDE_FILE macros/macro9.C; ```. Your present knowledge of ROOT should be enough to understand all the; technicalities behind the macro. Note that the variable `pull` in line; *61* is different from the definition above: instead of the parameter; error on `mean`, the fitted standard deviation of the distribution",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md:4274,power,powerful,4274,documentation/primer/functions_and_parameter_estimation.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md,1,['power'],['powerful']
Energy Efficiency,"ves. checker-271; built: February 8, 2013; highlights:. Faster analysis for scan-build xcodebuild when using Xcode 4.6 and higher:; ; scan-build now uses Xcode's built-in interposition mechanism for the static analyzer to provide faster builds while doing static analysis (PCH files are now built).; This change also allows scan-build to have better support for iOS project analysis without having to specifying weird SDK settings to scan-build. Better diagnostics for implicitly-defined member functions in C++.; New warning for malloc/free checker when passing malloc'ed pointer with non-zero offset to free().; Fixes for misc. parser crashes.; Newer than the static analyzer version in Xcode 4.6. checker-270; built: January 4, 2013; highlights:. Major performance enhancements to speed up interprocedural analysis.; Misc. bug fixes. checker-269; built: September 25, 2012; highlights:. Significantly improves interprocedural analysis for Objective-C.; Numerous bug fixes and heuristics to reduce false positives reported; 			over checker-268. checker-268; built: September 11, 2012; highlights:. Adds initial interprocedural analysis support for C++ and Objective-C. This will greatly improve analysis coverage and find deeper bugs in Objective-C and C++ code.; Contains a static analyzer newer than Xcode 4.4. NOTE: this checker build includes a huge number of changes. It has the potential to find many more bugs, but may report new kinds of false positives. We'd like to know about; these, and any other problems you encounter. When you encounter an issue, please file a bug report.; checker-267; built: June 1, 2012; highlights:; Adds basic interprocedural analysis support for blocks.; checker-266; built: May 23, 2012; highlights:; Contains numerous stability fixes over checker-266, especially when analyzing C++11 code.; checker-265; built: May 8, 2012; highlights:; This release contains a fix for a major crasher introduced in checker-264, and various refinements to; improve the precis",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:6532,reduce,reduce,6532,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,2,['reduce'],['reduce']
Energy Efficiency,"vm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :program:`llvm-mca` comes with several Views such as the Timeline View and; Summary View. These Views are generic and can work with most (if not all); targets. If you wish to add a new View to :program:`llvm-mca` and it does not; require any backend functionality that is not already exposed through MC layer; classes (MCSubtargetInfo, MCInstrInfo, etc.), please add it to the; `/tools/llvm-mca/View/` directory. However, if your new View is target specific; AND requires unexposed backend symbols or functionality, you can define it in; the `/lib/Target/<TargetName>/MCA/` directory. To enable this target specific View, you will have to use this target's; CustomBehaviour class to override the `CustomBehaviour::getViews()` methods.; There are 3 variations of these methods based on where you want your View to; appear in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:46603,schedul,scheduling,46603,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['schedul'],['scheduling']
Energy Efficiency,vm/tools/llvm-rc/ResourceScriptParser.h; llvm/tools/llvm-rc/ResourceScriptStmt.cpp; llvm/tools/llvm-rc/ResourceScriptToken.h; llvm/tools/llvm-rc/ResourceVisitor.h; llvm/tools/llvm-readobj/ObjDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.cpp; llvm/tools/llvm-readobj/WindowsResourceDumper.h; llvm/tools/llvm-reduce/DeltaManager.cpp; llvm/tools/llvm-reduce/DeltaManager.h; llvm/tools/llvm-reduce/ReducerWorkItem.cpp; llvm/tools/llvm-reduce/ReducerWorkItem.h; llvm/tools/llvm-reduce/TestRunner.cpp; llvm/tools/llvm-reduce/TestRunner.h; llvm/tools/llvm-reduce/deltas/Delta.cpp; llvm/tools/llvm-reduce/deltas/Delta.h; llvm/tools/llvm-reduce/deltas/ReduceAliases.cpp; llvm/tools/llvm-reduce/deltas/ReduceAliases.h; llvm/tools/llvm-reduce/deltas/ReduceArguments.h; llvm/tools/llvm-reduce/deltas/ReduceAttributes.cpp; llvm/tools/llvm-reduce/deltas/ReduceAttributes.h; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.cpp; llvm/tools/llvm-reduce/deltas/ReduceBasicBlocks.h; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctionBodies.h; llvm/tools/llvm-reduce/deltas/ReduceFunctions.cpp; llvm/tools/llvm-reduce/deltas/ReduceFunctions.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalObjects.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalValues.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVarInitializers.h; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.cpp; llvm/tools/llvm-reduce/deltas/ReduceGlobalVars.h; llvm/tools/llvm-reduce/deltas/ReduceInstructions.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructions.h; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.cpp; llvm/tools/llvm-reduce/deltas/ReduceInstructionsMIR.h; llvm/tools/llvm-reduce/deltas/ReduceMetadata.cpp; llvm/tools/llvm-reduce/deltas/ReduceMetadata.h; llvm/tools/llvm-reduce/deltas/ReduceModuleData.cpp; llvm/t,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:337607,reduce,reduce,337607,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['reduce'],['reduce']
Energy Efficiency,"we do *not* want; ""``int*``""). In order to provide all of this, ``Type`` has a; ``getAsPointerType()`` method that checks whether the type is structurally a; ``PointerType`` and, if so, returns the best one. If not, it returns a null; pointer. This structure is somewhat mystical, but after meditating on it, it will make; sense to you :). .. _QualType:. The ``QualType`` class; ----------------------. The ``QualType`` class is designed as a trivial value class that is small,; passed by-value and is efficient to query. The idea of ``QualType`` is that it; stores the type qualifiers (``const``, ``volatile``, ``restrict``, plus some; extended qualifiers required by language extensions) separately from the types; themselves. ``QualType`` is conceptually a pair of ""``Type*``"" and the bits; for these type qualifiers. By storing the type qualifiers as bits in the conceptual pair, it is extremely; efficient to get the set of qualifiers on a ``QualType`` (just return the field; of the pair), add a type qualifier (which is a trivial constant-time operation; that sets a bit), and remove one or more type qualifiers (just return a; ``QualType`` with the bitfield set to empty). Further, because the bits are stored outside of the type itself, we do not need; to create duplicates of types with different sets of qualifiers (i.e. there is; only a single heap allocated ""``int``"" type: ""``const int``"" and ""``volatile; const int``"" both point to the same heap allocated ""``int``"" type). This; reduces the heap size used to represent bits and also means we do not have to; consider qualifiers when uniquing types (:ref:`Type <Type>` does not even; contain qualifiers). In practice, the two most common type qualifiers (``const`` and ``restrict``); are stored in the low bits of the pointer to the ``Type`` object, together with; a flag indicating whether extended qualifiers are present (which must be; heap-allocated). This means that ``QualType`` is exactly the same size as a; pointer. .. _Declara",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:67009,efficient,efficient,67009,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['efficient'],['efficient']
Energy Efficiency,"what your class is; supposed to do as a free function in [MathFuncs].; This implementation must be compatible with the syntax supported by Clad. **2. Refactor evaluate():** Refactor the existing `RooAbsReal::evaluate()`; function to use the `MathFuncs.h` implementation. This is optional, but; can reduce code duplication and potential for bugs. This may require some; effort if an extensive caching infrastructure is used in your model. **3. Add translate():** RooFit classes are extended using a (typically) simple; `translate()` function that extracts the mathematically differentiable; properties out of the RooFit classes that make up the statistical model. The `translate()` function helps implement the Code Squashing logic that is; used to optimize numerical evaluations. It accomplishes this by using a small; subset of helper functions that are available in the; `RooFit::Detail::CodeSquashContext` and `RooFuncWrapper` classes; (see Appendix B). It converts a RooFit expression into a form that can be; efficiently evaluated by Clad. The `translate()` function returns an `std::string` representing the; underlying mathematical notation of the class as code, that can later be; concatenated into a single string representing the entire model. This string; of code is then just-in-time compiled by Cling (a C++ interpreter for Root). **4. analyticalIntegral() Use Case:** If your class includes (or should; include) the `analyticalIntegral()` function, then a simple; `buildCallToAnalyticIntegral()` function needs to be created to help call the; `analyticalIntegral()` function. # Example for adding Code Generation support to RooFit classes. Let us take the `RooPoisson.cxx` class as an example. > [roofit/roofit/src/RooPoisson.cxx](https://github.com/root-project/root/blob/master/roofit/roofit/src/RooPoisson.cxx). First step is to locate the `RooPoisson::evaluate()` function. Most RooFit; classes implement this function. > RooFit internally calls the `evaluate()` function to evaluat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:8686,efficient,efficiently,8686,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['efficient'],['efficiently']
Energy Efficiency,"when allocation has been completed.; using OnAllocatedFunction =; unique_function<void(Expected<std::unique_ptr<InFlightAlloc>)>;. /// Called when deallocation has completed.; using OnDeallocatedFunction = unique_function<void(Error)>;. /// Call to allocate memory.; virtual void allocate(const JITLinkDylib *JD, LinkGraph &G,; OnAllocatedFunction OnAllocated) = 0;. /// Call to deallocate memory.; virtual void deallocate(std::vector<FinalizedAlloc> Allocs,; OnDeallocatedFunction OnDeallocated) = 0;. The ``allocate`` method takes a ``JITLinkDylib*`` representing the target; simulated dylib, a reference to the ``LinkGraph`` that must be allocated for,; and a callback to run once an ``InFlightAlloc`` has been constructed.; ``JITLinkMemoryManager`` implementations can (optionally) use the ``JD``; argument to manage a per-simulated-dylib memory pool (since code model; constraints are typically imposed on a per-dylib basis, and not across; dylibs) [2]_. The ``LinkGraph`` describes the object file that we need to; allocate memory for. The allocator must allocate working memory for all of; the Blocks defined in the graph, assign address space for each Block within the; executing processes memory, and update the Blocks' addresses to reflect this; assignment. Block content should be copied to working memory, but does not need; to be transferred to executor memory yet (that will be done once the content is; fixed up). ``JITLinkMemoryManager`` implementations can take full; responsibility for these steps, or use the ``BasicLayout`` utility to reduce; the task to allocating working and executor memory for *segments*: chunks of; memory defined by permissions, alignments, content sizes, and zero-fill sizes.; Once the allocation step is complete the memory manager should construct an; ``InFlightAlloc`` object to represent the allocation, and then pass this object; to the ``OnAllocated`` callback. The ``InFlightAlloc`` object has two virtual methods:. .. code-block:: c++. using OnFina",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:27834,allocate,allocate,27834,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['allocate'],['allocate']
Energy Efficiency,"which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.xor``' intrinsic performs the integer ``XOR`` reduction; (:ref:`llvm.vector.reduce.xor <int_vector_reduce_xor>`) of the vector operand; ``val`` on each enabled lane, performing an '``xor``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.xor.v4i32(<4 x i32> %masked.a); %also.r = xor i32 %reduction, %start. .. _int_vp_reduce_smax:. '``llvm.vp.reduce.smax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:762301,reduce,reduce,762301,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable. Â Â Â Â Â Â Â Â Â Â ; ProofServ.LogFileMaxSizeÂ Â ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}. Â indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of TList (TProofOutputList) to be used on the; PROOF client to filter out PROOF internal objects when displaying or; printing the list. By default objects was names start with 'PROOF_' are; not shown. The presence of a non empty missing file list is; notified.; In the PROOF monitoring to: send additional information about memory; usage during the query, the name and size (# of files) of the dataset; processed (if any); add possibility to send the information to multiple; monitoring collectors.; Add support for block activation/deactivation of workers.; Add possibility to start the proofserv with 'system()' instead of; 'fork()' as done in PROOF-Lite. A new switch 'usefrk' has been added to; 'xpd.proofservmgr' to control that. Default is still fork(). Improvements; ; In TProof::ClearPackages, use the manager to execute the command on; all known worker machines. Improves the consistency when re-istalling; packages. In TProof::GetDataSets, add support for option ':lite:'; this allows; to fill the map with only the summary information about the datasets; (the header of TFileCollections), significantly increasing the speed; and the memory footprint when the number of datasets is very large.; Accept '.' in user names.; Add switch to control caching of the files read on MacOsX. A call to; fcntl(fd, F_NOCACHE, 1) is done after opening the file.; Add export of the en",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:2272,monitor,monitoring,2272,proof/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html,4,['monitor'],['monitoring']
Energy Efficiency,"would generally be used to make IP optimizations cheaper for the; runtime compiler... > o Explicit instructions to handle aliasing, e.g.s:; > -- an instruction to say ""I speculate that these two values are not; > aliased, but check at runtime"", like speculative execution in; > EPIC?; > -- or an instruction to check whether two values are aliased and; > execute different code depending on the answer, somewhat like; > predicated code in EPIC. These are also very good points... if this can be determined at compile; time. I think that an epic style of representation (not the instruction; packing, just the information presented) could be a very interesting model; to use... more later... > o (This one is a difficult but powerful idea.); > A ""thread-id"" field on every instruction that allows the static; > compiler to generate a set of parallel threads, and then have; > the runtime compiler and hardware do what they please with it.; > This has very powerful uses, but thread-id on every instruction; > is expensive in terms of instruction size and code size.; > We would need to compactly encode it somehow. Yes yes yes! :) I think it would be *VERY* useful to include this kind; of information (which EPIC architectures *implicitly* encode. The trend; that we are seeing supports this greatly:. 1. Commodity processors are getting massive SIMD support:; * Intel/Amd MMX/MMX2; * AMD's 3Dnow!; * Intel's SSE/SSE2; * Sun's VIS; 2. SMP is becoming much more common, especially in the server space.; 3. Multiple processors on a die are right around the corner. If nothing else, not designing this in would severely limit our future; expansion of the project... > Also, this will require some reading on at least two other; > projects:; > -- Multiscalar architecture from Wisconsin; > -- Simultaneous multithreading architecture from Washington; >; > o Or forget all this and stick to a traditional instruction set?. Heh... :) Well, from a pure research point of view, it is almost more; attactive to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:7232,power,powerful,7232,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['power'],['powerful']
Energy Efficiency,"written out to `/tmp/clusters.csv` in the; following format:. .. code-block:: none. cluster_id,opcode_name,config,sched_class; ...; 2,ADD32ri8_DB,,WriteALU,1.00; 2,ADD32ri_DB,,WriteALU,1.01; 2,ADD32rr,,WriteALU,1.01; 2,ADD32rr_DB,,WriteALU,1.00; 2,ADD32rr_REV,,WriteALU,1.00; 2,ADD64i32,,WriteALU,1.01; 2,ADD64ri32,,WriteALU,1.01; 2,MOVSX64rr32,,BSWAP32r_BSWAP64r_MOVSX64rr32,1.00; 2,VPADDQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSUBDYrr_VPSUBQYrr_VPSUBWYrr,1.02; 2,VPSUBQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSUBDYrr_VPSUBQYrr_VPSUBWYrr,1.01; 2,ADD64ri8,,WriteALU,1.00; 2,SETBr,,WriteSETCC,1.01; ... :program:`llvm-exegesis` will also analyze the clusters to point out; inconsistencies in the scheduling information. The output is an html file. For; example, `/tmp/inconsistencies.html` will contain messages like the following :. .. image:: llvm-exegesis-analysis.png; :align: center. Note that the scheduling class names will be resolved only when; :program:`llvm-exegesis` is compiled in debug mode, else only the class id will; be shown. This does not invalidate any of the analysis results though. OPTIONS; -------. .. option:: --help. Print a summary of command line options. .. option:: --opcode-index=<LLVM opcode index>. Specify the opcode to measure, by index. Specifying `-1` will result; in measuring every existing opcode. See example 1 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --opcode-name=<opcode name 1>,<opcode name 2>,... Specify the opcode to measure, by name. Several opcodes can be specified as; a comma-separated list. See example 1 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --snippets-file=<filename>. Specify the custom code snippet to measure. See example 2 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --mode=[latency|uops|inverse_throughput|analysis]. Specify the run mode. Note",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:8964,schedul,scheduling,8964,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['schedul'],['scheduling']
Energy Efficiency,"ws to either keep all benchmarks, or filter out (ignore) either all the; ones that do involve memory (involve instructions that may read or write to; memory), or the opposite, to only keep such benchmarks. .. option:: --analysis-clustering=[dbscan,naive]. Specify the clustering algorithm to use. By default DBSCAN will be used.; Naive clustering algorithm is better for doing further work on the; `-analysis-inconsistencies-output-file=` output, it will create one cluster; per opcode, and check that the cluster is stable (all points are neighbours). .. option:: --analysis-numpoints=<dbscan numPoints parameter>. Specify the numPoints parameters to be used for DBSCAN clustering; (`analysis` mode, DBSCAN only). .. option:: --analysis-clustering-epsilon=<dbscan epsilon parameter>. Specify the epsilon parameter used for clustering of benchmark points; (`analysis` mode). .. option:: --analysis-inconsistency-epsilon=<epsilon>. Specify the epsilon parameter used for detection of when the cluster; is different from the LLVM schedule profile values (`analysis` mode). .. option:: --analysis-display-unstable-clusters. If there is more than one benchmark for an opcode, said benchmarks may end up; not being clustered into the same cluster if the measured performance; characteristics are different. by default all such opcodes are filtered out.; This flag will instead show only such unstable opcodes. .. option:: --ignore-invalid-sched-class=false. If set, ignore instructions that do not have a sched class (class idx = 0). .. option:: --mtriple=<triple name>. Target triple. See `-version` for available targets. .. option:: --mcpu=<cpu name>. If set, measure the cpu characteristics using the counters for this CPU. This; is useful when creating new sched models (the host CPU is unknown to LLVM).; (`-mcpu=help` for details). .. option:: --analysis-override-benchmark-triple-and-cpu. By default, llvm-exegesis will analyze the benchmarks for the triple/CPU they; were measured for, but if you",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:16276,schedul,schedule,16276,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['schedul'],['schedule']
Energy Efficiency,x/Symbol.h; clang-tools-extra/clangd/index/SymbolCollector.cpp; clang-tools-extra/clangd/index/SymbolID.cpp; clang-tools-extra/clangd/index/SymbolLocation.cpp; clang-tools-extra/clangd/index/SymbolLocation.h; clang-tools-extra/clangd/index/SymbolOrigin.cpp; clang-tools-extra/clangd/index/SymbolOrigin.h; clang-tools-extra/clangd/index/YAMLSerialization.cpp; clang-tools-extra/clangd/index/dex/Iterator.cpp; clang-tools-extra/clangd/index/dex/Iterator.h; clang-tools-extra/clangd/index/dex/PostingList.cpp; clang-tools-extra/clangd/index/dex/PostingList.h; clang-tools-extra/clangd/index/dex/Token.h; clang-tools-extra/clangd/index/dex/Trigram.cpp; clang-tools-extra/clangd/index/dex/Trigram.h; clang-tools-extra/clangd/index/dex/dexp/Dexp.cpp; clang-tools-extra/clangd/index/remote/Client.cpp; clang-tools-extra/clangd/index/remote/Client.h; clang-tools-extra/clangd/index/remote/marshalling/Marshalling.cpp; clang-tools-extra/clangd/index/remote/marshalling/Marshalling.h; clang-tools-extra/clangd/index/remote/monitor/Monitor.cpp; clang-tools-extra/clangd/index/remote/server/Server.cpp; clang-tools-extra/clangd/index/remote/unimplemented/UnimplementedClient.cpp; clang-tools-extra/clangd/indexer/IndexerMain.cpp; clang-tools-extra/clangd/refactor/InsertionPoint.cpp; clang-tools-extra/clangd/refactor/InsertionPoint.h; clang-tools-extra/clangd/refactor/Rename.h; clang-tools-extra/clangd/refactor/Tweak.cpp; clang-tools-extra/clangd/refactor/Tweak.h; clang-tools-extra/clangd/refactor/tweaks/AddUsing.cpp; clang-tools-extra/clangd/refactor/tweaks/AnnotateHighlightings.cpp; clang-tools-extra/clangd/refactor/tweaks/DefineInline.cpp; clang-tools-extra/clangd/refactor/tweaks/DefineOutline.cpp; clang-tools-extra/clangd/refactor/tweaks/DumpAST.cpp; clang-tools-extra/clangd/refactor/tweaks/ExpandMacro.cpp; clang-tools-extra/clangd/refactor/tweaks/ExtractFunction.cpp; clang-tools-extra/clangd/refactor/tweaks/ObjCLocalizeStringLiteral.cpp; clang-tools-extra/clangd/refactor/tweaks/RemoveUsingNames,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:79795,monitor,monitor,79795,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['monitor'],['monitor']
Energy Efficiency,"x[] = { { 1.0f, 1.0f } }; // [0] = (1, 1); complex float x[] = { 1.0f, 1.0f }; // [0] = (1, 0), [1] = (1, 0). This extension also works in C++ mode, as far as that goes, but does not apply; to the C++ ``std::complex``. (In C++11, list initialization allows the same; syntax to be used with ``std::complex`` with the same meaning.). For GCC compatibility, ``__builtin_complex(re, im)`` can also be used to; construct a complex number from the given real and imaginary components. OpenCL Features; ===============. Clang supports internal OpenCL extensions documented below. ``__cl_clang_bitfields``; --------------------------------. With this extension it is possible to enable bitfields in structs; or unions using the OpenCL extension pragma mechanism detailed in; `the OpenCL Extension Specification, section 1.2; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#extensions-overview>`_. Use of bitfields in OpenCL kernels can result in reduced portability as struct; layout is not guaranteed to be consistent when compiled by different compilers.; If structs with bitfields are used as kernel function parameters, it can result; in incorrect functionality when the layout is different between the host and; device code. **Example of Use**:. .. code-block:: c++. #pragma OPENCL EXTENSION __cl_clang_bitfields : enable; struct with_bitfield {; unsigned int i : 5; // compiled - no diagnostic generated; };. #pragma OPENCL EXTENSION __cl_clang_bitfields : disable; struct without_bitfield {; unsigned int i : 5; // error - bitfields are not supported; };. ``__cl_clang_function_pointers``; --------------------------------. With this extension it is possible to enable various language features that; are relying on function pointers using regular OpenCL extension pragma; mechanism detailed in `the OpenCL Extension Specification,; section 1.2; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#extensions-overview>`_. In C++ for OpenCL t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:85938,reduce,reduced,85938,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['reduce'],['reduced']
Energy Efficiency,"xception handler to prevent; stack leaks. Following the nesting rules in '``llvm.call.preallocated.setup``', nested; calls to '``llvm.call.preallocated.setup``' and; '``llvm.call.preallocated.teardown``' are allowed but must be properly; nested. Example:; """""""""""""""". .. code-block:: llvm. %cs = call token @llvm.call.preallocated.setup(i32 1); %x = call ptr @llvm.call.preallocated.arg(token %cs, i32 0) preallocated(i32); invoke void @constructor(ptr %x) to label %conta unwind label %contb; conta:; call void @foo1(ptr preallocated(i32) %x) [""preallocated""(token %cs)]; ret void; contb:; %s = catchswitch within none [label %catch] unwind to caller; catch:; %p = catchpad within %s []; call void @llvm.call.preallocated.teardown(token %cs); ret void. Standard C/C++ Library Intrinsics; ---------------------------------. LLVM provides intrinsics for a few important standard C/C++ library; functions. These intrinsics allow source-language front-ends to pass; information about the alignment of the pointer arguments to the code; generator, providing opportunity for more efficient code generation. .. _int_abs:. '``llvm.abs.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.abs`` on any; integer bit width or any vector of integer elements. ::. declare i32 @llvm.abs.i32(i32 <src>, i1 <is_int_min_poison>); declare <4 x i32> @llvm.abs.v4i32(<4 x i32> <src>, i1 <is_int_min_poison>). Overview:; """""""""""""""""". The '``llvm.abs``' family of intrinsic functions returns the absolute value; of an argument. Arguments:; """""""""""""""""""". The first argument is the value for which the absolute value is to be returned.; This argument may be of any integer type or a vector with integer element type.; The return type must match the first argument type. The second argument must be a constant and is a flag to indicate whether the; result value of the '``llvm.abs``' intrinsic is a; :ref:`poison value <poisonvalues>` if the argument is statically or d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:542267,efficient,efficient,542267,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency,"xing rules. Analysis passes which wish to understand array indexing should not assume that; the static array type bounds are respected. The second sense of being out of bounds is computing an address that's beyond; the actual underlying allocated object. With the ``inbounds`` keyword, the result value of the GEP is ``poison`` if the; address is outside the actual underlying allocated object and not the address; one-past-the-end. Without the ``inbounds`` keyword, there are no restrictions on computing; out-of-bounds addresses. Obviously, performing a load or a store requires an; address of allocated and sufficiently aligned memory. But the GEP itself is only; concerned with computing addresses. Can array indices be negative?; ------------------------------. Yes. This is basically a special case of array indices being out of bounds. Can I compare two values computed with GEPs?; --------------------------------------------. Yes. If both addresses are within the same allocated object, or; one-past-the-end, you'll get the comparison result you expect. If either is; outside of it, integer arithmetic wrapping may occur, so the comparison may not; be meaningful. Can I do GEP with a different pointer type than the type of the underlying object?; ----------------------------------------------------------------------------------. Yes. There are no restrictions on bitcasting a pointer value to an arbitrary; pointer type. The types in a GEP serve only to define the parameters for the; underlying integer computation. They need not correspond with the actual type of; the underlying object. Furthermore, loads and stores don't have to use the same types as the type of; the underlying object. Types in this context serve only to specify memory size; and alignment. Beyond that there are merely a hint to the optimizer indicating; how the value will likely be used. Can I cast an object's address to integer and add it to null?; -------------------------------------------------------------.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:14468,allocate,allocated,14468,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['allocate'],['allocated']
Energy Efficiency,"xtended or truncated, and then multiplied by the type; allocation size (that is, the size rounded up to the ABI alignment) of the; currently indexed type. The offsets are then added to the low bits of the base address up to the index; type width, with silently-wrapping two's complement arithmetic. If the pointer; size is larger than the index size, this means that the bits outside the index; type width will not be affected. The result value of the ``getelementptr`` may be outside the object pointed; to by the base pointer. The result value may not necessarily be used to access; memory though, even if it happens to point into allocated storage. See the; :ref:`Pointer Aliasing Rules <pointeraliasing>` section for more; information. If the ``inbounds`` keyword is present, the result value of a; ``getelementptr`` with any non-zero indices is a; :ref:`poison value <poisonvalues>` if one of the following rules is violated:. * The base pointer has an *in bounds* address of an allocated object, which; means that it points into an allocated object, or to its end. Note that the; object does not have to be live anymore; being in-bounds of a deallocated; object is sufficient.; * If the type of an index is larger than the pointer index type, the; truncation to the pointer index type preserves the signed value.; * The multiplication of an index by the type size does not wrap the pointer; index type in a signed sense (``nsw``).; * The successive addition of each offset (without adding the base address) does; not wrap the pointer index type in a signed sense (``nsw``).; * The successive addition of the current address, interpreted as an unsigned; number, and each offset, interpreted as a signed number, does not wrap the; unsigned address space and remains *in bounds* of the allocated object.; As a corollary, if the added offset is non-negative, the addition does not; wrap in an unsigned sense (``nuw``).; * In cases where the base is a vector of pointers, the ``inbounds`` keyword; ap",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:437322,allocate,allocated,437322,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['allocate'],['allocated']
Energy Efficiency,"y newer distributions, like Ubuntu 11.10,; that require all dependent shared libs to be specified when linking. They; also have default options set to dead strip shared libs that don't resolve; any symbols (equivalent to the MacOS X build changes described above). Core Libraries; TClonesArray. Introduce TClonesArray::ConstructedAt which; always returns an already constructed object. If the slot is being used for the; first time, it calls the default constructor otherwise it returns the object as; is (unless a string is passed as the 2nd argument to the function in which case,; it also calls Clear(second_argument) on the object).; This allows to replace code like:. for (int i = 0; i < ev->Ntracks; i++) {; new(a[i]) TTrack(x,y,z,...);; ...; ...; }; ...; a.Delete(); // or a.Clear(""C""). with the simpler and more efficient:. for (int i = 0; i < ev->Ntracks; i++) {; TTrack *track = (TTrack*)a.ConstructedAt(i);; track->Set(x,y,z,....);; ...; ...; }; ...; a.Clear();. even in case where the TTrack class allocates memory. TClonesArray: update ExpandCreateFast to also reset the non-used slots; so that calling Clear (which does too much) is no longer necessary; when using ExpandCreateFast. New Thread Pool class. A first version of TThreadPool class has been introduced.; This class implements a Thread Pool pattern.; So far it supports only one type of queue - FIFO. Thread library. Reduces risk of internal dead lock by using a private internal lock to protect the internals of TThread, rather than using TThread::Lock. New header TThreadSlots.h to centralize and formalize the use of the TThread local memory slots amongst the ROOT packages. Global Variables. The global values gPad, gVirtualX, gInterpreter, gDirectory and gFile; are now all accessed via a static function of their respective class. The; access is made transparent via a CPP macro.; The access is now also made transparent from the CINT and python prompt.; gPad, gVirtualX and gInterpreter are now accessible even when the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v532/index.html:2246,allocate,allocates,2246,core/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v532/index.html,2,['allocate'],['allocates']
Energy Efficiency,"y predict the probability; density function (""pdf"") of measurements depending on a number of; parameters, and the aim of the experimental analysis is to extract the; parameters from the observed distribution of frequencies at which; certain values of the measurement are observed. Measurements of this; kind require means to generate and visualize frequency distributions,; so-called histograms, and stringent statistical treatment to extract the; model parameters from purely statistical distributions. Simulation of expected data is another important aspect in data; analysis. By repeated generation of ""pseudo-data"", which are analysed in; the same manner as intended for the real data, analysis procedures can; be validated or compared. In many cases, the distribution of the; measurement errors is not precisely known, and simulation offers the; possibility to test the effects of different assumptions. A powerful software framework addressing all of the above requirements; is ROOT, an open source project coordinated by the European Organisation for; Nuclear Research, CERN in Geneva. ROOT is very flexible and provides both a programming interface to use in own; applications and a graphical user interface for interactive data analysis. The; purpose of this document is to serve as a beginners guide and provides extendable; examples for your own use cases, based on typical problems addressed in; student labs. This guide will hopefully lay the ground for more complex; applications in your future scientific work building on a modern,; state-of the art tool for data analysis. This guide in form of a tutorial is intended to introduce you quickly to the; ROOT package. This goal will be accomplished using concrete examples, according; to the ""learning by doing"" principle. Also because of this reason, this guide; cannot cover all the complexity of the ROOT package. Nevertheless, once you feel; confident with the concepts presented in the following chapters, you will be; able to appre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/Introduction.md:2968,power,powerful,2968,documentation/primer/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/Introduction.md,1,['power'],['powerful']
Energy Efficiency,"y similar to ROOT classes, which fit more seamlessly into your; Python code. A more â€œpythonicâ€ version of the above macro3 would use a replacement of the; ROOT class TMath for the provisioning of data to TGraphPolar. With the math; package, the part of the code becomes. ``` {.cpp}; import math; from array import array; from ROOT import TCanvas , TGraphPolar; ...; ipt=range(0,npoints); r=array('d',map(lambda x: x*(rmax-rmin)/(npoints-1.)+rmin,ipt)); theta=array('d',map(math.sin,r)); e=array('d',npoints*[0.]); ... ```. #### Customised Binning ####; This example combines comfortable handling of arrays in Python to define; variable bin sizes of a ROOT histogram. All we need to know is the interface; of the relevant ROOT class and its methods (from the ROOT documentation):. ``` {.cpp}; TH1F(const char* name , const char* title , Int_t nbinsx , const Double_t* xbins); ```. Here is the Python code:. ``` {.python}; import ROOT; from array import array; arrBins = array('d' ,(1 ,4 ,9 ,16) ) # array of bin edges; histo = ROOT.TH1F(""hist"", ""hist"", len(arrBins)-1, arrBins); # fill it with equally spaced numbers; for i in range (1 ,16) :; histo.Fill(i); histo.Draw (); ```. ## Custom code: from C++ to Python ##; The ROOT interpreter and type sytem offer interesting possibilities when it comes; to JITting of C++ code.; Take for example this header file, containing a class and a function. ```{.cpp}; // file cpp2pythonExample.h; #include ""stdio.h"". class A{; public:; A(int i):m_i(i){}; int getI() const {return m_i;}; private:; int m_i=0;; };. void printA(const A& a ){; printf (""The value of A instance is %i.\n"",a.getI());; }; ```. ```{ .python }; >>> import ROOT; >>> ROOT.gInterpreter.ProcessLine('#include ""cpp2pythonExample.h""'); >>> a = ROOT.A(123); >>> ROOT.printA(a); The value of A instance is 123.; ```. This example might seem trivial, but it shows a powerful ROOT feature.; C++ code can be JITted within PyROOT and the entities defined in C++ can be; transparently used in Python!",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/root_in_python.md:4108,power,powerful,4108,documentation/primer/root_in_python.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/root_in_python.md,1,['power'],['powerful']
Energy Efficiency,"y), has few allocations, is easy to; address (iterators in the final vector are just indices or pointers), and can be; efficiently queried with a standard binary search (e.g.; ``std::lower_bound``; if you want the whole range of elements comparing; equal, use ``std::equal_range``). .. _dss_smallset:. llvm/ADT/SmallSet.h; ^^^^^^^^^^^^^^^^^^^. If you have a set-like data structure that is usually small and whose elements; are reasonably small, a ``SmallSet<Type, N>`` is a good choice. This set has; space for N elements in place (thus, if the set is dynamically smaller than N,; no malloc traffic is required) and accesses them with a simple linear search.; When the set grows beyond N elements, it allocates a more expensive; representation that guarantees efficient access (for most types, it falls back; to :ref:`std::set <dss_set>`, but for pointers it uses something far better,; :ref:`SmallPtrSet <dss_smallptrset>`. The magic of this class is that it handles small sets extremely efficiently, but; gracefully handles extremely large sets without loss of efficiency. .. _dss_smallptrset:. llvm/ADT/SmallPtrSet.h; ^^^^^^^^^^^^^^^^^^^^^^. ``SmallPtrSet`` has all the advantages of ``SmallSet`` (and a ``SmallSet`` of; pointers is transparently implemented with a ``SmallPtrSet``). If more than N; insertions are performed, a single quadratically probed hash table is allocated; and grows as needed, providing extremely efficient access (constant time; insertion/deleting/queries with low constant factors) and is very stingy with; malloc traffic. Note that, unlike :ref:`std::set <dss_set>`, the iterators of ``SmallPtrSet``; are invalidated whenever an insertion occurs. Also, the values visited by the; iterators are not visited in sorted order. .. _dss_stringset:. llvm/ADT/StringSet.h; ^^^^^^^^^^^^^^^^^^^^. ``StringSet`` is a thin wrapper around :ref:`StringMap\<char\> <dss_stringmap>`,; and it allows efficient storage and retrieval of unique strings. Functionally analogous to ``SmallS",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:78582,efficient,efficiently,78582,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['efficient'],['efficiently']
Energy Efficiency,"y; floating-point or vector of floating-point type. Not all targets support; all types however. Generally, the only supported type for the exponent is the one matching; with the C type ``int``. ::. declare float @llvm.powi.f32.i32(float %Val, i32 %power); declare double @llvm.powi.f64.i16(double %Val, i16 %power); declare x86_fp80 @llvm.powi.f80.i32(x86_fp80 %Val, i32 %power); declare fp128 @llvm.powi.f128.i32(fp128 %Val, i32 %power); declare ppc_fp128 @llvm.powi.ppcf128.i32(ppc_fp128 %Val, i32 %power). Overview:; """""""""""""""""". The '``llvm.powi.*``' intrinsics return the first operand raised to the; specified (positive or negative) power. The order of evaluation of; multiplications is not defined. When a vector of floating-point type is; used, the second argument remains a scalar integer value. Arguments:; """""""""""""""""""". The second argument is an integer power, and the first is a value to; raise to that power. Semantics:; """""""""""""""""""". This function returns the first value raised to the second power with an; unspecified sequence of rounding operations. '``llvm.sin.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sin`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.sin.f32(float %Val); declare double @llvm.sin.f64(double %Val); declare x86_fp80 @llvm.sin.f80(x86_fp80 %Val); declare fp128 @llvm.sin.f128(fp128 %Val); declare ppc_fp128 @llvm.sin.ppcf128(ppc_fp128 %Val). Overview:; """""""""""""""""". The '``llvm.sin.*``' intrinsics return the sine of the operand. Arguments:; """""""""""""""""""". The argument and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``sin``' function but without; trapping or setting ``errno``. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. '``llvm.cos.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:558759,power,power,558759,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['power'],['power']
Energy Efficiency,"ySet: a set of instructions ready to execute.; * IssuedSet: a set of instructions executing. Depending on the operands availability, instructions that are dispatched to the; scheduler are either placed into the WaitSet or into the ReadySet. Every cycle, the scheduler checks if instructions can be moved from the WaitSet; to the ReadySet, and if instructions from the ReadySet can be issued to the; underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younge",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39118,allocate,allocated,39118,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['allocate'],['allocated']
Energy Efficiency,"yer will call; this function to ask us what we would like to compile. At a minimum we need to; compile the function being called (given by the argument to the partitioning; function), but we could also request that the CompileOnDemandLayer compile other; functions that are unconditionally called (or highly likely to be called) from; the function being called. For KaleidoscopeJIT we'll keep it simple and just; request compilation of the function that was called. Next we pass a reference to; our CompileCallbackManager. Finally, we need to supply an ""indirect stubs; manager builder"": a utility function that constructs IndirectStubManagers, which; are in turn used to build the stubs for the functions in each module. The; CompileOnDemandLayer will call the indirect stub manager builder once for each; call to addModule, and use the resulting indirect stubs manager to create; stubs for all functions in all modules in the set. If/when the module set is; removed from the JIT the indirect stubs manager will be deleted, freeing any; memory allocated to the stubs. We supply this function by using the; createLocalIndirectStubsManagerBuilder utility. .. code-block:: c++. // ...; if (auto Sym = CODLayer.findSymbol(Name, false)); // ...; return cantFail(CODLayer.addModule(std::move(Ms),; std::move(Resolver)));; // ... // ...; return CODLayer.findSymbol(MangledNameStream.str(), true);; // ... // ...; CODLayer.removeModule(H);; // ... Finally, we need to replace the references to OptimizeLayer in our addModule,; findSymbol, and removeModule methods. With that, we're up and running. **To be done:**. ** Chapter conclusion.**. Full Code Listing; =================. Here is the complete code listing for our running example with a CompileOnDemand; layer added to enable lazy function-at-a-time compilation. To build this example, use:. .. code-block:: bash. # Compile; clang++ -g toy.cpp `llvm-config --cxxflags --ldflags --system-libs --libs core orcjit native` -O3 -o toy; # Run; ./toy. Here ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst:7426,allocate,allocated,7426,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,1,['allocate'],['allocated']
Energy Efficiency,"yond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrinsic may be used in a scheduling region. The iglp_opt intrinsic; cannot be combined with sched_barrier or sched_group_barrier. The iglp_opt strategy implementations are subject to change. llvm.amdgcn.atomic.cond.sub.u32 Provides direct access to flat_atomic_cond_sub_u32, global_atomic_cond_sub_u32; and ds_cond_sub_u32 based on address space on gfx12 targets. This; performs subtraction only if the memory value is greater than or; equal to the data value. llvm.amdgcn.s.getpc Provides access to the s_getpc_b64 instruction, but with the return value; sign-extended from the width of the underlying PC hardware register even on; processors where the s_getpc_b64 instruction returns a zero-extended value. ============================================== ==========================================================. .. TODO::. List AMDGPU intrinsics. LLVM IR Attributes; ------------------. The AMDGPU backend supports the following LLVM IR attributes. .. table:: AMDGPU LLVM IR Attributes; :name: amdgpu-llvm-i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:45064,schedul,scheduling,45064,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['schedul'],['scheduling']
Energy Efficiency,"ype();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_sigjmp_buf;; return QualType();; } else {; break; // Unnecessary.; }; } else {; Type = Context.getjmp_bufType();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_jmp_buf;; return QualType();; } else {; break; // Unnecessary.; }; }; }. It is better to write it like this:. .. code-block:: c++. case 'J':; if (Signed) {; Type = Context.getsigjmp_bufType();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_sigjmp_buf;; return QualType();; }; } else {; Type = Context.getjmp_bufType();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_jmp_buf;; return QualType();; }; }; break;. Or better yet (in this case) as:. .. code-block:: c++. case 'J':; if (Signed); Type = Context.getsigjmp_bufType();; else; Type = Context.getjmp_bufType();. if (Type.isNull()) {; Error = Signed ? ASTContext::GE_Missing_sigjmp_buf :; ASTContext::GE_Missing_jmp_buf;; return QualType();; }; break;. The idea is to reduce indentation and the amount of code you have to keep track; of when reading the code. Note: this advice does not apply to a ``constexpr if`` statement. The; substatement of the ``else`` clause may be a discarded statement, so removing; the ``else`` can cause unexpected template instantiations. Thus, the following; example is correct:. .. code-block:: c++. template<typename T>; static constexpr bool VarTempl = true;. template<typename T>; int func() {; if constexpr (VarTempl<T>); return 1;; else; static_assert(!VarTempl<T>);; }. Turn Predicate Loops into Predicate Functions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. It is very common to write small loops that just compute a boolean value. There; are a number of ways that people commonly write these, but an example of this; sort of thing is:. .. code-block:: c++. bool FoundFoo = false;; for (unsigned I = 0, E = BarList.size(); I != E; ++I); if (BarList[I]->isFoo()) {; FoundFoo = true;; break;; }. if (FoundFoo) {; ...; }. Instead of this sort of loop, we prefer to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:39821,reduce,reduce,39821,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['reduce'],['reduce']
Energy Efficiency,"ypedef types. Given; typedef int X;; typedefType(); matches ""typedef int X"". Matcher<Type>unaryTransformTypeMatcher<UnaryTransformType>...; Matches types nodes representing unary type transformations. Given:; typedef __underlying_type(T) type;; unaryTransformType(); matches ""__underlying_type(T)"". Matcher<Type>usingTypeMatcher<UsingType>...; Matches types specified through a using declaration. Given; namespace a { struct S {}; }; using a::S;; S s;. usingType() matches the type of the variable declaration of s. Matcher<Type>variableArrayTypeMatcher<VariableArrayType>...; Matches C arrays with a specified size that is not an; integer-constant-expression. Given; void f() {; int a[] = { 2, 3 }; int b[42];; int c[a[0]];; }; variableArrayType(); matches ""int c[a[0]]"". Narrowing Matchers. Narrowing matchers match certain attributes on the current node, thus; narrowing down the set of nodes of the current type to match on.; There are special logical narrowing matchers (allOf, anyOf, anything and unless); which allow users to create more powerful match expressions. Return typeNameParameters. Matcher<*>allOfMatcher<*>, ..., Matcher<*>; Matches if all given matchers match. Usable as: Any Matcher. Matcher<*>anyOfMatcher<*>, ..., Matcher<*>; Matches if any of the given matchers matches. Usable as: Any Matcher. Matcher<*>anything; Matches any node. Useful when another matcher requires a child matcher, but there's no; additional constraint. This will often be used with an explicit conversion; to an internal::Matcher<> type such as TypeMatcher. Example: DeclarationMatcher(anything()) matches all declarations, e.g.,; ""int* p"" and ""void f()"" in; int* p;; void f();. Usable as: Any Matcher. unspecifiedmapAnyOfnodeMatcherFunction...; Matches any of the NodeMatchers with InnerMatchers nested within. Given; if (true);; for (; true; );; with the matcher; mapAnyOf(ifStmt, forStmt).with(; hasCondition(cxxBoolLiteralExpr(equals(true))); ).bind(""trueCond""); matches the if and the for. It is eq",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:53622,power,powerful,53622,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,2,['power'],['powerful']
Energy Efficiency,"ypes; > Right now, I've spec'd out the language to have a pointer type, which; > works fine for lots of stuff... except that Java really has; > references: constrained pointers that cannot be manipulated: added and; > subtracted, moved, etc... Do we want to have a type like this? It; > could be very nice for analysis (pointer always points to the start of; > an object, etc...) and more closely matches Java semantics. The; > pointer type would be kept for C++ like semantics. Through analysis,; > C++ pointers could be promoted to references in the LLVM; > representation. You're right, having references would be useful. Even for C++ the *static*; compiler could generate references instead of pointers with fairly; straightforward analysis. Let's include a reference type for now. But I'm; also really concerned that LLVM is becoming big and complex and (perhaps); too high-level. After we get some initial performance results, we may have; a clearer idea of what our goals should be and we should revisit this; question then. > 2. Our ""implicit"" memory references in assembly language:; > After thinking about it, this model has two problems:; > A. If you do pointer analysis and realize that two stores are; > independent and can share the same memory source object,. not sure what you meant by ""share the same memory source object"". > there is; > no way to represent this in either the bytecode or assembly.; > B. When parsing assembly/bytecode, we effectively have to do a full; > SSA generation/PHI node insertion pass to build the dependencies; > when we don't want the ""pinned"" representation. This is not; > cool. I understand the concern. But again, let's focus on the performance first; and then look at the language design issues. E.g., it would be good to know; how big the bytecode files are before expanding them further. I am pretty; keen to explore the implications of LLVM for mobile devices. Both bytecode; size and power consumption are important to consider there. --Vikram. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-13-Reference-MemoryResponse.txt:2104,power,power,2104,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-13-Reference-MemoryResponse.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-13-Reference-MemoryResponse.txt,2,"['consumption', 'power']","['consumption', 'power']"
Energy Efficiency,"ysis results from the outer analysis manager; should be immutable, so invalidation shouldn't be a concern. However, it is; possible for some inner analysis to depend on some outer analysis, and when; the outer analysis is invalidated, we need to make sure that dependent inner; analyses are also invalidated. This actually happens with alias analysis; results. Alias analysis is a function-level analysis, but there are; module-level implementations of specific types of alias analysis. Currently; ``GlobalsAA`` is the only module-level alias analysis and it generally is not; invalidated so this is not so much of a concern. See; ``OuterAnalysisManagerProxy::Result::registerOuterAnalysisInvalidation()``; for more details. Invoking ``opt``; ================. .. code-block:: shell. $ opt -passes='pass1,pass2' /tmp/a.ll -S; # -p is an alias for -passes; $ opt -p pass1,pass2 /tmp/a.ll -S. The new PM typically requires explicit pass nesting. For example, to run a; function pass, then a module pass, we need to wrap the function pass in a module; adaptor:. .. code-block:: shell. $ opt -passes='function(no-op-function),no-op-module' /tmp/a.ll -S. A more complete example, and ``-debug-pass-manager`` to show the execution; order:. .. code-block:: shell. $ opt -passes='no-op-module,cgscc(no-op-cgscc,function(no-op-function,loop(no-op-loop))),function(no-op-function,loop(no-op-loop))' /tmp/a.ll -S -debug-pass-manager. Improper nesting can lead to error messages such as. .. code-block:: shell. $ opt -passes='no-op-function,no-op-module' /tmp/a.ll -S; opt: unknown function pass 'no-op-module'. The nesting is: module (-> cgscc) -> function -> loop, where the CGSCC nesting is optional. There are a couple of special cases for easier typing:. * If the first pass is not a module pass, a pass manager of the first pass is; implicitly created. * For example, the following are equivalent. .. code-block:: shell. $ opt -passes='no-op-function,no-op-function' /tmp/a.ll -S; $ opt -passes='function(no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:18641,adapt,adaptor,18641,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['adapt'],['adaptor']
Energy Efficiency,"ystem using HTML5 FileReader functionality.; Main limitation here - user should interactively select files for reading.; There is button __""...""__ on the main JSROOT page, which starts file selection dialog.; If valid ROOT file is selected, JSROOT will be able to normally read content of such file. ## JSROOT with THttpServer. THttpServer provides http access to objects from running ROOT application.; JSROOT is used to implement the user interface in the web browsers. The layout of the main page coming from THttpServer is very similar to normal JSROOT page.; One could browse existing items and display them. A snapshot of running; server can be seen on the [demo page](https://root.cern/js/latest/httpserver.C/). One could also specify similar URL parameters to configure the displayed items and drawing options. It is also possible to display one single item from the THttpServer server like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hpxpy/draw.htm?opt=colz>. ## Data monitoring with JSROOT. ### Monitoring with http server. The best possibility to organize the monitoring of data from a running application; is to use THttpServer. In such case the client can always access the latest; changes and request only the items currently displayed in the browser.; To enable monitoring, one should activate the appropriate checkbox or; provide __monitoring__ parameter in the URL string like:. <https://root.cern/js/latest/httpserver.C/Files/job1.root/hprof/draw.htm?monitoring=1000>. The parameter value is the update interval in milliseconds. ### JSON file-based monitoring. Solid file-based monitoring (without integration of THttpServer into application) can be; implemented in JSON format. There is the [TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class,; which is capable to convert any (beside TTree) ROOT object into JSON. Any ROOT application can use such class to; create JSON files for selected objects and write such files in a directory,; which can",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:30437,monitor,monitoring,30437,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['monitor'],['monitoring']
Energy Efficiency,"yy package, but the built-in module takes; precedence.; To use cppyy, first import a compatibility module::. $ pypy; [PyPy 5.8.0 with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:7541,reduce,reduced,7541,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['reduce'],['reduced']
Energy Efficiency,"zed for small strings, they themselves are not particularly small.; This means that they work great for temporary scratch buffers on the stack, but; should not generally be put into the heap: it is very rare to see a SmallString; as the member of a frequently-allocated heap data structure or returned; by-value. .. _dss_stdstring:. std::string; ^^^^^^^^^^^. The standard C++ std::string class is a very general class that (like; SmallString) owns its underlying data. sizeof(std::string) is very reasonable; so it can be embedded into heap data structures and returned by-value. On the; other hand, std::string is highly inefficient for inline editing (e.g.; concatenating a bunch of stuff together) and because it is provided by the; standard library, its performance characteristics depend a lot of the host; standard library (e.g. libc++ and MSVC provide a highly optimized string class,; GCC contains a really slow implementation). The major disadvantage of std::string is that almost every operation that makes; them larger can allocate memory, which is slow. As such, it is better to use; SmallVector or Twine as a scratch buffer, but then use std::string to persist; the result. .. _ds_set:. Set-Like Containers (std::set, SmallSet, SetVector, etc); --------------------------------------------------------. Set-like containers are useful when you need to canonicalize multiple values; into a single representation. There are several different choices for how to do; this, providing various trade-offs. .. _dss_sortedvectorset:. A sorted 'vector'; ^^^^^^^^^^^^^^^^^. If you intend to insert a lot of elements, then do a lot of queries, a great; approach is to use an std::vector (or other sequential container) with; std::sort+std::unique to remove duplicates. This approach works really well if; your usage pattern has these two distinct phases (insert then query), and can be; coupled with a good choice of :ref:`sequential container <ds_sequential>`. This combination provides the several n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:76545,allocate,allocate,76545,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['allocate'],['allocate']
Energy Efficiency,"zed reduction. That is, the reduction begins with; the start value and performs an fmul operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fmul(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result * input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, one (``1.0``) can be used, as it is the neutral; value of floating point multiplication. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fmul.v4f32(float 1.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_and:. '``llvm.vector.reduce.and.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.and.*``' intrinsics do a bitwise ``AND``; reduction of a vector, returning the result as a scalar. The return type matches; the element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_or:. '``llvm.vector.reduce.or.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.or.*``' intrinsics do a bitwise ``OR`` reduction; of a vector, returning the result as a scalar. The return type matches the; element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_xor:. '``llvm.vector.reduce.xor.*``' Intrinsic;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:654992,reduce,reduce,654992,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['reduce'],['reduce']
Energy Efficiency,"zer has completed operation because it has reached the specified; iteration limit (``-runs``) or time limit (``-max_total_time``).; ``RELOAD``; The fuzzer is performing a periodic reload of inputs from the corpus; directory; this allows it to discover any inputs discovered by other; fuzzer processes (see `Parallel Fuzzing`_). Each output line also reports the following statistics (when non-zero):. ``cov:``; Total number of code blocks or edges covered by executing the current corpus.; ``ft:``; libFuzzer uses different signals to evaluate the code coverage:; edge coverage, edge counters, value profiles, indirect caller/callee pairs, etc.; These signals combined are called *features* (`ft:`).; ``corp:``; Number of entries in the current in-memory test corpus and its size in bytes.; ``lim:``; Current limit on the length of new entries in the corpus. Increases over time; until the max length (``-max_len``) is reached.; ``exec/s:``; Number of fuzzer iterations per second.; ``rss:``; Current memory consumption. For ``NEW`` and ``REDUCE`` events, the output line also includes information; about the mutation operation that produced the new input:. ``L:``; Size of the new input in bytes.; ``MS: <n> <operations>``; Count and list of the mutation operations used to generate the input. Examples; ========; .. contents::; :local:; :depth: 1. Toy example; -----------. A simple function that does something interesting if it receives the input; ""HI!""::. cat << EOF > test_fuzzer.cc; #include <stdint.h>; #include <stddef.h>; extern ""C"" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {; if (size > 0 && data[0] == 'H'); if (size > 1 && data[1] == 'I'); if (size > 2 && data[2] == '!'); __builtin_trap();; return 0;; }; EOF; # Build test_fuzzer.cc with asan and link against libFuzzer.; clang++ -fsanitize=address,fuzzer test_fuzzer.cc; # Run the fuzzer with no corpus.; ./a.out. You should get an error pretty quickly::. INFO: Seed: 1523017872; INFO: Loaded 1 modules (16 guards): ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:17312,consumption,consumption,17312,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['consumption'],['consumption']
Energy Efficiency,"zer, ``inttoptr`` and ``ptrtoint`` for; non-integral types are analogous to ones on integral types with one; key exception: the optimizer may not, in general, insert new dynamic; occurrences of such casts. If a new cast is inserted, the optimizer would; need to either ensure that a) all possible values are valid, or b); appropriate fencing is inserted. Since the appropriate fencing is; implementation defined, the optimizer can't do the latter. The former is; challenging as many commonly expected properties, such as; ``ptrtoint(v)-ptrtoint(v) == 0``, don't hold for non-integral types.; Similar restrictions apply to intrinsics that might examine the pointer bits,; such as :ref:`llvm.ptrmask<int_ptrmask>`. . The alignment information provided by the frontend for a non-integral pointer; (typically using attributes or metadata) must be valid for every possible ; representation of the pointer. .. _globalvars:. Global Variables; ----------------. Global variables define regions of memory allocated at compilation time; instead of run-time. Global variable definitions must be initialized. Global variables in other translation units can also be declared, in which; case they don't have an initializer. Global variables can optionally specify a :ref:`linkage type <linkage>`. Either global variable definitions or declarations may have an explicit section; to be placed in and may have an optional explicit alignment specified. If there; is a mismatch between the explicit or inferred section information for the; variable declaration and its definition the resulting behavior is undefined. A variable may be defined as a global ``constant``, which indicates that; the contents of the variable will **never** be modified (enabling better; optimization, allowing the global data to be placed in the read-only; section of an executable, etc). Note that variables that need runtime; initialization cannot be marked ``constant`` as there is a store to the; variable. LLVM explicitly allows *declar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:30429,allocate,allocated,30429,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['allocate'],['allocated']
Energy Efficiency,"{!4, !1}. ; Some scope lists:; !5 = !{!4} ; A list containing only scope !4; !6 = !{!4, !3, !2}; !7 = !{!3}. ; These two instructions don't alias:; %0 = load float, ptr %c, align 4, !alias.scope !5; store float %0, ptr %arrayidx.i, align 4, !noalias !5. ; These two instructions also don't alias (for domain !1, the set of scopes; ; in the !alias.scope equals that in the !noalias list):; %2 = load float, ptr %c, align 4, !alias.scope !5; store float %2, ptr %arrayidx.i2, align 4, !noalias !6. ; These two instructions may alias (for domain !0, the set of scopes in; ; the !noalias list is not a superset of, or equal to, the scopes in the; ; !alias.scope list):; %2 = load float, ptr %c, align 4, !alias.scope !6; store float %0, ptr %arrayidx.i, align 4, !noalias !7. '``fpmath``' Metadata; ^^^^^^^^^^^^^^^^^^^^^. ``fpmath`` metadata may be attached to any instruction of floating-point; type. It can be used to express the maximum acceptable error in the; result of that instruction, in ULPs, thus potentially allowing the; compiler to use a more efficient but less accurate method of computing; it. ULP is defined as follows:. If ``x`` is a real number that lies between two finite consecutive; floating-point numbers ``a`` and ``b``, without being equal to one; of them, then ``ulp(x) = |b - a|``, otherwise ``ulp(x)`` is the; distance between the two non-equal finite floating-point numbers; nearest ``x``. Moreover, ``ulp(NaN)`` is ``NaN``. The metadata node shall consist of a single positive float type number; representing the maximum relative error, for example:. .. code-block:: llvm. !0 = !{ float 2.5 } ; maximum acceptable inaccuracy is 2.5 ULPs. .. _range-metadata:. '``range``' Metadata; ^^^^^^^^^^^^^^^^^^^^. ``range`` metadata may be attached only to ``load``, ``call`` and ``invoke`` of; integer or vector of integer types. It expresses the possible ranges the loaded; value or the value returned by the called function at this call site is in. If; the loaded or returned value i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:284101,efficient,efficient,284101,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['efficient'],['efficient']
Energy Efficiency,"|; | root.json?compact=3 | 6004 bytes |; | root.json?compact=23 | 5216 bytes |; | root.json.gz?compact=23 | 1855 bytes |. One should remember that JSON representation always includes names of the data fields which are not present in the binary representation. Even then the size difference is negligible. `root.json` used in JSROOT to request objects from THttpServer. ### Generating images out of objects. For the ROOT classes which are implementing Draw method (like [TH1](https://root.cern/doc/master/classTH1.html) or [TGraph](https://root.cern/doc/master/classTGraph.html)) one could produce images with requests: `root.png`, `root.gif`, `root.jpeg`. For example:. ```bash; [shell] wget ""http://localhost:8080/Files/hsimple.root/hpx/root.png?w=500&h=500&opt=lego1"" -O lego1.png; ```. For all such requests following parameters could be specified:. - **h** - image height; - **w** - image width; - **opt** - draw options. ### Methods execution. By default THttpServer starts in monitoring (read-only) mode and therefore forbid any methods execution. One could specify read-write mode when server is started:. ```cpp; auto serv = new THttpServer(""http:8080;rw"");; ```. Or one could disable read-only mode with the call:. ```cpp; serv->SetReadOnly(kFALSE);; ```. Or one could allow access to the folder, object or specific object methods with:. ```cpp; serv->Restrict(""/Histograms"", ""allow=admin""); // allow full access for user with 'admin' account; serv->Restrict(""/Histograms/hist1"", ""allow=all""); // allow full access for all users; serv->Restrict(""/Histograms/hist1"", ""allow_method=Rebin""); // allow only Rebin method; ```. 'exe.json' accepts following parameters:. - `method` - name of method to execute; - `prototype` - method prototype (see [TClass::GetMethodWithPrototype](https://root.cern/doc/master/classTClass.html#a2bef3a3d4bf3d8f8e97e989b63699746) for details); - `compact` - compact parameter, used to compress return value; - `_ret_object_` - name of the object which should be retu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:18798,monitor,monitoring,18798,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['monitor'],['monitoring']
Energy Efficiency,"}=${VALUE}` (e.g.; `SCUDO_OPTIONS=GWP_ASAN_SampleRate=100`). Options defined this way will; override any definition made through ``__gwp_asan_default_options``. The options string follows a syntax similar to ASan, where distinct options; can be assigned in the same string, separated by colons. For example, using the environment variable:. .. code:: console. GWP_ASAN_OPTIONS=""MaxSimultaneousAllocations=16:SampleRate=5000"" ./a.out. Or using the function:. .. code:: cpp. extern ""C"" const char *__gwp_asan_default_options() {; return ""MaxSimultaneousAllocations=16:SampleRate=5000"";; }. The following options are available:. +----------------------------+---------+--------------------------------------------------------------------------------+; | Option | Default | Description |; +----------------------------+---------+--------------------------------------------------------------------------------+; | Enabled | true | Is GWP-ASan enabled? |; +----------------------------+---------+--------------------------------------------------------------------------------+; | PerfectlyRightAlign | false | When allocations are right-aligned, should we perfectly align them up to the |; | | | page boundary? By default (false), we round up allocation size to the nearest |; | | | power of two (2, 4, 8, 16) up to a maximum of 16-byte alignment for |; | | | performance reasons. Setting this to true can find single byte |; | | | buffer-overflows at the cost of performance, and may be incompatible with |; | | | some architectures. |; +----------------------------+---------+--------------------------------------------------------------------------------+; | MaxSimultaneousAllocations | 16 | Number of simultaneously-guarded allocations available in the pool. |; +----------------------------+---------+--------------------------------------------------------------------------------+; | SampleRate | 5000 | The probability (1 / SampleRate) that a page is selected for GWP-ASan |; | | | sampling. Sam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:7503,power,power,7503,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['power'],['power']
Energy Efficiency,"~~~~~~~~. Subclasses of ``ValueType`` are valid types, e.g. ``i32``. GITypeOf; ~~~~~~~~. ``GITypeOf<""$x"">`` is a ``GISpecialType`` that allows for the creation of a; register or immediate with the same type as another (register) operand. Operand:. * An operand name as a string, prefixed by ``$``. Semantics:. * Can only appear in an 'apply' pattern.; * The operand name used must appear in the 'match' pattern of the; same ``GICombineRule``. .. code-block:: text; :caption: Example: Immediate. def mul_by_neg_one: GICombineRule <; (defs root:$root),; (match (G_MUL $dst, $x, -1)),; (apply (G_SUB $dst, (GITypeOf<""$x""> 0), $x)); >;. .. code-block:: text; :caption: Example: Temp Reg. def Test0 : GICombineRule<; (defs root:$dst),; (match (G_FMUL $dst, $src, -1)),; (apply (G_FSUB $dst, $src, $tmp),; (G_FNEG GITypeOf<""$dst"">:$tmp, $src))>;. Builtin Operations; ------------------. MIR Patterns also offer builtin operations, also called ""builtin instructions"".; They offer some powerful features that would otherwise require use of C++ code. GIReplaceReg; ~~~~~~~~~~~~. .. code-block:: text; :caption: Usage. (apply (GIReplaceReg $old, $new)). Operands:. * ``$old`` (out) register defined by a matched instruction; * ``$new`` (in) register. Semantics:. * Can only appear in an 'apply' pattern.; * If both old/new are operands of matched instructions,; ``canReplaceReg`` is checked before applying the rule. GIEraseRoot; ~~~~~~~~~~~. .. code-block:: text; :caption: Usage. (apply (GIEraseRoot)). Semantics:. * Can only appear as the only pattern of an 'apply' pattern list.; * The root cannot have any output operands.; * The root must be a CodeGenInstruction. Instruction Flags; -----------------. MIR Patterns support both matching & writing ``MIFlags``. .. code-block:: text; :caption: Example. def Test : GICombineRule<; (defs root:$dst),; (match (G_FOO $dst, $src, (MIFlags FmNoNans, FmNoInfs))),; (apply (G_BAR $dst, $src, (MIFlags FmReassoc)))>;. In ``apply`` patterns, we also support referring",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:3841,power,powerful,3841,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,1,['power'],['powerful']
Energy Efficiency,"â€˜widgets' or controls attached to a 3D object in; the viewer, allowing a direct manipulation of the object's geometry.; There are three manipulators for the three basic geometries; transformations. In each case, the *manipulator* consists of three; components, one for each local axis of the object, shown in standard; colors: red (X), green (Y) and blue (Z). ![GL Viewer object manipulators](pictures/030000DE.png). Activate the *manipulator* by moving the mouse over one of these; components (which turns yellow to indicate active state). Click with; left mouse and drag this active component to perform the manipulation.; Toggle between the *manipulator* types using the â€˜x', â€˜c', â€˜v' keys; while the mouse cursor is above the manipulator. Note: Manipulators; cannot be controlled via the API at present. #### Guides. Guides are visual aids drawn into the viewer world. Controls for these; are under the ""Guides"" tab:. Viewer Controls Pane Guides Tab. Axes show the world (global) frame *coordinate*directions: X (red), Y; (green) and Z (blue). The negative portion of the *axis* line is shown; in dark color, the positive in bright. The *axis* name and minimum /; maximum values are labeled in the same color. There are three options; for *axes* drawing - selected by radio buttons:. - None - not drawn (default). - Edge - draw axes on the (minimum) edge of the scene extents box. - Origin - drawn axes through the origin. For *edge axes*, the zero value for each axis is marked on the axis line; with a colored sphere. For *origin axes,* a single white sphere is shown; at the origin. *Edge axes* are depth clipped - i.e. are obscured by 3D objects in front; of them. *Origin axes* (which generally pass through the middle of the; 3D scene) are not depth clipped - so always visible. A single orange sphere of fixed view port (window) size can be shown at; any arbitrary position. Enable / disable the drawing with â€˜*Show'*; checkbox. Enter X/Y/Z position in the edit boxes to set position.; Init",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:117181,green,green,117181,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['green'],['green']
Integrability," 	 one-dimensional (i.e. one entry per event) or multi-dimensional (N entries per event).; * Function classes defining the type of fit (the objective function used for fitting):; 	- `ROOT::Fit::Chi2FCN` for chi2 (least-square fits),; 	- `ROOT::Fit::PoissonLikelihoodFCN` for binned likelihood fits of histograms,; 	- `ROOT::Fit::LogLikelihoodFCN` for generic un-binned likelihood fits.; 	These classes are templated on the type of function interface they implement (see later). User convenient typedefs are also provided.; 	They derive from the common generic interface multi-dimensional for function evaluation, `ROOT::Math::IBaseFunctionMultiDim`. In addition the fitter classes make uses of the generic interfaces for parametric function evaluations, `ROOT::Math::IParametricFunctionMultiDim`; to define the fit model function and use the `ROOT::Math::Minimizer` interface to perform the minimization of the objective function.; More information about the function interface and the multi-dimensional minimization in ROOT is given in the Mathematical Library chapter. Here we present a detailed description of the `ROOT::Fit` classes and how to use them.; Using these classes instead of the interface provided directly in the ROOT data objects, like `TH1::Fit` allow are more fine control; to configure and customise the fits. For example, using these classes a combined fit of several histograms can be performed. To understand how these class work, let's go through a simple example, such as fitting an histogram. When fitting an histogram, instead of using `TH1::Fit` we will show in the following hot wo use the `ROOT::Fit` classes.; We will show how to perform the following different type of fits with the histogram data:; * a least square fit using the observed errors (Neyman chi-squared);; * a least square fit using the expected errors from the function (Pearson chi-squared);; * a binned likelihood fit;; * an extended unbinned likelihood fits, if the histogram has been set to store in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:28223,interface,interface,28223,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['interface'],['interface']
Integrability," ![ROOT libraries dependencies](pictures/03000005.png). The libraries are designed and organized to minimize dependencies,; such that you can load just enough code for the task at hand rather; than having to load all libraries or one monolithic chunk. The core; library (`libCore.so`) contains the essentials; it is a part of all; ROOT applications. In the Figure 1-2 you see that libCore.so is made; up of base classes, container classes, meta information classes,; operating system specific classes, and the ZIP algorithm used for; compression of the ROOT files. The Cling library (`libCling.so`) is also needed in all ROOT; applications, and even by `libCore`. A; program referencing only **`TObject`** only needs `libCore`;; `libCling` will be opened automatically. To add the ability to read and write; ROOT objects one also has to load `libRIO`. As one would expect, none of that; depends on graphics or the GUI. Library dependencies have different consequences; depending on whether; you try to build a binary, or you just try to access a class that is; defined in a library. #### Linktime Library Dependencies. When building your own executable you will have to link against the; libraries that contain the classes you use. The ROOT reference guide; states the library a class is reference guide defined in. Almost all; relevant classes can be found in libraries returned by; `root-config -glibs`; the graphics libraries are retuned by; `root-config --libs`. These commands are commonly used in `Makefiles`.; Using `root-config` instead of enumerating the libraries by hand; allows you to link them in a platform independent way. Also, if ROOT; library names change you will not need to change your Makefile. A batch program that does not have a graphic display, which creates,; fills, and saves histograms and trees, only needs to link the core; libraries (`libCore`, `libRIO`), `libHist` and `libTree`.; If ROOT needs access to other libraries, it loads them dynamically.; For example, if t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:16892,depend,dependencies,16892,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,2,['depend'],"['dependencies', 'depending']"
Integrability," !ne; : !not !or !range !repr !setdagarg; : !setdagname !setdagop !shl !size !sra; : !srl !strconcat !sub !subst !substr; : !tail !tolower !toupper !xor. The ``!cond`` operator has a slightly different; syntax compared to other bang operators, so it is defined separately:. .. productionlist::; CondOperator: !cond. See `Appendix A: Bang Operators`_ for a description of each bang operator. Include files; -------------. TableGen has an include mechanism. The content of the included file; lexically replaces the ``include`` directive and is then parsed as if it was; originally in the main file. .. productionlist::; IncludeDirective: ""include"" `TokString`. Portions of the main file and included files can be conditionalized using; preprocessor directives. .. productionlist::; PreprocessorDirective: ""#define"" | ""#ifdef"" | ""#ifndef"". Types; =====. The TableGen language is statically typed, using a simple but complete type; system. Types are used to check for errors, to perform implicit conversions,; and to help interface designers constrain the allowed input. Every value is; required to have an associated type. TableGen supports a mixture of low-level types (e.g., ``bit``) and; high-level types (e.g., ``dag``). This flexibility allows you to describe a; wide range of records conveniently and compactly. .. productionlist::; Type: ""bit"" | ""int"" | ""string"" | ""dag""; :| ""bits"" ""<"" `TokInteger` "">""; :| ""list"" ""<"" `Type` "">""; :| `ClassID`; ClassID: `TokIdentifier`. ``bit``; A ``bit`` is a boolean value that can be 0 or 1. ``int``; The ``int`` type represents a simple 64-bit integer value, such as 5 or; -42. ``string``; The ``string`` type represents an ordered sequence of characters of arbitrary; length. ``bits<``\ *n*\ ``>``; The ``bits`` type is a fixed-sized integer of arbitrary length *n* that; is treated as separate bits. These bits can be accessed individually.; A field of this type is useful for representing an instruction operation; code, register number, or address mode/reg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:10344,interface,interface,10344,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['interface'],['interface']
Integrability," """"); endif(). # Set this name here, not used in multi conf loop,; # but add script will pick the right one.; set(LIBSFILE ${LLVM_BINARY_DIR}/${CMAKE_CFG_INTDIR}/libllvm-c.args). # Get the full name to the libs so the python script understands them.; foreach(lib ${LIB_NAMES}); list(APPEND FULL_LIB_NAMES ${LLVM_LIBRARY_DIR}/${lib}.lib); endforeach(). # Need to separate lib names with newlines.; string(REPLACE "";"" ""\n"" FILE_CONTENT ""${FULL_LIB_NAMES}""). if(NOT ""${CMAKE_CFG_INTDIR}"" STREQUAL "".""); foreach(BUILD_MODE ${CMAKE_CONFIGURATION_TYPES}); # Replace the special string with a per config directory.; string(REPLACE ${CMAKE_CFG_INTDIR} ${BUILD_MODE} PER_CONF_CONTENT ""${FILE_CONTENT}""). # Write out the full lib names into file to be read by the python script.; # One libsfile per build, the add_custom_command should expand; # ${CMAKE_CFG_INTDIR} correctly and select the right one.; file(WRITE ${LLVM_BINARY_DIR}/${BUILD_MODE}/libllvm-c.args ""${PER_CONF_CONTENT}""); endforeach(); else(); # Write out the full lib names into file to be read by the python script.; file(WRITE ${LIBSFILE} ""${FILE_CONTENT}""); endif(). # Generate the exports file dynamically.; set(GEN_SCRIPT ${CMAKE_CURRENT_SOURCE_DIR}/gen-msvc-exports.py). set(LLVM_EXPORTED_SYMBOL_FILE ${LLVM_BINARY_DIR}/${CMAKE_CFG_INTDIR}/libllvm-c.exports); get_host_tool_path(llvm-nm LLVM_NM llvm_nm_exe llvm_nm_target). add_custom_command(OUTPUT ${LLVM_EXPORTED_SYMBOL_FILE}; COMMAND ""${Python3_EXECUTABLE}"" ${GEN_SCRIPT} --libsfile ${LIBSFILE} ${GEN_UNDERSCORE} --nm ""${llvm_nm_exe}"" -o ${LLVM_EXPORTED_SYMBOL_FILE}; DEPENDS ${LIB_NAMES} ${llvm_nm_target}; COMMENT ""Generating export list for LLVM-C""; VERBATIM ). # Finally link the target.; add_llvm_library(LLVM-C SHARED INSTALL_WITH_TOOLCHAIN ${SOURCES} DEPENDS intrinsics_gen). if (LLVM_INTEGRATED_CRT_ALLOC AND MSVC); # Make sure we search LLVMSupport first, before the CRT libs; set(CMAKE_SHARED_LINKER_FLAGS ""${CMAKE_SHARED_LINKER_FLAGS} -INCLUDE:malloc""); endif(); ; endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt:6606,DEPEND,DEPENDS,6606,interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-shlib/CMakeLists.txt,2,['DEPEND'],['DEPENDS']
Integrability," ""0"" to draw TH2Poly. When used with any `COL` options, the empty; bins are not drawn.; - Fix a long pending problem with Z axis drawing when a lego or a surface was drawn; upside-down.; - Add a protection in TLatex when a string has a syntax error. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-7424).; - Implement the automatic placement of the Y axis title. If the title offset is; set to 0:; ~~~ {.cpp}; h->GetYaxis()->SetTitleOffset(0.);; ~~~; the axis title is automatically placed to avoid overlaps with the axis labels.; - Implement the automatic placement of the `TLegend`. A new constructor not; specifying the legend position is available. Only width and height are defined.; - `ChangeLabel` is now available for log axis as well as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8537).; - The `TGraph` copy constructor also copy the underlying `TH1F` if it exists (it; holds the axis titles).; - `TGraph` axis range was computed differently depending on the order of SetLog[x|y]""; This issue was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8751); - Add the new markers suggested [here](https://root-forum.cern.ch/t/adding-custom-markers/24506).; Improve the marker style for the OpenGl backend (some where wrong or missing). ![New markers](NewMarkers.png). - Remove a large memory leak in TFITSHDU's GetArrayRow, GetArrayColumn and GetTabRealVectorColumn member functions.; - When `TGraph`s belonging to a `TMultiGraph` were changed (for instance with `SetPoint`); after the `TMultiGraph` was drawn, the `TMultiGraph` range was not recomputed.; This issue was discovered thanks to [this forum post](https://root-forum.cern.ch/t/multi-layer-perceptron/24561/2).; - When a TGraph is drawn, the X-axis is drawn with increasing values from left to; right and the Y-axis from bottom to top. The two options `RX` and `RY` allow to; change this order. The option `RX` allows to draw the X-axis with increasing values; from right to left and the `RY` op",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:13531,depend,depending,13531,README/ReleaseNotes/v610/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md,1,['depend'],['depending']
Integrability," ""I1"" ); AT_decl_file( ""Objc_Property.m"" ); AT_decl_line( 3 ). 0x00000110 TAG_APPLE_property; AT_name ( ""p1"" ); AT_type ( {0x00000150} ( int ) ). 0x00000120: TAG_APPLE_property; AT_name ( ""p2"" ); AT_type ( {0x00000150} ( int ) ). 0x00000130: TAG_member [8]; AT_name( ""_p1"" ); AT_APPLE_property ( {0x00000110} ""p1"" ); AT_type( {0x00000150} ( int ) ); AT_artificial ( 0x1 ). 0x00000140: TAG_member [8]; AT_name( ""n2"" ); AT_APPLE_property ( {0x00000120} ""p2"" ); AT_type( {0x00000150} ( int ) ). 0x00000150: AT_type( ( int ) ). Note, the current convention is that the name of the ivar for an; auto-synthesized property is the name of the property from which it derives; with an underscore prepended, as is shown in the example. But we actually; don't need to know this convention, since we are given the name of the ivar; directly. Also, it is common practice in ObjC to have different property declarations in; the @interface and @implementation - e.g. to provide a read-only property in; the interface, and a read-write interface in the implementation. In that case,; the compiler should emit whichever property declaration will be in force in the; current translation unit. Developers can decorate a property with attributes which are encoded using; ``DW_AT_APPLE_property_attribute``. .. code-block:: objc. @property (readonly, nonatomic) int pr;. .. code-block:: none. TAG_APPLE_property [8]; AT_name( ""pr"" ); AT_type ( {0x00000147} (int) ); AT_APPLE_property_attribute (DW_APPLE_PROPERTY_readonly, DW_APPLE_PROPERTY_nonatomic). The setter and getter method names are attached to the property using; ``DW_AT_APPLE_property_setter`` and ``DW_AT_APPLE_property_getter`` attributes. .. code-block:: objc. @interface I1; @property (setter=myOwnP3Setter:) int p3;; -(void)myOwnP3Setter:(int)a;; @end. @implementation I1; @synthesize p3;; -(void)myOwnP3Setter:(int)a{ }; @end. The DWARF for this would be:. .. code-block:: none. 0x000003bd: TAG_structure_type [7] *; AT_APPLE_runtime_class( 0x10 ); AT_nam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:52763,interface,interface,52763,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,2,['interface'],['interface']
Integrability," ""Source"" form shall mean the preferred form for making modifications,; including but not limited to software source code, documentation; source, and configuration files. ""Object"" form shall mean any form resulting from mechanical; transformation or translation of a Source form, including but; not limited to compiled object code, generated documentation,; and conversions to other media types. ""Work"" shall mean the work of authorship, whether in Source or; Object form, made available under the License, as indicated by a; copyright notice that is included in or attached to the work; (an example is provided in the Appendix below). ""Derivative Works"" shall mean any work, whether in Source or Object; form, that is based on (or derived from) the Work and for which the; editorial revisions, annotations, elaborations, or other modifications; represent, as a whole, an original work of authorship. For the purposes; of this License, Derivative Works shall not include works that remain; separable from, or merely link (or bind by name) to the interfaces of,; the Work and Derivative Works thereof. ""Contribution"" shall mean any work of authorship, including; the original version of the Work and any modifications or additions; to that Work or Derivative Works thereof, that is intentionally; submitted to Licensor for inclusion in the Work by the copyright owner; or by an individual or Legal Entity authorized to submit on behalf of; the copyright owner. For the purposes of this definition, ""submitted""; means any form of electronic, verbal, or written communication sent; to the Licensor or its representatives, including but not limited to; communication on electronic mailing lists, source code control systems,; and issue tracking systems that are managed by, or on behalf of, the; Licensor for the purpose of discussing and improving the Work, but; excluding communication that is conspicuously marked or otherwise; designated in writing by the copyright owner as ""Not a Contribution."". ""C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT:2259,interface,interfaces,2259,interpreter/llvm-project/clang/LICENSE.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/LICENSE.TXT,5,['interface'],['interfaces']
Integrability," ""int a[2]"". Matcher<Type>decayedTypeMatcher<DecayedType>...; Matches decayed type; Example matches i[] in declaration of f.; (matcher = valueDecl(hasType(decayedType(hasDecayedType(pointerType()))))); Example matches i[1].; (matcher = expr(hasType(decayedType(hasDecayedType(pointerType()))))); void f(int i[]) {; i[1] = 0;; }. Matcher<Type>decltypeTypeMatcher<DecltypeType>...; Matches types nodes representing C++11 decltype(<expr>) types. Given:; short i = 1;; int j = 42;; decltype(i + j) result = i + j;; decltypeType(); matches ""decltype(i + j)"". Matcher<Type>deducedTemplateSpecializationTypeMatcher<DeducedTemplateSpecializationType>...; Matches C++17 deduced template specialization types, e.g. deduced class; template types. Given; template <typename T>; class C { public: C(T); };. C c(123);; deducedTemplateSpecializationType() matches the type in the declaration; of the variable c. Matcher<Type>dependentSizedArrayTypeMatcher<DependentSizedArrayType>...; Matches C++ arrays whose size is a value-dependent expression. Given; template<typename T, int Size>; class array {; T data[Size];; };; dependentSizedArrayType(); matches ""T data[Size]"". Matcher<Type>dependentSizedExtVectorTypeMatcher<DependentSizedExtVectorType>...; Matches C++ extended vector type where either the type or size is; dependent. Given; template<typename T, int Size>; class vector {; typedef T __attribute__((ext_vector_type(Size))) type;; };; dependentSizedExtVectorType(); matches ""T __attribute__((ext_vector_type(Size)))"". Matcher<Type>elaboratedTypeMatcher<ElaboratedType>...; Matches types specified with an elaborated type keyword or with a; qualified name. Given; namespace N {; namespace M {; class D {};; }; }; class C {};. class C c;; N::M::D d;. elaboratedType() matches the type of the variable declarations of both; c and d. Matcher<Type>enumTypeMatcher<EnumType>...; Matches enum types. Given; enum C { Green };; enum class S { Red };. C c;; S s;. enumType() matches the type of the variable declar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:47014,depend,dependent,47014,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,2,['depend'],['dependent']
Integrability," # (which would end up getting picked up by header search, instead of the correct; # versions).; if( CMAKE_CURRENT_SOURCE_DIR STREQUAL CMAKE_CURRENT_BINARY_DIR AND NOT MSVC_IDE ); message(FATAL_ERROR ""In-source builds are not allowed.; Please create a directory and run cmake from there, passing the path; to this source directory as the last argument.; This process created the file `CMakeCache.txt' and the directory `CMakeFiles'.; Please delete them.""); endif(). string(TOUPPER ""${CMAKE_BUILD_TYPE}"" uppercase_CMAKE_BUILD_TYPE). option(LLVM_ADDITIONAL_BUILD_TYPES ""Additional build types that are allowed to be passed into CMAKE_BUILD_TYPE"" """"). set(ALLOWED_BUILD_TYPES DEBUG RELEASE RELWITHDEBINFO MINSIZEREL ${LLVM_ADDITIONAL_BUILD_TYPES}); string (REPLACE "";"" ""|"" ALLOWED_BUILD_TYPES_STRING ""${ALLOWED_BUILD_TYPES}""); string (TOUPPER ""${ALLOWED_BUILD_TYPES_STRING}"" uppercase_ALLOWED_BUILD_TYPES). if (CMAKE_BUILD_TYPE AND; NOT uppercase_CMAKE_BUILD_TYPE MATCHES ""^(${uppercase_ALLOWED_BUILD_TYPES})$""); message(FATAL_ERROR ""Unknown value for CMAKE_BUILD_TYPE: ${CMAKE_BUILD_TYPE}""); endif(). # LLVM_INSTALL_PACKAGE_DIR needs to be declared prior to adding the tools; # subdirectory in order to have the value available for llvm-config.; include(GNUInstallPackageDir); set(LLVM_INSTALL_PACKAGE_DIR ""${CMAKE_INSTALL_PACKAGEDIR}/llvm"" CACHE STRING; ""Path for CMake subdirectory for LLVM (defaults to '${CMAKE_INSTALL_PACKAGEDIR}/llvm')""). set(LLVM_TOOLS_INSTALL_DIR ""${CMAKE_INSTALL_BINDIR}"" CACHE STRING; ""Path for binary subdirectory (defaults to '${CMAKE_INSTALL_BINDIR}')""); mark_as_advanced(LLVM_TOOLS_INSTALL_DIR). set(LLVM_UTILS_INSTALL_DIR ""${LLVM_TOOLS_INSTALL_DIR}"" CACHE STRING; ""Path to install LLVM utilities (enabled by LLVM_INSTALL_UTILS=ON) (defaults to LLVM_TOOLS_INSTALL_DIR)""); mark_as_advanced(LLVM_UTILS_INSTALL_DIR). set(LLVM_EXAMPLES_INSTALL_DIR ""examples"" CACHE STRING; ""Path for examples subdirectory (enabled by LLVM_BUILD_EXAMPLES=ON) (defaults to 'examples')""); mark_as",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:17824,message,message,17824,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['message'],['message']
Integrability," # your remotes here, if you don't remember what points to your; # fork, use git remote -v to see. Usually origin points to your; # fork and upstream to llvm/llvm-project; git push origin my_change. Before merging the PR, it is recommended that you rebase locally and re-run test; checks:. ::. # Add upstream as a remote (if you don't have it already); git remote add upstream https://github.com/llvm/llvm-project.git. # Make sure you have all the latest changes; git fetch upstream && git rebase -i upstream/main. # Make sure tests pass with latest changes and your change; ninja check. # Push the rebased changes to your fork.; git push origin my_change -f. # Now merge it; gh pr merge --squash --delete-branch. See more in-depth information about how to contribute in the following documentation:. * :doc:`Contributing`; * :doc:`MyFirstTypoFix`. Example Pull Request with git; ====================================. Instead of using the GitHub CLI to create a PR, you can push your code to a; remote branch on your fork and create the PR to upstream using the GitHub web; interface. Here is an example of making a PR using git and the GitHub web interface:. First follow the instructions to [fork the repository](https://docs.github.com/en/get-started/quickstart/fork-a-repo?tool=webui#forking-a-repository). Next follow the instructions to [clone your forked repository](https://docs.github.com/en/get-started/quickstart/fork-a-repo?tool=webui#cloning-your-forked-repository). Once you've cloned your forked repository,. ::. # Switch to the forked repo; cd llvm-project. # Create a new branch; git switch -c my_change. # Create your changes; $EDITOR file.cpp. # Don't forget clang-format; git clang-format. # and don't forget running your tests; ninja check-llvm. # Commit, use a good commit message; git commit file.cpp. # Push your changes to your fork branch, be mindful of; # your remotes here, if you don't remember what points to your; # fork, use git remote -v to see. Usually origin points ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitHub.rst:9601,interface,interface,9601,interpreter/llvm-project/llvm/docs/GitHub.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GitHub.rst,1,['interface'],['interface']
Integrability," #endif foo // no warning. #pragma clang diagnostic pop. The push and pop pragmas will save and restore the full diagnostic state; of the compiler, regardless of how it was set. That means that it is; possible to use push and pop around GCC compatible diagnostics and Clang; will push and pop them appropriately, while GCC will ignore the pushes; and pops as unknown pragmas. It should be noted that while Clang; supports the GCC pragma, Clang and GCC do not support the exact same set; of warnings, so even when using GCC compatible #pragmas there is no; guarantee that they will have identical behaviour on both compilers. In addition to controlling warnings and errors generated by the compiler, it is; possible to generate custom warning and error messages through the following; pragmas:. .. code-block:: c. // The following will produce warning messages; #pragma message ""some diagnostic message""; #pragma GCC warning ""TODO: replace deprecated feature"". // The following will produce an error message; #pragma GCC error ""Not supported"". These pragmas operate similarly to the ``#warning`` and ``#error`` preprocessor; directives, except that they may also be embedded into preprocessor macros via; the C99 ``_Pragma`` operator, for example:. .. code-block:: c. #define STR(X) #X; #define DEFER(M,...) M(__VA_ARGS__); #define CUSTOM_ERROR(X) _Pragma(STR(GCC error(X "" at line "" DEFER(STR,__LINE__)))). CUSTOM_ERROR(""Feature not available"");. Controlling Diagnostics in System Headers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Warnings are suppressed when they occur in system headers. By default,; an included file is treated as a system header if it is found in an; include path specified by ``-isystem``, but this can be overridden in; several ways. The ``system_header`` pragma can be used to mark the current file as; being a system header. No warnings will be produced from the location of; the pragma onwards within the same file. .. code-block:: c. #if foo; #endif foo // warning: extra ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:40890,message,message,40890,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['message'],['message']
Integrability," #endif. // To avoid problem with non-clang compilers not having this macro.; #if defined(__has_include_next); #if __has_include_next(""myinclude.h""); # include_next ""myinclude.h""; #endif; #endif. Note that ``__has_include_next``, like the GNU extension ``#include_next``; directive, is intended for use in headers only, and will issue a warning if; used in the top-level compilation file. A warning will also be issued if an; absolute path is used in the file argument. ``__has_warning``; -----------------. This function-like macro takes a string literal that represents a command line; option for a warning and returns true if that is a valid warning option. .. code-block:: c++. #if __has_warning(""-Wformat""); ...; #endif. .. _languageextensions-builtin-macros:. Builtin Macros; ==============. ``__BASE_FILE__``; Defined to a string that contains the name of the main input file passed to; Clang. ``__FILE_NAME__``; Clang-specific extension that functions similar to ``__FILE__`` but only; renders the last path component (the filename) instead of an invocation; dependent full path to that file. ``__COUNTER__``; Defined to an integer value that starts at zero and is incremented each time; the ``__COUNTER__`` macro is expanded. ``__INCLUDE_LEVEL__``; Defined to an integral value that is the include depth of the file currently; being translated. For the main file, this value is zero. ``__TIMESTAMP__``; Defined to the date and time of the last modification of the current source; file. ``__clang__``; Defined when compiling with Clang. ``__clang_major__``; Defined to the major marketing version number of Clang (e.g., the 2 in; 2.0.1). Note that marketing version numbers should not be used to check for; language features, as different vendors use different numbering schemes.; Instead, use the :ref:`langext-feature_check`. ``__clang_minor__``; Defined to the minor version number of Clang (e.g., the 0 in 2.0.1). Note; that marketing version numbers should not be used to check for langu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:12498,depend,dependent,12498,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['depend'],['dependent']
Integrability," $10^{-14}$. ## MnMigrad and VariableMetricMinimizer ##. [api:migrad]. MnMigrad provides minimization of the function by the method of; $\mbox{MIGRAD}$, the most efficient and complete single method,; recommended for general functions (see also [api:minimize]), and the; functionality for parameters interaction. It also retains the result; from the last minimization in case the user may want to do subsequent; minimization steps with parameter interactions in between the; minimization requests. The minimization is done by the; VariableMetricMinimizer. Minimization of the function can be done by; directly using the VariableMetricMinimizer if no parameters interaction; is required. The minimization produces as a by-product the error matrix; of the parameters, which is usually reliable unless warning messages are; produced. ### MnMigrad(const FCNBase&, const std::vector$<$double$>$&, const std::vector$<$double$>$&, unsigned int) ###. Constructor for the minimal required interface: $\mbox{FCN}$ and; starting values for parameters and uncertainties. Optional the strategy; level in MnStrategy can be specified. ### MnMigrad(const FCNBase&, const MnUserParameters&, unsigned int) ###. Constructor for high level parameters interface. Optional the strategy; level in MnStrategy can be specified. ### MnMigrad(const FCNBase&, const MnUserParameterState&, const MnStrategy&) ###. Constructor from a full state (parameters + covariance) as starting; input plus the desired strategy. ### operator() ###. [api:migradop] MnMigrad::operator()(unsigned int maxfcn, double; tolerance) causes minimization of the $\mbox{FCN}$ and returns the; result in form of a FunctionMinimum. The optional argument; $\mbox{maxfcn}$ specifies the (approximate) maximum number of; function calls after which the calculation will be stopped even if it; has not yet converged. The optional argument $\mbox{tolerance}$; specifies the required tolerance on the function value at the minimum.; The default $\mbox{tolerance}",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:42724,interface,interface,42724,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['interface'],['interface']
Integrability," ${CLANG_PGO_TRAINING_DATA_SOURCE_DIR}; USE_TOOLCHAIN EXLUDE_FROM_ALL NO_INSTALL DEPENDS generate-profraw); add_dependencies(generate-profdata generate-profraw-external); endif(); endif(); endif(). find_program(DTRACE dtrace); # TODO: Look into supporting this for the driver build. It will require changing; # the perf-helper.py file to understand to call `llvm` as `llvm clang`.; if(APPLE AND DTRACE AND NOT LLVM_TOOL_LLVM_DRIVER_BUILD); configure_lit_site_cfg(; ${CMAKE_CURRENT_SOURCE_DIR}/order-files.lit.site.cfg.in; ${CMAKE_CURRENT_BINARY_DIR}/order-files/lit.site.cfg; ). add_lit_testsuite(generate-dtrace-logs ""Generating clang dtrace data""; ${CMAKE_CURRENT_BINARY_DIR}/order-files/; EXCLUDE_FROM_CHECK_ALL; ARGS -j 1; DEPENDS clang clear-dtrace-logs; ). add_custom_target(clear-dtrace-logs; COMMAND ""${Python3_EXECUTABLE}"" ${CMAKE_CURRENT_SOURCE_DIR}/perf-helper.py clean ${CMAKE_CURRENT_BINARY_DIR} dtrace; COMMENT ""Clearing old dtrace data""). if(NOT CLANG_ORDER_FILE); message(FATAL_ERROR ""Output clang order file is not set""); endif(). add_custom_target(generate-order-file; COMMAND ""${Python3_EXECUTABLE}"" ${CMAKE_CURRENT_SOURCE_DIR}/perf-helper.py gen-order-file --binary $<TARGET_FILE:clang> --output ${CLANG_ORDER_FILE} ${CMAKE_CURRENT_BINARY_DIR}; COMMENT ""Generating order file""; DEPENDS generate-dtrace-logs); endif(). if(CLANG_BOLT_INSTRUMENT AND NOT LLVM_BUILD_INSTRUMENTED); configure_lit_site_cfg(; ${CMAKE_CURRENT_SOURCE_DIR}/bolt.lit.site.cfg.in; ${CMAKE_CURRENT_BINARY_DIR}/bolt-fdata/lit.site.cfg; ). add_lit_testsuite(generate-bolt-fdata ""Generating BOLT profile for Clang""; ${CMAKE_CURRENT_BINARY_DIR}/bolt-fdata/; EXCLUDE_FROM_CHECK_ALL; DEPENDS clang-instrumented clear-bolt-fdata; ). add_custom_target(clear-bolt-fdata; COMMAND ""${Python3_EXECUTABLE}"" ${CMAKE_CURRENT_SOURCE_DIR}/perf-helper.py clean ${CMAKE_CURRENT_BINARY_DIR} fdata; COMMENT ""Clearing old BOLT fdata""). # Merge profiles into one using merge-fdata; add_custom_target(clang-bolt-profile; COMMAND ""${Py",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/utils/perf-training/CMakeLists.txt:2574,message,message,2574,interpreter/llvm-project/clang/utils/perf-training/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/utils/perf-training/CMakeLists.txt,1,['message'],['message']
Integrability," %v = load i64, i64* %bc; ret i64 %v; }. define i32 @test(ptr %p) {; store i32 0, ptr %p; %v = load i64, ptr %p; ret i64 %v; }. Without opaque pointers, a check that the pointer operand of the load and; store are the same also ensures that the accessed type is the same. Using a; different type requires a bitcast, which will result in distinct pointer; operands. With opaque pointers, the bitcast is not present, and this check is no longer; sufficient. In the above example, it could result in store to load forwarding; of an incorrect type. Code making such assumptions needs to be adjusted to; check the accessed type explicitly:; ``LI->getType() == SI->getValueOperand()->getType()``. Frontends; ---------. Frontends need to be adjusted to track pointee types independently of LLVM,; insofar as they are necessary for lowering. For example, clang now tracks the; pointee type in the ``Address`` structure. Frontends using the C API through an FFI interface should be aware that a; number of C API functions are deprecated and will be removed as part of the; opaque pointer transition::. LLVMBuildLoad -> LLVMBuildLoad2; LLVMBuildCall -> LLVMBuildCall2; LLVMBuildInvoke -> LLVMBuildInvoke2; LLVMBuildGEP -> LLVMBuildGEP2; LLVMBuildInBoundsGEP -> LLVMBuildInBoundsGEP2; LLVMBuildStructGEP -> LLVMBuildStructGEP2; LLVMBuildPtrDiff -> LLVMBuildPtrDiff2; LLVMConstGEP -> LLVMConstGEP2; LLVMConstInBoundsGEP -> LLVMConstInBoundsGEP2; LLVMAddAlias -> LLVMAddAlias2. Additionally, it will no longer be possible to call ``LLVMGetElementType()``; on a pointer type. It is possible to control whether opaque pointers are used (if you want to; override the default) using ``LLVMContext::setOpaquePointers``. Temporarily disabling opaque pointers; =====================================. In LLVM 15, opaque pointers are enabled by default, but it it still possible to; use typed pointers using a number of opt-in flags. For users of the clang driver interface, it is possible to temporarily restore; the old de",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst:9954,interface,interface,9954,interpreter/llvm-project/llvm/docs/OpaquePointers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst,1,['interface'],['interface']
Integrability," (""{"" `RangeList` ""}"" | `RangePiece` | `Value`). The body of the ``foreach`` is a series of statements in braces or a; single statement with no braces. The statements are re-evaluated once for; each value in the range list, range piece, or single value. On each; iteration, the :token:`TokIdentifier` variable is set to the value and can; be used in the statements. The statement list establishes an inner scope. Variables local to a; ``foreach`` go out of scope at the end of each loop iteration, so their; values do not carry over from one iteration to the next. Foreach loops may; be nested. .. Note that the productions involving RangeList and RangePiece have precedence; over the more generic value parsing based on the first token. .. code-block:: text. foreach i = [0, 1, 2, 3] in {; def R#i : Register<...>;; def F#i : Register<...>;; }. This loop defines records named ``R0``, ``R1``, ``R2``, and ``R3``, along; with ``F0``, ``F1``, ``F2``, and ``F3``. ``dump`` --- print messages to stderr; -------------------------------------. A ``dump`` statement prints the input string to standard error; output. It is intended for debugging purpose. * At top level, the message is printed immediately. * Within a record/class/multiclass, `dump` gets evaluated at each; instantiation point of the containing record. .. productionlist::; Dump: ""dump"" `string` "";"". For example, it can be used in combination with `!repr` to investigate; the values passed to a multiclass:. .. code-block:: text. multiclass MC<dag s> {; dump ""s = "" # !repr(s);; }. ``if`` --- select statements based on a test; --------------------------------------------. The ``if`` statement allows one of two statement groups to be selected based; on the value of an expression. .. productionlist::; If: ""if"" `Value` ""then"" `IfBody`; :| ""if"" `Value` ""then"" `IfBody` ""else"" `IfBody`; IfBody: ""{"" `Statement`* ""}"" | `Statement`. The value expression is evaluated. If it evaluates to true (in the same; sense used by the bang operators)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:46958,message,messages,46958,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['message'],['messages']
Integrability," (PROOF) |; +---------------+------------------------------------------------------------+; | `proofserv` | the actual PROOF process, which is started by `proofd` |; | | after a user, has successfully been authenticated |; +---------------+------------------------------------------------------------+; | `rootd` | is the daemon for remote ROOT file access (see the |; | | **`TNetFile`**) |; +---------------+------------------------------------------------------------+. ### \$ROOTSYS/lib. There are several ways to use ROOT, one way is to run the executable; by typing `root` at the system prompt another way is to link with the; ROOT libraries and make the ROOT classes available in your own program. Here is a short description of the most relevant libraries, the ones; marked with a \* are only installed when the options specified them. - `libAsImage` is the image manipulation library. - `libCling` is the C++ interpreter (Cling). - `libCore` is the Base classes. - `libEG` is the abstract event generator interface classes. - \*`libEGPythia` is the Pythia5 event generator interface. - \*`libEGPythia6` is the Pythia6 event generator interface. - `libFitPanel` contains the GUI used for fitting. - `libGed` contains the GUI used for editing the properties of; histograms, graphs, etc. - `libGeom` is the geometry package (with builder and painter). - `libGpad` is the pad and canvas classes which depend on low level; graphics. - `libGraf` is the 2D graphics primitives (can be used independent; of libGpad). - `libGraf3d` is the 3D graphics primitives. - `libGui` is the GUI classes (depend on low level graphics). - `libGuiBld` is the GUI designer. - `libGuiHtml` contains the embedded HTML browser. - `libGX11` is the low level graphics interface to the X11 system. - \*`libGX11TTF` is an add-on library to libGX11 providing TrueType; fonts. - `libHbook` is for interface ROOT - HBOOK. - `libHist` is the histogram classes (with accompanying painter; library). - `libHtml` is the HTML docum",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:13522,interface,interface,13522,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['interface'],['interface']
Integrability," (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6918,rout,routines,6918,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['rout'],['routines']
Integrability," (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first gro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:6669,interface,interfaces,6669,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst,1,['interface'],['interfaces']
Integrability," (streamerElement type kStreamLoop). Fix support for call to MakeProject like:. gFile->MakeProject(""./classCode/"",""*"",""RECREATE++""). Better error handling if the source file failed to be created; or if the project directory can not be created. TParallelMergingFile. Introduce the class TParallelMergingFile part of the net package. This class connect ot a parallel merge server; and upload its content every time Write is called on the file object. After the upload the object of classes; with a ResetAfterMerge function are reset. A TParallelMergingFile is created whether a ?pmerge option is passed to TFile::Open as part of the file name.; For example:. TFile::Open(""mergedClient.root?pmerge"",""RECREATE""); // For now contact localhost:1095; TFile::Open(""mergedClient.root?pmerge=localhost:1095"",""RECREATE"");; TFile::Open(""rootd://root.cern/files/output.root?pmerger=pcanal:password@locahost:1095"",""NEW""). tutorials/net/treeClient.C and fastMergeServer.C: update to follow the change in interfaces; Introduce the tutorials parallelMergerClient.C and the temporary tutorials parallelMergerServer.C; to demonstrate the parallel merging (with parallelMergerServer.C being the prototype of the upcoming; parallel merger server executable). Other. Introduce the new function TFileMerger::PartialMerge(Int_t) which; will Merge the list of file _with_ the content of the output; file (if any). This allows make several successive Merge; into the same TFile object.; Yhe argument defines the type of merge as define by the bit values in EPartialMergeType:; ; kRegular : normal merge, overwritting the output file.; kIncremental : merge the input file with the content of the output file (if already exising) (default).; kAll : merge all type of objects (default).; kResetable : merge only the objects with a MergeAfterReset member function. ; kNonResetable : merge only the objects without a MergeAfterReset member function. . Removed TFileMerger::RecursiveMerge from the interface. Prevent TFileMerger (and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html:6544,interface,interfaces,6544,io/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html,2,['interface'],['interfaces']
Integrability," * **`ROOT::Math::IParametricFunctionMultiDim`**: Describes a multi dimensional parametric function. Similarly to the one dimensional version, the user needs to provide the; method `void SetParameters(double* p)` as well as the getter methods `const double * Parameters()` and `uint NPar()`.; Example of creating a parametric function:. ```{.cpp}; #include ""Math/IFunction.h""; #include ""Math/IParamFunction.h"". class MyParametricFunction: public ROOT::Math::IParametricFunctionMultiDim; {; private:; const double* pars;. public:; double DoEvalPar(const double* x, const double* p) const; {; return p[0] * x[0] + sin(x[1]) + p[1];; }. unsigned int NDim() const; {; return 2;; }. ROOT::Math::IParametricFunctionMultiDim* Clone() const; {; return new MyParametricFunction();; }. const double* Parameters() const; {; return pars;; }. void SetParameters(const double* p); {; pars = p;; }. unsigned int NPar() const; {; return 2;; }; };; ```. * **`ROOT::Math::IParametricGradFunctionMultiDim`**:; Provides an interface for parametric gradient multi-dimensional functions. In addition to function evaluation it provides the gradient with respect to the parameters,; via the method `ParameterGradient()`. This interface is only used in case of some dedicated fitting algorithms, when is required or more efficient to provide derivatives with respect to the; parameters. Here is an example:. ```{.cpp}; #include ""Math/IFunction.h""; #include ""Math/IParamFunction.h"". class MyParametricGradFunction:; public ROOT::Math::IParametricGradFunctionMultiDim; {; private:; const double* pars;. public:; double DoEvalPar(const double* x, const double* p) const; {; return p[0] * x[0] + sin(x[1]) + p[1];; }. unsigned int NDim() const; {; return 2;; }. ROOT::Math::IParametricGradFunctionMultiDim* Clone() const; {; return new MyParametricGradFunction();; }. const double* Parameters() const; {; return pars;; }. void SetParameters(const double* p); {; pars = p;; }. unsigned int NPar() const; {; return 2;; }. double DoP",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:40818,interface,interface,40818,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['interface'],['interface']
Integrability, * - clang/tools/clang-extdef-mapping; - `1`; - `0`; - `1`; - :none:`0%`; * - clang/tools/clang-format; - `1`; - `1`; - `0`; - :good:`100%`; * - clang/tools/clang-format/fuzzer; - `1`; - `0`; - `1`; - :none:`0%`; * - clang/tools/clang-fuzzer; - `6`; - `4`; - `2`; - :part:`66%`; * - clang/tools/clang-fuzzer/fuzzer-initialize; - `2`; - `0`; - `2`; - :none:`0%`; * - clang/tools/clang-fuzzer/handle-cxx; - `2`; - `0`; - `2`; - :none:`0%`; * - clang/tools/clang-fuzzer/handle-llvm; - `3`; - `1`; - `2`; - :part:`33%`; * - clang/tools/clang-fuzzer/proto-to-cxx; - `5`; - `0`; - `5`; - :none:`0%`; * - clang/tools/clang-fuzzer/proto-to-llvm; - `3`; - `0`; - `3`; - :none:`0%`; * - clang/tools/clang-import-test; - `1`; - `0`; - `1`; - :none:`0%`; * - clang/tools/clang-linker-wrapper; - `3`; - `2`; - `1`; - :part:`66%`; * - clang/tools/clang-nvlink-wrapper; - `1`; - `1`; - `0`; - :good:`100%`; * - clang/tools/clang-offload-bundler; - `1`; - `0`; - `1`; - :none:`0%`; * - clang/tools/clang-offload-wrapper; - `1`; - `1`; - `0`; - :good:`100%`; * - clang/tools/clang-pseudo; - `1`; - `1`; - `0`; - :good:`100%`; * - clang/tools/clang-refactor; - `4`; - `4`; - `0`; - :good:`100%`; * - clang/tools/clang-rename; - `1`; - `1`; - `0`; - :good:`100%`; * - clang/tools/clang-repl; - `1`; - `1`; - `0`; - :good:`100%`; * - clang/tools/clang-scan-deps; - `1`; - `1`; - `0`; - :good:`100%`; * - clang/tools/clang-shlib; - `1`; - `1`; - `0`; - :good:`100%`; * - clang/tools/diagtool; - `9`; - `0`; - `9`; - :none:`0%`; * - clang/tools/driver; - `4`; - `1`; - `3`; - :part:`25%`; * - clang/tools/libclang; - `35`; - `5`; - `30`; - :part:`14%`; * - clang/tools/scan-build-py/tests/functional/src/include; - `1`; - `1`; - `0`; - :good:`100%`; * - clang/unittests/Analysis; - `6`; - `2`; - `4`; - :part:`33%`; * - clang/unittests/Analysis/FlowSensitive; - `14`; - `13`; - `1`; - :part:`92%`; * - clang/unittests/AST; - `30`; - `8`; - `22`; - :part:`26%`; * - clang/unittests/ASTMatchers; - `6`; - `3`; - `3`; - :part,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst:12102,wrap,wrapper,12102,interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormattedStatus.rst,1,['wrap'],['wrapper']
Integrability," * A StringRef should not be bound to a temporary std::string whose lifetime is shorter than the StringRef's.; * Clang AST nodes should not have fields that can allocate memory. alpha.osx; ^^^^^^^^^. .. _alpha-osx-cocoa-DirectIvarAssignment:. alpha.osx.cocoa.DirectIvarAssignment (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for direct assignments to instance variables. .. code-block:: objc. @interface MyClass : NSObject {}; @property (readonly) id A;; - (void) foo;; @end. @implementation MyClass; - (void) foo {; _A = 0; // warn; }; @end. .. _alpha-osx-cocoa-DirectIvarAssignmentForAnnotatedFunctions:. alpha.osx.cocoa.DirectIvarAssignmentForAnnotatedFunctions (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for direct assignments to instance variables in; the methods annotated with ``objc_no_direct_instance_variable_assignment``. .. code-block:: objc. @interface MyClass : NSObject {}; @property (readonly) id A;; - (void) fAnnotated __attribute__((; annotate(""objc_no_direct_instance_variable_assignment"")));; - (void) fNotAnnotated;; @end. @implementation MyClass; - (void) fAnnotated {; _A = 0; // warn; }; - (void) fNotAnnotated {; _A = 0; // no warn; }; @end. .. _alpha-osx-cocoa-InstanceVariableInvalidation:. alpha.osx.cocoa.InstanceVariableInvalidation (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check that the invalidatable instance variables are; invalidated in the methods annotated with objc_instance_variable_invalidator. .. code-block:: objc. @protocol Invalidation <NSObject>; - (void) invalidate; __attribute__((annotate(""objc_instance_variable_invalidator"")));; @end. @interface InvalidationImpObj : NSObject <Invalidation>; @end. @interface SubclassInvalidationImpObj : InvalidationImpObj {; InvalidationImpObj *var;; }; - (void)invalidate;; @end. @implementation SubclassInvalidationImpObj; - (void) invalidate {}; @end; // warn: var needs to be invalidated or set to nil. .. _alpha-osx-cocoa-MissingInvalidat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:57768,interface,interface,57768,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['interface'],['interface']
Integrability," * Data classes containing the data sets used in the fitting. These classes are the`ROOT::Fit::BinData`for describing bin data sets,; 	 thus data points containing both coordinates and a corresponding value/weight; 	 with optionally an error on the value or the coordinate and the `ROOT::Fit::UnBinData` for un-binned data sets,; 	 which consists only of a vector of coordinate values. The coordinate values can be; 	 one-dimensional (i.e. one entry per event) or multi-dimensional (N entries per event).; * Function classes defining the type of fit (the objective function used for fitting):; 	- `ROOT::Fit::Chi2FCN` for chi2 (least-square fits),; 	- `ROOT::Fit::PoissonLikelihoodFCN` for binned likelihood fits of histograms,; 	- `ROOT::Fit::LogLikelihoodFCN` for generic un-binned likelihood fits.; 	These classes are templated on the type of function interface they implement (see later). User convenient typedefs are also provided.; 	They derive from the common generic interface multi-dimensional for function evaluation, `ROOT::Math::IBaseFunctionMultiDim`. In addition the fitter classes make uses of the generic interfaces for parametric function evaluations, `ROOT::Math::IParametricFunctionMultiDim`; to define the fit model function and use the `ROOT::Math::Minimizer` interface to perform the minimization of the objective function.; More information about the function interface and the multi-dimensional minimization in ROOT is given in the Mathematical Library chapter. Here we present a detailed description of the `ROOT::Fit` classes and how to use them.; Using these classes instead of the interface provided directly in the ROOT data objects, like `TH1::Fit` allow are more fine control; to configure and customise the fits. For example, using these classes a combined fit of several histograms can be performed. To understand how these class work, let's go through a simple example, such as fitting an histogram. When fitting an histogram, instead of using `TH1::Fit` we will sho",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:27815,interface,interface,27815,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['interface'],['interface']
Integrability," *G* was used we; also have alias to *F*. 4. Set *F* linkage to private. Make it strong :-). No global aliases, replaceDirectCallers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; If global aliases are not supported. We call ``replaceDirectCallers``. Just; go through all calls of *G* and replace it with calls of *F*. If you look into; the method you will see that it scans all uses of *G* too, and if use is callee; (if user is call instruction and *G* is used as what to be called), we replace; it with use of *F*. If â€œFâ€ could not be overridden, fix it!; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". We call ``writeThunkOrAlias(Function *F, Function *G)``. Here we try to replace; *G* with alias to *F* first. The next conditions are essential:. * target should support global aliases,; * the address itself of *G* should be not significant, not named and not; referenced anywhere,; * function should come with external, local or weak linkage. Otherwise we write thunk: some wrapper that has *G's* interface and calls *F*,; so *G* could be replaced with this wrapper. *writeAlias*. As follows from *llvm* reference:. â€œAliases act as *second name* for the aliasee valueâ€. So we just want to create; a second name for *F* and use it instead of *G*:. 1. create global alias itself (*GA*),. 2. adjust alignment of *F* so it must be maximum of current and *G's* alignment;. 3. replace uses of *G*:. 3.1. first mark all callers of *G* as to-be-analyzed-again, using; ``removeUsers`` method (see chapter above),. 3.2. call ``G->replaceAllUsesWith(GA)``. 4. Get rid of *G*. *writeThunk*. As it written in method comments:. â€œReplace G with a simple tail call to bitcast(F). Also replace direct uses of G; with bitcast(F). Deletes G.â€. In general it does the same as usual when we want to replace callee, except the; first point:. 1. We generate tail call wrapper around *F*, but with interface that allows use; it instead of *G*. 2. â€œAs-usualâ€: ``removeUsers`` and ``replaceAllUsesWith`` then. 3. Get rid of *G*. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst:30309,wrap,wrapper,30309,interpreter/llvm-project/llvm/docs/MergeFunctions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst,3,"['interface', 'wrap']","['interface', 'wrapper']"
Integrability," *b;; }; Q: How do I tell the static analyzer that I don't care about a specific dead store?; When the analyzer sees that a value stored into a variable is never used, it's going to produce a message similar to this one:; Value stored to 'x' is never read; You can use the (void)x; idiom to acknowledge that there is a dead store in your code but you do not want it to be reported in the future.; Q: How do I tell the static analyzer that I don't care about a specific unused instance variable in Objective C?; When the analyzer sees that a value stored into a variable is never used, it is going to produce a message similar to this one:; Instance variable 'commonName' in class 'HappyBird' is never used by the methods in its @implementation; You can add __attribute__((unused)) to the instance variable declaration to suppress the warning.; Q: How do I tell the static analyzer that I don't care about a specific unlocalized string?; When the analyzer sees that an unlocalized string is passed to a method that will present that string to the user, it is going to produce a message similar to this one:; User-facing text should use localized string macro. If your project deliberately uses unlocalized user-facing strings (for example, in a debugging UI that is never shown to users), you can suppress the analyzer warnings (and document your intent) with a function that just returns its input but is annotated to return a localized string:. __attribute__((annotate(""returns_localized_nsstring""))); static inline NSString *LocalizationNotNeeded(NSString *s) {; return s;; }. You can then call this function when creating your debugging UI:. [field setStringValue:LocalizationNotNeeded(@""Debug"")];. Some projects may also find it useful to use NSLocalizedString but add ""DNL"" or ""Do Not Localize"" to the string contents as a convention:. UILabel *testLabel = [[UILabel alloc] init];; NSString *s = NSLocalizedString(@""Hello <Do Not Localize>"", @""For debug purposes"");; [testLabel setText:s];. Q: H",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/faq.html:3302,message,message,3302,interpreter/llvm-project/clang/www/analyzer/faq.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/faq.html,2,['message'],['message']
Integrability," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:1476,message,message,1476,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,6,['message'],['message']
Integrability," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:1477,message,message,1477,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,4,['message'],['message']
Integrability," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ==============",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:1474,message,message,1474,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,2,['message'],['message']
Integrability," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== =====",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:1474,message,message,1474,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,2,['message'],['message']
Integrability," *option="""",; const Text_t *title="""",Int_t compress,Int_t netopt); ```. Depending on the `name` argument, the function returns a **`TFile`** or one; of its derivations, for example a; **`TNetXNGFile`** or a **`TDavixFile`** object. In case a URL; specifies a local file, a **`TFile`** object will be returned (and of; course no login information is needed). The arguments of the `Open()`; function are the same as the ones for the **`TFile`** constructor. Using `ReOpen()` method it is possible to reopen a file with a; different access mode, like from READ to UPDATE or from NEW, CREATE,; RECREATE, UPDATE to READ. Thus the mode argument can be either ""READ"" or; ""UPDATE"". The method returns:. - 0 in case the mode was successfully modified;. - 1 in case the mode did not change (it was already as requested or; there were wrong input arguments);. - -1 in case of failure. In the last case the file cannot be used; anymore. ## Remotely Access to ROOT Files. ROOT files can be accessed remotely in many ways, on the base of the protocol; URL. Among the most popular are XRootD (protocols 'root://' and 'xrd://') and; a Web server (protocl 'http://' or 'https://'). The rootd daemon is deprecated and has been removed in version 6.16/00. Please refer to the XRootD documentation for starting and ensuring that such a; daemon is running. Reading and writing ROOTÂ files over the net can be done by creating a; **`TFile`** object using the static method **`TFile::Open()`** object.; This will instantiate the appropriate derivation of **`TFile`** to handle the; request. Inheriting from the **`TFile`** class, the returned instance will have; exactly the same interface and behavior of **`TFile`**. The only difference; is that it reads and writes from a remote service.; In the example below the file is read via a web server through the TDavixFile plug-in. ### A Simple Session. ``` {.cpp}; root[] TFile *f1 = TFile::Open(""local/file.root"",""update""); root[] TFile *f2 = TFile::Open(""root://my.server.or",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:95601,protocol,protocol,95601,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['protocol'],['protocol']
Integrability," *â€˜No drawing'* sets On/Off the option ""`0`""- do not draw the fit; results. *â€˜Do not store/draw'* sets On/Off option ""`N`""- do not store the; function and do not draw it. ### Advances Options. The advance option button is enabled only after having performed the fit and provides; additional drawing options that can be used after having done the fit. These new drawing tools,; which can be selected by the ""Advanced Drawing Tool"" panel that pops up when clicking the ""Advanced"" button, are:. * *Contour*: to plot the confidence contour of two chosen parameters. One can select the number of points to draw the contour; (more points might require more time to compute it), the parameters and the desired confidence level . * *Scan* : to plot a scan of the minimization function (likelihood or chi-squared) around the minimum as function of the chosen parameter. * *Conf Interval* : to plot the confidence interval of the fitted function as a filled coloured band around its central value.; One can select the desired confidence level for the band to be plotted. ### Print Options. This set of options specifies the amount of feedback printed on the; root command line after performed fits. *â€˜Verbose'* - prints fit results after each iteration. *â€˜Quiet'* - no fit information is printed. *â€˜Default'* - between Verbose and Quiet. ### Command Buttons. *Fit button* - performs a fit taking different option settings via the; Fit Panel interface. *Reset* - sets the GUI elements and related fit settings to the; default ones. *Close* - closes the Fit panel window. ### Minimization Options. With this tab one can select specific options for minimization. These include. * The minimizer library ( *Minuit*, *Minuit2*, *Fumili*, *GSL*, *Genetics* ); * The method (algorithm) for minimization. For example for Minuit one can choose between (*Migrad*, *Simplex* or *Scan*); * Error definition; * Minimization tolerance; * Number of iterations/function calls; * Print Level: (*Default*, *Verbose* or *Quiet*). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:5694,interface,interface,5694,gui/fitpanel/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md,1,['interface'],['interface']
Integrability," - A landing pad block must have a '``landingpad``' instruction as its; first non-PHI instruction.; - There can be only one '``landingpad``' instruction within the landing; pad block.; - A basic block that is not a landing pad block may not include a; '``landingpad``' instruction. Example:; """""""""""""""". .. code-block:: llvm. ;; A landing pad which can catch an integer.; %res = landingpad { ptr, i32 }; catch ptr @_ZTIi; ;; A landing pad that is a cleanup.; %res = landingpad { ptr, i32 }; cleanup; ;; A landing pad which can catch an integer and can only throw a double.; %res = landingpad { ptr, i32 }; catch ptr @_ZTIi; filter [1 x ptr] [ptr @_ZTId]. .. _i_catchpad:. '``catchpad``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <resultval> = catchpad within <catchswitch> [<args>*]. Overview:; """""""""""""""""". The '``catchpad``' instruction is used by `LLVM's exception handling; system <ExceptionHandling.html#overview>`_ to specify that a basic block; begins a catch handler --- one where a personality routine attempts to transfer; control to catch an exception. Arguments:; """""""""""""""""""". The ``catchswitch`` operand must always be a token produced by a; :ref:`catchswitch <i_catchswitch>` instruction in a predecessor block. This; ensures that each ``catchpad`` has exactly one predecessor block, and it always; terminates in a ``catchswitch``. The ``args`` correspond to whatever information the personality routine; requires to know if this is an appropriate handler for the exception. Control; will transfer to the ``catchpad`` if this is the first appropriate handler for; the exception. The ``resultval`` has the type :ref:`token <t_token>` and is used to match the; ``catchpad`` to corresponding :ref:`catchrets <i_catchret>` and other nested EH; pads. Semantics:; """""""""""""""""""". When the call stack is being unwound due to an exception being thrown, the; exception is compared against the ``args``. If it doesn't match, control will; not reach the ``catchpad`` instruction. The re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:483747,rout,routine,483747,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['rout'],['routine']
Integrability," - `1, 2, 3 mean X, Y, Z; for `tube`, `tubs`, `cone`,; `cons - `1 means `Rxy`, 2 means `phi` and 3 means Z; for `pcon` and; `pgon` - 2 means `phi` and 3 means Z; for spheres 1 means `R `and 2; means `phi.`. In fact, the division operation has the same effect as positioning; volumes in a given order inside the divided container - the advantage; being that the navigation in such a structure is much faster. When a; volume is divided, a volume family corresponding to the slices is; created. In case all slices can be represented by a single shape, only; one volume is added to the family and positioned N times inside the; divided volume, otherwise, each slice will be represented by a distinct; volume in the family. Divisions can be also performed in a given range of one axis. For that,; one has to specify also the starting coordinate value and the step:. ``` {.cpp}; TGeoVolume *slicex = box->Divide(""SLICEX"",1,N,start,step);; ```. A check is always done on the resulting division range: if not fitting; into the container limits, an error message is posted. If we will browse; the divided volume we will notice that it will contain N nodes starting; with index 1 up to N. The first one has the lower X limit at `START`; position, while the last one will have the upper X limit at; `START+N*STEP`. The resulting slices cannot be positioned inside another; volume (they are by default positioned inside the divided one) but can; be further divided and may contain other volumes:. ``` {.cpp}; TGeoVolume *slicey = slicex->Divide(""SLICEY"",2,N1);; slicey->AddNode(other_vol,index,some_matrix);; ```. When doing that, we have to remember that `SLICEY` represents a family,; therefore all members of the family will be divided on Y and the other; volume will be added as node inside all. In the example above all the resulting slices had the same shape as the; divided volume (box). This is not always the case. For instance,; dividing a volume with `TUBE` shape on `PHI `axis will create equal; slice",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:85487,message,message,85487,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['message'],['message']
Integrability," --Wno-error=<value> - If set don't error out on the specified warning type.; =unknown - If set, unknown format options are only warned about.; This can be used to enable formatting, even if the; configuration contains unknown (newer) options.; Use with caution, as this might lead to dramatically; differing format depending on an option being; supported or not.; --assume-filename=<string> - Set filename used to determine the language and to find; .clang-format file.; Only used when reading from stdin.; If this is not passed, the .clang-format file is searched; relative to the current working directory when reading stdin.; Unrecognized filenames are treated as C++.; supported:; CSharp: .cs; Java: .java; JavaScript: .mjs .js .ts; Json: .json; Objective-C: .m .mm; Proto: .proto .protodevel; TableGen: .td; TextProto: .textpb .pb.txt .textproto .asciipb; Verilog: .sv .svh .v .vh; --cursor=<uint> - The position of the cursor when invoking; clang-format from an editor integration; --dry-run - If set, do not actually make the formatting changes; --dump-config - Dump configuration options to stdout and exit.; Can be used with -style option.; --fallback-style=<string> - The name of the predefined style used as a; fallback in case clang-format is invoked with; -style=file, but can not find the .clang-format; file to use. Defaults to 'LLVM'.; Use -fallback-style=none to skip formatting.; --ferror-limit=<uint> - Set the maximum number of clang-format errors to emit; before stopping (0 = no limit).; Used only with --dry-run or -n; --files=<filename> - A file containing a list of files to process, one per line.; -i - Inplace edit <file>s, if specified.; --length=<uint> - Format a range of this length (in bytes).; Multiple ranges can be formatted by specifying; several -offset and -length pairs.; When only a single -offset is specified without; -length, clang-format will format up to the end; of the file.; Can only be used with one input file.; --lines=<string> - <start line>:<end ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:1980,integrat,integration,1980,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['integrat'],['integration']
Integrability," --ctu-collect-only; ; # Analyze using the previously collected data; $ analyze-build --ctu-analyze-only. Use `--help` to get more information about the commands. Limitations; -----------. Generally speaking, the `intercept-build` and `analyze-build` tools together; does the same job as `scan-build` does. So, you can expect the same output; from this line as simple `scan-build` would do:. $ intercept-build <your build command> && analyze-build. The major difference is how and when the analyzer is run. The `scan-build`; tool has three distinct model to run the analyzer:. 1. Use compiler wrappers to make actions.; The compiler wrappers does run the real compiler and the analyzer.; This is the default behaviour, can be enforced with `--override-compiler`; flag. 2. Use special library to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` flag to get this model. 3. Use compiler wrappers to intercept compiler calls during the build process.; The analyzer run against each modules after the build finished.; Use `--intercept-first` and `--override-compiler` flags together to get; this model. The 1. and 3. are using compiler wrappers, which works only if the build; process respects the `CC` and `CXX` environment variables. (Some build; process can override these variable as command line parameter only. This case; you need to pass the compiler wrappers manually. eg.: `intercept-build; --override-compiler make CC=intercept-cc CXX=intercept-c++ all` where the; original build command would have been `make all` only.). The 1. runs the analyzer right after the real compilation. So, if the build; process removes removes intermediate modules (generated sources) the analyzer; output still kept. The 2. and 3. generate the compilation database first, and filters out those; modules which are not exists. So, it's suitable for incremental analysis during; the development. The 2. mode is available only",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md:2686,wrap,wrappers,2686,interpreter/llvm-project/clang/tools/scan-build-py/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/scan-build-py/README.md,1,['wrap'],['wrappers']
Integrability," -DLLVM_INCLUDE_TESTS=OFF""); endif(). if(LLVM_LIT); # Define the default arguments to use with 'lit', and an option for the user; # to override.; set(LIT_ARGS_DEFAULT ""-sv""); if (MSVC OR XCODE); set(LIT_ARGS_DEFAULT ""${LIT_ARGS_DEFAULT} --no-progress-bar""); endif(); set(LLVM_LIT_ARGS ""${LIT_ARGS_DEFAULT}"" CACHE STRING ""Default options for lit""). get_errc_messages(LLVM_LIT_ERRC_MESSAGES). # On Win32 hosts, provide an option to specify the path to the GnuWin32 tools.; if( WIN32 AND NOT CYGWIN ); set(LLVM_LIT_TOOLS_DIR """" CACHE PATH ""Path to GnuWin32 tools""); endif(); else(); set(LLVM_INCLUDE_TESTS OFF); endif(). umbrella_lit_testsuite_begin(check-all); endif() # LLVM_INCLUDE_TESTS; endif() # standalone. # Make sure that our source directory is on the current cmake module path so that; # we can include cmake files from this directory.; list(INSERT CMAKE_MODULE_PATH 0; ""${CMAKE_CURRENT_SOURCE_DIR}/cmake/modules""; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). # This allows disabling clang's XML dependency even if LLVM finds libxml2.; # By default, clang depends on libxml2 if LLVM does.; option(CLANG_ENABLE_LIBXML2 ""Whether libclang may depend on libxml2""; ${LLVM_ENABLE_LIBXML2}). if(CLANG_ENABLE_LIBXML2); # Don't look for libxml if we're using MSan, since uninstrumented third party; # code may call MSan interceptors like strlen, leading to false positives.; if(NOT LLVM_USE_SANITIZER MATCHES ""Memory.*""); set (LIBXML2_FOUND 0); find_package(LibXml2 2.5.3 QUIET); if (LIBXML2_FOUND); set(CLANG_HAVE_LIBXML 1); endif(); endif(); endif(). include(CheckIncludeFile); check_include_file(sys/resource.h CLANG_HAVE_RLIMITS). # This check requires _GNU_SOURCE on linux; check_include_file(dlfcn.h CLANG_HAVE_DLFCN_H); if( CLANG_HAVE_DLFCN_H ); include(CheckLibraryExists); include(CheckSymbolExists); check_library_exists(dl dlopen """" HAVE_LIBDL); if( HAVE_LIBDL ); list(APPEND CMAKE_REQUIRED_LIBRARIES dl); endif(); list(APPEND CMAKE_REQUIRED_DEFINITIONS -D_GNU_SOURCE); check_symbol_exists(dladd",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:5262,depend,dependency,5262,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,1,['depend'],['dependency']
Integrability," -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -fmodules-cache-path=cache -DENABLE_A; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -fmodules-cache-path=cache -DENABLE_A -DOTHER_OPTIONS. This way, a single directory containing multiple variants of modules can be prepared and reused. The options configuring the module cache are independent of other options. Module Semantics; ================. Modules are modeled as if each submodule were a separate translation unit, and a module import makes names from the other translation unit visible. Each submodule starts with a new preprocessor state and an empty translation unit. .. note::. This behavior is currently only approximated when building a module with submodules. Entities within a submodule that has already been built are visible when building later submodules in that module. This can lead to fragile modules that depend on the build order used for the submodules of the module, and should not be relied upon. This behavior is subject to change. As an example, in C, this implies that if two structs are defined in different submodules with the same name, those two types are distinct types (but may be *compatible* types if their definitions match). In C++, two structs defined with the same name in different submodules are the *same* type, and must be equivalent under C++'s One Definition Rule. .. note::. Clang currently only performs minimal checking for violations of the One Definition Rule. If any submodule of a module is imported into any part of a program, the entire top-level module is considered to be part of the program. As a consequence of this, Clang may diagnose conflicts between an entity declared in an unimported submodule and an entity declared in the current translation unit, and Clang may inline or devirtualize based on knowledge from unimported submodules. Macros; ------. The C and C++ preprocessor assumes that",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:24597,depend,depend,24597,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['depend'],['depend']
Integrability," -p. Display the specified section(s) as a list of strings. ``section`` may be a; section index or section name. .. option:: --string-table. Display contents of the string table. .. option:: --symbols, --syms, -s. Display the symbol table. .. option:: --unwind, -u. Display unwind information. .. option:: --version. Display the version of the :program:`llvm-readobj` executable. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. ELF SPECIFIC OPTIONS; --------------------. The following options are implemented only for the ELF file format. .. option:: --arch-specific, -A. Display architecture-specific information, e.g. the ARM attributes section on ARM. .. option:: --bb-addr-map. Display the contents of the basic block address map section(s), which contain the; address of each function, along with the relative offset of each basic block. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:4940,depend,dependent,4940,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,1,['depend'],['dependent']
Integrability," .. _DeclContext:. Declaration contexts; --------------------. Every declaration in a program exists within some *declaration context*, such; as a translation unit, namespace, class, or function. Declaration contexts in; Clang are represented by the ``DeclContext`` class, from which the various; declaration-context AST nodes (``TranslationUnitDecl``, ``NamespaceDecl``,; ``RecordDecl``, ``FunctionDecl``, etc.) will derive. The ``DeclContext`` class; provides several facilities common to each declaration context:. Source-centric vs. Semantics-centric View of Declarations. ``DeclContext`` provides two views of the declarations stored within a; declaration context. The source-centric view accurately represents the; program source code as written, including multiple declarations of entities; where present (see the section :ref:`Redeclarations and Overloads; <Redeclarations>`), while the semantics-centric view represents the program; semantics. The two views are kept synchronized by semantic analysis while; the ASTs are being constructed. Storage of declarations within that context. Every declaration context can contain some number of declarations. For; example, a C++ class (represented by ``RecordDecl``) contains various member; functions, fields, nested types, and so on. All of these declarations will; be stored within the ``DeclContext``, and one can iterate over the; declarations via [``DeclContext::decls_begin()``,; ``DeclContext::decls_end()``). This mechanism provides the source-centric; view of declarations in the context. Lookup of declarations within that context. The ``DeclContext`` structure provides efficient name lookup for names within; that declaration context. For example, if ``N`` is a namespace we can look; for the name ``N::f`` using ``DeclContext::lookup``. The lookup itself is; based on a lazily-constructed array (for declaration contexts with a small; number of declarations) or hash table (for declaration contexts with more; declarations). The looku",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:74012,synchroniz,synchronized,74012,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['synchroniz'],['synchronized']
Integrability," .. option:: --num-repetitions=<Number of repetitions>. Specify the target number of executed instructions. Note that the actual; repetition count of the snippet will be `num-repetitions`/`snippet size`.; Higher values lead to more accurate measurements but lengthen the benchmark. .. option:: --loop-body-size=<Preferred loop body size>. Only effective for `-repetition-mode=[loop|min]`.; Instead of looping over the snippet directly, first duplicate it so that the; loop body contains at least this many instructions. This potentially results; in loop body being cached in the CPU Op Cache / Loop Cache, which allows to; which may have higher throughput than the CPU decoders. .. option:: --max-configs-per-opcode=<value>. Specify the maximum configurations that can be generated for each opcode.; By default this is `1`, meaning that we assume that a single measurement is; enough to characterize an opcode. This might not be true of all instructions:; for example, the performance characteristics of the LEA instruction on X86; depends on the value of assigned registers and immediates. Setting a value of; `-max-configs-per-opcode` larger than `1` allows `llvm-exegesis` to explore; more configurations to discover if some register or immediate assignments; lead to different performance characteristics. .. option:: --benchmarks-file=</path/to/file>. File to read (`analysis` mode) or write (`latency`/`uops`/`inverse_throughput`; modes) benchmark results. ""-"" uses stdin/stdout. .. option:: --analysis-clusters-output-file=</path/to/file>. If provided, write the analysis clusters as CSV to this file. ""-"" prints to; stdout. By default, this analysis is not run. .. option:: --analysis-inconsistencies-output-file=</path/to/file>. If non-empty, write inconsistencies found during analysis to this file. `-`; prints to stdout. By default, this analysis is not run. .. option:: --analysis-filter=[all|reg-only|mem-only]. By default, all benchmark results are analysed, but sometimes it may be us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:14192,depend,depends,14192,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['depend'],['depends']
Integrability," ... *not allowed* to add or remove SCC's from the current Module, though; they may change the contents of an SCC.; #. ... *allowed* to add or remove global variables from the current Module.; #. ... *allowed* to maintain state across invocations of :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` (including global data). Implementing a ``CallGraphSCCPass`` is slightly tricky in some cases because it; has to handle SCCs with more than one node in it. All of the virtual methods; described below should return ``true`` if they modified the program, or; ``false`` if they didn't. The ``doInitialization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(CallGraph &CG);. The ``doInitialization`` method is allowed to do most of the things that; ``CallGraphSCCPass``\ es are not allowed to do. They can add and remove; functions, get pointers to functions, etc. The ``doInitialization`` method is; designed to do simple initialization type of stuff that does not depend on the; SCCs being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). .. _writing-an-llvm-pass-runOnSCC:. The ``runOnSCC`` method; ^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnSCC(CallGraphSCC &SCC) = 0;. The ``runOnSCC`` method performs the interesting work of the pass, and should; return ``true`` if the module was modified by the transformation, ``false``; otherwise. The ``doFinalization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(CallGraph &CG);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` for every SCC in the program being compiled. .. _writing-an-llvm-pass-FunctionPass:. The ``FunctionPass`` class; --------------------------. In contrast to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:16173,depend,depend,16173,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['depend'],['depend']
Integrability," ...---.---.---.---.-------...; | P | P | P | P | User; '''---'---'---'---'-------'''. * Layout b) is modelled by pointing at the ``Use[]`` array. .. code-block:: none. .-------...; | User; '-------'''; |; v; .---.---.---.---...; | P | P | P | P |; '---'---'---'---'''. *(In the above figures* '``P``' *stands for the* ``Use**`` *that is stored in; each* ``Use`` *object in the member* ``Use::Prev`` *)*. .. _polymorphism:. Designing Type Hierarchies and Polymorphic Interfaces; -----------------------------------------------------. There are two different design patterns that tend to result in the use of; virtual dispatch for methods in a type hierarchy in C++ programs. The first is; a genuine type hierarchy where different types in the hierarchy model; a specific subset of the functionality and semantics, and these types nest; strictly within each other. Good examples of this can be seen in the ``Value``; or ``Type`` type hierarchies. A second is the desire to dispatch dynamically across a collection of; polymorphic interface implementations. This latter use case can be modeled with; virtual dispatch and inheritance by defining an abstract interface base class; which all implementations derive from and override. However, this; implementation strategy forces an **""is-a""** relationship to exist that is not; actually meaningful. There is often not some nested hierarchy of useful; generalizations which code might interact with and move up and down. Instead,; there is a singular interface which is dispatched across a range of; implementations. The preferred implementation strategy for the second use case is that of; generic programming (sometimes called ""compile-time duck typing"" or ""static; polymorphism""). For example, a template over some type parameter ``T`` can be; instantiated across any particular implementation that conforms to the; interface or *concept*. A good example here is the highly generic properties of; any type which models a node in a directed graph. LLVM ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:129481,interface,interface,129481,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['interface'],['interface']
Integrability," ...; // IntRegs Super-register Classes..; static const TargetRegisterClass* const IntRegsSuperRegClasses [] = {; NULL; };; ...; // IntRegs Register Class sub-classes...; static const TargetRegisterClass* const IntRegsSubclasses [] = {; NULL; };; ...; // IntRegs Register Class super-classes...; static const TargetRegisterClass* const IntRegsSuperclasses [] = {; NULL; };. IntRegsClass::IntRegsClass() : TargetRegisterClass(IntRegsRegClassID,; IntRegsVTs, IntRegsSubclasses, IntRegsSuperclasses, IntRegsSubRegClasses,; IntRegsSuperRegClasses, 4, 4, 1, IntRegs, IntRegs + 32) {}; }. The register allocators will avoid using reserved registers, and callee saved; registers are not used until all the volatile registers have been used. That; is usually good enough, but in some cases it may be necessary to provide custom; allocation orders. Implement a subclass of ``TargetRegisterInfo``; ----------------------------------------------. The final step is to hand code portions of ``XXXRegisterInfo``, which; implements the interface described in ``TargetRegisterInfo.h`` (see; :ref:`TargetRegisterInfo`). These functions return ``0``, ``NULL``, or; ``false``, unless overridden. Here is a list of functions that are overridden; for the SPARC implementation in ``SparcRegisterInfo.cpp``:. * ``getCalleeSavedRegs`` --- Returns a list of callee-saved registers in the; order of the desired callee-save stack frame offset. * ``getReservedRegs`` --- Returns a bitset indexed by physical register; numbers, indicating if a particular register is unavailable. * ``hasFP`` --- Return a Boolean indicating if a function should have a; dedicated frame pointer register. * ``eliminateCallFramePseudoInstr`` --- If call frame setup or destroy pseudo; instructions are used, this can be called to eliminate them. * ``eliminateFrameIndex`` --- Eliminate abstract frame indices from; instructions that may use them. * ``emitPrologue`` --- Insert prologue code into the function. * ``emitEpilogue`` --- Insert epilogue",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:26453,interface,interface,26453,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['interface'],['interface']
Integrability, 1238; C++11; Overloading ambiguity binding reference to function; Unknown. 1239; C++11; Hexadecimal floating-point literals vs user-defined literals; Unknown. 1240; C++11; constexpr defaulted constructors; Unknown. 1241; C++11; Which members does a destructor destroy?; Unknown. 1242; C++11; Initializing variant class members; Unknown. 1243; C++11; Misleading footnote regarding multiple-declarator declarations; Unknown. 1244; C++11; Equivalence of alias templates and class templates; Unknown. 1245; C++11; Matching declarations involving decltype; Unknown. 1246; C++11; Non-deduced non-final parameter packs; Unknown. 1247; CD4; Restriction on alias name appearing in type-id; Unknown. 1248; open; Updating Annex C to C99; Not resolved. 1249; CD6; Cv-qualification of nested lambda capture; Unknown. 1250; CD3; Cv-qualification of incomplete virtual function return types; Clang 3.9. 1251; CD3; C compatibility: casting to unqualified void*; Unknown. 1252; CD6; Overloading member function templates based on dependent return type; Unknown. 1253; open; Generic non-template members; Not resolved. 1254; NAD; odr-use vs template arguments and constexpr functions; Unknown. 1255; drafting; Definition problems with constexpr functions; Not resolved. 1256; open; Unevaluated operands are not necessarily constant expressions; Not resolved. 1257; open; Instantiation via non-dependent references in uninstantiated templates; Not resolved. 1258; CD5; â€œInstantiation contextâ€ differs from dependent lookup rules; Unknown. 1259; NAD; Deleting a POD via a pointer to base; Unknown. 1260; CD3; Incorrect use of term â€œoverloadedâ€ in description of odr-use; Unknown. 1261; CD3; Explicit handling of cv-qualification with non-class prvalues; Unknown. 1262; CD3; Default template arguments and deduction failure; Unknown. 1263; NAD; Mismatch between rvalue reference binding and overload resolution; Unknown. 1264; CD3; Use of this in constexpr constructor; Unknown. 1265; CD3; Mixed use of the auto specifie,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:83488,depend,dependent,83488,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,2,['depend'],['dependent']
Integrability," 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Must be 0. 0; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:1203,message,message,1203,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,1,['message'],['message']
Integrability," 1`` is zero. Another example is:. .. code-block:: none. %1:(s32) = G_CONSTANT i32 0xFF0; %2:(s32) = G_AND %0, %1; %3:(s32) = G_CONSTANT i32 0x0FF; %4:(s32) = G_AND %2, %3. We can use the constants and the definition of ``G_AND`` to determine the known; bits:. .. code-block:: none. ; %0 = 0x????????; %1:(s32) = G_CONSTANT i32 0xFF0 ; %1 = 0x00000FF0; %2:(s32) = G_AND %0, %1 ; %2 = 0x00000??0; %3:(s32) = G_CONSTANT i32 0x0FF ; %3 = 0x000000FF; %4:(s32) = G_AND %2, %3 ; %4 = 0x000000?0. and then use this to simplify the expression:. .. code-block:: none. ; %0 = 0x????????; %5:(s32) = G_CONSTANT i32 0x0F0 ; %5 = 0x00000FF0; %4:(s32) = G_AND %0, %5 ; %4 = 0x000000?0. Note that ``%4`` still has the same known bits as before the transformation.; Many transformations share this property. The main exception being when the; transform causes undefined bits to become defined to either zero, one, or; defined but unknown. Usage; -----. To use Known Bits Analysis in a pass, first include the header and register the; dependency with ``INITIALIZE_PASS_DEPENDENCY``. .. code-block:: c++. #include ""llvm/CodeGen/GlobalISel/GISelKnownBits.h"". ... INITIALIZE_PASS_BEGIN(...); INITIALIZE_PASS_DEPENDENCY(GISelKnownBitsAnalysis); INITIALIZE_PASS_END(...). and require the pass in ``getAnalysisUsage``. .. code-block:: c++. void MyPass::getAnalysisUsage(AnalysisUsage &AU) const {; AU.addRequired<GISelKnownBitsAnalysis>();; // Optional: If your pass preserves known bits analysis (many do) then; // indicate that it's preserved for re-use by another pass here.; AU.addPreserved<GISelKnownBitsAnalysis>();; }. Then it's just a matter of fetching the analysis and using it:. .. code-block:: c++. bool MyPass::runOnMachineFunction(MachineFunction &MF) {; ...; GISelKnownBits &KB = getAnalysis<GISelKnownBitsAnalysis>().get(MF);; ...; MachineInstr *MI = ...;; KnownBits Known = KB->getKnownBits(MI->getOperand(0).getReg());; if (Known.Zeros & 1) {; // Bit 0 is known to be zero; }; ...; }. There are many more A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst:1473,depend,dependency,1473,interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst,1,['depend'],['dependency']
Integrability," 2. a coroutine resume function that is invoked when the coroutine is resumed,; which takes a pointer to the coroutine object and returns `void`;. 3. a coroutine destroy function that is invoked when the coroutine is; destroyed, which takes a pointer to the coroutine object and returns; `void`. Because the resume and destroy functions are shared across all suspend; points, suspend points must store the index of the active suspend in; the coroutine object, and the resume/destroy functions must switch over; that index to get back to the correct point. Hence the name of this; lowering. Pointers to the resume and destroy functions are stored in the coroutine; object at known offsets which are fixed for all coroutines. A completed; coroutine is represented with a null resume function. There is a somewhat complex protocol of intrinsics for allocating and; deallocating the coroutine object. It is complex in order to allow the; allocation to be elided due to inlining. This protocol is discussed; in further detail below. The frontend may generate code to call the coroutine function directly;; this will become a call to the ramp function and will return a pointer; to the coroutine object. The frontend should always resume or destroy; the coroutine using the corresponding intrinsics. Returned-Continuation Lowering; ------------------------------. In returned-continuation lowering, signaled by the use of; `llvm.coro.id.retcon` or `llvm.coro.id.retcon.once`, some aspects of; the ABI must be handled more explicitly by the frontend. In this lowering, every suspend point takes a list of ""yielded values""; which are returned back to the caller along with a function pointer,; called the continuation function. The coroutine is resumed by simply; calling this continuation function pointer. The original coroutine; is divided into the ramp function and then an arbitrary number of; these continuation functions, one for each suspend point. LLVM actually supports two closely-related returned-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:4955,protocol,protocol,4955,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['protocol'],['protocol']
Integrability, 2392; C++23; new-expression size check and constant evaluation; Unknown. 2393; NAD; Pseudo-destructors and object lifetime; Unknown. 2394; CD5; Const-default-constructible for members; Clang 15. 2395; drafting; Parameters following a pack expansion; Not resolved. 2396; CD6; Lookup of names in complex conversion-type-ids; No. 2397; CD6; auto specifier for pointers and references to arrays; Clang 17. 2398; drafting; Template template parameter matching and deduction; Not resolved. 2399; CD5; Unclear referent of â€œexpressionâ€ in assignment-expression; Unknown. 2400; CD5; Constexpr virtual functions and temporary objects; Unknown. 2401; drafting; Array decay vs prohibition of subobject non-type arguments; Not resolved. 2402; CD6; When is the restriction to a single c-char in a Unicode literal enforced?; Unknown. 2403; drafting; Temporary materialization and base/member initialization; Not resolved. 2404; CD5; [[no_unique_address]] and allocation order; Unknown. 2405; CD6; Additional type-dependent expressions; Unknown. 2406; CD5; [[fallthrough]] attribute and iteration statements; Clang 5. 2407; C++23; Missing entry in Annex C for defaulted comparison operators; Unknown. 2408; NAD; Temporaries and previously-initialized elements in aggregate initialization; Unknown. 2409; drafting; Explicit specializations of constexpr static data members; Not resolved. 2410; C++23; Implicit calls of immediate functions; Unknown. 2411; C++20; Comparison of pointers to members in template non-type arguments; Unknown. 2412; review; SFINAE vs undeduced placeholder type; Not resolved. 2413; CD6; typename in conversion-function-ids; Unknown. 2414; C++20; Unclear results if both member and friend operator<=> are declared; Unknown. 2415; NAD; using-declarations vs copy assignment operators; Unknown. 2416; C++20; Explicit specializations vs constexpr and consteval; Unknown. 2417; open; Explicit instantiation and exception specifications; Not resolved. 2418; CD5; Missing cases in definition of â€œu,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:164467,depend,dependent,164467,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,2,['depend'],['dependent']
Integrability," 42} # dict filled with str; >>> d[cppyy.gbl.gs] # drop-in use of std::string -> str; 42; >>>. To handle codecs other than UTF-8, the ``std::string`` pythonization adds a; ``decode`` method, with the same signature as the equivalent method of; ``bytes``.; If it is known that a specific C++ function always returns an ``std::string``; representing unicode with a codec other than UTF-8, it can in turn be; explicitly pythonized to do the conversion with that codec. `std::string_view`; """""""""""""""""""""""""""""""""""". It is possible to construct a (char-based) ``std::string_view`` from a Python; ``str``, but it requires the unicode object to be encoded and by default,; UTF-8 is chosen.; This will give the expected result if all characters in the ``str`` are from; the ASCII set, but otherwise it is recommend to encode on the Python side and; pass the resulting ``bytes`` object instead. `std::wstring`; """""""""""""""""""""""""""". C++'s ""wide"" string, ``std::wstring``, is based on ``wchar_t``, a character; type that is not particularly portable as it can be 2 or 4 bytes in size,; depending on the platform.; cppyy supports ``std::wstring`` directly, using the ``wchar_t`` array; conversions provided by Python's C-API. `const char*`; """""""""""""""""""""""""". The C representation of text, ``const char*``, is problematic for two; reasons: it does not express ownership; and its length is implicit, namely up; to the first occurrence of ``'\0'``.; The first can, up to an extent, be ameliorated: there are a range of cases; where ownership can be inferred.; In particular, if the C string is set from a Python ``str``, it is the latter; that owns the memory and the bound proxy of the former that in turn owns the; (unconverted) ``str`` instance.; However, if the ``const char*``'s memory is allocated in C/C++, memory; management is by necessity fully manual.; Length, on the other hand, can only be known in the case of a fixed array.; However even then, the more common case is to use the fixed array as a; buffer, with the a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst:2953,depend,depending,2953,bindings/pyroot/cppyy/cppyy/doc/source/strings.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst,1,['depend'],['depending']
Integrability," 5.24 in addition to these notes. Bindings - packages related to the interplay with other programming languages (Python, Ruby); Cint - the C++ interpreter; Core - the basic ROOT functionality; Geometry - building, representing and drawing geometrical objects; 2D Graphics - ROOT's two dimensional graphics interface; 3D Graphics - ROOT's three dimensional graphics interface; Graphical User Interface - from basic GUI elements to ROOT's own, complete dialogs; Histograming - counting values, spectra, and drawing them; HTML - the documentation generator; Input/Ouput - storing and reading data; Mathemathics - everything one can use to calculate: minimizers, matrixes, FFT, and much more; Miscellaneous - things that didn't make it into the other groups: table ; Monte Carlo - monte carlo and physics simulation interfaces; Networking - network-related parts, e.g. protocols and authentication interfaces; PROOF - parallel ROOT facility; RooFit - a fitting library; RooStats - a collection of statistical tools ; SQL - database interfaces; TMVA - multivariate analysis tools; Trees - ROOT's unique container class and related utilities. Binaries for all supported platforms are available at:. https://root.cern/releases/release-52600/. For more information, see:. http://root.cern.ch; The following people have contributed to this new version:; Bertrand Bellenot, CERN/SFT,; Brian Bockelman, UNL,; Rene Brun, CERN/SFT,; Philippe Canal, FNAL,; Olivier Couet, CERN/SFT,; Kyle Cranmer, NYU/Atlas, RooStats; Valeri Fine, BNL/STAR,; Lucie Flekova, CERN/SFT summer student,; Fabrizio Furano, CERN/IT, ; Gerri Ganis, CERN/SFT,; Andrei Gheata, CERN/Alice,; Mary-Louise Gill, CERN/SFT summer student,; David Gonzalez Maline, CERN/SFT, ; Andreas Hoecker, CERN/Atlas, TMVA ; Louis HÃ¶fler, ; Jan Iwaszkiewicz, CERN, ; Daniele Kruse, CERN, GDML; Wim Lavrijsen, LBNL, PyRoot; Alfio Lazzaro, Milano/AtlasMinuit; Sergei Linev, GSI,; Anar Manafov, GSI, ; Lorenzo Moneta, CERN/SFT,; Axel Naumann, CERN/SFT,; Eddy Offer",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/doc/v526/index.html:1222,protocol,protocols,1222,doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/doc/v526/index.html,6,"['interface', 'protocol']","['interfaces', 'protocols']"
Integrability," :program:`clang-format` is integrated into `CLion <https://www.jetbrains; .com/clion/>`_ as an alternative code formatter. CLion turns it on; automatically when there is a ``.clang-format`` file under the project root.; Code style rules are applied as you type, including indentation,; auto-completion, code generation, and refactorings. :program:`clang-format` can also be enabled without a ``.clang-format`` file.; In this case, CLion prompts you to create one based on the current IDE settings; or the default LLVM style. Visual Studio Integration; =========================. Download the latest Visual Studio extension from the `alpha build site; <https://llvm.org/builds/>`_. The default key-binding is Ctrl-R,Ctrl-F. Visual Studio Code Integration; ==============================. Get the latest Visual Studio Code extension from the `Visual Studio Marketplace <https://marketplace.visualstudio.com/items?itemName=xaver.clang-format>`_. The default key-binding is Alt-Shift-F. Git integration; ===============. The script `clang/tools/clang-format/git-clang-format` can be used to; format just the lines touched in git commits:. .. code-block:: console. % git clang-format -h; usage: git clang-format [OPTIONS] [<commit>] [<commit>|--staged] [--] [<file>...]. If zero or one commits are given, run clang-format on all lines that differ; between the working directory and <commit>, which defaults to HEAD. Changes are; only applied to the working directory, or in the stage/index. Examples:; To format staged changes, i.e everything that's been `git add`ed:; git clang-format. To also format everything touched in the most recent commit:; git clang-format HEAD~1. If you're on a branch off main, to format everything touched on your branch:; git clang-format main. If two commits are given (requires --diff), run clang-format on all lines in the; second <commit> that differ from the first <commit>. The following git-config settings set the default of the corresponding option:; clangFormat.bi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:10175,integrat,integration,10175,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['integrat'],['integration']
Integrability," ; Wigner coefficient functions:; ; double wigner_3j(int ja, int jb, int jc, int ma, int mb, int mc);; double wigner_6j(int ja, int jb, int jc, int jd, int je, int jf);; double wigner_9j(int ja, int jb, int jc, int jd, int je, int jf, int jg, int jh, int ji);; . New statistical function: non-central chisquare probability; density function; ; double noncentral_chisquared_pdf(double x, double r, double lambda);; ; It is implemented using Bessel functions or hypergeometric function; ; New classes VavilovAccurate and VavilovFast,; derived from the abstract base class Vavilov,; provide pdf, cdf and quantile functions for the Vavilov distribution,; based on the algorithms of CERNLIB (G116 and G115, respectively).; The classes VavilovAccuratePdf,; VavilovAccurateCdf and VavilovAccurateQuantile; implement the IParametricFunctionOneDim interface; for easier use in fit problems. . Unuran. Use new version 1.7.2 ; Add new class TUnuranSampler implementing the; ROOT::Math::DistSampler interface for one dimensional; continuous and discrete distributions and for mult-dimensional ones; . Foam. Add new class TFoamSampler implementing the; ROOT::Math::DistSampler interface for generating random; numbers according to any one or multi-dim distributions using Foam.; ; All the TFoam options can be controlled via the; ROOT::Math::DistSamplerOptions class, which can be passed; as input to the virtual ROOT::Math::DistSampler::Init(..); function.; . GenVector. Add some missing copy constructor and assignment operators to; fix compilation issue observed with LLVM (Clang). Minuit. Fix a bug when using at the same time TMinuit or TFitter with; the new TMinuitMinimizer class. See bug 72909.; . Minuit2. Fix the returned error from the Minimizer class for fixed and; constant parameters. Now is set explicitly to zero.; ; Fix a problem in re-defining fixed parameters as variable; ones. Before it was not possible to release them.; ; Fix a problem in the number of function calls when running MnHesse; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html:9083,interface,interface,9083,math/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html,2,['interface'],['interface']
Integrability," <N>, \ **a**\ <N+1>, ... **a**\ <K>\ **]** **[acc**\ <N>, \ **acc**\ <N+1>, ... **acc**\ <K>\ **]** A sequence of (\ *K-N+1*\ ) *accumulator* registers. Register indices must be specified as decimal; :ref:`integer numbers<amdgpu_synid_integer_number>`.; =================================================== ========================================================= ====================================================================. Note: *N* and *K* must satisfy the following conditions:. * *N* <= *K*.; * 0 <= *N* <= 255.; * 0 <= *K* <= 255.; * *K-N+1* must be in the range from 1 to 12 or equal to 16 or 32. GFX90A and GFX940 have an additional alignment requirement:; pairs of *accumulator* registers must be even-aligned; (first register must be even). Examples:. .. parsed-literal::. a255; a[0]; a[0:1]; a[1:1]; a[0:3]; a[2*2]; a[1-1:2-1]; [a252]; [a252,a253,a254,a255]. acc0; acc[1]; [acc250]; [acc2,acc3]. .. _amdgpu_synid_s:. s; -. Scalar 32-bit registers. The number of available *scalar* registers depends on the GPU:. ======= ============================; GPU Number of *scalar* registers; ======= ============================; GFX7 104; GFX8 102; GFX9 102; GFX10+ 106; ======= ============================. A sequence of *scalar* registers may be used to operate with more than 32 bits of data.; Assembler currently supports tuples with 1 to 12, 16 and 32 *scalar* registers. Pairs of *scalar* registers must be even-aligned (first register must be even).; Sequences of 4 and more *scalar* registers must be quad-aligned. ======================================================== ====================================================================; Syntax Description; ======================================================== ====================================================================; **s**\ <N> A single 32-bit *scalar* register. *N* must be a decimal; :ref:`integer number<amdgpu_synid_integer_number>`. **s[**\ <N>\ **]** A single 32-bit *scalar* register. *N* may be sp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:7025,depend,depends,7025,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,1,['depend'],['depends']
Integrability," <dest>, ptr <src>,; i64 <len>, i1 <isvolatile>). Overview:; """""""""""""""""". The '``llvm.memmove.*``' intrinsics move a block of memory from the; source location to the destination location. It is similar to the; '``llvm.memcpy``' intrinsic but allows the two memory locations to; overlap. Note that, unlike the standard libc function, the ``llvm.memmove.*``; intrinsics do not return a value, takes an extra isvolatile; argument and the pointers can be in specified address spaces. Arguments:; """""""""""""""""""". The first argument is a pointer to the destination, the second is a; pointer to the source. The third argument is an integer argument; specifying the number of bytes to copy, and the fourth is a; boolean indicating a volatile access. The :ref:`align <attr_align>` parameter attribute can be provided; for the first and second arguments. If the ``isvolatile`` parameter is ``true``, the ``llvm.memmove`` call; is a :ref:`volatile operation <volatile>`. The detailed access behavior is; not very cleanly specified and it is unwise to depend on it. Semantics:; """""""""""""""""""". The '``llvm.memmove.*``' intrinsics copy a block of memory from the; source location to the destination location, which may overlap. It; copies ""len"" bytes of memory over. If the argument is known to be; aligned to some boundary, this can be specified as an attribute on; the argument. If ``<len>`` is 0, it is no-op modulo the behavior of attributes attached to; the arguments.; If ``<len>`` is not a well-defined value, the behavior is undefined.; If ``<len>`` is not zero, both ``<dest>`` and ``<src>`` should be well-defined,; otherwise the behavior is undefined. .. _int_memset:. '``llvm.memset.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use llvm.memset on any integer; bit width and for different address spaces. However, not all targets; support all bit widths. ::. declare void @llvm.memset.p0.i32(ptr <dest>, i8 <val>,; i32 <len>, i1 <isvolatile>); decla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:551992,depend,depend,551992,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['depend'],['depend']
Integrability," <i_fmul>`, :ref:`fdiv <i_fdiv>`,; :ref:`frem <i_frem>`, :ref:`fcmp <i_fcmp>`), :ref:`phi <i_phi>`,; :ref:`select <i_select>` and :ref:`call <i_call>`; may use the following flags to enable otherwise unsafe; floating-point transformations. ``nnan``; No NaNs - Allow optimizations to assume the arguments and result are not; NaN. If an argument is a nan, or the result would be a nan, it produces; a :ref:`poison value <poisonvalues>` instead. ``ninf``; No Infs - Allow optimizations to assume the arguments and result are not; +/-Inf. If an argument is +/-Inf, or the result would be +/-Inf, it; produces a :ref:`poison value <poisonvalues>` instead. ``nsz``; No Signed Zeros - Allow optimizations to treat the sign of a zero; argument or zero result as insignificant. This does not imply that -0.0; is poison and/or guaranteed to not exist in the operation. ``arcp``; Allow Reciprocal - Allow optimizations to use the reciprocal of an; argument rather than perform division. ``contract``; Allow floating-point contraction (e.g. fusing a multiply followed by an; addition into a fused multiply-and-add). This does not enable reassociating; to form arbitrary contractions. For example, ``(a*b) + (c*d) + e`` can not; be transformed into ``(a*b) + ((c*d) + e)`` to create two fma operations. .. _fastmath_afn:. ``afn``; Approximate functions - Allow substitution of approximate calculations for; functions (sin, log, sqrt, etc). See floating-point intrinsic definitions; for places where this can apply to LLVM's intrinsic math functions. ``reassoc``; Allow reassociation transformations for floating-point instructions.; This may dramatically change results in floating-point. ``fast``; This flag implies all of the others. .. _uselistorder:. Use-list Order Directives; -------------------------. Use-list directives encode the in-memory order of each use-list, allowing the; order to be recreated. ``<order-indexes>`` is a comma-separated list of; indexes that are assigned to the referenced value's u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:162560,contract,contract,162560,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['contract'],"['contract', 'contraction']"
Integrability," <pthread.h>; int Global;; void *Thread1(void *x) {; Global = 42;; return x;; }; int main() {; pthread_t t;; pthread_create(&t, NULL, Thread1, NULL);; Global = 43;; pthread_join(t, NULL);; return Global;; }. $ clang -fsanitize=thread -g -O1 tiny_race.c. If a bug is detected, the program will print an error message to stderr.; Currently, ThreadSanitizer symbolizes its output using an external; ``addr2line`` process (this will be fixed in future). .. code-block:: bash. % ./a.out; WARNING: ThreadSanitizer: data race (pid=19219); Write of size 4 at 0x7fcf47b21bc0 by thread T1:; #0 Thread1 tiny_race.c:4 (exe+0x00000000a360). Previous write of size 4 at 0x7fcf47b21bc0 by main thread:; #0 main tiny_race.c:10 (exe+0x00000000a3b4). Thread T1 (running) created at:; #0 pthread_create tsan_interceptors.cc:705 (exe+0x00000000c790); #1 main tiny_race.c:9 (exe+0x00000000a3a4). ``__has_feature(thread_sanitizer)``; ------------------------------------. In some cases one may need to execute different code depending on whether; ThreadSanitizer is enabled.; :ref:`\_\_has\_feature <langext-__has_feature-__has_extension>` can be used for; this purpose. .. code-block:: c. #if defined(__has_feature); # if __has_feature(thread_sanitizer); // code that builds only under ThreadSanitizer; # endif; #endif. ``__attribute__((no_sanitize(""thread"")))``; -----------------------------------------------. Some code should not be instrumented by ThreadSanitizer. One may use the; function attribute ``no_sanitize(""thread"")`` to disable instrumentation of plain; (non-atomic) loads/stores in a particular function. ThreadSanitizer still; instruments such functions to avoid false positives and provide meaningful stack; traces. This attribute may not be supported by other compilers, so we suggest; to use it together with ``__has_feature(thread_sanitizer)``. ``__attribute__((disable_sanitizer_instrumentation))``; --------------------------------------------------------. The ``disable_sanitizer_instrumentation`` ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSanitizer.rst:2097,depend,depending,2097,interpreter/llvm-project/clang/docs/ThreadSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSanitizer.rst,1,['depend'],['depending']
Integrability," = A.getMember(I);; if (auto Err = ChildOrErr.takeError()) {; if (Err.isA<BadFileFormat>()); consumeError(std::move(Err)); else; return Err;; }; auto &Child = *ChildOrErr;; // Use Child; ...; }; return Error::success();; }. Concatenating Errors with joinErrors; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". In the archive walking example above ``BadFileFormat`` errors are simply; consumed and ignored. If the client had wanted report these errors after; completing the walk over the archive they could use the ``joinErrors`` utility:. .. code-block:: c++. Error walkArchive(Archive A) {; Error DeferredErrs = Error::success();; for (unsigned I = 0; I != A.numMembers(); ++I) {; auto ChildOrErr = A.getMember(I);; if (auto Err = ChildOrErr.takeError()); if (Err.isA<BadFileFormat>()); DeferredErrs = joinErrors(std::move(DeferredErrs), std::move(Err));; else; return Err;; auto &Child = *ChildOrErr;; // Use Child; ...; }; return DeferredErrs;; }. The ``joinErrors`` routine builds a special error type called ``ErrorList``,; which holds a list of user defined errors. The ``handleErrors`` routine; recognizes this type and will attempt to handle each of the contained errors in; order. If all contained errors can be handled, ``handleErrors`` will return; ``Error::success()``, otherwise ``handleErrors`` will concatenate the remaining; errors and return the resulting ``ErrorList``. Building fallible iterators and iterator ranges; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The archive walking examples above retrieve archive members by index, however; this requires considerable boiler-plate for iteration and error checking. We can; clean this up by using the ""fallible iterator"" pattern, which supports the; following natural iteration idiom for fallible containers like Archive:. .. code-block:: c++. Error Err = Error::success();; for (auto &Child : Ar->children(Err)) {; // Use Child - only enter the loop when it's valid. // Allow early exit from the loop body, since we know that Err is succ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:36402,rout,routine,36402,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['rout'],['routine']
Integrability," = G_ADD %src0:_(s32), %src1:_(s32). The above example adds %src1 to %src0 and stores the result in %dst. G_SDIVREM, G_UDIVREM; ^^^^^^^^^^^^^^^^^^^^. Perform integer division and remainder thereby producing two results. .. code-block:: none. %div:_(s32), %rem:_(s32) = G_SDIVREM %0:_(s32), %1:_(s32). G_SADDSAT, G_UADDSAT, G_SSUBSAT, G_USUBSAT, G_SSHLSAT, G_USHLSAT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Signed and unsigned addition, subtraction and left shift with saturation. .. code-block:: none. %2:_(s32) = G_SADDSAT %0:_(s32), %1:_(s32). G_SHL, G_LSHR, G_ASHR; ^^^^^^^^^^^^^^^^^^^^^. Shift the bits of a scalar left or right inserting zeros (sign-bit for G_ASHR). G_ROTR, G_ROTL; ^^^^^^^^^^^^^^. Rotate the bits right (G_ROTR) or left (G_ROTL). G_ICMP; ^^^^^^. Perform integer comparison producing non-zero (true) or zero (false). It's; target specific whether a true value is 1, ~0U, or some other non-zero value. G_SELECT; ^^^^^^^^. Select between two values depending on a zero/non-zero value. .. code-block:: none. %5:_(s32) = G_SELECT %4(s1), %6, %2. G_PTR_ADD; ^^^^^^^^^. Add a scalar offset in addressible units to a pointer. Addressible units are; typically bytes but this may vary between targets. .. code-block:: none. %1:_(p0) = G_PTR_ADD %0:_(p0), %1:_(s32). .. caution::. There are currently no in-tree targets that use this with addressable units; not equal to 8 bit. G_PTRMASK; ^^^^^^^^^^. Zero out an arbitrary mask of bits of a pointer. The mask type must be; an integer, and the number of vector elements must match for all; operands. This corresponds to `i_intr_llvm_ptrmask`. .. code-block:: none. %2:_(p0) = G_PTRMASK %0, %1. G_SMIN, G_SMAX, G_UMIN, G_UMAX; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Take the minimum/maximum of two values. .. code-block:: none. %5:_(s32) = G_SMIN %6, %2. G_ABS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Take the absolute value of a signed integer. The absolute value of the minimum; negative value (e.g. the 8-bit value `0x80`) i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:7201,depend,depending,7201,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,1,['depend'],['depending']
Integrability," = Records.getAllDerivedDefinitions(""Attribute"");; for (Record *AttrRec : AttrRecords) {; ...; }. Getting Record Names and Fields; ===============================. As described above (see `Record`_), there are multiple functions that; return the name of a record. One particularly useful one is; ``getNameInitAsString()``, which returns the name as a ``std::string``. There are also multiple functions that return the fields of a record. To; obtain and iterate over all the fields:. .. code-block:: text. for (const RecordVal &Field : SomeRec->getValues()) {; ...; }. You will recall that ``RecordVal`` is the class whose instances contain; information about the fields in records. The ``getValue()`` function returns the ``RecordVal`` instance for a field; specified by name. There are multiple overloaded functions, some taking a; ``StringRef`` and others taking a ``const Init *``. Some functions return a; ``RecordVal *`` and others return a ``const RecordVal *``. If the field does; not exist, a fatal error message is printed. More often than not, you are interested in the value of the field, not all; the information in the ``RecordVal``. There is a large set of functions that; take a field name in some form and return its value. One function,; ``getValueInit``, returns the value as an ``Init *``. Another function,; ``isValueUnset``, returns a boolean specifying whether the value is unset; (uninitialized). Most of the functions return the value in some more useful form. For; example:. .. code-block:: text. std::vector<int64_t> RegCosts =; SomeRec->getValueAsListOfInts(""RegCosts"");. The field ``RegCosts`` is assumed to be a list of integers. That list is; returned as a ``std::vector`` of 64-bit integers. If the field is not a list; of integers, a fatal error message is printed. Here is a function that returns a field value as a ``Record``, but returns; null if the field does not exist. .. code-block:: text. if (Record *BaseRec = SomeRec->getValueAsOptionalDef(BaseFieldName)) {",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackGuide.rst:20328,message,message,20328,interpreter/llvm-project/llvm/docs/TableGen/BackGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackGuide.rst,1,['message'],['message']
Integrability," = { [2].y = 1.0, [0].x = 1.0 };; point ptarray2[10] = { [2].y = 1.0, [2].x = 0.0, [0].x = 1.0 };; designatorCountIs(2); matches '{ [2].y = 1.0, [0].x = 1.0 }',; but not '{ [2].y = 1.0, [2].x = 0.0, [0].x = 1.0 }'. Matcher<EnumDecl>isScoped; Matches C++11 scoped enum declaration. Example matches Y (matcher = enumDecl(isScoped())); enum X {};; enum class Y {};. Matcher<Expr>isInstantiationDependent; Matches expressions that are instantiation-dependent even if it is; neither type- nor value-dependent. In the following example, the expression sizeof(sizeof(T() + T())); is instantiation-dependent (since it involves a template parameter T),; but is neither type- nor value-dependent, since the type of the inner; sizeof is known (std::size_t) and therefore the size of the outer; sizeof is known.; template<typename T>; void f(T x, T y) { sizeof(sizeof(T() + T()); }; expr(isInstantiationDependent()) matches sizeof(sizeof(T() + T()). Matcher<Expr>isTypeDependent; Matches expressions that are type-dependent because the template type; is not yet instantiated. For example, the expressions ""x"" and ""x + y"" are type-dependent in; the following code, but ""y"" is not type-dependent:; template<typename T>; void add(T x, int y) {; x + y;; }; expr(isTypeDependent()) matches x + y. Matcher<Expr>isValueDependent; Matches expression that are value-dependent because they contain a; non-type template parameter. For example, the array bound of ""Chars"" in the following example is; value-dependent.; template<int Size> int f() { return Size; }; expr(isValueDependent()) matches return Size. Matcher<Expr>nullPointerConstant; Matches expressions that resolve to a null pointer constant, such as; GNU's __null, C++11's nullptr, or C's NULL macro. Given:; void *v1 = NULL;; void *v2 = nullptr;; void *v3 = __null; // GNU extension; char *cp = (char *)0;; int *ip = 0;; int i = 0;; expr(nullPointerConstant()); matches the initializer for v1, v2, v3, cp, and ip. Does not match the; initializer for i. Matcher",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:86681,depend,dependent,86681,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,2,['depend'],['dependent']
Integrability," @end. Matcher<Decl>objcImplementationDeclMatcher<ObjCImplementationDecl>...; Matches Objective-C implementation declarations. Example matches Foo; @implementation Foo; @end. Matcher<Decl>objcInterfaceDeclMatcher<ObjCInterfaceDecl>...; Matches Objective-C interface declarations. Example matches Foo; @interface Foo; @end. Matcher<Decl>objcIvarDeclMatcher<ObjCIvarDecl>...; Matches Objective-C instance variable declarations. Example matches _enabled; @implementation Foo {; BOOL _enabled;; }; @end. Matcher<Decl>objcMethodDeclMatcher<ObjCMethodDecl>...; Matches Objective-C method declarations. Example matches both declaration and definition of -[Foo method]; @interface Foo; - (void)method;; @end. @implementation Foo; - (void)method {}; @end. Matcher<Decl>objcPropertyDeclMatcher<ObjCPropertyDecl>...; Matches Objective-C property declarations. Example matches enabled; @interface Foo; @property BOOL enabled;; @end. Matcher<Decl>objcProtocolDeclMatcher<ObjCProtocolDecl>...; Matches Objective-C protocol declarations. Example matches FooDelegate; @protocol FooDelegate; @end. Matcher<Decl>parmVarDeclMatcher<ParmVarDecl>...; Matches parameter variable declarations. Given; void f(int x);; parmVarDecl(); matches int x. Matcher<Decl>recordDeclMatcher<RecordDecl>...; Matches class, struct, and union declarations. Example matches X, Z, U, and S; class X;; template<class T> class Z {};; struct S {};; union U {};. Matcher<Decl>staticAssertDeclMatcher<StaticAssertDecl>...; Matches a C++ static_assert declaration. Example:; staticAssertDecl(); matches; static_assert(sizeof(S) == sizeof(int)); in; struct S {; int x;; };; static_assert(sizeof(S) == sizeof(int));. Matcher<Decl>tagDeclMatcher<TagDecl>...; Matches tag declarations. Example matches X, Z, U, S, E; class X;; template<class T> class Z {};; struct S {};; union U {};; enum E {; A, B, C; };. Matcher<Decl>templateTemplateParmDeclMatcher<TemplateTemplateParmDecl>...; Matches template template parameter declarations. Given; template <t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:16299,protocol,protocol,16299,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,2,['protocol'],['protocol']
Integrability," @interface I - (void) f:(int) y; @end; void foo(I *i) { [i f:12]; }; objcMessageExpr(hasAnyArgument(integerLiteral(equals(12)))); matches [i f:12]. Matcher<ObjCMessageExpr>hasArgumentunsigned N, Matcher<Expr> InnerMatcher; Matches the n'th argument of a call expression or a constructor; call expression. Example matches y in x(y); (matcher = callExpr(hasArgument(0, declRefExpr()))); void x(int) { int y; x(y); }. Matcher<ObjCMessageExpr>hasReceiverMatcher<Expr> InnerMatcher; Matches if the Objective-C message is sent to an instance,; and the inner matcher matches on that instance. For example the method call in; NSString *x = @""hello"";; [x containsString:@""h""];; is matched by; objcMessageExpr(hasReceiver(declRefExpr(to(varDecl(hasName(""x"")))))). Matcher<ObjCMessageExpr>hasReceiverTypeMatcher<QualType> InnerMatcher; Matches on the receiver of an ObjectiveC Message expression. Example; matcher = objCMessageExpr(hasReceiverType(asString(""UIWebView *"")));; matches the [webView ...] message invocation.; NSString *webViewJavaScript = ...; UIWebView *webView = ...; [webView stringByEvaluatingJavaScriptFromString:webViewJavascript];. Matcher<ObjCMethodDecl>hasAnyParameterMatcher<ParmVarDecl> InnerMatcher; Matches any parameter of a function or an ObjC method declaration or a; block. Does not match the 'this' parameter of a method. Given; class X { void f(int x, int y, int z) {} };; cxxMethodDecl(hasAnyParameter(hasName(""y""))); matches f(int x, int y, int z) {}; with hasAnyParameter(...); matching int y. For ObjectiveC, given; @interface I - (void) f:(int) y; @end. the matcher objcMethodDecl(hasAnyParameter(hasName(""y""))); matches the declaration of method f with hasParameter; matching y. For blocks, given; b = ^(int y) { printf(""%d"", y) };. the matcher blockDecl(hasAnyParameter(hasName(""y""))); matches the declaration of the block b with hasParameter; matching y. Matcher<ObjCMethodDecl>hasParameterunsigned N, Matcher<ParmVarDecl> InnerMatcher; Matches the n'th parameter of a f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:221992,message,message,221992,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,2,['message'],['message']
Integrability," @llvm.memset.p0.i32(ptr <dest>, i8 <val>,; i32 <len>, i1 <isvolatile>); declare void @llvm.memset.p0.i64(ptr <dest>, i8 <val>,; i64 <len>, i1 <isvolatile>). Overview:; """""""""""""""""". The '``llvm.memset.*``' intrinsics fill a block of memory with a; particular byte value. Note that, unlike the standard libc function, the ``llvm.memset``; intrinsic does not return a value and takes an extra volatile; argument. Also, the destination can be in an arbitrary address space. Arguments:; """""""""""""""""""". The first argument is a pointer to the destination to fill, the second; is the byte value with which to fill it, the third argument is an; integer argument specifying the number of bytes to fill, and the fourth; is a boolean indicating a volatile access. The :ref:`align <attr_align>` parameter attribute can be provided; for the first arguments. If the ``isvolatile`` parameter is ``true``, the ``llvm.memset`` call is; a :ref:`volatile operation <volatile>`. The detailed access behavior is not; very cleanly specified and it is unwise to depend on it. Semantics:; """""""""""""""""""". The '``llvm.memset.*``' intrinsics fill ""len"" bytes of memory starting; at the destination location. If the argument is known to be; aligned to some boundary, this can be specified as an attribute on; the argument. If ``<len>`` is 0, it is no-op modulo the behavior of attributes attached to; the arguments.; If ``<len>`` is not a well-defined value, the behavior is undefined.; If ``<len>`` is not zero, ``<dest>`` should be well-defined, otherwise the; behavior is undefined. .. _int_memset_inline:. '``llvm.memset.inline``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.memset.inline`` on any; integer bit width and for different address spaces. Not all targets; support all bit widths however. ::. declare void @llvm.memset.inline.p0.p0i8.i32(ptr <dest>, i8 <val>,; i32 <len>, i1 <isvolatile>); declare void @llvm.memset.inline.p0.p0.i64(ptr <dest>, i8 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:553914,depend,depend,553914,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['depend'],['depend']
Integrability," A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DO",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:1196,message,message,1196,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,7,['message'],['message']
Integrability," A marker is a point with a fancy shape! The possible markers are shown; in the next figure. ![Markers](pictures/030000B0.png). The marker constructor is:. ``` {.cpp}; TMarker(Double_t x,Double_t y,Int_t marker); ```. The parameters `x` and `y` are the marker coordinates and `marker` is; the marker type, shown in the previous figure. Suppose the pointer `ma`; is a valid marker. The marker size is set via `ma->SetMarkerSize(size)`,; where `size` is the desired size. Note, that the marker types 1, 6 and 7; (the dots) cannot be scaled. They are always drawn with the same number; of pixels. `SetMarkerSize` does not apply on them. To have a ""scalable; dot"" a circle shape should be used instead, for example, the marker type; 20. The default marker type is 1, if `SetMarkerStyle` is not specified.; It is the most common one to draw scatter plots. ![Different marker sizes](pictures/030000B1.png). ![Different marker sizes](pictures/030000B2.png). The user interface for changing the marker color, style and size looks; like shown in this picture. It takes place in the editor frame anytime; the selected object inherits the class **`TAttMarker`**. Non-symmetric symbols should be used carefully in plotting. The next two; graphs show how the misleading a careless use of symbols can be. The two; plots represent the same data sets but because of a bad symbol choice,; the two on the top appear further apart from the next example. ![The use of non-symmetric markers](pictures/030000B3.png). A **`TPolyMaker`** is defined by an array on N points in a 2D space. At; each point `x[i]`, `y[i]` a marker is drawn. The list of marker types is; shown in the previous paragraph. The marker attributes are managed by; the class **`TAttMarker`** and are described in ""Graphical Objects; Attributes"". The **`TPolyMarker`** constructor is:. ``` {.cpp}; TPolyMarker(Int_t n,Double_t *x,Double_t *y,Option_t *option); ```. Where `x` and `y` are arrays of coordinates for the `n` points that form; the poly-mark",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:37022,interface,interface,37022,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['interface'],['interface']
Integrability," ABI alignment of types; the layout of structs and; unions and the value returned by the alignof operator remain the same. This option can be overridden on a case-by-case basis by putting an explicit; â€œalignedâ€ alignment on a struct, union, or typedef. For example:. .. code-block:: console. #include <immintrin.h>; // Make an aligned typedef of the AVX-512 16-int vector type.; typedef __v16si __aligned_v16si __attribute__((aligned(64)));. void initialize_vector(__aligned_v16si *v) {; // The compiler may assume that â€˜vâ€™ is 64-byte aligned, regardless of the; // value of -fmax-type-align.; }. .. option:: -faddrsig, -fno-addrsig. Controls whether Clang emits an address-significance table into the object; file. Address-significance tables allow linkers to implement `safe ICF; <https://research.google.com/pubs/archive/36912.pdf>`_ without the false; positives that can result from other implementation techniques such as; relocation scanning. Address-significance tables are enabled by default; on ELF targets when using the integrated assembler. This flag currently; only has an effect on ELF targets. .. option:: -f[no]-unique-internal-linkage-names. Controls whether Clang emits a unique (best-effort) symbol name for internal; linkage symbols. When this option is set, compiler hashes the main source; file path from the command line and appends it to all internal symbols. If a; program contains multiple objects compiled with the same command-line source; file path, the symbols are not guaranteed to be unique. This option is; particularly useful in attributing profile information to the correct; function when multiple functions with the same private linkage name exist; in the binary. It should be noted that this option cannot guarantee uniqueness and the; following is an example where it is not unique when two modules contain; symbols with the same private linkage name:. .. code-block:: console. $ cd $P/foo && clang -c -funique-internal-linkage-names name_conflict.c; $ cd $P/ba",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:87053,integrat,integrated,87053,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['integrat'],['integrated']
Integrability," Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmax``' intrinsic performs the floating-point ``MAX``; reduction (:ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>`) of the; vector operand ``val`` on each enabled lane, taking the maximum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``-QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the smallest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``-Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>` intrinsic (and thus the; '``llvm.maxnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmax.v4f32(float %float, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:772536,depend,dependent,772536,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['depend'],['dependent']
Integrability," Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmin``' intrinsic performs the floating-point ``MIN``; reduction (:ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``+QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the largest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``+Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>` intrinsic (and thus the; '``llvm.minnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum element magnitude ``0.0`` and containing both ``+0.0`` and; ``-0.0`` elements, the sign of the result is unspecified. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.reduce.fmin.v4f32(float %start, <4 x float> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:775410,depend,dependent,775410,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['depend'],['dependent']
Integrability," Built Module Interface file; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. A ``Built Module Interface file`` stands for the precompiled result of an importable module unit.; It is also called the acronym ``BMI`` generally. Global module fragment; ~~~~~~~~~~~~~~~~~~~~~~. In a module unit, the section from ``module;`` to the module declaration is called the global module fragment. How to build projects using modules; -----------------------------------. Quick Start; ~~~~~~~~~~~. Let's see a ""hello world"" example that uses modules. .. code-block:: c++. // Hello.cppm; module;; #include <iostream>; export module Hello;; export void hello() {; std::cout << ""Hello World!\n"";; }. // use.cpp; import Hello;; int main() {; hello();; return 0;; }. Then we type:. .. code-block:: console. $ clang++ -std=c++20 Hello.cppm --precompile -o Hello.pcm; $ clang++ -std=c++20 use.cpp -fmodule-file=Hello=Hello.pcm Hello.pcm -o Hello.out; $ ./Hello.out; Hello World!. In this example, we make and use a simple module ``Hello`` which contains only a; primary module interface unit ``Hello.cppm``. Then let's see a little bit more complex ""hello world"" example which uses the 4 kinds of module units. .. code-block:: c++. // M.cppm; export module M;; export import :interface_part;; import :impl_part;; export void Hello();. // interface_part.cppm; export module M:interface_part;; export void World();. // impl_part.cppm; module;; #include <iostream>; #include <string>; module M:impl_part;; import :interface_part;. std::string W = ""World."";; void World() {; std::cout << W << std::endl;; }. // Impl.cpp; module;; #include <iostream>; module M;; void Hello() {; std::cout << ""Hello "";; }. // User.cpp; import M;; int main() {; Hello();; World();; return 0;; }. Then we are able to compile the example by the following command:. .. code-block:: console. # Precompiling the module; $ clang++ -std=c++20 interface_part.cppm --precompile -o M-interface_part.pcm; $ clang++ -std=c++20 impl_part.cppm --precompile -fprebuilt-module-pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:4978,interface,interface,4978,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,1,['interface'],['interface']
Integrability," C), or if the exception needs to be; forwarded to a prior activation, the exception frame contains information about; how to unwind the current activation and restore the state of the prior; activation. This process is repeated until the exception is handled. If the; exception is not handled and no activations remain, then the application is; terminated with an appropriate error message. Because different programming languages have different behaviors when handling; exceptions, the exception handling ABI provides a mechanism for; supplying *personalities*. An exception handling personality is defined by; way of a *personality function* (e.g. ``__gxx_personality_v0`` in C++),; which receives the context of the exception, an *exception structure*; containing the exception object type and value, and a reference to the exception; table for the current function. The personality function for the current; compile unit is specified in a *common exception frame*. The organization of an exception table is language dependent. For C++, an; exception table is organized as a series of code ranges defining what to do if; an exception occurs in that range. Typically, the information associated with a; range defines which types of exception objects (using C++ *type info*) that are; handled in that range, and an associated action that should take place. Actions; typically pass control to a *landing pad*. A landing pad corresponds roughly to the code found in the ``catch`` portion of; a ``try``/``catch`` sequence. When execution resumes at a landing pad, it; receives an *exception structure* and a *selector value* corresponding to the; *type* of exception thrown. The selector is then used to determine which *catch*; should actually process the exception. LLVM Code Generation; ====================. From a C++ developer's perspective, exceptions are defined in terms of the; ``throw`` and ``try``/``catch`` statements. In this section we will describe the; implementation of LLVM exceptio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:5009,depend,dependent,5009,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,1,['depend'],['dependent']
Integrability," CFA location; description.*. .. note::. Should DWARF allow the address size to be a different size to the size of; the register? Requiring them to be the same bit size avoids any issue of; conversion as the bit contents of the register is simply interpreted as a; value of the address. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers,; and to actually reading bytes from the next register (or reads out of bounds; for the last register) for smaller registers. There are no GDB tests that; read a register out of bounds (except an illegal hand written assembly; test). *register(R)*; This register has been stored in another register numbered R. The previous value of this register is the location description obtained using; the call frame information for the current frame and current program location; for register R. The DWARF is ill-formed if the size of this register does not match the size; of register R or if there is a cyclic dependency in the call frame; information. .. note::. Should this also allow R to be larger than this register? If so is the value; stored in the low order bits and it is undefined what is stored in the; extra upper bits?. *expression(E)*; The previous value of this register is located at the location description; produced by evaluating the DWARF operation expression E (see; :ref:`amdgpu-dwarf-operation-expressions`). E is evaluated with the current context, except the result kind is a location; description, the compilation unit is unspecified, the object is unspecified,; and an initial stack comprising the location description of the current CFA; (see :ref:`amdgpu-dwarf-operation-expressions`). *val_expression(E)*; The previous value of this register is located at the implicit location; description created from the value produced by evaluating the DWARF operation; expression E (see :ref:`amdgpu-dwarf-operation-expressions`). E is evaluated with the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:194167,depend,dependency,194167,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['depend'],['dependency']
Integrability," COFF COMDAT where a function will only be selected if; the COMDAT key's section is the largest:. .. code-block:: text. $foo = comdat largest; @foo = global i32 2, comdat($foo). define void @bar() comdat($foo) {; ret void; }. In a COFF object file, this will create a COMDAT section with selection kind; ``IMAGE_COMDAT_SELECT_LARGEST`` containing the contents of the ``@foo`` symbol; and another COMDAT section with selection kind; ``IMAGE_COMDAT_SELECT_ASSOCIATIVE`` which is associated with the first COMDAT; section and contains the contents of the ``@bar`` symbol. As a syntactic sugar the ``$name`` can be omitted if the name is the same as; the global name:. .. code-block:: llvm. $foo = comdat any; @foo = global i32 2, comdat; @bar = global i32 3, comdat($foo). There are some restrictions on the properties of the global object.; It, or an alias to it, must have the same name as the COMDAT group when; targeting COFF.; The contents and size of this object may be used during link-time to determine; which COMDAT groups get selected depending on the selection kind.; Because the name of the object must match the name of the COMDAT group, the; linkage of the global object must not be local; local symbols can get renamed; if a collision occurs in the symbol table. The combined use of COMDATS and section attributes may yield surprising results.; For example:. .. code-block:: llvm. $foo = comdat any; $bar = comdat any; @g1 = global i32 42, section ""sec"", comdat($foo); @g2 = global i32 42, section ""sec"", comdat($bar). From the object file perspective, this requires the creation of two sections; with the same name. This is necessary because both globals belong to different; COMDAT groups and COMDATs, at the object file level, are represented by; sections. Note that certain IR constructs like global variables and functions may; create COMDATs in the object file in addition to any which are specified using; COMDAT IR. This arises when the code generator is configured to emit globals",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:47883,depend,depending,47883,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['depend'],['depending']
Integrability," Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsRea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4665,depend,depends,4665,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,4,"['depend', 'integrat']","['depends', 'integration']"
Integrability," Clang related project you would like; added to this list. FreeBSD Clang Page. Site:. https://wiki.freebsd.org/BuildingFreeBSDWithClang. This is an effort to get FreeBSD to build with clang/llvm.; . Chromium Clang Page. Site:. https://chromium.googlesource.com/chromium/src/+/refs/heads/main/docs/clang.md. Notes on using Clang to build the Chromium web browser.; . Debian Clang Page. Sites:; https://clang.debian.net/. https://wiki.debian.org/llvm-clang. Notes on using Clang to rebuild the whole Debian archive.; . Include what you use. Site:; https://github.com/include-what-you-use/include-what-you-use. Analyze #includes in C and C++ source files; . OCLint. Site:; http://oclint.org/. OCLint is a static code analysis tool for improving quality and reducing defects by inspecting C, C++ and Objective-C code.; . DXR. Site:; https://github.com/mozilla/dxr. DXR is a code search and navigation tool aimed at making sense of large projects like Firefox. It supports full-text and regex searches as well as structural queries like ""Find all the callers of this function.""; . CodeCompass. Site:; https://github.com/Ericsson/CodeCompass. CodeCompass is an open-source, extensible code comprehension framework which uses LLVM/Clang to analyze and visualize C and C++ projects. It also supports both regex-based text search, discovering complex C/C++ language elements, with advanced navigation and visualisation.; . CodeChecker. Site:; https://github.com/Ericsson/CodeChecker. CodeChecker is a static analysis infrastructure built on the LLVM/Clang Static Analyzer toolchain. It provides a user interface to execute analysis of C/C++ projects with Clang SA and Clang-Tidy, which outputs are then stored into a database navigable via a web application. This web application and a corresponding command-line tool supports a variety of report management and issue triaging options, such as difference view between analyses, automatic incremental analysis, marking and commenting on individual reports.; . ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/related.html:1989,interface,interface,1989,interpreter/llvm-project/clang/www/related.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/related.html,2,['interface'],['interface']
Integrability," Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ----------------------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Suppor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:2456,depend,dependent,2456,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst,2,"['depend', 'interface']","['dependent', 'interfaces']"
Integrability," Constructors and Assignment. The following declarations are available:. ``` {.cpp}; // create an empty vector (x=0, y=0, z=0, t=0); XYZTVector v1;; // vector with x=1, y=2, z=3, t=4; XYZTVector v2(1,2,3,4);; // vector with pt=1, eta=2, phi=PI, E=5; PtEtaPhiEVector v3(1,2,PI,5);; ```. Note that each type of vector is constructed by passing its coordinate; representation, so a **`XYZTVector`**`(1,2,3,4)` is different from a; `PtEtaPhiEVector(1,2,3,4)`. In addition, the Vector classes can be; constructed by any vector, which implements the accessors `x()`, `y()`,; `z()` and `t()`. This can be another `ROOT::Math::`**`LorentzVector`** based on a; different coordinate system or any vector of a different package, like; the CLHEP **`HepLorentzVector`** that implements the required signature. ``` {.cpp}; XYZTVector v1(1,2,3,4);; PtEtaPhiEVector v2(v1);; CLHEP::HepLorentzVector q(1,2,3,4);; XYZTVector v3(q);; ```. #### Coordinate Accessors. All the same coordinate accessors are available through the interface of; `ROOT::Math::`**`LorentzVector`**. For example:. ``` {.cpp}; //returns cartesian components for the cartesian vector v1; v1.X(); v1.X(); v1.Z(); v1.T();; //returns cartesian components for the cylindrical vector v2; v2.Px(); v2.Py(); v2.Pz(); v2.E();; //returns other components for the cartesian vector v1; v1.Pt(); v1.Eta(); v1.Phi(); v1.M(); ```. In addition, all 4 vector coordinates can be retrieved with the; `GetCoordinates` method:. ``` {.cpp}; double d[4];; //fill d array with (x,y,z,t) components of v1; v1.GetCoordinates(d);; //fill d array with (pt,eta,phi,e) components of v2; v2.GetCoordinates(d);; std::vector w(4);; //fill std::vector with (x,y,z,t); v1.GetCoordinates(w.begin(),w.end());; //components of v1; ```. To get information on all the coordinate accessors see the; `ROOT::Math::`**`LorentzVector`** reference documentation. #### Setter Methods. One can set only all the three coordinates via:. ``` {.cpp}; //sets the (x,y,z,t) for a XYZTVector; v1.SetCo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:87908,interface,interface,87908,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['interface'],['interface']
Integrability," DR; Type-dependence of requires-expression; Unknown. 2786; open; Comparing pointers to complete objects; Not resolved. 2787; open; Kind of explicit object copy/move assignment function; Not resolved. 2788; open; Correspondence and redeclarations; Not resolved. 2789; DR; Overload resolution with implicit and explicit object member functions; Clang 18. 2790; open; Aggregate initialization and user-defined conversion sequence; Not resolved. 2791; DR; Unclear phrasing about ""returning to the caller""; Unknown. 2792; DR; Clean up specification of noexcept operator; Unknown. 2793; DR; Block-scope declaration conflicting with parameter name; Unknown. 2794; open; Uniqueness of lambdas in alias templates; Not resolved. 2795; DR; Overlapping empty subobjects with different cv-qualification; Unknown. 2796; DR; Function pointer conversions for relational operators; Unknown. 2797; open; Meaning of ""corresponds"" for rewritten operator candidates; Not resolved. 2798; DR; Manifestly constant evaluation of the static_assert message; Clang 17. 2799; drafting; Inheriting default constructors; Not resolved. 2800; review; Instantiating constexpr variables for potential constant evaluation; Not resolved. 2801; DR; Reference binding with reference-related types; Unknown. 2802; open; Constrained auto and redeclaration with non-abbreviated syntax; Not resolved. 2803; tentatively ready; Overload resolution for reference binding of similar types; Unknown. 2804; open; Lookup for determining rewrite targets; Not resolved. 2805; open; Underspecified selection of deallocation function; Not resolved. 2806; DR; Make a type-requirement a type-only context; Unknown. 2807; DR; Destructors declared consteval; Unknown. 2808; review; Explicit specialization of defaulted special member function; Not resolved. 2809; tentatively ready; An implicit definition does not redeclare a function; Unknown. 2810; tentatively ready; Requiring the absence of diagnostics for templates; Unknown. 2811; tentatively ready; C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:194101,message,message,194101,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,2,['message'],['message']
