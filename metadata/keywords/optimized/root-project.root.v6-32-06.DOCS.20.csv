quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Performance,"happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:301624,cache,cache,301624,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"haracterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine granularity such as on a per-function basis,; including intelligent handling of inlining decisions -- protected code can be; prevented from inlining into unprotected code, and unprotected code will become; protected when inlined into protected code. For systems where only a limited; set of code is reachable by externally controlled inputs, it may be possible to; limit the scope of mitigation through such mechanisms without compromising the; application's overall security. The performance impact may also be focused in a; few key functions that can be hand-mitigated in ways that have lower; performance overhead while the remainder of the application receives automatic; protection. For both limiting the scope of mitigation or manually mitigating hot functions,; there needs to be some support for mixing mitigated and unmitigated code; without completely defeating the mitigation. For the first use case, it would; be particularly desirable that mitigated code remains safe when being called; during misspeculation from unmitigated code. For the second use case, it may be important to connect the automatic; mitigation technique to explicit mitigation APIs such as what is described in; http://wg21.link/p0928 (or any other eventual API) so that there is a clean way; to switch from automatic to manual mitigation without immediately exposing a; hole. However, the design for how to do this is hard to come up with until the; APIs are better established. We will revisit this as those APIs mature.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:49671,perform,performance,49671,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,['perform'],['performance']
Performance,"hared by all SAs on the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each L1 quadrant of a single SA accesses a different L2 channel. Each L1; quadrant has a separate request queue per L2 channel. Therefore, the vector; and scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence.; * On GFX10.3 and GFX11 a memory attached last level (MALL) cache exists for GPU memory.; The MALL cache is fully coherent with GPU memory and has no impact on system; coherence. All agents (GPU and CPU) access GPU memory through the MALL cache. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:339779,cache,cache,339779,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"has a value less than or equal to 2. ``NT_AMD_HSA_HSAIL``; Specifies the HSAIL properties used by the HSAIL Finalizer. The description; field has the following layout:. .. code:: c. struct amdgpu_hsa_note_hsail_s {; uint32_t hsail_major_version;; uint32_t hsail_minor_version;; uint8_t profile;; uint8_t machine_model;; uint8_t default_float_round;; };. ``NT_AMD_HSA_ISA_VERSION``; Specifies the target ISA version. The description field has the following layout:. .. code:: c. struct amdgpu_hsa_note_isa_s {; uint16_t vendor_name_size;; uint16_t architecture_name_size;; uint32_t major;; uint32_t minor;; uint32_t stepping;; char vendor_and_architecture_name[1];; };. ``vendor_name_size`` and ``architecture_name_size`` are the length of the; vendor and architecture names respectively, including the NUL character. ``vendor_and_architecture_name`` contains the NUL terminates string for the; vendor, immediately followed by the NUL terminated string for the; architecture. This note record is used by the HSA runtime loader. Code object V2 only supports a limited number of processors and has fixed; settings for target features. See; :ref:`amdgpu-elf-note-record-supported_processors-v2-table` for a list of; processors and the corresponding target ID. In the table the note record ISA; name is a concatenation of the vendor name, architecture name, major, minor,; and stepping separated by a "":"". The target ID column shows the processor name and fixed target features used; by the LLVM compiler. The LLVM compiler does not generate a; ``NT_AMD_HSA_HSAIL`` note record. A code object generated by the Finalizer also uses code object V2 and always; generates a ``NT_AMD_HSA_HSAIL`` note record. The processor name and; ``sramecc`` target feature is as shown in; :ref:`amdgpu-elf-note-record-supported_processors-v2-table` but the ``xnack``; target feature is specified by the ``EF_AMDGPU_FEATURE_XNACK_V2`` ``e_flags``; bit. ``NT_AMD_HSA_ISA_NAME``; Specifies the target ISA name as a non-NUL term",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:72751,load,loader,72751,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loader']
Performance,"hat TH1/TH2 superimposing in 3D works properly; 4. Fix - use provided options in JSROOT.redraw function; 5. Fix - arb8 shape, used in composite. ## Changes in 5.7.1; 1. Fix - cover for WebVR API inconsistencies in Android devices (#184); 2. Fix - add more checks in TF1 GetParName/GetParValue methods (#185); 3. Fix - bins highlight in lego drawing with ""zero"" option; 4. Fix - drawing tracks with geometry from TObjArray; 5. Fix - interactive TGraph point move on time scale; 6. Fix - arb8 shapes faces building. ## Changes in 5.7.0; 1. Add support of TProfile2Poly class; 2. Add support of TGeoOverlap class, provide access from TGeoManager; 3. Add support of TGeoHalfSpace for composites; 4. Implement TF2 drawings update, see tutorials/graphics/anim.C; 5. Improve windows handling in flex(ible) layout; 6. Better position for text in TH2Poly drawings; 7. Enable projections drawing also with TH2 lego plots; 8. Use gStyle attributes to draw histogram title; 9. Use requestAnimationFrame when do monitoring, improves performance; 10. Support eve7 geometry viewer - render data generated in ROOT itself; 11. Many adjustment with new TWebCanvas - interactivity, attributes/position updates; 12. Provide initial WebVR support (#176), thanks to Diego Marcos (@dmarcos); 13. Upgrade three.js 86 -> 102, use SoftwareRenderer instead of CanvasRenderer; 14. Upgrade d3.js 4.4.4 -> 5.7.0; 15. Use d3.js and three.js from npm when running with node.js; 16. Fix - support clipping for tracks and points in geo painter; 17. Fix - drawing of TGeoNode with finder; 18. Fix - key press events processed only in active pad (ROOT-9128); 19. Fix - use X0/Y0 in xtru shape (#182), thanks to @altavir; 20. Move most of ui5-specific code into ROOT repository, where it will be maintained; 21. Provide special widget for object inspector. ## Changes in 5.6.4; 1. Fix - try workaround corrupted data in TTree; 2. Fix - support min0 draw option like ROOT does; 3. Fix - correctly handle TH2Poly draw options; 4. Fix - sel",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:30338,perform,performance,30338,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['perform'],['performance']
Performance,"hat allow injecting passes into; certain parts of the pipeline. For example,. .. code-block:: c++. PassBuilder PB;; PB.registerPipelineStartEPCallback([&](ModulePassManager &MPM,; PassBuilder::OptimizationLevel Level) {; MPM.addPass(FooPass());; };. will add ``FooPass`` near the very beginning of the pipeline for pass; managers created by that ``PassBuilder``. See the documentation for; ``PassBuilder`` for the various places that passes can be added. If a ``PassBuilder`` has a corresponding ``TargetMachine`` for a backend, it; will call ``TargetMachine::registerPassBuilderCallbacks()`` to allow the; backend to inject passes into the pipeline. Clang's ``BackendUtil.cpp`` shows examples of a frontend adding (mostly; sanitizer) passes to various parts of the pipeline.; ``AMDGPUTargetMachine::registerPassBuilderCallbacks()`` is an example of a; backend adding passes to various parts of the pipeline. Pass plugins can also add passes into default pipelines. Different tools have; different ways of loading dynamic pass plugins. For example, ``opt; -load-pass-plugin=path/to/plugin.so`` loads a pass plugin into ``opt``. For; information on writing a pass plugin, see :doc:`WritingAnLLVMNewPMPass`. Using Analyses; ==============. LLVM provides many analyses that passes can use, such as a dominator tree.; Calculating these can be expensive, so the new pass manager has; infrastructure to cache analyses and reuse them when possible. When a pass runs on some IR, it also receives an analysis manager which it can; query for analyses. Querying for an analysis will cause the manager to check if; it has already computed the result for the requested IR. If it already has and; the result is still valid, it will return that. Otherwise it will construct a; new result by calling the analysis's ``run()`` method, cache it, and return it.; You can also ask the analysis manager to only return an analysis if it's; already cached. The analysis manager only provides analysis results for the same IR",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:6567,load,loading,6567,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['load'],['loading']
Performance,"hat any retainable object pointers it receives or; generates are instantaneously valid from that point until a point; which, by the concurrency model of the host language, happens-after; the generation of the pointer and happens-before a release of that; object (possibly via an aliasing pointer or indirectly due to; destruction of a different object). .. admonition:: Rationale. There is very little point in trying to guarantee correctness in the; presence of race conditions. ARC does not have a stack-scanning; garbage collector, and guaranteeing the atomicity of every load and; store operation would be prohibitive and preclude a vast amount of; optimization. ARC may assume that non-ARC code engages in sensible balancing; behavior and does not rely on exact or minimum retain count values; except as guaranteed by ``__strong`` object invariants or +1 transfer; conventions. For example, if an object is provably double-retained; and double-released, ARC may eliminate the inner retain and release;; it does not need to guard against code which performs an unbalanced; release followed by a ""balancing"" retain. .. _arc.optimization.liveness:. Object liveness; ---------------. ARC may not allow a retainable object ``X`` to be deallocated at a; time ``T`` in a computation history if:. * ``X`` is the value stored in a ``__strong`` object ``S`` with; :ref:`precise lifetime semantics <arc.optimization.precise>`, or. * ``X`` is the value stored in a ``__strong`` object ``S`` with; imprecise lifetime semantics and, at some point after ``T`` but; before the next store to ``S``, the computation history features a; load from ``S`` and in some way depends on the value loaded, or. * ``X`` is a value described as being released at the end of the; current full-expression and, at some point after ``T`` but before; the end of the full-expression, the computation history depends; on that value. .. admonition:: Rationale. The intent of the second rule is to say that objects held in normal; ``_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:78567,perform,performs,78567,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['performs']
Performance,"hat can help developers, generally they must have code available. List of projects and tools; ==========================. `<https://github.com/Andersbakken/rtags/>`_; ""RTags is a client/server application that indexes c/c++ code and keeps; a persistent in-memory database of references, symbolnames, completions; etc."". `<https://rprichard.github.io/CxxCodeBrowser/>`_; ""A C/C++ source code indexer and navigator"". `<https://github.com/etaoins/qconnectlint>`_; ""qconnectlint is a Clang tool for statically verifying the consistency; of signal and slot connections made with Qt's ``QObject::connect``."". `<https://github.com/woboq/woboq_codebrowser>`_; ""The Woboq Code Browser is a web-based code browser for C/C++ projects.; Check out `<https://code.woboq.org/>`_ for an example!"". `<https://github.com/mozilla/dxr>`_; ""DXR is a source code cross-reference tool that uses static analysis; data collected by instrumented compilers."". `<https://github.com/eschulte/clang-mutate>`_; ""This tool performs a number of operations on C-language source files."". `<https://github.com/gmarpons/Crisp>`_; ""A coding rule validation add-on for LLVM/clang. Crisp rules are written; in Prolog. A high-level declarative DSL to easily write new rules is under; development. It will be called CRISP, an acronym for *Coding Rules in; Sugared Prolog*."". `<https://github.com/drothlis/clang-ctags>`_; ""Generate tag file for C++ source code."". `<https://github.com/exclipy/clang_indexer>`_; ""This is an indexer for C and C++ based on the libclang library."". `<https://github.com/holtgrewe/linty>`_; ""Linty - C/C++ Style Checking with Python & libclang."". `<https://github.com/axw/cmonster>`_; ""cmonster is a Python wrapper for the Clang C++ parser."". `<https://github.com/rizsotto/Constantine>`_; ""Constantine is a toy project to learn how to write clang plugin.; Implements pseudo const analysis. Generates warnings about variables,; which were declared without const qualifier."". `<https://github.com/jessevdk/cldoc>`_; """,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ExternalClangExamples.rst:2034,perform,performs,2034,interpreter/llvm-project/clang/docs/ExternalClangExamples.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ExternalClangExamples.rst,1,['perform'],['performs']
Performance,"hat have made existing approaches to safer C dialects difficult to; adopt, offering these properties that make it widely adoptable in practice:. * It is designed to preserve the Application Binary Interface (ABI).; * It interoperates well with plain C code.; * It can be adopted partially and incrementally while still providing safety; benefits.; * It is a conforming extension to C.; * Consequently, source code that adopts the extension can continue to be; compiled by toolchains that do not support the extension (CAVEAT: this still; requires inclusion of a header file macro-defining bounds annotations to; empty).; * It has a relatively low adoption cost. This document discusses the key designs of ``-fbounds-safety``. The document is; subject to be actively updated with a more detailed specification. The; implementation plan can be found in :doc:`BoundsSafetyImplPlans`. Programming Model; =================. Overview; --------. ``-fbounds-safety`` ensures that pointers are not used to access memory beyond; their bounds by performing bounds checking. If a bounds check fails, the program; will deterministically trap before out-of-bounds memory is accessed. In our model, every pointer has an explicit or implicit bounds attribute that; determines its bounds and ensures guaranteed bounds checking. Consider the; example below where the ``__counted_by(count)`` annotation indicates that; parameter ``p`` points to a buffer of integers containing ``count`` elements. An; off-by-one error is present in the loop condition, leading to ``p[i]`` being; out-of-bounds access during the loop's final iteration. The compiler inserts a; bounds check before ``p`` is dereferenced to ensure that the access remains; within the specified bounds. .. code-block:: c. void fill_array_with_indices(int *__counted_by(count) p, unsigned count) {; // off-by-one error (i < count); for (unsigned i = 0; i <= count; ++i) {; // bounds check inserted:; // if (i >= count) trap();; p[i] = i;; }; }. A bounds anno",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:3023,perform,performing,3023,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['perform'],['performing']
Performance,"hat in safe floating-point; modes, such as `-ffp-model=precise` or `-ffp-model=strict`, this option; has no effect because the optimizer is prohibited from making unsafe; transformations. .. option:: -fexcess-precision:. The C and C++ standards allow floating-point expressions to be computed as if; intermediate results had more precision (and/or a wider range) than the type; of the expression strictly allows. This is called excess precision; arithmetic.; Excess precision arithmetic can improve the accuracy of results (although not; always), and it can make computation significantly faster if the target lacks; direct hardware support for arithmetic in a particular type. However, it can; also undermine strict floating-point reproducibility. Under the standards, assignments and explicit casts force the operand to be; converted to its formal type, discarding any excess precision. Because data; can only flow between statements via an assignment, this means that the use; of excess precision arithmetic is a reliable local property of a single; statement, and results do not change based on optimization. However, when; excess precision arithmetic is in use, Clang does not guarantee strict; reproducibility, and future compiler releases may recognize more; opportunities to use excess precision arithmetic, e.g. with floating-point; builtins. Clang does not use excess precision arithmetic for most types or on most; targets. For example, even on pre-SSE X86 targets where ``float`` and; ``double`` computations must be performed in the 80-bit X87 format, Clang; rounds all intermediate results correctly for their type. Clang currently; uses excess precision arithmetic by default only for the following types and; targets:. * ``_Float16`` on X86 targets without ``AVX512-FP16``. The ``-fexcess-precision=<value>`` option can be used to control the use of; excess precision arithmetic. Valid values are:. * ``standard`` - The default. Allow the use of excess precision arithmetic; under the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:67163,optimiz,optimization,67163,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance,"hat it returns a; pointer which is guaranteed to be valid at least as long as the innermost; autorelease pool. There are no additional semantics enforced in the definition; of such a method; it merely enables optimizations in callers. .. _arc.objects.operands.casts:. Bridged casts; ^^^^^^^^^^^^^. A :arc-term:`bridged cast` is a C-style cast annotated with one of three; keywords:. * ``(__bridge T) op`` casts the operand to the destination type ``T``. If; ``T`` is a retainable object pointer type, then ``op`` must have a; non-retainable pointer type. If ``T`` is a non-retainable pointer type,; then ``op`` must have a retainable object pointer type. Otherwise the cast; is ill-formed. There is no transfer of ownership, and ARC inserts no retain; operations.; * ``(__bridge_retained T) op`` casts the operand, which must have retainable; object pointer type, to the destination type, which must be a non-retainable; pointer type. ARC retains the value, subject to the usual optimizations on; local values, and the recipient is responsible for balancing that +1.; * ``(__bridge_transfer T) op`` casts the operand, which must have; non-retainable pointer type, to the destination type, which must be a; retainable object pointer type. ARC will release the value at the end of; the enclosing full-expression, subject to the usual optimizations on local; values. These casts are required in order to transfer objects in and out of ARC; control; see the rationale in the section on :ref:`conversion of retainable; object pointers <arc.objects.restrictions.conversion>`. Using a ``__bridge_retained`` or ``__bridge_transfer`` cast purely to convince; ARC to emit an unbalanced retain or release, respectively, is poor form. .. _arc.objects.restrictions:. Restrictions; ------------. .. _arc.objects.restrictions.conversion:. Conversion of retainable object pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In general, a program which attempts to implicitly or explicitly convert a; value of retaina",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:23500,optimiz,optimizations,23500,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizations']
Performance,"hat represents the byte offset DR of a debugging information entry D; relative to the beginning of the ``.debug_info`` section that contains the; current compilation unit. D may not be in the current compilation unit. .. note::. DWARF Version 5 states that DR can be an offset in a ``.debug_info``; section other than the one that contains the current compilation unit. It; states that relocation of references from one executable or shared object; file to another must be performed by the consumer. But given that DR is; defined as an offset in a ``.debug_info`` section this seems impossible.; If DR was defined as an implementation defined value, then the consumer; could choose to interpret the value in an implementation defined manner to; reference a debug information in another executable or shared object. In ELF the ``.debug_info`` section is in a non-\ ``PT_LOAD`` segment so; standard dynamic relocations cannot be used. But even if they were loaded; segments and dynamic relocations were used, DR would need to be the; address of D, not an offset in a ``.debug_info`` section. That would also; need DR to be the size of a global address. So it would not be possible to; use the 32-bit DWARF format in a 64-bit global address space. In addition,; the consumer would need to determine what executable or shared object the; relocated address was in so it could determine the containing compilation; unit. GDB only interprets DR as an offset in the ``.debug_info`` section that; contains the current compilation unit. This comment also applies to ``DW_OP_implicit_pointer`` and; ``DW_OP_LLVM_aspace_implicit_pointer``. *Operand interpretation of* ``DW_OP_call2``\ *,* ``DW_OP_call4``\ *, and*; ``DW_OP_call_ref`` *is exactly like that for* ``DW_FORM_ref2``\ *,; ``DW_FORM_ref4``\ *, and* ``DW_FORM_ref_addr``\ *, respectively.*. The call operation is evaluated by:. * If D has a ``DW_AT_location`` attribute that is encoded as a ``exprloc``; that specifies an operation expression E, then ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:73754,load,loaded,73754,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['load'],['loaded']
Performance,"hat rules can be added to. If multiple opcodes are given, they are; all permanently bound to the same ruleset. The rules in a ruleset are executed; from top to bottom and will start again from the top if an instruction is; legalized as a result of the rules. If the ruleset is exhausted without; satisfying any rule, then it is considered unsupported. When it doesn't declare the instruction legal, each pass over the rules may; request that one type changes to another type. Sometimes this can cause multiple; types to change but we avoid this as much as possible as making multiple changes; can make it difficult to avoid infinite loops where, for example, narrowing one; type causes another to be too small and widening that type causes the first one; to be too big. In general, it's advisable to declare instructions legal as close to the top of; the rule as possible and to place any expensive rules as low as possible. This; helps with performance as testing for legality happens more often than; legalization and legalization can require multiple passes over the rules. As a concrete example, consider the rule::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0);. and the instruction::. %2:_(s7) = G_ADD %0:_(s7), %1:_(s7). this doesn't meet the predicate for the :ref:`.legalFor() <legalfor>` as ``s7``; is not one of the listed types so it falls through to the; :ref:`.clampScalar() <clampscalar>`. It does meet the predicate for this rule; as the type is smaller than the ``s32`` and this rule instructs the legalizer; to change type 0 to ``s32``. It then restarts from the top. This time it does; satisfy ``.legalFor()`` and the resulting output is::. %3:_(s32) = G_ANYEXT %0:_(s7); %4:_(s32) = G_ANYEXT %1:_(s7); %5:_(s32) = G_ADD %3:_(s32), %4:_(s32); %2:_(s7) = G_TRUNC %5:_(s32). where the ``G_ADD`` is legal and the other instructions are scheduled for; pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:4864,perform,performance,4864,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,1,['perform'],['performance']
Performance,"hat support vector masked gathers and allows vectorizing basic blocks with data and control divergence. Other targets may support this intrinsic differently, for example by lowering it into a sequence of scalar load operations.; The semantics of this operation are equivalent to a sequence of conditional scalar loads with subsequent gathering all loaded values into a single vector. The mask restricts memory access to certain lanes and facilitates vectorization of predicated basic blocks. ::. %res = call <4 x double> @llvm.masked.gather.v4f64.v4p0(<4 x ptr> %ptrs, i32 8, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x double> poison). ;; The gather with all-true mask is equivalent to the following instruction sequence; %ptr0 = extractelement <4 x ptr> %ptrs, i32 0; %ptr1 = extractelement <4 x ptr> %ptrs, i32 1; %ptr2 = extractelement <4 x ptr> %ptrs, i32 2; %ptr3 = extractelement <4 x ptr> %ptrs, i32 3. %val0 = load double, ptr %ptr0, align 8; %val1 = load double, ptr %ptr1, align 8; %val2 = load double, ptr %ptr2, align 8; %val3 = load double, ptr %ptr3, align 8. %vec0 = insertelement <4 x double> poison, %val0, 0; %vec01 = insertelement <4 x double> %vec0, %val1, 1; %vec012 = insertelement <4 x double> %vec01, %val2, 2; %vec0123 = insertelement <4 x double> %vec012, %val3, 3. .. _int_mscatter:. '``llvm.masked.scatter.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The data stored in memory is a vector of any integer, floating-point or pointer data type. Each vector element is stored in an arbitrary memory address. Scatter with overlapping addresses is guaranteed to be ordered from least-significant to most-significant element. ::. declare void @llvm.masked.scatter.v8i32.v8p0 (<8 x i32> <value>, <8 x ptr> <ptrs>, i32 <alignment>, <8 x i1> <mask>); declare void @llvm.masked.scatter.v16f32.v16p1(<16 x float> <value>, <16 x ptr addrspace(1)> <ptrs>, i32 <alignment>, <16 x i1> <mask>); declare void @llvm.mas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:851203,load,load,851203,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,4,['load'],['load']
Performance,"hat the edges A=>B; and B=>C were executed, but we still don't know if the edge A=>C was executed.; Such edges of control flow graph are called; `critical <https://en.wikipedia.org/wiki/Control_flow_graph#Special_edges>`_.; The edge-level coverage simply splits all critical edges by introducing new; dummy blocks and then instruments those blocks:. .. code-block:: none. A; |\; | \; D B; | /; |/; C. Tracing data flow; =================. Support for data-flow-guided fuzzing.; With ``-fsanitize-coverage=trace-cmp`` the compiler will insert extra instrumentation; around comparison instructions and switch statements.; Similarly, with ``-fsanitize-coverage=trace-div`` the compiler will instrument; integer division instructions (to capture the right argument of division); and with ``-fsanitize-coverage=trace-gep`` --; the `LLVM GEP instructions <https://llvm.org/docs/GetElementPtr.html>`_; (to capture array indices).; Similarly, with ``-fsanitize-coverage=trace-loads`` and ``-fsanitize-coverage=trace-stores``; the compiler will instrument loads and stores, respectively. Currently, these flags do not work by themselves - they require one; of ``-fsanitize-coverage={trace-pc,inline-8bit-counters,inline-bool}``; flags to work. Unless ``no-prune`` option is provided, some of the comparison instructions; will not be instrumented. .. code-block:: c++. // Called before a comparison instruction.; // Arg1 and Arg2 are arguments of the comparison.; void __sanitizer_cov_trace_cmp1(uint8_t Arg1, uint8_t Arg2);; void __sanitizer_cov_trace_cmp2(uint16_t Arg1, uint16_t Arg2);; void __sanitizer_cov_trace_cmp4(uint32_t Arg1, uint32_t Arg2);; void __sanitizer_cov_trace_cmp8(uint64_t Arg1, uint64_t Arg2);. // Called before a comparison instruction if exactly one of the arguments is constant.; // Arg1 and Arg2 are arguments of the comparison, Arg1 is a compile-time constant.; // These callbacks are emitted by -fsanitize-coverage=trace-cmp since 2017-08-11; void __sanitizer_cov_trace_const_cmp1(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SanitizerCoverage.rst:9303,load,loads,9303,interpreter/llvm-project/clang/docs/SanitizerCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SanitizerCoverage.rst,2,['load'],['loads']
Performance,"hat the function will delegate to some other; function with a tail call. The prototype of a thunk should not be used for; optimization purposes. The caller is expected to cast the thunk prototype to; match the thunk target prototype. ``""tls-load-hoist""``; This attribute indicates that the function will try to reduce redundant; tls address calculation by hoisting tls variable. ``uwtable[(sync|async)]``; This attribute indicates that the ABI being targeted requires that; an unwind table entry be produced for this function even if we can; show that no exceptions passes by it. This is normally the case for; the ELF x86-64 abi, but it can be disabled for some compilation; units. The optional parameter describes what kind of unwind tables; to generate: ``sync`` for normal unwind tables, ``async`` for asynchronous; (instruction precise) unwind tables. Without the parameter, the attribute; ``uwtable`` is equivalent to ``uwtable(async)``.; ``nocf_check``; This attribute indicates that no control-flow check will be performed on; the attributed entity. It disables -fcf-protection=<> for a specific; entity to fine grain the HW control flow protection mechanism. The flag; is target independent and currently appertains to a function or function; pointer.; ``shadowcallstack``; This attribute indicates that the ShadowCallStack checks are enabled for; the function. The instrumentation checks that the return address for the; function has not changed between the function prolog and epilog. It is; currently x86_64-specific. .. _langref_mustprogress:. ``mustprogress``; This attribute indicates that the function is required to return, unwind,; or interact with the environment in an observable way e.g. via a volatile; memory access, I/O, or other synchronization. The ``mustprogress``; attribute is intended to model the requirements of the first section of; [intro.progress] of the C++ Standard. As a consequence, a loop in a; function with the `mustprogress` attribute can be assumed to term",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:109259,perform,performed,109259,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"hat this intrinsic cannot yet be called in a ``constexpr`` context. Atomic Min/Max builtins with memory ordering; --------------------------------------------. There are two atomic builtins with min/max in-memory comparison and swap.; The syntax and semantics are similar to GCC-compatible __atomic_* builtins. * ``__atomic_fetch_min``; * ``__atomic_fetch_max``. The builtins work with signed and unsigned integers and require to specify memory ordering.; The return value is the original value that was stored in memory before comparison. Example:. .. code-block:: c. unsigned int val = __atomic_fetch_min(unsigned int *pi, unsigned int ui, __ATOMIC_RELAXED);. The third argument is one of the memory ordering specifiers ``__ATOMIC_RELAXED``,; ``__ATOMIC_CONSUME``, ``__ATOMIC_ACQUIRE``, ``__ATOMIC_RELEASE``,; ``__ATOMIC_ACQ_REL``, or ``__ATOMIC_SEQ_CST`` following C++11 memory model semantics. In terms of acquire-release ordering barriers these two operations are always; considered as operations with *load-store* semantics, even when the original value; is not actually modified after comparison. .. _langext-__c11_atomic:. __c11_atomic builtins; ---------------------. Clang provides a set of builtins which are intended to be used to implement; C11's ``<stdatomic.h>`` header. These builtins provide the semantics of the; ``_explicit`` form of the corresponding C11 operation, and are named with a; ``__c11_`` prefix. The supported operations, and the differences from; the corresponding C11 operations, are:. * ``__c11_atomic_init``; * ``__c11_atomic_thread_fence``; * ``__c11_atomic_signal_fence``; * ``__c11_atomic_is_lock_free`` (The argument is the size of the; ``_Atomic(...)`` object, instead of its address); * ``__c11_atomic_store``; * ``__c11_atomic_load``; * ``__c11_atomic_exchange``; * ``__c11_atomic_compare_exchange_strong``; * ``__c11_atomic_compare_exchange_weak``; * ``__c11_atomic_fetch_add``; * ``__c11_atomic_fetch_sub``; * ``__c11_atomic_fetch_and``; * ``__c11_atomic_f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:140407,load,load-store,140407,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['load'],['load-store']
Performance,"hat this is not an alias for :option:`--timeout`; the two are; different kinds of maximums. .. option:: --num-shards=M. Divide the set of selected tests into ``M`` equal-sized subsets or; ""shards"", and run only one of them. Must be used with the; ``--run-shard=N`` option, which selects the shard to run. The environment; variable ``LIT_NUM_SHARDS`` can also be used in place of this; option. These two options provide a coarse mechanism for partitioning large; testsuites, for parallel execution on separate machines (say in a large; testing farm). .. option:: --order={lexical,random,smart}. Define the order in which tests are run. The supported values are:. - lexical - tests will be run in lexical order according to the test file; path. This option is useful when predictable test order is desired. - random - tests will be run in random order. - smart - tests that failed previously will be run first, then the remaining; tests, all in descending execution time order. This is the default as it; optimizes concurrency. .. option:: --run-shard=N. Select which shard to run, assuming the ``--num-shards=M`` option was; provided. The two options must be used together, and the value of ``N``; must be in the range ``1..M``. The environment variable; ``LIT_RUN_SHARD`` can also be used in place of this option. .. option:: --timeout=N. Spend at most ``N`` seconds (approximately) running each individual test.; ``0`` means no time limit, and ``0`` is the default. Note that this is not an; alias for :option:`--max-time`; the two are different kinds of maximums. .. option:: --filter=REGEXP. Run only those tests whose name matches the regular expression specified in; ``REGEXP``. The environment variable ``LIT_FILTER`` can be also used in place; of this option, which is especially useful in environments where the call; to ``lit`` is issued indirectly. .. option:: --filter-out=REGEXP. Filter out those tests whose name matches the regular expression specified in; ``REGEXP``. The environment v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:7517,optimiz,optimizes,7517,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,2,"['concurren', 'optimiz']","['concurrency', 'optimizes']"
Performance,"hat's been `git add`ed:; git clang-format. To also format everything touched in the most recent commit:; git clang-format HEAD~1. If you're on a branch off main, to format everything touched on your branch:; git clang-format main. If two commits are given (requires --diff), run clang-format on all lines in the; second <commit> that differ from the first <commit>. The following git-config settings set the default of the corresponding option:; clangFormat.binary; clangFormat.commit; clangFormat.extensions; clangFormat.style. positional arguments:; <commit> revision from which to compute the diff; <file>... if specified, only consider differences in these files. optional arguments:; -h, --help show this help message and exit; --binary BINARY path to clang-format; --commit COMMIT default commit to use if none is specified; --diff print a diff instead of applying the changes; --diffstat print a diffstat instead of applying the changes; --extensions EXTENSIONS; comma-separated list of file extensions to format, excluding the period and case-insensitive; -f, --force allow changes to unstaged files; -p, --patch select hunks interactively; -q, --quiet print less information; --staged, --cached format lines in the stage instead of the working dir; --style STYLE passed to clang-format; -v, --verbose print extra information. Script for patch reformatting; =============================. The python script `clang/tools/clang-format/clang-format-diff.py` parses the; output of a unified diff and reformats all contained lines with; :program:`clang-format`. .. code-block:: console. usage: clang-format-diff.py [-h] [-i] [-p NUM] [-regex PATTERN] [-iregex PATTERN] [-sort-includes] [-v] [-style STYLE]; [-fallback-style FALLBACK_STYLE] [-binary BINARY]. This script reads input from a unified diff and reformats all the changed; lines. This is useful to reformat all the lines touched by a specific patch.; Example usage for git/svn users:. git diff -U0 --no-color --relative HEAD^ | clang-form",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:11924,cache,cached,11924,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['cache'],['cached']
Performance,"hat; is executed as a statement. There is no return value, but an error; message will be printed if there are problems such as syntax errors. `Eval(const char* expr) `- the argument is a string of Python code that; is evaluated as an expression. The result of the expression is returned,; if it is either a builtin type (int, long, float, double, and; `const char*` are supported), a Python type that can cross, or a ROOT; type. If a ROOT type is returned, an explicit cast to void\* is needed; to assign the return value to a local pointer (which may have a; different type), whereas builtin types will be cast implicitly, if; possible, to the type of the local variable to which they are assigned. `Bind(TObject* obj,const char* label)` - transfer a ROOT object from the; Cling to the Python interpreter, where it will be referenced with a; variable called ""`label`"". `Prompt()` - Transfer the interactive prompt to Python. With the ROOT v4.00/06 and later, the **`TPython`** class will be loaded; automatically on use, for older editions, the `libPyROOT.so` needs to be; loaded first with `gSystem->Load()` before use. Refer back to the other; example of the use of **`TPython`** that was given in ""Access to Python; from ROOT"". To show in detail how Python access can be used, an example Python; module is needed, as follows:. ``` {.cpp}; print('creating class MyPyClass ... '); class MyPyClass:; def __init__(self):; print('in MyPyClass.__init__'); self._browser = None; def gime(self, what):; return what; ```. This module can now be loaded into a Cling session, the class used to; instantiate objects, and their member functions called for showing how; different types can cross:. ``` {.cpp}; root[] TPython::LoadMacro(""MyPyClass.py"");; creating class MyPyClass ...; root[] MyPyClass m;; in MyPyClass.__init__; root[] char* s = m.gime(""aap"");; root[] s; (char* 0x41ee7754)""aap""; ```. Note that the `LoadMacro()` call makes the class automatically; available, such that it can be used directly.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:17277,load,loaded,17277,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['load'],['loaded']
Performance,"have on an ``void*`` lvalue with the same alignment; and non-ownership qualification. :arc-term:`Reading` occurs when performing a lvalue-to-rvalue conversion on an; object lvalue. * For ``__weak`` objects, the current pointee is retained and then released at; the end of the current full-expression. In particular, messaging a ``__weak``; object keeps the object retained until the end of the full expression. .. code-block:: objc. __weak MyObject *weakObj;. void foo() {; // weakObj is retained before the message send and released at the end of; // the full expression.; [weakObj m];; }. This must execute atomically with respect to assignments and to the final; release of the pointee.; * For all other objects, the lvalue is loaded with primitive semantics. :arc-term:`Assignment` occurs when evaluating an assignment operator. The; semantics vary based on the qualification:. * For ``__strong`` objects, the new pointee is first retained; second, the; lvalue is loaded with primitive semantics; third, the new pointee is stored; into the lvalue with primitive semantics; and finally, the old pointee is; released. This is not performed atomically; external synchronization must be; used to make this safe in the face of concurrent loads and stores.; * For ``__weak`` objects, the lvalue is updated to point to the new pointee,; unless the new pointee is an object currently undergoing deallocation, in; which case the lvalue is updated to a null pointer. This must execute; atomically with respect to other assignments to the object, to reads from the; object, and to the final release of the new pointee.; * For ``__unsafe_unretained`` objects, the new pointee is stored into the; lvalue using primitive semantics.; * For ``__autoreleasing`` objects, the new pointee is retained, autoreleased,; and stored into the lvalue using primitive semantics. :arc-term:`Initialization` occurs when an object's lifetime begins, which; depends on its storage duration. Initialization proceeds in two stage",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:38737,load,loaded,38737,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['load'],['loaded']
Performance,"have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above, consider proposing a piece; of metadata which provides the optimization hint you need. Such extensions are; relatively common and are generally well received by the community. You will; need to ensure that your proposal is sufficiently general so that it benefits; others if you wish to contribute it upstream. You should also consider describing the problem you're facing on `Discourse; <https://discourse.llvm.org>`_ and asking for advice.; It's entirely possible someone has encountered your problem before and can; give good advice. If there are multiple interested parties, that also; increases the chances that a metadata extension would be well received by the; community as a whole. Adding to this document; =======================. If you run across a case that you feel deserves to be covered here, please send; a patch to `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ for review. If you have questions on these items, please ask them on `Discourse; <https://discourse.llvm.org>`_. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:13639,optimiz,optimization,13639,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimization']
Performance,"having open it. XrdProofd plugin. Make sure that the limit on the number of old; sessions is applied whenever a new session is started and not only when; the daemon is started.; Fix the behaviour of the xpd.allowedusers directive: if; at least one of these directives is present, users in the password file; are not allowed by default but must be explicitly appear in one; xpd.allowedusers directive ; Fix a source for memory leak in; XrdProofdProtocol::SendMsg; Optimize the usage of strings in a few places. DataSet manager. Correctly classify as TTree all TTree derived classes; (e.g. TNtuple's); Fix a problem in saving the end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the default value after the first file. TDataSetManagerFile. Solve a consistency problem in checking URLs for; duplication when adding them to the relevant TFileInfo; During dataset validation, do not fail on duplications; but notify and add them to the bad file list. TPacketizerAdaptive, TPacketizer. Improve data node / worker matching by always using the; host FQDN. TPacketizerUnit, TEventIter. Make sure that the entry; number passed to TSelector::Process is unique and in increasing order; for non-data driven processing (packetizer TPacketizerUnit). This; allows to give a meaning to this variable, for example to related it to; one dimension of an integration. Fixes in PROOF-Lite:. Make sure that with envs settings via TProof::AddEnvVar; are effective; this enables, for example, the automatic valgrind setup; introduced in 5.24/00 or the experiment specific settings via the; script defined by the env PROOF_INIT; Fix a problem with TProof::Load so that now it can be; al",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:8402,cache,cache,8402,proof/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html,2,['cache'],['cache']
Performance,"he LLVM IR. Stack memory allocated with the alloca; instruction is fully general: you can pass the address of the stack slot; to functions, you can store it in other variables, etc. In our example; above, we could rewrite the example to use the alloca technique to avoid; using a PHI node:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; %X = alloca i32 ; type of %X is i32*.; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; store i32 %X.0, i32* %X ; Update X; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; store i32 %X.1, i32* %X ; Update X; br label %cond_next. cond_next:; %X.2 = load i32, i32* %X ; Read X; ret i32 %X.2; }. With this, we have discovered a way to handle arbitrary mutable; variables without the need to create Phi nodes at all:. #. Each mutable variable becomes a stack allocation.; #. Each read of the variable becomes a load from the stack.; #. Each update of the variable becomes a store to the stack.; #. Taking the address of a variable just uses the stack address; directly. While this solution has solved our immediate problem, it introduced; another one: we have now apparently introduced a lot of stack traffic; for very simple and common operations, a major performance problem.; Fortunately for us, the LLVM optimizer has a highly-tuned optimization; pass named ""mem2reg"" that handles this case, promoting allocas like this; into SSA registers, inserting Phi nodes as appropriate. If you run this; example through the pass, for example, you'll get:. .. code-block:: bash. $ llvm-as < example.ll | opt -passes=mem2reg | llvm-dis; @G = weak global i32 0; @H = weak global i32 0. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:6293,load,load,6293,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance,"he ``TargetFrameLowering`` class; ---------------------------------. The ``TargetFrameLowering`` class is used to provide information about the stack; frame layout of the target. It holds the direction of stack growth, the known; stack alignment on entry to each function, and the offset to the local area.; The offset to the local area is the offset from the stack pointer on function; entry to the first location where function data (local variables, spill; locations) can be stored. The ``TargetSubtarget`` class; -----------------------------. The ``TargetSubtarget`` class is used to provide information about the specific; chip set being targeted. A sub-target informs code generation of which; instructions are supported, instruction latencies and instruction execution; itinerary; i.e., which processing units are used, in what order, and for how; long. The ``TargetJITInfo`` class; ---------------------------. The ``TargetJITInfo`` class exposes an abstract interface used by the; Just-In-Time code generator to perform target-specific activities, such as; emitting stubs. If a ``TargetMachine`` supports JIT code generation, it should; provide one of these objects through the ``getJITInfo`` method. .. _code being generated:; .. _machine code representation:. Machine code description classes; ================================. At the high-level, LLVM code is translated to a machine specific representation; formed out of :raw-html:`<tt>` `MachineFunction`_ :raw-html:`</tt>`,; :raw-html:`<tt>` `MachineBasicBlock`_ :raw-html:`</tt>`, and :raw-html:`<tt>`; `MachineInstr`_ :raw-html:`</tt>` instances (defined in; ``include/llvm/CodeGen``). This representation is completely target agnostic,; representing instructions in their most abstract form: an opcode and a series of; operands. This representation is designed to support both an SSA representation; for machine code, as well as a register allocated, non-SSA form. .. _MachineInstr:. The ``MachineInstr`` class; --------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:14946,perform,perform,14946,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['perform'],['perform']
Performance,"he ``store`` is marked as ``volatile``, then the optimizer is not; allowed to modify the number or order of execution of this ``store`` with other; :ref:`volatile operations <volatile>`. Only values of :ref:`first class; <t_firstclass>` types of known size (i.e. not containing an :ref:`opaque; structural type <t_opaque>`) can be stored. If the ``store`` is marked as ``atomic``, it takes an extra :ref:`ordering; <ordering>` and optional ``syncscope(""<target-scope>"")`` argument. The; ``acquire`` and ``acq_rel`` orderings aren't valid on ``store`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic stores. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemporal`` does not have any; defined semantics for atomic stores. The optional constant ``align`` argument specifies the alignment of the; operation (that is, the alignment of the memory address). It is the; responsibility of the code emitter to ensure that the alignment information is; correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address space. Access of the high bytes can interfere with debugging tools, so; should not be accessed if the function has the ``sanitize_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:420871,perform,performance,420871,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performance']
Performance,"he address is a decimal number that specifies the address the memory; definition should start at. Note that a single memory definition can be; mapped multiple times. Using this annotation requires the subprocess; execution mode.; * `LLVM-EXEGESIS-SNIPPET-ADDRESS <address>` - This annotation allows for; setting the address where the beginning of the snippet to be executed will; be mapped in at. The address is given in hexadecimal. Note that the snippet; also includes setup code, so the instruction exactly at the specified; address will not be the first instruction in the snippet. Using this; annotation requires the subprocess execution mode. This is useful in; cases where the memory accessed by the snippet depends on the location; of the snippet, like RIP-relative addressing. EXAMPLE 1: benchmarking instructions; ------------------------------------. Assume you have an X86-64 machine. To measure the latency of a single; instruction, run:. .. code-block:: bash. $ llvm-exegesis --mode=latency --opcode-name=ADD64rr. Measuring the uop decomposition or inverse throughput of an instruction works similarly:. .. code-block:: bash. $ llvm-exegesis --mode=uops --opcode-name=ADD64rr; $ llvm-exegesis --mode=inverse_throughput --opcode-name=ADD64rr. The output is a YAML document (the default is to write to stdout, but you can; redirect the output to a file using `--benchmarks-file`):. .. code-block:: none. ---; key:; opcode_name: ADD64rr; mode: latency; config: ''; cpu_name: haswell; llvm_triple: x86_64-unknown-linux-gnu; num_repetitions: 10000; measurements:; - { key: latency, value: 1.0058, debug_string: '' }; error: ''; info: 'explicit self cycles, selecting one aliasing configuration.; Snippet:; ADD64rr R8, R8, R10; '; ... To measure the latency of all instructions for the host architecture, run:. .. code-block:: bash. $ llvm-exegesis --mode=latency --opcode-index=-1. EXAMPLE 2: benchmarking a custom code snippet; ---------------------------------------------. To measure the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:4926,latency,latency,4926,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['latency'],['latency']
Performance,"he aperture sizes are 2^32 bytes and the base is aligned to 2^32; which makes it easier to convert from flat to segment or segment to flat. Image and Samplers; ~~~~~~~~~~~~~~~~~~. Image and sample handles created by an HSA compatible runtime (see; :ref:`amdgpu-os`) are 64-bit addresses of a hardware 32-byte V# and 48 byte S#; object respectively. In order to support the HSA ``query_sampler`` operations; two extra dwords are used to store the HSA BRIG enumeration values for the; queries that are not trivially deducible from the S# representation. HSA Signals; ~~~~~~~~~~~. HSA signal handles created by an HSA compatible runtime (see :ref:`amdgpu-os`); are 64-bit addresses of a structure allocated in memory accessible from both the; CPU and GPU. The structure is defined by the runtime and subject to change; between releases. For example, see [AMD-ROCm-github]_. .. _amdgpu-amdhsa-hsa-aql-queue:. HSA AQL Queue; ~~~~~~~~~~~~~. The HSA AQL queue structure is defined by an HSA compatible runtime (see; :ref:`amdgpu-os`) and subject to change between releases. For example, see; [AMD-ROCm-github]_. For some processors it contains fields needed to implement; certain language features such as the flat address aperture bases. It also; contains fields used by CP such as managing the allocation of scratch memory. .. _amdgpu-amdhsa-kernel-descriptor:. Kernel Descriptor; ~~~~~~~~~~~~~~~~~. A kernel descriptor consists of the information needed by CP to initiate the; execution of a kernel, including the entry point address of the machine code; that implements the kernel. Code Object V3 Kernel Descriptor; ++++++++++++++++++++++++++++++++. CP microcode requires the Kernel descriptor to be allocated on 64-byte; alignment. The fields used by CP for code objects before V3 also match those specified in; :ref:`amdgpu-amdhsa-kernel-descriptor-v3-table`. .. table:: Code Object V3 Kernel Descriptor; :name: amdgpu-amdhsa-kernel-descriptor-v3-table. ======= ======= ===============================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:157528,queue,queue,157528,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance,"he base pointer and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.load``' intrinsic is designed for conditional reading of selected vector elements in a single IR operation. It is useful for targets that support vector masked loads and allows vectorizing predicated basic blocks on these targets. Other targets may support this intrinsic differently, for example by lowering it into a sequence of branches that guard scalar load operations.; The result of this operation is equivalent to a regular vector load instruction followed by a 'select' between the loaded and the passthru values, predicated on the same mask. However, using this intrinsic prevents exceptions on memory access to masked-off lanes. ::. %res = call <16 x float> @llvm.masked.load.v16f32.p0(ptr %ptr, i32 4, <16 x i1>%mask, <16 x float> %passthru). ;; The result of the two following instructions is identical aside from potential memory access exception; %loadlal = load <16 x float>, ptr %ptr, align 4; %res = select <16 x i1> %mask, <16 x float> %loadlal, <16 x float> %passthru. .. _int_mstore:. '``llvm.masked.store.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The data stored in memory is a vector of any integer, floating-point or pointer data type. ::. declare void @llvm.masked.store.v8i32.p0 (<8 x i32> <value>, ptr <ptr>, i32 <alignment>, <8 x i1> <mask>); declare void @llvm.masked.store.v16f32.p0(<16 x float> <value>, ptr <ptr>, i32 <alignment>, <16 x i1> <mask>); ;; The data is a vector of pointers; declare void @llvm.masked.store.v8p0.p0 (<8 x ptr> <value>, ptr <ptr>, i32 <alignment>, <8 x i1> <mask>). Overview:; """""""""""""""""". Writes a vector to memory according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. Arguments:; """""""""""""""""""". The first operand is the vector value to be written to memory. The seco",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:845444,load,loadlal,845444,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,3,['load'],"['load', 'loadlal']"
Performance,"he base pointer, there can be signed overflow. How can I tell if my front-end is following the rules?; ------------------------------------------------------. There is currently no checker for the getelementptr rules. Currently, the only; way to do this is to manually check each place in your front-end where; GetElementPtr operators are created. It's not possible to write a checker which could find all rule violations; statically. It would be possible to write a checker which works by instrumenting; the code with dynamic checks though. Alternatively, it would be possible to; write a static checker which catches a subset of possible problems. However, no; such checker exists today. Rationale; =========. Why is GEP designed this way?; -----------------------------. The design of GEP has the following goals, in rough unofficial order of; priority:. * Support C, C-like languages, and languages which can be conceptually lowered; into C (this covers a lot). * Support optimizations such as those that are common in C compilers. In; particular, GEP is a cornerstone of LLVM's `pointer aliasing; model <LangRef.html#pointeraliasing>`_. * Provide a consistent method for computing addresses so that address; computations don't need to be a part of load and store instructions in the IR. * Support non-C-like languages, to the extent that it doesn't interfere with; other goals. * Minimize target-specific information in the IR. Why do struct member indices always use ``i32``?; ------------------------------------------------. The specific type i32 is probably just a historical artifact, however it's wide; enough for all practical purposes, so there's been no need to change it. It; doesn't necessarily imply i32 address arithmetic; it's just an identifier which; identifies a field in a struct. Requiring that all struct indices be the same; reduces the range of possibilities for cases where two GEPs are effectively the; same but have distinct operand types. What's an uglygep?; ----------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:19433,optimiz,optimizations,19433,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['optimiz'],['optimizations']
Performance,"he basic block B is an exiting block; ending in a divergent branch, and the basic block C is an exit of the loop.; Thus, the call to convergent_op() is outside the loop. This causes a mismatch; between the programmer's expectation and the compiled program. The call should; be executed convergently on every iteration of the loop, by threads that; together take the branch to exit the loop. But when compiled, all threads that; take the divergent exit on different iterations first converge at the beginning; of basic block C and then together execute the call to convergent_op(). In this case, :ref:`llvm.experimental.convergence.loop; <llvm.experimental.convergence.loop>` can be used to express the desired; semantics. A call to this intrinsic is placed in the loop header, which tracks; each iteration of the loop. The token produced by this is used as a; ``convergencectrl`` operand to the convergent call. The semantics of the; ``loop`` intrinsic ensures that the convergent call is performed convergently; only by those threads that convergently exited the loop in a given iteration. .. code-block:: llvm. define void @example() convergent {; %entry = call token @llvm.experimental.convergence.entry(); br label %for. for:; %inner = call token @llvm.experimental.convergence.loop() [""convergencectrl""(token %entry)]; %for.cond = i1 ...; br i1 %for.cond, label %B, label %E. B:; ...; %condition = i1 ...; br i1 %condition, label %C, label %D. C:; call void @convergent_op() [""convergencectrl""(token %inner)]; br label %E. D:; ...; br label %for. E:; ...; ret void; }. The LLVM IR version of the same program shows a cycle consisting of the basic; blocks ``%for``, ``%B`` and ``%D``, while ``%C`` is an exit reached by the; divergent branch at the end of the exiting block ``%B``. But the use of; convergence control tokens makes it clear that block ``%C`` must be executed; convergently only by those threads that convergently take the exit edge from %B; to ``%C``. In other words, the convergen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst:17262,perform,performed,17262,interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergentOperations.rst,1,['perform'],['performed']
Performance,"he bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24007,perform,performance,24007,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance,"he bug in the program and the program's state when the location is reached. These are; both encapsulated in an ExplodedNode. In order to obtain the correct ExplodedNode, a decision must be made; as to whether or not analysis can continue along the current path. This decision; is based on whether the detected bug is one that would prevent the program under; analysis from continuing. For example, leaking of a resource should not stop; analysis, as the program can continue to run after the leak. Dereferencing a; null pointer, on the other hand, should stop analysis, as there is no way for; the program to meaningfully continue after such an error. If analysis can continue, then the most recent ExplodedNode; generated by the checker can be passed to the BugReport constructor; without additional modification. This ExplodedNode will be the one; returned by the most recent call to CheckerContext::addTransition.; If no transition has been performed during the current callback, the checker should call CheckerContext::addTransition(); and use the returned node for bug reporting. If analysis can not continue, then the current state should be transitioned; into a so-called sink node, a node from which no further analysis will be; performed. This is done by calling the ; CheckerContext::generateSink function; this function is the same as the; addTransition function, but marks the state as a sink node. Like; addTransition, this returns an ExplodedNode with the updated; state, which can then be passed to the BugReport constructor. After a BugReport is created, it should be passed to the analyzer core; by calling CheckerContext::emitReport. AST Visitors; Some checks might not require path-sensitivity to be effective. Simple AST walk; might be sufficient. If that is the case, consider implementing a Clang; compiler warning. On the other hand, a check might not be acceptable as a compiler; warning; for example, because of a relatively high false positive rate. In this; situation, AST ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html:17424,perform,performed,17424,interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,2,['perform'],['performed']
Performance,"he code would be:. .. code-block:: c++. {; FOO foo;; comp_ctor(&foo); // default constructor; struct __block_literal_10 _block_literal = {; &_NSConcreteStackBlock,; (1<<25)|(1<<26)|(1<<29), <uninitialized>,; __block_invoke_10,; &__block_descriptor_10,; };; comp_ctor(&_block_literal->foo, &foo); // const copy into stack version; struct __block_literal_10 &block = &_block_literal; // assign literal to block variable; block->invoke(block); // invoke block; comp_dtor(&_block_literal->foo); // destroy stack version of const block copy; comp_dtor(&foo); // destroy original version; }. C++ objects stored in ``__block`` storage start out on the stack in a; ``block_byref`` data structure as do other variables. Such objects (if not; ``const`` objects) must support a regular copy constructor. The ``block_byref``; data structure will have copy and destroy helper routines synthesized by the; compiler. The copy helper will have code created to perform the copy; constructor based on the initial stack ``block_byref`` data structure, and will; also set the (1<<26) bit in addition to the (1<<25) bit. The destroy helper; will have code to do the destructor on the object stored within the supplied; ``block_byref`` heap data structure. For example,. .. code-block:: c++. __block FOO blockStorageFoo;. requires the normal constructor for the embedded ``blockStorageFoo`` object:. .. code-block:: c++. FOO_ctor(& _block_byref_blockStorageFoo->blockStorageFoo);. and at scope termination the destructor:. .. code-block:: c++. FOO_dtor(& _block_byref_blockStorageFoo->blockStorageFoo);. Note that the forwarding indirection is *NOT* used. The compiler would need to generate (if used from a block literal) the following; copy/dispose helpers:. .. code-block:: c++. void _block_byref_obj_keep(struct _block_byref_blockStorageFoo *dst, struct _block_byref_blockStorageFoo *src) {; FOO_ctor(&dst->blockStorageFoo, &src->blockStorageFoo);; }. void _block_byref_obj_dispose(struct _block_byref_blockStorageFoo ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst:26292,perform,perform,26292,interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,1,['perform'],['perform']
Performance,"he code; clearer. .. _arc.misc:. Miscellaneous; =============. .. _arc.misc.special_methods:. Special methods; ---------------. .. _arc.misc.special_methods.retain:. Memory management methods; ^^^^^^^^^^^^^^^^^^^^^^^^^. A program is ill-formed if it contains a method definition, message send, or; ``@selector`` expression for any of the following selectors:. * ``autorelease``; * ``release``; * ``retain``; * ``retainCount``. .. admonition:: Rationale. ``retainCount`` is banned because ARC robs it of consistent semantics. The; others were banned after weighing three options for how to deal with message; sends:. **Honoring** them would work out very poorly if a programmer naively or; accidentally tried to incorporate code written for manual retain/release code; into an ARC program. At best, such code would do twice as much work as; necessary; quite frequently, however, ARC and the explicit code would both; try to balance the same retain, leading to crashes. The cost is losing the; ability to perform ""unrooted"" retains, i.e. retains not logically; corresponding to a strong reference in the object graph. **Ignoring** them would badly violate user expectations about their code.; While it *would* make it easier to develop code simultaneously for ARC and; non-ARC, there is very little reason to do so except for certain library; developers. ARC and non-ARC translation units share an execution model and; can seamlessly interoperate. Within a translation unit, a developer who; faithfully maintains their code in non-ARC mode is suffering all the; restrictions of ARC for zero benefit, while a developer who isn't testing the; non-ARC mode is likely to be unpleasantly surprised if they try to go back to; it. **Banning** them has the disadvantage of making it very awkward to migrate; existing code to ARC. The best answer to that, given a number of other; changes and restrictions in ARC, is to provide a specialized tool to assist; users in that migration. Implementing these methods w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:85898,perform,perform,85898,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['perform']
Performance,"he collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, such non-integral pointer type have no defined mapping to an; integer representation. This semantic quirk allows the runtime to pick a; integer mapping for each point in the program allowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract machine model comes for collectors; which need to model potentially relocatable objects. For a compiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:5115,optimiz,optimizer,5115,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['optimiz'],['optimizer']
Performance,"he command option ``-all-stats`` or; ``-register-file-stats``. In this example, we can conclude that the IPC is mostly limited by data; dependencies, and not by resource pressure. Instruction Flow; ^^^^^^^^^^^^^^^^; This section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34653,queue,queue,34653,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['queue'],['queue']
Performance,"he compiler to communicate how many source; language threads of execution are mapped to a target architecture thread's SIMT; lanes. See ``DW_AT_LLVM_lanes`` in :ref:`amdgpu-dwarf-low-level-information`. .. _amdgpu-dwarf-support-for-divergent-control-flow-of-simt-hardware:. 2.13 Support for Divergent Control Flow of SIMT Hardware; --------------------------------------------------------. If the source language is mapped onto the AMDGPU wavefronts in a SIMT manner the; compiler can use the AMDGPU execution mask register to control which lanes are; active. To describe the conceptual location of non-active lanes requires an; attribute that has an expression that computes the source location PC for each; lane. For efficiency, the expression calculates the source location the wavefront as a; whole. This can be done using the ``DW_OP_LLVM_select_bit_piece`` (see; :ref:`amdgpu-dwarf-operation-to-create-vector-composite-location-descriptions`); operation. The AMDGPU may update the execution mask to perform whole wavefront operations.; Therefore, there is a need for an attribute that computes the current active; lane mask. This can have an expression that may evaluate to the SIMT active lane; mask register or to a saved mask when in whole wavefront execution mode. An example that uses these attributes is referenced in the; :ref:`amdgpu-dwarf-further-examples` appendix. See ``DW_AT_LLVM_lane_pc`` and ``DW_AT_LLVM_active_lane`` in; :ref:`amdgpu-dwarf-composite-location-description-operations`. 2.14 Define Source Language Memory Classes; -------------------------------------------. AMDGPU supports languages, such as OpenCL [:ref:`OpenCL <amdgpu-dwarf-OpenCL>`],; that define source language memory classes. Support is added to define language; specific memory spaces so they can be used in a consistent way by consumers. Support for using memory spaces in defining source language types and data; object allocation is also added. See :ref:`amdgpu-dwarf-memory-spaces`. 2.15 Define Augm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:29440,perform,perform,29440,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['perform']
Performance,"he debug information.; When compiling a program that uses Clang modules or precompiled headers,; this option produces complete debug information with faster compile; times and much smaller object files. This option should not be used when building static libraries for; distribution to other machines because the debug info will contain; references to the module cache on the machine the object files in the; library were built on. .. option:: -fstandalone-debug -fno-standalone-debug. Clang supports a number of optimizations to reduce the size of debug; information in the binary. They work based on the assumption that the; debug type information can be spread out over multiple compilation units.; For instance, Clang will not emit type definitions for types that are not; needed by a module and could be replaced with a forward declaration.; Further, Clang will only emit type info for a dynamic C++ class in the; module that contains the vtable for the class. The :option:`-fstandalone-debug` option turns off these optimizations.; This is useful when working with 3rd-party libraries that don't come with; debug information. This is the default on Darwin. Note that Clang will; never emit type information for types that are not referenced at all by the; program. .. option:: -feliminate-unused-debug-types. By default, Clang does not emit type information for types that are defined; but not used in a program. To retain the debug info for these unused types,; the negation **-fno-eliminate-unused-debug-types** can be used. .. option:: -fexceptions. Allow exceptions to be thrown through Clang compiled stack frames (on many; targets, this will enable unwind information for functions that might have; an exception thrown through them). For most targets, this is enabled by; default for C++. .. option:: -ftrapv. Generate code to catch integer overflow errors. Signed integer overflow is; undefined in C. With this flag, extra code is generated to detect this and; abort when it happens. .. o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:13393,optimiz,optimizations,13393,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['optimiz'],['optimizations']
Performance,"he element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fadd:. '``llvm.vector.reduce.fadd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fadd.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fadd.*``' intrinsics do a floating-point; ``ADD`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fadd operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fadd(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result + input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, negative zero (``-0.0``) can be used, as it is; the neutral value of floating point addition. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fadd.v4f32(float -0.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fadd.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_mul:. '``llvm.vector.reduce.mul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:651767,perform,performs,651767,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"he element-type of the vector input. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of integer values. .. _int_vector_reduce_fmul:. '``llvm.vector.reduce.fmul.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %a); declare double @llvm.vector.reduce.fmul.v2f64(double %start_value, <2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fmul.*``' intrinsics do a floating-point; ``MUL`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. If the intrinsic call has the 'reassoc' flag set, then the reduction will not; preserve the associativity of an equivalent scalarized counterpart. Otherwise; the reduction will be *sequential*, thus implying that the operation respects; the associativity of a scalarized reduction. That is, the reduction begins with; the start value and performs an fmul operation with consecutively increasing; vector element indices. See the following pseudocode:. ::. float sequential_fmul(start_value, input_vector); result = start_value; for i = 0 to length(input_vector); result = result * input_vector[i]; return result. Arguments:; """"""""""""""""""""; The first argument to this intrinsic is a scalar start value for the reduction.; The type of the start value matches the element-type of the vector input.; The second argument must be a vector of floating-point values. To ignore the start value, one (``1.0``) can be used, as it is the neutral; value of floating point multiplication. Examples:; """""""""""""""""". ::. %unord = call reassoc float @llvm.vector.reduce.fmul.v4f32(float 1.0, <4 x float> %input) ; relaxed reduction; %ord = call float @llvm.vector.reduce.fmul.v4f32(float %start_value, <4 x float> %input) ; sequential reduction. .. _int_vector_reduce_and:. '``llvm.vector.reduce.and.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""".",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:654066,perform,performs,654066,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"he elements. This is possible only for vector up to size 10.; * Constructor from an iterator copying the data referred by the iterator. It is possible; to specify the _begin_ and _end_ of the iterator or the _begin_ and the size. Note that; for the Vector the iterator is not generic and must be of type _T*,_ where T is the type; of the contained elements. Here are some examples on how to create a vector. In the following we assume that we are; using the namespace ROOT::Math. ~~~ {.cpp}; SVector<double,N> v; // create a vector of size N, v[i]=0; SVector<double,3> v(1,2,3); // create a vector of size 3, v[0]=1,v[1]=2,v[2]=3; double a[9] = {1,2,3,4,5,6,7,8,9}; // input data; SVector<double,9> v(a,9); // create a vector using the a[] data; ~~~. ### Accessing and Setting Methods. The single vector elements can be set or retrieved using the _operator[i]_ , _operator(i)_; or the iterator interface. Notice that the index starts from zero and not from one as in; FORTRAN. Also no check is performed on the passed index. Furthermore, all the matrix; elements can be set also by using the ROOT::SVector::SetElements function passing a generic; iterator. The elements can be accessed also by using the ROOT::Math::SVector::apply(i) function. ~~~ {.cpp}; v[0] = 1; // set the first element; v(1) = 2; // set the second element; *(v.begin()+3) = 3; // set the third element; // set vector elements from a std::vector<double>::iterator</double>; std::vector <double> w(3);; v.SetElements(w.begin(),w.end());. double x = m(i); // return the i-th element; x = m.apply(i); // return the i-th element; x = *(m.begin()+i); // return the i-th element; ~~~. In addition there are methods to place a sub-vector in a vector. If the size of the the; sub-vector is larger than the vector size a static assert ( a compilation error) is produced. ~~~ {.cpp}; SVector<double,N> v;; SVector<double,M> w; // M <= N otherwise a compilation error is obtained later; // place a vector of size M starting from element iof",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md:1615,perform,performed,1615,math/smatrix/doc/SVector.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md,1,['perform'],['performed']
Performance,"he expression template technique, no temporary; objects are created in this operation. - Constructor by passing directly the elements. This is possible only; for vectors up to size 10. - Constructor from an iterator copying the data referred by the; iterator. It is possible to specify the *begin* and *end* of the; iterator or the *begin* and the *size*. Note that for the Vector the; iterator is not generic and must be of type `T*`, where `T` is the; type of the contained elements. In the following example we assume that we are using the namespace; **`ROOT::Math`**. ``` {.cpp}; //create an empty vector of size 3 ( v[0]=v[1]=v[2]=0); SVector<double,3> v;; double d[3] = {1,2,3};; SVector<double,3> v(d,3); //create a vector from a C array; ```. #### Accessing and Setting Methods. The single vector elements can be set or retrieved using the; `operator[i]`, `operator(i)` or the iterator interface. Notice that the; index starts from zero and not from one as in FORTRAN. Also no check is; performed on the passed index. The full vector elements can be set also; by using the SetElements function passing a generic iterator. ``` {.cpp}; double x = m(i); // return the i-th element; x = *(m.begin()+i); // return the i-th element; v[0] = 1; // set the first element; v(1) = 2; // set the second element; *(v.begin()+3) = 3; // set the third element; std::vector<double> w(3);. // set vector elements from a std::vector<double>::iterator; v.SetElements(w.begin(),w.end());; ```. In addition there are methods to place a sub-vector in a vector. If the; size of the sub-vector is larger than the vector size a static assert (a; compilation error) is produced. ``` {.cpp}; SVector>double,N> v;; SVector>double,M> w;; // M <= N otherwise a compilation error is obtained later; // place a vector of size M starting from; // element ioff, v[ioff+i]=w[i]; v.Place_at(w,ioff);; // return a sub-vector of size M starting from; // v[ioff]: w[i]=v[ioff+i]; w = v.Sub < SVector>double,M> > (ioff);; ```. For th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:103533,perform,performed,103533,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['perform'],['performed']
Performance,"he following trivial assembly::. f: // @f; movz	w8, #0x2a; ins 	v0.s[0], w8; ret. Problem; =======. The main problem is how vectors are represented in memory and in registers. First, a recap. The ""endianness"" of an item affects its representation in memory only. In a register, a number is just a sequence of bits - 64 bits in the case of AArch64 general purpose registers. Memory, however, is a sequence of addressable units of 8 bits in size. Any number greater than 8 bits must therefore be split up into 8-bit chunks, and endianness describes the order in which these chunks are laid out in memory. A ""little endian"" layout has the least significant byte first (lowest in memory address). A ""big endian"" layout has the *most* significant byte first. This means that when loading an item from big endian memory, the lowest 8-bits in memory must go in the most significant 8-bits, and so forth. ``LDR`` and ``LD1``; ===================. .. figure:: ARM-BE-ldr.png; :align: right. Big endian vector load using ``LDR``. A vector is a consecutive sequence of items that are operated on simultaneously. To load a 64-bit vector, 64 bits need to be read from memory. In little endian mode, we can do this by just performing a 64-bit load - ``LDR q0, [foo]``. However if we try this in big endian mode, because of the byte swapping the lane indices end up being swapped! The zero'th item as laid out in memory becomes the n'th lane in the vector. .. figure:: ARM-BE-ld1.png; :align: right. Big endian vector load using ``LD1``. Note that the lanes retain the correct ordering. Because of this, the instruction ``LD1`` performs a vector load but performs byte swapping not on the entire 64 bits, but on the individual items within the vector. This means that the register content is the same as it would have been on a little endian system. It may seem that ``LD1`` should suffice to perform vector loads on a big endian machine. However there are pros and cons to the two approaches that make it less than",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:2683,load,load,2683,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['load'],['load']
Performance,"he following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:320207,load,load,320207,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"he following; order:. ``` {.cpp}; MyClass(UserClass1*);; MyClass(UserClass2*);; MyClass(TRootIOCtor*);; MyClass(); // Or a constructor with all its arguments defaulted.; ```. ## rootcling: The Cling Dictionary Generator. A way in which dictionaries can be generated is via the `rootcling`; utility. This tool generates takes as input a set of headers and; generates in output the dictionary C++ code and a `pcm` file.; This latter file is fundamental for the correct functioning of the; dictionary at runtime. It should be located in the directory where; the shared library is installed in which the compiled dictionary; resides. NOTA BENE: the dictionaries that will be used within the same project; must have unique names. In other words, compiled object files relative; to dictionary source files cannot reside in the same library or in; two libraries loaded by the same application if the original source; files have the same name.; This loose limitation is imposed by the registration mechanism ROOT; has in place to keep track of dynamically loaded libraries. In the following example, we walk through the steps necessary to; generate a dictionary, I/O, and inspect member functions. Let's start; with a **`TEvent`** class, which contains a collection of **`TTracks`**. The `TEvent.h` header is:. ``` {.cpp}; #ifndef __TEvent__; #define __TEvent__; #include ""TObject.h""; #include ""TCollection.h"". class TTrack;. class TEvent : public TObject {; private:; Int_t fId; // event sequential id; Float_t fTotalMom; // total momentum; TCollection *fTracks; // collection of tracks; public:; TEvent() { fId = 0; fTotalMom = 0; fTracks = nullptr; }; TEvent(Int_t id);; ~TEvent();; void AddTrack(TTrack *t);; Int_t GetId() const { return fId; }; Int_t GetNoTracks() const;; void Print(Option_t *opt="""");; Float_t TotalMomentum();. ClassDef(TEvent,1); //Simple event class; };. #endif; ```. The things to notice in these header files are:. - The usage of the `ClassDef` macro. - The default constructors o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md:14140,load,loaded,14140,documentation/users-guide/AddingaClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md,1,['load'],['loaded']
Performance,"he legalizer to; legalize an intrinsic directly to a target instruction. The concrete; requirement is that the following additional constraints are preserved after; each of these passes:. IRTranslator. The representation must be gMIR, MIR, or a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually transition the gMIR to MIR. Legalizer. No illegal operations must remain or be introduced after this pass. Register Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:2594,perform,performance,2594,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,1,['perform'],['performance']
Performance,"he library only if the script or any of the; files it includes are newer than the library. When checking the; timestamp, ACLiC generates a dependency file which name is the same as; the library name, just replacing the 'so' extension by the extension; 'd'. For example on most platforms, `hsimple.cxx` will generate; `hsimple_cxx.d`. To ensure that the shared library is rebuilt you can use the ++; syntax:. ``` {.cpp}; root[] .L MyScript.C++; ```. To build, load, and execute the function with the same name as the; file you can use the `.x` command. This is the same as executing a; named script; you can also provide parameters. The only; difference is you need to append a + or a ++. ``` {.cpp}; root[] .x MyScript.C+(4000); Creating shared library /home/./MyScript_C.so; ```. You can select whether the script in compiled with debug symbol or; with optimization by appending the letter 'g' or 'O' after the '+' or; '++'. Without the specification, the script is compiled with the same; level of debugging symbol and optimization as the currently running; ROOT executable. For example:. ``` {.cpp}; root[] .L MyScript.C++g; ```. will compile `MyScript.C` with debug symbols; usually this means; giving the `-g` option to compiler. ``` {.cpp}; root[] .L MyScript.C++O; ```. will compile `MyScript.C` with optimizations; usually this means; giving the `-O` option to compiler. The syntax:. ``` {.cpp}; root[] .L MyScript.C++; ```. is using the default optimization level. The initial default is to; compile with the same level of optimization as the root executable; itself. The default can be changed by:. ``` {.cpp}; root[] gSystem->SetAclicMode(TSystem::kDebug);; root[] gSystem->SetAclicMode(TSystem::kOpt);; ```. Note that the commands:. ``` {.cpp}; root[] .L MyScript.C+g; root[] .L MyScript.C+O; ```. respectively compile `MyScript.C` with debug and optimization if the; library does not exist yet; they will not change the debug and the; optimization level if the library already exist and i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md:15100,optimiz,optimization,15100,documentation/users-guide/Cling.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md,1,['optimiz'],['optimization']
Performance,"he new flag `RSnapshotOption::fOverwriteIfExists` to `true` to force the deletion of the TTree that is; already present and the writing of a new TTree with the same name. See; [ROOT-10573](https://sft.its.cern.ch/jira/browse/ROOT-10573) for more details.; - RDataFrame changed its error handling strategy in case of unreadable input files. Instead of simply logging an error; and skipping the file, it now throws an exception if any of the input files is unreadable (this could also happen in; the middle of an event loop). See [ROOT-10549](https://sft.its.cern.ch/jira/browse/ROOT-10549) for more details.; - New analysis examples based on the recent ATLAS Open Data release ([`Higgs to two photons`](https://root.cern/doc/master/df104__HiggsToTwoPhotons_8py.html), [`W boson analysis`](https://root.cern/doc/master/df105__WBosonAnalysis_8py.html), [`Higgs to four leptons`](https://root.cern/doc/master/df106__HiggsToFourLeptons_8py.html)); - An exception is now thrown in case the size of ROOT's thread-pool changes between RDataFrame construction time and the time the event loop begins.; - Just-in-time compilation of large portions of the computation graph has been optimized, and it is now much faster. Please report any regressions you might encounter on [our issue tracker](https://sft.its.cern.ch/jira/projects/ROOT).; - `MakeRootDataFrame` is now a safe way to construct RDFs. It used to return RDFs with more limited functionality. ## PyROOT. - Introduce the `ROOT.Numba.Declare` decorator which provides a simple way to call Python callables from C++. The Python callables are; just-in-time compiled with [numba](http://numba.pydata.org/), which ensures a runtime performance similar to a C++ implementation.; The feature is targeted to improve the performance of Python based analyses, e.g., allows seamless integration into `RDataFrame` workflows.; See the tutorial [`pyroot004_NumbaDeclare.py`](https://root.cern/doc/master/pyroot004__NumbaDeclare_8py.html) for further information.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md:10617,optimiz,optimized,10617,README/ReleaseNotes/v622/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v622/index.md,3,"['optimiz', 'perform']","['optimized', 'performance']"
Performance,"he next continuation function. Semantics:; """""""""""""""""""". The result of the intrinsic indicates whether the coroutine should resume; abnormally (non-zero). In a normal coroutine, it is undefined behavior if the coroutine executes; a call to ``llvm.coro.suspend.retcon`` after resuming abnormally. In a yield-once coroutine, it is undefined behavior if the coroutine; executes a call to ``llvm.coro.suspend.retcon`` after resuming in any way. Coroutine Transformation Passes; ===============================; CoroEarly; ---------; The pass CoroEarly lowers coroutine intrinsics that hide the details of the; structure of the coroutine frame, but, otherwise not needed to be preserved to; help later coroutine passes. This pass lowers `coro.frame`_, `coro.done`_,; and `coro.promise`_ intrinsics. .. _CoroSplit:. CoroSplit; ---------; The pass CoroSplit builds coroutine frame and outlines resume and destroy parts; into separate functions. CoroElide; ---------; The pass CoroElide examines if the inlined coroutine is eligible for heap; allocation elision optimization. If so, it replaces; `coro.begin` intrinsic with an address of a coroutine frame placed on its caller; and replaces `coro.alloc` and `coro.free` intrinsics with `false` and `null`; respectively to remove the deallocation code.; This pass also replaces `coro.resume` and `coro.destroy` intrinsics with direct; calls to resume and destroy functions for a particular coroutine where possible. CoroCleanup; -----------; This pass runs late to lower all coroutine related intrinsics not replaced by; earlier passes. Attributes; ==========. coro_only_destroy_when_complete; -------------------------------. When the coroutine are marked with coro_only_destroy_when_complete, it indicates; the coroutine must reach the final suspend point when it get destroyed. This attribute only works for switched-resume coroutines now. Metadata; ========. '``coro.outside.frame``' Metadata; ---------------------------------. ``coro.outside.frame`` metad",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:56839,optimiz,optimization,56839,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['optimiz'],['optimization']
Performance,"he normally taken function address; and is not safe to call. For example, with ``-fsanitize=cfi``, taking a; function address produces a callable pointer to a CFI jump table, while; ``__builtin_function_start`` returns an address that fails; :doc:`cfi-icall<ControlFlowIntegrity>` checks. ``__builtin_operator_new`` and ``__builtin_operator_delete``; ------------------------------------------------------------. A call to ``__builtin_operator_new(args)`` is exactly the same as a call to; ``::operator new(args)``, except that it allows certain optimizations; that the C++ standard does not permit for a direct function call to; ``::operator new`` (in particular, removing ``new`` / ``delete`` pairs and; merging allocations), and that the call is required to resolve to a; `replaceable global allocation function; <https://en.cppreference.com/w/cpp/memory/new/operator_new>`_. Likewise, ``__builtin_operator_delete`` is exactly the same as a call to; ``::operator delete(args)``, except that it permits optimizations; and that the call is required to resolve to a; `replaceable global deallocation function; <https://en.cppreference.com/w/cpp/memory/new/operator_delete>`_. These builtins are intended for use in the implementation of ``std::allocator``; and other similar allocation libraries, and are only available in C++. Query for this feature with ``__has_builtin(__builtin_operator_new)`` or; ``__has_builtin(__builtin_operator_delete)``:. * If the value is at least ``201802L``, the builtins behave as described above. * If the value is non-zero, the builtins may not support calling arbitrary; replaceable global (de)allocation functions, but do support calling at least; ``::operator new(size_t)`` and ``::operator delete(void*)``. ``__builtin_preserve_access_index``; -----------------------------------. ``__builtin_preserve_access_index`` specifies a code section where; array subscript access and structure/union member access are relocatable; under bpf compile-once run-everywhere fr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:119659,optimiz,optimizations,119659,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizations']
Performance,"he object to draw and the third one is the drawing option. Here is complete [running example](https://root.cern/js/latest/api.htm#custom_html_read_json) ans [source code](https://github.com/root-project/jsroot/blob/master/demo/read_json.htm):. ```javascript; import { httpRequest, draw, redraw, resize, cleanup } from 'https://root.cern/js/latest/modules/main.mjs';; let filename = ""https://root.cern/js/files/th2ul.json.gz"";; let obj = await httpRequest(filename, 'object');; draw(""drawing"", obj, ""lego"");; ```. In very seldom cases one need to access painter object, created in `draw()` function. This can be done via; handling Promise results like:. ```javascript; let painter = await draw(""drawing"", obj, ""colz"");; console.log('Object type in painter', painter.getClassName());; ```. One is also able to update the drawing with a new version of the object:. ```javascript; // after some interval request object again; redraw(""drawing"", obj2, ""colz"");; ```. The `redraw` function will call `draw` if the drawing was not performed before. In the case when changing of HTML layout leads to resize of element with JSROOT drawing,; one should call `resize()` to let JSROOT adjust drawing size. One should do:. ```javascript; resize(""drawing"");; ```. As second argument one could specify exact size for draw elements like:. ```javascript; resize(""drawing"", { width: 500, height: 200 });; ```. To correctly cleanup JSROOT drawings from HTML element, one should call:. ```javascript; cleanup(""drawing"");; ```. ### File API. JSROOT defines the TFile class, which can be used to access binary ROOT files.; One should always remember that all I/O operations are asynchronous in JSROOT.; Therefore promises are used to retrieve results when the I/O operation is completed.; For example, reading an object from a file and displaying it will look like:. ```javascript; import { openFile, draw } from 'https://root.cern/js/latest/modules/main.mjs';; let filename = ""https://root.cern/js/files/hsimple.root"";; le",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:39221,perform,performed,39221,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['perform'],['performed']
Performance,"he ordering and the adjacency between the two or more; assignments. The Clang CFG is used to implement this analysis as Clang CFG; provides a linear view of statements within each ``CFGBlock`` (Clang; ``CFGBlock`` represents a single basic block in a source-level CFG). Bounds check optimizations; ==========================. In ``-fbounds-safety``, the Clang frontend emits run-time checks for every; memory dereference if the type system or analyses in the frontend couldnt; verify its bounds safety. The implementation relies on LLVM optimizations to; remove redundant run-time checks. Using this optimization strategy, if the; original source code already has bounds checks, the fewer additional checks; ``-fbounds-safety`` will introduce. The LLVM ``ConstraintElimination`` pass is; design to remove provable redundant checks (please check Florian Hahns; presentation in 2021 LLVM Dev Meeting and the implementation to learn more). In; the following example, ``-fbounds-safety`` implicitly adds the redundant bounds; checks that the optimizer can remove:. .. code-block:: c. void fill_array_with_indices(int *__counted_by(count) p, size_t count) {; for (size_t i = 0; i < count; ++i) {; // implicit bounds checks:; // if (p + i < p || p + i + 1 > p + count) trap();; p[i] = i;; }; }. ``ConstraintElimination`` collects the following facts and determines if the; bounds checks can be safely removed:. * Inside the for-loop, ``0 <= i < count``, hence ``1 <= i + 1 <= count``.; * Pointer arithmetic ``p + count`` in the if-condition doesnt wrap.; * ``-fbounds-safety`` treats pointer arithmetic overflow as deterministically; twos complement computation, not an undefined behavior. Therefore,; getelementptr does not typically have inbounds keyword. However, the compiler; does emit inbounds for ``p + count`` in this case because; ``__counted_by(count)`` has the invariant that p has at least as many as; elements as count. Using this information, ``ConstraintElimination`` is able; to determi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:6727,optimiz,optimizer,6727,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['optimiz'],['optimizer']
Performance,"he same; as the code in the previous section):. .. code-block:: llvm. loop:; %n.addr = phi i32 [ %n, %entry ], [ %inc, %loop.resume ]; call void @print(i32 %n.addr) #4; %2 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend [i8 0, label %loop; i8 1, label %cleanup]. In this case, the coroutine frame would include a suspend index that will; indicate at which suspend point the coroutine needs to resume. .. code-block:: llvm. %f.frame = type { ptr, ptr, i32, i32 }. The resume function will use an index to jump to an appropriate basic block and will look; as follows:. .. code-block:: llvm. define internal fastcc void @f.Resume(ptr %FramePtr) {; entry.Resume:; %index.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 2; %index = load i8, ptr %index.addr, align 1; %switch = icmp eq i8 %index, 0; %n.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i64 0, i32 3; %n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:19274,load,load,19274,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['load'],['load']
Performance,"he section on; :ref:`modules <pchinternals-modules>`. Clang's AST files are designed with a compact on-disk representation, which; minimizes both creation time and the time required to initially load the AST; file. The AST file itself contains a serialized representation of Clang's; abstract syntax trees and supporting data structures, stored using the same; compressed bitstream as `LLVM's bitcode file format; <https://llvm.org/docs/BitCodeFormat.html>`_. Clang's AST files are loaded ""lazily"" from disk. When an AST file is initially; loaded, Clang reads only a small amount of data from the AST file to establish; where certain important data structures are stored. The amount of data read in; this initial load is independent of the size of the AST file, such that a; larger AST file does not lead to longer AST load times. The actual header data; in the AST file --- macros, functions, variables, types, etc. --- is loaded; only when it is referenced from the user's code, at which point only that; entity (and those entities it depends on) are deserialized from the AST file.; With this approach, the cost of using an AST file for a translation unit is; proportional to the amount of code actually used from the AST file, rather than; being proportional to the size of the AST file itself. When given the `-print-stats` option, Clang produces statistics; describing how much of the AST file was actually loaded from disk. For a; simple ""Hello, World!"" program that includes the Apple ``Cocoa.h`` header; (which is built as a precompiled header), this option illustrates how little of; the actual precompiled header is required:. .. code-block:: none. *** AST File Statistics:; 895/39981 source location entries read (2.238563%); 19/15315 types read (0.124061%); 20/82685 declarations read (0.024188%); 154/58070 identifiers read (0.265197%); 0/7260 selectors read (0.000000%); 0/30842 statements read (0.000000%); 4/8400 macros read (0.047619%); 1/4995 lexical declcontexts read (0.020020%);",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:3853,load,loaded,3853,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['load'],['loaded']
Performance,"he sequence of '1' and '0' bits in the mask. E.g., if the mask vector is '10010001', ""expandload"" reads 3 values from memory addresses ptr, ptr+1, ptr+2 and places them in lanes 0, 3 and 7 accordingly. The masked-off lanes are filled by elements from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. It has the same underlying type as the element of the returned vector. The second operand, mask, is a vector of boolean values with the same number of elements as the return type. The third is a pass-through value that is used to fill the masked-off lanes of the result. The return type and the type of the '``passthru``' operand have the same vector type. Semantics:; """""""""""""""""""". The '``llvm.masked.expandload``' intrinsic is designed for reading multiple scalar values from adjacent memory addresses into possibly non-adjacent vector lanes. It is useful for targets that support vector expanding loads and allows vectorizing loop with cross-iteration dependency like in the following example:. .. code-block:: c. // In this loop we load from B and spread the elements into array A.; double *A, B; int *C;; for (int i = 0; i < size; ++i) {; if (C[i] != 0); A[i] = B[j++];; }. .. code-block:: llvm. ; Load several elements from array B and expand them in a vector.; ; The number of loaded elements is equal to the number of '1' elements in the Mask.; %Tmp = call <8 x double> @llvm.masked.expandload.v8f64(ptr %Bptr, <8 x i1> %Mask, <8 x double> poison); ; Store the result in A; call void @llvm.masked.store.v8f64.p0(<8 x double> %Tmp, ptr %Aptr, i32 8, <8 x i1> %Mask). ; %Bptr should be increased on each iteration according to the number of '1' elements in the Mask.; %MaskI = bitcast <8 x i1> %Mask to i8; %MaskIPopcnt = call i8 @llvm.ctpop.i8(i8 %MaskI); %MaskI64 = zext i8 %MaskIPopcnt to i64; %BNextInd = add i64 %BInd, %MaskI64. Other targets may support this intrinsic differently, for example, by lowering it",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:856962,load,loads,856962,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loads']
Performance,"he signed summation, and the second element; of which is a bit specifying if the signed summation resulted in an; overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.sadd.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. '``llvm.uadd.with.overflow.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.uadd.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.uadd.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.uadd.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.uadd.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.uadd.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """""""""""""""""". The '``llvm.uadd.with.overflow``' family of intrinsic functions perform; an unsigned addition of the two arguments, and indicate whether a carry; occurred during the unsigned summation. Arguments:; """""""""""""""""""". The arguments (%a and %b) and the first element of the result structure; may be of integer types of any bit width, but they must have the same; bit width. The second element of the result structure must be of type; ``i1``. ``%a`` and ``%b`` are the two values that will undergo unsigned; addition. Semantics:; """""""""""""""""""". The '``llvm.uadd.with.overflow``' family of intrinsic functions perform; an unsigned addition of the two arguments. They return a structure --- the; first element of which is the sum, and the second element of which is a; bit specifying if the unsigned summation resulted in a carry. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.uadd.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %carry, label %normal. '``llvm.ssub.with.overflow.*``' Intrinsics; ^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:603094,perform,perform,603094,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"he target; ISelLowering code has set the corresponding ``ATOMIC_CMPXCHG``, ``ATOMIC_SWAP``,; or ``ATOMIC_LOAD_*`` operation to ""Expand"", and if it has opted-into the; availability of those library functions via a call to ``initSyncLibcalls()``. The full set of functions that may be called by LLVM is (for ``N`` being 1, 2,; 4, 8, or 16)::. iN __sync_val_compare_and_swap_N(iN *ptr, iN expected, iN desired); iN __sync_lock_test_and_set_N(iN *ptr, iN val); iN __sync_fetch_and_add_N(iN *ptr, iN val); iN __sync_fetch_and_sub_N(iN *ptr, iN val); iN __sync_fetch_and_and_N(iN *ptr, iN val); iN __sync_fetch_and_or_N(iN *ptr, iN val); iN __sync_fetch_and_xor_N(iN *ptr, iN val); iN __sync_fetch_and_nand_N(iN *ptr, iN val); iN __sync_fetch_and_max_N(iN *ptr, iN val); iN __sync_fetch_and_umax_N(iN *ptr, iN val); iN __sync_fetch_and_min_N(iN *ptr, iN val); iN __sync_fetch_and_umin_N(iN *ptr, iN val). This list doesn't include any function for atomic load or store; all known; architectures support atomic loads and stores directly (possibly by emitting a; fence on either side of a normal load or store.). There's also, somewhat separately, the possibility to lower ``ATOMIC_FENCE`` to; ``__sync_synchronize()``. This may happen or not happen independent of all the; above, controlled purely by ``setOperationAction(ISD::ATOMIC_FENCE, ...)``. On AArch64, a variant of the __sync_* routines is used which contain the memory; order as part of the function name. These routines may determine at runtime; whether the single-instruction atomic operations which were introduced as part; of AArch64 Large System Extensions ""LSE"" instruction set are available, or if; it needs to fall back to an LL/SC loop. The following helper functions are; implemented in both ``compiler-rt`` and ``libgcc`` libraries; (``N`` is one of 1, 2, 4, 8, and ``M`` is one of 1, 2, 4, 8 and 16, and; ``ORDER`` is one of 'relax', 'acq', 'rel', 'acq_rel')::. iM __aarch64_casM_ORDER(iM expected, iM desired, iM *ptr); iN __aarch64_s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:29844,load,load,29844,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,3,['load'],"['load', 'loads']"
Performance,"he-new-pass-manager/>`_. Just Tell Me How To Run The Default Optimization Pipeline With The New Pass Manager; ===================================================================================. .. code-block:: c++. // Create the analysis managers.; // These must be declared in this order so that they are destroyed in the; // correct order due to inter-analysis-manager references.; LoopAnalysisManager LAM;; FunctionAnalysisManager FAM;; CGSCCAnalysisManager CGAM;; ModuleAnalysisManager MAM;. // Create the new pass manager builder.; // Take a look at the PassBuilder constructor parameters for more; // customization, e.g. specifying a TargetMachine or various debugging; // options.; PassBuilder PB;. // Register all the basic analyses with the managers.; PB.registerModuleAnalyses(MAM);; PB.registerCGSCCAnalyses(CGAM);; PB.registerFunctionAnalyses(FAM);; PB.registerLoopAnalyses(LAM);; PB.crossRegisterProxies(LAM, FAM, CGAM, MAM);. // Create the pass manager.; // This one corresponds to a typical -O2 optimization pipeline.; ModulePassManager MPM = PB.buildPerModuleDefaultPipeline(OptimizationLevel::O2);. // Optimize the IR!; MPM.run(MyModule, MAM);. The C API also supports most of this, see ``llvm-c/Transforms/PassBuilder.h``. Adding Passes to a Pass Manager; ===============================. For how to write a new PM pass, see :doc:`this page <WritingAnLLVMNewPMPass>`. To add a pass to a new PM pass manager, the important thing is to match the; pass type and the pass manager type. For example, a ``FunctionPassManager``; can only contain function passes:. .. code-block:: c++. FunctionPassManager FPM;; // InstSimplifyPass is a function pass; FPM.addPass(InstSimplifyPass());. If you want to add a loop pass that runs on all loops in a function to a; ``FunctionPassManager``, the loop pass must be wrapped in a function pass; adaptor that goes through all the loops in the function and runs the loop; pass on each one. .. code-block:: c++. FunctionPassManager FPM;; // LoopRotatePa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:1241,optimiz,optimization,1241,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['optimiz'],['optimization']
Performance,"he; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have alre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:230430,load,load,230430,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"he; code responsible for creation and initialization of the coroutine frame and; execution of the coroutine until a suspend point is reached:. .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %alloc = call noalias ptr @malloc(i32 24); %frame = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); %1 = getelementptr %f.frame, ptr %frame, i32 0, i32 0; store ptr @f.resume, ptr %1; %2 = getelementptr %f.frame, ptr %frame, i32 0, i32 1; store ptr @f.destroy, ptr %2. %inc = add nsw i32 %n, 1; %inc.spill.addr = getelementptr inbounds %f.Frame, ptr %FramePtr, i32 0, i32 2; store i32 %inc, ptr %inc.spill.addr; call void @print(i32 %n). ret ptr %frame; }. Outlined resume part of the coroutine will reside in function `f.resume`:. .. code-block:: llvm. define internal fastcc void @f.resume(ptr %frame.ptr.resume) {; entry:; %inc.spill.addr = getelementptr %f.frame, ptr %frame.ptr.resume, i64 0, i32 2; %inc.spill = load i32, ptr %inc.spill.addr, align 4; %inc = add i32 %inc.spill, 1; store i32 %inc, ptr %inc.spill.addr, align 4; tail call void @print(i32 %inc); ret void; }. Whereas function `f.destroy` will contain the cleanup code for the coroutine:. .. code-block:: llvm. define internal fastcc void @f.destroy(ptr %frame.ptr.destroy) {; entry:; tail call void @free(ptr %frame.ptr.destroy); ret void; }. Avoiding Heap Allocations; -------------------------. A particular coroutine usage pattern, which is illustrated by the `main`; function in the overview section, where a coroutine is created, manipulated and; destroyed by the same calling function, is common for coroutines implementing; RAII idiom and is suitable for allocation elision optimization which avoid; dynamic allocation by storing the coroutine frame as a static `alloca` in its; caller. In the entry block, we will call `coro.alloc`_ intrinsic that will return `true`; when dynamic allocation is required, and `false` if dynamic allocation is; el",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:15745,load,load,15745,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['load'],['load']
Performance,"he; ones that control inlining). .. code-block:: c++. #pragma clang optimize off; // This function will be decorated with optnone.; int foo() {; // ... code; }. // optnone conflicts with always_inline, so bar() will not be decorated.; __attribute__((always_inline)) int bar() {; // ... code; }; #pragma clang optimize on. If no ``on`` is found to close an ``off`` region, the end of the region is the; end of the compilation unit. Note that a stray ``#pragma clang optimize on`` does not selectively enable; additional optimizations when compiling at low optimization levels. This feature; can only be used to selectively disable optimizations. The pragma has an effect on functions only at the point of their definition; for; function templates, this means that the state of the pragma at the point of an; instantiation is not necessarily relevant. Consider the following example:. .. code-block:: c++. template<typename T> T twice(T t) {; return 2 * t;; }. #pragma clang optimize off; template<typename T> T thrice(T t) {; return 3 * t;; }. int container(int a, int b) {; return twice(a) + thrice(b);; }; #pragma clang optimize on. In this example, the definition of the template function ``twice`` is outside; the pragma region, whereas the definition of ``thrice`` is inside the region.; The ``container`` function is also in the region and will not be optimized, but; it causes the instantiation of ``twice`` and ``thrice`` with an ``int`` type; of; these two instantiations, ``twice`` will be optimized (because its definition; was outside the region) and ``thrice`` will not be optimized. Clang also implements MSVC's range-based pragma,; ``#pragma optimize(""[optimization-list]"", on | off)``. At the moment, Clang only; supports an empty optimization list, whereas MSVC supports the arguments, ``s``,; ``g``, ``t``, and ``y``. Currently, the implementation of ``pragma optimize`` behaves; the same as ``#pragma clang optimize``. All functions; between ``off`` and ``on`` will be decorated wit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:160382,optimiz,optimize,160382,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimize']
Performance,"he; program location associated with the call site in the current caller frame; F that invoked the callee frame. * If the current lane is specified and the architecture program location LPC; computed by the ``DW_AT_LLVM_lane_pc`` attribute for the current lane is not; the undefined location description (indicating the lane was not active on; entry to the call frame), it must be LPC. * Otherwise the result is undefined. *A current compilation unit*. The compilation unit debug information entry that contains the DWARF expression; being evaluated. It is required for operations that reference debug information associated with; the same compilation unit, including indicating if such references use the; 32-bit or 64-bit DWARF format. It can also provide the default address space; address size if no current target architecture is specified. *For example, the* ``DW_OP_constx`` *and* ``DW_OP_addrx`` *operations.*. *Note that this compilation unit may not be the same as the compilation unit; determined from the loaded code object corresponding to the current program; location. For example, the evaluation of the expression E associated with a*; ``DW_AT_location`` *attribute of the debug information entry operand of the*; ``DW_OP_call*`` *operations is evaluated with the compilation unit that; contains E and not the one that contains the* ``DW_OP_call*`` *operation; expression.*. *A current target architecture*. The target architecture. It is required for operations that specify target architecture specific; entities. *For example, target architecture specific entities include DWARF register; identifiers, DWARF lane identifiers, DWARF address space identifiers, the; default address space, and the address space address sizes.*. If specified:. * If the current frame is specified, then the current target architecture must; be the same as the target architecture of the current frame. * If the current frame is specified and is the top frame, and if the current; thread is specified, t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:51033,load,loaded,51033,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['load'],['loaded']
Performance,"he; section on the OpenCL Header <opencl_header>`):. .. code-block:: console. $ clang -Xclang -finclude-default-header test.cl. Alternatively the internal header `opencl-c.h` containing the declarations; can be included manually using ``-include`` or ``-I`` followed by the path; to the header location. The header can be found in the clang source tree or; installation directory. .. code-block:: console. $ clang -I<path to clang sources>/lib/Headers/opencl-c.h test.cl; $ clang -I<path to clang installation>/lib/clang/<llvm version>/include/opencl-c.h/opencl-c.h test.cl. In this example it is assumed that the kernel code contains; ``#include <opencl-c.h>`` just as a regular C include. Because the header is very large and long to parse, PCH (:doc:`PCHInternals`); and modules (:doc:`Modules`) can be used internally to improve the compilation; speed. To enable modules for OpenCL:. .. code-block:: console. $ clang --target=spir-unknown-unknown -c -emit-llvm -Xclang -finclude-default-header -fmodules -fimplicit-module-maps -fmodules-cache-path=<path to the generated module> test.cl. Another way to circumvent long parsing latency for the OpenCL builtin; declarations is to use mechanism enabled by :ref:`-fdeclare-opencl-builtins; <opencl_fdeclare_opencl_builtins>` flag that is available as an alternative; feature. .. _opencl_fdeclare_opencl_builtins:. .. option:: -fdeclare-opencl-builtins. In addition to regular header includes with builtin types and functions using; :ref:`-finclude-default-header <opencl_finclude_default_header>`, clang; supports a fast mechanism to declare builtin functions with; ``-fdeclare-opencl-builtins``. This does not declare the builtin types and; therefore it has to be used in combination with ``-finclude-default-header``; if full functionality is required. **Example of Use**:. .. code-block:: console. $ clang -Xclang -fdeclare-opencl-builtins test.cl. .. _opencl_fake_address_space_map:. .. option:: -ffake-address-space-map. Overrides the target add",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst:4142,cache,cache-path,4142,interpreter/llvm-project/clang/docs/OpenCLSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenCLSupport.rst,1,['cache'],['cache-path']
Performance,"hed my ORC can run concurrently (provided the client; sets up an appropriate dispatcher). Built-in dependency tracking ensures that; ORC does not release pointers to JIT'd code or data until all dependencies; have also been JIT'd and they are safe to call or use. **Removable Code**; Resources for JIT'd program representations. **Orthogonality** and **Composability**; Each of the features above can be used independently. It is possible to put; ORC components together to make a non-lazy, in-process, single threaded JIT; or a lazy, out-of-process, concurrent JIT, or anything in between. LLJIT and LLLazyJIT; ===================. ORC provides two basic JIT classes off-the-shelf. These are useful both as; examples of how to assemble ORC components to make a JIT, and as replacements; for earlier LLVM JIT APIs (e.g. MCJIT). The LLJIT class uses an IRCompileLayer and RTDyldObjectLinkingLayer to support; compilation of LLVM IR and linking of relocatable object files. All operations; are performed eagerly on symbol lookup (i.e. a symbol's definition is compiled; as soon as you attempt to look up its address). LLJIT is a suitable replacement; for MCJIT in most cases (note: some more advanced features, e.g.; JITEventListeners are not supported yet). The LLLazyJIT extends LLJIT and adds a CompileOnDemandLayer to enable lazy; compilation of LLVM IR. When an LLVM IR module is added via the addLazyIRModule; method, function bodies in that module will not be compiled until they are first; called. LLLazyJIT aims to provide a replacement of LLVM's original (pre-MCJIT); JIT API. LLJIT and LLLazyJIT instances can be created using their respective builder; classes: LLJITBuilder and LLazyJITBuilder. For example, assuming you have a; module ``M`` loaded on a ThreadSafeContext ``Ctx``:. .. code-block:: c++. // Try to detect the host arch and construct an LLJIT instance.; auto JIT = LLJITBuilder().create();. // If we could not construct an instance, return an error.; if (!JIT); return JIT.take",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:3957,perform,performed,3957,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['perform'],['performed']
Performance,"hed to it. E.g. .. code-block:: c++. ThreadSafeContext TSCtx(std::make_unique<LLVMContext>());. ThreadPool TP(NumThreads);; JITStack J;. for (auto &ModulePath : ModulePaths) {; TP.async(; [&]() {; auto Lock = TSCtx.getLock();; auto M = loadModuleOnContext(ModulePath, TSCtx.getContext());; J.addModule(ThreadSafeModule(std::move(M), TSCtx));; });; }. TP.wait();. To make exclusive access to Modules easier to manage the ThreadSafeModule class; provides a convenience function, ``withModuleDo``, that implicitly (1) locks the; associated context, (2) runs a given function object, (3) unlocks the context,; and (3) returns the result generated by the function object. E.g. .. code-block:: c++. ThreadSafeModule TSM = getModule(...);. // Dump the module:; size_t NumFunctionsInModule =; TSM.withModuleDo(; [](Module &M) { // <- Context locked before entering lambda.; return M.size();; } // <- Context unlocked after leaving.; );. Clients wishing to maximize possibilities for concurrent compilation will want; to create every new ThreadSafeModule on a new ThreadSafeContext. For this; reason a convenience constructor for ThreadSafeModule is provided that implicitly; constructs a new ThreadSafeContext value from a std::unique_ptr<LLVMContext>:. .. code-block:: c++. // Maximize concurrency opportunities by loading every module on a; // separate context.; for (const auto &IRPath : IRPaths) {; auto Ctx = std::make_unique<LLVMContext>();; auto M = std::make_unique<LLVMContext>(""M"", *Ctx);; CompileLayer.add(MainJD, ThreadSafeModule(std::move(M), std::move(Ctx)));; }. Clients who plan to run single-threaded may choose to save memory by loading; all modules on the same context:. .. code-block:: c++. // Save memory by using one context for all Modules:; ThreadSafeContext TSCtx(std::make_unique<LLVMContext>());; for (const auto &IRPath : IRPaths) {; ThreadSafeModule TSM(parsePath(IRPath, *TSCtx.getContext()), TSCtx);; CompileLayer.add(MainJD, ThreadSafeModule(std::move(TSM));; }. .. _ProcessAnd",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:30514,concurren,concurrent,30514,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['concurren'],['concurrent']
Performance,"heduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42297,load,load,42297,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['load'],"['load', 'loads']"
Performance,"help. .. option:: -filetype=<output file type>. Specify what kind of output ``llc`` should generated. Options are: ``asm``; for textual assembly ( ``'.s'``), ``obj`` for native object files (``'.o'``); and ``null`` for not emitting anything (for performance testing). Note that not all targets support all options. .. option:: -mattr=a1,+a2,-a3,... Override or control specific attributes of the target, such as whether SIMD; operations are enabled or not. The default set of attributes is set by the; current CPU. For a list of available attributes, use:. .. code-block:: none. llvm-as < /dev/null | llc -march=xyz -mattr=help. .. option:: --frame-pointer. Specify effect of frame pointer elimination optimization (all,non-leaf,none). .. option:: --disable-excess-fp-precision. Disable optimizations that may produce excess precision for floating point.; Note that this option can dramatically slow down code on some systems; (e.g. X86). .. option:: --enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: --enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: --enable-no-signed-zeros-fp-math. Enable FP math optimizations that assume the sign of 0 is insignificant. .. option:: --enable-no-trapping-fp-math. Enable setting the FP exceptions build attribute not to use exceptions. .. option:: --enable-unsafe-fp-math. Enable optimizations that make unsafe assumptions about IEEE math (e.g. that; addition is associative) or may not work for all input ranges. These; optimizations allow the code generator to make use of some instructions which; would otherwise not be usable (such as ``fsin`` on X86). .. option:: --stats. Print statistics recorded by code-generation passes. .. option:: --time-passes. Record the amount of time needed for each pass and print a report to standard; error. .. option:: --load=<dso_path>. Dynamically load ``dso_path`` (a path to a dynamically shared object) that; implements an LLVM target. This will perm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst:3436,optimiz,optimizations,3436,interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,1,['optimiz'],['optimizations']
Performance,help/latest/variable/CMAKE_LANG_COMPILER.html). - `CMAKE_Fortran_COMPILER`. Select the Fortran compiler executable to be used. Not set by default and not; required unless running the Fortran Test Suite. - `CMAKE_BUILD_TYPE`. Select a build type like `OPTIMIZE` or `DEBUG` selecting a set of predefined; compiler flags. These flags are applied regardless of the `CMAKE_C_FLAGS`; option and may be changed by modifying `CMAKE_C_FLAGS_OPTIMIZE` etc. See; [https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html](https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html). - `TEST_SUITE_FORTRAN`. Activate that Fortran tests. This is a work in progress. More information can be; found in the [Flang documentation](https://flang.llvm.org/docs/FortranLLVMTestSuite.html). - `TEST_SUITE_RUN_UNDER`. Prefix test invocations with the given tool. This is typically used to run; cross-compiled tests within a simulator tool. - `TEST_SUITE_BENCHMARKING_ONLY`. Disable tests that are unsuitable for performance measurements. The disabled; tests either run for a very short time or are dominated by I/O performance; making them unsuitable as compiler performance tests. - `TEST_SUITE_SUBDIRS`. Semicolon-separated list of directories to include. This can be used to only; build parts of the test-suite or to include external suites. This option; does not work reliably with deeper subdirectories as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. -,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:5643,perform,performance,5643,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,1,['perform'],['performance']
Performance,"hem to always be noisy. A standard compromise is to comment; them out, allowing you to enable them if you need them in the future. The ``llvm/Support/Debug.h`` (`doxygen; <https://llvm.org/doxygen/Debug_8h_source.html>`__) file provides a macro named; ``LLVM_DEBUG()`` that is a much nicer solution to this problem. Basically, you can; put arbitrary code into the argument of the ``LLVM_DEBUG`` macro, and it is only; executed if '``opt``' (or any other tool) is run with the '``-debug``' command; line argument:. .. code-block:: c++. LLVM_DEBUG(dbgs() << ""I am here!\n"");. Then you can run your pass like this:. .. code-block:: none. $ opt < a.bc > /dev/null -mypass; <no output>; $ opt < a.bc > /dev/null -mypass -debug; I am here!. Using the ``LLVM_DEBUG()`` macro instead of a home-brewed solution allows you to not; have to create ""yet another"" command line option for the debug output for your; pass. Note that ``LLVM_DEBUG()`` macros are disabled for non-asserts builds, so they; do not cause a performance impact at all (for the same reason, they should also; not contain side-effects!). One additional nice thing about the ``LLVM_DEBUG()`` macro is that you can enable or; disable it directly in gdb. Just use ""``set DebugFlag=0``"" or ""``set; DebugFlag=1``"" from the gdb if the program is running. If the program hasn't; been started yet, you can always just run it with ``-debug``. .. _DEBUG_TYPE:. Fine grained debug info with ``DEBUG_TYPE`` and the ``-debug-only`` option; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes you may find yourself in a situation where enabling ``-debug`` just; turns on **too much** information (such as when working on the code generator).; If you want to enable debug information with more fine-grained control, you; should define the ``DEBUG_TYPE`` macro and use the ``-debug-only`` option as; follows:. .. code-block:: c++. #define DEBUG_TYPE ""foo""; LLVM_DEBUG(dbgs() << ""'foo' debug type\n"");; #undef DEBUG_TYPE; #def",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:43437,perform,performance,43437,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['performance']
Performance,"hen the check fails, calling an assertion handler. For example, consider the following code; fragment:. void foo(int *p) {; assert(p != NULL);; }. When this code is preprocessed on Mac OS X it expands to the following:. void foo(int *p) {; (__builtin_expect(!(p != NULL), 0) ? __assert_rtn(__func__, ""t.c"", 4, ""p != NULL"") : (void)0);; }. In this example, the assertion handler is __assert_rtn. When called,; most assertion handlers typically print an error and terminate the program. The; analyzer can exploit such semantics by ending the analysis of a path once it; hits a call to an assertion handler.; The trick, however, is that the analyzer needs to know that a called function; is an assertion handler; otherwise the analyzer might assume the function call; returns and it will continue analyzing the path where the assertion condition; failed. This can lead to false positives, as the assertion condition usually; implies a safety condition (e.g., a pointer is not null) prior to performing; some action that depends on that condition (e.g., dereferencing a pointer).; The analyzer knows about several well-known assertion handlers, but can; automatically infer if a function should be treated as an assertion handler if; it is annotated with the 'noreturn' attribute or the (Clang-specific); 'analyzer_noreturn' attribute. Note that, currently, clang does not support; these attributes on Objective-C methods and C++ methods.; Attribute 'noreturn'; The 'noreturn' attribute is a GCC-attribute that can be placed on the; declarations of functions. It means exactly what its name implies: a function; with a 'noreturn' attribute should never return.; Specific details of the syntax of using the 'noreturn' attribute can be found; in GCC's; documentation.; Not only does the analyzer exploit this information when pruning false paths,; but the compiler also takes it seriously and will generate different code (and; possibly better optimized) under the assumption that the function does not; re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html:21394,perform,performing,21394,interpreter/llvm-project/clang/www/analyzer/annotations.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/annotations.html,2,['perform'],['performing']
Performance,"hen trying to use ``MemorySSA``; to reason about atomic or volatile operations, as in:. .. code-block:: llvm. define i8 @foo(ptr %a) {; entry:; br i1 undef, label %if.then, label %if.end. if.then:; ; 1 = MemoryDef(liveOnEntry); %0 = load volatile i8, ptr %a; br label %if.end. if.end:; %av = phi i8 [0, %entry], [%0, %if.then]; ret i8 %av; }. Going solely by ``MemorySSA``'s analysis, hoisting the ``load`` to ``entry`` may; seem legal. Because it's a volatile load, though, it's not. Design tradeoffs; ----------------. Precision; ^^^^^^^^^. ``MemorySSA`` in LLVM deliberately trades off precision for speed.; Let us think about memory variables as if they were disjoint partitions of the; memory (that is, if you have one variable, as above, it represents the entire; memory, and if you have multiple variables, each one represents some; disjoint portion of the memory). First, because alias analysis results conflict with each other, and; each result may be what an analysis wants (IE; TBAA may say no-alias, and something else may say must-alias), it is; not possible to partition the memory the way every optimization wants.; Second, some alias analysis results are not transitive (IE A noalias B,; and B noalias C, does not mean A noalias C), so it is not possible to; come up with a precise partitioning in all cases without variables to; represent every pair of possible aliases. Thus, partitioning; precisely may require introducing at least N^2 new virtual variables,; phi nodes, etc. Each of these variables may be clobbered at multiple def sites. To give an example, if you were to split up struct fields into; individual variables, all aliasing operations that may-def multiple struct; fields, will may-def more than one of them. This is pretty common (calls,; copies, field stores, etc). Experience with SSA forms for memory in other compilers has shown that; it is simply not possible to do this precisely, and in fact, doing it; precisely is not worth it, because now all the optimizat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:17191,optimiz,optimization,17191,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimization']
Performance,"hen using OpenUI5 with THttpServer. First of all, location of JSROOT modules should be specified; as `/jsrootsys/modules/main.mjs`. And then trying to access files from local disk, one should specify `/currentdir/` folder:. ```javascript; jQuery.sap.registerModulePath(""NavExample"", ""/currentdir/"");; ```. JSROOT provides [example](https://root.cern/js/latest/demo/openui5/) showing usage of JSROOT drawing in the OpenUI5,; [source code](https://github.com/root-project/jsroot/tree/master/demo/openui5) can be found in repository. ### Migration v6 -> v7. * Core functionality should be imported from `main.mjs` module like:. ```javascript; import { create, parse, createHistogram, redraw } from 'https://root.cern/js/7.0.0/modules/main.mjs';; ```. * It is still possible to use `JSRoot.core.js` script, which provides very similar (but not identical!) functionality as with `v6` via global `JSROOT` object. * `JSROOT.define()` and `JSROOT.require()` functions only available after `JSRoot.core.js` loading. * Support of `require.js` and `openui5` loaders was removed. * Global hierarchy painter `JSROOT.hpainter` no longer existing, one can use `getHPainter` function:. ```javascript; import { getHPainter } from 'https://root.cern/js/7.0.0/modules/main.mjs';; let hpainter = getHPainter();; ```. * All math functions previously available via `JSROOT.Math` should be imported from `base/math.mjs` module:. ```javascript; import * as math from 'https://root.cern/js/7.0.0/modules/base/math.mjs';; ```. * Indication of batch mode `JSROOT.batch_mode` should be accessed via functions:. ```javascript; import { isBatchMode, setBatchMode } from 'https://root.cern/js/7.0.0/modules/main.mjs';; let was_batch = isBatchMode();; if (!was_batch) setBatchMode(true);; ```. * `JSROOT.extend()` function was removed, use `Object.assign()` instead. ### Migration v5 -> v6. * Main script was renamed to `JSRoot.core.js`. Old `JSRootCore.js` was deprecated and removed in v6.2. All URL parameters for main script ign",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:47736,load,loading,47736,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['load'],['loading']
Performance,"her options you can use are:. .. code-block:: bash. Use Ninja instead of Make: ""-G Ninja""; Build with assertions on: ""-DLLVM_ENABLE_ASSERTIONS=True""; Local (non-sudo) install path: ""-DCMAKE_INSTALL_PREFIX=$HOME/llvm/install""; CPU flags: ""DCMAKE_C_FLAGS=-mcpu=cortex-a15"" (same for CXX_FLAGS). After that, just typing ``make -jN`` or ``ninja`` will build everything.; ``make -jN check-all`` or ``ninja check-all`` will run all compiler tests. For; running the test suite, please refer to :doc:`TestingGuide`. #. If you are building LLVM/Clang on an ARM board with 1G of memory or less,; please use ``gold`` rather then GNU ``ld``. In any case it is probably a good; idea to set up a swap partition, too. .. code-block:: bash. $ sudo ln -sf /usr/bin/ld /usr/bin/ld.gold. #. ARM development boards can be unstable and you may experience that cores; are disappearing, caches being flushed on every big.LITTLE switch, and; other similar issues. To help ease the effect of this, set the Linux; scheduler to ""performance"" on **all** cores using this little script:. .. code-block:: bash. # The code below requires the package 'cpufrequtils' to be installed.; for ((cpu=0; cpu<`grep -c proc /proc/cpuinfo`; cpu++)); do; sudo cpufreq-set -c $cpu -g performance; done. Remember to turn that off after the build, or you may risk burning your; CPU. Most modern kernels don't need that, so only use it if you have; problems. #. Running the build on SD cards is ok, but they are more prone to failures; than good quality USB sticks, and those are more prone to failures than; external hard-drives (those are also a lot faster). So, at least, you; should consider to buy a fast USB stick. On systems with a fast eMMC,; that's a good option too. #. Make sure you have a decent power supply (dozens of dollars worth) that can; provide *at least* 4 amperes, this is especially important if you use USB; devices with your board. Externally powered USB/SATA harddrives are even; better than having a good power supply.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst:2789,perform,performance,2789,interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst,1,['perform'],['performance']
Performance,"here are cores. If the number of; cores can't be computed for the architecture, then it will launch; ``std::thread::hardware_concurrency`` number of threads in parallel.; For machines with hyper-threading, this is the total number of; virtual cores. For some applications and machine configurations this; may be too aggressive, in which case the amount of parallelism can; be reduced to ``N`` via:. - gold:; ``-Wl,-plugin-opt,jobs=N``; - ld64:; ``-Wl,-mllvm,-threads=N``; - ld.lld, ld64.lld:; ``-Wl,--thinlto-jobs=N``; - lld-link:; ``/opt:lldltojobs=N``. Other possible values for ``N`` are:. - 0:; Use one thread per physical core (default); - 1:; Use a single thread only (disable multi-threading); - all:; Use one thread per logical core (uses all hyper-threads). Incremental; -----------; .. _incremental:. ThinLTO supports fast incremental builds through the use of a cache,; which currently must be enabled through a linker option. - gold (as of LLVM 4.0):; ``-Wl,-plugin-opt,cache-dir=/path/to/cache``; - ld64 (supported since clang 3.9 and Xcode 8) and Mach-O ld64.lld (as of LLVM; 15.0):; ``-Wl,-cache_path_lto,/path/to/cache``; - ELF ld.lld (as of LLVM 5.0):; ``-Wl,--thinlto-cache-dir=/path/to/cache``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocache:/path/to/cache``. Cache Pruning; -------------. To help keep the size of the cache under control, ThinLTO supports cache; pruning. Cache pruning is supported with gold, ld64, and lld, but currently only; gold and lld allow you to control the policy with a policy string. The cache; policy must be specified with a linker option. - gold (as of LLVM 6.0):; ``-Wl,-plugin-opt,cache-policy=POLICY``; - ELF ld.lld (as of LLVM 5.0), Mach-O ld64.lld (as of LLVM 15.0):; ``-Wl,--thinlto-cache-policy=POLICY``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocachepolicy:POLICY``. A policy string is a series of key-value pairs separated by ``:`` characters.; Possible key-value pairs are:. - ``cache_size=X%``: The maximum size for the cache directo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:4743,cache,cache-dir,4743,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,2,['cache'],"['cache', 'cache-dir']"
Performance,"here, ""int""), or a string representation of; the parameters (e.g. ""'double'""), or a mixture of both (e.g. ""'TCanvas,; 0'"" or ""'double', 0"" ). The ""std::vector\<int\>"" class is one of the; classes builtin by default into the Cling extension dlls. You will get a; non-functional class (instances of which can still be passed around to; C++) if the corresponding dictionary doesn't exist. #### Access to ROOT Globals. Most globals and global functions can be imported directly from the; ROOT.py module, but some common ones (most notably **`gMinuit`**,; although that variable now exists at startup from release 5.08 onward); do not exist yet at program startup, as they exist in modules that are; loaded later (e.g. through the auto-loading mechanism). An example; session should make this clear:. ``` {.cpp}; >>> from ROOT import *; >>> gROOT # directly available; <ROOT.TROOT object at 0x399c30>; >>> gMinuit # library not yet loaded: not available; Traceback (most recent call last):; File ""<stdin>"", line 1, in ?; NameError: name 'gMinuit' is not defined; >>> TMinuit # use of TMinuit class forces auto-loading; <class '__main__.TMinuit'>; >>> gMinuit # now gMinuit is available; <__main__.TMinuit object at 0x1458c70>; >>> not not gMinuit # but it is the null pointer, until set; False; >>> g = TMinuit(); >>> not not gMinuit; True; ```. It is also possible to create globals interactively, either by executing; a Cling macro, or by a call to `gROOT.ProcessLine()`. These globals are; made available in the same way: either use them directly after creation; in 'from ROOT import \*' more, or get them from the ROOT namespace after; an 'import ROOT'. As of 5.08, the behaviour of ROOT globals is the same as python globals,; which is sometimes counterintuitive: since they are references, they can; be changed only if done so directly through their containing module. The; following session shows that in detail:. ``` {.cpp}; >>> from ROOT import *; >>> print(gDebug); 0; >>> gROOT.ProcessLine( 'gDe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:13320,load,loaded,13320,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,2,['load'],"['loaded', 'loading']"
Performance,"herit from TAttLine class so the line style or; width can also be changed:. ~~~{.cpp}; myVolume->SetLineColor(kRed);; myVolume->SetLineWith(2);; myVolume->SetLineStyle(kDotted);; ~~~. When drawing in solid mode, the color of the drawn volume corresponds to; the line color. \anchor GP04bb; #### Visibility Settings. The way geometry is build forces the definition of several volumes that; does not represent real objects, but just virtual containers used for; grouping and positioning volumes together. One would not want to see; them in the picture. Since every volume is by default visible, one has; to do this sort of tuning by its own:. ~~~{.cpp}; myVolumeContainer->SetVisibility(kFALSE);; ~~~. As described before, the drawing package supports two main global; options: 1 (default) - only final volume leaves; 0 - all volumes down; the drawn one appear on the screen. The global visible level put a; limitation on the maximum applied depth. Combined with visibility; settings per volume, these can tune quite well what should appear on the; screen. However, there are situations when users want to see a volume; branch displayed down to the maximum depth, keeping at the same time a; limitation or even suppressing others. In order to accomplish that, one; should use the volume attribute: ""Visible daughters"". By default, all; daughters of all volumes are displayed if there is no limitation related; with their level depth with respect to the top drawn volume. \anchor GP04c; ### Ray Tracing. Ray tracing is a quite known drawing technique based on tracking rays; from the eye position through all pixels of a view port device. The; pixel color is derived from the properties of the first crossed surface,; according some illumination model and material optical properties. While; there are currently existing quite sophisticated ray tracing models,; `TGeo` is currently using a very simple approach where the light; source is matching the eye position (no shadows or back-tracing of the; ref",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:103126,tune,tune,103126,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['tune'],['tune']
Performance,"hese module maps. One can use module maps without modules to check the integrity of the use of header files. To do this, use the ``-fimplicit-module-maps`` option instead of the ``-fmodules`` option, or use ``-fmodule-map-file=`` option to explicitly specify the module map files to load. Compilation model; -----------------; The binary representation of modules is automatically generated by the compiler on an as-needed basis. When a module is imported (e.g., by an ``#include`` of one of the module's headers), the compiler will spawn a second instance of itself [#]_, with a fresh preprocessing context [#]_, to parse just the headers in that module. The resulting Abstract Syntax Tree (AST) is then persisted into the binary representation of the module that is then loaded into translation unit where the module import was encountered. The binary representation of modules is persisted in the *module cache*. Imports of a module will first query the module cache and, if a binary representation of the required module is already available, will load that representation directly. Thus, a module's headers will only be parsed once per language configuration, rather than once per translation unit that uses the module. Modules maintain references to each of the headers that were part of the module build. If any of those headers changes, or if any of the modules on which a module depends change, then the module will be (automatically) recompiled. The process should never require any user intervention. Command-line parameters; -----------------------; ``-fmodules``; Enable the modules feature. ``-fbuiltin-module-map``; Load the Clang builtins module map file. (Equivalent to ``-fmodule-map-file=<resource dir>/include/module.modulemap``). ``-fimplicit-module-maps``; Enable implicit search for module map files named ``module.modulemap`` and similar. This option is implied by ``-fmodules``. If this is disabled with ``-fno-implicit-module-maps``, module map files will only be loaded if t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:13778,cache,cache,13778,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,2,"['cache', 'load']","['cache', 'load']"
Performance,"hey are variable length, inefficient to hash and compare when; long, expensive to copy, etc. StringMap is a specialized container designed to; cope with these issues. It supports mapping an arbitrary range of bytes to an; arbitrary other object. The StringMap implementation uses a quadratically-probed hash table, where the; buckets store a pointer to the heap allocated entries (and some other stuff).; The entries in the map must be heap allocated because the strings are variable; length. The string data (key) and the element object (value) are stored in the; same allocation with the string data immediately after the element object.; This container guarantees the ""``(char*)(&Value+1)``"" points to the key string; for a value. The StringMap is very fast for several reasons: quadratic probing is very cache; efficient for lookups, the hash value of strings in buckets is not recomputed; when looking up an element, StringMap rarely has to touch the memory for; unrelated objects when looking up a value (even when hash collisions happen),; hash table growth does not recompute the hash values for strings already in the; table, and each pair in the map is store in a single allocation (the string data; is stored in the same allocation as the Value of a pair). StringMap also provides query methods that take byte ranges, so it only ever; copies a string if a value is inserted into the table. StringMap iteration order, however, is not guaranteed to be deterministic, so; any uses which require that should instead use a std::map. .. _dss_indexmap:. llvm/ADT/IndexedMap.h; ^^^^^^^^^^^^^^^^^^^^^. IndexedMap is a specialized container for mapping small dense integers (or; values that can be mapped to small dense integers) to some other type. It is; internally implemented as a vector with a mapping function that maps the keys; to the dense integer range. This is useful for cases like virtual registers in the LLVM code generator: they; have a dense mapping that is offset by a compile-time",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:89370,cache,cache,89370,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['cache'],['cache']
Performance,"hh52tv_2nrdxrj31nyw0000gn/T/a-9be59b.o``. * ``/var/folders/43/9y164hh52tv_2nrdxrj31nyw0000gn/T/a-9be59b.opt.bitstream``. * ``out``. * ``out.dSYM/Contents/Resources/Remarks/out``. Darwin-only: compiling for multiple architectures will use the following; scheme:. ``<base>-<arch>.opt.<format>``. Note that this is incompatible with passing the; :option:`-foptimization-record-file` option. .. option:: -foptimization-record-file. Control the file to which optimization reports are written. This implies; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`. On Darwin platforms, this is incompatible with passing multiple; ``-arch <arch>`` options. .. option:: -foptimization-record-passes. Only include passes which match a specified regular expression. When optimization reports are being output (see; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`), this; option controls the passes that will be included in the final report. If this option is not used, all the passes are included in the optimization; record. .. _opt_fdiagnostics-show-hotness:. .. option:: -f[no-]diagnostics-show-hotness. Enable profile hotness information in diagnostic line. This option controls whether Clang prints the profile hotness associated; with diagnostics in the presence of profile-guided optimization information.; This is currently supported with optimization remarks (see; :ref:`Options to Emit Optimization Reports <rpass>`). The hotness information; allows users to focus on the hot optimization remarks that are likely to be; more relevant for run-time performance. For example, in this output, the block containing the callsite of `foo` was; executed 3000 times according to the profile data:. ::. s.c:7:10: remark: foo inlined into bar (hotness: 3000) [-Rpass-analysis=inline]; sum += foo(x, x - 2);; ^. This option is implied when; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>` is used.; Otherwise, it defaults to off. .. option:: -fdiagnostics-hotness-thr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:13709,optimiz,optimization,13709,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance,"hierarchy. From; outside, the whole thing looks like a big pack that you can open finding; out other smaller packs nicely arranged waiting to be opened at their; turn. The biggest one containing all others defines the ""`world`"" of the; model. We will often call this `master reference system (MARS)`. Going; on and opening our packs, we will obviously find out some empty ones,; otherwise, something is very wrong... We will call these leaves (by; analogy with a tree structure). On the other hand, any volume is a small world by itself - what we need; to do is to take it out and to ignore all the rest since it is a; self-contained object. In fact, the modeller can act like this,; considering a given volume as temporary MARS, but we will describe this; feature later on. Let us focus on the biggest pack - it is mandatory to; define one. Consider the simplest geometry that is made of a single box.; Here is an example on how to build it:. ### Example 1: Creating the World. We first need to load the geometry library. This is not needed if one; does `make map` in root folder. ``` {.cpp}; root[] gSystem->Load(""libGeom"");; ```. Second, we have to create an instance of the geometry manager class.; This takes care of all the modeller components, performing several tasks; to insure geometry validity and containing the user interface for; building and interacting with the geometry. After its creation, the; geometry manager class can be accessed with the global; ***`gGeoManager`***:. ``` {.cpp}; root[] new TGeoManager(""world"", ""the simplest geometry"");; ```. We want to create a single volume in our geometry, but since any volume; needs to have an associated medium, we will create a dummy one. You can; safely ignore the following lines for the time being, since materials; and media will be explained in detail later on. ``` {.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""Vacuum"",0,0,0);; root[] TGeoMedium *med = new TGeoMedium(""Vacuum"",1,mat);; ```. We can finally make our volume ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:2129,load,load,2129,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['load'],['load']
Performance,"his class is instantiated, `fChain` will point to the; original tree or chain this class was made from. In our case, this is; ""T"" in ""`Event.root`"". If the class is instantiated with a tree as a; parameter to the constructor, `fChain` will point to the tree named in; the parameter. Next is `fCurrent`, which is also a pointer to the; current tree/chain. Its role is only relevant when we have multiple; trees chained together in a **`TChain`**. The class definition shows us; that this tree has one branch and one leaf per data member. The methods; of `MyClass` are:. - `MyClass(TTree *tree=0) -` this constructor has an optional tree; for a parameter. If you pass a tree, `MyClass` will use it rather; than the tree from which it was created. - `void Init(TTree *tree) -` it is called by the constructor to; initialize the tree for reading. It associates each branch with the; corresponding leaf data member. - `~MyClass() - `the destructor, nothing special. - `Int_t GetEntry(Int_t entry) -` it loads the class with the entry; specified. Once you have executed `GetEntry`, the leaf data members; in `MyClass` are set to the values of the entry. For example,; `GetEntry(12)` loads the 13th event into the event data member of; `MyClass` (note that the first entry is 0). `GetEntry` returns the; number of bytes read from the file. In case the same entry is read; twice, ROOT does not have to do any I/O. In this case `GetEntry`; returns 1. It does not return 0, because many people assume a return; of 0 means an error has occurred while reading. - `Int_t LoadTree(Int_t entry)` and `void Notify()` - these two; methods are related to chains. `LoadTree` will load the tree; containing the specified entry from a chain of trees. Notify is; called by `LoadTree` to adjust the branch addresses. - `void Loop()` - it is the skeleton method that loops through each; entry of the tree. This is interesting to us, because we will need; to customize it for our analysis. ### MyClass.C. `MyClass::Loop` cons",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:127061,load,loads,127061,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['loads']
Performance,"his guidance is that a unified return block with high in-degree is fine. Use of allocas; ^^^^^^^^^^^^^^. An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:2997,load,loads,2997,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['load'],['loads']
Performance,"his intrinsic stores a null pointer into the; ""ptrloc"" location. At compile-time, the code generator generates; information to allow the runtime to find the pointer at GC safe points.; The '``llvm.gcroot``' intrinsic may only be used in a function which; :ref:`specifies a GC algorithm <gc>`. .. _int_gcread:. '``llvm.gcread``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.gcread(ptr %ObjPtr, ptr %Ptr). Overview:; """""""""""""""""". The '``llvm.gcread``' intrinsic identifies reads of references from heap; locations, allowing garbage collector implementations that require read; barriers. Arguments:; """""""""""""""""""". The second argument is the address to read from, which should be an; address allocated from the garbage collector. The first object is a; pointer to the start of the referenced object, if needed by the language; runtime (otherwise null). Semantics:; """""""""""""""""""". The '``llvm.gcread``' intrinsic has the same semantics as a load; instruction, but may be replaced with substantially more complex code by; the garbage collector runtime, as needed. The '``llvm.gcread``'; intrinsic may only be used in a function which :ref:`specifies a GC; algorithm <gc>`. .. _int_gcwrite:. '``llvm.gcwrite``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.gcwrite(ptr %P1, ptr %Obj, ptr %P2). Overview:; """""""""""""""""". The '``llvm.gcwrite``' intrinsic identifies writes of references to heap; locations, allowing garbage collector implementations that require write; barriers (such as generational or reference counting collectors). Arguments:; """""""""""""""""""". The first argument is the reference to store, the second is the start of; the object to store it to, and the third is the address of the field of; Obj to store to. If the runtime does not require a pointer to the; object, Obj may be null. Semantics:; """""""""""""""""""". The '``llvm.gcwrite``' intrinsic has the same semantics as a store; instruction, but may be replaced with substantially more co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:498308,load,load,498308,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"his section is currently incomplete and has inaccuracies. It is WIP that will; be updated as information is determined. See :ref:`amdgpu-dwarf-address-space-identifier` for information on swizzled; addresses. Unswizzled addresses are normal linear addresses. .. _amdgpu-amdhsa-function-call-convention-kernel-functions:. Kernel Functions; ++++++++++++++++. This section describes the call convention ABI for the outer kernel function. See :ref:`amdgpu-amdhsa-initial-kernel-execution-state` for the kernel call; convention. The following is not part of the AMDGPU kernel calling convention but describes; how the AMDGPU implements function calls:. 1. Clang decides the kernarg layout to match the *HSA Programmer's Language; Reference* [HSA]_. - All structs are passed directly.; - Lambda values are passed *TBA*. .. TODO::. - Does this really follow HSA rules? Or are structs >16 bytes passed; by-value struct?; - What is ABI for lambda values?. 4. The kernel performs certain setup in its prolog, as described in; :ref:`amdgpu-amdhsa-kernel-prolog`. .. _amdgpu-amdhsa-function-call-convention-non-kernel-functions:. Non-Kernel Functions; ++++++++++++++++++++. This section describes the call convention ABI for functions other than the; outer kernel function. If a kernel has function calls then scratch is always allocated and used for; the call stack which grows from low address to high address using the swizzled; scratch address space. On entry to a function:. 1. SGPR0-3 contain a V# with the following properties (see; :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`):. * Base address pointing to the beginning of the wavefront scratch backing; memory.; * Swizzled with dword element size and stride of wavefront size elements. 2. The FLAT_SCRATCH register pair is setup. See; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; 3. GFX6-GFX8: M0 register set to the size of LDS in bytes. See; :ref:`amdgpu-amdhsa-kernel-prolog-m0`.; 4. The EXEC register is set to the lanes active on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:386859,perform,performs,386859,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performs']
Performance,"his will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Chec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36758,perform,performance,36758,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance,"his works quite well on Linux (through ``gdb``) and decently on MacOS; (through ``unwind``), but is currently unreliable on MS Windows.; To prevent printing of this trace, which can be slow to produce, set the; envar ``CPPYY_CRASH_QUIET`` to '1'. It is even more useful to obtain a traceback through the Python code that led; up to the problem in C++.; Many modern debuggers allow mixed-mode C++/Python debugging (for example; `gdb`_ and `MSVC`_), but cppyy can also turn abortive C++ signals (such as a; segmentation violation) into Python exceptions, yielding a normal traceback.; This is particularly useful when working with cross-inheritance and other; cross-language callbacks. To enable the signals to exceptions conversion, import the lowlevel module; ``cppyy.ll`` and use:. .. code-block:: python. import cppyy.ll; cppyy.ll.set_signals_as_exception(True). Call ``set_signals_as_exception(False)`` to disable the conversion again.; It is recommended to only have the conversion enabled around the problematic; code, as it comes with a performance penalty.; If the problem can be localized to a specific function, you can use its; ``__sig2exc__`` flag to only have the conversion active in that function.; Finally, for convenient scoping, you can also use:. .. code-block:: python. with cppyy.ll.signals_as_exception():; # crashing code goes here. The translation of signals to exceptions is as follows (all of the exceptions; are subclasses of ``cppyy.ll.FatalError``):. ======================================== ========================================; C++ signal Python exception; ======================================== ========================================; ``SIGSEGV`` ``cppyy.ll.SegmentationViolation``; ``SIGBUS`` ``cppyy.ll.BusError``; ``SIGABRT`` ``cppyy.ll.AbortSignal``; ``SIGILL`` ``cppyy.ll.IllegalInstruction``; ======================================== ========================================. As an example, consider the following cross-inheritance code that crashes; with ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst:1836,perform,performance,1836,bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst,1,['perform'],['performance']
Performance,"hose cases, the filter is not expected to handle line; breaks in arbitrary places inside a markup element, but only inside certain; fields. This format assumes that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treated as a single address; space for symbolization purposes if desired. Dependence on Build IDs; =======================. The symbolizer markup scheme relies on contextual information about runtime; memory address layout to make it possible to convert markup elements into useful; symbolic form. This relies on having an unmistakable identification of which; binary was loaded at each address. An ELF Build ID is the payload of an ELF note with name ``""GNU""`` and type; ``NT_GNU_BUILD_ID``, a unique byte sequence that identifies a particular binary; (executable, shared library, loadable module, or driver module). The linker; generates this automatically based on a hash that includes the complete symbol; table and debugging information, even if this is later stripped from the binary. This specification uses the ELF Build ID as the sole means of identifying; binaries. Each binary relevant to the log must have been linked with a unique; Build ID. The symbolizing filter must have some means of mapping a Build ID back; to the original ELF binary (either the whole unstripped binary, or a stripped; binary paired with a separate debug file). Colorization; ============. The markup format supports a restricted subset of ANSI X3.64 SGR (Select Graphic; Rendition) control sequences. These are unlike other markup elements:. * They specify p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:3776,load,loaded,3776,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,1,['load'],['loaded']
Performance,"hough it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ``llvm::TimePassesIsEnabled`` flag; exported by the ``lib/IR/PassManager.cpp`` file. .. todo::. TODO: complete this section. .. _dynamically loaded options:. Dynamically adding command line options; ---------------------------------------. .. todo::. TODO: fill in this section; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:67136,load,loaded,67136,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,1,['load'],['loaded']
Performance,"hout any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on crea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9739,cache,cache,9739,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,2,['cache'],['cache']
Performance,"hout the specification, the script is compiled with the same; level of debugging symbol and optimization as the currently running; ROOT executable. For example:. ``` {.cpp}; root[] .L MyScript.C++g; ```. will compile `MyScript.C` with debug symbols; usually this means; giving the `-g` option to compiler. ``` {.cpp}; root[] .L MyScript.C++O; ```. will compile `MyScript.C` with optimizations; usually this means; giving the `-O` option to compiler. The syntax:. ``` {.cpp}; root[] .L MyScript.C++; ```. is using the default optimization level. The initial default is to; compile with the same level of optimization as the root executable; itself. The default can be changed by:. ``` {.cpp}; root[] gSystem->SetAclicMode(TSystem::kDebug);; root[] gSystem->SetAclicMode(TSystem::kOpt);; ```. Note that the commands:. ``` {.cpp}; root[] .L MyScript.C+g; root[] .L MyScript.C+O; ```. respectively compile `MyScript.C` with debug and optimization if the; library does not exist yet; they will not change the debug and the; optimization level if the library already exist and it is up to date.; To use ACLiC from compiled code or from inside another macro, we; recommend using `gROOT->ProcessLine()`. For; example, in one script you can use ACLiC to compile and load another; script. ``` {.cpp}; gROOT->ProcessLine("".L MyScript.C+""); gROOT->ProcessLine("".L MyScript.C++""); ```. ### Setting the Include Path. You can get the include path by typing:. ``` {.cpp}; root[] .include; ```. You can append to the include path by typing:. ``` {.cpp}; root[] .include $HOME/mypackage/include; ```. In a script you can append to the include path:. ``` {.cpp}; gSystem->AddIncludePath("" -I$HOME/mypackage/include ""); ```. You can also overwrite the existing include path:. ``` {.cpp}; gSystem->SetIncludePath("" -I$HOME/mypackage/include ""); ```. The `$ROOTSYS/include` directory is automatically appended to the; include path, so you do not have to worry about including it. To add; library that should be used during",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md:15938,optimiz,optimization,15938,documentation/users-guide/Cling.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md,2,['optimiz'],['optimization']
Performance,"however; the ""technological"" limitations of M can be seen around a maximum of 15; free parameters at a time. ## Interference with other packages ##. The new M has been designed to interfere as little as possible with; other programs or packages which may be loaded at the same time. M is; thread safe by default. Optionally the user can select a different way; of dynamically allocating memory in the class StackAllacator for M , in; which case (and after an entire recompilation of the whole library) the; thread safety is lost. ## Floating-point precision ##. [install:epsmac]. M is entirely based on double precision. The actual floating point; precision of double precision (32bit or 64bit) is platform dependent; and can even vary on the same platform, depending on whether a floating; point number is read from memory a CPU register. The argument of the user's implementation of FCNBase::operator() is; therefore a std:vector$<$double$>$. M expects that the calculations; inside $\mbox{FCN}$ will be performed approximately to the same; accuracy. The accuracy M expects is called *machine precision*; (MnMachinePrecision, see [api:epsmac]) and can be printed on demand; using std::cout. If the user fools M by making internal $\mbox{FCN}$; computations in single precision, M will interpret roundoff noise as; significant and will usually either fail to find a minimum, or give; incorrect values for the parameter errors. It is therefore recommended to make sure that all computations in; $\mbox{FCN}$, as well as all methods and functions called by; $\mbox{FCN}$, are done in double precision. If for some reason the; computations cannot be done to a precision comparable with that expected; by M , the user **must** inform M of this situation with setting a; different machine precision via the; MnMachinePrecision::setPrecision(double) method. With reduced precision, the user may find that certain features; sensitive to first and second differences ($\mbox{HESSE}$,; $\mbox{MINOS}$, $\mb",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:26925,perform,performed,26925,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['perform'],['performed']
Performance,"hown in Figures [5.2](#f52) and [5.3](#f53). [f52]: figures/histo_sum.png ""f52""; <a name=""f52""></a>. ![The sum of two histograms.\label{f52}][f52]. [f53]: figures/histo_ratio.png ""f53""; <a name=""f53""></a>. ![The ratio of two histograms.\label{f53}][f53]. Some lines now need a bit of clarification:. - line *3*: Cling, as we know, is also able to interpret more than one; function per file. In this case the function simply sets up some; parameters to conveniently set the line of histograms. - line *19* to *21*: Some `C++` syntax for conditional; statements is used to fill the histograms with different numbers of; entries inside the loop. - line *30*: The sum of two histograms. A weight, which can be negative, can; be assigned to the added histogram. - line *41*: The division of two histograms is rather straightforward. - line *44* to *62*: When you draw two quantities and their ratios, it; is much better if all the information is condensed in one single; plot. These lines provide a skeleton to perform this operation. ## Two-dimensional Histograms ##. Two-dimensional histograms are a very useful tool, for example to; inspect correlations between variables. You can exploit the; bi-dimensional histogram classes provided by ROOT in a simple way.; Let's see how in this macro:. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/macro7.C; ```. Two kinds of plots are provided within the code, the first one; containing three-dimensional representations (Figure [5.4](#f54)) and the second one; projections and profiles (Figure [5.5](#f55)) of the bi-dimensional histogram. [f54]: figures/th2f.png ""f54""; <a name=""f54""></a>. ![Different ways of representing bi-dimensional; histograms.\label{f54}][f54]. [f55]: figures/proj_and_prof.png ""f55""; <a name=""f55""></a>. ![The projections and profiles of bi-dimensional; histograms.\label{f55}][f55]. When a projection is performed along the x (y) direction, for every bin; along the x (y) axis, all bin contents along the y (x) axis are summed; up (upper the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/histograms.md:3126,perform,perform,3126,documentation/primer/histograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/histograms.md,1,['perform'],['perform']
Performance,"hread attempted to take on the ROOT lock).; - The interpreter now suspend the ROOT lock (which is taken to protect the interpreter global state) during user code execution. ## I/O Libraries; - LZ4 (with compression level 4) is now the default compression algorithm for new ROOT files (LZ4 is lossless data compression algorithm that is focused on compression and decompression speed, while in ROOT case providing benefit in faster decompression at the price of a bit worse compression ratio comparing to ZLIB); - If two or more files have an identical streamer info record, this is only treated once therewith avoiding to take the global lock.; - Allow writing temporary objects (with same address) in the same TBuffer(s). A new flag to TBuffer*::WriteObject allows to skip the mechanism that prevent the 2nd streaming of an object. This allows the (re)use of temporary objects to store different data in the same buffer.; - Reuse branch proxies internally used by TTreeReader{Value,Array} therewith increasing performance when having multiple readers pointing to the same branch.; - Implement reading of objects data from JSON; - Provide TBufferJSON::ToJSON() and TBufferJSON::FromJSON() methods; - Provide TBufferXML::ToXML() and TBufferXML::FromXML() methods; - Converts NaN and Infinity values into null in JSON, there are no other direct equivalent. ## TTree Libraries; - Enable the TTreeCache by default of `TTree::Draw`, `TTreeReader` and `RDataFrame`; - Significant enhancement in the `TTreeCache` filling algorithm to increase robustness in case of oddly clustered `TTree` and under provisioned cache size. See the [merge request](https://github.com/root-project/root/pull/1960) for more details.; - Proxies are now properly re-used when multiple TTreeReader{Value,Array}s are associated to a single branch. Deserialisation is therefore performed once. This is an advantage for complex TDataFrame graphs.; - Add TBranch::BackFill to allow the addition of new branches to an existing tree and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:4107,perform,performance,4107,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['perform'],['performance']
Performance,"https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attacker-controlled_ addresses. To prevent these; from reading secret data, the low 2gb of the address space and 2gb above and; below any executable pages should be protected. Credit:; * The core idea of tracing misspeculation through data and marking pointers to; block misspeculated loads was developed as part of a HACS 2018 discussion; between Chandler Carruth, Paul Kocher, Thomas Pornin, and several other; individuals.; * Core idea of masking out loaded bits was part of the original mitigation; suggested by Jann Horn when these attacks were reported. ### Indirect Branches, Calls, and Returns. It is possible to attack control flow other than conditional branches with; variant #1 style mispredictions.; * A prediction towards a hot call target of a virtual method can lead to it; being speculatively executed when an expected type is used (often called; ""type confusion"").; * A hot case may be speculatively executed due to prediction instead of the; correct case for a switch statement implemented as a jump table.; * A hot common return address may be predicted incorrectly when returning from; a function. These code patterns are also vulnerable to Spectre variant #2, and as such are; best mitigated with a; [retpoline](https://support.google.com/faqs/answer/7625886) on x86 platforms.;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:8071,load,loads,8071,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance,"i-stage PGO builds are a workflow for generating PGO; profiles that can be used to optimize clang. At a high level, the way PGO works is that you build an instrumented compiler,; then you run the instrumented compiler against sample source files. While the; instrumented compiler runs it will output a bunch of files containing; performance counters (.profraw files). After generating all the profraw files; you use llvm-profdata to merge the files into a single profdata file that you; can feed into the LLVM_PROFDATA_FILE option. Our PGO.cmake cache automates that whole process. You can use it for; configuration with CMake with the following command:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/PGO.cmake \; <path to source>/llvm. There are several additional options that the cache file also accepts to modify; the build, particularly the PGO_INSTRUMENT_LTO option. Setting this option to; Thin or Full will enable ThinLTO or full LTO respectively, further enhancing; the performance gains from a PGO build by enabling interprocedural; optimizations. For example, to run a CMake configuration for a PGO build; that also enables ThinTLO, use the following command:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/PGO.cmake \; -DPGO_INSTRUMENT_LTO=Thin \; <path to source>/llvm. By default, clang will generate profile data by compiling a simple; hello world program. You can also tell clang use an external; project for generating profile data that may be a better fit for your; use case. The project you specify must either be a lit test suite; (use the CLANG_PGO_TRAINING_DATA option) or a CMake project (use the; CLANG_PERF_TRAINING_DATA_SOURCE_DIR option). For example, If you wanted to use the; `LLVM Test Suite <https://github.com/llvm/llvm-test-suite/>`_ to generate; profile data you would use the following command:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/PGO.cmake \; -DBOO",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:5857,perform,performance,5857,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,2,"['optimiz', 'perform']","['optimizations', 'performance']"
Performance,"i.e. ProcessID) support. To; enable; schema evolution for all messages call; TMessage::EnableSchemaEvolutionForAll(kTRUE).; To enable it only for a specific message call; mess->EnableSchemaEvolution(kTRUE).; The default for schema evolution is off. The streamer and process id; information are send only once per socket (and is supported for all; types of; sockets, TSocket, TPSocket and TXSocket). If you communicate between; two; ROOT based applications, check the version numbers on both sides. If; they; are not the same enable the schema evolution support (in case ROOT; objects; are transferred). . XROOTD. New version 20080621-0000 containing several improvements and fixes; Server:. New daemon 'cmsd' supposed to replace 'olbd' with improved performances; Improved polling strategy; Fix problem with handling writev creating unjustified disconnections; Fix problem with setrlimit on MacOsX Leopard. Client:; ; Fix a nasty memory leak in XrdClientCacheRead affecting; processing via TChain; Optimized fileclosing recipe; Fix; potential cache thrashing problem with big blocks requests. Fixes / improvements in the GSI plug-in:; ; support for large (> 32 bits) certificate serial; numbers in CRL handling; support for an external function for DN-to-username; mapping function; provide example for an LDAP based search; fixed a few problem with return code checking. netx. TXNetFile:; . Enable dynamic cache size synchronization; ; Enable per-instance control of the cache parameters; also for RAW files; by; default cache is OFF for these files, but there maybe cases in which the cache can; improve performances.; Remove call to XrdClient::Sync in SysStat. Correctly honor the create/recreate options coming from TFile::Open(); Allow the size of the (written) file to be retrieved after the Close (solves several reported file size mismatches).; . TXNetSystem:; ; Fix problem with GetDirEntry: the entry object was; going out-of-scope so; that the returned string was meaningless.; Reset; the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html:1103,cache,cache,1103,net/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html,3,"['Optimiz', 'cache']","['Optimized', 'cache']"
Performance,"i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_sqrt:. '``llvm.vp.sqrt.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.sqrt.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.sqrt.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.sqrt.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point square root of a vector of floating-point values. Arguments:; """""""""""""""""""". The first operand and the result have the same vector of floating-point type.; The second operand is the vector mask and has the same number of elements as the; result vector type. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.sqrt``' intrinsic performs floating-point square root (:ref:`sqrt <int_sqrt>`) of; the first vector operand on each enabled lane. The result on disabled lanes is; a :ref:`poison value <poisonvalues>`. The operation is performed in the default; floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.sqrt.v4f32(<4 x float> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.sqrt.v4f32(<4 x float> %a); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_fma:. '``llvm.vp.fma.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.fma.v16f32 (<16 x float> <left_op>, <16 x float> <middle_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.fma.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <middle_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:743867,perform,performs,743867,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.fmuladd(<4 x float> %a, <4 x float> %b, <4 x float> %c); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_reduce_add:. '``llvm.vp.reduce.add.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.add.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.add.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``ADD`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.add``' intrinsic performs the integer ``ADD`` reduction; (:ref:`llvm.vector.reduce.add <int_vector_reduce_add>`) of the vector operand; ``val`` on each enabled lane, adding it to the scalar ``start_value``. Disabled; lanes are treated as containing the neutral value ``0`` (i.e. having no effect; on the reduction operation). If the vector length is zero, the result is equal; to ``start_value``. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.add.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:748979,perform,performed,748979,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.fsub.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.fsub.v256f64 (<256 x double> <left_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point subtraction of two vectors of floating-point values. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of floating-point type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.fsub``' intrinsic performs floating-point subtraction (:ref:`fsub <i_fsub>`); of the first and second vector operand on each enabled lane. The result on; disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.fsub.v4f32(<4 x float> %a, <4 x float> %b, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = fsub <4 x float> %a, %b; %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_fmul:. '``llvm.vp.fmul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.fmul.v16f32 (<16 x float> <left_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.fmul.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.fmul.v256f64 (<256 x double> <left_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point multiplication of two ve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:735037,perform,performed,735037,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.and``' intrinsic performs the integer ``AND`` reduction; (:ref:`llvm.vector.reduce.and <int_vector_reduce_and>`) of the vector operand; ``val`` on each enabled lane, performing an '``and``' of that with with the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.and.v4i32(<4 x i32> %masked.a); %also.r = and i32 %reduction, %start. .. _int_vp_reduce_or:. '``llvm.vp.reduce.or.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.or.v4i32(i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:757882,perform,performing,757882,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performing']
Performance,"i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.copysign.nxv4f32 (<vscale x 4 x float> <mag_op>, <vscale x 4 x float> <sign_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.copysign.v256f64 (<256 x double> <mag_op>, <256 x double> <sign_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point copysign of two vectors of floating-point values. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of floating-point type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.copysign``' intrinsic performs floating-point copysign (:ref:`copysign <int_copysign>`); of the first and second vector operand on each enabled lane. The result on; disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.copysign.v4f32(<4 x float> %mag, <4 x float> %sign, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.copysign.v4f32(<4 x float> %mag, <4 x float> %sign); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_minnum:. '``llvm.vp.minnum.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.minnum.v16f32 (<16 x float> <left_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.minnum.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.minnum.v256f64 (<256 x double> <left_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Ov",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:724805,perform,performed,724805,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"i32); declare i64 @llvm.loop.decrement.reg.i64(i64, i64). Overview:; """""""""""""""""". The '``llvm.loop.decrement.reg.*``' intrinsics are used to lower the loop; iteration counter and return an updated value that will be used in the next; loop test check. Arguments:; """""""""""""""""""". Both arguments must have identical integer types. The first operand is the; loop iteration counter. The second operand is the maximum number of elements; processed in an iteration. Semantics:; """""""""""""""""""". The '``llvm.loop.decrement.reg.*``' intrinsics do an integer ``SUB`` of its; two operands, which is not allowed to wrap. They return the remaining number of; iterations still to be executed, and can be used together with a ``PHI``,; ``ICMP`` and ``BR`` to control the number of loop iterations executed. Any; optimisations are allowed to treat it is a ``SUB``, and it is supported by; SCEV, so it's the backends responsibility to handle cases where it may be; optimised. These intrinsics are marked as ``IntrNoDuplicate`` to avoid; optimizers duplicating these instructions. '``llvm.loop.decrement.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare i1 @llvm.loop.decrement.i32(i32); declare i1 @llvm.loop.decrement.i64(i64). Overview:; """""""""""""""""". The HardwareLoops pass allows the loop decrement value to be specified with an; option. It defaults to a loop decrement value of 1, but it can be an unsigned; integer value provided by this option. The '``llvm.loop.decrement.*``'; intrinsics decrement the loop iteration counter with this value, and return a; false predicate if the loop should exit, and true otherwise.; This is emitted if the loop counter is not updated via a ``PHI`` node, which; can also be controlled with an option. Arguments:; """""""""""""""""""". The integer argument is the loop decrement value used to decrement the loop; iteration counter. Semantics:; """""""""""""""""""". The '``llvm.loop.decrement.*``' intrinsics do a ``SUB`` of the loop iterati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:648832,optimiz,optimizers,648832,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizers']
Performance,"i64(ptr %ptr, i64 %stride, <4 x i1> %mask, i32 %evl); declare <vscale x 2 x i16> @llvm.experimental.vp.strided.load.nxv2i16.i64(ptr %ptr, i64 %stride, <vscale x 2 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.experimental.vp.strided.load``' intrinsic loads, into a vector, scalar values from; memory locations evenly spaced apart by '``stride``' number of bytes, starting from '``ptr``'. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is the stride; value expressed in bytes. The third operand is a vector of boolean values; with the same number of elements as the return type. The fourth is the explicit; vector length of the operation. The base pointer underlying type matches the type of the scalar; elements of the return operand. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.experimental.vp.strided.load``' intrinsic loads, into a vector, multiple scalar; values from memory in the same way as the :ref:`llvm.vp.gather <int_vp_gather>` intrinsic,; where the vector of pointers is in the form:. ``%ptrs = <%ptr, %ptr + %stride, %ptr + 2 * %stride, ... >``,. with '``ptr``' previously casted to a pointer '``i8``', '``stride``' always interpreted as a signed; integer and all arithmetic occurring in the pointer type. Examples:; """""""""""""""""". .. code-block:: text. 	 %r = call <8 x i64> @llvm.experimental.vp.strided.load.v8i64.i64(i64* %ptr, i64 %stride, <8 x i64> %mask, i32 %evl); 	 ;; The operation can also be expressed like this:. 	 %addr = bitcast i64* %ptr to i8*; 	 ;; Create a vector of pointers %addrs in the form:; 	 ;; %addrs = <%addr, %addr + %stride, %addr + 2 * %stride, ...>; 	 %ptrs = bitcast <8 x i8* > %addrs to <8 x i64* >; 	 %also.r = call <8 x i64> @llvm.vp.gather.v8i64.v8p0i64(<8 x i64* > %ptrs, <8 x i64> %mask, i32 %evl). .. _int_experimental_vp_strided_store:. '``llvm.experimental.vp.strided.store``' Intrinsic; ^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:788200,load,load,788200,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['load'],"['load', 'loads']"
Performance,"i8 0, ptr %p3; br label %while.cond. while.cond:; ; 3 = MemoryPhi({%0,1},{if.end,2}); br i1 undef, label %if.then, label %if.else. if.then:; br label %if.end. if.else:; br label %if.end. if.end:; ; MemoryUse(1); %1 = load i8, ptr %p1; ; 2 = MemoryDef(3); store i8 2, ptr %p2; ; MemoryUse(1); %2 = load i8, ptr %p3; br label %while.cond; }. Because we removed the stores from ``if.then`` and ``if.else``, a ``MemoryPhi``; for ``if.end`` would be pointless, so we don't place one. So, if you need to; place a ``MemoryDef`` in ``if.then`` or ``if.else``, you'll need to also create; a ``MemoryPhi`` for ``if.end``. If it turns out that this is a large burden, we can just place ``MemoryPhi``\ s; everywhere. Because we have Walkers that are capable of optimizing above said; phis, doing so shouldn't prohibit optimizations. Non-Goals; ---------. ``MemorySSA`` is meant to reason about the relation between memory; operations, and enable quicker querying.; It isn't meant to be the single source of truth for all potential memory-related; optimizations. Specifically, care must be taken when trying to use ``MemorySSA``; to reason about atomic or volatile operations, as in:. .. code-block:: llvm. define i8 @foo(ptr %a) {; entry:; br i1 undef, label %if.then, label %if.end. if.then:; ; 1 = MemoryDef(liveOnEntry); %0 = load volatile i8, ptr %a; br label %if.end. if.end:; %av = phi i8 [0, %entry], [%0, %if.then]; ret i8 %av; }. Going solely by ``MemorySSA``'s analysis, hoisting the ``load`` to ``entry`` may; seem legal. Because it's a volatile load, though, it's not. Design tradeoffs; ----------------. Precision; ^^^^^^^^^. ``MemorySSA`` in LLVM deliberately trades off precision for speed.; Let us think about memory variables as if they were disjoint partitions of the; memory (that is, if you have one variable, as above, it represents the entire; memory, and if you have multiple variables, each one represents some; disjoint portion of the memory). First, because alias analysis results confl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:16032,optimiz,optimizations,16032,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimizations']
Performance,"i8*`` style typed pointers. In opaque pointer mode, all typed pointers used in IR, bitcode, or created; using ``PointerType::get()`` and similar APIs are automatically converted into; opaque pointers. This simplifies migration and allows testing existing IR with; opaque pointers. .. code-block:: llvm. define i8* @test(i8* %p) {; %p2 = getelementptr i8, i8* %p, i64 1; ret i8* %p2; }. ; Is automatically converted into the following if -opaque-pointers; ; is enabled:. define ptr @test(ptr %p) {; %p2 = getelementptr i8, ptr %p, i64 1; ret ptr %p2; }. Migration Instructions; ======================. In order to support opaque pointers, two types of changes tend to be necessary.; The first is the removal of all calls to ``PointerType::getElementType()`` and; ``Type::getPointerElementType()``. In the LLVM middle-end and backend, this is usually accomplished by inspecting; the type of relevant operations instead. For example, memory access related; analyses and optimizations should use the types encoded in the load and store; instructions instead of querying the pointer type. Here are some common ways to avoid pointer element type accesses:. * For loads, use ``getType()``.; * For stores, use ``getValueOperand()->getType()``.; * Use ``getLoadStoreType()`` to handle both of the above in one call.; * For getelementptr instructions, use ``getSourceElementType()``.; * For calls, use ``getFunctionType()``.; * For allocas, use ``getAllocatedType()``.; * For globals, use ``getValueType()``.; * For consistency assertions, use; ``PointerType::isOpaqueOrPointeeTypeEquals()``.; * To create a pointer type in a different address space, use; ``PointerType::getWithSamePointeeType()``.; * To check that two pointers have the same element type, use; ``PointerType::hasSameElementTypeAs()``.; * While it is preferred to write code in a way that accepts both typed and; opaque pointers, ``Type::isOpaquePointerTy()`` and; ``PointerType::isOpaque()`` can be used to handle opaque pointers specially.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst:6636,optimiz,optimizations,6636,interpreter/llvm-project/llvm/docs/OpaquePointers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst,2,"['load', 'optimiz']","['load', 'optimizations']"
Performance,"iables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their defaults is more likely to cause; things to go wrong. They are also unstable across LLVM versions. **LLVM_TOOLS_INSTALL_DIR**:STRING; The path to install the main LLVM tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configuratio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:38794,cache,cache,38794,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['cache'],['cache']
Performance,"ial for RDataFrame helper functions](https://root.cern/doc/master/df020__helpers_8C.html).; - Throw if name of a custom column is not a valid C++ name.; - Allow every RDataFrame variable be cast to a common type `ROOT::RDF::RNode`.; - Speed up just-in-time compilation (and therefore runtime) of Snapshots with a large number of branches.; - Create names for histograms and graphs based on the input columns if no model is provided.; - RCutFlowReport can print cumulative efficiency of cuts.; - Reading and writing of columns holding `vector<bool>` instances and `bool` C arrays.; - Support `rdfentry_` and `rdfslot_` implicit columns (`tdfentry_` and `tdfslot_` kept for backwards compatibility).; - Remove `RDataFrame` from the 32-bit builds.; - Speed up interpreted usage of RDataFrame (i.e. in macros or from ROOT prompt) by removing certain cling runtime safety checks.; - Streamline and better document usage of multi-thread RDataFrame: edge cases in which processing of an event could start; before processing of another event finished have been removed, making it easier for user to write safe parallel RDF operations.; See the [relevant documentation](https://root.cern.ch/doc/master/classROOT_1_1RDataFrame.html#parallel-execution) for more information. ### TTreeProcessorMT; - Parallelise search of cluster boundaries for input datasets with no friends or TEntryLists. The net effect is a faster initialization time in this common case.; - Handle gracefully the presence of chains the files associated to which are corrupted.; - Reduce number of expensive `TChain::LoadTree` calls by spawning nested TBB tasks to ensure clusters of a given file will be most likely processed by the same thread. ### TTree; - TTrees can be forced to only create new baskets at event cluster boundaries.; This simplifies file layout and I/O at the cost of memory. Recommended for; simple file formats such as ntuples but not more complex data types. To; enable, invoke `tree->SetBit(TTree::kOnlyFlushAtCluste",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:9771,multi-thread,multi-thread,9771,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['multi-thread'],['multi-thread']
Performance,"ial stack frame,; not accounting for any dynamic allocation. * ``roots_size()``: The count of roots in the function. To access the stack map, use ``GCFunctionMetadata::roots_begin()`` and; -``end()`` from the :ref:`GCMetadataPrinter <assembly>`:. .. code-block:: c++. for (iterator I = begin(), E = end(); I != E; ++I) {; GCFunctionInfo *FI = *I;; unsigned FrameSize = FI->getFrameSize();; size_t RootCount = FI->roots_size();. for (GCFunctionInfo::roots_iterator RI = FI->roots_begin(),; RE = FI->roots_end();; RI != RE; ++RI) {; int RootNum = RI->Num;; int RootStackOffset = RI->StackOffset;; Constant *RootMetadata = RI->Metadata;; }; }. If the ``llvm.gcroot`` intrinsic is eliminated before code generation by a; custom lowering pass, LLVM will compute an empty stack map. This may be useful; for collector plugins which implement reference counting or a shadow stack. .. _init-roots:. Initializing roots to null; ---------------------------. It is recommended that frontends initialize roots explicitly to avoid; potentially confusing the optimizer. This prevents the GC from visiting; uninitialized pointers, which will almost certainly cause it to crash. As a fallback, LLVM will automatically initialize each root to ``null``; upon entry to the function. Support for this mode in code generation is; largely a legacy detail to keep old collector implementations working. Custom lowering of intrinsics; ------------------------------. For GCs which use barriers or unusual treatment of stack roots, the; implementor is responsibly for providing a custom pass to lower the; intrinsics with the desired semantics. If you have opted in to custom; lowering of a particular intrinsic your pass **must** eliminate all; instances of the corresponding intrinsic in functions which opt in to; your GC. The best example of such a pass is the ShadowStackGC and it's; ShadowStackGCLowering pass. There is currently no way to register such a custom lowering pass; without building a custom copy of LLVM. ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:33706,optimiz,optimizer,33706,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['optimiz'],['optimizer']
Performance,"ialize. Types that don't express ownership may still; be non-trivial to copy because of some sort of address sensitivity;; for example, a relative reference. Distinguishing default; initialization allows types to impose policies about how they are; created. These rules assume that assignment into an l-value is always a; modification of an existing object rather than an initialization.; Assignment is then a compound operation where the old value is; read and destroyed, if necessary, and the new value is put into; place. These are the natural semantics of value propagation, where; all basic operations on the type come down to copies and destroys,; and everything else is just an optimization on top of those. The most glaring weakness of programming with non-trivial types in C; is that there are no language mechanisms (akin to C++'s placement; ``new`` and explicit destructor calls) for explicitly creating and; destroying objects. Clang should consider adding builtins for this; purpose, as well as for common optimizations like destructive; relocation. Application of the formal C rules to nontrivial ownership qualifiers; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Nontrivially ownership-qualified types are considered non-trivial; to copy, destroy, and default-initialize. A dynamic object of nontrivially ownership-qualified type contingently; exists at a location if the memory is filled with a zero pattern, e.g.; by ``calloc`` or ``bzero``. Such an object can be safely accessed in; all of the cases above, but its memory can also be safely repurposed.; Assigning a null pointer into an l-value of ``__weak`` or; ``__strong``-qualified type accesses the dynamic object there (and thus; may have undefined behavior if no such object exists), but afterwards; the object's memory is guaranteed to be filled with a zero pattern; and thus may be either further accessed or repurposed as needed.; The upshot is that programs may safely initialize dynamically-alloc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:59624,optimiz,optimizations,59624,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizations']
Performance,ialized static data members; Unknown. 1204; C++11; Specifiers in a for-range-declaration; Unknown. 1205; dup; Lvalue reference binding and function viability; Unknown. 1206; C++11; Defining opaque enumeration members of class templates; Unknown. 1207; C++11; Type of class member in trailing-return-type; Unknown. 1208; C++11; Explicit noexcept in defaulted definition; Unknown. 1209; open; Is a potentially-evaluated expression in a template definition a use?; Not resolved. 1210; C++11; Injection of elaborated-type-specifier in enumeration scope; Unknown. 1211; drafting; Misaligned lvalues; Not resolved. 1212; C++11; Non-function-call xvalues and decltype; Unknown. 1213; CD3; Array subscripting and xvalues; Clang 7. 1214; C++11; Kinds of initializers; Unknown. 1215; C++11; Definition of POD struct; Unknown. 1216; C++11; Exceptions allowed by a noexcept-specification; Unknown. 1217; NAD; Are deleted functions implicitly noexcept?; Unknown. 1218; C++11; What is the currently-handled exception in a multi-threaded program?; Unknown. 1219; C++11; Non-static data member initializers in constant expressions; Unknown. 1220; C++11; Looking up conversion-type-ids; Unknown. 1221; open; Partial ordering and reference collapsing; Not resolved. 1222; NAD; Unnecessary restriction on auto array types; Unknown. 1223; drafting; Syntactic disambiguation and trailing-return-types; Clang 17. 1224; C++11; constexpr defaulted copy constructors; Unknown. 1225; C++11; constexpr constructors and virtual bases; Unknown. 1226; CD3; Converting a braced-init-list default argument; Unknown. 1227; CD3; Mixing immediate and non-immediate contexts in deduction failure; Clang 3.0. 1228; NAD; Copy-list-initialization and explicit constructors; Unknown. 1229; C++11; Overload resolution with empty braced-init-list argument; Unknown. 1230; dup; Confusing description of ambiguity of destructor name; Unknown. 1231; C++11; Variadic templates requiring an empty pack expansion; Unknown. 1232; C++11; Creati,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:81076,multi-thread,multi-threaded,81076,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,2,['multi-thread'],['multi-threaded']
Performance,"iant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above, consider proposing a piece; of metadata which provides the optimization hint you need. Such extensions are; relatively common and are generally well received by the community. You will; need to ensure that your proposal is sufficiently general so that it benefits; others if you wish to contribute it upstream. You should also consider describing the problem you're facing on `Discourse; <https://discourse.llvm.org>`_ and asking for advice.; It's entirely possible someone has encountered your problem before and can; give good advice. If there are multiple interested parties, that also; increases the chances that a metadata extension would be well received by the; community as a whole. Adding to this document; ===",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:13296,optimiz,optimized,13296,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimized']
Performance,"ias analysis will take advantage of that). In addition,; it is legal to reorder non-atomic and Unordered loads around Monotonic; loads. CSE/DSE and a few other optimizations are allowed, but Monotonic; operations are unlikely to be used in ways which would make those; optimizations useful. Notes for code generation; Code generation is essentially the same as that for unordered for loads and; stores. No fences are required. ``cmpxchg`` and ``atomicrmw`` are required; to appear as a single operation. Acquire; -------. Acquire provides a barrier of the sort necessary to acquire a lock to access; other memory with normal loads and stores. Relevant standard; This corresponds to the C++/C ``memory_order_acquire``. It should also be; used for C++/C ``memory_order_consume``. Notes for frontends; If you are writing a frontend which uses this directly, use with caution.; Acquire only provides a semantic guarantee when paired with a Release; operation. Notes for optimizers; Optimizers not aware of atomics can treat this like a nothrow call. It is; also possible to move stores from before an Acquire load or read-modify-write; operation to after it, and move non-Acquire loads from before an Acquire; operation to after it. Notes for code generation; Architectures with weak memory ordering (essentially everything relevant today; except x86 and SPARC) require some sort of fence to maintain the Acquire; semantics. The precise fences required varies widely by architecture, but for; a simple implementation, most architectures provide a barrier which is strong; enough for everything (``dmb`` on ARM, ``sync`` on PowerPC, etc.). Putting; such a fence after the equivalent Monotonic operation is sufficient to; maintain Acquire semantics for a memory operation. Release; -------. Release is similar to Acquire, but with a barrier of the sort necessary to; release a lock. Relevant standard; This corresponds to the C++/C ``memory_order_release``. Notes for frontends; If you are writing a fronte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:11914,optimiz,optimizers,11914,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['optimiz'],['optimizers']
Performance,"ibed above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue base address in the V#. The; result is a V# with a base address pointing to the beginning of the wavefront; scratch backing memory. The Private Segment Buffer is always requested, but the Private Segment; Wavefront Offset is only requested if it is used (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). .. _amdgpu-amdhsa-memory-model:. Memory Model; ~~~~~~~~~~~~. This section describes the mapping of the LLVM memory model onto AMDGPU machine; code (see :ref:`memmodel`). The AMDGPU backend supports the memory synchronization scopes specified in; :ref:`amdgpu-memory-scopes`. The code sequences used to implement the memory model specify the order of; instructions that a single thread must execute. The ``s_waitcnt`` and cache; management instructions such as ``buffer_wbinvl1_vol`` are defined with respect; to other memory instructions executed by the same thread. This allows them to be; moved earlier or later which can allow them to be combined with other instances; of the same instruction, or hoisted/sunk out of loops to improve performance.; Only the instructions related to the memory model are given; additional; ``s_waitcnt`` instructions are required to ensure registers are defined before; being used. These may be able to be combined with the memory model ``s_waitcnt``; instructions as described above. The AMDGPU backend supports the following memory models:. HSA Memory Model [HSA]_; The HSA memory model uses a single happens-before relation for all address; spaces (see :ref:`amdgpu-address-spaces`).; OpenCL Memory Model [OpenCL]_; The OpenCL memory model which has separate happens-before relations for the; global and local address spaces. Only a fence specifying both global and; local address space, and seq_cst instructions join the relationships. Since; t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:201178,cache,cache,201178,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"ibly binned by adding GenBinned(tagname); to generate(). In that case all component pdfs labeled with pdf->setAttribute(tagname) will be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calcu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6662,perform,performance,6662,roofit/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html,2,['perform'],['performance']
Performance,"ibraries and they can be instantiated using the plugin; manager. Implementations based on Unuran and Foam exist.; The tutorial math/multidimSampling.C is an example on; how to use this class. New class ROOT::Math::GoFTest for goodness of fit; tests of unbinned data; ; The class implements the Kolmogorov-Smirnov and; Anderson-Darling tests for two samples (data vs data ) and; one sample (data vs distribution); For the data vs distribution test, the user can compare using a; predefined distributions (Gaussian, LogNormal or Exponential) or; by passing a user defined PDF or CDF.; Example 1: perform a 2 sample GoF test from two arrays,; sample1[n1] and sample2[n2] containing the data; ; ROOT::Math::GoFTest goftest(n1, sample1, n2, sample2);; double pValueAD = goftest.AndersonDarling2SamplesTest();; double pValueKS = goftest.KolmogorovSmirnov2SamplesTest();; ; The class can return optionally also the test statistics instead of; the p value.; Example 2: perform a 1 sample test with a pre-defined; distribution starting from a data set sample[n]. ROOT::Math::GoFTest goftest(n, sample, ROOT::Math::GoFTest::kGaussian);; double pValueAD = goftest.AndersonDarlingTest();; double pValueKS = goftest.KolmogorovSmirnovTest();; . Example 3: perform a 1 sample test with a user-defined; distribution provided as cdf; ; ROOT::Math::Functor1D cdf_func(&ROOT::Math::landau_cdf);; ROOT::Math::GofTest goftest(n, sample, cdf_func, ROOT::Math::GoFTest::kCDF);; double pValueAD = goftest.AndersonDarlingTest();; . Example 4: perform a 1 sample test with a user-defined; distribution provided as pdf. Note that in this case to avoid; integration problems is sometimes recommended to give some; reasonable xmin and xmax values. xmin (and xmax) should however be; smaller (larger) than the minimum (maximum) data value.; ; ROOT::Math::Functor1D pdf_func(&ROOT::Math::landau_pdf);; double xmin = 5*TMath::Min_Element(n,sample);; double xmax = 5*TMath::Max_Element(n,sample);; ROOT::Math::GofTest goftest(n, sampl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html:1518,perform,perform,1518,math/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html,2,['perform'],['perform']
Performance,"ibrary on disk. A *dynamic linker* applies relocations to executables and dynamic libraries that; have been loaded into memory. A *JIT linker* takes a single relocatable object file at a time and links it; into a target process, usually using a context object to allow the linked code; to resolve symbols in the target. RuntimeDyld; -----------. In order to keep RuntimeDyld's implementation simple MCJIT imposed some; restrictions on compiled code:. #. It had to use the Large code model, and often restricted available relocation; models in order to limit the kinds of relocations that had to be supported. #. It required strong linkage and default visibility on all symbols -- behavior; for other linkages/visibilities was not well defined. #. It constrained and/or prohibited the use of features requiring runtime; support, e.g. static initializers or thread local storage. As a result of these restrictions not all language features supported by LLVM; worked under MCJIT, and objects to be loaded under the JIT had to be compiled to; target it (precluding the use of precompiled code from other sources under the; JIT). RuntimeDyld also provided very limited visibility into the linking process; itself: Clients could access conservative estimates of section size; (RuntimeDyld bundled stub size and padding estimates into the section size; value) and the final relocated bytes, but could not access RuntimeDyld's; internal object representations. Eliminating these restrictions and limitations was one of the primary motivations; for the development of JITLink. The llvm-jitlink tool; =====================. The ``llvm-jitlink`` tool is a command line wrapper for the JITLink library.; It loads some set of relocatable object files and then links them using; JITLink. Depending on the options used it will then execute them, or validate; the linked memory. The ``llvm-jitlink`` tool was originally designed to aid JITLink development by; providing a simple environment for testing. Basic usage; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:36362,load,loaded,36362,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['load'],['loaded']
Performance,"ibute of the debugger information; entry corresponding to the current subprogram as described in; :ref:`amdgpu-dwarf-low-level-information`. The location description L is updated as if the ``DW_OP_LLVM_offset_uconst; B`` operation was applied. The updated L is pushed on the stack. 7. ``DW_OP_breg0``, ``DW_OP_breg1``, ..., ``DW_OP_breg31``. The ``DW_OP_breg<N>`` operations encode the numbers of up to 32 registers,; numbered from 0 through 31, inclusive. The register number R corresponds to; the N in the operation name. They have a single signed LEB128 integer operand that represents a byte; displacement B. The address space identifier AS is defined as the one corresponding to the; target architecture specific default address space. The address size S is defined as the address bit size of the target; architecture specific address space corresponding to AS. The contents of the register specified by R are retrieved as if a; ``DW_OP_regval_type R, DR`` operation was performed where DR is the offset; of a hypothetical debug information entry in the current compilation unit; for an unsigned integral base type of size S bits. B is added and the least; significant S bits are treated as an unsigned value to be used as an address; A. They push a location description L comprising one memory location; description LS on the stack. LS specifies the memory location storage that; corresponds to AS with a bit offset equal to A scaled by 8 (the byte size). 8. ``DW_OP_bregx``. ``DW_OP_bregx`` has two operands. The first is an unsigned LEB128 integer; that represents a register number R. The second is a signed LEB128; integer that represents a byte displacement B. The action is the same as for ``DW_OP_breg<N>``, except that R is used as; the register number and B is used as the byte displacement. 9. ``DW_OP_LLVM_aspace_bregx`` *New*. ``DW_OP_LLVM_aspace_bregx`` has two operands. The first is an unsigned; LEB128 integer that represents a register number R. The second is a signed; LEB128 i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:115927,perform,performed,115927,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['performed']
Performance,"ibute__((matrix_type(5, 5)));. fx5x5 f1(ix5x5 i, fx5x5 f) {; return (fx5x5) i;; }. template <typename X>; using matrix_4_4 = X __attribute__((matrix_type(4, 4)));. void f2() {; matrix_5_5<double> d;; matrix_5_5<int> i;; i = (matrix_5_5<int>)d;; i = static_cast<matrix_5_5<int>>(d);; }. Half-Precision Floating Point; =============================. Clang supports three half-precision (16-bit) floating point types:; ``__fp16``, ``_Float16`` and ``__bf16``. These types are supported; in all language modes, but their support differs between targets.; A target is said to have ""native support"" for a type if the target; processor offers instructions for directly performing basic arithmetic; on that type. In the absence of native support, a type can still be; supported if the compiler can emulate arithmetic on the type by promoting; to ``float``; see below for more information on this emulation. * ``__fp16`` is supported on all targets. The special semantics of this; type mean that no arithmetic is ever performed directly on ``__fp16`` values;; see below. * ``_Float16`` is supported on the following targets:. * 32-bit ARM (natively on some architecture versions); * 64-bit ARM (AArch64) (natively on ARMv8.2a and above); * AMDGPU (natively); * SPIR (natively); * X86 (if SSE2 is available; natively if AVX512-FP16 is also available); * RISC-V (natively if Zfh or Zhinx is available). * ``__bf16`` is supported on the following targets (currently never natively):. * 32-bit ARM; * 64-bit ARM (AArch64); * RISC-V; * X86 (when SSE2 is available). (For X86, SSE2 is available on 64-bit and all recent 32-bit processors.). ``__fp16`` and ``_Float16`` both use the binary16 format from IEEE; 754-2008, which provides a 5-bit exponent and an 11-bit significand; (counting the implicit leading 1). ``__bf16`` uses the `bfloat16; <https://en.wikipedia.org/wiki/Bfloat16_floating-point_format>`_ format,; which provides an 8-bit exponent and an 8-bit significand; this is the same; exponent range as `fl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:30572,perform,performed,30572,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['perform'],['performed']
Performance,"ic 13 ``word64`` B + A; ``R_AMDGPU_REL16`` Static 14 ``word16`` ((S + A - P) - 4) / 4; ========================== ======= ===== ========== ==============================. ``R_AMDGPU_ABS32_LO`` and ``R_AMDGPU_ABS32_HI`` are only supported by; the ``mesa3d`` OS, which does not support ``R_AMDGPU_ABS64``. There is no current OS loader support for 32-bit programs and so; ``R_AMDGPU_ABS32`` is not used. .. _amdgpu-loaded-code-object-path-uniform-resource-identifier:. Loaded Code Object Path Uniform Resource Identifier (URI); ---------------------------------------------------------. The AMD GPU code object loader represents the path of the ELF shared object from; which the code object was loaded as a textual Uniform Resource Identifier (URI).; Note that the code object is the in memory loaded relocated form of the ELF; shared object. Multiple code objects may be loaded at different memory; addresses in the same process from the same ELF shared object. The loaded code object path URI syntax is defined by the following BNF syntax:. .. code::. code_object_uri ::== file_uri | memory_uri; file_uri ::== ""file://"" file_path [ range_specifier ]; memory_uri ::== ""memory://"" process_id range_specifier; range_specifier ::== [ ""#"" | ""?"" ] ""offset="" number ""&"" ""size="" number; file_path ::== URI_ENCODED_OS_FILE_PATH; process_id ::== DECIMAL_NUMBER; number ::== HEX_NUMBER | DECIMAL_NUMBER | OCTAL_NUMBER. **number**; Is a C integral literal where hexadecimal values are prefixed by ""0x"" or ""0X"",; and octal values by ""0"". **file_path**; Is the file's path specified as a URI encoded UTF-8 string. In URI encoding,; every character that is not in the regular expression ``[a-zA-Z0-9/_.~-]`` is; encoded as two uppercase hexadecimal digits proceeded by ""%"". Directories in; the path are separated by ""/"". **offset**; Is a 0-based byte offset to the start of the code object. For a file URI, it; is from the start of the file specified by the ``file_path``, and if omitted; defaults to 0. For a memor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:83212,load,loaded,83212,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loaded']
Performance,"ic calls). The above generates::. define <4 x i32> @f(<4 x i32> %p) {; %vset_lane = insertelement <4 x i32> %p, i32 42, i32 0; ret <4 x i32> %vset_lane; }. Which then becomes the following trivial assembly::. f: // @f; movz	w8, #0x2a; ins 	v0.s[0], w8; ret. Problem; =======. The main problem is how vectors are represented in memory and in registers. First, a recap. The ""endianness"" of an item affects its representation in memory only. In a register, a number is just a sequence of bits - 64 bits in the case of AArch64 general purpose registers. Memory, however, is a sequence of addressable units of 8 bits in size. Any number greater than 8 bits must therefore be split up into 8-bit chunks, and endianness describes the order in which these chunks are laid out in memory. A ""little endian"" layout has the least significant byte first (lowest in memory address). A ""big endian"" layout has the *most* significant byte first. This means that when loading an item from big endian memory, the lowest 8-bits in memory must go in the most significant 8-bits, and so forth. ``LDR`` and ``LD1``; ===================. .. figure:: ARM-BE-ldr.png; :align: right. Big endian vector load using ``LDR``. A vector is a consecutive sequence of items that are operated on simultaneously. To load a 64-bit vector, 64 bits need to be read from memory. In little endian mode, we can do this by just performing a 64-bit load - ``LDR q0, [foo]``. However if we try this in big endian mode, because of the byte swapping the lane indices end up being swapped! The zero'th item as laid out in memory becomes the n'th lane in the vector. .. figure:: ARM-BE-ld1.png; :align: right. Big endian vector load using ``LD1``. Note that the lanes retain the correct ordering. Because of this, the instruction ``LD1`` performs a vector load but performs byte swapping not on the entire 64 bits, but on the individual items within the vector. This means that the register content is the same as it would have been on a little endia",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:2458,load,loading,2458,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['load'],['loading']
Performance,"ic information in the IR. Why do struct member indices always use ``i32``?; ------------------------------------------------. The specific type i32 is probably just a historical artifact, however it's wide; enough for all practical purposes, so there's been no need to change it. It; doesn't necessarily imply i32 address arithmetic; it's just an identifier which; identifies a field in a struct. Requiring that all struct indices be the same; reduces the range of possibilities for cases where two GEPs are effectively the; same but have distinct operand types. What's an uglygep?; ------------------. Some LLVM optimizers operate on GEPs by internally lowering them into more; primitive integer expressions, which allows them to be combined with other; integer expressions and/or split into multiple separate integer expressions. If; they've made non-trivial changes, translating back into LLVM IR can involve; reverse-engineering the structure of the addressing in order to fit it into the; static type of the original first operand. It isn't always possibly to fully; reconstruct this structure; sometimes the underlying addressing doesn't; correspond with the static type at all. In such cases the optimizer instead will; emit a GEP with the base pointer casted to a simple address-unit pointer, using; the name ""uglygep"". This isn't pretty, but it's just as valid, and it's; sufficient to preserve the pointer aliasing guarantees that GEP provides. Summary; =======. In summary, here's some things to always remember about the GetElementPtr; instruction:. #. The GEP instruction never accesses memory, it only provides pointer; computations. #. The second operand to the GEP instruction is always a pointer and it must be; indexed. #. There are no superfluous indices for the GEP instruction. #. Trailing zero indices are superfluous for pointer aliasing, but not for the; types of the pointers. #. Leading zero indices are not superfluous for pointer aliasing nor the types; of the pointers.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:21067,optimiz,optimizer,21067,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['optimiz'],['optimizer']
Performance,"ic line. This option controls whether Clang prints the profile hotness associated; with diagnostics in the presence of profile-guided optimization information.; This is currently supported with optimization remarks (see; :ref:`Options to Emit Optimization Reports <rpass>`). The hotness information; allows users to focus on the hot optimization remarks that are likely to be; more relevant for run-time performance. For example, in this output, the block containing the callsite of `foo` was; executed 3000 times according to the profile data:. ::. s.c:7:10: remark: foo inlined into bar (hotness: 3000) [-Rpass-analysis=inline]; sum += foo(x, x - 2);; ^. This option is implied when; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>` is used.; Otherwise, it defaults to off. .. option:: -fdiagnostics-hotness-threshold. Prevent optimization remarks from being output if they do not have at least; this hotness value. This option, which defaults to zero, controls the minimum hotness an; optimization remark would need in order to be output by Clang. This is; currently supported with optimization remarks (see :ref:`Options to Emit; Optimization Reports <rpass>`) when profile hotness information in; diagnostics is enabled (see; :ref:`-fdiagnostics-show-hotness <opt_fdiagnostics-show-hotness>`). .. _opt_fdiagnostics-fixit-info:. .. option:: -f[no-]diagnostics-fixit-info. Enable ""FixIt"" information in the diagnostics output. This option, which defaults to on, controls whether or not Clang; prints the information on how to fix a specific diagnostic; underneath it when it knows. For example, in this output:. ::. test.c:28:8: warning: extra tokens at end of #endif directive [-Wextra-tokens]; #endif bad; ^; //. Passing **-fno-diagnostics-fixit-info** will prevent Clang from; printing the ""//"" line at the end of the message. This information; is useful for users who may not understand what is wrong, but can be; confusing for machine parsing. .. _opt_fdiagnostics-print-sourc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:14863,optimiz,optimization,14863,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance,"ic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic sc1=1; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load sc0=1; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_inv. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:295953,load,load,295953,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"ic relocations for function pointers in VTables can be replaced with; static relocations for offsets between the VTable and virtual functions which; may not be ``dso_local``. This is currently only supported for ELF binary formats. .. _no_cfi:. No CFI; ------. ``no_cfi @func``. With `Control-Flow Integrity (CFI); <https://clang.llvm.org/docs/ControlFlowIntegrity.html>`_, a '``no_cfi``'; constant represents a function reference that does not get replaced with a; reference to the CFI jump table in the ``LowerTypeTests`` pass. These constants; may be useful in low-level programs, such as operating system kernels, which; need to refer to the actual function body. .. _constantexprs:. Constant Expressions; --------------------. Constant expressions are used to allow expressions involving other; constants to be used as constants. Constant expressions may be of any; :ref:`first class <t_firstclass>` type and may involve any LLVM operation; that does not have side effects (e.g. load and call are not supported).; The following is the syntax for constant expressions:. ``trunc (CST to TYPE)``; Perform the :ref:`trunc operation <i_trunc>` on constants.; ``ptrtoint (CST to TYPE)``; Perform the :ref:`ptrtoint operation <i_ptrtoint>` on constants.; ``inttoptr (CST to TYPE)``; Perform the :ref:`inttoptr operation <i_inttoptr>` on constants.; This one is *really* dangerous!; ``bitcast (CST to TYPE)``; Convert a constant, CST, to another TYPE.; The constraints of the operands are the same as those for the; :ref:`bitcast instruction <i_bitcast>`.; ``addrspacecast (CST to TYPE)``; Convert a constant pointer or constant vector of pointer, CST, to another; TYPE in a different address space. The constraints of the operands are the; same as those for the :ref:`addrspacecast instruction <i_addrspacecast>`.; ``getelementptr (TY, CSTPTR, IDX0, IDX1, ...)``, ``getelementptr inbounds (TY, CSTPTR, IDX0, IDX1, ...)``; Perform the :ref:`getelementptr operation <i_getelementptr>` on; constants. As w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:203447,load,load,203447,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"ic. ::. declare <4 x i1> @llvm.get.active.lane.mask.v4i1.i32(i32 %base, i32 %n); declare <8 x i1> @llvm.get.active.lane.mask.v8i1.i64(i64 %base, i64 %n); declare <16 x i1> @llvm.get.active.lane.mask.v16i1.i64(i64 %base, i64 %n); declare <vscale x 16 x i1> @llvm.get.active.lane.mask.nxv16i1.i64(i64 %base, i64 %n). Overview:; """""""""""""""""". Create a mask representing active and inactive vector lanes. Arguments:; """""""""""""""""""". Both operands have the same scalar integer type. The result is a vector with; the i1 element type. Semantics:; """""""""""""""""""". The '``llvm.get.active.lane.mask.*``' intrinsics are semantically equivalent; to:. ::. %m[i] = icmp ult (%base + i), %n. where ``%m`` is a vector (mask) of active/inactive lanes with its elements; indexed by ``i``, and ``%base``, ``%n`` are the two arguments to; ``llvm.get.active.lane.mask.*``, ``%icmp`` is an integer compare and ``ult``; the unsigned less-than comparison operator. Overflow cannot occur in; ``(%base + i)`` and its comparison against ``%n`` as it is performed in integer; numbers and not in machine numbers. If ``%n`` is ``0``, then the result is a; poison value. The above is equivalent to:. ::. %m = @llvm.get.active.lane.mask(%base, %n). This can, for example, be emitted by the loop vectorizer in which case; ``%base`` is the first element of the vector induction variable (VIV) and; ``%n`` is the loop tripcount. Thus, these intrinsics perform an element-wise; less than comparison of VIV with the loop tripcount, producing a mask of; true/false values representing active/inactive vector lanes, except if the VIV; overflows in which case they return false in the lanes where the VIV overflows.; The arguments are scalar types to accommodate scalable vector types, for which; it is unknown what the type of the step vector needs to be that enumerate its; lanes without overflow. This mask ``%m`` can e.g. be used in masked load/store instructions. These; intrinsics provide a hint to the backend. I.e., for a vector loop, the; back",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:777916,perform,performed,777916,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"ic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:359960,perform,performing,359960,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"ic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_gl*_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the caches. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; conside",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:373451,load,loads,373451,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"ic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; comple",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:223140,load,load,223140,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"ic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 3. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc1=1; store atomic release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; sc0=1 sc1=1; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:309379,load,load,309379,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"icate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return addr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36889,optimiz,optimizations,36889,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['optimiz'],['optimizations']
Performance,"ication does not alter the storage requirements for objects,; except that it is undefined behavior if a ``__weak`` object is inadequately; aligned for an object of type ``id``. The other qualifiers may be used on; explicitly under-aligned memory. The runtime tracks ``__weak`` objects which holds non-null values. It is; undefined behavior to direct modify a ``__weak`` object which is being tracked; by the runtime except through an; :ref:`objc_storeWeak <arc.runtime.objc_storeWeak>`,; :ref:`objc_destroyWeak <arc.runtime.objc_destroyWeak>`, or; :ref:`objc_moveWeak <arc.runtime.objc_moveWeak>` call. The runtime must provide a number of new entrypoints which the compiler may; emit, which are described in the remainder of this section. .. admonition:: Rationale. Several of these functions are semantically equivalent to a message send; we; emit calls to C functions instead because:. * the machine code to do so is significantly smaller,; * it is much easier to recognize the C functions in the ARC optimizer, and; * a sufficient sophisticated runtime may be able to avoid the message send in; common cases. Several other of these functions are ""fused"" operations which can be; described entirely in terms of other operations. We use the fused operations; primarily as a code-size optimization, although in some cases there is also a; real potential for avoiding redundant operations in the runtime. .. _arc.runtime.objc_autorelease:. ``id objc_autorelease(id value);``; ----------------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it adds the object; to the innermost autorelease pool exactly as if the object had been sent the; ``autorelease`` message. Always returns ``value``. .. _arc.runtime.objc_autoreleasePoolPop:. ``void objc_autoreleasePoolPop(void *pool);``; ---------------------------------------------. *Precondition:* ``pool`` is the result of a previous call to; :ref:`objc_autore",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:106541,optimiz,optimizer,106541,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizer']
Performance,"ication, and the second element; of which is a bit specifying if the signed multiplication resulted in an; overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.smul.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. '``llvm.umul.with.overflow.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.umul.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.umul.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.umul.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.umul.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.umul.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """""""""""""""""". The '``llvm.umul.with.overflow``' family of intrinsic functions perform; a unsigned multiplication of the two arguments, and indicate whether an; overflow occurred during the unsigned multiplication. Arguments:; """""""""""""""""""". The arguments (%a and %b) and the first element of the result structure; may be of integer types of any bit width, but they must have the same; bit width. The second element of the result structure must be of type; ``i1``. ``%a`` and ``%b`` are the two values that will undergo unsigned; multiplication. Semantics:; """""""""""""""""""". The '``llvm.umul.with.overflow``' family of intrinsic functions perform; an unsigned multiplication of the two arguments. They return a structure ---; the first element of which is the multiplication, and the second; element of which is a bit specifying if the unsigned multiplication; resulted in an overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.umul.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. Saturation A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:609531,perform,perform,609531,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"icense (see LICENSE.TXT in; the topmost) directory, it has no external dependencies, and it works on; all platforms that I tested:; - Linux; - Windows (probably >= 2000); - MacOS; - Solaris; Adding other platforms is trivial. = Internal Design. TextInput.h contains the main interface. The reading can be extended by; adding classes that derive from Reader; the displaying can be extended; by deriving from Display. There can be multiple readers and multiple displays. All displays are; equal, all readers are equal. All displays show the input of all; readers. The terminal / console implementations for readers and; displays are provided. Both readers and displays only attach while; textinput is acively reading input. As soon as the input is done (enter; was pressed), they detach from the terminal, allowing the application; to take control of the terminal, and even to crash without leaving the; terminal in a non-default state. The editor provides basic emacs-like keybinding, as known from e.g.; bash. It supports ^O, ^R (for now without regex), and most word-centric; editing commands. See KeyBinding for details. KeyBinding maps the InputData read from the Reader to Editor::Commands.; The Editor performs the requested editing actions, and the Displays; are informed about the changes. TextInput gives access to the read; state (""are we done?"") and the input. = Why no [N]Curses?. Because of platform independence (well, one could still have a; TerminalDisplayCurses) and because nowadays this is actually rarely; needed. Sure, it's the ""right"" way of interfacing terminals. But the; number of terminal types in the wild has siginifantly decreased, so; just hard-coding escape sequences became a viable alternative. = References. These pages helped when writing libtextinput:; http://tldp.org/LDP/lpg/node129.html; http://rtfm.etla.org/xterm/ctlseq.html; http://frexx.de/xterm-256-notes; Thanks a lot to the authors for creating these useful pages!. Axel Naumann <axel@cern.ch>, May 2011; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/textinput/src/textinput/doc/textinput.txt:1408,perform,performs,1408,core/textinput/src/textinput/doc/textinput.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/textinput/src/textinput/doc/textinput.txt,1,['perform'],['performs']
Performance,"ices you make (is this a debug build?). - settings detected from your system (where are libraries installed?). - project structure (which files are part of 'clang'?). First, create a directory to build in. Usually, this is; llvm-project/build. .. code:: console. $ mkdir llvm-project/build; $ cd llvm-project/build. Now, run CMake:. .. code:: console. $ cmake -G Ninja ../llvm -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=clang. If all goes well, you'll see a lot of ""performing test"" lines, and; finally:. .. code:: console. Configuring done; Generating done; Build files have been written to: /path/llvm-project/build. And you should see a build.ninja file. Let's break down that last command a little:. - **-G Ninja**: we're going to use ninja to build; please create; build.ninja. - **../llvm**: this is the path to the source of the ""main"" LLVM; project. - The two **-D** flags set CMake variables, which override; CMake/project defaults:. - **CMAKE_BUILD_TYPE=Release**: build in optimized mode, which is; (surprisingly) the fastest option. If you want to run under a debugger, you should use the default Debug; (which is totally unoptimized, and will lead to >10x slower test; runs) or RelWithDebInfo which is a halfway point.; **CMAKE_BUILD_TYPE** affects code generation only, assertions are; on by default regardless! **LLVM_ENABLE_ASSERTIONS=Off** disables; them. - **LLVM_ENABLE_PROJECTS=clang**: this lists the LLVM subprojects; you are interested in building, in addition to LLVM itself. Multiple; projects can be listed, separated by semicolons, such as ""clang;; lldb"".In this example, we'll be making a change to Clang, so we; should build it. Finally, create a symlink (or a copy) of; llvm-project/build/compile-commands.json into llvm-project/:. .. code:: console. $ ln -s build/compile_commands.json ../. (This isn't strictly necessary for building and testing, but allows; tools like clang-tidy, clang-query, and clangd to work in your source; tree). Build and test; --------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst:3469,optimiz,optimized,3469,interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MyFirstTypoFix.rst,1,['optimiz'],['optimized']
Performance,"ich does multiple memory operations, like; ``LDRD`` on ARM without LPAE, or not naturally-aligned ``LDRD`` on LPAE ARM). Monotonic; ---------. Monotonic is the weakest level of atomicity that can be used in synchronization; primitives, although it does not provide any general synchronization. It; essentially guarantees that if you take all the operations affecting a specific; address, a consistent ordering exists. Relevant standard; This corresponds to the C++/C ``memory_order_relaxed``; see those; standards for the exact definition. Notes for frontends; If you are writing a frontend which uses this directly, use with caution. The; guarantees in terms of synchronization are very weak, so make sure these are; only used in a pattern which you know is correct. Generally, these would; either be used for atomic operations which do not protect other memory (like; an atomic counter), or along with a ``fence``. Notes for optimizers; In terms of the optimizer, this can be treated as a read+write on the relevant; memory location (and alias analysis will take advantage of that). In addition,; it is legal to reorder non-atomic and Unordered loads around Monotonic; loads. CSE/DSE and a few other optimizations are allowed, but Monotonic; operations are unlikely to be used in ways which would make those; optimizations useful. Notes for code generation; Code generation is essentially the same as that for unordered for loads and; stores. No fences are required. ``cmpxchg`` and ``atomicrmw`` are required; to appear as a single operation. Acquire; -------. Acquire provides a barrier of the sort necessary to acquire a lock to access; other memory with normal loads and stores. Relevant standard; This corresponds to the C++/C ``memory_order_acquire``. It should also be; used for C++/C ``memory_order_consume``. Notes for frontends; If you are writing a frontend which uses this directly, use with caution.; Acquire only provides a semantic guarantee when paired with a Release; operation. No",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:10833,optimiz,optimizers,10833,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,['optimiz'],"['optimizer', 'optimizers']"
Performance,"ich may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:209670,cache,caches,209670,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"icial testers list is in the file ``RELEASE_TESTERS.TXT``, in the ``LLVM``; repository. Community Testing; -----------------. Once all testing has been completed and appropriate bugs filed, the release; candidate tarballs are put on the website and the LLVM community is notified. We ask that all LLVM developers test the release in any the following ways:. #. Download ``llvm-X.Y``, ``llvm-test-X.Y``, and the appropriate ``clang``; binary. Build LLVM. Run ``make check`` and the full LLVM test suite (``make; TEST=nightly report``). #. Download ``llvm-X.Y``, ``llvm-test-X.Y``, and the ``clang`` sources. Compile; everything. Run ``make check`` and the full LLVM test suite (``make; TEST=nightly report``). #. Download ``llvm-X.Y``, ``llvm-test-X.Y``, and the appropriate ``clang``; binary. Build whole programs with it (ex. Chromium, Firefox, Apache) for; your platform. #. Download ``llvm-X.Y``, ``llvm-test-X.Y``, and the appropriate ``clang``; binary. Build *your* programs with it and check for conformance and; performance regressions. #. Run the :doc:`release process <ReleaseProcess>`, if your platform is; *different* than that which is officially supported, and report back errors; only if they were not reported by the official release tester for that; architecture. We also ask that the OS distribution release managers test their packages with; the first candidate of every release, and report any *new* errors in GitHub.; If the bug can be reproduced with an unpatched upstream version of the release; candidate (as opposed to the distribution's own build), the priority should be; release blocker. During the first round of testing, all regressions must be fixed before the; second release candidate is tagged. In the subsequent stages, the testing is only to ensure that bug; fixes previously merged in have not created new major problems. *This is not; the time to solve additional and unrelated bugs!* If no patches are merged in,; the release is determined to be ready and the re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst:8862,perform,performance,8862,interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToReleaseLLVM.rst,1,['perform'],['performance']
Performance,"icrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:261339,perform,performing,261339,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"icrmw.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; at",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:267765,load,load,267765,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"icroprocessors are ""universal IR's"", allowing many source languages to; be mapped to them). By providing type information, LLVM can be used as; the target of optimizations: for example, through pointer analysis, it; can be proven that a C automatic variable is never accessed outside of; the current function, allowing it to be promoted to a simple SSA value; instead of a memory location. .. _wellformed:. Well-Formedness; ---------------. It is important to note that this document describes 'well formed' LLVM; assembly language. There is a difference between what the parser accepts; and what is considered 'well formed'. For example, the following; instruction is syntactically okay, but not well formed:. .. code-block:: llvm. %x = add i32 1, %x. because the definition of ``%x`` does not dominate all of its uses. The; LLVM infrastructure provides a verification pass that may be used to; verify that an LLVM module is well formed. This pass is automatically; run by the parser after parsing input assembly and by the optimizer; before it outputs bitcode. The violations pointed out by the verifier; pass indicate bugs in transformation passes or input to the parser. .. _identifiers:. Identifiers; ===========. LLVM identifiers come in two basic types: global and local. Global; identifiers (functions, global variables) begin with the ``'@'``; character. Local identifiers (register names, types) begin with the; ``'%'`` character. Additionally, there are three different formats for; identifiers, for different purposes:. #. Named values are represented as a string of characters with their; prefix. For example, ``%foo``, ``@DivisionByZero``,; ``%a.really.long.identifier``. The actual regular expression used is; '``[%@][-a-zA-Z$._][-a-zA-Z$._0-9]*``'. Identifiers that require other; characters in their names can be surrounded with quotes. Special; characters may be escaped using ``""\xx""`` where ``xx`` is the ASCII; code for the character in hexadecimal. In this way, any character ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:2427,optimiz,optimizer,2427,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance,"ics as having LLVM's default behavior. Each of these intrinsics corresponds to a normal floating-point operation. The; data arguments and the return value are the same as the corresponding FP; operation. The rounding mode argument is a metadata string specifying what; assumptions, if any, the optimizer can make when transforming constant; values. Some constrained FP intrinsics omit this argument. If required; by the intrinsic, this argument must be one of the following strings:. ::. ""round.dynamic""; ""round.tonearest""; ""round.downward""; ""round.upward""; ""round.towardzero""; ""round.tonearestaway"". If this argument is ""round.dynamic"" optimization passes must assume that the; rounding mode is unknown and may change at runtime. No transformations that; depend on rounding mode may be performed in this case. The other possible values for the rounding mode argument correspond to the; similarly named IEEE rounding modes. If the argument is any of these values; optimization passes may perform transformations as long as they are consistent; with the specified rounding mode. For example, 'x-0'->'x' is not a valid transformation if the rounding mode is; ""round.downward"" or ""round.dynamic"" because if the value of 'x' is +0 then; 'x-0' should evaluate to '-0' when rounding downward. However, this; transformation is legal for all other rounding modes. For values other than ""round.dynamic"" optimization passes may assume that the; actual runtime rounding mode (as defined in a target-specific manner) matches; the specified rounding mode, but this is not guaranteed. Using a specific; non-dynamic rounding mode which does not match the actual rounding mode at; runtime results in undefined behavior. The exception behavior argument is a metadata string describing the floating; point exception semantics that required for the intrinsic. This argument; must be one of the following strings:. ::. ""fpexcept.ignore""; ""fpexcept.maytrap""; ""fpexcept.strict"". If this argument is ""fpexcept.ignore"" optim",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:869043,optimiz,optimization,869043,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,"icular:. - `TStyle::SetLabelFont`. - `TStyle::SetLineStyleString`: set the format of dashed lines. - `TStyle::SetOptStat`. - `TStyle::SetPalette` to change the colors palette. - `TStyle::SetTitleOffset`. - `TStyle::SetOptDate(Int_t optdate)` to support several date formats.; If `optdate` is non-null, the current date/time will be printed in; the canvas. The position of the date string can be controlled by:; `optdate = 10*format `+` mode`. - `mode = 1` the date is printed in the bottom/left corner. - `mode = 2` date is printed in the bottom/right corner. - `mode = 3` date is printed in the top/right corner. - `format = 0` (default) date format is like: ""Wed Sep 25 17:10:35; 2002"". - `format = 1` date format is: ""2002-09-25"". - `format = 2` date format is: ""2002-09-25 17:10:35"". ## 3D Viewers. ROOT provides several viewers capable of displaying 3D content:. - the Pad - simple line drawing using **`TPad`** and associated; projection class **`TView`**;. - GL Viewer - high quality and performance viewer(See ""The GL; Viewer"");. - X3D viewer - simple legacy viewer (See ""The X3D Viewer"");. - GL-in-pad - combination of basic GL viewer in **`TPad`**, with no; hardware acceleration. The X3D and GL viewers are created as external windows, associated with; a pad, and displaying the same content as it. Only these external; viewers are detailed here - for Pad (**`TPad`**, **`TView`** classes); you should refer to ""Graphical Containers: Canvas and Pad"" and the class; definitions. All viewers use a common architecture to publish 3D objects to the; viewer - described in ""Common 3D Viewer Architecture"" below. In most; cases, you will **not** need to use this, working instead with a; package, such as the ""The Geometry Package"", which provides; comprehensive, high level functionality to create and place objects into; complex 3D scenes, and uses the viewer architecture internally to show; the result in your chosen viewer. ### Invoking a 3D viewer. A 3D viewer can be created in a script b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:105258,perform,performance,105258,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['perform'],['performance']
Performance,"id *pa1 = __builtin_function_start((void(A::*)(int)) &A::a);; void *pa2 = __builtin_function_start((void(A::*)()) &A::a);. **Description**:. The ``__builtin_function_start`` builtin accepts an argument that can be; constant-evaluated to a function, and returns the address of the function; body. This builtin is not supported on all targets. The returned pointer may differ from the normally taken function address; and is not safe to call. For example, with ``-fsanitize=cfi``, taking a; function address produces a callable pointer to a CFI jump table, while; ``__builtin_function_start`` returns an address that fails; :doc:`cfi-icall<ControlFlowIntegrity>` checks. ``__builtin_operator_new`` and ``__builtin_operator_delete``; ------------------------------------------------------------. A call to ``__builtin_operator_new(args)`` is exactly the same as a call to; ``::operator new(args)``, except that it allows certain optimizations; that the C++ standard does not permit for a direct function call to; ``::operator new`` (in particular, removing ``new`` / ``delete`` pairs and; merging allocations), and that the call is required to resolve to a; `replaceable global allocation function; <https://en.cppreference.com/w/cpp/memory/new/operator_new>`_. Likewise, ``__builtin_operator_delete`` is exactly the same as a call to; ``::operator delete(args)``, except that it permits optimizations; and that the call is required to resolve to a; `replaceable global deallocation function; <https://en.cppreference.com/w/cpp/memory/new/operator_delete>`_. These builtins are intended for use in the implementation of ``std::allocator``; and other similar allocation libraries, and are only available in C++. Query for this feature with ``__has_builtin(__builtin_operator_new)`` or; ``__has_builtin(__builtin_operator_delete)``:. * If the value is at least ``201802L``, the builtins behave as described above. * If the value is non-zero, the builtins may not support calling arbitrary; replaceable glo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:119200,optimiz,optimizations,119200,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizations']
Performance,"id) {; int x[8] __attribute__((aligned(128)));; memset (x, 0, sizeof (x));; bar (x);; }. //===----------------------------------------------------------------------===//. Altivec: Codegen'ing MUL with vector FMADD should add -0.0, not 0.0:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=8763. When -ffast-math is on, we can use 0.0. //===----------------------------------------------------------------------===//. Consider this:; v4f32 Vector;; v4f32 Vector2 = { Vector.X, Vector.X, Vector.X, Vector.X };. Since we know that ""Vector"" is 16-byte aligned and we know the element offset ; of "".X"", we should change the load into a lve*x instruction, instead of doing; a load/store/lve*x sequence. //===----------------------------------------------------------------------===//. Implement passing vectors by value into calls and receiving them as arguments. //===----------------------------------------------------------------------===//. GCC apparently tries to codegen { C1, C2, Variable, C3 } as a constant pool load; of C1/C2/C3, then a load and vperm of Variable. //===----------------------------------------------------------------------===//. We need a way to teach tblgen that some operands of an intrinsic are required to; be constants. The verifier should enforce this constraint. //===----------------------------------------------------------------------===//. We currently codegen SCALAR_TO_VECTOR as a store of the scalar to a 16-byte; aligned stack slot, followed by a load/vperm. We should probably just store it; to a scalar stack slot, then use lvsl/vperm to load it. If the value is already; in memory this is a big win. //===----------------------------------------------------------------------===//. extract_vector_elt of an arbitrary constant vector can be done with the ; following instructions:. vTemp = vec_splat(v0,2); // 2 is the element the src is in.; vec_ste(&destloc,0,vTemp);. We can do an arbitrary non-constant value by using lvsr/perm/ste. //===---------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt:1520,load,load,1520,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,4,['load'],['load']
Performance,"ide."". ***`A:`*** By default, **`TGeoVolume`**`::Draw()` paints the content of; a given volume three levels down. You can change this by using:; ***`gGeoManager`***`::SetVisLevel(n);`. Not only that, but none of the volumes at intermediate levels (0-2) are; visible on the drawing unless they are final leaves' on their branch; (e.g. have no other volumes positioned inside). This behavior is the; default one and corresponds to leaves' global visualization mode; (**`TGeoManager::fVisOption = 1`). In order to see on the screen the; intermediate containers, one can change this mode:; `gGeoManager->SetVisOption(0)`.**. ***`Q:`*** ""Volumes are highlighted when moving the mouse over their vertices. What does it mean?"". ***`A:`*** Indeed, moving the mouse close to some volume vertices; selects it. By checking the `Event Status` entry in the root canvas; `Options` menu, you will see exactly which is the selected node in the; bottom right. Right-clicking when a volume is selected will open its; context menu where several actions can be performed (e.g. drawing it). ***`Q:`*** ""OK, but now I do not want to see all the geometry, but just a particular volume and its content. How can I do this?"". ***`A:`*** Once you have set a convenient global visualization option; and level, what you need is just call the `Draw()` method of your; interesting volume. You can do this either by interacting with the; expanded tree of volumes in a ROOT browser (where the context menu of; any volume is available), either by getting a pointer to it (e.g. by; name): `gGeoManager->GetVolume(""vol_name"")->Draw();`. ### Visualization Settings and Attributes. Supposing you now understand the basic things to do for drawing the; geometry or parts of it, you still might be not happy and wishing to; have more control on it. We will describe below how you can fine-tune some; settings. Since the corresponding attributes are flags belonging to; volume and node objects, you can change them at any time (even when th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:140486,perform,performed,140486,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance,"identify all pointers in the; program at run-time (which requires that the source-language be type-safe in; most cases). Identifying pointers at run-time requires compiler support to; locate all places that hold live pointer variables at run-time, including the; :ref:`processor stack and registers <gcroot>`. Conservative garbage collection is attractive because it does not require any; special compiler support, but it does have problems. In particular, because the; conservative garbage collector cannot *know* that a particular word in the; machine is a pointer, it cannot move live objects in the heap (preventing the; use of compacting and generational GC algorithms) and it can occasionally suffer; from memory leaks due to integer values that happen to point to objects in the; program. In addition, some aggressive compiler transformations can break; conservative garbage collectors (though these seem rare in practice). Accurate garbage collectors do not suffer from any of these problems, but they; can suffer from degraded scalar optimization of the program. In particular,; because the runtime must be able to identify and update all pointers active in; the program, some optimizations are less effective. In practice, however, the; locality and performance benefits of using aggressive garbage collection; techniques dominates any low-level losses. This document describes the mechanisms and interfaces provided by LLVM to; support accurate garbage collection. Goals and non-goals; -------------------. LLVM's intermediate representation provides :ref:`garbage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected lan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:4559,optimiz,optimization,4559,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['optimiz'],['optimization']
Performance,"idi_indexable``, with ``&vla[n]`` as the upper bound and ``&vla[0]`` as the; lower bound. Then, it's copied to ``int *p``, which is implicitly ``int; *__bidi_indexable p``. Please note that value of ``n`` used to create the upper; bound is ``10``, not ``100``, in this case because ``10`` is the actual length; of ``vla``, the value of ``n`` at the time when the array is being allocated. .. code-block:: c. void foo(void) {; int n = 10;; int vla[n];; n = 100;; int *p = vla; // { .ptr: &vla[0], .upper: &vla[10], .lower: &vla[0] }; // it's `&vla[10]` because the value of `n` was 10 at the; // time when the array is actually allocated.; // ...; }. By promoting array references to ``__bidi_indexable``, all array accesses are; bounds checked in ``-fbounds-safety``, just as ``__bidi_indexable`` pointers; are. Maintaining correctness of bounds annotations; ---------------------------------------------. ``-fbounds-safety`` maintains correctness of bounds annotations by performing; additional checks when a pointer object and/or its related value containing the; bounds information is updated. For example, ``__single`` expresses an invariant that the pointer must either; point to a single valid object or be a null pointer. To maintain this invariant,; the compiler inserts checks when initializing a ``__single`` pointer, as shown; in the following example:. .. code-block:: c. void foo(void *__sized_by(size) vp, size_t size) {; // Inserted check:; // if ((int*)upper_bound(vp) - (int*)vp < sizeof(int) && !!vp) trap();; int *__single ip = (int *)vp;; }. Additionally, an explicit bounds annotation such as ``int *__counted_by(count); buf`` defines a relationship between two variables, ``buf`` and ``count``:; namely, that ``buf`` has ``count`` number of elements available. This; relationship must hold even after any of these related variables are updated. To; this end, the model requires that assignments to ``buf`` and ``count`` must be; side by side, with no side effects between them. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:35266,perform,performing,35266,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['perform'],['performing']
Performance,"ield 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analyzes instruction; dispatch events, as well as static/dynamic dispatch",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4424,queue,queue,4424,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['queue'],['queue']
Performance,"ies ``GlobalsAA``, one that always stops at ``MemoryPhi`` nodes, etc). Default walker APIs; ^^^^^^^^^^^^^^^^^^^. There are two main APIs used to retrieve the clobbering access using the walker:. - ``MemoryAccess *getClobberingMemoryAccess(MemoryAccess *MA);`` return the; clobbering memory access for ``MA``, caching all intermediate results; computed along the way as part of each access queried. - ``MemoryAccess *getClobberingMemoryAccess(MemoryAccess *MA, const MemoryLocation &Loc);``; returns the access clobbering memory location ``Loc``, starting at ``MA``.; Because this API does not request the clobbering access of a specific memory; access, there are no results that can be cached. Locating clobbers yourself; ^^^^^^^^^^^^^^^^^^^^^^^^^^. If you choose to make your own walker, you can find the clobber for a; ``MemoryAccess`` by walking every ``MemoryDef`` that dominates said; ``MemoryAccess``. The structure of ``MemoryDef``\ s makes this relatively simple;; they ultimately form a linked list of every clobber that dominates the; ``MemoryAccess`` that you're trying to optimize. In other words, the; ``definingAccess`` of a ``MemoryDef`` is always the nearest dominating; ``MemoryDef`` or ``MemoryPhi`` of said ``MemoryDef``. Use and Def optimization; ------------------------. ``MemoryUse``\ s keep a single operand, which is their defining or optimized; access.; Traditionally ``MemorySSA`` optimized ``MemoryUse``\ s at build-time, up to a; given threshold.; Specifically, the operand of every ``MemoryUse`` was optimized to point to the; actual clobber of said ``MemoryUse``. This can be seen in the above example; the; second ``MemoryUse`` in ``if.end`` has an operand of ``1``, which is a; ``MemoryDef`` from the entry block. This is done to make walking,; value numbering, etc, faster and easier.; As of `this revision <https://reviews.llvm.org/D121381>`_, the default was; changed to not optimize uses at build time, in order to provide the option to; reduce compile-time if th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:10795,optimiz,optimize,10795,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimize']
Performance,"ies does NOT imply; penalties in performance, but in some cases, it can be observed that it; is not as performing as bounding the structure in a container volume; with a simple shape. Choosing a normal container is therefore; recommended whenever possible. ![Assemblies of volumes](pictures/080001CF.png). ### Geometrical Transformations. All geometrical transformations handled by the modeller are provided as; a built-in package. This was designed to minimize memory requirements; and optimize performance of point/vector master-to-local and; local-to-master computation. We need to have in mind that a; transformation in **`TGeo`** has two major use-cases. The first one is; for defining the placement of a volume with respect to its container; reference frame. This frame will be called 'master' and the frame of the; positioned volume - 'local'. If `T` is a transformation used for; positioning volume daughters, then: `MASTER = T * LOCAL`. Therefore `T `is used to perform a local to master conversion, while; `T-1` for a master to local conversion. The second use case is the; computation of the global transformation of a given object in the; geometry. Since the geometry is built as 'volumes-inside-volumes', the; global transformation represents the pile-up of all local; transformations in the corresponding branch. Once a given object in the; hierarchy becomes the current one, the conversion from master to local; coordinates or the other way around can be done from the manager class. A general homogenous transformation is defined as a 4x4 matrix embedding; a rotation, a translation and a scale. The advantage of this description; is that each basic transformation can be represented as a homogenous; matrix, composition being performed as simple matrix multiplication. Rotation:; $\left|\begin{array}{cccc}; r_{11} & r_{12} & r_{13} & 0 \\; r_{21} & r_{22} & r_{23} & 0 \\; r_{31} & r_{32} & r_{33} & 0 \\; 0 & 0 & 0 & 1; \end{array}; \right|$; Translation:; $\left|\begin{array}{ccc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:91644,perform,perform,91644,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['perform']
Performance,"iew:; """""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point type to half precision floating-point format. Arguments:; """""""""""""""""""". The intrinsic function contains single argument - the value to be; converted. Semantics:; """""""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point format to half precision floating-point format. The; return value is an ``i16`` which contains the converted number. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call i16 @llvm.convert.to.fp16.f32(float %a); store i16 %res, i16* @x, align 2. .. _int_convert_from_fp16:. '``llvm.convert.from.fp16``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.convert.from.fp16.f32(i16 %a); declare double @llvm.convert.from.fp16.f64(i16 %a). Overview:; """""""""""""""""". The '``llvm.convert.from.fp16``' intrinsic function performs a; conversion from half precision floating-point format to single precision; floating-point format. Arguments:; """""""""""""""""""". The intrinsic function contains single argument - the value to be; converted. Semantics:; """""""""""""""""""". The '``llvm.convert.from.fp16``' intrinsic function performs a; conversion from half single precision floating-point format to single; precision floating-point format. The input half-float value is; represented by an ``i16`` value. Examples:; """""""""""""""""". .. code-block:: llvm. %a = load i16, ptr @x, align 2; %res = call float @llvm.convert.from.fp16(i16 %a). Saturating floating-point to integer conversions; ------------------------------------------------. The ``fptoui`` and ``fptosi`` instructions return a; :ref:`poison value <poisonvalues>` if the rounded-towards-zero value is not; representable by the result type. These intrinsics provide an alternative; conversion, which will saturate towards the smallest and largest representable; integer values instead. '``llvm.fptoui.sat.*``' Intrinsic; ^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:682637,perform,performs,682637,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251036,cache,caches,251036,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"if d=3 the minimum bin edges of bin b is; of the form of the following array: {xbmin, ybmin, zbmin}.; Example 1: constructing a TKDTreeBinning object with; sample[dataSize] containing the data and dataDim and nBins,; multidimensional and bin number parameters.; ; TKDTreeBinning* fBins = new TKDTreeBinning(dataSize, dataDim, sample, nBins);; . Example 2: retrieving the bin edges. For the multidimensional case both minimum; and maximum ones are necessary for the bins to be well defined; ; Double_t* binsMinEdges = fBins->GetBinsMinEdges();; Double_t* binsMaxEdges = fBins->GetBinsMaxEdges();; ; If you wish to retrieve them sorted by their density issue before the earlier getters; fBins->SortBinsByDensity();; ; Example 3: retrieving the bin edges of bin b. For the multidimensional; case both minimum and maximum ones are necessary for the bins to be well defined; ; std::pair binEdges = fBins->GetBinEdges(b);; . Example 4: perform queries on bin b information; ; Double_t density = GetBinDensity(b);; Double_t volume = GetBinVolume(b);; Double_t* center = GetBinCenter(b);; . The tutorial math/kdTreeBinning.C is an example on; how to use this class. New statistical functions ROOT::Math::landau_quantile (inverse of landau cumulative distribution); translated from RANLAN and; ROOT::Math::landau_quantile_c.; ; New statistical functions; ROOT::Math::negative_binomial_pdf and the cumulative distributions; ROOT::Math::negative_binomial_cdf and ROOT::Math::negative_binomial_cdf_c.; ; New special functions: sine and cosine integral, translated by; B. List from CERNLIB:; ROOT::Math::sinint and ROOT::Math::cosint. New classes ROOT::Math::IOptions and; ROOT::Math::GenAlgoOptions for dealing in general with the; options for the numerical algorithm. The first one is the interface; for the second and defines the setting and retrieval of generic pair; of (name,value) options.; They are used for defining possible extra; options for the minimizer, integration and sampler options.; ; Integrati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html:4138,perform,perform,4138,math/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html,2,['perform'],['perform']
Performance,"if last character of the string, is also stripped. In the; following, we have some parameters, like tick marks length and; characters height (in percentage of the length of the axis, in user; coordinates). The default values are as follows:. - Primary tick marks: 3.0 %. - Secondary tick marks: 1.5 %. - Third order tick marks: .75 %. - Characters height for labels: 4%. - Labels offset: 1.0 %. #### Stripping Decimals. Use the `TStyle::SetStripDecimals` to strip decimals when drawing axis; labels. By default, the option is set to true, and `TGaxis::PaintAxis`; removes trailing zeros after the dot in the axis labels, e.g. {0, 0.5,; 1, 1.5, 2, 2.5, etc.}. ``` {.cpp}; TStyle::SetStripDecimals (Bool_t strip=kTRUE); ```. If this function is called with `strip=kFALSE`, `TGaxis::PaintAxis()`; will draw labels with the same number of digits after the dot, e.g.; {0.0, 0.5, 1.0, 1.5, 2.0, 2.5, etc.}. #### Optional Grid. `chopt = 'W'`: cross-Wire. #### Axis Binning Optimization. By default, the axis binning is optimized. - `chopt = 'N'`: No binning optimization. - `chopt = 'I'`: Integer labeling. ### Axis with Time Units. Histograms' axis can be defined as ""time axis"". To do that it is enough; to activate the `SetTimeDisplay` attribute on a given axis. If `h` is a; histogram, it is done the following way:. ``` {.cpp}; h->GetXaxis()->SetTimeDisplay(1); // X axis is a time axis; ```. Two parameters can be adjusted in order to define time axis: the time; format and the time offset. #### Time Format. It defines the format of the labels along the time axis. It can be; changed using the **`TAxis`** method `SetTimeFormat`. The time format is; the one used by the C function `strftime()`. It is a string containing; the following formatting characters:. +-----------------+----------------------------------------------------------+; | For the date: | %a abbreviated weekday name |; | | |; | | %b abbreviated month name |; | | |; | | %d day of the month (01-31) |; | | |; | | %m month (01-12) |;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:58176,optimiz,optimized,58176,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['optimiz'],['optimized']
Performance,"if you want to both a) confirm that all of LLVM builds with your host; compiler, and b) want to do a multi-stage clang build on your target, you; may be better off with two separate bots. Splitting increases resource; consumption, but makes it easy for each bot to keep up with commit flow.; Additionally, splitting bots may assist in triage by narrowing attention to; relevant parts of the failing configuration. In general, we recommend Release build types with Assertions enabled. This; generally provides a good balance between build times and bug detection for; most buildbots. There may be room for including some debug info (e.g. with; `-gmlt`), but in general the balance between debug info quality and build; times is a delicate one. Use Ninja & LLD; Ninja really does help build times over Make, particularly for highly; parallel builds. LLD helps to reduce both link times and memory usage; during linking significantly. With a build machine with sufficient; parallelism, link times tend to dominate critical path of the build, and are; thus worth optimizing. Use CCache and NOT incremental builds; Using ccache materially improves average build times. Incremental builds; can be slightly faster, but introduce the risk of build corruption due to; e.g. state changes, etc... At this point, the recommendation is not to; use incremental builds and instead use ccache as the latter captures the; majority of the benefit with less risk of false positives. One of the non-obvious benefits of using ccache is that it makes the; builder less sensitive to which projects are being monitored vs built.; If a change triggers a build request, but doesn't change the build output; (e.g. doc changes, python utility changes, etc..), the build will entirely; hit in cache and the build request will complete in just the testing time. With multiple workers, it is tempting to try to configure a shared cache; between the workers. Experience to date indicates this is difficult to; well, and that having l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:11034,optimiz,optimizing,11034,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['optimiz'],['optimizing']
Performance,"if(LLVM_BYE_LINK_INTO_TOOLS); message(WARNING ""Setting LLVM_BYE_LINK_INTO_TOOLS=ON only makes sense for testing purpose""); endif(). # The plugin expects to not link against the Support and Core libraries,; # but expects them to exist in the process loading the plugin. This doesn't; # work with DLLs on Windows (where a shared library can't have undefined; # references), so just skip this example on Windows.; if (NOT WIN32 AND NOT CYGWIN); add_llvm_pass_plugin(Bye; Bye.cpp; DEPENDS; intrinsics_gen; BUILDTREE_ONLY; ). install(TARGETS ${name} RUNTIME DESTINATION ""${LLVM_EXAMPLES_INSTALL_DIR}""); set_target_properties(${name} PROPERTIES FOLDER ""Examples""); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Bye/CMakeLists.txt:249,load,loading,249,interpreter/llvm-project/llvm/examples/Bye/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/Bye/CMakeLists.txt,1,['load'],['loading']
Performance,"if(LLVM_EXAMPLEIRTRANSFORMS_LINK_INTO_TOOLS); message(WARNING ""Setting LLVM_EXAMPLEIRTRANSFORMS_LINK_INTO_TOOLS=ON only makes sense for testing purpose""); endif(). # The plugin expects to not link against the Support and Core libraries,; # but expects them to exist in the process loading the plugin. This doesn't; # work with DLLs on Windows (where a shared library can't have undefined; # references), so just skip this example on Windows.; if (NOT WIN32 AND NOT CYGWIN); add_llvm_pass_plugin(ExampleIRTransforms; SimplifyCFG.cpp; DEPENDS; intrinsics_gen; BUILDTREE_ONLY; ). install(TARGETS ${name} RUNTIME DESTINATION ""${LLVM_EXAMPLES_INSTALL_DIR}""); set_target_properties(${name} PROPERTIES FOLDER ""Examples""); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/IRTransforms/CMakeLists.txt:281,load,loading,281,interpreter/llvm-project/llvm/examples/IRTransforms/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/examples/IRTransforms/CMakeLists.txt,1,['load'],['loading']
Performance,"ifferent consequences; depending on whether; you try to build a binary, or you just try to access a class that is; defined in a library. #### Linktime Library Dependencies. When building your own executable you will have to link against the; libraries that contain the classes you use. The ROOT reference guide; states the library a class is reference guide defined in. Almost all; relevant classes can be found in libraries returned by; `root-config -glibs`; the graphics libraries are retuned by; `root-config --libs`. These commands are commonly used in `Makefiles`.; Using `root-config` instead of enumerating the libraries by hand; allows you to link them in a platform independent way. Also, if ROOT; library names change you will not need to change your Makefile. A batch program that does not have a graphic display, which creates,; fills, and saves histograms and trees, only needs to link the core; libraries (`libCore`, `libRIO`), `libHist` and `libTree`.; If ROOT needs access to other libraries, it loads them dynamically.; For example, if the **`TreeViewer`** is used, `libTreePlayer` and all; libraries `libTreePlayer` depends on are loaded also. The dependent; libraries are shown in the ROOT reference guide's library dependency; graph. The difference between reference guide `libHist` and; `libHistPainter` is that the former needs to be explicitly linked and; the latter will be loaded automatically at runtime when ROOT needs it,; by means of the Plugin Manager. plugin manager. In the Figure 1-2, the libraries represented by green boxes outside of; the core are loaded via the plugin manager plugin manager or; equivalent techniques, while the white ones are not. Of course, if one; wants to access a plugin library directly, it has to be explicitly; linked. An example of a plugin library is `libMinuit`. To create and; fill histograms you need to link `libHist.so`. If the code has a call; to fit the histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet lo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:17923,load,loads,17923,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['load'],['loads']
Performance,"ifferent sets of lanes than the current; active lanes. For example, some code must execute with all lanes made; temporarily active.* ``DW_AT_LLVM_active_lane`` *allows the compiler to; provide the means to determine the source language active lanes at any; program location. Typically, this attribute will use a loclist to express; different locations of the active lane mask at different program locations.*. If not present and ``DW_AT_LLVM_lanes`` is greater than 1, then the target; architecture execution mask is used. 7. A ``DW_TAG_subprogram``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_entry_point`` debugger information entry may have a; ``DW_AT_LLVM_iterations`` attribute whose value is an integer constant or a; DWARF expression E. Its value is the number of source language loop; iterations executing concurrently by the target architecture for a single; source language thread of execution. *A compiler may generate code that executes more than one iteration of a; source language loop concurrently using optimization techniques such as; software pipelining or SIMD vectorization. The number of concurrent; iterations may vary for different loop nests in the same subprogram.; Typically, this attribute will use a loclist to express different values at; different program locations.*. If the attribute is an integer constant, then the value is the constant. The; DWARF is ill-formed if the constant is less than or equal to 0. Otherwise, E is evaluated with a context that has a result kind of a; location description, an unspecified object, the compilation unit that; contains E, an empty initial stack, and other context elements corresponding; to the source language thread of execution upon which the user is focused,; if any. The DWARF is ill-formed if the result is not a location description; comprised of one implicit location description, that when read as the; generic type, results in a value V that is less than or equal to 0. The; result of the attribute is the value V. I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:165988,concurren,concurrently,165988,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,2,"['concurren', 'optimiz']","['concurrently', 'optimization']"
Performance,"ifferent types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VALUE %1, $noreg, !123, !DIExpression(). And has the following operands:; * The first operand can record the variable location as a register,; a frame index, an immediate, or the base address register if the original; debug intrinsic referred to memory. ``$noreg`` indicates the variable; location is undefined, equivalent to an ``undef`` dbg.value operand.; * The type of the second operand indicates whether the variable location is; directly referred to by the DBG_VALUE, or whether it is indirect. The; ``$noreg`` register signifies the former, an immediate operand (0) the; latter.; * Operand 3 is the Variable field of the origin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:26881,optimiz,optimized,26881,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimized']
Performance,"ific; target and fixed accordingly. The extension can be turned off by the option ``-fno-define-target-os-macros``; as a workaround. What's New in Clang |release|?; ==============================; Some of the major new features and improvements to Clang are listed; here. Generic improvements to Clang as a whole or to its underlying; infrastructure are described first, followed by language-specific; sections with improvements to Clang's support for those languages. C++ Language Changes; --------------------. C++20 Feature Support; ^^^^^^^^^^^^^^^^^^^^^; - Implemented `P1907R1 <https://wg21.link/P1907R1>`_ which extends allowed non-type template argument; kinds with e.g. floating point values and pointers and references to subobjects.; This feature is still experimental. Accordingly, ``__cpp_nontype_template_args`` was not updated.; However, its support can be tested with ``__has_extension(cxx_generalized_nttp)``. - Clang won't perform ODR checks for decls in the global module fragment any; more to ease the implementation and improve the user's using experience.; This follows the MSVC's behavior. Users interested in testing the more strict; behavior can use the flag '-Xclang -fno-skip-odr-check-in-gmf'.; (`#79240 <https://github.com/llvm/llvm-project/issues/79240>`_). C++23 Feature Support; ^^^^^^^^^^^^^^^^^^^^^; - Implemented `P0847R7: Deducing this <https://wg21.link/P0847R7>`_. Some related core issues were also; implemented (`CWG2553 <https://wg21.link/CWG2553>`_, `CWG2554 <https://wg21.link/CWG2554>`_,; `CWG2653 <https://wg21.link/CWG2653>`_, `CWG2687 <https://wg21.link/CWG2687>`_). Because the; support for this feature is still experimental, the feature test macro ``__cpp_explicit_this_parameter``; was not set in this version.; However, its support can be tested with ``__has_extension(cxx_explicit_this_parameter)``. - Added a separate warning to warn the use of attributes on lambdas as a C++23 extension; in previous language versions: ``-Wc++23-lambda-attributes`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:9175,perform,perform,9175,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['perform'],['perform']
Performance,"ified rounding mode. For example, 'x-0'->'x' is not a valid transformation if the rounding mode is; ""round.downward"" or ""round.dynamic"" because if the value of 'x' is +0 then; 'x-0' should evaluate to '-0' when rounding downward. However, this; transformation is legal for all other rounding modes. For values other than ""round.dynamic"" optimization passes may assume that the; actual runtime rounding mode (as defined in a target-specific manner) matches; the specified rounding mode, but this is not guaranteed. Using a specific; non-dynamic rounding mode which does not match the actual rounding mode at; runtime results in undefined behavior. The exception behavior argument is a metadata string describing the floating; point exception semantics that required for the intrinsic. This argument; must be one of the following strings:. ::. ""fpexcept.ignore""; ""fpexcept.maytrap""; ""fpexcept.strict"". If this argument is ""fpexcept.ignore"" optimization passes may assume that the; exception status flags will not be read and that floating-point exceptions will; be masked. This allows transformations to be performed that may change the; exception semantics of the original code. For example, FP operations may be; speculatively executed in this case whereas they must not be for either of the; other possible values of this argument. If the exception behavior argument is ""fpexcept.maytrap"" optimization passes; must avoid transformations that may raise exceptions that would not have been; raised by the original code (such as speculatively executing FP operations), but; passes are not required to preserve all exceptions that are implied by the; original code. For example, exceptions may be potentially hidden by constant; folding. If the exception behavior argument is ""fpexcept.strict"" all transformations must; strictly preserve the floating-point exception semantics of the original code.; Any FP exception that would have been raised by the original code must be raised; by the transformed co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:870074,optimiz,optimization,870074,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"ifts out any bits that disagree with the resultant sign bit. Example:; """""""""""""""". .. code-block:: text. <result> = shl i32 4, %var ; yields i32: 4 << %var; <result> = shl i32 4, 2 ; yields i32: 16; <result> = shl i32 1, 10 ; yields i32: 1024; <result> = shl i32 1, 32 ; undefined; <result> = shl <2 x i32> < i32 1, i32 1>, < i32 1, i32 2> ; yields: result=<2 x i32> < i32 2, i32 4>. .. _i_lshr:. '``lshr``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = lshr <ty> <op1>, <op2> ; yields ty:result; <result> = lshr exact <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``lshr``' instruction (logical shift right) returns the first; operand shifted to the right a specified number of bits with zero fill. Arguments:; """""""""""""""""""". Both arguments to the '``lshr``' instruction must be the same; :ref:`integer <t_integer>` or :ref:`vector <t_vector>` of integer type.; '``op2``' is treated as an unsigned value. Semantics:; """""""""""""""""""". This instruction always performs a logical shift right operation. The; most significant bits of the result will be filled with zero bits after; the shift. If ``op2`` is (statically or dynamically) equal to or larger; than the number of bits in ``op1``, this instruction returns a :ref:`poison; value <poisonvalues>`. If the arguments are vectors, each vector element; of ``op1`` is shifted by the corresponding shift amount in ``op2``. If the ``exact`` keyword is present, the result value of the ``lshr`` is; a poison value if any of the bits shifted out are non-zero. Example:; """""""""""""""". .. code-block:: text. <result> = lshr i32 4, 1 ; yields i32:result = 2; <result> = lshr i32 4, 2 ; yields i32:result = 1; <result> = lshr i8 4, 3 ; yields i8:result = 0; <result> = lshr i8 -2, 1 ; yields i8:result = 0x7F; <result> = lshr i32 1, 32 ; undefined; <result> = lshr <2 x i32> < i32 -2, i32 4>, < i32 1, i32 2> ; yields: result=<2 x i32> < i32 0x7FFFFFFF, i32 1>. .. _i_ashr:. '``ashr``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:394580,perform,performs,394580,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"ifying the check at each; call site to a range and alignment check. Shared library support; ======================. **EXPERIMENTAL**. The basic CFI mode described above assumes that the application is a; monolithic binary; at least that all possible virtual/indirect call; targets and the entire class hierarchy are known at link time. The; cross-DSO mode, enabled with **-f[no-]sanitize-cfi-cross-dso** relaxes; this requirement by allowing virtual and indirect calls to cross the; DSO boundary. Assuming the following setup: the binary consists of several; instrumented and several uninstrumented DSOs. Some of them may be; dlopen-ed/dlclose-d periodically, even frequently. - Calls made from uninstrumented DSOs are not checked and just work.; - Calls inside any instrumented DSO are fully protected.; - Calls between different instrumented DSOs are also protected, with; a performance penalty (in addition to the monolithic CFI; overhead).; - Calls from an instrumented DSO to an uninstrumented one are; unchecked and just work, with performance penalty.; - Calls from an instrumented DSO outside of any known DSO are; detected as CFI violations. In the monolithic scheme a call site is instrumented as. .. code-block:: none. if (!InlinedFastCheck(f)); abort();; call *f. In the cross-DSO scheme it becomes. .. code-block:: none. if (!InlinedFastCheck(f)); __cfi_slowpath(CallSiteTypeId, f);; call *f. CallSiteTypeId; --------------. ``CallSiteTypeId`` is a stable process-wide identifier of the; call-site type. For a virtual call site, the type in question is the class; type; for an indirect function call it is the function signature. The; mapping from a type to an identifier is an ABI detail. In the current,; experimental, implementation the identifier of type T is calculated as; follows:. - Obtain the mangled name for ""typeinfo name for T"".; - Calculate MD5 hash of the name as a string.; - Reinterpret the first 8 bytes of the hash as a little-endian; 64-bit integer. It is possible, bu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:19581,perform,performance,19581,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['perform'],['performance']
Performance,"ight click on a histogram to pop up the; context menu, and then select the menu entry Fit Panel. The new Fit Panel GUI is available in ROOT v5.14. Its goal is to; replace the old Fit Panel and to provide more user friendly way for; performing, exploring and comparing fits. By design, this user interface is planned to contain two tabs:; ""General"" and ""Minimization"". Currently, the ""General"" tab provides; user interface elements for setting the fit function, fit method and; different fit, draw, print options.; The ""Minimization tab"" provides the option to set the Minimizer to use in the fit and; its specific options. The new fit panel is a modeless dialog, i.e. when opened, it does not; prevent users from interacting with other windows. Its first prototype; is a singleton application. When the Fit Panel is activated, users can; select an object for fitting in the usual way, i.e. by left-mouse; click on it. If the selected object is suitable for fitting, the fit; panel is connected with this object and users can perform fits by; setting different parameters and options. ### Function Choice and Settings. *Predefined' combo box* - contains a list of predefined functions in; ROOT. You have a choice of several polynomials, a Gaussian, a Landau,; and an Exponential function. The default one is Gaussian. *Operation' radio button group* defines the selected operational mode; between functions:. *Nop* - no operation (default);. *Add* - addition;. *Conv* - convolution (will be implemented in the future). Users can enter the function expression into the text entry field; below the Predefined' combo box. The entered string is checked after; the Enter key was pressed and an error message shows up, if the; function string is not accepted. *Set Parameters*' button opens a dialog for parameters settings,; which will be explained later. ### Fitter Settings. *Method' combo box* currently provides only two fit model choices:; Chi-square and Binned Likelihood. The default one is Chi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:21071,perform,perform,21071,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['perform'],['perform']
Performance,"ignment assumption is; different from the alignment used for the load/store instructions when align; isn't specified. The pointer passed into cmpxchg must have alignment greater than or; equal to the size in memory of the operand. Semantics:; """""""""""""""""""". The contents of memory at the location specified by the '``<pointer>``' operand; is read and compared to '``<cmp>``'; if the values are equal, '``<new>``' is; written to the location. The original value at the location is returned,; together with a flag indicating success (true) or failure (false). If the cmpxchg operation is marked as ``weak`` then a spurious failure is; permitted: the operation may not write ``<new>`` even if the comparison; matched. If the cmpxchg operation is strong (the default), the i1 value is 1 if and only; if the value loaded equals ``cmp``. A successful ``cmpxchg`` is a read-modify-write instruction for the purpose of; identifying release sequences. A failed ``cmpxchg`` is equivalent to an atomic; load with an ordering parameter determined the second ordering parameter. Example:; """""""""""""""". .. code-block:: llvm. entry:; %orig = load atomic i32, ptr %ptr unordered, align 4 ; yields i32; br label %loop. loop:; %cmp = phi i32 [ %orig, %entry ], [%value_loaded, %loop]; %squared = mul i32 %cmp, %cmp; %val_success = cmpxchg ptr %ptr, i32 %cmp, i32 %squared acq_rel monotonic ; yields { i32, i1 }; %value_loaded = extractvalue { i32, i1 } %val_success, 0; %success = extractvalue { i32, i1 } %val_success, 1; br i1 %success, label %done, label %loop. done:; ... .. _i_atomicrmw:. '``atomicrmw``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. atomicrmw [volatile] <operation> ptr <pointer>, <ty> <value> [syncscope(""<target-scope>"")] <ordering>[, align <alignment>] ; yields ty. Overview:; """""""""""""""""". The '``atomicrmw``' instruction is used to atomically modify memory. Arguments:; """""""""""""""""""". There are three arguments to the '``atomicrmw``' instruction: an; operation to apply, an address who",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:428442,load,load,428442,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"ignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you dont specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that theyll be fine). It is also used to provide a; contract to the back end saying either this load/store has this alignment, or; it is undefined behavior. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesnt make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:5545,optimiz,optimizers,5545,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,2,"['optimiz', 'perform']","['optimizers', 'perform']"
Performance,"il/llvm-dev/2015-February/081822.html>`_. Issues with explicit pointee types; ==================================. LLVM IR pointers can be cast back and forth between pointers with different; pointee types. The pointee type does not necessarily represent the actual; underlying type in memory. In other words, the pointee type carries no real; semantics. Historically LLVM was some sort of type-safe subset of C. Having pointee types; provided an extra layer of checks to make sure that the Clang frontend matched; its frontend values/operations with the corresponding LLVM IR. However, as other; languages like C++ adopted LLVM, the community realized that pointee types were; more of a hindrance for LLVM development and that the extra type checking with; some frontends wasn't worth it. LLVM's type system was `originally designed; <https://llvm.org/pubs/2003-05-01-GCCSummit2003.html>`_ to support high-level; optimization. However, years of LLVM implementation experience have demonstrated; that the pointee type system design does not effectively support; optimization. Memory optimization algorithms, such as SROA, GVN, and AA,; generally need to look through LLVM's struct types and reason about the; underlying memory offsets. The community realized that pointee types hinder LLVM; development, rather than helping it. Some of the initially proposed high-level; optimizations have evolved into `TBAA; <https://llvm.org/docs/LangRef.html#tbaa-metadata>`_ due to limitations with; representing higher-level language information directly via SSA values. Pointee types provide some value to frontends because the IR verifier uses types; to detect straightforward type confusion bugs. However, frontends also have to; deal with the complexity of inserting bitcasts everywhere that they might be; required. The community consensus is that the costs of pointee types; outweight the benefits, and that they should be removed. Many operations do not actually care about the underlying type. These; ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst:2606,optimiz,optimization,2606,interpreter/llvm-project/llvm/docs/OpaquePointers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst,1,['optimiz'],['optimization']
Performance,"ild the plugin, and then call clang with the plugin from the; source tree:. .. code-block:: console. $ export BD=/path/to/build/directory; $ (cd $BD && make PrintFunctionNames ); $ clang++ -D_GNU_SOURCE -D_DEBUG -D__STDC_CONSTANT_MACROS \; -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS -D_GNU_SOURCE \; -I$BD/tools/clang/include -Itools/clang/include -I$BD/include -Iinclude \; tools/clang/tools/clang-check/ClangCheck.cpp -fsyntax-only \; -Xclang -load -Xclang $BD/lib/PrintFunctionNames.so -Xclang \; -plugin -Xclang print-fns. Also see the print-function-name plugin example's; `README <https://github.com/llvm/llvm-project/blob/main/clang/examples/PrintFunctionNames/README.txt>`_. Using the clang command line; ----------------------------. Using `-fplugin=plugin` on the clang command line passes the plugin; through as an argument to `-load` on the cc1 command line. If the plugin; class implements the ``getActionType`` method then the plugin is run; automatically. For example, to run the plugin automatically after the main AST; action (i.e. the same as using `-add-plugin`):. .. code-block:: c++. // Automatically run the plugin after the main AST action; PluginASTAction::ActionType getActionType() override {; return AddAfterMainAction;; }. Interaction with ``-clear-ast-before-backend``; ----------------------------------------------. To reduce peak memory usage of the compiler, plugins are recommended to run; *before* the main action, which is usually code generation. This is because; having any plugins that run after the codegen action automatically turns off; ``-clear-ast-before-backend``. ``-clear-ast-before-backend`` reduces peak; memory by clearing the Clang AST after generating IR and before running IR; optimizations. Use ``CmdlineBeforeMainAction`` or ``AddBeforeMainAction`` as; ``getActionType`` to run plugins while still benefitting from; ``-clear-ast-before-backend``. Plugins must make sure not to modify the AST,; otherwise they should run after the main action. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst:7718,optimiz,optimizations,7718,interpreter/llvm-project/clang/docs/ClangPlugins.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst,1,['optimiz'],['optimizations']
Performance,"ild; system can cache the resource directory by itself and pass ``-resource-dir <resource-dir>``; explicitly in the command line options:. .. code-block:: console. $ clang-scan-deps -format=p1689 -- <path-to-compiler-executable>/clang++ -std=c++20 -resource-dir <resource-dir> mod.cppm -c -o mod.o. Possible Questions; ==================. How modules speed up compilation; --------------------------------. A classic theory for the reason why modules speed up the compilation is:; if there are ``n`` headers and ``m`` source files and each header is included by each source file,; then the complexity of the compilation is ``O(n*m)``;; But if there are ``n`` module interfaces and ``m`` source files, the complexity of the compilation is; ``O(n+m)``. So, using modules would be a big win when scaling.; In a simpler word, we could get rid of many redundant compilations by using modules. Roughly, this theory is correct. But the problem is that it is too rough.; The behavior depends on the optimization level, as we will illustrate below. First is ``O0``. The compilation process is described in the following graph. .. code-block:: none. -------------frontend-----------------------middle end--------------------backend----;    ; ---parsing----sema----codegen------- transformations ---- codegen -------- codegen --. ---------------------------------------------------------------------------------------; | ; | source file ; | ; ---------------------------------------------------------------------------------------. --------;  ; imported;  ;  code ;  ; --------. Here we can see that the source file (could be a non-module unit or a module unit) would get processed by the; whole pipeline.; But the imported code would only get involved in semantic analysis, which is mainly about name lookup,; overload resolution and template instantiation.; All of these processes are fast relative to the whole compilation process.; More importantly, the imported code only n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:40218,optimiz,optimization,40218,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,1,['optimiz'],['optimization']
Performance,"ile that can be consumed later. By default, the format of the serialized remarks is :ref:`YAML; <yamlremarks>`, and it can be accompanied by a :ref:`section <remarkssection>`; in the object files to easily retrieve it. :doc:`llc <CommandGuide/llc>` and :doc:`opt <CommandGuide/opt>` support the; following options:. ``Basic options``. .. option:: -pass-remarks-output=<filename>. Enables the serialization of remarks to a file specified in <filename>. By default, the output is serialized to :ref:`YAML <yamlremarks>`. .. option:: -pass-remarks-format=<format>. Specifies the output format of the serialized remarks. Supported formats:. * :ref:`yaml <yamlremarks>` (default); * :ref:`yaml-strtab <yamlstrtabremarks>`; * :ref:`bitstream <bitstreamremarks>`. ``Content configuration``. .. option:: -pass-remarks-filter=<regex>. Only passes whose name match the given (POSIX) regular expression will be; serialized to the final output. .. option:: -pass-remarks-with-hotness. With PGO, include profile count in optimization remarks. .. option:: -pass-remarks-hotness-threshold. The minimum profile count required for an optimization remark to be; emitted. Other tools that support remarks:. :program:`llvm-lto`. .. option:: -lto-pass-remarks-output=<filename>; .. option:: -lto-pass-remarks-filter=<regex>; .. option:: -lto-pass-remarks-format=<format>; .. option:: -lto-pass-remarks-with-hotness; .. option:: -lto-pass-remarks-hotness-threshold. :program:`gold-plugin` and :program:`lld`. .. option:: -opt-remarks-filename=<filename>; .. option:: -opt-remarks-filter=<regex>; .. option:: -opt-remarks-format=<format>; .. option:: -opt-remarks-with-hotness. Serialization modes; ===================. There are two modes available for serializing remarks:. ``Separate``. In this mode, the remarks and the metadata are serialized separately. The; client is responsible for parsing the metadata first, then use the metadata; to correctly parse the remarks. ``Standalone``. In this mode, the remarks and the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst:3199,optimiz,optimization,3199,interpreter/llvm-project/llvm/docs/Remarks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst,1,['optimiz'],['optimization']
Performance,"ile. You can override the default; and specify that the member class `Streamer `is used by setting the; `TClonesArray::BypassStreamer` bit to false:. ``` {.cpp}; TClonesArray *fTracks;; fTracks->BypassStreamer(kFALSE); // use the member Streamer; ```. When the `kBypassStreamer` bit is set, the automatically generated; `Streamer `can call directly the method **`TClass::WriteBuffer`**.; Bypassing the `Streamer` improves the performance when writing/reading; the objects in the **`TClonesArray`**. However, the drawback is when a; **`TClonesArray`** is written with `split=0` bypassing the `Streamer`,; the `StreamerInfo `of the class in the array being optimized, one cannot; later use the **`TClonesArray`** with `split > 0`. For example, there is; a problem with the following scenario: a class `Foo` has a; **`TClonesArray`** of `Bar` objects the `Foo` object is written with; `split=0` to `Tree` `T1`. In this case the `StreamerInfo` for the class; `Bar` is created in optimized mode in such a way that data members of; the same type are written as an array improving the I/O performance. In; a new program, `T1` is read and a new `Tree` `T2` is created with the; object `Foo` in `split > 1`. When the `T2 `branch is created, the `StreamerInfo` for the class `Bar`; is created with no optimization (mandatory for the split mode). The; optimized Bar `StreamerInfo` is going to be used to read the; **`TClonesArray`** in `T1`. The result will be `Bar` objects with data; member values not in the right sequence. The solution to this problem is; to call `BypassStreamer(kFALSE)` for the **`TClonesArray`**. In this; case, the normal `Bar::Streamer` function will be called. The; `Bar::Streamer` function works OK independently if the `Bar`; `StreamerInfo `had been generated in optimized mode or not. ## Pointers and References in Persistency. An object pointer as a data member presents a challenge to the streaming; software. If the object pointed to is saved every time, it could create; circula",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:54579,optimiz,optimized,54579,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,2,"['optimiz', 'perform']","['optimized', 'performance']"
Performance,ile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:213345,load,load,213345,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic glc=1. - If not TgSplit execution; mode, omit glc=1. load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic glc=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; store atomic monotonic - system - global 1. buffer/global/flat_store; - generic; store atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:243833,load,load,243833,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ile; operation may modify the memory at that address. A volatile operation; may not modify any other memory accessible by the module being compiled.; A volatile operation may not call any code in the current module. In general (without target specific context), the address space of a; volatile operation may not be changed. Different address spaces may; have different trapping behavior when dereferencing an invalid; pointer. The compiler may assume execution will continue after a volatile operation,; so operations which modify memory or may have undefined behavior can be; hoisted past a volatile operation. As an exception to the preceding rule, the compiler may not assume execution; will continue after a volatile store operation. This restriction is necessary; to support the somewhat common pattern in C of intentionally storing to an; invalid pointer to crash the program. In the future, it might make sense to; allow frontends to control this behavior. IR-level volatile loads and stores cannot safely be optimized into llvm.memcpy; or llvm.memmove intrinsics even when those intrinsics are flagged volatile.; Likewise, the backend should never split or merge target-legal volatile; load/store instructions. Similarly, IR-level volatile loads and stores cannot; change from integer to floating-point or vice versa. .. admonition:: Rationale. Platforms may rely on volatile loads and stores of natively supported; data width to be executed as single instruction. For example, in C; this holds for an l-value of volatile primitive type with native; hardware support, but not necessarily for aggregate types. The; frontend upholds these expectations, which are intentionally; unspecified in the IR. The rules above ensure that IR transformations; do not violate the frontend's contract with the language. .. _memmodel:. Memory Model for Concurrent Operations; --------------------------------------. The LLVM IR does not define any way to start parallel threads of; execution or to register s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:147876,load,loads,147876,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['load', 'optimiz']","['loads', 'optimized']"
Performance,"ile=A=prebuilt/A.pcm; clang -cc1 -emit-obj use.c -fmodules -fmodule-map-file=module.modulemap -fmodule-file=A=prebuilt/A.pcm -fmodule-file=B=prebuilt/B.pcm. Instead of of specifying the mappings manually, it can be convenient to use the ``-fprebuilt-module-path`` option. Let's also use ``-fimplicit-module-maps`` instead of manually pointing to our module map. .. code-block:: sh. rm -rf prebuilt; mkdir prebuilt; clang -cc1 -emit-module -o prebuilt/A.pcm -fmodules module.modulemap -fmodule-name=A; clang -cc1 -emit-module -o prebuilt/B.pcm -fmodules module.modulemap -fmodule-name=B -fprebuilt-module-path=prebuilt; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt. A trick to prebuild all modules required for our source file in one command is to generate implicit modules while using the ``-fdisable-module-hash`` option. .. code-block:: sh. rm -rf prebuilt ; mkdir prebuilt; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -fdisable-module-hash; ls prebuilt/*.pcm; # prebuilt/A.pcm prebuilt/B.pcm. Note that with explicit or prebuilt modules, we are responsible for, and should be particularly careful about the compatibility of our modules.; Using mismatching compilation options and modules may lead to issues. .. code-block:: sh. clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -DENABLE_A; # use.c:4:10: warning: implicit declaration of function 'a' is invalid in C99 [-Wimplicit-function-declaration]; # return a(x);; # ^; # 1 warning generated. So we need to maintain multiple versions of prebuilt modules. We can do so using a manual module mapping, or pointing to a different prebuilt module cache path. For example:. .. code-block:: sh. rm -rf prebuilt ; mkdir prebuilt ; rm -rf prebuilt_a ; mkdir prebuilt_a; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -fdisable-module-hash; clang -cc1 -emit-obj use.c -fmodul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:20848,cache,cache-path,20848,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['cache'],['cache-path']
Performance,"iled.; Linkage relationships between ``JITDylibs`` determine how inter-module; references are resolved, and symbol resolvers are no longer used. See the; section `Design Overview`_ for more details. Unless multiple JITDylibs are needed to model linkage relationships, ORCv1; clients should place all code in a single JITDylib.; MCJIT clients should use LLJIT (see `LLJIT and LLLazyJIT`_), and can place; code in LLJIT's default created main JITDylib (See; ``LLJIT::getMainJITDylib()``). 2. All JIT stacks now need an ``ExecutionSession`` instance. ExecutionSession; manages the string pool, error reporting, synchronization, and symbol; lookup. 3. ORCv2 uses uniqued strings (``SymbolStringPtr`` instances) rather than; string values in order to reduce memory overhead and improve lookup; performance. See the subsection `How to manage symbol strings`_. 4. IR layers require ThreadSafeModule instances, rather than; std::unique_ptr<Module>s. ThreadSafeModule is a wrapper that ensures that; Modules that use the same LLVMContext are not accessed concurrently.; See `How to use ThreadSafeModule and ThreadSafeContext`_. 5. Symbol lookup is no longer handled by layers. Instead, there is a; ``lookup`` method on JITDylib that takes a list of JITDylibs to scan. .. code-block:: c++. ExecutionSession ES;; JITDylib &JD1 = ...;; JITDylib &JD2 = ...;. auto Sym = ES.lookup({&JD1, &JD2}, ES.intern(""_main""));. 6. The removeModule/removeObject methods are replaced by; ``ResourceTracker::remove``.; See the subsection `How to remove code`_. For code examples and suggestions of how to use the ORCv2 APIs, please see; the section `How-tos`_. How-tos; =======. How to manage symbol strings; ----------------------------. Symbol strings in ORC are uniqued to improve lookup performance, reduce memory; overhead, and allow symbol names to function as efficient keys. To get the; unique ``SymbolStringPtr`` for a string value, call the; ``ExecutionSession::intern`` method:. .. code-block:: c++. ExecutionSession ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:21369,concurren,concurrently,21369,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['concurren'],['concurrently']
Performance,"iler to generate DWARF for languages that; map a thread to the complete wavefront. It also allows more efficient DWARF to; be generated to describe the CFI as only a single expression is required for; the whole vector register, rather than a separate expression for each lane's; dword of the vector register. It also allows the compiler to produce DWARF; that indexes the vector register if it spills scalar registers into portions; of a vector register. Since DWARF stack value entries have a base type and AMDGPU registers are a; vector of dwords, the ability to specify that a base type is a vector is; required. See ``DW_AT_LLVM_vector_size`` in :ref:`amdgpu-dwarf-base-type-entries`. .. _amdgpu-dwarf-operation-to-create-vector-composite-location-descriptions:. 2.10 DWARF Operations to Create Vector Composite Location Descriptions; ----------------------------------------------------------------------. AMDGPU optimized code may spill vector registers to non-global address space; memory, and this spilling may be done only for SIMT lanes that are active on; entry to the subprogram. To support this the CFI rule for the partially spilled; register needs to use an expression that uses the EXEC register as a bit mask to; select between the register (for inactive lanes) and the stack spill location; (for active lanes that are spilled). This needs to evaluate to a location; description, and not a value, as a debugger needs to change the value if the; user assigns to the variable. Another usage is to create an expression that evaluates to provide a vector of; logical PCs for active and inactive lanes in a SIMT execution model. Again the; EXEC register is used to select between active and inactive PC values. In order; to represent a vector of PC values, a way to create a composite location; description that is a vector of a single location is used. It may be possible to use existing DWARF to incrementally build the composite; location description, possibly using the DWARF operation",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:24667,optimiz,optimized,24667,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimized']
Performance,"iler.used``' Global Variable; --------------------------------------------. The ``@llvm.compiler.used`` directive is the same as the ``@llvm.used``; directive, except that it only prevents the compiler from touching the; symbol. On targets that support it, this allows an intelligent linker to; optimize references to the symbol without being impeded as it would be; by ``@llvm.used``. This is a rare construct that should only be used in rare circumstances,; and should not be exposed to source languages. .. _gv_llvmglobalctors:. The '``llvm.global_ctors``' Global Variable; -------------------------------------------. .. code-block:: llvm. %0 = type { i32, ptr, ptr }; @llvm.global_ctors = appending global [1 x %0] [%0 { i32 65535, ptr @ctor, ptr @data }]. The ``@llvm.global_ctors`` array contains a list of constructor; functions, priorities, and an associated global or function.; The functions referenced by this array will be called in ascending order; of priority (i.e. lowest first) when the module is loaded. The order of; functions with the same priority is not defined. If the third field is non-null, and points to a global variable; or function, the initializer function will only run if the associated; data from the current module is not discarded.; On ELF the referenced global variable or function must be in a comdat. .. _llvmglobaldtors:. The '``llvm.global_dtors``' Global Variable; -------------------------------------------. .. code-block:: llvm. %0 = type { i32, ptr, ptr }; @llvm.global_dtors = appending global [1 x %0] [%0 { i32 65535, ptr @dtor, ptr @data }]. The ``@llvm.global_dtors`` array contains a list of destructor; functions, priorities, and an associated global or function.; The functions referenced by this array will be called in descending; order of priority (i.e. highest first) when the module is unloaded. The; order of functions with the same priority is not defined. If the third field is non-null, and points to a global variable; or function, the d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:353040,load,loaded,353040,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loaded']
Performance,"ility layer. N: Aaron Ballman; E: aaron@aaronballman.com; D: Clang frontend, frontend attributes, Windows support, general bug fixing; I: AaronBallman. N: Alexey Bataev; E: a.bataev@outlook.com; D: Clang frontend, OpenMP in clang, SLP vectorizer, Loop vectorizer, InstCombine; I: ABataev. N: Nate Begeman; E: natebegeman@mac.com; D: PowerPC backend developer; D: Target-independent code generator and analysis improvements. N: Daniel Berlin; E: dberlin@dberlin.org; D: ET-Forest implementation.; D: Sparse bitmap. N: Geoff Berry; E: gberry@codeaurora.org; E: gcb@acm.org; D: AArch64 backend improvements; D: Added EarlyCSE MemorySSA support; D: CodeGen improvements. N: David Blaikie; E: dblaikie@gmail.com; D: General bug fixing/fit & finish, mostly in Clang. N: Neil Booth; E: neil@daikokuya.co.uk; D: APFloat implementation. N: Alex Bradbury; E: asb@igalia.com; D: RISC-V backend. N: Misha Brukman; E: brukman+llvm@uiuc.edu; W: http://misha.brukman.net; D: Portions of X86 and Sparc JIT compilers, PowerPC backend; D: Incremental bitcode loader. N: Cameron Buschardt; E: buschard@uiuc.edu; D: The `mem2reg' pass - promotes values stored in memory to registers. N: Brendon Cahoon; E: bcahoon@codeaurora.org; D: Loop unrolling with run-time trip counts. N: Chandler Carruth; E: chandlerc@gmail.com; E: chandlerc@google.com; D: Hashing algorithms and interfaces; D: Inline cost analysis; D: Machine block placement pass; D: SROA. N: Casey Carter; E: ccarter@uiuc.edu; D: Fixes to the Reassociation pass, various improvement patches. N: Evan Cheng; E: evan.cheng@apple.com; D: ARM and X86 backends; D: Instruction scheduler improvements; D: Register allocator improvements; D: Loop optimizer improvements; D: Target-independent code generator improvements. N: Dan Villiom Podlaski Christiansen; E: danchr@gmail.com; E: danchr@cs.au.dk; W: http://villiom.dk; D: LLVM Makefile improvements; D: Clang diagnostic & driver tweaks; S: Aarhus, Denmark. N: Jeff Cohen; E: jeffc@jolt-lang.org; W: http://jolt-l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT:1851,load,loader,1851,interpreter/llvm-project/llvm/CREDITS.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT,1,['load'],['loader']
Performance,"ilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolved O(N^2) scaling problem in ```TTree::Draw()``` observed when a branch that contains a; large TClonesArray where each element contains another small vector container.; - `TTree::TTree()` now takes the `TDirectory*` that the tree should be constructed in.; Defaults to `gDirectory`, i.e. the default behavior did not change.; - To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced.; This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained; (the absolute value of MaxVirtualSize in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:9364,queue,queue,9364,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['queue'],['queue']
Performance,"ill use the following operations:. #. ``cmpNumbers(number1, number2)`` is a method that returns -1 if left is less; than right; 0, if left and right are equal; and 1 otherwise. #. ``cmpFlags(flag1, flag2)`` is a hypothetical method that compares two flags.; The logic is the same as in ``cmpNumbers``, where ``true`` is 1, and; ``false`` is 0. The rest of the article is based on *MergeFunctions.cpp* source code; (found in *<llvm_dir>/lib/Transforms/IPO/MergeFunctions.cpp*). We would like; to ask reader to keep this file open, so we could use it as a reference; for further explanations. Now, we're ready to proceed to the next chapter and see how it works. Functions comparison; ====================; At first, let's define how exactly we compare complex objects. Complex object comparison (function, basic-block, etc) is mostly based on its; sub-object comparison results. It is similar to the next ""tree"" objects; comparison:. #. For two trees *T1* and *T2* we perform *depth-first-traversal* and have; two sequences as a product: ""*T1Items*"" and ""*T2Items*"". #. We then compare chains ""*T1Items*"" and ""*T2Items*"" in; the most-significant-item-first order. The result of items comparison; would be the result of *T1* and *T2* comparison itself. FunctionComparator::compare(void); ---------------------------------; A brief look at the source code tells us that the comparison starts in the; ``int FunctionComparator::compare(void)`` method. 1. The first parts to be compared are the function's attributes and some; properties that is outside the attributes term, but still could make the; function different without changing its body. This part of the comparison is; usually done within simple *cmpNumbers* or *cmpFlags* operations (e.g.; ``cmpFlags(F1->hasGC(), F2->hasGC())``). Below is a full list of function's; properties to be compared on this stage:. * *Attributes* (those are returned by ``Function::getAttributes()``; method). * *GC*, for equivalence, *RHS* and *LHS* should be bot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst:11476,perform,perform,11476,interpreter/llvm-project/llvm/docs/MergeFunctions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst,1,['perform'],['perform']
Performance,"ils. AArch64 has `Address Tagging`_ (or top-byte-ignore, TBI), a hardware feature that allows; software to use the 8 most significant bits of a 64-bit pointer as; a tag. HWASAN uses `Address Tagging`_; to implement a memory safety tool, similar to :doc:`AddressSanitizer`,; but with smaller memory overhead and slightly different (mostly better); accuracy guarantees. Intel's `Linear Address Masking`_ (LAM) also provides address tagging for; x86_64, though it is not widely available in hardware yet. For x86_64, HWASAN; has a limited implementation using page aliasing instead. Algorithm; =========; * Every heap/stack/global memory object is forcibly aligned by `TG` bytes; (`TG` is e.g. 16 or 64). We call `TG` the **tagging granularity**.; * For every such object a random `TS`-bit tag `T` is chosen (`TS`, or tag size, is e.g. 4 or 8); * The pointer to the object is tagged with `T`.; * The memory for the object is also tagged with `T` (using a `TG=>1` shadow memory); * Every load and store is instrumented to read the memory tag and compare it; with the pointer tag, exception is raised on tag mismatch. For a more detailed discussion of this approach see https://arxiv.org/pdf/1802.09517.pdf. Short granules; --------------. A short granule is a granule of size between 1 and `TG-1` bytes. The size; of a short granule is stored at the location in shadow memory where the; granule's tag is normally stored, while the granule's actual tag is stored; in the last byte of the granule. This means that in order to verify that a; pointer tag matches a memory tag, HWASAN must check for two possibilities:. * the pointer tag is equal to the memory tag in shadow memory, or; * the shadow memory tag is actually a short granule size, the value being loaded; is in bounds of the granule and the pointer tag is equal to the last byte of; the granule. Pointer tags between 1 to `TG-1` are possible and are as likely as any other; tag. This means that these tags in memory have two interpretations: the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:1723,load,load,1723,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['load'],['load']
Performance,"ilt with ``-DLLVM_BINUTILS_INCDIR`` set properly. See; the instructions for the; `LLVM gold plugin <https://llvm.org/docs/GoldPlugin.html#how-to-build-it>`_. Controlling Backend Parallelism; -------------------------------; .. _parallelism:. By default, the ThinLTO link step will launch as many; threads in parallel as there are cores. If the number of; cores can't be computed for the architecture, then it will launch; ``std::thread::hardware_concurrency`` number of threads in parallel.; For machines with hyper-threading, this is the total number of; virtual cores. For some applications and machine configurations this; may be too aggressive, in which case the amount of parallelism can; be reduced to ``N`` via:. - gold:; ``-Wl,-plugin-opt,jobs=N``; - ld64:; ``-Wl,-mllvm,-threads=N``; - ld.lld, ld64.lld:; ``-Wl,--thinlto-jobs=N``; - lld-link:; ``/opt:lldltojobs=N``. Other possible values for ``N`` are:. - 0:; Use one thread per physical core (default); - 1:; Use a single thread only (disable multi-threading); - all:; Use one thread per logical core (uses all hyper-threads). Incremental; -----------; .. _incremental:. ThinLTO supports fast incremental builds through the use of a cache,; which currently must be enabled through a linker option. - gold (as of LLVM 4.0):; ``-Wl,-plugin-opt,cache-dir=/path/to/cache``; - ld64 (supported since clang 3.9 and Xcode 8) and Mach-O ld64.lld (as of LLVM; 15.0):; ``-Wl,-cache_path_lto,/path/to/cache``; - ELF ld.lld (as of LLVM 5.0):; ``-Wl,--thinlto-cache-dir=/path/to/cache``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocache:/path/to/cache``. Cache Pruning; -------------. To help keep the size of the cache under control, ThinLTO supports cache; pruning. Cache pruning is supported with gold, ld64, and lld, but currently only; gold and lld allow you to control the policy with a policy string. The cache; policy must be specified with a linker option. - gold (as of LLVM 6.0):; ``-Wl,-plugin-opt,cache-policy=POLICY``; - ELF ld.lld (as of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:4444,multi-thread,multi-threading,4444,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,1,['multi-thread'],['multi-threading']
Performance,"image:: ./loop-terminology-guarded-loop.png; :width: 500 px. The result is a little bit more complicated than we may expect; because LoopRotate ensures that the loop is in; :ref:`Loop Simplify Form <loop-terminology-loop-simplify>`; after rotation.; In this case, it inserted the %loop.preheader basic block so; that the loop has a preheader and it introduced the %loop.exit; basic block so that the loop has dedicated exits; (otherwise, %exit would be jumped from both %latch and %entry,; but %entry is not contained in the loop).; Note that a loop has to be in Loop Simplify Form beforehand; too for LoopRotate to be applied successfully. The main advantage of this form is that it allows hoisting; invariant instructions, especially loads, into the preheader.; That could be done in non-rotated loops as well but with; some disadvantages. Let's illustrate them with an example:. .. code-block:: C. for (int i = 0; i < n; ++i) {; auto v = *p;; use(v);; }. We assume that loading from p is invariant and use(v) is some; statement that uses v.; If we wanted to execute the load only once we could move it; ""out"" of the loop body, resulting in this:. .. code-block:: C. auto v = *p;; for (int i = 0; i < n; ++i) {; use(v);; }. However, now, in the case that n <= 0, in the initial form,; the loop body would never execute, and so, the load would; never execute. This is a problem mainly for semantic reasons.; Consider the case in which n <= 0 and loading from p is invalid.; In the initial program there would be no error. However, with this; transformation we would introduce one, effectively breaking; the initial semantics. To avoid both of these problems, we can insert a guard:. .. code-block:: C. if (n > 0) { // loop guard; auto v = *p;; for (int i = 0; i < n; ++i) {; use(v);; }; }. This is certainly better but it could be improved slightly. Notice; that the check for whether n is bigger than 0 is executed twice (and; n does not change in between). Once when we check the guard condition; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:22494,load,loading,22494,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['load'],['loading']
Performance,"imator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking.; Could be a viable option if cluster compression ratios turn out to change significantly in a single file. - Calculate the cluster compression ratio from column-based individual estimators.; More complex to implement and to recalculate the estimator on every fill,; requires additional state for every column.; One might reduce the additional state and complexity by only applying the fine-grained estimator for collections.; Such an estimator would react better to a sudden change in the amount of data written for collections / columns; that have substentially different compression ratios. Page Checksums; --------------. By default, RNTuple appends xxhash-3 64bit checksums to every compressed page.; Typically, checksums increase the data size in the region of a per mille.; As a side effect, page checksums allow for efficient ""same page merging"":; identical pages in the same cluster will be written only once.; On typical datasets, same page merging saves a few percent.; Conversely, turning off page checksums also disables the same page merging optimization.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:5194,optimiz,optimization,5194,tree/ntuple/v7/doc/tuning.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md,1,['optimiz'],['optimization']
Performance,"ime to read sample** is the execution; time of the script `$ROOTSYS/test/eventb`. This script loops on all; events. For each event, the branch containing the number of tracks is; read. In case the number of tracks is less than 585, the full event is; read in memory. This test is obviously not possible in non-split mode.; In non-split mode, the full event must be read in memory. The times; reported in the table correspond to complete I/O operations necessary to; deal with **machine independent binary files**. On **Linux**, this also; includes byte-swapping operations. The ROOT file allows for direct; access to any event in the file and direct access to any part of an; event when split=1. Note also that the uncompressed file generated with split=0 is 48.7; Mbytes and only 47.17 Mbytes for the option split=1. The difference in; size is due to the object identification mechanism overhead when the; event is written to a single buffer. This overhead does not exist in; split mode because the branch buffers are optimized for homogeneous data; types. You can run the test programs on your architecture. The program; `Event` will report the write performance. You can measure the read; performance by executing the scripts `eventa` and `eventb`. The; performance depends not only of the processor type, but also of the disk; devices (local, NFS, AFS, etc.). ## Chains; \index{tree!chains}. A **`TChain`** object is a list of ROOT files containing the same tree.; As an example, assume we have three files called; `file1.root, file2.root, file3.root`. Each file contains one tree called; ""`T`"". We can create a chain with the following statements:. ``` {.cpp}; TChain chain(""T""); // name of the tree is the argument; chain.Add(""file1.root"");; chain.Add(""file2.root"");; chain.Add(""file3.root"");; ```. The name of the **`TChain`** will be the same as the name of the tree;; in this case it will be `""T"". Note that two `objects can have the same; name as long as they are not histograms in the same",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:139804,optimiz,optimized,139804,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['optimiz'],['optimized']
Performance,"ime. A feasible temporary solution is to use specific physical registers at the; lowering time for small (<= 4 words?) transfer size. * ARM CSRet calling convention requires the hidden argument to be returned by; the callee. //===---------------------------------------------------------------------===//. We can definitely do a better job on BB placements to eliminate some branches.; It's very common to see llvm generated assembly code that looks like this:. LBB3:; ...; LBB4:; ...; beq LBB3; b LBB2. If BB4 is the only predecessor of BB3, then we can emit BB3 after BB4. We can; then eliminate beq and turn the unconditional branch to LBB2 to a bne. See McCat/18-imp/ComputeBoundingBoxes for an example. //===---------------------------------------------------------------------===//. Pre-/post- indexed load / stores:. 1) We should not make the pre/post- indexed load/store transform if the base ptr; is guaranteed to be live beyond the load/store. This can happen if the base; ptr is live out of the block we are performing the optimization. e.g. mov r1, r2; ldr r3, [r1], #4; ... vs. ldr r3, [r2]; add r1, r2, #4; ... In most cases, this is just a wasted optimization. However, sometimes it can; negatively impact the performance because two-address code is more restrictive; when it comes to scheduling. Unfortunately, liveout information is currently unavailable during DAG combine; time. 2) Consider spliting a indexed load / store into a pair of add/sub + load/store; to solve #1 (in TwoAddressInstructionPass.cpp). 3) Enhance LSR to generate more opportunities for indexed ops. 4) Once we added support for multiple result patterns, write indexed loads; patterns instead of C++ instruction selection code. 5) Use VLDM / VSTM to emulate indexed FP load / store. //===---------------------------------------------------------------------===//. Implement support for some more tricky ways to materialize immediates. For; example, to get 0xffff8000, we can use:. mov r9, #&3f8000; sub r9, r9,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:8423,perform,performing,8423,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,4,"['optimiz', 'perform']","['optimization', 'performing']"
Performance,"imination`` collects the following facts and determines if the; bounds checks can be safely removed:. * Inside the for-loop, ``0 <= i < count``, hence ``1 <= i + 1 <= count``.; * Pointer arithmetic ``p + count`` in the if-condition doesnt wrap.; * ``-fbounds-safety`` treats pointer arithmetic overflow as deterministically; twos complement computation, not an undefined behavior. Therefore,; getelementptr does not typically have inbounds keyword. However, the compiler; does emit inbounds for ``p + count`` in this case because; ``__counted_by(count)`` has the invariant that p has at least as many as; elements as count. Using this information, ``ConstraintElimination`` is able; to determine ``p + count`` doesnt wrap.; * Accordingly, ``p + i`` and ``p + i + 1`` also dont wrap.; * Therefore, ``p <= p + i`` and ``p + i + 1 <= p + count``.; * The if-condition simplifies to false and becomes dead code that the subsequent; optimization passes can remove. ``OptRemarks`` can be utilized to provide insights into performance tuning. It; has the capability to report on checks that it cannot eliminate, possibly with; reasons, allowing programmers to adjust their code to unlock further; optimizations. Debugging; =========. Internal bounds annotations; ---------------------------. Internal bounds annotations change a pointer into a wide pointer. The debugger; needs to understand that wide pointers are essentially pointers with a struct; layout. To handle this, a wide pointer is described as a record type in the; debug info. The type name has a special name prefix (e.g.,; ``__bounds_safety$bidi_indexable``) which can be recognized by a debug info; consumer to provide support that goes beyond showing the internal structure of; the wide pointer. There are no DWARF extensions needed to support wide pointers.; In our implementation, LLDB recognizes wide pointer types by name and; reconstructs them as wide pointer Clang AST types for use in the expression; evaluator. External bounds an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:8011,perform,performance,8011,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['perform'],['performance']
Performance,"imization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:2343,optimiz,optimization,2343,roofit/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html,2,['optimiz'],['optimization']
Performance,"imizations that Result in Concurrent Iteration Execution; --------------------------------------------------------------------------------------------. A compiler can perform loop optimizations that result in the generated code; executing multiple iterations concurrently. For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of one iteration to hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SIMD; hardware to allow a single instruction to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:33618,concurren,concurrency,33618,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,3,"['concurren', 'optimiz']","['concurrency', 'optimizations']"
Performance,"in a; unique section. It will also place all basic blocks of functions ``bar``; in unique sections. Further, section clusters can also be specified using the ``list=<arg>``; option. For example, ``list=spec.txt`` where ``spec.txt`` contains:. ::. !foo; !!1 !!3 !!5; !!2 !!4 !!6. will create two unique sections for function ``foo`` with the first; containing the odd numbered basic blocks and the second containing the; even numbered basic blocks. Basic block sections allow the linker to reorder basic blocks and enables; link-time optimizations like whole program inter-procedural basic block; reordering. Profile Guided Optimization; ---------------------------. Profile information enables better optimization. For example, knowing that a; branch is taken very frequently helps the compiler make better decisions when; ordering basic blocks. Knowing that a function ``foo`` is called more; frequently than another function ``bar`` helps the inliner. Optimization; levels ``-O2`` and above are recommended for use of profile guided optimization. Clang supports profile guided optimization with two different kinds of; profiling. A sampling profiler can generate a profile with very low runtime; overhead, or you can build an instrumented version of the code that collects; more detailed profile information. Both kinds of profiles can provide execution; counts for instructions in the code and information on branches taken and; function invocation. Regardless of which kind of profiling you use, be careful to collect profiles; by running your code with inputs that are representative of the typical; behavior. Code that is not exercised in the profile will be optimized as if it; is unimportant, and the compiler may make poor optimization choices for code; that is disproportionately used while profiling. Differences Between Sampling and Instrumentation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Although both techniques are used for similar purposes, there are important; differences ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:89985,optimiz,optimization,89985,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance,"in other contextual elements, never the ``%s`` string. The; ``module`` element defining a module ID must always be emitted before any; other elements that refer to that module ID, so that a filter never needs to; keep track of dangling references. The second ``%s`` is the module type and it; determines what the remaining fields are. The following module types are; supported:. * ``elf:%x``. Here ``%x`` encodes an ELF Build ID. The Build ID should refer to a single; linked binary. The Build ID string is the sole way to identify the binary from; which this module was loaded. Example::. {{{module:1:libc.so:elf:83238ab56ba10497}}}. ``{{{mmap:%p:%i:...}}}``. This contextual element is used to give information about a particular region; in memory. ``%p`` is the starting address and ``%i`` gives the size in hex of the; region of memory. The ``...`` part can take different forms to give different; information about the specified region of memory. The allowed forms are the; following:. * ``load:%i:%s:%p``. This subelement informs the filter that a segment was loaded from a module.; The module is identified by its module ID ``%i``. The ``%s`` is one or more of; the letters 'r', 'w', and 'x' (in that order and in either upper or lower; case) to indicate this segment of memory is readable, writable, and/or; executable. The symbolizing filter can use this information to guess whether; an address is a likely code address or a likely data address in the given; module. The remaining ``%p`` gives the module relative address. For ELF files; the module relative address will be the ``p_vaddr`` of the associated program; header. For example if your module's executable segment has; ``p_vaddr=0x1000``, ``p_memsz=0x1234``, and was loaded at ``0x7acba69d5000``; then you need to subtract ``0x7acba69d4000`` from any address between; ``0x7acba69d5000`` and ``0x7acba69d6234`` to get the module relative address.; The starting address will usually have been rounded down to the active page; size, an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:20452,load,load,20452,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,1,['load'],['load']
Performance,"in the case of **Require** (which adds restrictions on another metadata; value) or **Override**. An example of module flags:. .. code-block:: llvm. !0 = !{ i32 1, !""foo"", i32 1 }; !1 = !{ i32 4, !""bar"", i32 37 }; !2 = !{ i32 2, !""qux"", i32 42 }; !3 = !{ i32 3, !""qux"",; !{; !""foo"", i32 1; }; }; !llvm.module.flags = !{ !0, !1, !2, !3 }. - Metadata ``!0`` has the ID ``!""foo""`` and the value '1'. The behavior; if two or more ``!""foo""`` flags are seen is to emit an error if their; values are not equal. - Metadata ``!1`` has the ID ``!""bar""`` and the value '37'. The; behavior if two or more ``!""bar""`` flags are seen is to use the value; '37'. - Metadata ``!2`` has the ID ``!""qux""`` and the value '42'. The; behavior if two or more ``!""qux""`` flags are seen is to emit a; warning if their values are not equal. - Metadata ``!3`` has the ID ``!""qux""`` and the value:. ::. !{ !""foo"", i32 1 }. The behavior is to emit an error if the ``llvm.module.flags`` does not; contain a flag with the ID ``!""foo""`` that has the value '1' after linking is; performed. Synthesized Functions Module Flags Metadata; -------------------------------------------. These metadata specify the default attributes synthesized functions should have.; These metadata are currently respected by a few instrumentation passes, such as; sanitizers. These metadata correspond to a few function attributes with significant code; generation behaviors. Function attributes with just optimization purposes; should not be listed because the performance impact of these synthesized; functions is small. - ""frame-pointer"": **Max**. The value can be 0, 1, or 2. A synthesized function; will get the ""frame-pointer"" function attribute, with value being ""none"",; ""non-leaf"", or ""all"", respectively.; - ""function_return_thunk_extern"": The synthesized function will get the; ``fn_return_thunk_extern`` function attribute.; - ""uwtable"": **Max**. The value can be 0, 1, or 2. If the value is 1, a synthesized; function will get the ``uwtable(syn",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:331031,perform,performed,331031,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"in the root canvas; `Options` menu, you will see exactly which is the selected node in the; bottom right. Right-clicking when a volume is selected will open its; context menu where several actions can be performed (e.g. drawing it). ***`Q:`*** ""OK, but now I do not want to see all the geometry, but just a particular volume and its content. How can I do this?"". ***`A:`*** Once you have set a convenient global visualization option; and level, what you need is just call the `Draw()` method of your; interesting volume. You can do this either by interacting with the; expanded tree of volumes in a ROOT browser (where the context menu of; any volume is available), either by getting a pointer to it (e.g. by; name): `gGeoManager->GetVolume(""vol_name"")->Draw();`. ### Visualization Settings and Attributes. Supposing you now understand the basic things to do for drawing the; geometry or parts of it, you still might be not happy and wishing to; have more control on it. We will describe below how you can fine-tune some; settings. Since the corresponding attributes are flags belonging to; volume and node objects, you can change them at any time (even when the; picture is already drawn) and see immediately the result. #### Colors and Line Styles. We have already described how to change the line colors for volumes. In; fact, volume objects inherit from TAttLine class so the line style or; width can also be changed:. ``` {.cpp}; myVolume->SetLineColor(kRed);; myVolume->SetLineWith(2);; myVolume->SetLineStyle(kDotted);; ```. When drawing in solid mode, the color of the drawn volume corresponds to; the line color. #### Visibility Settings. The way geometry is build forces the definition of several volumes that; does not represent real objects, but just virtual containers used for; grouping and positioning volumes together. One would not want to see; them in the picture. Since every volume is by default visible, one has; to do this sort of tuning by its own:. ``` {.cpp}; myVolumeContaine",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:141293,tune,tune,141293,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['tune'],['tune']
Performance,"in the; xrootd config file (new directive xpd.worker, see Wiki reference pages); Support for automatic reconnections in the case xrootd; is restarted; Dedicated admin area (under <xrd.admin>/.xproofd.<port>) to; keep information about active and terminated sessions, and active; clients. This is used to reguraly check the client and session; activity, to cleanup orphalin sessions and to shutdown inactive client; connections.; domain + level control of printout message. Dynamic ""per-query"" scheduling. Dynamic worker startup. It can be enabled by the cluster; administrator with the 'xpd.putrc Proof.DynamicStartup 1' directive; in the config file. The effect is that a session starts only on; the master. When a query is submitted (call to TProof::Process),; the session master contacts the scheduler.; In response it receives a list of workers and starts the worker; processes. The environment is copied from the master to the workers.; It consist of: the include and library paths, the set of enabled; packages as well as the macros loaded by the user. . Flexible and fault-tolerant workers. A packet resubmitting mechanism. When a worker dies all the; packets that it processed are resubmitted.; Added the possibility to handle dynamically removed workers and partly processed; packets (when a worker is stopped while processing a packet it finishes; the current event and the rest of the packet is reassigned to another workers).; It's done by a new method TPacketizerAdaptive::AddProcessed(TSlave *sl,; TProofProgressStatus *st, TList **) and TPacketizerAdaptive::ReassignPacket. ; Memory controlAdd; the possibility to display the memory footprint on workers and master as a; function of the entry processed (workers) or of the merging step; (master). A new button has been added to the PROOF dialog box to; retrieve and display the memory usage. On the workers about 100; measurements are recorded by default; this number can be changed with 'proof->SetParameter(""PROOF_MemLogFreq"", memlo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:1578,load,loaded,1578,proof/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html,2,['load'],['loaded']
Performance,"in; ``argmem: write``. ``dead_on_unwind``; At a high level, this attribute indicates that the pointer argument is dead; if the call unwinds, in the sense that the caller will not depend on the; contents of the memory. Stores that would only be visible on the unwind; path can be elided. More precisely, the behavior is as-if any memory written through the; pointer during the execution of the function is overwritten with a poison; value on unwind. This includes memory written by the implicit write implied; by the ``writable`` attribute. The caller is allowed to access the affected; memory, but all loads that are not preceded by a store will return poison. This attribute cannot be applied to return values. .. _gc:. Garbage Collector Strategy Names; --------------------------------. Each function may specify a garbage collector strategy name, which is simply a; string:. .. code-block:: llvm. define void @f() gc ""name"" { ... }. The supported values of *name* includes those :ref:`built in to LLVM; <builtin-gc-strategies>` and any provided by loaded plugins. Specifying a GC; strategy will cause the compiler to alter its output in order to support the; named garbage collection algorithm. Note that LLVM itself does not contain a; garbage collector, this functionality is restricted to generating machine code; which can interoperate with a collector provided externally. .. _prefixdata:. Prefix Data; -----------. Prefix data is data associated with a function which the code; generator will emit immediately before the function's entrypoint.; The purpose of this feature is to allow frontends to associate; language-specific runtime metadata with specific functions and make it; available through the function pointer while still allowing the; function pointer to be called. To access the data for a given function, a program may bitcast the; function pointer to a pointer to the constant's type and dereference; index -1. This implies that the IR symbol points just past the end of; the pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:72071,load,loaded,72071,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loaded']
Performance,"in_expect_with_probability(x, 0, .3)) {; bar();; }. **Description**:. The ``__builtin_expect_with_probability()`` builtin is typically used with; control flow conditions such as in ``if`` and ``switch`` statements to help; branch prediction. It means that its first argument ``expr`` is expected to take; the value of its second argument ``val`` with probability ``p``. ``p`` must be; within ``[0.0 ; 1.0]`` bounds. This builtin always returns the value of ``expr``. Query for this feature with ``__has_builtin(__builtin_expect_with_probability)``. ``__builtin_prefetch``; ----------------------. ``__builtin_prefetch`` is used to communicate with the cache handler to bring; data into the cache before it gets used. **Syntax**:. .. code-block:: c++. void __builtin_prefetch(const void *addr, int rw=0, int locality=3). **Example of use**:. .. code-block:: c++. __builtin_prefetch(a + i);. **Description**:. The ``__builtin_prefetch(addr, rw, locality)`` builtin is expected to be used to; avoid cache misses when the developer has a good understanding of which data; are going to be used next. ``addr`` is the address that needs to be brought into; the cache. ``rw`` indicates the expected access mode: ``0`` for *read* and ``1``; for *write*. In case of *read write* access, ``1`` is to be used. ``locality``; indicates the expected persistence of data in cache, from ``0`` which means that; data can be discarded from cache after its next use to ``3`` which means that; data is going to be reused a lot once in cache. ``1`` and ``2`` provide; intermediate behavior between these two extremes. Query for this feature with ``__has_builtin(__builtin_prefetch)``. ``__sync_swap``; ---------------. ``__sync_swap`` is used to atomically swap integers or pointers in memory. **Syntax**:. .. code-block:: c++. type __sync_swap(type *ptr, type value, ...). **Example of Use**:. .. code-block:: c++. int old_value = __sync_swap(&value, new_value);. **Description**:. The ``__sync_swap()`` builtin extends th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:115907,cache,cache,115907,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['cache'],['cache']
Performance,"inal pointer. Note again, however, that; dependence does not survive a store, so ARC does not guarantee the; continued validity of the return value past the end of the; full-expression. .. _arc.optimization.object_lifetime:. No object lifetime extension; ----------------------------. If, in the formal computation history of the program, an object ``X``; has been deallocated by the time of an observable side-effect, then; ARC must cause ``X`` to be deallocated by no later than the occurrence; of that side-effect, except as influenced by the re-ordering of the; destruction of objects. .. admonition:: Rationale. This rule is intended to prohibit ARC from observably extending the; lifetime of a retainable object, other than as specified in this; document. Together with the rule limiting the transformation of; releases, this rule requires ARC to eliminate retains and release; only in pairs. ARC's power to reorder the destruction of objects is critical to its; ability to do any optimization, for essentially the same reason that; it must retain the power to decrease the lifetime of an object.; Unfortunately, while it's generally poor style for the destruction; of objects to have arbitrary side-effects, it's certainly possible.; Hence the caveat. .. _arc.optimization.precise:. Precise lifetime semantics; --------------------------. In general, ARC maintains an invariant that a retainable object pointer held in; a ``__strong`` object will be retained for the full formal lifetime of the; object. Objects subject to this invariant have :arc-term:`precise lifetime; semantics`. By default, local variables of automatic storage duration do not have precise; lifetime semantics. Such objects are simply strong references which hold; values of retainable object pointer type, and these values are still fully; subject to the optimizations on values under local control. .. admonition:: Rationale. Applying these precise-lifetime semantics strictly would be prohibitive.; Many useful optimiz",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:83190,optimiz,optimization,83190,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimization']
Performance,"include(GetLibraryName). # Ensure that libSupport does not carry any static global initializer.; # libSupport can be embedded in use cases where we don't want to load all; # cl::opt unless we want to parse the command line.; # ManagedStatic can be used to enable lazy-initialization of globals.; # We don't use `add_flag_if_supported` as instead of compiling an empty file we; # check if the current platform is able to compile global std::mutex with this; # flag (Linux can, Darwin can't for example).; check_cxx_compiler_flag(""-Werror=global-constructors"" HAS_WERROR_GLOBAL_CTORS); if (HAS_WERROR_GLOBAL_CTORS); SET(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -Werror=global-constructors""); CHECK_CXX_SOURCE_COMPILES(""; #include <mutex>; static std::mutex TestGlobalCtorDtor;; static std::recursive_mutex TestGlobalCtorDtor2;; int main() { (void)TestGlobalCtorDtor; (void)TestGlobalCtorDtor2; return 0;}; "" LLVM_HAS_NOGLOBAL_CTOR_MUTEX); if (NOT LLVM_HAS_NOGLOBAL_CTOR_MUTEX); string(REPLACE ""-Werror=global-constructors"" """" CMAKE_CXX_FLAGS ${CMAKE_CXX_FLAGS}); endif(); endif(). if(LLVM_ENABLE_ZLIB); list(APPEND imported_libs ZLIB::ZLIB); endif(). if(LLVM_ENABLE_ZSTD); if(TARGET zstd::libzstd_shared AND NOT LLVM_USE_STATIC_ZSTD); set(zstd_target zstd::libzstd_shared); else(); set(zstd_target zstd::libzstd_static); endif(); endif(). if(LLVM_ENABLE_ZSTD); list(APPEND imported_libs ${zstd_target}); endif(). if( MSVC OR MINGW ); # libuuid required for FOLDERID_Profile usage in lib/Support/Windows/Path.inc.; # advapi32 required for CryptAcquireContextW in lib/Support/Windows/Path.inc.; set(system_libs ${system_libs} psapi shell32 ole32 uuid advapi32 ws2_32); elseif( CMAKE_HOST_UNIX ); if( HAVE_LIBRT ); set(system_libs ${system_libs} rt); endif(); if( HAVE_LIBDL ); set(system_libs ${system_libs} ${CMAKE_DL_LIBS}); endif(); if( HAVE_BACKTRACE AND NOT ""${Backtrace_LIBRARIES}"" STREQUAL """" ); # On BSDs, CMake returns a fully qualified path to the backtrace library.; # We need to remove the path and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CMakeLists.txt:162,load,load,162,interpreter/llvm-project/llvm/lib/Support/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CMakeLists.txt,1,['load'],['load']
Performance,include_directories(include). set(LLVM_LINK_COMPONENTS; AllTargetsAsmParsers; AllTargetsMCAs # CustomBehaviour and InstrPostProcess; AllTargetsDescs; AllTargetsDisassemblers; AllTargetsInfos; MCA; MC; MCParser; Support; TargetParser; ). add_llvm_tool(llvm-mca; llvm-mca.cpp; CodeRegion.cpp; CodeRegionGenerator.cpp; PipelinePrinter.cpp; Views/BottleneckAnalysis.cpp; Views/DispatchStatistics.cpp; Views/InstructionInfoView.cpp; Views/InstructionView.cpp; Views/RegisterFileStatistics.cpp; Views/ResourcePressureView.cpp; Views/RetireControlUnitStatistics.cpp; Views/SchedulerStatistics.cpp; Views/SummaryView.cpp; Views/TimelineView.cpp; ). set(LLVM_MCA_SOURCE_DIR ${CURRENT_SOURCE_DIR}); ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/CMakeLists.txt:343,Bottleneck,BottleneckAnalysis,343,interpreter/llvm-project/llvm/tools/llvm-mca/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-mca/CMakeLists.txt,1,['Bottleneck'],['BottleneckAnalysis']
Performance,"ind a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes due to this, but alternate models may be; explored in the future. Relocations Along Exceptional Edges; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Relocations along exceptional paths are currently broken in ToT. In; particular, there is current no way to represent a rethrow on a path which; also has relocations. See `this llvm-dev discussion; <https://groups.google.com/forum/#!topic/llvm-dev/AE417XjgxvI>`_ for more; detail. Bugs and Enhancements; =====================. Currently known bugs and enhancements under consideration can be; tracked by performing a `bugzilla search; <https://bugs.llvm.org/buglist.cgi?cmdtype=runnamed&namedcmd=Statepoint%20Bugs&list_id=64342>`_; for [Statepoint] in the summary field. When filing new bugs, please; use this tag so that interested parties see the newly filed bug. As; with most LLVM features, design discussions take place on the `Discourse forums <https://discourse.llvm.org>`_ and patches; should be sent to `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ for review.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:36466,perform,performing,36466,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['perform'],['performing']
Performance,"ind, the high-level idea is that we want to make a stack; variable (which lives in memory, because it is on the stack) for each; mutable object in a function. To take advantage of this trick, we need; to talk about how LLVM represents stack variables. In LLVM, all memory accesses are explicit with load/store instructions,; and it is carefully designed not to have (or need) an ""address-of""; operator. Notice how the type of the @G/@H global variables is actually; ""i32\*"" even though the variable is defined as ""i32"". What this means is; that @G defines *space* for an i32 in the global data area, but its; *name* actually refers to the address for that space. Stack variables; work the same way, except that instead of being declared with global; variable definitions, they are declared with the `LLVM alloca; instruction <../../LangRef.html#alloca-instruction>`_:. .. code-block:: llvm. define i32 @example() {; entry:; %X = alloca i32 ; type of %X is i32*.; ...; %tmp = load i32, i32* %X ; load the stack value %X from the stack.; %tmp2 = add i32 %tmp, 1 ; increment it; store i32 %tmp2, i32* %X ; store it back; ... This code shows an example of how you can declare and manipulate a stack; variable in the LLVM IR. Stack memory allocated with the alloca; instruction is fully general: you can pass the address of the stack slot; to functions, you can store it in other variables, etc. In our example; above, we could rewrite the example to use the alloca technique to avoid; using a PHI node:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; %X = alloca i32 ; type of %X is i32*.; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; store i32 %X.0, i32* %X ; Update X; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; store i32 %X.1, i32* %X ; Update X; br label %cond_next. cond_next:; %X.2 = load i32, i32* %X ; Read X; ret i32 %X.2;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:5050,load,load,5050,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,2,['load'],['load']
Performance,"independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, om",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:364439,load,loads,364439,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,ine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup;,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:212800,load,load,212800,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ines have the form of an event code and statistics. The; possible event codes are:. ``READ``; The fuzzer has read in all of the provided input samples from the corpus; directories.; ``INITED``; The fuzzer has completed initialization, which includes running each of; the initial input samples through the code under test.; ``NEW``; The fuzzer has created a test input that covers new areas of the code; under test. This input will be saved to the primary corpus directory.; ``REDUCE``; The fuzzer has found a better (smaller) input that triggers previously; discovered features (set ``-reduce_inputs=0`` to disable).; ``pulse``; The fuzzer has generated 2\ :sup:`n` inputs (generated periodically to reassure; the user that the fuzzer is still working).; ``DONE``; The fuzzer has completed operation because it has reached the specified; iteration limit (``-runs``) or time limit (``-max_total_time``).; ``RELOAD``; The fuzzer is performing a periodic reload of inputs from the corpus; directory; this allows it to discover any inputs discovered by other; fuzzer processes (see `Parallel Fuzzing`_). Each output line also reports the following statistics (when non-zero):. ``cov:``; Total number of code blocks or edges covered by executing the current corpus.; ``ft:``; libFuzzer uses different signals to evaluate the code coverage:; edge coverage, edge counters, value profiles, indirect caller/callee pairs, etc.; These signals combined are called *features* (`ft:`).; ``corp:``; Number of entries in the current in-memory test corpus and its size in bytes.; ``lim:``; Current limit on the length of new entries in the corpus. Increases over time; until the max length (``-max_len``) is reached.; ``exec/s:``; Number of fuzzer iterations per second.; ``rss:``; Current memory consumption. For ``NEW`` and ``REDUCE`` events, the output line also includes information; about the mutation operation that produced the new input:. ``L:``; Size of the new input in bytes.; ``MS: <n> <operations>``; Coun",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:16462,perform,performing,16462,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['perform'],['performing']
Performance,"ines. Dump the mappings between source lines and code addresses. .. option:: -module-syms. Display symbols (variables, functions, etc) for each compiland. .. option:: -sym-types=<types>. Type of symbols to dump when -globals, -externals, or -module-syms is; specified. (default all). .. code-block:: text. =thunks - Display thunk symbols; =data - Display data symbols; =funcs - Display function symbols; =all - Display all symbols (default). .. option:: -symbol-order=<order>. For symbols dumped via the -module-syms, -globals, or -externals options, sort; the results in specified order. .. code-block:: text. =none - Undefined / no particular sort order; =name - Sort symbols by name; =size - Sort symbols by size. .. option:: -typedefs. Display typedef types. .. option:: -types. Display all types (implies -classes, -enums, -typedefs). Other Options; +++++++++++++. .. option:: -color-output. Force color output on or off. By default, color if used if outputting to a; terminal. .. option:: -load-address=<uint>. When displaying relative virtual addresses, assume the process is loaded at the; given address and display what would be the absolute address. .. _dump_subcommand:. dump; ~~~~. USAGE: :program:`llvm-pdbutil` dump [*options*] <input PDB file>. .. program:: llvm-pdbutil dump. Summary; ^^^^^^^^^^^. The **dump** subcommand displays low level information about the structure of a; PDB file. It is used heavily by LLVM's testing infrastructure, but can also be; used for PDB forensics. It serves a role similar to that of Microsoft's; `cvdump` tool. .. note::; The **dump** subcommand exposes internal details of the file format. As; such, the reader should be familiar with :doc:`/PDB/index` before using this; command. Options; ^^^^^^^. MSF Container Options; +++++++++++++++++++++. .. option:: -streams. dump a summary of all of the streams in the PDB file. .. option:: -stream-blocks. In conjunction with :option:`-streams`, add information to the output about; what blocks the specif",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:6810,load,load-address,6810,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,1,['load'],['load-address']
Performance,"infinities. Allow floating-point optimizations that assume arguments and results are; not +-Inf.; Defaults to ``-fhonor-infinities``. If both ``-fno-honor-infinities`` and ``-fno-honor-nans`` are used,; has the same effect as specifying ``-ffinite-math-only``. .. option:: -f[no-]honor-nans. Allow floating-point optimizations that assume arguments and results are; not NaNs.; Defaults to ``-fhonor-nans``. If both ``-fno-honor-infinities`` and ``-fno-honor-nans`` are used,; has the same effect as specifying ``-ffinite-math-only``. .. option:: -f[no-]approx-func. Allow certain math function calls (such as ``log``, ``sqrt``, ``pow``, etc); to be replaced with an approximately equivalent set of instructions; or alternative math function calls. For example, a ``pow(x, 0.25)``; may be replaced with ``sqrt(sqrt(x))``, despite being an inexact result; in cases where ``x`` is ``-0.0`` or ``-inf``.; Defaults to ``-fno-approx-func``. .. option:: -f[no-]signed-zeros. Allow optimizations that ignore the sign of floating point zeros.; Defaults to ``-fsigned-zeros``. .. option:: -f[no-]associative-math. Allow floating point operations to be reassociated.; Defaults to ``-fno-associative-math``. .. option:: -f[no-]reciprocal-math. Allow division operations to be transformed into multiplication by a; reciprocal. This can be significantly faster than an ordinary division; but can also have significantly less precision. Defaults to; ``-fno-reciprocal-math``. .. option:: -f[no-]unsafe-math-optimizations. Allow unsafe floating-point optimizations.; ``-funsafe-math-optimizations`` also implies:. * ``-fapprox-func``; * ``-fassociative-math``; * ``-freciprocal-math``; * ``-fno-signed-zeros``; * ``-fno-trapping-math``; * ``-ffp-contract=fast``. ``-fno-unsafe-math-optimizations`` implies:. * ``-fno-approx-func``; * ``-fno-associative-math``; * ``-fno-reciprocal-math``; * ``-fsigned-zeros``; * ``-ftrapping-math``; * ``-ffp-contract=on``; * ``-fdenormal-fp-math=ieee``. There is ambiguity about ho",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:58711,optimiz,optimizations,58711,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,"information provided by the ``AliasAnalysis`` interface. First you initialize the AliasSetTracker by using the ""``add``"" methods to add; information about various potentially aliasing instructions in the scope you are; interested in. Once all of the alias sets are completed, your pass should; simply iterate through the constructed alias sets, using the ``AliasSetTracker``; ``begin()``/``end()`` methods. The ``AliasSet``\s formed by the ``AliasSetTracker`` are guaranteed to be; disjoint, calculate mod/ref information and volatility for the set, and keep; track of whether or not all of the pointers in the set are Must aliases. The; AliasSetTracker also makes sure that sets are properly folded due to call; instructions, and can provide a list of pointers in each set. As an example user of this, the `Loop Invariant Code Motion; <doxygen/structLICM.html>`_ pass uses ``AliasSetTracker``\s to calculate alias; sets for each loop nest. If an ``AliasSet`` in a loop is not modified, then all; load instructions from that set may be hoisted out of the loop. If any alias; sets are stored to **and** are must alias sets, then the stores may be sunk; to outside of the loop, promoting the memory location to a register for the; duration of the loop nest. Both of these transformations only apply if the; pointer argument is loop-invariant. The AliasSetTracker implementation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The AliasSetTracker class is implemented to be as efficient as possible. It; uses the union-find algorithm to efficiently merge AliasSets when a pointer is; inserted into the AliasSetTracker that aliases multiple sets. The primary data; structure is a hash table mapping pointers to the AliasSet they are in. The AliasSetTracker class must maintain a list of all of the LLVM ``Value*``\s; that are in each AliasSet. Since the hash table already has entries for each; LLVM ``Value*`` of interest, the AliasesSets thread the linked list through; these hash-table nodes to avoid having to a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:21223,load,load,21223,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['load'],['load']
Performance,"ing and objects drawing, one can provide number of URL parameters in address string like:. - file - name of the file, which will be automatically open with page loading; - files - array of file names for loading; - json - name of JSON file with stored ROOT object like histogram or canvas; - item - item name to be displayed; - opt - drawing option for the item; - items - array of items name to be displayed; - opts - array of drawing options for the items; - expand - item name(s) to be expanded in the hierarchy browser; - focus - item name to be focused on in the hierarchy browser; - title - set browser title; - dir - list files in directory on http server, see https://github.com/root-project/jsroot/issues/283; - layout - can be 'simple', 'flex', 'tabs', 'gridNxM', 'horizNMK', 'vertNMK'; - browser - layout of the browser 'fix' (default), 'float', 'no' (hidden), 'off' (fully disabled); - nobrowser - do not display file browser (same as browser=no); - float - display floating browser (same as browser=float); - status - configure status line 'no' (default), 'off' (completely disable), 'size'; - inject - name of extra JavaScript to load, see several examples in demo/ subdir; - optimize - drawing optimization 0:off, 1:only large histograms (default), 2:always; - palette - id of default color palette, 51..121 - new ROOT6 palette (default 57); - interactive - enable/disable interactive functions 0 - disable all, 1 - enable all; - noselect - hide file-selection part in the browser (only when file name is specified); - mathjax - use MathJax for latex output; - latex - 'off', 'symbols', 'normal', 'mathjax', 'alwaysmath' control of TLatex processor; - style - name of TStyle object to define global JSROOT style; - toolbar - show canvas tool buttons 'off', 'on' and 'popup', 'left' or 'right' for position, 'vert' for vertical; - divsize - fixed size in pixels for main div element like &dvisize=1500x800; - canvsize - default canvas size in pixels like &canvsize=1200x800; - optstat - ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:2136,load,load,2136,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,3,"['load', 'optimiz']","['load', 'optimization', 'optimize']"
Performance,"ing conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter removed: LLVM's SmallVectorBase; is templated over the type of fSize and fCapacity. It contains the parts of `RVec` that do not depend on the value; type.; No other classes in the hierarchy can contain data members! We expect the memory after `SmallVectorBase` to be; occupied by the small inline buffer. `SmallVectorTemplateCommon<T>`; - `getFirstEl()`: returns the address of the beginning of the small buffer; - `begin()`, `end()`, `front()`, `back()`, etc. Basically the same as the corresponding LLVM class.; It contains the parts that are independent of whether T is a POD or not. `SmallVectorTemplateBase<T, bool TriviallyCopiable>` and the specialization `SmallVectorTemplateBase<T, true>`; - `grow()`, `uninitialized_copy`, `uninitialized_move`, `push_back()`, `pop_back()`. This class contains the parts of `RVec` that can be optimized for trivially copiable types.; In particular, destruction can be skipped and memcpy can be used in place of copy/move construction.; These optimizations are inherited from LLVM's SmallVector. `RVecImpl<T>`; The analogous of LLVM's `SmallVectorImpl`, it factors out of `RVec` the parts that are independent of; the small buffer size, to limit the amount of code generated and provide a way to slice the small buffer; size when passing around `RVec` objects. `RVecN<T, N>`; It aggregates `RVecImpl` and `SmallVectorStorage` (see below) through public inheritance.; `N` is the small buffer size. `RVec<T>`; Inherits from `RVecN` and fixes the small buffer size `N` to a reasonable default.; We expect most users to use this type and only very rarely switch to `RVecN` to tweak the small buffer size. ### Helper types. - `SmallVectorAlignmentAndSize`: used to figure out the offset of the first small-buffer element in; `SmallVectorTemplateCommon::getFirstEl`; - `SmallVectorStorage`: pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:2838,optimiz,optimized,2838,math/vecops/ARCHITECTURE.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md,1,['optimiz'],['optimized']
Performance,"ing instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unreadable by the; OS to fully harden the load. ###### RIP-relative addressing is even easier to break. There is a common addressing mode idiom that is substantially harder to check:; addressing relative to the instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:30245,load,load,30245,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['load']
Performance,"ing launch times and eliminating redundant work. In fact,; the ORC APIs provide us with a layer to lazily compile LLVM IR:; *CompileOnDemandLayer*. The CompileOnDemandLayer class conforms to the layer interface described in; Chapter 2, but its addModule method behaves quite differently from the layers; we have seen so far: rather than doing any work up front, it just scans the; Modules being added and arranges for each function in them to be compiled the; first time it is called. To do this, the CompileOnDemandLayer creates two small; utilities for each function that it scans: a *stub* and a *compile; callback*. The stub is a pair of a function pointer (which will be pointed at; the function's implementation once the function has been compiled) and an; indirect jump through the pointer. By fixing the address of the indirect jump; for the lifetime of the program we can give the function a permanent ""effective; address"", one that can be safely used for indirection and function pointer; comparison even if the function's implementation is never compiled, or if it is; compiled more than once (due to, for example, recompiling the function at a; higher optimization level) and changes address. The second utility, the compile; callback, represents a re-entry point from the program into the compiler that; will trigger compilation and then execution of a function. By initializing the; function's stub to point at the function's compile callback, we enable lazy; compilation: The first attempted call to the function will follow the function; pointer and trigger the compile callback instead. The compile callback will; compile the function, update the function pointer for the stub, then execute; the function. On all subsequent calls to the function, the function pointer; will point at the already-compiled function, so there is no further overhead; from the compiler. We will look at this process in more detail in the next; chapter of this tutorial, but for now we'll trust the Compile",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst:2743,optimiz,optimization,2743,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,1,['optimiz'],['optimization']
Performance,"ing loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:217197,load,load,217197,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ing of C++ Modules. The main focus for the technology preview was not in performance until recently.; We have invested some resources in optimizations and we would like to show you; (probably outdated) performance results:. * Memory footprint -- mostly due to importing all C++ Modules at startup; we see overhead which depends on the number of preloaded modules. For; ROOT it is between 40-60 MB depending on the concrete configuration.; When the workload increases we notice that the overall memory performance; decreases in number of cases.; * Execution times -- likewise we have an execution overhead. For ; workflows which take ms the slowdown can be 2x. Increasing of the work; to seconds shows 50-60% slowdowns. The performance is dependent on many factors such as configuration of ROOT and; workflow. You can read more at our Intel IPCC-ROOT Showcase presentation; here (pp 25-33)[[8]]. #### Loading C++ Modules on Demand. In long term, we should optimize the preloading of modules to be a no-op and; avoid recursive behavior based on identifier lookup callbacks. Unfortunately,; at the moment the loading of C++ modules on demand shows significantly better; performance results. You can visit our continuous performance monitoring tool where we compare; the performance of ROOT against ROOT with a PCH [[9]].; *Note: if you get error 400, clean your cache or open a private browser session.*. ## How to use; C++ Modules in ROOT are default since v6.20 (Unix) and v6.22 (OSX). Enjoy. To disable C++ Modules in ROOT use `-Druntime_cxxmodules=Off`. ## Citing ROOT's C++ Modules; ```latex; % Peer-Reviewed Publication; %; % 22nd International Conference on Computing in High Energy and Nuclear Physics (CHEP); % 8-14 October, 2016, San Francisco, USA; %; @inproceedings{Vassilev_ROOTModules,; author = {Vassilev,V.},; title = {{Optimizing ROOT's Performance Using C++ Modules}},; journal = {Journal of Physics: Conference Series},; year = 2017,; month = {oct},; volume = {898},; number = {7},; pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:18907,optimiz,optimize,18907,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['optimiz'],['optimize']
Performance,"ing optimization for a range of function definitions, a; range-based pragma is provided. Its syntax is ``#pragma clang optimize``; followed by ``off`` or ``on``. All function definitions in the region between an ``off`` and the following; ``on`` will be decorated with the ``optnone`` attribute unless doing so would; conflict with explicit attributes already present on the function (e.g. the; ones that control inlining). .. code-block:: c++. #pragma clang optimize off; // This function will be decorated with optnone.; int foo() {; // ... code; }. // optnone conflicts with always_inline, so bar() will not be decorated.; __attribute__((always_inline)) int bar() {; // ... code; }; #pragma clang optimize on. If no ``on`` is found to close an ``off`` region, the end of the region is the; end of the compilation unit. Note that a stray ``#pragma clang optimize on`` does not selectively enable; additional optimizations when compiling at low optimization levels. This feature; can only be used to selectively disable optimizations. The pragma has an effect on functions only at the point of their definition; for; function templates, this means that the state of the pragma at the point of an; instantiation is not necessarily relevant. Consider the following example:. .. code-block:: c++. template<typename T> T twice(T t) {; return 2 * t;; }. #pragma clang optimize off; template<typename T> T thrice(T t) {; return 3 * t;; }. int container(int a, int b) {; return twice(a) + thrice(b);; }; #pragma clang optimize on. In this example, the definition of the template function ``twice`` is outside; the pragma region, whereas the definition of ``thrice`` is inside the region.; The ``container`` function is also in the region and will not be optimized, but; it causes the instantiation of ``twice`` and ``thrice`` with an ``int`` type; of; these two instantiations, ``twice`` will be optimized (because its definition; was outside the region) and ``thrice`` will not be optimized. Clang also imp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:160039,optimiz,optimizations,160039,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizations']
Performance,"ing optimizer support to your; language, and adding JIT compiler support. These additions will; demonstrate how to get nice, efficient code for the Kaleidoscope; language. Trivial Constant Folding; ========================. Our demonstration for Chapter 3 is elegant and easy to extend.; Unfortunately, it does not produce wonderful code. The IRBuilder,; however, does give us obvious optimizations when compiling simple code:. ::. ready> def test(x) 1+2+x;; Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double 3.000000e+00, %x; ret double %addtmp; }. This code is not a literal transcription of the AST built by parsing the; input. That would be:. ::. ready> def test(x) 1+2+x;; Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double 2.000000e+00, 1.000000e+00; %addtmp1 = fadd double %addtmp, %x; ret double %addtmp1; }. Constant folding, as seen above, in particular, is a very common and; very important optimization: so much so that many language implementors; implement constant folding support in their AST representation. With LLVM, you don't need this support in the AST. Since all calls to; build LLVM IR go through the LLVM IR builder, the builder itself checked; to see if there was a constant folding opportunity when you call it. If; so, it just does the constant fold and return the constant instead of; creating an instruction. Well, that was easy :). In practice, we recommend always using; ``IRBuilder`` when generating code like this. It has no ""syntactic; overhead"" for its use (you don't have to uglify your compiler with; constant checks everywhere) and it can dramatically reduce the amount of; LLVM IR that is generated in some cases (particular for languages with a; macro preprocessor or that use a lot of constants). On the other hand, the ``IRBuilder`` is limited by the fact that it does; all of its analysis inline with the code as it is built. If you take a; slightly more complex example:. ::. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:1443,optimiz,optimization,1443,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimization']
Performance,"ing sanitizer instrumentation; is disabled for this function.; ``nosanitize_coverage``; This attribute indicates that SanitizerCoverage instrumentation is disabled; for this function.; ``null_pointer_is_valid``; If ``null_pointer_is_valid`` is set, then the ``null`` address; in address-space 0 is considered to be a valid address for memory loads and; stores. Any analysis or optimization should not treat dereferencing a; pointer to ``null`` as undefined behavior in this function.; Note: Comparing address of a global variable to ``null`` may still; evaluate to false because of a limitation in querying this attribute inside; constant expressions.; ``optdebug``; This attribute suggests that optimization passes and code generator passes; should make choices that try to preserve debug info without significantly; degrading runtime performance.; This attribute is incompatible with the ``minsize``, ``optsize``, and; ``optnone`` attributes.; ``optforfuzzing``; This attribute indicates that this function should be optimized; for maximum fuzzing signal.; ``optnone``; This function attribute indicates that most optimization passes will skip; this function, with the exception of interprocedural optimization passes.; Code generation defaults to the ""fast"" instruction selector.; This attribute cannot be used together with the ``alwaysinline``; attribute; this attribute is also incompatible; with the ``minsize``, ``optsize``, and ``optdebug`` attributes. This attribute requires the ``noinline`` attribute to be specified on; the function as well, so the function is never inlined into any caller.; Only functions with the ``alwaysinline`` attribute are valid; candidates for inlining into the body of this function.; ``optsize``; This attribute suggests that optimization passes and code generator; passes make choices that keep the code size of this function low,; and otherwise do optimizations specifically to reduce code size as; long as they do not significantly impact runtime performanc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:95698,optimiz,optimized,95698,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimized']
Performance,"ing the data; ```. In the case of transformations, constructor and method to set`/`get; components exist with linear algebra matrices. The requisite is that the; matrix data are stored, for example in the case of a Lorentz rotation,; from (`0,0`) thru (`3,3`). ``` {.cpp}; TMatrixD(4,4) m;; LorentzRotation r(m); //create Lorentz r; ```. #### Connection to Other Vector Classes. The 3D and 4D vectors of the `GenVector` package can be constructed and; assigned from any vector which satisfies the following requisites:. - for 3D vectors implementing the `x()`, `y()` and `z()` methods. - for Lorentz vectors implementing the `x()`, `y()`, `z()` and `t()`; methods. ``` {.cpp}; CLHEP::Hep3Vector hv;; XYZVector v1(hv); //create 3D vector from; //CLHEP 3D Vector; HepGeom::Point3D hp;; XYZPoint p1(hp); //create a 3D p; ```. ## Linear Algebra: SMatrix Package. The ROOT Linear algebra package is documented in a separate chapter (see; ""Linear Algebra in ROOT""). `SMatrix` is a C++ package, for high; performance vector and matrix computations. It has been introduced in; ROOT v5.08. It is optimized for describing small matrices and vectors; and It can be used only in problems when the size of the matrices is; known at compile time, like in the tracking reconstruction of physics; experiments. It is based on a C++ technique, called expression; templates, to achieve an high level optimization. The C++ templates can; be used to implement vector and matrix expressions such that these; expressions can be transformed at compile time to code which is; equivalent to hand optimized code in a low-level language like FORTRAN; or C (see for example T. Veldhuizen, Expression Templates, C++ Report,; 1995). The `SMatrix` has been developed initially by T. Glebe in; Max-Planck-Institut, Heidelberg, as part of the `HeraB` analysis; framework. A subset of the original package has been now incorporated in; the ROOT distribution, with the aim to provide a stand-alone and high; performance matrix package. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:99065,perform,performance,99065,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['perform'],['performance']
Performance,"ing the stage2 compiler. **stage2-check-clang**; Depends on stage2 and runs check-clang using the stage2 compiler. **stage2-check-all**; Depends on stage2 and runs check-all using the stage2 compiler. **stage2-test-suite**; Depends on stage2 and runs the test-suite using the stage2 compiler (requires; in-tree test-suite). BOLT; ====. `BOLT <https://github.com/llvm/llvm-project/blob/main/bolt/README.md>`_; (Binary Optimization and Layout Tool) is a tool that optimizes binaries; post-link by profiling them at runtime and then using that information to; optimize the layout of the final binary among other optimizations performed; at the binary level. There are also CMake caches available to build; LLVM/Clang with BOLT. To configure a single-stage build that builds LLVM/Clang and then optimizes; it with BOLT, use the following CMake configuration:. .. code-block:: console. $ cmake <path to source>/llvm -C <path to source>/clang/cmake/caches/BOLT.cmake. Then, build the BOLT-optimized binary by running the following ninja command:. .. code-block:: console. $ ninja clang-bolt. If you're seeing errors in the build process, try building with a recent; version of Clang/LLVM by setting the CMAKE_C_COMPILER and; CMAKE_CXX_COMPILER flags to the appropriate values. It is also possible to use BOLT on top of PGO and (Thin)LTO for an even more; significant runtime speedup. To configure a three stage PGO build with ThinLTO; that optimizes the resulting binary with BOLT, use the following CMake; configuration command:. .. code-block:: console. $ cmake -G Ninja <path to source>/llvm \; -C <path to source>/clang/cmake/caches/BOLT-PGO.cmake \; -DBOOTSTRAP_LLVM_ENABLE_LLD=ON \; -DBOOTSTRAP_BOOTSTRAP_LLVM_ENABLE_LLD=ON \; -DPGO_INSTRUMENT_LTO=Thin. Then, to build the final optimized binary, build the stage2-clang-bolt target:. .. code-block:: console. $ ninja stage2-clang-bolt. 3-Stage Non-Determinism; =======================. In the ancient lore of compilers non-determinism is like the mult",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:10470,optimiz,optimized,10470,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['optimiz'],['optimized']
Performance,"ing to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those pressure increase events were; caused by contention on processor resources JFPA/JFPU0. The `critical sequence` is the most expensive sequence of instructions according; to the simulation. It is annotated to provide extra information about critical; register dependencies and resource interferences between instructions. Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler full: 272 (44.6%); LQ - Load queue full: 0; SQ - Store queue full: 0; GROUP - Static restrictions on the dispatch group: 0. Dispatch Logic - number of cycles where we saw N micro opcodes dispatched:; [# dispatched], [# cycles]; 0, 24 (3.9%); 1, 272 (44.6%); 2, 314 (51.5%). Schedulers - number of cycles where we saw N micro opcodes issued:; [# issued], [# cycles]; 0, 7 (1.1%); 1, 306 (50.2%); 2, 297 (48.7%). Scheduler's queue usage:; [1] Resource name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:28723,perform,performance,28723,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['perform'],['performance']
Performance,"ing up the calculation of ratios and differences. This calculation is in part; delegated to `TEfficiency`. A single option can be given as a parameter, that is; used to determine which procedure is chosen. The remaining option string is then; passed through to the calculation, if applicable. Several examples illustrate how to use this class. See:; `$ROOTSYS/tutorials/hist/ratioplot?.C`. * New option ""I"" allowing to draw TGraph with invisible axis (used by `TRatioPlot`);. ## New histogram drawing options. ### COL2; COL2 is a new rendering technique providing potential performance improvements; compared to the standard COL option. The performance comparison of the COL2 to; the COL option depends on the histogram and the size of the rendering region in; the current pad. In general, a small (approx. less than 100 bins per axis),; sparsely populated TH2 will render faster with the COL option. However, for larger histograms (approx. more than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:22314,perform,performance,22314,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['perform'],['performance']
Performance,"ing"" algorithm and bases the; determination of the best node-split during the training; on a random subset of variables only, which is; individually chosen for each split.; ; BDT: Move to TRandom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficiencies belonging into a bin. Since the best; background rejection is in general obtained for the lowest; possible signal efficiency, the reference signal efficiency; is the lowest value in the bin.; ; Cuts: Fixed Cuts (optimisaton) method -> event; with smallest value was not included in search for optimal; cut (thanks to Dimitris Varouchas, LAL-Orsay, for helping; us detecting the problem).; ; Genetic Algorithm: Corrected configurable random; seed in GeneticAlgorithm (thanks to David Gonzalez Maline,; CERN, for pointing this out); ; GUI: Fixes in input-variable and MVA plotting:; under/over-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:4588,perform,performance,4588,tmva/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html,2,['perform'],['performance']
Performance,"ing, static analysis, code generation,; etc.); Allow tight integration with IDEs; Use the LLVM 'Apache 2'; License. Internal Design and; Implementation:. A real-world, production quality compiler; A simple and hackable code base; A single unified parser for C, Objective C, C++, and Objective C++; Conformance with C/C++/ObjC and their variants. Of course this is only a rough outline of the goals and features of; Clang. To get a true sense of what it is all about, see the Features section, which breaks; each of these down and explains them in more detail. Why?. Development of the new front-end was started out of a need; for a compiler that allows better diagnostics, better integration with; IDEs, a license that is compatible with commercial products, and a; nimble compiler that is easy to develop and maintain. All of these were; motivations for starting work on a new front-end that could; meet these needs. Current Status. Clang is considered to; be a production quality C, Objective-C, C++ and Objective-C++ compiler when; targeting any target supported by LLVM. As example, Clang is used in; production to build performance-critical software like Chrome or Firefox.; If you are looking for source analysis or source-to-source; transformation tools, Clang is probably a great solution for you. Please see; the C++ status page or the; C status page for more information about what; standard modes and features are supported. Get it and get involved!. Start by getting the code, building it, and; playing with it. This will show you the sorts of things we can do; today and will let you have the ""Clang experience"" first hand: hopefully; it will ""resonate"" with you. :); Once you've done that, please consider getting; involved in the Clang community. The Clang developers include numerous; volunteer contributors with a variety of backgrounds. If you're; interested in; following the development of Clang, signing up for a mailing list is a good; way to learn about how the project works. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/index.html:1859,perform,performance-critical,1859,interpreter/llvm-project/clang/www/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/index.html,2,['perform'],['performance-critical']
Performance,"ing. It is relatively easy to compile a macro, either as a pre-compiled; library to load into ROOT, or as a stand-alone application, by adding; some include statements for header file or some ""dressing code"" to any; macro. ## General Remarks on ROOT macros ##. If you have a number of lines which you were able to execute at the ROOT; prompt, they can be turned into a ROOT macro by giving them a name which; corresponds to the file name without extension. The general structure; for a macro stored in file `MacroName.C` is. ``` {.cpp}; void MacroName() {; < ...; your lines of C++ code; ... >; }; ```. The macro is executed by typing. ``` {.cpp}; > root MacroName.C; ```. at the system prompt, or executed using `.x`. ``` {.cpp}; > root; root [0] .x MacroName.C; ```. at the ROOT prompt. or it can be loaded into a ROOT session and then; be executed by typing. ``` {.cpp}; root [0].L MacroName.C; root [1] MacroName();; ```. at the ROOT prompt. Note that more than one macro can be loaded this; way, as each macro has a unique name in the ROOT name space. A small set; of options can help making your plot nicer. ``` {.cpp}; gROOT->SetStyle(""Plain""); // set plain TStyle; gStyle->SetOptStat(111111); // draw statistics on plots,; // (0) for no output; gStyle->SetOptFit(1111); // draw fit results on plot,; // (0) for no ouput; gStyle->SetPalette(57); // set color map; gStyle->SetOptTitle(0); // suppress title box; ...; ```. Next, you should create a canvas for graphical output, with size,; subdivisions and format suitable to your needs, see documentation of; class `TCanvas`:. ``` {.cpp}; TCanvas c1(""c1"",""<Title>"",0,0,400,300); // create a canvas, specify position and size in pixels; c1.Divide(2,2); //set subdivisions, called pads; c1.cd(1); //change to pad 1 of canvas c1; ```. These parts of a well-written macro are pretty standard, and you should; remember to include pieces of code like in the examples above to make; sure your plots always look as you had intended. Below, in section [I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/your_first_ROOT_macro.md:1233,load,loaded,1233,documentation/primer/your_first_ROOT_macro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/your_first_ROOT_macro.md,1,['load'],['loaded']
Performance,"ing; `RooFit` classes as well as custom implementations you might be using. ### Native and proxy-based importers and exporters. `RooFitHS3` allows to different types of importers and exporters:; *Native* implementations, and *proxy-based* ones. If for a certain; class several implementations are provided, the native; implementation(s) take precedence. ### Writing your own importers and exporters: Proxy-based. Proxy-based implementations can be added very easily and without; actually writing any `C++` code -- you only need to add a short item; to a list in a `JSON` file, namely the; [export keys](https://github.com/root-project/root/blob/master/etc/RooFitHS3_wsexportkeys.json); for an exporter, or the; [factory expressions](https://github.com/root-project/root/blob/master/etc/RooFitHS3_wsfactoryexpressions.json); for an importer. This works in the following way: Every `RooFit` class performs; dependency tracking via proxies, which have names. This can be; exploited to perform the mapping of proxy names to `json` keys upon; export. In the other direction, the `RooWorkspace` has a factory; interface that allows to call any constructor via a string; interface. Hence:; - If a `RooFit` class has no other members aside from proxies, it can; be exported using a set of `export keys`.; - If all relevant members to a `RooFit` class are passed as; constructor arguments, it can be imported using a `factory; expression`. For the importer, an entry in the; [factory expressions](https://github.com/root-project/root/blob/master/etc/RooFitHS3_wsfactoryexpressions.json); needs to be added as follows:. ``` {.json}; ""<json-key>"": {; ""class"": ""<C++ class name>"",; ""arguments"": [; ""<json-key of constructor argument #1>"",; ""<json-key of constructor argument #2>"",; ...; ]; }; ```. Similarly, for the exporter, an entry in the; [export keys](https://github.com/root-project/root/blob/master/etc/RooFitHS3_wsexportkeys.json); needs to be added as follows:. ``` {.json}; ""<C++ class name>"": {; ""typ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md:3058,perform,perform,3058,roofit/doc/developers/roofit_hs3.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md,1,['perform'],['perform']
Performance,"ing; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. load atomic acquire - agent - generic 1. flat_load sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load sc0=1 sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:297853,load,load,297853,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ing; problem in Chrome/Safari, see <http://bit.ly/1wjqCQ9>. ## Changes in 3.2; 1. Support JSON objects embedding in html pages, produced by THttpServer; 2. For small resize of canvas use autoscale functionality of SVG. Only when; relative changes too large, redraw complete canvas again.; 3. Use touch-punch.min.js to process touch events with jquery-ui; 4. Even when several TH1/TGraph/TF1 objects with fill attribute overlap each other,; one able to get tooltip for underlying objects; 5. Use jquery-ui menu for context menu; 6. From context menu one could select several options for drawing; 7. Provide user interface for executing TTree::Draw on THttpServer; 8. 3D graphic (three.js) works only with IE11. ## Changes in 3.1; 1. Correctly show tooltips in case of overlapped objects; 2. Implement JSROOT.create() method to create supported; in JavaScript ROOT classes like TH1 or TGraph; 3. Fix problem with JSROOT.draw in HTML element with zero width (display:none); 4. Provide possibility to load user scripts with JSROOT.BuildSimpleGUI; and JSROOT.AssertPrerequisites, also with main index.htm; 5. Support of TCutG drawing; 6. Implement hierarchy display (former dtree) with jQuery; 7. Fix several problems in drawing optimization; 8. Implement dragging objects from hierarchy browser into existing canvas; to superimpose several objects; 9. Implement col2 and col3 draw options, using html5 canvas; 10. Support 'p' and 'p0' draw options for TH1 class. ## Development of version 3.0. ### November 2014; 1. Better font size and position in pave stats; 2. Resize/move of element only inside correspondent pad; 3. Adjust of frame size when Y-axis exceed pad limits; 4. Correct values in tooltip for THStack; 5. Exclude drawing of markers from TGraph outside visible range; 6. Drawing of canvas without TFrame object; 7. Many other small bug fixes and improvements, thanks to Maximilian Dietrich. ### October 2014; 1. Add ""shortcut icon""; 2. Add demo of online THttpServer - shell script copies dat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:69518,load,load,69518,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['load'],['load']
Performance,"ingMemoryAccess(MemoryAccess *MA, const MemoryLocation &Loc);``; returns the access clobbering memory location ``Loc``, starting at ``MA``.; Because this API does not request the clobbering access of a specific memory; access, there are no results that can be cached. Locating clobbers yourself; ^^^^^^^^^^^^^^^^^^^^^^^^^^. If you choose to make your own walker, you can find the clobber for a; ``MemoryAccess`` by walking every ``MemoryDef`` that dominates said; ``MemoryAccess``. The structure of ``MemoryDef``\ s makes this relatively simple;; they ultimately form a linked list of every clobber that dominates the; ``MemoryAccess`` that you're trying to optimize. In other words, the; ``definingAccess`` of a ``MemoryDef`` is always the nearest dominating; ``MemoryDef`` or ``MemoryPhi`` of said ``MemoryDef``. Use and Def optimization; ------------------------. ``MemoryUse``\ s keep a single operand, which is their defining or optimized; access.; Traditionally ``MemorySSA`` optimized ``MemoryUse``\ s at build-time, up to a; given threshold.; Specifically, the operand of every ``MemoryUse`` was optimized to point to the; actual clobber of said ``MemoryUse``. This can be seen in the above example; the; second ``MemoryUse`` in ``if.end`` has an operand of ``1``, which is a; ``MemoryDef`` from the entry block. This is done to make walking,; value numbering, etc, faster and easier.; As of `this revision <https://reviews.llvm.org/D121381>`_, the default was; changed to not optimize uses at build time, in order to provide the option to; reduce compile-time if the walking is not necessary in a pass. Most users call; the new API ``ensureOptimizedUses()`` to keep the previous behavior and do a; one-time optimization of ``MemoryUse``\ s, if this was not done before.; New pass users are recommended to call ``ensureOptimizedUses()``. Initially it was not possible to optimize ``MemoryDef``\ s in the same way, as we; restricted ``MemorySSA`` to one operand per access.; This was changed an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:11119,optimiz,optimized,11119,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimized']
Performance,"ings are contained in CMake Cache files.; You can build an Apple Clang compiler using the following commands:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/Apple-stage1.cmake <path to source>/llvm; $ ninja stage2-distribution. This CMake invocation configures the stage1 host compiler, and sets; CLANG_BOOTSTRAP_CMAKE_ARGS to pass the Apple-stage2.cmake cache script to the; stage2 configuration step. When you build the stage2-distribution target it builds the minimal stage1; compiler and required tools, then configures and builds the stage2 compiler; based on the settings in Apple-stage2.cmake. This pattern of using cache scripts to set complex settings, and specifically to; make later stage builds include cache scripts is common in our more advanced; build configurations. Multi-stage PGO; ===============. Profile-Guided Optimizations (PGO) is a really great way to optimize the code; clang generates. Our multi-stage PGO builds are a workflow for generating PGO; profiles that can be used to optimize clang. At a high level, the way PGO works is that you build an instrumented compiler,; then you run the instrumented compiler against sample source files. While the; instrumented compiler runs it will output a bunch of files containing; performance counters (.profraw files). After generating all the profraw files; you use llvm-profdata to merge the files into a single profdata file that you; can feed into the LLVM_PROFDATA_FILE option. Our PGO.cmake cache automates that whole process. You can use it for; configuration with CMake with the following command:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/PGO.cmake \; <path to source>/llvm. There are several additional options that the cache file also accepts to modify; the build, particularly the PGO_INSTRUMENT_LTO option. Setting this option to; Thin or Full will enable ThinLTO or full LTO respectively, further enhancing; the performance gains from a PGO b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:4925,optimiz,optimize,4925,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['optimiz'],['optimize']
Performance,"ings:. ::. ""round.dynamic""; ""round.tonearest""; ""round.downward""; ""round.upward""; ""round.towardzero""; ""round.tonearestaway"". If this argument is ""round.dynamic"" optimization passes must assume that the; rounding mode is unknown and may change at runtime. No transformations that; depend on rounding mode may be performed in this case. The other possible values for the rounding mode argument correspond to the; similarly named IEEE rounding modes. If the argument is any of these values; optimization passes may perform transformations as long as they are consistent; with the specified rounding mode. For example, 'x-0'->'x' is not a valid transformation if the rounding mode is; ""round.downward"" or ""round.dynamic"" because if the value of 'x' is +0 then; 'x-0' should evaluate to '-0' when rounding downward. However, this; transformation is legal for all other rounding modes. For values other than ""round.dynamic"" optimization passes may assume that the; actual runtime rounding mode (as defined in a target-specific manner) matches; the specified rounding mode, but this is not guaranteed. Using a specific; non-dynamic rounding mode which does not match the actual rounding mode at; runtime results in undefined behavior. The exception behavior argument is a metadata string describing the floating; point exception semantics that required for the intrinsic. This argument; must be one of the following strings:. ::. ""fpexcept.ignore""; ""fpexcept.maytrap""; ""fpexcept.strict"". If this argument is ""fpexcept.ignore"" optimization passes may assume that the; exception status flags will not be read and that floating-point exceptions will; be masked. This allows transformations to be performed that may change the; exception semantics of the original code. For example, FP operations may be; speculatively executed in this case whereas they must not be for either of the; other possible values of this argument. If the exception behavior argument is ""fpexcept.maytrap"" optimization passes; must avoid",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:869473,optimiz,optimization,869473,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"ings`. Implement a subclass of ``TargetInstrInfo``; -------------------------------------------. The final step is to hand code portions of ``XXXInstrInfo``, which implements; the interface described in ``TargetInstrInfo.h`` (see :ref:`TargetInstrInfo`).; These functions return ``0`` or a Boolean or they assert, unless overridden.; Here's a list of functions that are overridden for the SPARC implementation in; ``SparcInstrInfo.cpp``:. * ``isLoadFromStackSlot`` --- If the specified machine instruction is a direct; load from a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``isStoreToStackSlot`` --- If the specified machine instruction is a direct; store to a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``copyPhysReg`` --- Copy values between a pair of physical registers. * ``storeRegToStackSlot`` --- Store a register value to a stack slot. * ``loadRegFromStackSlot`` --- Load a register value from a stack slot. * ``storeRegToAddr`` --- Store a register value to memory. * ``loadRegFromAddr`` --- Load a register value from memory. * ``foldMemoryOperand`` --- Attempt to combine instructions of any load or; store instruction for the specified operand(s). Branch Folding and If Conversion; --------------------------------. Performance can be improved by combining instructions or by eliminating; instructions that are never reached. The ``analyzeBranch`` method in; ``XXXInstrInfo`` may be implemented to examine conditional instructions and; remove unnecessary instructions. ``analyzeBranch`` looks at the end of a; machine basic block (MBB) for opportunities for improvement, such as branch; folding and if conversion. The ``BranchFolder`` and ``IfConverter`` machine; function passes (see the source files ``BranchFolding.cpp`` and; ``IfConversion.cpp`` in the ``lib/CodeGen`` directory) call ``analyzeBranch``; to improve the control flow graph that represents the instr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:46553,load,loadRegFromStackSlot,46553,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['load'],['loadRegFromStackSlot']
Performance,"iningAccess`` of a ``MemoryDef`` is always the nearest dominating; ``MemoryDef`` or ``MemoryPhi`` of said ``MemoryDef``. Use and Def optimization; ------------------------. ``MemoryUse``\ s keep a single operand, which is their defining or optimized; access.; Traditionally ``MemorySSA`` optimized ``MemoryUse``\ s at build-time, up to a; given threshold.; Specifically, the operand of every ``MemoryUse`` was optimized to point to the; actual clobber of said ``MemoryUse``. This can be seen in the above example; the; second ``MemoryUse`` in ``if.end`` has an operand of ``1``, which is a; ``MemoryDef`` from the entry block. This is done to make walking,; value numbering, etc, faster and easier.; As of `this revision <https://reviews.llvm.org/D121381>`_, the default was; changed to not optimize uses at build time, in order to provide the option to; reduce compile-time if the walking is not necessary in a pass. Most users call; the new API ``ensureOptimizedUses()`` to keep the previous behavior and do a; one-time optimization of ``MemoryUse``\ s, if this was not done before.; New pass users are recommended to call ``ensureOptimizedUses()``. Initially it was not possible to optimize ``MemoryDef``\ s in the same way, as we; restricted ``MemorySSA`` to one operand per access.; This was changed and ``MemoryDef``\ s now keep two operands.; The first one, the defining access, is; always the previous ``MemoryDef`` or ``MemoryPhi`` in the same basic block, or; the last one in a dominating predecessor if the current block doesn't have any; other accesses writing to memory. This is needed for walking Def chains.; The second operand is the optimized access, if there was a previous call on the; walker's ``getClobberingMemoryAccess(MA)``. This API will cache information; as part of ``MA``.; Optimizing all ``MemoryDef``\ s has quadratic time complexity and is not done; by default. A walk of the uses for any MemoryDef can find the accesses that were optimized; to it.; A code snippet for s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:11853,optimiz,optimization,11853,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimization']
Performance,"inline void do(unsigned N = 1) { /* ... */ }. ``` ; The associated with libA header files form libA's full descriptor. A.h,; potentially only part of the descriptor of libA, expands to more than 26000; lines of code. ```cpp; // Main.cpp; #include ""A.h""; int main() {; do();; return 0;; }. ```; Main.cpp, reuses code from libA by including libA's descriptor and links against; libA. The full descriptor can contain thousands of files expanding to millions; of lines of code -- a common case for framework libraries, for instance. ROOT goes further and enhances C++ by allowing the following code to work without; explicitly requiring to `#include <A.h>`. Currently, ROOT's lack of support of; line `#5` is a long-standing, known limitation that is lifted with modules. ```cpp; // ROOT prompt; root [] AStruct<float> S0; // #1: implicit loading of libA. Full descriptor required.; root [] AStruct<float>* S1; // #2: implicit loading of libA. No full descriptor required.; root [] if (gFile) S1->doIt(); // #3: implicit loading of libA. Full descriptor required.; root [] gSystem->Load(""libA""); // #4: explicit loading of libA. No full descriptor required.; root [] do(); // #5: error: implicit loading of libA is currently unsupported. ```. This pattern is not only used in the ROOT prompt but in I/O hotspots such as; `ShowMembers` and `TClass::IsA`. A naive implementation of this feature would require inclusion of all reachable; library descriptors (aka header files) at ROOT startup time. Of course this is; not feasible and ROOT inserts a set of optimizations to fence itself from the; costly full header inclusion. Unfortunately, several of them are home-grown and; in a few cases inaccurate (eg line #5) causing a noticeable technical debt. Here we will briefly describe the three common layers of optimizations: ROOT PCH,; ROOTMAP and RDICT. The ROOT precompiled header (PCH) reduces the CPU and memory cost for ROOT's; most used libraries. The precompiled header technology is well-understood ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:5036,load,loading,5036,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['load'],['loading']
Performance,"inning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register allocation a second; time if the tentative V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue base address in the V#. The; result is a V# with a base address pointing to the beginning of the wavefront; scratch backing memory. The Private Segment Buffer is always requested, but the Private Segment; Wavefront Offset is only requested if it is used (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). .. _amdgpu-amdhsa-memory-model:. Memory Model; ~~~~~~~~~~~~. This section describes the mapping of the LLVM memory model onto AMDGPU machine; code (see :ref:`memmodel`). The AMDGPU backend supports the memory synchronization scopes specified in; :ref:`amdgpu-memory-scopes`. The code sequences used to implement the m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:200083,perform,perform,200083,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['perform']
Performance,"inserted. ``idx`` represents the starting element number at which ``subvec`` will be; inserted. ``idx`` must be a constant multiple of ``subvec``'s known minimum; vector length. If ``subvec`` is a scalable vector, ``idx`` is first scaled by; the runtime scaling factor of ``subvec``. The elements of ``vec`` starting at; ``idx`` are overwritten with ``subvec``. Elements ``idx`` through (``idx`` +; num_elements(``subvec``) - 1) must be valid ``vec`` indices. If this condition; cannot be determined statically but is false at runtime, then the result vector; is a :ref:`poison value <poisonvalues>`. '``llvm.vector.extract``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. ; Extract fixed type from scalable type; declare <4 x float> @llvm.vector.extract.v4f32.nxv4f32(<vscale x 4 x float> %vec, i64 <idx>); declare <2 x double> @llvm.vector.extract.v2f64.nxv2f64(<vscale x 2 x double> %vec, i64 <idx>). ; Extract scalable type from scalable type; declare <vscale x 2 x float> @llvm.vector.extract.nxv2f32.nxv4f32(<vscale x 4 x float> %vec, i64 <idx>). ; Extract fixed type from fixed type; declare <2 x double> @llvm.vector.extract.v2f64.v4f64(<4 x double> %vec, i64 <idx>). Overview:; """""""""""""""""". The '``llvm.vector.extract.*``' intrinsics extract a vector from within another; vector starting from a given index. The return type must be explicitly; specified. Conceptually, this can be used to decompose a scalable vector into; non-scalable parts, however this intrinsic can also be used on purely fixed; types. Scalable vectors can only be extracted from other scalable vectors. Arguments:; """""""""""""""""""". The ``vec`` is the vector from which we will extract a subvector. The ``idx`` specifies the starting element number within ``vec`` from which a; subvector is extracted. ``idx`` must be a constant multiple of the known-minimum; vector length of the result type. If the result type is a scalable vector,; ``idx`` is first scaled by the res",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:664504,scalab,scalable,664504,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['scalab'],['scalable']
Performance,"insic differently, for example by lowering it into a sequence of branches that guard scalar store operations. ::. ;; This instruction unconditionally stores data vector in multiple addresses; call @llvm.masked.scatter.v8i32.v8p0(<8 x i32> %value, <8 x ptr> %ptrs, i32 4, <8 x i1> <true, true, .. true>). ;; It is equivalent to a list of scalar stores; %val0 = extractelement <8 x i32> %value, i32 0; %val1 = extractelement <8 x i32> %value, i32 1; ..; %val7 = extractelement <8 x i32> %value, i32 7; %ptr0 = extractelement <8 x ptr> %ptrs, i32 0; %ptr1 = extractelement <8 x ptr> %ptrs, i32 1; ..; %ptr7 = extractelement <8 x ptr> %ptrs, i32 7; ;; Note: the order of the following stores is important when they overlap:; store i32 %val0, ptr %ptr0, align 4; store i32 %val1, ptr %ptr1, align 4; ..; store i32 %val7, ptr %ptr7, align 4. Masked Vector Expanding Load and Compressing Store Intrinsics; -------------------------------------------------------------. LLVM provides intrinsics for expanding load and compressing store operations. Data selected from a vector according to a mask is stored in consecutive memory addresses (compressed store), and vice-versa (expanding load). These operations effective map to ""if (cond.i) a[j++] = v.i"" and ""if (cond.i) v.i = a[j++]"" patterns, respectively. Note that when the mask starts with '1' bits followed by '0' bits, these operations are identical to :ref:`llvm.masked.store <int_mstore>` and :ref:`llvm.masked.load <int_mload>`. .. _int_expandload:. '``llvm.masked.expandload.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. Several values of integer, floating point or pointer data type are loaded from consecutive memory addresses and stored into the elements of a vector according to the mask. ::. declare <16 x float> @llvm.masked.expandload.v16f32 (ptr <ptr>, <16 x i1> <mask>, <16 x float> <passthru>); declare <2 x i64> @llvm.masked.expandload.v2i64 (ptr <ptr>, <2 x i1> <mask>, <2",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:854610,load,load,854610,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"insic is marked as experimental the; recommended way to express reverse operations for fixed-width vectors is still; to use a shufflevector, as that may allow for more optimization opportunities. Arguments:; """""""""""""""""""". The argument to this intrinsic must be a vector. '``llvm.experimental.vector.deinterleave2``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare {<2 x double>, <2 x double>} @llvm.experimental.vector.deinterleave2.v4f64(<4 x double> %vec1); declare {<vscale x 4 x i32>, <vscale x 4 x i32>} @llvm.experimental.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> %vec1). Overview:; """""""""""""""""". The '``llvm.experimental.vector.deinterleave2``' intrinsic constructs two; vectors by deinterleaving the even and odd lanes of the input vector. This intrinsic works for both fixed and scalable vectors. While this intrinsic; supports all vector types the recommended way to express this operation for; fixed-width vectors is still to use a shufflevector, as that may allow for more; optimization opportunities. For example:. .. code-block:: text. {<2 x i64>, <2 x i64>} llvm.experimental.vector.deinterleave2.v4i64(<4 x i64> <i64 0, i64 1, i64 2, i64 3>); ==> {<2 x i64> <i64 0, i64 2>, <2 x i64> <i64 1, i64 3>}. Arguments:; """""""""""""""""""". The argument is a vector whose type corresponds to the logical concatenation of; the two result types. '``llvm.experimental.vector.interleave2``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x double> @llvm.experimental.vector.interleave2.v4f64(<2 x double> %vec1, <2 x double> %vec2); declare <vscale x 8 x i32> @llvm.experimental.vector.interleave2.nxv8i32(<vscale x 4 x i32> %vec1, <vscale x 4 x i32> %vec2). Overview:; """""""""""""""""". The '``llvm.experimental.vector.interleave2``' intrinsic constructs a vector; by interleaving two input vectors. This intrinsic works for both fixed",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:667610,optimiz,optimization,667610,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"insic); - fmin: ``*ptr = minnum(*ptr, val)`` (match the `llvm.minnum.*`` intrinsic); - uinc_wrap: ``*ptr = (*ptr u>= val) ? 0 : (*ptr + 1)`` (increment value with wraparound to zero when incremented above input value); - udec_wrap: ``*ptr = ((*ptr == 0) || (*ptr u> val)) ? val : (*ptr - 1)`` (decrement with wraparound to input value when decremented below zero). Example:; """""""""""""""". .. code-block:: llvm. %old = atomicrmw add ptr %ptr, i32 1 acquire ; yields i32. .. _i_getelementptr:. '``getelementptr``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = getelementptr <ty>, ptr <ptrval>{, [inrange] <ty> <idx>}*; <result> = getelementptr inbounds <ty>, ptr <ptrval>{, [inrange] <ty> <idx>}*; <result> = getelementptr <ty>, <N x ptr> <ptrval>, [inrange] <vector index type> <idx>. Overview:; """""""""""""""""". The '``getelementptr``' instruction is used to get the address of a; subelement of an :ref:`aggregate <t_aggregate>` data structure. It performs; address calculation only and does not access memory. The instruction can also; be used to calculate a vector of such addresses. Arguments:; """""""""""""""""""". The first argument is always a type used as the basis for the calculations.; The second argument is always a pointer or a vector of pointers, and is the; base address to start from. The remaining arguments are indices; that indicate which of the elements of the aggregate object are indexed.; The interpretation of each index is dependent on the type being indexed; into. The first index always indexes the pointer value given as the; second argument, the second index indexes a value of the type pointed to; (not necessarily the value directly pointed to, since the first index; can be non-zero), etc. The first type indexed into must be a pointer; value, subsequent types can be arrays, vectors, and structs. Note that; subsequent types being indexed into can never be pointers, since that; would require loading the pointer before continuing calculation. The type ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:432854,perform,performs,432854,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"insic-impl. Generate intrinsic information. .. option:: -gen-opt-parser-defs. Generate options definitions. .. option:: -gen-opt-rst. Generate option RST. .. option:: -gen-pseudo-lowering. Generate pseudo instruction lowering. .. option:: -gen-register-bank. Generate register bank descriptions. .. option:: -gen-register-info. Generate registers and register classes info. .. option:: -register-info-debug. Make -gen-register-info dump register information for debugging. .. option:: -gen-searchable-tables. Generate generic searchable tables. See :doc:`TableGen BackEnds <../TableGen/BackEnds>`; for a detailed description. .. option:: -gen-subtarget. Generate subtarget enumerations. .. option:: -gen-x86-EVEX2VEX-tables. Generate X86 EVEX to VEX compress tables. .. option:: -gen-x86-fold-tables. Generate X86 fold tables. .. option:: -long-string-literals. When emitting large string tables, prefer string literals over; comma-separated char literals. This can be a readability and; compile-time performance win, but upsets some compilers. .. option:: -print-enums. Print enumeration values for a class. .. option:: -class=classname. Make -print-enums print the enumeration list for the specified class. .. option:: -print-sets. Print expanded sets for testing DAG exprs. mlir-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-avail-interface-decls. Generate availability interface declarations. .. option:: -gen-avail-interface-defs. Generate op interface definitions. .. option:: -gen-dialect-doc. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:12556,perform,performance,12556,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,1,['perform'],['performance']
Performance,"insics indicates that the variable ``X`` is; declared at line number 2 at a function level scope in function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scope information for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:17812,optimiz,optimized,17812,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimized']
Performance,"inside $\mbox{FCN}$ will be performed approximately to the same; accuracy. The accuracy M expects is called *machine precision*; (MnMachinePrecision, see [api:epsmac]) and can be printed on demand; using std::cout. If the user fools M by making internal $\mbox{FCN}$; computations in single precision, M will interpret roundoff noise as; significant and will usually either fail to find a minimum, or give; incorrect values for the parameter errors. It is therefore recommended to make sure that all computations in; $\mbox{FCN}$, as well as all methods and functions called by; $\mbox{FCN}$, are done in double precision. If for some reason the; computations cannot be done to a precision comparable with that expected; by M , the user **must** inform M of this situation with setting a; different machine precision via the; MnMachinePrecision::setPrecision(double) method. With reduced precision, the user may find that certain features; sensitive to first and second differences ($\mbox{HESSE}$,; $\mbox{MINOS}$, $\mbox{CONTOURS}$) do not work properly, in; which case the calculations must be performed in higher precision. # How to use M #. [howto:howto]. ## The $\mbox{FCN}$ Function ##. [howto:fcn]. The user must always implement a derived class of FCNBase (the; ""$\mbox{FCN}$"") which calculates the function value to be minimized; or analyzed. ![](figures/fcnbase.png). Note that when M is being used through an intermediate package such as; HippoDraw @bib-HippoDraw, then the user's $\mbox{FCN}$ may be; supplied by the this package. The name of the user's class to implement the FCNBase interface may be; chosen freely (in documentation we give it the generic name; $\mbox{FCN}$). ### FCNBase::operator()(const std::vector$<$double$>$&) ###. The meaning of the vector of parameters std::vector$<$double$>$ in the; argument of FCNBase::operator() are of course defined by the user, who; uses the values of those parameters to calculate their function value. The; order and the position of th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:27994,perform,performed,27994,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['perform'],['performed']
Performance,"instead of enumerating the libraries by hand; allows you to link them in a platform independent way. Also, if ROOT; library names change you will not need to change your Makefile. A batch program that does not have a graphic display, which creates,; fills, and saves histograms and trees, only needs to link the core; libraries (`libCore`, `libRIO`), `libHist` and `libTree`.; If ROOT needs access to other libraries, it loads them dynamically.; For example, if the **`TreeViewer`** is used, `libTreePlayer` and all; libraries `libTreePlayer` depends on are loaded also. The dependent; libraries are shown in the ROOT reference guide's library dependency; graph. The difference between reference guide `libHist` and; `libHistPainter` is that the former needs to be explicitly linked and; the latter will be loaded automatically at runtime when ROOT needs it,; by means of the Plugin Manager. plugin manager. In the Figure 1-2, the libraries represented by green boxes outside of; the core are loaded via the plugin manager plugin manager or; equivalent techniques, while the white ones are not. Of course, if one; wants to access a plugin library directly, it has to be explicitly; linked. An example of a plugin library is `libMinuit`. To create and; fill histograms you need to link `libHist.so`. If the code has a call; to fit the histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin class of which an object will be created; (e.g. **`TRFIOFile`**), the library to be loaded (in short; `lib",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:18495,load,loaded,18495,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['load'],['loaded']
Performance,"instruction pointer. We cannot change the value of; the instruction pointer register and so we have the harder problem of forcing; `%base + scale * %index + offset` to be an invalid address, by *only* changing; `%index`. The only advantage we have is that the attacker also cannot modify; `%base`. If we use the fast instruction sequence above, but only apply it to; the index, we will always access `%rip + (scale * -1) + offset`. If the; attacker can find a load which with this address happens to point to secret; data, then they can reach it. However, the loader and base libraries can also; simply refuse to map the heap, data segments, or stack within 2gb of any of the; text in the program, much like it can reserve the low 2gb of address space. ###### The flag registers again make everything hard. Unfortunately, the technique of using `orq`-instructions has a serious flaw on; x86. The very thing that makes it easy to accumulate state, the flag registers; containing predicates, causes serious problems here because they may be alive; and used by the loading instruction or subsequent instructions. On x86, the; `orq` instruction **sets** the flags and will override anything already there.; This makes inserting them into the instruction stream very hazardous.; Unfortunately, unlike when hardening the loaded value, we have no fallback here; and so we must have a fully general approach available. The first thing we must do when generating these sequences is try to analyze; the surrounding code to prove that the flags are not in fact alive or being; used. Typically, it has been set by some other instruction which just happens; to set the flags register (much like ours!) with no actual dependency. In those; cases, it is safe to directly insert these instructions. Alternatively we may; be able to move them earlier to avoid clobbering the used value. However, this may ultimately be impossible. In that case, we need to preserve; the flags around these instructions:; ```; ... .LBB",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:31476,load,loading,31476,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loading']
Performance,"instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:281846,load,load,281846,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"insysroot:` is not specified, the `/vctoolsdir:` argument is consulted; as a location to identify where the Visual C++ Tools are located. If; `/vctoolsversion:` is specified, that version is preferred, otherwise, the; highest version detected is used. 2. Consult the environment. - `/external:[VARIABLE]`. This specifies a user identified environment variable which is treated as; a path delimiter (`;`) separated list of paths to map into `-imsvc`; arguments which are treated as `-isystem`. - `INCLUDE` and `EXTERNAL_INCLUDE`. The path delimiter (`;`) separated list of paths will be mapped to; `-imsvc` arguments which are treated as `-isystem`. - `LIB` (indirectly). The linker `link.exe` or `lld-link.exe` will honour the environment; variable `LIB` which is a path delimiter (`;`) set of paths to consult for; the import libraries to use when linking the final target. The following environment variables will be consulted and used to form paths; to validate and load content from as appropriate:. - `VCToolsInstallDir`; - `VCINSTALLDIR`; - `Path`. 3. Consult `ISetupConfiguration` [Windows Only]. Assuming that the toolchain is built with `USE_MSVC_SETUP_API` defined and; is running on Windows, the Visual Studio COM interface `ISetupConfiguration`; will be used to locate the installation of the MSVC toolset. 4. Fallback to the registry [DEPRECATED]. The registry information is used to help locate the installation as a final; fallback. This is only possible for pre-VS2017 installations and is; considered deprecated. Restrictions and Limitations compared to Clang; ----------------------------------------------. Strict Aliasing; ^^^^^^^^^^^^^^^. Strict aliasing (TBAA) is always off by default in clang-cl. Whereas in clang,; strict aliasing is turned on by default for all optimization levels. To enable LLVM optimizations based on strict aliasing rules (e.g., optimizations; based on type of expressions in C/C++), user will need to explicitly pass; `-fstrict-aliasing` to clang-cl.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:197479,optimiz,optimization,197479,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,3,['optimiz'],"['optimization', 'optimizations']"
Performance,"int X) {; int t, i;; ; for (t = 0; t < N; ++t); for (i = 0; i < 4; ++i); W[t / X][i][t % X] = TK[i][t];; ; return 5;; }. We generate relatively atrocious code for this loop compared to gcc. We could also strength reduce the rem and the div:; http://www.lcs.mit.edu/pubs/pdf/MIT-LCS-TM-600.pdf. ===-------------------------------------------------------------------------===. We generate ugly code for this:. void func(unsigned int *ret, float dx, float dy, float dz, float dw) {; unsigned code = 0;; if(dx < -dw) code |= 1;; if(dx > dw) code |= 2;; if(dy < -dw) code |= 4;; if(dy > dw) code |= 8;; if(dz < -dw) code |= 16;; if(dz > dw) code |= 32;; *ret = code;; }. ===-------------------------------------------------------------------------===. %struct.B = type { i8, [3 x i8] }. define void @bar(%struct.B* %b) {; entry:; %tmp = bitcast %struct.B* %b to i32* ; <uint*> [#uses=1]; %tmp = load i32* %tmp ; <uint> [#uses=1]; %tmp3 = bitcast %struct.B* %b to i32* ; <uint*> [#uses=1]; %tmp4 = load i32* %tmp3 ; <uint> [#uses=1]; %tmp8 = bitcast %struct.B* %b to i32* ; <uint*> [#uses=2]; %tmp9 = load i32* %tmp8 ; <uint> [#uses=1]; %tmp4.mask17 = shl i32 %tmp4, i8 1 ; <uint> [#uses=1]; %tmp1415 = and i32 %tmp4.mask17, 2147483648 ; <uint> [#uses=1]; %tmp.masked = and i32 %tmp, 2147483648 ; <uint> [#uses=1]; %tmp11 = or i32 %tmp1415, %tmp.masked ; <uint> [#uses=1]; %tmp12 = and i32 %tmp9, 2147483647 ; <uint> [#uses=1]; %tmp13 = or i32 %tmp12, %tmp11 ; <uint> [#uses=1]; store i32 %tmp13, i32* %tmp8; ret void; }. We emit:. _foo:; lwz r2, 0(r3); slwi r4, r2, 1; or r4, r4, r2; rlwimi r2, r4, 0, 0, 0; stw r2, 0(r3); blr. We could collapse a bunch of those ORs and ANDs and generate the following; equivalent code:. _foo:; lwz r2, 0(r3); rlwinm r4, r2, 1, 0, 0; or r2, r2, r4; stw r2, 0(r3); blr. ===-------------------------------------------------------------------------===. Consider a function like this:. float foo(float X) { return X + 1234.4123f; }. The FP constant ends up in the constant poo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt:5499,load,load,5499,interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README.txt,2,['load'],['load']
Performance,"int b, int c) {return (a&&b) || (a&&c) || (a&&b&&c);}; Should fold to a && (b || c). Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return x | ((x & 8) ^ 8);}; Should combine to x | 8. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return x ^ ((x & 8) ^ 8);}; Should also combine to x | 8. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int x) {return ((x | -9) ^ 8) & x;}; Should combine to x & -9. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(unsigned a) {return a * 0x11111111 >> 28 & 1;}; Should combine to ""a * 0x88888888 >> 31"". Currently not optimized; with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(char* x) {if ((*x & 32) == 0) return b();}; There's an unnecessary zext in the generated code with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(unsigned long long x) {return 40 * (x >> 1);}; Should combine to ""20 * (((unsigned)x) & -2)"". Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int g(int x) { return (x - 10) < 0; }; Should combine to ""x <= 9"" (the sub has nsw). Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int g(int x) { return (x + 10) < 0; }; Should combine to ""x < -10"" (the add has nsw). Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:26052,optimiz,optimized,26052,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['optimiz'],['optimized']
Performance,"int' is called first,; // then 'h()', that throws an exception and eventually; // 'g()' is never called.; f(g(new int), h()); // warn: 'g()' may never be called.; }. memory.DstBufferTooSmall; (C, C++); Destination buffer passed to memory function is too small.; Note: security.insecureAPI.strcpy currently warns; on usage of strcpy and suggests to replace it.; Note: alpha.unix.CStringChecker contains some similar checks.; Source: CWE-120. void test() {; const char* s1 = ""abc"";; char *s2 = new char;; strcpy(s2, s1); // warn; }. void test() {; int* p1 = new int[3];; int* p2 = new int;; memcpy(p2, p1, 3); // warn; }. memory.NegativeArraySize; (C, C++); 'n' is used to specify the buffer size may be negative.; Note: possibly an enhancement to ; alpha.security.MallocOverflow.; Source: CWE-20,; Example 2. void test() {; int *p;; int n1 = -1;; p = new int[n1]; // warn; }. memory.ZeroAlloc; (C, C++); Allocation of zero bytes.; Note: an enhancement to unix.Malloc.; Note: unix.API perform C-checks for zero; allocation. This should be moved to unix.Malloc.; Source: C++03 3.7.3.1p2; C++11 3.7.4.1p2. #include <stdlib.h>. void test() {; int *p = malloc(0); // warn; free(p);; }. void test() {; int *p = new int[0]; // warn; delete[] p;; }. D6178. constructors/destructors. Name, DescriptionExampleProgress. ctordtor.ExptInsideDtor; (C++); It is dangerous to let an exception leave a destructor.; Using try..catch solves the problem.; Source: Scott Meyers ""More Effective C++"", item 11: Prevent exceptions from; leaving destructors. class A {; A() {}; ~A() { throw 1; } // warn; };. void f() throw(int);. class A {; A() {}; ~A() { f(); } // warn; };. ctordtor.PlacementSelfCopy; (C++11); For a placement copy or move, it is almost certainly an error if the; constructed object is also the object being copied from. class A {};. void test(A *dst, A *src) {; ::new (dst) A(*dst); // warn (should be 'src'); }. exceptions. Name, DescriptionExampleProgress. exceptions.ThrowSpecButNotThrow; (C++); Functi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:1909,perform,perform,1909,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,2,['perform'],['perform']
Performance,"int)>, __promise = {count = 1}, v = 43, a = 45, __coro_index = 1 '\001', struct_std__suspend_always_0 = {__int_8 = 0 '\000'},; class_await_counter_1 = {__int_8 = 0 '\000'}, class_await_counter_2 = {__int_8 = 0 '\000'}, struct_std__suspend_always_3 = {__int_8 = 0 '\000'}}. In the above, the values of `v` and `a` are clearly expressed, as are the; temporary values for `await_counter` (`class_await_counter_1` and; `class_await_counter_2`) and `std::suspend_always` (; `struct_std__suspend_always_0` and `struct_std__suspend_always_3`). The index; of the current suspension point of the coroutine is emitted as `__coro_index`.; In the above example, the `__coro_index` value of `1` means the coroutine; stopped at the second suspend point (Note that `__coro_index` is zero indexed); which is the first `co_await await_counter{};` in `coro_task`. Note that the; first initial suspend point is the compiler generated; `co_await promise_type::initial_suspend()`. However, when optimizations are enabled, the printed result changes drastically:. .. parsed-literal::. {__resume_fn = 0x401280 <coro_task(int)>, __destroy_fn = 0x401390 <coro_task(int)>, __promise = {count = 1}, __int_32_0 = 43, __coro_index = 1 '\001'}. Unused values are optimized out, as well as the name of the local variable `a`.; The only information remained is the value of a 32 bit integer. In this simple; case, it seems to be pretty clear that `__int_32_0` represents `a`. However, it; is not true. An important note with optimization is that the value of a variable may not; properly express the intended value in the source code. For example:. .. code-block:: c++. static task coro_task(int v) {; int a = v;; co_await await_counter{};; a++; // __int_32_0 is 43 here; std::cout << a << ""\n"";; a++; // __int_32_0 is still 43 here; std::cout << a << ""\n"";; a++; // __int_32_0 is still 43 here!; std::cout << a << ""\n"";; co_await await_counter{};; a++; // __int_32_0 is still 43 here!!; std::cout << a << ""\n"";; a++; // Why is __in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst:8316,optimiz,optimizations,8316,interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,1,['optimiz'],['optimizations']
Performance,"int> struct AStruct {; void doIt() { /*...*/ }; std::string Name; ; std::vector<U> Collection;; // ...; };. template<class T, class U = AStruct<T>>; inline void freeFunction() { /* ... */ }; inline void do(unsigned N = 1) { /* ... */ }. ``` ; The associated with libA header files form libA's full descriptor. A.h,; potentially only part of the descriptor of libA, expands to more than 26000; lines of code. ```cpp; // Main.cpp; #include ""A.h""; int main() {; do();; return 0;; }. ```; Main.cpp, reuses code from libA by including libA's descriptor and links against; libA. The full descriptor can contain thousands of files expanding to millions; of lines of code -- a common case for framework libraries, for instance. ROOT goes further and enhances C++ by allowing the following code to work without; explicitly requiring to `#include <A.h>`. Currently, ROOT's lack of support of; line `#5` is a long-standing, known limitation that is lifted with modules. ```cpp; // ROOT prompt; root [] AStruct<float> S0; // #1: implicit loading of libA. Full descriptor required.; root [] AStruct<float>* S1; // #2: implicit loading of libA. No full descriptor required.; root [] if (gFile) S1->doIt(); // #3: implicit loading of libA. Full descriptor required.; root [] gSystem->Load(""libA""); // #4: explicit loading of libA. No full descriptor required.; root [] do(); // #5: error: implicit loading of libA is currently unsupported. ```. This pattern is not only used in the ROOT prompt but in I/O hotspots such as; `ShowMembers` and `TClass::IsA`. A naive implementation of this feature would require inclusion of all reachable; library descriptors (aka header files) at ROOT startup time. Of course this is; not feasible and ROOT inserts a set of optimizations to fence itself from the; costly full header inclusion. Unfortunately, several of them are home-grown and; in a few cases inaccurate (eg line #5) causing a noticeable technical debt. Here we will briefly describe the three common layers of optim",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:4854,load,loading,4854,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['load'],['loading']
Performance,"inter is dereferenceable, the cast is assumed to be; reversible (i.e. casting the result back to the original address space; should yield the original bit pattern). Example:; """""""""""""""". .. code-block:: llvm. %X = addrspacecast ptr %x to ptr addrspace(1); %Y = addrspacecast ptr addrspace(1) %y to ptr addrspace(2); %Z = addrspacecast <4 x ptr> %z to <4 x ptr addrspace(3)>. .. _otherops:. Other Operations; ----------------. The instructions in this category are the ""miscellaneous"" instructions,; which defy better classification. .. _i_icmp:. '``icmp``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = icmp <cond> <ty> <op1>, <op2> ; yields i1 or <N x i1>:result. Overview:; """""""""""""""""". The '``icmp``' instruction returns a boolean value or a vector of; boolean values based on comparison of its two integer, integer vector,; pointer, or pointer vector operands. Arguments:; """""""""""""""""""". The '``icmp``' instruction takes three operands. The first operand is; the condition code indicating the kind of comparison to perform. It is; not a value, just a keyword. The possible condition codes are:. .. _icmp_md_cc:. #. ``eq``: equal; #. ``ne``: not equal; #. ``ugt``: unsigned greater than; #. ``uge``: unsigned greater or equal; #. ``ult``: unsigned less than; #. ``ule``: unsigned less or equal; #. ``sgt``: signed greater than; #. ``sge``: signed greater or equal; #. ``slt``: signed less than; #. ``sle``: signed less or equal. The remaining two arguments must be :ref:`integer <t_integer>` or; :ref:`pointer <t_pointer>` or integer :ref:`vector <t_vector>` typed. They; must also be identical types. Semantics:; """""""""""""""""""". The '``icmp``' compares ``op1`` and ``op2`` according to the condition; code given as ``cond``. The comparison performed always yields either an; :ref:`i1 <t_integer>` or vector of ``i1`` result, as follows:. .. _icmp_md_cc_sem:. #. ``eq``: yields ``true`` if the operands are equal, ``false``; otherwise. No sign interpretation is necessary or performed.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:459963,perform,perform,459963,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"intermediate language (instead of bitcode). .. option:: -d. If specified, :program:`llvm-link` prints a human-readable version of the; output bitcode file to standard error. .. option:: --help. Print a summary of command line options. .. option:: -v. Verbose mode. Print information about what :program:`llvm-link` is doing.; This typically includes a message for each bitcode file linked in and for each; library found. .. option:: --override <filename>. Adds the passed-in file to the link and overrides symbols that have already; been declared with the definitions in the file that is passed in. This flag; can be specified multiple times to have multiple files act as overrides. If; a symbol is declared more than twice, the definition from the file declared; last takes precedence. .. option:: --import <function:filename>. Specify a function that should be imported from the specified file for; linking with ThinLTO. This option can be specified multiple times to import; multiple functions. .. option:: --summary-index <filename>. Specify the path to a file containing the module summary index with the; results of an earlier ThinLTO link. This option is required when ; `--import` is used. .. option:: --internalize. Internalize the linked symbols. .. option:: --disable-debug-info-type-map. Disables the use of a uniquing type map for debug info. .. option:: --only-needed. Link only needed symbols. .. option:: --disable-lazy-loading. Disable lazy module loading. .. option:: --suppress-warnings. Suppress all linker warnings. .. option:: --preserve-bc-uselistorder; ; Preserve the use-list order when writing LLVM bitcode. .. option:: --preserve-ll-uselistorder. Preserve the use-list order when writing LLVM assembly. .. option:: --ignore-non-bitcode. Do not error out when a non-bitcode file is encountered while processing; an archive. EXIT STATUS; -----------. If :program:`llvm-link` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-link.rst:2305,load,loading,2305,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-link.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-link.rst,2,['load'],['loading']
Performance,"into 8-bit chunks, and endianness describes the order in which these chunks are laid out in memory. A ""little endian"" layout has the least significant byte first (lowest in memory address). A ""big endian"" layout has the *most* significant byte first. This means that when loading an item from big endian memory, the lowest 8-bits in memory must go in the most significant 8-bits, and so forth. ``LDR`` and ``LD1``; ===================. .. figure:: ARM-BE-ldr.png; :align: right. Big endian vector load using ``LDR``. A vector is a consecutive sequence of items that are operated on simultaneously. To load a 64-bit vector, 64 bits need to be read from memory. In little endian mode, we can do this by just performing a 64-bit load - ``LDR q0, [foo]``. However if we try this in big endian mode, because of the byte swapping the lane indices end up being swapped! The zero'th item as laid out in memory becomes the n'th lane in the vector. .. figure:: ARM-BE-ld1.png; :align: right. Big endian vector load using ``LD1``. Note that the lanes retain the correct ordering. Because of this, the instruction ``LD1`` performs a vector load but performs byte swapping not on the entire 64 bits, but on the individual items within the vector. This means that the register content is the same as it would have been on a little endian system. It may seem that ``LD1`` should suffice to perform vector loads on a big endian machine. However there are pros and cons to the two approaches that make it less than simple which register format to pick. There are two options:. 1. The content of a vector register is the same *as if* it had been loaded with an ``LDR`` instruction.; 2. The content of a vector register is the same *as if* it had been loaded with an ``LD1`` instruction. Because ``LD1 == LDR + REV`` and similarly ``LDR == LD1 + REV`` (on a big endian system), we can simulate either type of load with the other type of load plus a ``REV`` instruction. So we're not deciding which instructions to use, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:3186,load,load,3186,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['load'],['load']
Performance,"intrinsic converts its unsigned integer operand to the; :ref:`floating-point <t_floating>` return type. The operation has a mask and; an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm.vp.uitofp``' intrinsic takes a value to cast as its first operand.; The value to cast must be vector of :ref:`integer <t_integer>` type. The; return type is the type to cast the value to. The return type must be a vector; of :ref:`floating-point <t_floating>` type. The second operand is the vector; mask. The return type, the value to cast, and the vector mask have the same; number of elements. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.uitofp``' intrinsic interprets its first operand as an unsigned; integer quantity and converts it to the corresponding floating-point value. If; the value cannot be exactly represented, it is rounded using the default; rounding mode. The conversion is performed on lane positions below the; explicit vector length and where the vector mask is true. Masked-off lanes are; ``poison``. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.uitofp.v4f32.v4i32(<4 x i32> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = uitofp <4 x i32> %a to <4 x float>; %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_sitofp:. '``llvm.vp.sitofp.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.sitofp.v16f32.v16i32 (<16 x i32> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.sitofp.nxv4f32.nxv4i32 (<vscale x 4 x i32> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.sitofp.v256f64.v256i64 (<256 x i64> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.sitofp``' intrinsic converts its signed integer oper",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:810410,perform,performed,810410,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"intrinsic, together with :ref:`deoptimization operand bundles; <deopt_opbundles>`, allows frontends to express guards or checks on; optimistic assumptions made during compilation. The semantics of; ``@llvm.experimental.guard`` is defined in terms of; ``@llvm.experimental.deoptimize`` -- its body is defined to be; equivalent to:. .. code-block:: text. define void @llvm.experimental.guard(i1 %pred, <args...>) {; %realPred = and i1 %pred, undef; br i1 %realPred, label %continue, label %leave [, !make.implicit !{}]. leave:; call void @llvm.experimental.deoptimize(<args...>) [ ""deopt""() ]; ret void. continue:; ret void; }. with the optional ``[, !make.implicit !{}]`` present if and only if it; is present on the call site. For more details on ``!make.implicit``,; see :doc:`FaultMaps`. In words, ``@llvm.experimental.guard`` executes the attached; ``""deopt""`` continuation if (but **not** only if) its first argument; is ``false``. Since the optimizer is allowed to replace the ``undef``; with an arbitrary value, it can optimize guard to fail ""spuriously"",; i.e. without the original condition being false (hence the ""not only; if""); and this allows for ""check widening"" type optimizations. ``@llvm.experimental.guard`` cannot be invoked. After ``@llvm.experimental.guard`` was first added, a more general; formulation was found in ``@llvm.experimental.widenable.condition``.; Support for ``@llvm.experimental.guard`` is slowly being rephrased in; terms of this alternate. '``llvm.experimental.widenable.condition``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i1 @llvm.experimental.widenable.condition(). Overview:; """""""""""""""""". This intrinsic represents a ""widenable condition"" which is; boolean expressions with the following property: whether this; expression is `true` or `false`, the program is correct and; well-defined. Together with :ref:`deoptimization operand bundles <deopt_opbundles>`,; ``@llvm.experimental.widenable.condition`` al",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:945967,optimiz,optimizer,945967,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['optimiz'],"['optimize', 'optimizer']"
Performance,"intrinsics provide an alternative; conversion, which will saturate towards the smallest and largest representable; integer values instead. '``llvm.fptoui.sat.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.fptoui.sat`` on any; floating-point argument type and any integer result type, or vectors thereof.; Not all targets may support all types, however. ::. declare i32 @llvm.fptoui.sat.i32.f32(float %f); declare i19 @llvm.fptoui.sat.i19.f64(double %f); declare <4 x i100> @llvm.fptoui.sat.v4i100.v4f128(<4 x fp128> %f). Overview:; """""""""""""""""". This intrinsic converts the argument into an unsigned integer using saturating; semantics. Arguments:; """""""""""""""""""". The argument may be any floating-point or vector of floating-point type. The; return value may be any integer or vector of integer type. The number of vector; elements in argument and return must be the same. Semantics:; """""""""""""""""""". The conversion to integer is performed subject to the following rules:. - If the argument is any NaN, zero is returned.; - If the argument is smaller than zero (this includes negative infinity),; zero is returned.; - If the argument is larger than the largest representable unsigned integer of; the result type (this includes positive infinity), the largest representable; unsigned integer is returned.; - Otherwise, the result of rounding the argument towards zero is returned. Example:; """""""""""""""". .. code-block:: text. %a = call i8 @llvm.fptoui.sat.i8.f32(float 123.9) ; yields i8: 123; %b = call i8 @llvm.fptoui.sat.i8.f32(float -5.7) ; yields i8: 0; %c = call i8 @llvm.fptoui.sat.i8.f32(float 377.0) ; yields i8: 255; %d = call i8 @llvm.fptoui.sat.i8.f32(float 0xFFF8000000000000) ; yields i8: 0. '``llvm.fptosi.sat.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.fptosi.sat`` on any; floating-point argument type and any integer result type, or vectors ther",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:684495,perform,performed,684495,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"ints are preserved after; each of these passes:. IRTranslator. The representation must be gMIR, MIR, or a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually transition the gMIR to MIR. Legalizer. No illegal operations must remain or be introduced after this pass. Register Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this probl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:2784,optimiz,optimization,2784,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,1,['optimiz'],['optimization']
Performance,"ints in a parameter scan don't converge due to numerical or model instabilities.; These points will be skipped, and HypoTestInverter can continue.; - Tweak pull / residual plots. ROOT automatically zoomed out a bit when a pull / residual plot is created. Now, the; axis range of the original plot is transferred to the residual plot, so the pulls can be drawn below the main plot. ### Massive speed up of RooFit's `BatchMode` on CPUs with vector extensions. RooFit's [`BatchMode`](https://root.cern/doc/master/classRooAbsPdf.html#a8f802a3a93467d5b7b089e3ccaec0fa8) has been around; [since ROOT 6.20](https://root.cern/doc/v620/release-notes.html#fast-function-evaluation-and-vectorisation), but to; fully use vector extensions of modern CPUs, a manual compilation of ROOT was necessary, setting the required compiler flags. Now, RooFit comes with dedicated computation libraries, each compiled for a specific CPU architecture. When RooFit is loaded for the; first time, ROOT inspects the CPU capabilities, and loads the fastest supported version of this computation library.; This means that RooFit can now use vector extensions such as AVX2 without being recompiled, which enables a speed up of up to 4x for certain computations.; Combined with better data access patterns (~3x speed up, ROOT 6.20), computations with optimised PDFs speed up between 4x and 16x. The fast `BatchMode` now also works in combination with multi processing (`NumCPU`) and with binned data (`RooDataHist`). See [Demo notebook in SWAN](https://github.com/hageboeck/rootNotebooks),; [EPJ Web Conf. 245 (2020) 06007](https://www.epj-conferences.org/articles/epjconf/abs/2020/21/epjconf_chep2020_06007/epjconf_chep2020_06007.html),; [arxiv:2012.02746](https://arxiv.org/abs/2012.02746). #### RooBatchCompute Library. The library that contains the optimised computation functions is called `RooBatchCompute`. The PDFs contained in this library are highly optimized, and there is currently work in progress for further optimizat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:15432,load,loaded,15432,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,2,['load'],"['loaded', 'loads']"
Performance,"inv. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:296851,load,load,296851,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"invalidating the; caches. 5. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:272195,perform,performing,272195,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:249446,load,loads,249446,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"invariant.group.p0(ptr <ptr>). Overview:; """""""""""""""""". The '``llvm.strip.invariant.group``' intrinsic can be used when an invariant; established by ``invariant.group`` metadata no longer holds, to obtain a new pointer; value that does not carry the invariant information. It is an experimental; intrinsic, which means that its semantics might change in the future. Arguments:; """""""""""""""""""". The ``llvm.strip.invariant.group`` takes only one argument, which is a pointer; to the memory. Semantics:; """""""""""""""""""". Returns another pointer that aliases its argument but which has no associated; ``invariant.group`` metadata.; It does not read any memory and can be speculated. .. _constrainedfp:. Constrained Floating-Point Intrinsics; -------------------------------------. These intrinsics are used to provide special handling of floating-point; operations when specific rounding mode or floating-point exception behavior is; required. By default, LLVM optimization passes assume that the rounding mode is; round-to-nearest and that floating-point exceptions will not be monitored.; Constrained FP intrinsics are used to support non-default rounding modes and; accurately preserve exception behavior without compromising LLVM's ability to; optimize FP code when the default behavior is used. If any FP operation in a function is constrained then they all must be; constrained. This is required for correct LLVM IR. Optimizations that; move code around can create miscompiles if mixing of constrained and normal; operations is done. The correct way to mix constrained and less constrained; operations is to use the rounding mode and exception handling metadata to; mark constrained intrinsics as having LLVM's default behavior. Each of these intrinsics corresponds to a normal floating-point operation. The; data arguments and the return value are the same as the corresponding FP; operation. The rounding mode argument is a metadata string specifying what; assumptions, if any, the optimizer can make when tr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:867344,optimiz,optimization,867344,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"invariants and rules for static analysis tools, such as the `Clang Static; Analyzer <https://clang-analyzer.llvm.org/>`_. These attributes are documented; in the analyzer's `list of source-level annotations; <https://clang-analyzer.llvm.org/annotations.html>`_. Extensions for Dynamic Analysis; ===============================. Use ``__has_feature(address_sanitizer)`` to check if the code is being built; with :doc:`AddressSanitizer`. Use ``__has_feature(thread_sanitizer)`` to check if the code is being built; with :doc:`ThreadSanitizer`. Use ``__has_feature(memory_sanitizer)`` to check if the code is being built; with :doc:`MemorySanitizer`. Use ``__has_feature(dataflow_sanitizer)`` to check if the code is being built; with :doc:`DataFlowSanitizer`. Use ``__has_feature(safe_stack)`` to check if the code is being built; with :doc:`SafeStack`. Extensions for selectively disabling optimization; =================================================. Clang provides a mechanism for selectively disabling optimizations in functions; and methods. To disable optimizations in a single function definition, the GNU-style or C++11; non-standard attribute ``optnone`` can be used. .. code-block:: c++. // The following functions will not be optimized.; // GNU-style attribute; __attribute__((optnone)) int foo() {; // ... code; }; // C++11 attribute; [[clang::optnone]] int bar() {; // ... code; }. To facilitate disabling optimization for a range of function definitions, a; range-based pragma is provided. Its syntax is ``#pragma clang optimize``; followed by ``off`` or ``on``. All function definitions in the region between an ``off`` and the following; ``on`` will be decorated with the ``optnone`` attribute unless doing so would; conflict with explicit attributes already present on the function (e.g. the; ones that control inlining). .. code-block:: c++. #pragma clang optimize off; // This function will be decorated with optnone.; int foo() {; // ... code; }. // optnone conflicts with always",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:158609,optimiz,optimizations,158609,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizations']
Performance,"ion 5,; and the new semantics for DWARF Version 6 which has been done for some; other features. Another option is to limit the execution to be on the same stack only to; the evaluation of an expression E that is the value of a; ``DW_AT_location`` attribute of a ``DW_TAG_dwarf_procedure`` debugging; information entry. The DWARF would be ill-formed if E is a location list; expression that does not match exactly one location list entry. In all; other cases the evaluation of an expression E that is the value of a; ``DW_AT_location`` attribute would evaluate E with the current context,; except the result kind is a location description, the compilation unit; is the one that contains D, and the initial stack is empty. The location; description result is pushed on the stack. * If D has a ``DW_AT_const_value`` attribute with a value V, then it is as; if a ``DW_OP_implicit_value V`` operation was executed. *This allows a call operation to be used to compute the location; description for any variable or formal parameter regardless of whether the; producer has optimized it to a constant. This is consistent with the*; ``DW_OP_implicit_pointer`` *operation.*. .. note::. Alternatively, could deprecate using ``DW_AT_const_value`` for; ``DW_TAG_variable`` and ``DW_TAG_formal_parameter`` debugger information; entries that are constants and instead use ``DW_AT_location`` with an; operation expression that results in a location description with one; implicit location description. Then this rule would not be required. * Otherwise, there is no effect and no changes are made to the stack. .. note::. In DWARF Version 5, if D does not have a ``DW_AT_location`` then; ``DW_OP_call*`` is defined to have no effect. It is unclear that this is; the right definition as a producer should be able to rely on using; ``DW_OP_call*`` to get a location description for any non-\; ``DW_TAG_dwarf_procedure`` debugging information entries. Also, the; producer should not be creating DWARF with ``DW_OP_call*`` ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:80542,optimiz,optimized,80542,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimized']
Performance,"ion and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L1 caches use an L2 cache shared by all SAs on the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each L1 quadrant of a single SA accesses a different L2 channel. Each L1; quadrant has a separate request queue per L2 channel. Therefore, the vector; and scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence.; * On GFX10.3 and GFX11 a memory attached last level (MALL) cache exists for GPU memory.; The MALL cache is fully coherent with GPU memory and has no impact on system; coherence. All agents (GPU and CPU) access GPU memory through the MALL cache. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensure",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:339570,cache,cache,339570,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"ion appropriately (to and from; the MakeClass mode (also known as the decomposed object mode)). This can also be; used to reset the mode of some branch with a MakeClass/MakeSelector file. Dramatically reduce the amount of memory allocation induces by the management of the TBasket and TBuffer; for each branch. Instead of creating one TBasket object and one TBuffer object and its associated memory buffer; for each onfile basket of each branch, we now create only one TBasket and one TBuffer object for the lifetime of; each branch. The memory buffer associated with the TBuffer object is also created once and rarely reallocated;; it is reallocated only when the buffer size is reset (for example by the AutoFlush mechanism) and when the user; object do not fit in the currently allocated memory (but we do not shrink it after that. The same minization; is applied to the scratch area used to read the compressed version of a basket from the file.; In TTree and TChain's LoadTree fReadEntry is now set to -1 in case of failure to find the proper row.; In TTree::CloneTree, TChain::Merge and TTree::CopyEntries introduces more flexibility; in the handling of the case where a TTreeIndex is 'missing' in one or more of the; TTree objects being collated. If the tree or any of the underlying tree of the chain has an index,; that index and any index in the subsequent underlying TTree objects will be merged. There are currently three 'options'; to control this merging:; ; NoIndex : all the TTreeIndex object are dropped.; DropIndexOnError : if any of the underlying TTree object do no have a TTreeIndex,; they are all dropped.; AsIsIndexOnError [default]: In case of missing TTreeIndex, the resulting TTree index has gaps.; BuildIndexOnError : If any of the underlying TTree object do no have a TTreeIndex,; all TTreeIndex are 'ignored' and the mising piece are rebuilt. Previously the index were kept only if the first files had an index and if there was any missing index,; the resulting index had ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:1124,Load,LoadTree,1124,tree/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html,1,['Load'],['LoadTree']
Performance,"ion being an implicit_def. The; proper solution is to add new ISD opcodes for the no-output variant. DAG; combiner can then transform the node before it gets to target node selection. Problem #2 is we are adding a whole bunch of x86 atomic instructions when in; fact these instructions are identical to the non-lock versions. We need a way to; add target specific information to target nodes and have this information; carried over to machine instructions. Asm printer (or JIT) can use this; information to add the ""lock"" prefix. //===---------------------------------------------------------------------===//. struct B {; unsigned char y0 : 1;; };. int bar(struct B* a) { return a->y0; }. define i32 @bar(%struct.B* nocapture %a) nounwind readonly optsize {; %1 = getelementptr inbounds %struct.B* %a, i64 0, i32 0; %2 = load i8* %1, align 1; %3 = and i8 %2, 1; %4 = zext i8 %3 to i32; ret i32 %4; }. bar: # @bar; # %bb.0:; movb (%rdi), %al; andb $1, %al; movzbl %al, %eax; ret. Missed optimization: should be movl+andl. //===---------------------------------------------------------------------===//. The x86_64 abi says:. Booleans, when stored in a memory object, are stored as single byte objects the; value of which is always 0 (false) or 1 (true). We are not using this fact:. int bar(_Bool *a) { return *a; }. define i32 @bar(i8* nocapture %a) nounwind readonly optsize {; %1 = load i8* %a, align 1, !tbaa !0; %tmp = and i8 %1, 1; %2 = zext i8 %tmp to i32; ret i32 %2; }. bar:; movb (%rdi), %al; andb $1, %al; movzbl %al, %eax; ret. GCC produces. bar:; movzbl (%rdi), %eax; ret. //===---------------------------------------------------------------------===//. Take the following C code:; int f(int a, int b) { return (unsigned char)a == (unsigned char)b; }. We generate the following IR with clang:; define i32 @f(i32 %a, i32 %b) nounwind readnone {; entry:; %tmp = xor i32 %b, %a ; <i32> [#uses=1]; %tmp6 = and i32 %tmp, 255 ; <i32> [#uses=1]; %cmp = icmp eq i32 %tmp6, 0 ; <i1> [#uses=1]; %c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:35180,optimiz,optimization,35180,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['optimiz'],['optimization']
Performance,"ion is `PHI` instructions: these become implicit definitions at; control flow merges once regalloc finishes, and any debug numbers attached to; `PHI` instructions are lost. To circumvent this, debug numbers of `PHI`s are; recorded at the start of register allocation (`phi-node-elimination`), then; `DBG_PHI` instructions are inserted after regalloc finishes. This requires some; maintenance of which register a variable is located in during regalloc, but at; single positions (block entry points) rather than ranges of instructions. An example, before regalloc:. ```text; bb.2:; %2 = PHI %1, %bb.0, %2, %bb.1, debug-instr-number 1; ```. After:. ```text; bb.2:; DBG_PHI $rax, 1; ```. # `LiveDebugValues`. After optimisations and code layout complete, information about variable; values must be translated into variable locations, i.e. registers and stack; slots. This is performed in the [`LiveDebugValues` pass][LiveDebugValues], where; the debug instructions and machine code are separated out into two independent; functions:; * One that assigns values to variable names,; * One that assigns values to machine registers and stack slots. LLVM's existing SSA tools are used to place `PHI`s for each function, between; variable values and the values contained in machine locations, with value; propagation eliminating any unnecessary `PHI`s. The two can then be joined up; to map variables to values, then values to locations, for each instruction in; the function. Key to this process is being able to identify the movement of values between; registers and stack locations, so that the location of values can be preserved; for the full time that they are resident in the machine. # Required target support and transition guide. Instruction referencing will work on any target, but likely with poor coverage.; Supporting instruction referencing well requires:; * Target hooks to be implemented to allow `LiveDebugValues` to follow values; through the machine,; * Target-specific optimisations to be in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:4429,perform,performed,4429,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,1,['perform'],['performed']
Performance,"ion must be disabled when the call-site needs to toggle; PSTATE.SM, such that the caller can restore the original value of PSTATE.SM. 3. Handling PSTATE.ZA; =====================. In contrast to PSTATE.SM, enabling PSTATE.ZA does not affect the SVE vector; length and also doesn't clobber FP/AdvSIMD/SVE registers. This means it is safe; to toggle PSTATE.ZA using intrinsics. This also makes it simpler to setup a; lazy-save mechanism for calls to private-ZA functions (i.e. functions that may; either directly or indirectly clobber ZA state). For the purpose of handling functions marked with ``aarch64_pstate_za_new``,; we have introduced a new LLVM IR pass (SMEABIPass) that is run just before; SelectionDAG. Any such functions dealt with by this pass are marked with; ``aarch64_expanded_pstate_za``. Setting up a lazy-save; ----------------------. Committing a lazy-save; ----------------------. Exception handling and ZA; -------------------------. 4. Types; ========. AArch64 Predicate-as-Counter Type; ---------------------------------. :Overview:. The predicate-as-counter type represents the type of a predicate-as-counter; value held in a AArch64 SVE predicate register. Such a value contains; information about the number of active lanes, the element width and a bit that; tells whether the generated mask should be inverted. ACLE intrinsics should be; used to move the predicate-as-counter value to/from a predicate vector. There are certain limitations on the type:. * The type can be used for function parameters and return values. * The supported LLVM operations on this type are limited to ``load``, ``store``,; ``phi``, ``select`` and ``alloca`` instructions. The predicate-as-counter type is a scalable type. :Syntax:. ::. target(""aarch64.svcount""). 5. References; =============. .. _aarch64_sme_acle:. 1. `SME ACLE Pull-request <https://github.com/ARM-software/acle/pull/188>`__. .. _aarch64_sme_abi:. 2. `SME ABI Pull-request <https://github.com/ARM-software/abi-aa/pull/123>`__; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst:18261,load,load,18261,interpreter/llvm-project/llvm/docs/AArch64SME.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst,2,"['load', 'scalab']","['load', 'scalable']"
Performance,"ion or; from the target. This is because the ``__FLT_EVAL_METHOD__`` macro; cannot expand to the correct evaluation method in the presence of a ``#pragma``; which alters the evaluation method. An error is issued if; ``__FLT_EVAL_METHOD__`` is expanded inside a scope modified by; ``#pragma clang fp eval_method``. .. _fp-constant-eval:. A note about Floating Point Constant Evaluation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In C, the only place floating point operations are guaranteed to be evaluated; during translation is in the initializers of variables of static storage; duration, which are all notionally initialized before the program begins; executing (and thus before a non-default floating point environment can be; entered). But C++ has many more contexts where floating point constant; evaluation occurs. Specifically: for static/thread-local variables,; first try evaluating the initializer in a constant context, including in the; constant floating point environment (just like in C), and then, if that fails,; fall back to emitting runtime code to perform the initialization (which might; in general be in a different floating point environment). Consider this example when compiled with ``-frounding-math``. .. code-block:: console. constexpr float func_01(float x, float y) {; return x + y;; }; float V1 = func_01(1.0F, 0x0.000001p0F);. The C++ rule is that initializers for static storage duration variables are; first evaluated during translation (therefore, in the default rounding mode),; and only evaluated at runtime (and therefore in the runtime rounding mode) if; the compile-time evaluation fails. This is in line with the C rules;; C11 F.8.5 says: *All computation for automatic initialization is done (as if); at execution time; thus, it is affected by any operative modes and raises; floating-point exceptions as required by IEC 60559 (provided the state for the; FENV_ACCESS pragma is on). All computation for initialization of objects; that have static o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:73414,perform,perform,73414,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['perform'],['perform']
Performance,"ion outside atomic; ===========================. The basic ``'load'`` and ``'store'`` allow a variety of optimizations, but can; lead to undefined results in a concurrent environment; see `NotAtomic`_. This; section specifically goes into the one optimizer restriction which applies in; concurrent environments, which gets a bit more of an extended description; because any optimization dealing with stores needs to be aware of it. From the optimizer's point of view, the rule is that if there are not any; instructions with atomic ordering involved, concurrency does not matter, with; one exception: if a variable might be visible to another thread or signal; handler, a store cannot be inserted along a path where it might not execute; otherwise. Take the following example:. .. code-block:: c. /* C code, for readability; run through clang -O2 -S -emit-llvm to get; equivalent IR */; int x;; void f(int* a) {; for (int i = 0; i < 100; i++) {; if (a[i]); x += 1;; }; }. The following is equivalent in non-concurrent situations:. .. code-block:: c. int x;; void f(int* a) {; int xtemp = x;; for (int i = 0; i < 100; i++) {; if (a[i]); xtemp += 1;; }; x = xtemp;; }. However, LLVM is not allowed to transform the former to the latter: it could; indirectly introduce undefined behavior if another thread can access ``x`` at; the same time. That thread would read `undef` instead of the value it was; expecting, which can lead to undefined behavior down the line. (This example is; particularly of interest because before the concurrency model was implemented,; LLVM would perform this transformation.). Note that speculative loads are allowed; a load which is part of a race returns; ``undef``, but does not have undefined behavior. Atomic instructions; ===================. For cases where simple loads and stores are not sufficient, LLVM provides; various atomic instructions. The exact guarantees provided depend on the; ordering; see `Atomic orderings`_. ``load atomic`` and ``store atomic`` provid",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:3420,concurren,concurrent,3420,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['concurren'],['concurrent']
Performance,"ion package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter), for solving linear least square fits.; - \ref Minuit2Page ""Minuit2"": new object-oriented implementation of MINUIT, with the same minimization algorithms (such as Migrad or Simplex). In addition it provides a new implementation of the Fumili algorithm, a specialized method for finding the minimum of a standard least square or likelihood functions.; - **Fumili**: library providing the implementation of the original Fumili fitting algorithm (class TFumili). - **Linear algebra**. Two libraries are contained in %ROOT for describing linear algebra matrices and vector classes:. - Matrix: general matrix package providing matrix classes (TMatrixD and TMatrixF) and vector classes (TVectorD and TVectorF) and the complete environment to perform linear algebra calculations, like equation solving and eigenvalue decompositions.; - \ref SMatrixPage ""SMatrix"": package optimized for high performances matrix and vector computations of small and fixed size. It is based on expression templates to achieve an high level optimization. - **Physics Vectors**: Classes for describing vectors in 2, 3 and 4 dimensions (relativistic vectors) and their rotation and transformation algorithms. Two package exist in %ROOT:. - Physics: library with the TVector3 and TLorentzVector classes.; - GenVector: new library providing generic class templates for modeling the vectors. See the \ref GenVector ""GenVector"" page. - \ref Unuran ""UNURAN"": Package with universal algorithms for generating non-uniform pseudo-random numbers, from a large classes of continuous or discrete distributions in one or multi-dimensions. - **Foam** Multi-dimensional general purpose Monte Carlo event generator (and integrator). It generates randomly points (vectors) according to an arbitrary probability distribution in n dimensions. - **FFTW** Library with implementation of the fast Fourier transform (FFT) using the FFTW pac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:2867,optimiz,optimized,2867,math/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md,2,"['optimiz', 'perform']","['optimized', 'performances']"
Performance,"ion pass; FPM.addPass(InstSimplifyPass());. MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));. Generally you want to group CGSCC/function/loop passes together in a pass; manager, as opposed to adding adaptors for each pass to the containing upper; level pass manager. For example,. .. code-block:: c++. ModulePassManager MPM;; MPM.addPass(createModuleToFunctionPassAdaptor(FunctionPass1()));; MPM.addPass(createModuleToFunctionPassAdaptor(FunctionPass2()));; MPM.run();. will run ``FunctionPass1`` on each function in a module, then run; ``FunctionPass2`` on each function in the module. In contrast,. .. code-block:: c++. ModulePassManager MPM;. FunctionPassManager FPM;; FPM.addPass(FunctionPass1());; FPM.addPass(FunctionPass2());. MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));. will run ``FunctionPass1`` and ``FunctionPass2`` on the first function in a; module, then run both passes on the second function in the module, and so on.; This is better for cache locality around LLVM data structures. This similarly; applies for the other IR types, and in some cases can even affect the quality; of optimization. For example, running all loop passes on a loop may cause a; later loop to be able to be optimized more than if each loop pass were run; separately. Inserting Passes into Default Pipelines; =======================================. Rather than manually adding passes to a pass manager, the typical way of; creating a pass manager is to use a ``PassBuilder`` and call something like; ``PassBuilder::buildPerModuleDefaultPipeline()`` which creates a typical; pipeline for a given optimization level. Sometimes either frontends or backends will want to inject passes into the; pipeline. For example, frontends may want to add instrumentation, and target; backends may want to add passes that lower custom intrinsics. For these; cases, ``PassBuilder`` exposes callbacks that allow injecting passes into; certain parts of the pipeline. For example,. .. code-bloc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:4640,cache,cache,4640,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['cache'],['cache']
Performance,"ion to allow constant; memory to change values between kernel dispatches. **Region**; The region address space uses the hardware Global Data Store (GDS). All; wavefronts executing on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of the wavefront access this using dword (4 byte) interleaving. The mapping; used from private address to backing memory address is:. ``wavefront-scratch-base +; ((private-address / 4) * wavefront-size * 4) +; (wavefront-lane-id * 4) + (private-address % 4)``. If each lane of a wavefront accesses the same private address, the; interleaving results in adjacent dwords be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:26406,perform,performance,26406,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performance']
Performance,"ion to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic atomic cmpxchg. Expects a MachineMemOperand in addition to explicit; operands. G_ATOMICRMW_XCHG, G_ATOMICRMW_ADD, G_ATOMICRMW_SUB, G_ATOMICRMW_AND,; G_ATOMICRMW_NAND, G_ATOMICRMW_OR, G_ATOMICRMW_XOR, G_ATOMICRMW_MAX,; G_ATOMICRMW_MIN, G_ATOMICRMW_UMAX, G_ATOMICRMW_UMIN, G_ATOMICRMW_FADD,; G_ATOMICRMW_FSUB, G_ATOMICRMW_FMAX, G_ATOMICRMW_FMIN; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomicrmw. Expects a MachineMemOperand in addition to explicit; operands. G_FENCE; ^^^^^^^. Generic fence. The first operand is the memory ordering. The second operand is; the syncscope. See the LLVM LangRef entry on the '``fence'`` instruction for more details. G_MEMCPY; ^^^^^^^^. Generic memcpy. Expects two MachineMemOperands covering the store and load; respectively, in addition to explicit operands. G_MEMCPY_INLINE; ^^^^^^^^^^^^^^^. Generic inlined memcpy. Like G_MEMCPY, but it is guaranteed that this version; will not be lowered as a call to an external function. Currently the size; operand is required to evaluate as a constant (not an immediate), though that is; expected to change when llvm.memcpy.inline is taught to support dynamic sizes. G_MEMMOVE; ^^^^^^^^^. Generic memmove. Similar to G_MEMCPY, but the source and destination memory; ranges are allowed to overlap. G_MEMSET; ^^^^^^^^. Generic memset. Expects a MachineMemOperand in addition to explicit operands. G_BZERO; ^^^^^^^. Generic bzero. Expects a MachineMemOperand in addition to explicit operands. Control Flow; ------------. G_PHI; ^^^^^. Implement the  node in the SSA graph representing the function. .. code-block:: none. %dst(s8) = G_PHI %src1(s8), %bb.<id1>, %src2(s8), %bb.<id2>. G_BR; ^^^^. Unconditional branch. .. code-block:: none. G_BR %bb.<id>. G_BRCOND; ^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:18170,load,load,18170,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,1,['load'],['load']
Performance,"ion uses the VALUE_STACK physical register to impose; ordering dependencies on instructions with stack operands. This is pessimistic;; we should consider alternate ways to model stack dependencies. //===---------------------------------------------------------------------===//. Lots of things could be done in WebAssemblyTargetTransformInfo.cpp. Similarly,; there are numerous optimization-related hooks that can be overridden in; WebAssemblyTargetLowering. //===---------------------------------------------------------------------===//. Instead of the OptimizeReturned pass, which should consider preserving the; ""returned"" attribute through to MachineInstrs and extending the; MemIntrinsicResults pass to do this optimization on calls too. That would also; let the WebAssemblyPeephole pass clean up dead defs for such calls, as it does; for stores. //===---------------------------------------------------------------------===//. Consider implementing optimizeSelect, optimizeCompareInstr, optimizeCondBranch,; optimizeLoadInstr, and/or getMachineCombinerPatterns. //===---------------------------------------------------------------------===//. Find a clean way to fix the problem which leads to the Shrink Wrapping pass; being run after the WebAssembly PEI pass. //===---------------------------------------------------------------------===//. When setting multiple local variables to the same constant, we currently get; code like this:. i32.const $4=, 0; i32.const $3=, 0. It could be done with a smaller encoding like this:. i32.const $push5=, 0; local.tee $push6=, $4=, $pop5; local.copy $3=, $pop6. //===---------------------------------------------------------------------===//. WebAssembly registers are implicitly initialized to zero. Explicit zeroing is; therefore often redundant and could be optimized away. //===---------------------------------------------------------------------===//. Small indices may use smaller encodings than large indices.; WebAssemblyRegColoring and/or WebA",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt:3485,optimiz,optimizeSelect,3485,interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,8,['optimiz'],"['optimizeCompareInstr', 'optimizeCondBranch', 'optimizeLoadInstr', 'optimizeSelect']"
Performance,"ion when performed during the link stage. This document describes the; interface and design between the LTO optimizer and the linker. Design Philosophy; =================. The LLVM Link Time Optimizer provides complete transparency, while doing; intermodular optimization, in the compiler tool chain. Its main goal is to let; the developer take advantage of intermodular optimizations without making any; significant changes to the developer's makefiles or build system. This is; achieved through tight integration with the linker. In this model, the linker; treats LLVM bitcode files like native object files and allows mixing and; matching among them. The linker uses `libLTO`_, a shared object, to handle LLVM; bitcode files. This tight integration between the linker and LLVM optimizer; helps to do optimizations that are not possible in other models. The linker; input allows the optimizer to avoid relying on conservative escape analysis. .. _libLTO-example:. Example of link time optimization; ---------------------------------. The following example illustrates the advantages of LTO's integrated approach; and clean interface. This example requires a system linker which supports LTO; through the interface described in this document. Here, clang transparently; invokes system linker. * Input source file ``a.c`` is compiled into LLVM bitcode form.; * Input source file ``main.c`` is compiled into native object code. .. code-block:: c++. --- a.h ---; extern int foo1(void);; extern void foo2(void);; extern void foo4(void);. --- a.c ---; #include ""a.h"". static signed int i = 0;. void foo2(void) {; i = -1;; }. static int foo3() {; foo4();; return 10;; }. int foo1(void) {; int data = 0;. if (i < 0); data = foo3();. data = data + 42;; return data;; }. --- main.c ---; #include <stdio.h>; #include ""a.h"". void foo4(void) {; printf(""Hi\n"");; }. int main() {; return foo1();; }. To compile, run:. .. code-block:: console. % clang -flto -c a.c -o a.o # <-- a.o is LLVM bitcode file; % clang -c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:1360,optimiz,optimization,1360,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['optimiz'],['optimization']
Performance,"ion"". Here are a few observations about this:. First, you're right that LLVM does lose information. For example, as of; this writing, there is no way to distinguish in the LLVM IR whether an; SSA-value came from a C ""int"" or a C ""long"" on an ILP32 machine (other; than debug info). Both get compiled down to an 'i32' value and the; information about what it came from is lost. The more general issue; here, is that the LLVM type system uses ""structural equivalence"" instead; of ""name equivalence"". Another place this surprises people is if you; have two types in a high-level language that have the same structure; (e.g. two different structs that have a single int field): these types; will compile down into a single LLVM type and it will be impossible to; tell what it came from. Second, while LLVM does lose information, LLVM is not a fixed target: we; continue to enhance and improve it in many different ways. In addition; to adding new features (LLVM did not always support exceptions or debug; info), we also extend the IR to capture important information for; optimization (e.g. whether an argument is sign or zero extended,; information about pointers aliasing, etc). Many of the enhancements are; user-driven: people want LLVM to include some specific feature, so they; go ahead and extend it. Third, it is *possible and easy* to add language-specific optimizations,; and you have a number of choices in how to do it. As one trivial; example, it is easy to add language-specific optimization passes that; ""know"" things about code compiled for a language. In the case of the C; family, there is an optimization pass that ""knows"" about the standard C; library functions. If you call ""exit(0)"" in main(), it knows that it is; safe to optimize that into ""return 0;"" because C specifies what the; 'exit' function does. In addition to simple library knowledge, it is possible to embed a; variety of other language-specific information into the LLVM IR. If you; have a specific need and run into ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst:10056,optimiz,optimization,10056,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,1,['optimiz'],['optimization']
Performance,"ion's return value's second; element is true, the following rules apply to the first element:. - If the given pointer is associated with the given type metadata identifier,; it is the function pointer loaded from the given byte offset from the given; pointer. - If the given pointer is not associated with the given type metadata; identifier, it is one of the following (the choice of which is unspecified):. 1. The function pointer that would have been loaded from an arbitrarily chosen; (through an unspecified mechanism) pointer associated with the type; metadata. 2. If the function has a non-void return type, a pointer to a function that; returns an unspecified value without causing side effects. If the function's return value's second element is false, the value of the; first element is undefined. .. _type.checked.load.relative:. '``llvm.type.checked.load.relative``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare {ptr, i1} @llvm.type.checked.load.relative(ptr %ptr, i32 %offset, metadata %type) argmemonly nounwind readonly. Overview:; """""""""""""""""". The ``llvm.type.checked.load.relative`` intrinsic loads a relative pointer to a; function from a virtual table pointer using metadata. Otherwise, its semantic is; identical to the ``llvm.type.checked.load`` intrinsic. A relative pointer is a pointer to an offset to the pointed to value. The; address of the underlying pointer of the relative pointer is obtained by adding; the offset to the address of the offset value. '``llvm.arithmetic.fence``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.arithmetic.fence(<type> <op>). Overview:; """""""""""""""""". The purpose of the ``llvm.arithmetic.fence`` intrinsic; is to prevent the optimizer from performing fast-math optimizations,; particularly reassociation,; between the argument and the expression that contains the argument.; It can be used to preserve the parentheses in the source language. Arguments:;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:939941,load,load,939941,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"ion(ISD::CTPOP, MVT::i32, Expand);; ...; if (TM.getSubtarget<SparcSubtarget>().isV9()); setOperationAction(ISD::CTPOP, MVT::i32, Legal);. Calling Conventions; -------------------. To support target-specific calling conventions, ``XXXGenCallingConv.td`` uses; interfaces (such as ``CCIfType`` and ``CCAssignToReg``) that are defined in; ``lib/Target/TargetCallingConv.td``. TableGen can take the target descriptor; file ``XXXGenCallingConv.td`` and generate the header file; ``XXXGenCallingConv.inc``, which is typically included in; ``XXXISelLowering.cpp``. You can use the interfaces in; ``TargetCallingConv.td`` to specify:. * The order of parameter allocation. * Where parameters and return values are placed (that is, on the stack or in; registers). * Which registers may be used. * Whether the caller or callee unwinds the stack. The following example demonstrates the use of the ``CCIfType`` and; ``CCAssignToReg`` interfaces. If the ``CCIfType`` predicate is true (that is,; if the current argument is of type ``f32`` or ``f64``), then the action is; performed. In this case, the ``CCAssignToReg`` action assigns the argument; value to the first available register: either ``R0`` or ``R1``. .. code-block:: text. CCIfType<[f32,f64], CCAssignToReg<[R0, R1]>>. ``SparcCallingConv.td`` contains definitions for a target-specific return-value; calling convention (``RetCC_Sparc32``) and a basic 32-bit C calling convention; (``CC_Sparc32``). The definition of ``RetCC_Sparc32`` (shown below) indicates; which registers are used for specified scalar return types. A single-precision; float is returned to register ``F0``, and a double-precision float goes to; register ``D0``. A 32-bit integer is returned in register ``I0`` or ``I1``. .. code-block:: text. def RetCC_Sparc32 : CallingConv<[; CCIfType<[i32], CCAssignToReg<[I0, I1]>>,; CCIfType<[f32], CCAssignToReg<[F0]>>,; CCIfType<[f64], CCAssignToReg<[D0]>>; ]>;. The definition of ``CC_Sparc32`` in ``SparcCallingConv.td`` introduces; ``CCAssi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:62522,perform,performed,62522,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['perform'],['performed']
Performance,"ion*. It is a global value. It is a constant, since it's the only; supposed global here. The method also compares: Constants that are of the; same type and if right constant can be losslessly bit-casted to the left; one, then we also compare them. How to implement cmpValues?; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; *Association* is a case of equality for us. We just treat such values as equal,; but, in general, we need to implement antisymmetric relation. As mentioned; above, to understand what is *less*, we can use order in which we; meet values. If both values have the same order in a function (met at the same; time), we then treat values as *associated*. Otherwise  it depends on who was; first. Every time we run the top-level compare method, we initialize two identical; maps (one for the left side, another one for the right side):. ``map<Value, int> sn_mapL, sn_mapR;``. The key of the map is the *Value* itself, the *value*  is its order (call it; *serial number*). To add value *V* we need to perform the next procedure:. ``sn_map.insert(std::make_pair(V, sn_map.size()));``. For the first *Value*, map will return *0*, for the second *Value* map will; return *1*, and so on. We can then check whether left and right values met at the same time with; a simple comparison:. ``cmpNumbers(sn_mapL[Left], sn_mapR[Right]);``. Of course, we can combine insertion and comparison:. .. code-block:: c++. std::pair<iterator, bool>; LeftRes = sn_mapL.insert(std::make_pair(Left, sn_mapL.size())), RightRes; = sn_mapR.insert(std::make_pair(Right, sn_mapR.size()));; return cmpNumbers(LeftRes.first->second, RightRes.first->second);. Let's look, how whole method could be implemented. 1. We have to start with the bad news. Consider function self and; cross-referencing cases:. .. code-block:: c++. // self-reference unsigned fact0(unsigned n) { return n > 1 ? n; * fact0(n-1) : 1; } unsigned fact1(unsigned n) { return n > 1 ? n *; fact1(n-1) : 1; }. // cross-reference unsigned ping(unsigned n) { return ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst:19028,perform,perform,19028,interpreter/llvm-project/llvm/docs/MergeFunctions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MergeFunctions.rst,1,['perform'],['perform']
Performance,"ion, a file containing the subset of basic blocks; that need to placed in unique sections can be specified. The format of the; file is as follows. For example, ``list=spec.txt`` where ``spec.txt`` is the; following:. ::. !foo; !!2; !_Z3barv. will place the machine basic block with ``id 2`` in function ``foo`` in a; unique section. It will also place all basic blocks of functions ``bar``; in unique sections. Further, section clusters can also be specified using the ``list=<arg>``; option. For example, ``list=spec.txt`` where ``spec.txt`` contains:. ::. !foo; !!1 !!3 !!5; !!2 !!4 !!6. will create two unique sections for function ``foo`` with the first; containing the odd numbered basic blocks and the second containing the; even numbered basic blocks. Basic block sections allow the linker to reorder basic blocks and enables; link-time optimizations like whole program inter-procedural basic block; reordering. Profile Guided Optimization; ---------------------------. Profile information enables better optimization. For example, knowing that a; branch is taken very frequently helps the compiler make better decisions when; ordering basic blocks. Knowing that a function ``foo`` is called more; frequently than another function ``bar`` helps the inliner. Optimization; levels ``-O2`` and above are recommended for use of profile guided optimization. Clang supports profile guided optimization with two different kinds of; profiling. A sampling profiler can generate a profile with very low runtime; overhead, or you can build an instrumented version of the code that collects; more detailed profile information. Both kinds of profiles can provide execution; counts for instructions in the code and information on branches taken and; function invocation. Regardless of which kind of profiling you use, be careful to collect profiles; by running your code with inputs that are representative of the typical; behavior. Code that is not exercised in the profile will be optimized as if it; is un",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:89651,optimiz,optimization,89651,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance,"ion. * - ``half``; - 16-bit floating-point value. * - ``bfloat``; - 16-bit ""brain"" floating-point value (7-bit significand). Provides the; same number of exponent bits as ``float``, so that it matches its dynamic; range, but with greatly reduced precision. Used in Intel's AVX-512 BF16; extensions and Arm's ARMv8.6-A extensions, among others. * - ``float``; - 32-bit floating-point value. * - ``double``; - 64-bit floating-point value. * - ``fp128``; - 128-bit floating-point value (113-bit significand). * - ``x86_fp80``; - 80-bit floating-point value (X87). * - ``ppc_fp128``; - 128-bit floating-point value (two 64-bits). The binary format of half, float, double, and fp128 correspond to the; IEEE-754-2008 specifications for binary16, binary32, binary64, and binary128; respectively. X86_amx Type; """""""""""""""""""""""". :Overview:. The x86_amx type represents a value held in an AMX tile register on an x86; machine. The operations allowed on it are quite limited. Only few intrinsics; are allowed: stride load and store, zero and dot product. No instruction is; allowed for this type. There are no arguments, arrays, pointers, vectors; or constants of this type. :Syntax:. ::. x86_amx. X86_mmx Type; """""""""""""""""""""""". :Overview:. The x86_mmx type represents a value held in an MMX register on an x86; machine. The operations allowed on it are quite limited: parameters and; return values, load and store, and bitcast. User-specified MMX; instructions are represented as intrinsic or asm calls with arguments; and/or results of this type. There are no arrays, vectors or constants; of this type. :Syntax:. ::. x86_mmx. .. _t_pointer:. Pointer Type; """""""""""""""""""""""". :Overview:. The pointer type ``ptr`` is used to specify memory locations. Pointers are; commonly used to reference objects in memory. Pointer types may have an optional address space attribute defining; the numbered address space where the pointed-to object resides. For; example, ``ptr addrspace(5)`` is a pointer to address space 5.; In additi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:170088,load,load,170088,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"ion. The least-significant bit (lsb) and width operands are in the range:. ::. 0 <= lsb < lsb + width <= source bitwidth, where all values are unsigned. G_SBFX sign-extends the result, while G_UBFX zero-extends the result. .. code-block:: none. ; Extract 5 bits starting at bit 1 from %x and store them in %a.; ; Sign-extend the result.; ;; ; Example:; ; %x = 0...0000[10110]1 ---> %a = 1...111111[10110]; %lsb_one = G_CONSTANT i32 1; %width_five = G_CONSTANT i32 5; %a:_(s32) = G_SBFX %x, %lsb_one, %width_five. ; Extract 3 bits starting at bit 2 from %x and store them in %b. Zero-extend; ; the result.; ;; ; Example:; ; %x = 1...11111[100]11 ---> %b = 0...00000[100]; %lsb_two = G_CONSTANT i32 2; %width_three = G_CONSTANT i32 3; %b:_(s32) = G_UBFX %x, %lsb_two, %width_three. Integer Operations; -------------------. G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SDIV, G_UDIV, G_SREM, G_UREM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These each perform their respective integer arithmetic on a scalar. .. code-block:: none. %dst:_(s32) = G_ADD %src0:_(s32), %src1:_(s32). The above example adds %src1 to %src0 and stores the result in %dst. G_SDIVREM, G_UDIVREM; ^^^^^^^^^^^^^^^^^^^^. Perform integer division and remainder thereby producing two results. .. code-block:: none. %div:_(s32), %rem:_(s32) = G_SDIVREM %0:_(s32), %1:_(s32). G_SADDSAT, G_UADDSAT, G_SSUBSAT, G_USUBSAT, G_SSHLSAT, G_USHLSAT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Signed and unsigned addition, subtraction and left shift with saturation. .. code-block:: none. %2:_(s32) = G_SADDSAT %0:_(s32), %1:_(s32). G_SHL, G_LSHR, G_ASHR; ^^^^^^^^^^^^^^^^^^^^^. Shift the bits of a scalar left or right inserting zeros (sign-bit for G_ASHR). G_ROTR, G_ROTL; ^^^^^^^^^^^^^^. Rotate the bits right (G_ROTR) or left (G_ROTL). G_ICMP; ^^^^^^. Perform integer comparison producing non-zero (true) or zero (false). It's; target specific whether a true value is 1, ~0U, or some othe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:6115,perform,perform,6115,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,1,['perform'],['perform']
Performance,"ion:: -march=arch. Specify the architecture for which to generate assembly, overriding the target; encoded in the bitcode file. See the output of **llc -help** for a list of; valid architectures. By default this is inferred from the target triple or; autodetected to the current architecture. .. option:: -mcpu=cpuname. Specify a specific chip in the current architecture to generate code for.; By default this is inferred from the target triple and autodetected to; the current architecture. For a list of available CPUs, use:; **llvm-as < /dev/null | llc -march=xyz -mcpu=help**. .. option:: -mattr=a1,+a2,-a3,... Override or control specific attributes of the target, such as whether SIMD; operations are enabled or not. The default set of attributes is set by the; current CPU. For a list of available attributes, use:; **llvm-as < /dev/null | llc -march=xyz -mattr=help**. FLOATING POINT OPTIONS; ----------------------. .. option:: -disable-excess-fp-precision. Disable optimizations that may increase floating point precision. .. option:: -enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: -enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: -enable-unsafe-fp-math. Causes :program:`lli` to enable optimizations that may decrease floating point; precision. .. option:: -soft-float. Causes :program:`lli` to generate software floating point library calls instead of; equivalent hardware instructions. CODE GENERATION OPTIONS; -----------------------. .. option:: -code-model=model. Choose the code model from:. .. code-block:: text. default: Target default code model; tiny: Tiny code model; small: Small code model; kernel: Kernel code model; medium: Medium code model; large: Large code model. .. option:: -disable-post-RA-scheduler. Disable scheduling after register allocation. .. option:: -disable-spill-fusing. Disable fusing of spill code into instructions. .. option:: -jit-enable-eh. Exception handling should be enabl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:3009,optimiz,optimizations,3009,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,1,['optimiz'],['optimizations']
Performance,"ion; =================================================. Clang provides a mechanism for selectively disabling optimizations in functions; and methods. To disable optimizations in a single function definition, the GNU-style or C++11; non-standard attribute ``optnone`` can be used. .. code-block:: c++. // The following functions will not be optimized.; // GNU-style attribute; __attribute__((optnone)) int foo() {; // ... code; }; // C++11 attribute; [[clang::optnone]] int bar() {; // ... code; }. To facilitate disabling optimization for a range of function definitions, a; range-based pragma is provided. Its syntax is ``#pragma clang optimize``; followed by ``off`` or ``on``. All function definitions in the region between an ``off`` and the following; ``on`` will be decorated with the ``optnone`` attribute unless doing so would; conflict with explicit attributes already present on the function (e.g. the; ones that control inlining). .. code-block:: c++. #pragma clang optimize off; // This function will be decorated with optnone.; int foo() {; // ... code; }. // optnone conflicts with always_inline, so bar() will not be decorated.; __attribute__((always_inline)) int bar() {; // ... code; }; #pragma clang optimize on. If no ``on`` is found to close an ``off`` region, the end of the region is the; end of the compilation unit. Note that a stray ``#pragma clang optimize on`` does not selectively enable; additional optimizations when compiling at low optimization levels. This feature; can only be used to selectively disable optimizations. The pragma has an effect on functions only at the point of their definition; for; function templates, this means that the state of the pragma at the point of an; instantiation is not necessarily relevant. Consider the following example:. .. code-block:: c++. template<typename T> T twice(T t) {; return 2 * t;; }. #pragma clang optimize off; template<typename T> T thrice(T t) {; return 3 * t;; }. int container(int a, int b) {; return twice(a) + ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:159477,optimiz,optimize,159477,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimize']
Performance,ionCuda COMMAND testMinimizationCuda). # DNN - Arithmetic Cuda; add_executable(testArithmeticCuda TestMatrixArithmeticCuda.cxx); TARGET_LINK_LIBRARIES(testArithmeticCuda ${Libraries} ); ROOT_ADD_TEST(TMVA-DNN-ArithmeticCuda COMMAND testArithmeticCuda). # DNN - DataLoader Cuda; add_executable(testDataLoaderCuda TestDataLoaderCuda.cxx); TARGET_LINK_LIBRARIES(testDataLoaderCuda ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-DataLoaderCuda COMMAND testDataLoaderCuda). # DNN - Optimization GPU. add_executable(testOptimizationCuda TestOptimizationCuda.cxx); TARGET_LINK_LIBRARIES(testOptimizationCuda ${Libraries} ); ROOT_ADD_TEST(TMVA-DNN-Optimization-Cuda COMMAND testOptimizationCuda). #Cuda tests using CUDNN; if (tmva-cudnn). # DNN - Batch normalization Cudnn; add_executable(testBatchNormalizationCudnn TestBatchNormalizationCudnn.cxx ); TARGET_LINK_LIBRARIES(testBatchNormalizationCudnn ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-BatchNormalization-Cudnn COMMAND testBatchNormalizationCudnn). # DNN Optimization GPU Cudnn. add_executable(testOptimizationCudnn TestOptimizationCudnn.cxx); TARGET_LINK_LIBRARIES(testOptimizationCudnn ${Libraries} ); ROOT_ADD_TEST(TMVA-DNN-Optimization-Cudnn COMMAND testOptimizationCudnn). # DNN - TensorDataLoader Cudnn; #add_executable(testTensorDataLoaderCudnn TestTensorDataLoaderCudnn.cxx); #TARGET_LINK_LIBRARIES(testTensorDataLoaderCudnn ${Libraries} ${DNN_CUDA_LIBRARIES}); #ROOT_ADD_TEST(TMVA-DNN-TensorDataLoaderCudnn COMMAND testTensorDataLoaderCudnn). endif(). endif (). #--- CPU tests. ----------------------------; #; # always run the Cpu tests. If tmva-cpu is off (no Blas or no imt); # they will work using TMatrix operations. # DNN - Arithmetic Functions CPU; ROOT_EXECUTABLE(testArithmeticCpu TestMatrixArithmeticCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-Arithmetic-Cpu COMMAND testArithmeticCpu). # DNN - Activation Functions CPU; ROOT_EXECUTABLE(testActivationFunctionsCpu TestActivationFunctionsCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TES,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/DNN/CMakeLists.txt:3311,Optimiz,Optimization,3311,tmva/tmva/test/DNN/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/DNN/CMakeLists.txt,1,['Optimiz'],['Optimization']
Performance,"ion``.; Support for ``@llvm.experimental.guard`` is slowly being rephrased in; terms of this alternate. '``llvm.experimental.widenable.condition``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i1 @llvm.experimental.widenable.condition(). Overview:; """""""""""""""""". This intrinsic represents a ""widenable condition"" which is; boolean expressions with the following property: whether this; expression is `true` or `false`, the program is correct and; well-defined. Together with :ref:`deoptimization operand bundles <deopt_opbundles>`,; ``@llvm.experimental.widenable.condition`` allows frontends to; express guards or checks on optimistic assumptions made during; compilation and represent them as branch instructions on special; conditions. While this may appear similar in semantics to `undef`, it is very; different in that an invocation produces a particular, singular; value. It is also intended to be lowered late, and remain available; for specific optimizations and transforms that can benefit from its; special properties. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". The intrinsic ``@llvm.experimental.widenable.condition()``; returns either `true` or `false`. For each evaluation of a call; to this intrinsic, the program must be valid and correct both if; it returns `true` and if it returns `false`. This allows; transformation passes to replace evaluations of this intrinsic; with either value whenever one is beneficial. When used in a branch condition, it allows us to choose between; two alternative correct solutions for the same problem, like; in example below:. .. code-block:: text. %cond = call i1 @llvm.experimental.widenable.condition(); br i1 %cond, label %solution_1, label %solution_2. label %fast_path:; ; Apply memory-consuming but fast solution for a task. label %slow_path:; ; Cheap in memory but slow solution. Whether the result of intrinsic's call is `true` or `false`,; it should be correct to pick either soluti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:947396,optimiz,optimizations,947396,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"ionic/pthread_create.cpp#128; .. _`Clang 7.0.1 documentation`: https://releases.llvm.org/7.0.1/tools/clang/docs/ShadowCallStack.html. Comparison; ----------. To optimize for memory consumption and cache locality, the shadow call; stack stores only an array of return addresses. This is in contrast to other; schemes, like :doc:`SafeStack`, that mirror the entire stack and trade-off; consuming more memory for shorter function prologs and epilogs with fewer; memory accesses. `Return Flow Guard`_ is a pure software implementation of shadow call stacks; on x86_64. Like the previous implementation of ShadowCallStack on x86_64, it is; inherently racy due to the architecture's use of the stack for calls and; returns. Intel `Control-flow Enforcement Technology`_ (CET) is a proposed hardware; extension that would add native support to use a shadow stack to store/check; return addresses at call/return time. Being a hardware implementation, it; would not suffer from race conditions and would not incur the overhead of; function instrumentation, but it does require operating system support. .. _`Return Flow Guard`: https://xlab.tencent.com/en/2016/11/02/return-flow-guard/; .. _`Control-flow Enforcement Technology`: https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf. Compatibility; -------------. A runtime is not provided in compiler-rt so one must be provided by the; compiled application or the operating system. Integrating the runtime into; the operating system should be preferred since otherwise all thread creation; and destruction would need to be intercepted by the application. The instrumentation makes use of the platform register ``x18`` on AArch64 and; ``x3`` (``gp``) on RISC-V. For simplicity we will refer to this as the; ``SCSReg``. On some platforms, ``SCSReg`` is reserved, and on others, it is; designated as a scratch register. This generally means that any code that may; run on the same thread as code compiled w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ShadowCallStack.rst:2104,race condition,race conditions,2104,interpreter/llvm-project/clang/docs/ShadowCallStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ShadowCallStack.rst,1,['race condition'],['race conditions']
Performance,"ions (1d); ; Update of class documentation; ; The documentation in the code itself that is extracted by THtml to construct; the online class documentation has been updated for all classes. Now all classes; have (again) a short class description, as well as a (short) description of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace; member functions addClassDeclImportDir() and addClassImplImportDir().; ; When a TFile with a RooWorkspace containing source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct range",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:2213,load,loaded,2213,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,2,['load'],['loaded']
Performance,"ions and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208213,cache,caches,208213,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"ions in the module being added to; // the JIT.; for (auto &F : *M); FPM->run(F);. return M;; }. At the bottom of our JIT we add a private method to do the actual optimization:; *optimizeModule*. This function takes the module to be transformed as input (as; a ThreadSafeModule) along with a reference to a reference to a new class:; ``MaterializationResponsibility``. The MaterializationResponsibility argument; can be used to query JIT state for the module being transformed, such as the set; of definitions in the module that JIT'd code is actively trying to call/access.; For now we will ignore this argument and use a standard optimization; pipeline. To do this we set up a FunctionPassManager, add some passes to it, run; it over every function in the module, and then return the mutated module. The; specific optimizations are the same ones used in `Chapter 4 <LangImpl04.html>`_; of the ""Implementing a language with LLVM"" tutorial series. Readers may visit; that chapter for a more in-depth discussion of these, and of IR optimization in; general. And that's it in terms of changes to KaleidoscopeJIT: When a module is added via; addModule the OptimizeLayer will call our optimizeModule function before passing; the transformed module on to the CompileLayer below. Of course, we could have; called optimizeModule directly in our addModule function and not gone to the; bother of using the IRTransformLayer, but doing so gives us another opportunity; to see how layers compose. It also provides a neat entry point to the *layer*; concept itself, because IRTransformLayer is one of the simplest layers that; can be implemented. .. code-block:: c++. // From IRTransformLayer.h:; class IRTransformLayer : public IRLayer {; public:; using TransformFunction = std::function<Expected<ThreadSafeModule>(; ThreadSafeModule, const MaterializationResponsibility &R)>;. IRTransformLayer(ExecutionSession &ES, IRLayer &BaseLayer,; TransformFunction Transform = identityTransform);. void setTransform(Transf",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:5850,optimiz,optimization,5850,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,1,['optimiz'],['optimization']
Performance,"ions it might transform. * ``isUnordered()``: A load or store which is not volatile and at most; Unordered. This would be checked, for example, by LICM before hoisting an; operation. * ``mayReadFromMemory()``/``mayWriteToMemory()``: Existing predicate, but note; that they return true for any operation which is volatile or at least; Monotonic. * ``isStrongerThan`` / ``isAtLeastOrStrongerThan``: These are predicates on; orderings. They can be useful for passes that are aware of atomics, for; example to do DSE across a single atomic access, but not across a; release-acquire pair (see MemoryDependencyAnalysis for an example of this). * Alias analysis: Note that AA will return ModRef for anything Acquire or; Release, and for the address accessed by any Monotonic operation. To support optimizing around atomic operations, make sure you are using the; right predicates; everything should work if that is done. If your pass should; optimize some atomic operations (Unordered operations in particular), make sure; it doesn't replace an atomic load or store with a non-atomic operation. Some examples of how optimizations interact with various kinds of atomic; operations:. * ``memcpyopt``: An atomic operation cannot be optimized into part of a; memcpy/memset, including unordered loads/stores. It can pull operations; across some atomic operations. * LICM: Unordered loads/stores can be moved out of a loop. It just treats; monotonic operations like a read+write to a memory location, and anything; stricter than that like a nothrow call. * DSE: Unordered stores can be DSE'ed like normal stores. Monotonic stores can; be DSE'ed in some cases, but it's tricky to reason about, and not especially; important. It is possible in some case for DSE to operate across a stronger; atomic operation, but it is fairly tricky. DSE delegates this reasoning to; MemoryDependencyAnalysis (which is also used by other passes like GVN). * Folding a load: Any atomic load from a constant global can be constant-fo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:16934,optimiz,optimize,16934,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,"['load', 'optimiz']","['load', 'optimize']"
Performance,"ions),; the memory is reclaimed. Allocating zero bytes is legal, but the returned; pointer may not be unique. The order in which memory is allocated (ie.,; which way the stack grows) is not specified. Note that '``alloca``' outside of the alloca address space from the; :ref:`datalayout string<langref_datalayout>` is meaningful only if the; target has assigned it a semantics. If the returned pointer is used by :ref:`llvm.lifetime.start <int_lifestart>`,; the returned object is initially dead.; See :ref:`llvm.lifetime.start <int_lifestart>` and; :ref:`llvm.lifetime.end <int_lifeend>` for the precise semantics of; lifetime-manipulating intrinsics. Example:; """""""""""""""". .. code-block:: llvm. %ptr = alloca i32 ; yields ptr; %ptr = alloca i32, i32 4 ; yields ptr; %ptr = alloca i32, i32 4, align 1024 ; yields ptr; %ptr = alloca i32, align 1024 ; yields ptr. .. _i_load:. '``load``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = load [volatile] <ty>, ptr <pointer>[, align <alignment>][, !nontemporal !<nontemp_node>][, !invariant.load !<empty_node>][, !invariant.group !<empty_node>][, !nonnull !<empty_node>][, !dereferenceable !<deref_bytes_node>][, !dereferenceable_or_null !<deref_bytes_node>][, !align !<align_node>][, !noundef !<empty_node>]; <result> = load atomic [volatile] <ty>, ptr <pointer> [syncscope(""<target-scope>"")] <ordering>, align <alignment> [, !invariant.group !<empty_node>]; !<nontemp_node> = !{ i32 1 }; !<empty_node> = !{}; !<deref_bytes_node> = !{ i64 <dereferenceable_bytes> }; !<align_node> = !{ i64 <value_alignment> }. Overview:; """""""""""""""""". The '``load``' instruction is used to read from memory. Arguments:; """""""""""""""""""". The argument to the ``load`` instruction specifies the memory address from which; to load. The type specified must be a :ref:`first class <t_firstclass>` type of; known size (i.e. not containing an :ref:`opaque structural type <t_opaque>`). If; the ``load`` is marked as ``volatile``, then the optimizer is not allowed to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:411904,load,load,411904,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"ions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:34945,load,loads,34945,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance,"ions. For example, it; is undefined behaviour to share vector-length dependent state between functions; that may operate with different values for PSTATE.SM. Front-ends must honour; these restrictions when generating LLVM IR. Even though the runtime SVE vector length may change, for the purpose of LLVM IR; and almost all parts of CodeGen we can assume that the runtime value for; ``vscale`` does not. If we let the compiler insert the appropriate ``smstart``; and ``smstop`` instructions around call boundaries, then the effects on SVE; state can be mitigated. By limiting the state changes to a very brief window; around the call we can control how the operations are scheduled and how live; values remain preserved between state transitions. In order to control PSTATE.SM at this level of granularity, we use function and; callsite attributes rather than intrinsics. Restrictions on attributes; --------------------------. * It is undefined behaviour to pass or return (pointers to) scalable vector; objects to/from functions which may use a different SVE vector length.; This includes functions with a non-streaming interface, but marked with; ``aarch64_pstate_sm_body``. * It is not allowed for a function to be decorated with both; ``aarch64_pstate_sm_compatible`` and ``aarch64_pstate_sm_enabled``. * It is not allowed for a function to be decorated with both; ``aarch64_pstate_za_new`` and ``aarch64_pstate_za_preserved``. * It is not allowed for a function to be decorated with both; ``aarch64_pstate_za_new`` and ``aarch64_pstate_za_shared``. These restrictions also apply in the higher level SME ACLE, which means we can; emit diagnostics in Clang to signal users about incorrect behaviour. Compiler inserted streaming-mode changes; ----------------------------------------. The table below describes the transitions in PSTATE.SM the compiler has to; account for when doing calls between functions with different attributes.; In this table, we use the following abbreviations:. ``N``; fun",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst:3153,scalab,scalable,3153,interpreter/llvm-project/llvm/docs/AArch64SME.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AArch64SME.rst,1,['scalab'],['scalable']
Performance,"ipping for tracks and points in geo painter; 17. Fix - drawing of TGeoNode with finder; 18. Fix - key press events processed only in active pad (ROOT-9128); 19. Fix - use X0/Y0 in xtru shape (#182), thanks to @altavir; 20. Move most of ui5-specific code into ROOT repository, where it will be maintained; 21. Provide special widget for object inspector. ## Changes in 5.6.4; 1. Fix - try workaround corrupted data in TTree; 2. Fix - support min0 draw option like ROOT does; 3. Fix - correctly handle TH2Poly draw options; 4. Fix - seldom error in JSROOT.cleanup; 5. Fix - repair TTree player UI; 6. Fix - error in TH3 filling; 7. Fix - correctly access top element in simple layout; 8. Fix - exclude duplicated points when drawing TH2 with SURF3 options. ## Changes in 5.6.3; 1. Fix - support clipping for tracks and points in geo painter; 2. Fix - geometry with TGeoNodeOffset was not correctly drawn; 3. Fix - use proper formatting for entries and integral (#179); 4. Fix - TTree::Draw for 3d histogram was not properly performed. ## Changes in 5.6.2; 1. Fix - correctly handle negative parameter values in TF1/TF2. ## Changes in 5.6.1; 1. Add TMath.BreitWigner function; 2. Support custom streamers for TMaterial and TMixture (very old examples); 3. Fix Y-scale drawing of THStack (https://root-forum.cern.ch/t/31266); 4. Fix - select palette from colz element; 5. Fix - LZ4 uncompression of large buffers. ## Changes in 5.6.0; 1. By drawing outline speed up (factor 10) canvas with many small sub-pads; 2. Let configure user click and double-click handlers, extend tooltip.htm example; 3. Implement workaround for standard THREE.SVGRenderer - no need for patched version; 4. When producing 3D graphical images in batch, use normal THREE.CanvasRenderer; 5. Use WebGL renderer in Chrome headless mode for 3D images generation; 6. Provide possibility to create SVG files for canvas or frame (#172); 7. Support text drawing with TH1 bar option; 8. Fix - when drawing text, reserve extra y range to sho",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:31806,perform,performed,31806,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['perform'],['performed']
Performance,"iption: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void say_hello(MyClass* m) {; ... std::cout << ""Hello, the number is: "" << m->m_data << std::endl;; ... }""""""); True; >>> MyClass.say_hello = cppyy.gbl.say_hello; >>> m.say_hello(); Hello, the number is: 42; >>> m.m_data = 13; >>> m.s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:1158,perform,performance,1158,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst,2,['perform'],['performance']
Performance,"ir vector; widths. This restricts the types of loops that can be vectorized. The vectorizer; automatically determines if the loop is safe and profitable to vectorize. A; vector instruction cost model is used to select the vector width. Interleaving multiple loop iterations allows modern processors to further; improve instruction-level parallelism (ILP) using advanced hardware features,; such as multiple execution units and out-of-order execution. The vectorizer uses; a cost model that depends on the register pressure and generated code size to; select the interleaving count. Vectorization is enabled by ``vectorize(enable)`` and interleaving is enabled; by ``interleave(enable)``. This is useful when compiling with ``-Os`` to; manually enable vectorization or interleaving. .. code-block:: c++. #pragma clang loop vectorize(enable); #pragma clang loop interleave(enable); for(...) {; ...; }. The vector width is specified by; ``vectorize_width(_value_[, fixed|scalable])``, where _value_ is a positive; integer and the type of vectorization can be specified with an optional; second parameter. The default for the second parameter is 'fixed' and; refers to fixed width vectorization, whereas 'scalable' indicates the; compiler should use scalable vectors instead. Another use of vectorize_width; is ``vectorize_width(fixed|scalable)`` where the user can hint at the type; of vectorization to use without specifying the exact width. In both variants; of the pragma the vectorizer may decide to fall back on fixed width; vectorization if the target does not support scalable vectors. The interleave count is specified by ``interleave_count(_value_)``, where; _value_ is a positive integer. This is useful for specifying the optimal; width/count of the set of target architectures supported by your application. .. code-block:: c++. #pragma clang loop vectorize_width(2); #pragma clang loop interleave_count(2); for(...) {; ...; }. Specifying a width/count of 1 disables the optimization, and is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:164445,scalab,scalable,164445,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['scalab'],['scalable']
Performance,"ir(). llvm_ExternalProject_Add(builtins; ${compiler_rt_path}/lib/builtins; DEPENDS ${ARG_DEPENDS}; CMAKE_ARGS -DLLVM_LIBRARY_OUTPUT_INTDIR=${LLVM_LIBRARY_DIR}; -DLLVM_RUNTIME_OUTPUT_INTDIR=${LLVM_TOOLS_BINARY_DIR}; -DLLVM_DEFAULT_TARGET_TRIPLE=${LLVM_TARGET_TRIPLE}; -DLLVM_ENABLE_PER_TARGET_RUNTIME_DIR=${LLVM_ENABLE_PER_TARGET_RUNTIME_DIR}; -DCMAKE_C_COMPILER_WORKS=ON; -DCMAKE_ASM_COMPILER_WORKS=ON; ${COMMON_CMAKE_ARGS}; ${BUILTINS_CMAKE_ARGS}; PASSTHROUGH_PREFIXES COMPILER_RT; DARWIN; SANITIZER; USE_TOOLCHAIN; TARGET_TRIPLE ${LLVM_TARGET_TRIPLE}; ${EXTRA_ARGS}); endfunction(). function(builtin_register_target compiler_rt_path name); cmake_parse_arguments(ARG """" """" ""DEPENDS;CMAKE_ARGS;EXTRA_ARGS"" ${ARGN}). set(${name}_extra_args ${ARG_CMAKE_ARGS}); get_cmake_property(variable_names VARIABLES); foreach(variable_name ${variable_names}); string(FIND ""${variable_name}"" ""BUILTINS_${name}"" out); if(""${out}"" EQUAL 0); string(REPLACE ""BUILTINS_${name}_"" """" new_name ${variable_name}); if(new_name STREQUAL CACHE_FILES); foreach(cache IN LISTS ${variable_name}); list(APPEND ${name}_extra_args -C ${cache}); endforeach(); else(); string(REPLACE "";"" ""|"" new_value ""${${variable_name}}""); list(APPEND ${name}_extra_args ""-D${new_name}=${new_value}""); endif(); endif(); endforeach(). llvm_ExternalProject_Add(builtins-${name}; ${compiler_rt_path}/lib/builtins; DEPENDS ${ARG_DEPENDS}; CMAKE_ARGS -DLLVM_LIBRARY_OUTPUT_INTDIR=${LLVM_LIBRARY_DIR}; -DLLVM_RUNTIME_OUTPUT_INTDIR=${LLVM_TOOLS_BINARY_DIR}; -DLLVM_ENABLE_PER_TARGET_RUNTIME_DIR=ON; -DCMAKE_C_COMPILER_WORKS=ON; -DCMAKE_ASM_COMPILER_WORKS=ON; -DCOMPILER_RT_DEFAULT_TARGET_ONLY=ON; ${COMMON_CMAKE_ARGS}; ${${name}_extra_args}; USE_TOOLCHAIN; ${EXTRA_ARGS} ${ARG_EXTRA_ARGS}); endfunction(). # If compiler-rt is present we need to build the builtin libraries first. This; # is required because the other runtimes need the builtin libraries present; # before the just-built compiler can pass the configuration tests.; get_compiler_rt_path(com",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt:3907,cache,cache,3907,interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,2,['cache'],['cache']
Performance,"ired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:363813,load,load,363813,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"is `AppendPad()`. This statement calls method; of **`TObject`** that just adds the pointer of the object, here a; histogram, to the list of objects attached to the current pad. Since; this is a **`TObject`**'s method, every object may be ""drawn"", which; means attached to a pad. When is the painting done then ? The answer is: when needed. Every object; that derives from **`TObject`** has a `Paint()` method. It may be empty,; but for graphical objects, this routine contains all the instructions to; paint effectively it in the active pad. Since a Pad has the list of; objects it owns, it will call successively the `Paint()` method of each; object, thus re-painting the whole pad on the screen. If the object is a; sub-pad, its `Paint()` method will call the `Paint()` method of the; objects attached, recursively calling `Paint()` for all the objects. ![Pad painting](pictures/pad_02.png). In some cases a pad need to be painted during a macro execution. To; force the pad painting `gPad->Update()` (see next section) should be performed. The list of primitives stored in the pad is also used to pick objects; and to interact with them. ### The Global Pad: gPad. When an object is drawn, it is always in the so-called active pad. For; every day use, it is comfortable to be able to access the active pad,; whatever it is. For that purpose, there is a global pointer, called; ***`gPad`***. It is always pointing to the active pad. If you want to; change the fill color of the active pad to blue but you do not know its; name, do this. ``` {.cpp}; root[] gPad->SetFillColor(38); ```. To get the list of colors, go to the paragraph ""Color and color; palettes"" or if you have an opened canvas, click on the `View` menu,; selecting the `Colors` item. #### Finding an Object in a Pad. Now that we have a pointer to the active pad, ***`gPad`*** and that we; know this pad contains some objects, it is sometimes interesting to; access one of those objects. The method `GetPrimitive()` of **`TPad`**,; i.e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:14999,perform,performed,14999,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['perform'],['performed']
Performance,"is a summary of the changes made. All of these changes are; transparent to end-use cases ; ; ; New implementation of RooFit data types. The implementation of data stored in RooDataSet and RooDataHist; was historically handled by ROOT TTrees (though class RooTreeDataStore). The default storage type; has now been changed to class RooVectorDataStore which stores the information in STL arrays. Existing; datasets based on trees can be read in transparently, and are converted to vector form in the ; persistent-to-transient conversion (the datafile is not modified in this operation); ; The vector store has two important advantages: 1) faster data access (raw data access times are 70 times ; faster than for TTrees), 2) ability to rewrite columns on the fly. The first advantage is important; for the existing constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:1365,optimiz,optimization,1365,roofit/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html,2,['optimiz'],['optimization']
Performance,"is document covers how to integrate LLVM into a compiler for a language which; supports garbage collection. **Note that LLVM itself does not provide a; garbage collector.** You must provide your own. Quick Start; ============. First, you should pick a collector strategy. LLVM includes a number of built; in ones, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to know about) in your generated IR, so that LLVM can encode them into; your final stack maps. Depending on the collector strategy chosen, this is; accomplishe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:1155,load,load,1155,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['load']
Performance,"is fine to mix `Numba`_ and cppyy code.; It does mean a download cost of about 20MB for the binary wheel (exact size; differs per platform) on installation, and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-approach is beneficial.; In High Energy Physics, from which it originated, cppyy is regularly used in; software stacks of many thousands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:9015,load,loading,9015,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,1,['load'],['loading']
Performance,"is function will be decorated with optnone.; int foo() {; // ... code; }. // optnone conflicts with always_inline, so bar() will not be decorated.; __attribute__((always_inline)) int bar() {; // ... code; }; #pragma clang optimize on. If no ``on`` is found to close an ``off`` region, the end of the region is the; end of the compilation unit. Note that a stray ``#pragma clang optimize on`` does not selectively enable; additional optimizations when compiling at low optimization levels. This feature; can only be used to selectively disable optimizations. The pragma has an effect on functions only at the point of their definition; for; function templates, this means that the state of the pragma at the point of an; instantiation is not necessarily relevant. Consider the following example:. .. code-block:: c++. template<typename T> T twice(T t) {; return 2 * t;; }. #pragma clang optimize off; template<typename T> T thrice(T t) {; return 3 * t;; }. int container(int a, int b) {; return twice(a) + thrice(b);; }; #pragma clang optimize on. In this example, the definition of the template function ``twice`` is outside; the pragma region, whereas the definition of ``thrice`` is inside the region.; The ``container`` function is also in the region and will not be optimized, but; it causes the instantiation of ``twice`` and ``thrice`` with an ``int`` type; of; these two instantiations, ``twice`` will be optimized (because its definition; was outside the region) and ``thrice`` will not be optimized. Clang also implements MSVC's range-based pragma,; ``#pragma optimize(""[optimization-list]"", on | off)``. At the moment, Clang only; supports an empty optimization list, whereas MSVC supports the arguments, ``s``,; ``g``, ``t``, and ``y``. Currently, the implementation of ``pragma optimize`` behaves; the same as ``#pragma clang optimize``. All functions; between ``off`` and ``on`` will be decorated with the ``optnone`` attribute. .. code-block:: c++. #pragma optimize("""", off); // This fun",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:160530,optimiz,optimize,160530,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimize']
Performance,"is increases maintenance cost for; link time optimizer significantly, which is not necessary. This approach; also requires staying synchronized with linker developments on various; platforms, which is not the main focus of the link time optimizer. Finally,; this approach increases end user's build time due to the duplication of work; done by this separate tool and the linker itself. Multi-phase communication between ``libLTO`` and linker; =======================================================. The linker collects information about symbol definitions and uses in various; link objects which is more accurate than any information collected by other; tools during typical build cycles. The linker collects this information by; looking at the definitions and uses of symbols in native .o files and using; symbol visibility information. The linker also uses user-supplied information,; such as a list of exported symbols. LLVM optimizer collects control flow; information, data flow information and knows much more about program structure; from the optimizer's point of view. Our goal is to take advantage of tight; integration between the linker and the optimizer by sharing this information; during various linking phases. Phase 1 : Read LLVM Bitcode Files; ---------------------------------. The linker first reads all object files in natural order and collects symbol; information. This includes native object files as well as LLVM bitcode files.; To minimize the cost to the linker in the case that all .o files are native; object files, the linker only calls ``lto_module_create()`` when a supplied; object file is found to not be a native object file. If ``lto_module_create()``; returns that the file is an LLVM bitcode file, the linker then iterates over the; module using ``lto_module_get_symbol_name()`` and; ``lto_module_get_symbol_attribute()`` to get all symbols defined and referenced.; This information is added to the linker's global symbol table. The lto* functions are all implem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:5139,optimiz,optimizer,5139,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,2,['optimiz'],['optimizer']
Performance,"is known to; never be null. If the value is null at runtime, a poison value is returned; instead. This is analogous to the ``nonnull`` attribute on parameters and; return values. This metadata can only be applied to loads of a pointer type. The optional ``!dereferenceable`` metadata must reference a single metadata; name ``<deref_bytes_node>`` corresponding to a metadata node with one ``i64``; entry.; See ``dereferenceable`` metadata :ref:`dereferenceable <md_dereferenceable>`. The optional ``!dereferenceable_or_null`` metadata must reference a single; metadata name ``<deref_bytes_node>`` corresponding to a metadata node with one; ``i64`` entry.; See ``dereferenceable_or_null`` metadata :ref:`dereferenceable_or_null; <md_dereferenceable_or_null>`. The optional ``!align`` metadata must reference a single metadata name; ``<align_node>`` corresponding to a metadata node with one ``i64`` entry.; The existence of the ``!align`` metadata on the instruction tells the; optimizer that the value loaded is known to be aligned to a boundary specified; by the integer value in the metadata node. The alignment must be a power of 2.; This is analogous to the ''align'' attribute on parameters and return values.; This metadata can only be applied to loads of a pointer type. If the returned; value is not appropriately aligned at runtime, a poison value is returned; instead. The optional ``!noundef`` metadata must reference a single metadata name; ``<empty_node>`` corresponding to a node with no entries. The existence of; ``!noundef`` metadata on the instruction tells the optimizer that the value; loaded is known to be :ref:`well defined <welldefinedvalues>`.; If the value isn't well defined, the behavior is undefined. If the ``!noundef``; metadata is combined with poison-generating metadata like ``!nonnull``,; violation of that metadata constraint will also result in undefined behavior. Semantics:; """""""""""""""""""". The location of memory pointed to is loaded. If the value being loaded; is o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:417166,optimiz,optimizer,417166,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['load', 'optimiz']","['loaded', 'optimizer']"
Performance,"is loop will be split into two loops between statements S1 and S2. The; second loop containing S2 will be vectorized. Loop Distribution is currently not enabled by default in the optimizer because; it can hurt performance in some cases. For example, instruction-level; parallelism could be reduced by sequentializing the execution of the; statements S1 and S2 above. If Loop Distribution is turned on globally with; ``-mllvm -enable-loop-distribution``, specifying ``distribute(disable)`` can; be used the disable it on a per-loop basis. Additional Information; ----------------------. For convenience multiple loop hints can be specified on a single line. .. code-block:: c++. #pragma clang loop vectorize_width(4) interleave_count(8); for(...) {; ...; }. If an optimization cannot be applied any hints that apply to it will be ignored.; For example, the hint ``vectorize_width(4)`` is ignored if the loop is not; proven safe to vectorize. To identify and diagnose optimization issues use; `-Rpass`, `-Rpass-missed`, and `-Rpass-analysis` command line options. See the; user guide for details. Extensions to specify floating-point flags; ====================================================. The ``#pragma clang fp`` pragma allows floating-point options to be specified; for a section of the source code. This pragma can only appear at file scope or; at the start of a compound statement (excluding comments). When using within a; compound statement, the pragma is active within the scope of the compound; statement. Currently, the following settings can be controlled with this pragma:. ``#pragma clang fp reassociate`` allows control over the reassociation; of floating point expressions. When enabled, this pragma allows the expression; ``x + (y + z)`` to be reassociated as ``(x + y) + z``.; Reassociation can also occur across multiple statements.; This pragma can be used to disable reassociation when it is otherwise; enabled for the translation unit with the ``-fassociative-math`` flag.; The",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:169419,optimiz,optimization,169419,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimization']
Performance,"is necessary to insert; bounds checking for ``buf[i]``. .. code-block:: c. void *__sized_by(size) malloc(size_t size);. int *__counted_by(n) get_array_with_0_to_n_1(size_t n) {; int *buf = malloc(sizeof(int) * n);; for (size_t i = 0; i < n; ++i); buf[i] = i;; return buf;; }. Annotations for sentinel-delimited arrays; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A C string is an array of characters. The null terminator  the first null; character ('\0') element in the array  marks the end of the string.; ``-fbounds-safety`` provides ``__null_terminated`` to annotate C strings and the; generalized form ``__terminated_by(T)`` to annotate pointers and arrays with an; end marked by a sentinel value. The model prevents dereferencing a; ``__terminated_by`` pointer beyond its end. Calculating the location of the end; (i.e., the address of the sentinel value), requires reading the entire array in; memory and would have some performance costs. To avoid an unintended performance; hit, the model puts some restrictions on how these pointers can be used.; ``__terminated_by`` pointers cannot be indexed and can only be incremented one; element at a time. To allow these operations, the pointers must be explicitly; converted to ``__indexable`` pointers using the intrinsic function; ``__unsafe_terminated_by_to_indexable(P, T)`` (or; ``__unsafe_null_terminated_to_indexable(P)``) which converts the; ``__terminated_by`` pointer ``P`` to an ``__indexable`` pointer. * ``__null_terminated`` : The pointer or array is terminated by ``NULL`` or; ``0``. Modifying the terminator or incrementing the pointer beyond it is; prevented at run time. * ``__terminated_by(T)`` : The pointer or array is terminated by ``T`` which is; a constant expression. Accessing or incrementing the pointer beyond the; terminator is not allowed. This is a generalization of ``__null_terminated``; which is defined as ``__terminated_by(0)``. Annotation for interoperating with bounds-unsafe code; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:18466,perform,performance,18466,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['perform'],['performance']
Performance,"is needed to copy the contents of html directory without; # appending html/ into LLVM_INSTALL_DOXYGEN_HTML_DIR.; install(DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/doxygen/html/.; COMPONENT doxygen-html; DESTINATION ""${LLVM_INSTALL_DOXYGEN_HTML_DIR}""); endif(); endif(); endif(). if (LLVM_ENABLE_SPHINX); include(AddSphinxTarget); if (SPHINX_FOUND); if (${SPHINX_OUTPUT_HTML}); add_sphinx_target(html llvm); endif(). if (${SPHINX_OUTPUT_MAN}); add_sphinx_target(man llvm); add_sphinx_target(man llvm-dwarfdump); add_sphinx_target(man dsymutil); endif(). endif(); endif(). list(FIND LLVM_BINDINGS_LIST ocaml uses_ocaml); if( NOT uses_ocaml LESS 0 AND LLVM_ENABLE_OCAMLDOC ); set(doc_targets; ocaml_llvm; ocaml_llvm_all_backends; ocaml_llvm_analysis; ocaml_llvm_bitreader; ocaml_llvm_bitwriter; ocaml_llvm_executionengine; ocaml_llvm_irreader; ocaml_llvm_linker; ocaml_llvm_target; ocaml_llvm_transform_utils; ). foreach(llvm_target ${LLVM_TARGETS_TO_BUILD}); list(APPEND doc_targets ocaml_llvm_${llvm_target}); endforeach(). set(odoc_files); foreach( doc_target ${doc_targets} ); get_target_property(odoc_file ${doc_target} OCAML_ODOC); list(APPEND odoc_files -load ${odoc_file}); endforeach(). add_custom_target(ocaml_doc; COMMAND ${CMAKE_COMMAND} -E remove_directory ${CMAKE_CURRENT_BINARY_DIR}/ocamldoc/html; COMMAND ${CMAKE_COMMAND} -E make_directory ${CMAKE_CURRENT_BINARY_DIR}/ocamldoc/html; COMMAND ${OCAMLFIND} ocamldoc -d ${CMAKE_CURRENT_BINARY_DIR}/ocamldoc/html; -sort -colorize-code -html ${odoc_files}; COMMAND ${CMAKE_COMMAND} -E copy ${CMAKE_CURRENT_SOURCE_DIR}/_ocamldoc/style.css; ${CMAKE_CURRENT_BINARY_DIR}/ocamldoc/html). add_dependencies(ocaml_doc ${doc_targets}). if (NOT LLVM_INSTALL_TOOLCHAIN_ONLY); # ./ suffix is needed to copy the contents of html directory without; # appending html/ into LLVM_INSTALL_OCAMLDOC_HTML_DIR.; install(DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/ocamldoc/html/.; COMPONENT ocamldoc-html; DESTINATION ""${LLVM_INSTALL_OCAMLDOC_HTML_DIR}""); endif(); endif(); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakeLists.txt:4453,load,load,4453,interpreter/llvm-project/llvm/docs/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakeLists.txt,1,['load'],['load']
Performance,"is not copyable, but derived from ``std::exception``, the; result of its ``what()`` reported with an instance of Python's ``Exception``.; In all other cases, including exceptions thrown from interpreted code (due to; limitations of the Clang JIT), the exception will turn into an instance of; ``Exception`` with a generic message. The standard C++ exceptions are explicitly not mapped onto standard Python; exceptions, since other than a few simple cases, the mapping is too crude to; be useful as the typical usage in each standard library is too different.; Thus, for example, a thrown ``std::runtime_error`` instance will become a; ``cppyy.gbl.std.runtime_error`` instance on the Python side (with Python's; ``Exception`` as its base class), not a ``RuntimeError`` instance. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. In addition, the examples require the ``throw`` to be in compiled code.; Save the following and build it into a shared library ``libfeatures.so`` (or; ``libfeatures.dll`` on MS Windows):. .. code-block:: C++. #include ""features.h"". void throw_an_error(int i) {; if (i) throw SomeError{""this is an error""};; throw SomeOtherError{""this is another error""};; }. And load the resulting library:. .. code-block:: python. >>> cppyy.load_library('libfeatures'); >>>. Then try it out:. .. code-block:: python. >>> cppyy.gbl.throw_an_error(1); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.SomeError: void ::throw_an_error(int i) =>; SomeError: this is an error; >>> . Note how the full type is preserved and how the result of ``what()`` is used; for printing the exception.; By preserving the full C++ type, it is possible to call any other member; functions the exception may provi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst:1927,load,load,1927,bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,1,['load'],['load']
Performance,"is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not termi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32233,optimiz,optimized,32233,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['optimiz'],['optimized']
Performance,"is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39807,load,load,39807,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,3,['load'],"['load', 'loads']"
Performance,"is option can dramatically slow down code on some systems; (e.g. X86). .. option:: --enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: --enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: --enable-no-signed-zeros-fp-math. Enable FP math optimizations that assume the sign of 0 is insignificant. .. option:: --enable-no-trapping-fp-math. Enable setting the FP exceptions build attribute not to use exceptions. .. option:: --enable-unsafe-fp-math. Enable optimizations that make unsafe assumptions about IEEE math (e.g. that; addition is associative) or may not work for all input ranges. These; optimizations allow the code generator to make use of some instructions which; would otherwise not be usable (such as ``fsin`` on X86). .. option:: --stats. Print statistics recorded by code-generation passes. .. option:: --time-passes. Record the amount of time needed for each pass and print a report to standard; error. .. option:: --load=<dso_path>. Dynamically load ``dso_path`` (a path to a dynamically shared object) that; implements an LLVM target. This will permit the target name to be used with; the :option:`-march` option so that code can be generated for that target. .. option:: -meabi=[default|gnu|4|5]. Specify which EABI version should conform to. Valid EABI versions are *gnu*,; *4* and *5*. Default value (*default*) depends on the triple. .. option:: -stack-size-section. Emit the .stack_sizes section which contains stack size metadata. The section; contains an array of pairs of function symbol values (pointer size) and stack; sizes (unsigned LEB128). The stack size values only include the space allocated; in the function prologue. Functions with dynamic stack allocations are not; included. .. option:: -remarks-section. Emit the __remarks (MachO) section which contains metadata about remark; diagnostics. Tuning/Configuration Options; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. option:: --print-after-isel. Print generat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst:4318,load,load,4318,interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,1,['load'],['load']
Performance,"is performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.sdot2 Provides direct access to v_dot2_i32_i16 across targets which; support such instructions. This performs signed dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output.; When applicable (e.g. no clamping), this is lowered into; v_dot2c_i32_i16 for targets which support it. llvm.amdgcn.sdot4 Provides direct access to v_dot4_i32_i8 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot4c_i32_i8 for targets which support it.; RDNA3 does not offer v_dot4_i32_i8, and rather offers; v_dot4_i32_iu8 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sdot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot8c_i32_i4 for targets which support it.; RDNA3 does not offer v_dot8_i32_i4, and rather offers; v_dot4_i32_iu4 which has operands to hold the signedness of the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:40443,perform,performs,40443,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performs']
Performance,"is program to create a little endian version of the table. The table; is used in PPCISelLowering.cpp, PPCTargetLowering::LOWERVECTOR_SHUFFLE(). //===----------------------------------------------------------------------===//. Opportunies to use instructions from PPCInstrVSX.td during code gen; - Conversion instructions (Sections 7.6.1.5 and 7.6.1.6 of ISA 2.07); - Scalar comparisons (xscmpodp and xscmpudp); - Min and max (xsmaxdp, xsmindp, xvmaxdp, xvmindp, xvmaxsp, xvminsp). Related to this: we currently do not generate the lxvw4x instruction for either; v4f32 or v4i32, probably because adding a dag pattern to the recognizer requires; a single target type. This should probably be addressed in the PPCISelDAGToDAG logic. //===----------------------------------------------------------------------===//. Currently EXTRACT_VECTOR_ELT and INSERT_VECTOR_ELT are type-legal only; for v2f64 with VSX available. We should create custom lowering; support for the other vector types. Without this support, we generate; sequences with load-hit-store hazards. v4f32 can be supported with VSX by shifting the correct element into; big-endian lane 0, using xscvspdpn to produce a double-precision; representation of the single-precision value in big-endian; double-precision lane 0, and reinterpreting lane 0 as an FPR or; vector-scalar register. v2i64 can be supported with VSX and P8Vector in the same manner as; v2f64, followed by a direct move to a GPR. v4i32 can be supported with VSX and P8Vector by shifting the correct; element into big-endian lane 1, using a direct move to a GPR, and; sign-extending the 32-bit result to 64 bits. v8i16 can be supported with VSX and P8Vector by shifting the correct; element into big-endian lane 3, using a direct move to a GPR, and; sign-extending the 16-bit result to 64 bits. v16i8 can be supported with VSX and P8Vector by shifting the correct; element into big-endian lane 7, using a direct move to a GPR, and; sign-extending the 8-bit result to 64 bits.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt:10300,load,load-hit-store,10300,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,2,['load'],['load-hit-store']
Performance,"is relatively simple;; they ultimately form a linked list of every clobber that dominates the; ``MemoryAccess`` that you're trying to optimize. In other words, the; ``definingAccess`` of a ``MemoryDef`` is always the nearest dominating; ``MemoryDef`` or ``MemoryPhi`` of said ``MemoryDef``. Use and Def optimization; ------------------------. ``MemoryUse``\ s keep a single operand, which is their defining or optimized; access.; Traditionally ``MemorySSA`` optimized ``MemoryUse``\ s at build-time, up to a; given threshold.; Specifically, the operand of every ``MemoryUse`` was optimized to point to the; actual clobber of said ``MemoryUse``. This can be seen in the above example; the; second ``MemoryUse`` in ``if.end`` has an operand of ``1``, which is a; ``MemoryDef`` from the entry block. This is done to make walking,; value numbering, etc, faster and easier.; As of `this revision <https://reviews.llvm.org/D121381>`_, the default was; changed to not optimize uses at build time, in order to provide the option to; reduce compile-time if the walking is not necessary in a pass. Most users call; the new API ``ensureOptimizedUses()`` to keep the previous behavior and do a; one-time optimization of ``MemoryUse``\ s, if this was not done before.; New pass users are recommended to call ``ensureOptimizedUses()``. Initially it was not possible to optimize ``MemoryDef``\ s in the same way, as we; restricted ``MemorySSA`` to one operand per access.; This was changed and ``MemoryDef``\ s now keep two operands.; The first one, the defining access, is; always the previous ``MemoryDef`` or ``MemoryPhi`` in the same basic block, or; the last one in a dominating predecessor if the current block doesn't have any; other accesses writing to memory. This is needed for walking Def chains.; The second operand is the optimized access, if there was a previous call on the; walker's ``getClobberingMemoryAccess(MA)``. This API will cache information; as part of ``MA``.; Optimizing all ``MemoryDef``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:11622,optimiz,optimize,11622,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimize']
Performance,"is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:207745,cache,cache,207745,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:239614,cache,cache,239614,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"is solution has solved our immediate problem, it introduced; another one: we have now apparently introduced a lot of stack traffic; for very simple and common operations, a major performance problem.; Fortunately for us, the LLVM optimizer has a highly-tuned optimization; pass named ""mem2reg"" that handles this case, promoting allocas like this; into SSA registers, inserting Phi nodes as appropriate. If you run this; example through the pass, for example, you'll get:. .. code-block:: bash. $ llvm-as < example.ll | opt -passes=mem2reg | llvm-dis; @G = weak global i32 0; @H = weak global i32 0. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.01 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.01; }. The mem2reg pass implements the standard ""iterated dominance frontier""; algorithm for constructing SSA form and has a number of optimizations; that speed up (very common) degenerate cases. The mem2reg optimization; pass is the answer to dealing with mutable variables, and we highly; recommend that you depend on it. Note that mem2reg only works on; variables in certain circumstances:. #. mem2reg is alloca-driven: it looks for allocas and if it can handle; them, it promotes them. It does not apply to global variables or heap; allocations.; #. mem2reg only looks for alloca instructions in the entry block of the; function. Being in the entry block guarantees that the alloca is only; executed once, which makes analysis simpler.; #. mem2reg only promotes allocas whose uses are direct loads and stores.; If the address of the stack object is passed to a function, or if any; funny pointer arithmetic is involved, the alloca will not be; promoted.; #. mem2reg only works on allocas of `first; class <../../LangRef.html#first-class-types>`_ values (such as pointers,; scalars and vectors), an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:7495,optimiz,optimizations,7495,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['optimiz'],['optimizations']
Performance,"is sufficient for both of these is to harden all of the; speculative stores. However, as most stores aren't interesting and don't; inherently leak data, this is expected to be prohibitively expensive given the; attack it is defending against. ## Implementation Details. There are a number of complex details impacting the implementation of this; technique, both on a particular architecture and within a particular compiler.; We discuss proposed implementation techniques for the x86 architecture and the; LLVM compiler. These are primarily to serve as an example, as other; implementation techniques are very possible. ### x86 Implementation Details. On the x86 platform we break down the implementation into three core; components: accumulating the predicate state through the control flow graph,; checking the loads, and checking control transfers between procedures. #### Accumulating Predicate State. Consider baseline x86 instructions like the following, which test three; conditions and if all pass, loads data from memory and potentially leaks it; through some side channel:; ```; # %bb.0: # %entry; pushq %rax; testl %edi, %edi; jne .LBB0_4; # %bb.1: # %then1; testl %esi, %esi; jne .LBB0_4; # %bb.2: # %then2; testl %edx, %edx; je .LBB0_3; .LBB0_4: # %exit; popq %rax; retq; .LBB0_3: # %danger; movl (%rcx), %edi; callq leak; popq %rax; retq; ```. When we go to speculatively execute the load, we want to know whether any of; the dynamically executed predicates have been misspeculated. To track that,; along each conditional edge, we need to track the data which would allow that; edge to be taken. On x86, this data is stored in the flags register used by the; conditional jump instruction. Along both edges after this fork in control flow,; the flags register remains alive and contains data that we can use to build up; our accumulated predicate state. We accumulate it using the x86 conditional; move instruction which also reads the flag registers where the state resides.; These cond",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:15206,load,loads,15206,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance,"is; being closed by a ``}``. For example:. .. code-block:: c++. namespace llvm {; namespace knowledge {. /// This class represents things that Smith can have an intimate; /// understanding of and contains the data associated with it.; class Grokable {; ...; public:; explicit Grokable() { ... }; virtual ~Grokable() = 0;. ... };. } // namespace knowledge; } // namespace llvm. Feel free to skip the closing comment when the namespace being closed is; obvious for any reason. For example, the outer-most namespace in a header file; is rarely a source of confusion. But namespaces both anonymous and named in; source files that are being closed half way through the file probably could use; clarification. .. _static:. Anonymous Namespaces; ^^^^^^^^^^^^^^^^^^^^. After talking about namespaces in general, you may be wondering about anonymous; namespaces in particular. Anonymous namespaces are a great language feature; that tells the C++ compiler that the contents of the namespace are only visible; within the current translation unit, allowing more aggressive optimization and; eliminating the possibility of symbol name collisions. Anonymous namespaces are; to C++ as ""static"" is to C functions and global variables. While ""``static``""; is available in C++, anonymous namespaces are more general: they can make entire; classes private to a file. The problem with anonymous namespaces is that they naturally want to encourage; indentation of their body, and they reduce locality of reference: if you see a; random function definition in a C++ file, it is easy to see if it is marked; static, but seeing if it is in an anonymous namespace requires scanning a big; chunk of the file. Because of this, we have a simple guideline: make anonymous namespaces as small; as possible, and only use them for class declarations. For example:. .. code-block:: c++. namespace {; class StringSort {; ...; public:; StringSort(...); bool operator<(const char *RHS) const;; };; } // namespace. static void runHelper(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:59933,optimiz,optimization,59933,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['optimiz'],['optimization']
Performance,"is; the condition code indicating the kind of comparison to perform. It is; not a value, just a keyword. The possible condition codes are:. .. _icmp_md_cc:. #. ``eq``: equal; #. ``ne``: not equal; #. ``ugt``: unsigned greater than; #. ``uge``: unsigned greater or equal; #. ``ult``: unsigned less than; #. ``ule``: unsigned less or equal; #. ``sgt``: signed greater than; #. ``sge``: signed greater or equal; #. ``slt``: signed less than; #. ``sle``: signed less or equal. The remaining two arguments must be :ref:`integer <t_integer>` or; :ref:`pointer <t_pointer>` or integer :ref:`vector <t_vector>` typed. They; must also be identical types. Semantics:; """""""""""""""""""". The '``icmp``' compares ``op1`` and ``op2`` according to the condition; code given as ``cond``. The comparison performed always yields either an; :ref:`i1 <t_integer>` or vector of ``i1`` result, as follows:. .. _icmp_md_cc_sem:. #. ``eq``: yields ``true`` if the operands are equal, ``false``; otherwise. No sign interpretation is necessary or performed.; #. ``ne``: yields ``true`` if the operands are unequal, ``false``; otherwise. No sign interpretation is necessary or performed.; #. ``ugt``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is greater than ``op2``.; #. ``uge``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is greater than or equal to ``op2``.; #. ``ult``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is less than ``op2``.; #. ``ule``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is less than or equal to ``op2``.; #. ``sgt``: interprets the operands as signed values and yields ``true``; if ``op1`` is greater than ``op2``.; #. ``sge``: interprets the operands as signed values and yields ``true``; if ``op1`` is greater than or equal to ``op2``.; #. ``slt``: interprets the operands as signed values and yields ``true``; if ``op1`` is less than ``op2``.; #. ``sle``: interprets the opera",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:460918,perform,performed,460918,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"is; undefined behavior to direct modify a ``__weak`` object which is being tracked; by the runtime except through an; :ref:`objc_storeWeak <arc.runtime.objc_storeWeak>`,; :ref:`objc_destroyWeak <arc.runtime.objc_destroyWeak>`, or; :ref:`objc_moveWeak <arc.runtime.objc_moveWeak>` call. The runtime must provide a number of new entrypoints which the compiler may; emit, which are described in the remainder of this section. .. admonition:: Rationale. Several of these functions are semantically equivalent to a message send; we; emit calls to C functions instead because:. * the machine code to do so is significantly smaller,; * it is much easier to recognize the C functions in the ARC optimizer, and; * a sufficient sophisticated runtime may be able to avoid the message send in; common cases. Several other of these functions are ""fused"" operations which can be; described entirely in terms of other operations. We use the fused operations; primarily as a code-size optimization, although in some cases there is also a; real potential for avoiding redundant operations in the runtime. .. _arc.runtime.objc_autorelease:. ``id objc_autorelease(id value);``; ----------------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it adds the object; to the innermost autorelease pool exactly as if the object had been sent the; ``autorelease`` message. Always returns ``value``. .. _arc.runtime.objc_autoreleasePoolPop:. ``void objc_autoreleasePoolPop(void *pool);``; ---------------------------------------------. *Precondition:* ``pool`` is the result of a previous call to; :ref:`objc_autoreleasePoolPush <arc.runtime.objc_autoreleasePoolPush>` on the; current thread, where neither ``pool`` nor any enclosing pool have previously; been popped. Releases all the objects added to the given autorelease pool and any; autorelease pools it encloses, then sets the current autorelease pool to the; pool directly en",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:106823,optimiz,optimization,106823,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimization']
Performance,"isfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:280059,load,load,280059,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:149940,queue,queue,149940,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance,"ist of metadata that; describe the IR. For our purposes, we need to declare a metadata node that; assigns the ""kernel"" attribute to the LLVM IR function that should be emitted; as a PTX `kernel` function. These metadata nodes take the form:. .. code-block:: text. !{<function ref>, metadata !""kernel"", i32 1}. For the previous example, we have:. .. code-block:: llvm. !nvvm.annotations = !{!0}; !0 = !{void (float addrspace(1)*,; float addrspace(1)*,; float addrspace(1)*)* @kernel, !""kernel"", i32 1}. Here, we have a single metadata declaration in ``nvvm.annotations``. This; metadata annotates our ``@kernel`` function with the ``kernel`` attribute. Running the Kernel; ------------------. Generating PTX from LLVM IR is all well and good, but how do we execute it on; a real GPU device? The CUDA Driver API provides a convenient mechanism for; loading and JIT compiling PTX to a native GPU device, and launching a kernel.; The API is similar to OpenCL. A simple example showing how to load and; execute our vector addition code is shown below. Note that for brevity this; code does not perform much error checking!. .. note::. You can also use the ``ptxas`` tool provided by the CUDA Toolkit to offline; compile PTX to machine code (SASS) for a specific GPU architecture. Such; binaries can be loaded by the CUDA Driver API in the same way as PTX. This; can be useful for reducing startup time by precompiling the PTX kernels. .. code-block:: c++. #include <iostream>; #include <fstream>; #include <cassert>; #include ""cuda.h"". void checkCudaErrors(CUresult err) {; assert(err == CUDA_SUCCESS);; }. /// main - Program entry point; int main(int argc, char **argv) {; CUdevice device;; CUmodule cudaModule;; CUcontext context;; CUfunction function;; CUlinkState linker;; int devCount;. // CUDA initialization; checkCudaErrors(cuInit(0));; checkCudaErrors(cuDeviceGetCount(&devCount));; checkCudaErrors(cuDeviceGet(&device, 0));. char name[128];; checkCudaErrors(cuDeviceGetName(name, 128, device));; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst:19111,load,load,19111,interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,1,['load'],['load']
Performance,"ist, the head is ``DeclContext::FirstDecl``) could be empty. However, member; functions like ``DeclContext::lookup()`` may initiate a load. Usually, external sources are associated with precompiled headers. For example,; when we load a class from a PCH then the members are loaded only if we do want; to look up something in the class' context. In case of LLDB, an implementation of the ``ExternalASTSource`` interface is; attached to the AST context which is related to the parsed expression. This; implementation of the ``ExternalASTSource`` interface is realized with the help; of the ``ASTImporter`` class. This way, LLDB can reuse Clang's parsing; machinery while synthesizing the underlying AST from the debug data (e.g. from; DWARF). From the view of the ``ASTImporter`` this means both the ""to"" and the; ""from"" context may have declaration contexts with external lexical storage. If; a ``DeclContext`` in the ""to"" AST context has external lexical storage then we; must take extra attention to work only with the already loaded declarations!; Otherwise, we would end up with an uncontrolled import process. For instance,; if we used the regular ``DeclContext::lookup()`` to find the existing; declarations in the ""to"" context then the ``lookup()`` call itself would; initiate a new import while we are in the middle of importing a declaration!; (By the time we initiate the lookup we haven't registered yet that we already; started to import the node of the ""from"" context.) This is why we use; ``DeclContext::noload_lookup()`` instead. Class Template Instantiations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Different translation units may have class template instantiations with the; same template arguments, but with a different set of instantiated; ``MethodDecls`` and ``FieldDecls``. Consider the following files:. .. code-block:: c++. // x.h; template <typename T>; struct X {; int a{0}; // FieldDecl with InitListExpr; X(char) : a(3) {} // (1); X(int) {} // (2); };. // foo.cpp; void foo() {; // ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:107819,load,loaded,107819,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['load'],['loaded']
Performance,"ist` and `libTree`.; If ROOT needs access to other libraries, it loads them dynamically.; For example, if the **`TreeViewer`** is used, `libTreePlayer` and all; libraries `libTreePlayer` depends on are loaded also. The dependent; libraries are shown in the ROOT reference guide's library dependency; graph. The difference between reference guide `libHist` and; `libHistPainter` is that the former needs to be explicitly linked and; the latter will be loaded automatically at runtime when ROOT needs it,; by means of the Plugin Manager. plugin manager. In the Figure 1-2, the libraries represented by green boxes outside of; the core are loaded via the plugin manager plugin manager or; equivalent techniques, while the white ones are not. Of course, if one; wants to access a plugin library directly, it has to be explicitly; linked. An example of a plugin library is `libMinuit`. To create and; fill histograms you need to link `libHist.so`. If the code has a call; to fit the histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin class of which an object will be created; (e.g. **`TRFIOFile`**), the library to be loaded (in short; `libRFIO.so` to RFIO), and the constructor to be called (e.g.; ""`TRFIOFile()`""). This can be specified in the `.rootrc` which already; contains many plugin definitions, or by calls to; `gROOT->GetPluginManager()->AddHandler()`. #### Library AutoLoading. When using a class in Cling, e.g. in an interpreted source file, ROOT; will automatically load the library",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:18877,load,load,18877,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,2,['load'],"['load', 'loaded']"
Performance,"isting predicate, but note; that they return true for any operation which is volatile or at least; Monotonic. * ``isStrongerThan`` / ``isAtLeastOrStrongerThan``: These are predicates on; orderings. They can be useful for passes that are aware of atomics, for; example to do DSE across a single atomic access, but not across a; release-acquire pair (see MemoryDependencyAnalysis for an example of this). * Alias analysis: Note that AA will return ModRef for anything Acquire or; Release, and for the address accessed by any Monotonic operation. To support optimizing around atomic operations, make sure you are using the; right predicates; everything should work if that is done. If your pass should; optimize some atomic operations (Unordered operations in particular), make sure; it doesn't replace an atomic load or store with a non-atomic operation. Some examples of how optimizations interact with various kinds of atomic; operations:. * ``memcpyopt``: An atomic operation cannot be optimized into part of a; memcpy/memset, including unordered loads/stores. It can pull operations; across some atomic operations. * LICM: Unordered loads/stores can be moved out of a loop. It just treats; monotonic operations like a read+write to a memory location, and anything; stricter than that like a nothrow call. * DSE: Unordered stores can be DSE'ed like normal stores. Monotonic stores can; be DSE'ed in some cases, but it's tricky to reason about, and not especially; important. It is possible in some case for DSE to operate across a stronger; atomic operation, but it is fairly tricky. DSE delegates this reasoning to; MemoryDependencyAnalysis (which is also used by other passes like GVN). * Folding a load: Any atomic load from a constant global can be constant-folded,; because it cannot be observed. Similar reasoning allows sroa with; atomic loads and stores. Atomics and Codegen; ===================. Atomic operations are represented in the SelectionDAG with ``ATOMIC_*`` opcodes.; On architect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:17221,optimiz,optimized,17221,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,"['load', 'optimiz']","['loads', 'optimized']"
Performance,"istogram until end of file is reached. ``` {.cpp}; root [1] TH1F h(""h"",""example histogram"",100,0.,5.);; root [2] ifstream inp; double x;; root [3] inp.open(""expo.dat"");; root [4] while (inp >> x) { h.Fill(x); }; root [5] h.Draw();; root [6] inp.close();; ```. Histograms and random numbers are very important tools in statistical; data analysis, a whole chapter will be dedicated to this topic. ## Interactive ROOT ##. Look at one of your plots again and move the mouse across. You will; notice that this is much more than a static picture, as the mouse; pointer changes its shape when touching objects on the plot. When the; mouse is over an object, a right-click opens a pull-down menu displaying; in the top line the name of the ROOT class you are dealing with, e.g.; `TCanvas` for the display window itself, `TFrame` for the frame of the; plot, `TAxis` for the axes, `TPaveText` for the plot name. Depending on; which plot you are investigating, menus for the ROOT classes `TF1`,; `TGraphErrors` or `TH1F` will show up when a right-click is performed on; the respective graphical representations. The menu items allow direct; access to the members of the various classes, and you can even modify; them, e.g. change colour and size of the axis ticks or labels, the; function lines, marker types and so on. Try it!. [f24]: figures/ROOTPanel_SetParameters.png ""f24""; <a name=""f24""></a>. ![Interactive ROOT panel for setting function parameters.\label{f24}][f24]. You will probably like the following: in the output produced by the; example `slits.C`, right-click on the function line and select; ""SetLineAttributes"", then left-click on ""Set Parameters"". This gives; access to a panel allowing you to interactively change the parameters of; the function, as shown in Figure [2.4](#f24). Change the slit width, or go from one to; two and then three or more slits, just as you like. When clicking on; ""Apply"", the function plot is updated to reflect the actual value of the; parameters you have set. [f2",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:13738,perform,performed,13738,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['perform'],['performed']
Performance,"istribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2708,perform,perform,2708,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['perform'],['perform']
Performance,"isualize it with ray tracing; top->Raytrace();; ```. ![A composite shape example](pictures/080001CD.png). Composite shapes can be subsequently used for defining volumes.; Moreover, these volumes contain other volumes, following the general; criteria. Volumes created based on composite shapes cannot be divided. ### Navigation Methods Performed By Shapes. Shapes are named objects and register themselves to the `manager class`; at creation time. This is responsible for their final deletion. Shapes; can be created without name if their retrieval by name is no needed.; Generally shapes are objects that are useful only at geometry creation; stage. The pointer to a shape is in fact needed only when referring to a; given volume and it is always accessible at that level. Several volumes; may reference a single shape; therefore its deletion is not possible; once volumes were defined based on it. The navigation features related for instance to tracking particles are; performed in the following way: Each shape implement its specific; algorithms for all required tasks in its local reference system. Note; that the manager class handles global queries related to geometry.; However, shape-related queries might be sometimes useful:. ``` {.cpp}; Bool_t TGeoShape::Contains(Double_t *point[3]);; ```. The method above returns `kTRUE` if the point \*point is actually inside; the shape. The point has to be defined in the local shape reference. For; instance, for a box having `DX,DY` and `DZ `half-lengths a point will be; considered inside if:. `-DX <= point[0] <= DX`. `-DY <= point[1] <= DY`. `-DZ <= point[2] <= DZ`. ``` {.cpp}; Double_t TGeoShape::DistFromInside(Double_t *point[3],; Double_t *dir[3], Int_t iact,Double_t step,Double_t *safe);; ```. The method computes the distance to exiting a shape from a given point; `inside`, along a given direction. This direction is given by its; director cosines with respect to the local shape coordinate system. This; method provides additional info",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:50074,perform,performed,50074,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance,"it aligned. When LLVM is determining the alignment for a given type, it uses the; following rules:. #. If the type sought is an exact match for one of the specifications,; that specification is used.; #. If no match is found, and the type sought is an integer type, then; the smallest integer type that is larger than the bitwidth of the; sought type is used. If none of the specifications are larger than; the bitwidth then the largest integer type is used. For example,; given the default specifications above, the i7 type will use the; alignment of i8 (next largest) while both i65 and i256 will use the; alignment of i64 (largest specified). The function of the data layout string may not be what you expect.; Notably, this is not a specification from the frontend of what alignment; the code generator should use. Instead, if specified, the target data layout is required to match what; the ultimate *code generator* expects. This string is used by the; mid-level optimizers to improve code, and this only works if it matches; what the ultimate code generator uses. There is no way to generate IR; that does not embed this target-specific detail into the IR. If you; don't specify the string, the default specifications will be used to; generate a Data Layout and the optimization phases will operate; accordingly and introduce target specificity into the IR with respect to; these default specifications. .. _langref_triple:. Target Triple; -------------. A module may specify a target triple string that describes the target; host. The syntax for the target triple is simply:. .. code-block:: llvm. target triple = ""x86_64-apple-macosx10.7.0"". The *target triple* string consists of a series of identifiers delimited; by the minus sign character ('-'). The canonical forms are:. ::. ARCHITECTURE-VENDOR-OPERATING_SYSTEM; ARCHITECTURE-VENDOR-OPERATING_SYSTEM-ENVIRONMENT. This information is passed along to the backend so that it generates; code for the proper architecture. It's possible to o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:138969,optimiz,optimizers,138969,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizers']
Performance,"it and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:40197,load,loads,40197,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['load'],['loads']
Performance,"it becomes MIR. Although we tend to talk about them as distinct passes, it should be noted that; there's a good deal of flexibility here and it's ok for things to happen; earlier than described below. For example, it's not unusual for the legalizer to; legalize an intrinsic directly to a target instruction. The concrete; requirement is that the following additional constraints are preserved after; each of these passes:. IRTranslator. The representation must be gMIR, MIR, or a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually transition the gMIR to MIR. Legalizer. No illegal operations must remain or be introduced after this pass. Register Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:2421,perform,perform,2421,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,"it is just a name, no relocations can be used. * No alias in the expression can be weak as the possibility of the; intermediate alias being overridden cannot be represented in an; object file. * If the alias has the ``available_externally`` linkage, the aliasee must be an; ``available_externally`` global value; otherwise the aliasee can be an; expression but no global value in the expression can be a declaration, since; that would require a relocation, which is not possible. * If either the alias or the aliasee may be replaced by a symbol outside the; module at link time or runtime, any optimization cannot replace the alias with; the aliasee, since the behavior may be different. The alias may be used as a; name guaranteed to point to the content in the current module. .. _langref_ifunc:. IFuncs; -------. IFuncs, like as aliases, don't create any new data or func. They are just a new; symbol that is resolved at runtime by calling a resolver function. On ELF platforms, IFuncs are resolved by the dynamic linker at load time. On; Mach-O platforms, they are lowered in terms of ``.symbol_resolver`` functions,; which lazily resolve the callee the first time they are called. IFunc may have an optional :ref:`linkage type <linkage>` and an optional; :ref:`visibility style <visibility>`. Syntax::. @<Name> = [Linkage] [PreemptionSpecifier] [Visibility] ifunc <IFuncTy>, <ResolverTy>* @<Resolver>; [, partition ""name""]. .. _langref_comdats:. Comdats; -------. Comdat IR provides access to object file COMDAT/section group functionality; which represents interrelated sections. Comdats have a name which represents the COMDAT key and a selection kind to; provide input on how the linker deduplicates comdats with the same key in two; different object files. A comdat must be included or omitted as a unit.; Discarding the whole comdat is allowed but discarding a subset is not. A global object may be a member of at most one comdat. Aliases are placed in the; same COMDAT that their aliasee c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:44902,load,load,44902,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"it vector, 64 bits need to be read from memory. In little endian mode, we can do this by just performing a 64-bit load - ``LDR q0, [foo]``. However if we try this in big endian mode, because of the byte swapping the lane indices end up being swapped! The zero'th item as laid out in memory becomes the n'th lane in the vector. .. figure:: ARM-BE-ld1.png; :align: right. Big endian vector load using ``LD1``. Note that the lanes retain the correct ordering. Because of this, the instruction ``LD1`` performs a vector load but performs byte swapping not on the entire 64 bits, but on the individual items within the vector. This means that the register content is the same as it would have been on a little endian system. It may seem that ``LD1`` should suffice to perform vector loads on a big endian machine. However there are pros and cons to the two approaches that make it less than simple which register format to pick. There are two options:. 1. The content of a vector register is the same *as if* it had been loaded with an ``LDR`` instruction.; 2. The content of a vector register is the same *as if* it had been loaded with an ``LD1`` instruction. Because ``LD1 == LDR + REV`` and similarly ``LDR == LD1 + REV`` (on a big endian system), we can simulate either type of load with the other type of load plus a ``REV`` instruction. So we're not deciding which instructions to use, but which format to use (which will then influence which instruction is best to use). .. The 'clearer' container is required to make the following section header come after the floated; images above.; .. container:: clearer. Note that throughout this section we only mention loads. Stores have exactly the same problems as their associated loads, so have been skipped for brevity. Considerations; ==============. LLVM IR Lane ordering; ---------------------. LLVM IR has first class vector types. In LLVM IR, the zero'th element of a vector resides at the lowest memory address. The optimizer relies on this prope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:3814,load,loaded,3814,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['load'],['loaded']
Performance,"it.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:221531,perform,performing,221531,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"itable for this benchmark to turn the conditional stores to mc[k]; into a conditional move (select instr in IR) and allow the final store to do the; store. See GCC PR27313 for more details. Note that this is valid to xform even; with the new C++ memory model, since mc[k] is previously loaded and later; stored. //===---------------------------------------------------------------------===//. [SCALAR PRE]; There are many PRE testcases in testsuite/gcc.dg/tree-ssa/ssa-pre-*.c in the; GCC testsuite. //===---------------------------------------------------------------------===//. There are some interesting cases in testsuite/gcc.dg/tree-ssa/pred-comm* in the; GCC testsuite. For example, we get the first example in predcom-1.c, but ; miss the second one:. unsigned fib[1000];; unsigned avg[1000];. __attribute__ ((noinline)); void count_averages(int n) {; int i;; for (i = 1; i < n; i++); avg[i] = (((unsigned long) fib[i - 1] + fib[i] + fib[i + 1]) / 3) & 0xffff;; }. which compiles into two loads instead of one in the loop. predcom-2.c is the same as predcom-1.c. predcom-3.c is very similar but needs loads feeding each other instead of; store->load. //===---------------------------------------------------------------------===//. [ALIAS ANALYSIS]. Type based alias analysis:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=14705. We should do better analysis of posix_memalign. At the least it should; no-capture its pointer argument, at best, we should know that the out-value; result doesn't point to anything (like malloc). One example of this is in; SingleSource/Benchmarks/Misc/dt.c. //===---------------------------------------------------------------------===//. Interesting missed case because of control flow flattening (should be 2 loads):; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=26629; With: llvm-gcc t2.c -S -o - -O0 -emit-llvm | llvm-as | ; opt -mem2reg -gvn -instcombine | llvm-dis; we miss it because we need 1) CRIT EDGE 2) MULTIPLE DIFFERENT; VALS PRODUCED BY ONE BLOCK OV",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:35284,load,loads,35284,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['loads']
Performance,"itcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:262104,load,load,262104,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"itcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:261981,load,load,261981,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"itcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208137,cache,cache,208137,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"ites of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:290098,cache,cache,290098,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['cache'],"['cache', 'caches']"
Performance,"ith THttpServer providing address like:; <http://localhost:8080/jsrootsys/demo/demo.htm?addr=../../Files/job1.root/hpx/root.json.gz&layout=3x3>; 18. Also for online server process url options like 'item', 'items', 'layout'; 19. Possibility to generate URL, which reproduces opened page with layout and drawn items. ### August 2014; 1. All communication between server and browser done with JSON format.; 2. Fix small error in dtree.js - one should always set; last sibling (_ls) property while tree can be dynamically changed.; 3. In JSRootCore.js provide central function, which handles different kinds; of XMLHttpRequest. Use only async requests, also when getting file header.; 4. Fully reorganize data management in file/tree/directory/collection hierarchical; display. Now complete description collected in HPainter class and decoupled from; visualization, performed with dTree.js.; 5. Remove all global variables from the code.; 6. Automatic scripts/style loading handled via JSROOT.loadScript() function.; One can specify arbitrary scripts list, which asynchronously loaded by browser.; 7. Method to build simple GUI changed and more simplified :). The example in index.htm.; While loadScript and AssertPrerequisites functions moved to JSROOT, one; can easily build many different kinds of GUIs, reusing provided JSRootCore.js functions.; 8. In example.htm also use AssertPrerequisites to load necessary scripts.; This helps to keep code up-to-date even by big changes in JavaScript code.; 9. Provide monitoring of online THttpServer with similar interface as for ROOT files.; 10. Fix several errors in TKey Streamer, use member names as in ROOT itself.; 11. Keep the only version identifier JSROOT.version for JS code; 12. One can specify in JSROOT.AssertPrerequisites functionality which is required.; One could specify '2d', 'io' (default) or '3d'.; 13. Use new AssertPrerequisites functionality to load only required functionality.; 14. When displaying single element, one could specify dr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:74425,load,loadScript,74425,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['load'],['loadScript']
Performance,"ith the command:. ```bash; [shell] wget http://localhost:8080/Objects/subfolder/obj/root.json; ```. Then, its representation will look like:. ```json; {; ""_typename"" : ""TNamed"",; ""fUniqueID"" : 0,; ""fBits"" : 0,; ""fName"" : ""obj"",; ""fTitle"" : ""title""; }; ```. The following requests can be performed:. | Name | Description |; | :----------- | :---------------- |; | `root.bin` | binary data produced by object streaming with `TBufferFile` |; | `root.json` | ROOT JSON representation for object and objects members |; | `file.root` | Creates TMemFile with the only object, from ROOT 6.32 |; | `root.xml` | ROOT XML representation |; | `root.png` | PNG image (if object drawing implemented) |; | `root.gif` | GIF image |; | `root.jpeg` | JPEG image |; | `exe.json` | method execution in the object |; | `exe.bin` | method execution, return result in binary form |; | `cmd.json` | command execution |; | `item.json` | item (object) properties, specified on the server |; | `multi.json` | perform several requests at once |; | `multi.bin` | perform several requests at once, return result in binary form |. All data will be automatically zipped if '.gz' extension is appended. Like:. ```bash; [shell] wget http://localhost:8080/Objects/subfolder/obj/root.json.gz; ```. If the access to the server is restricted with htdigest, it is recommended to use the **curl** program since only curl correctly implements such authentication method. The command will look like:. ```bash; [shell] curl --user ""accout:password"" http://localhost:8080/Objects/subfolder/obj/root.json --digest -o root.json; ```. ### Objects data access in JSON format. Request `root.json` implemented with [TBufferJSON](https://root.cern/doc/master/classTBufferJSON.html) class. TBufferJSON generates such object representation, which could be directly used in [JSROOT](https://root.cern/js/) for drawing. `root.json` request returns either complete object or just object member like:. ```bash; [shell] wget http://localhost:8080/Objects/subf",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:15862,perform,perform,15862,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['perform'],['perform']
Performance,"ith; each other. They may touch on one boundaries or shape vertex. The daughter nodes of a volume can be also removed or replaced with; other nodes:. ``` {.cpp}; void RemoveNode(TGeoNode* node); TGeoNode*ReplaceNode(TGeoNode* nodeorig, TGeoShape* newshape = 0,; TGeoMatrix* newpos = 0, TGeoMedium* newmed = 0); ```. The last method allows replacing an existing daughter of a volume with; another one. Providing only the node to be replaced will just create a; new volume for the node but having exactly the same parameters as the; old one. This helps in case of divisions for decoupling a node from the; logical hierarchy so getting new content/properties. For non-divided; volumes, one can change the shape and/or the position of the daughter. #### Virtual Containers and Assemblies of Volumes. Virtual containers are volumes that do not represent real objects, but; they are needed for grouping and positioning together other volumes.; Such grouping helps not only geometry creation, but also optimizes; tracking performance; therefore, it is highly recommended. Virtual; volumes need to inherit material/medium properties from the volume they; are placed into in order to be ""invisible"" at tracking time. Let us suppose that we need to group together two volumes `A` and `B`; into a structure and position this into several other volumes `D,E,` and; `F`. What we need to do is to create a virtual container volume `C`; holding `A` and `B`, then position `C` in the other volumes. Note that `C` is a volume having a determined medium. Since it is not a; real volume, we need to manually set its medium the same as that of; `D,E` or `F` in order to make it invisible' (same physics properties).; In other words, the limitation in proceeding this way is that `D,E,` and; `F` must point to the same medium. If this was not the case, we would; have to define different virtual volumes for each placement: `C`, `C'`; and `C""`, having the same shape but different media matching the; corresponding conta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:69850,optimiz,optimizes,69850,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,2,"['optimiz', 'perform']","['optimizes', 'performance']"
Performance,"ither through code generation or; having been retrieved from an ObjectCache, it is passed to RuntimeDyld to; be loaded. The RuntimeDyld wrapper class examines the object to determine; its file format and creates an instance of either RuntimeDyldELF or; RuntimeDyldMachO (both of which derive from the RuntimeDyldImpl base; class) and calls the RuntimeDyldImpl::loadObject method to perform that; actual loading. .. image:: MCJIT-dyld-load.png. RuntimeDyldImpl::loadObject begins by creating an ObjectImage instance; from the ObjectBuffer it received. ObjectImage, which wraps the; ObjectFile class, is a helper class which parses the binary object image; and provides access to the information contained in the format-specific; headers, including section, symbol and relocation information. RuntimeDyldImpl::loadObject then iterates through the symbols in the; image. Information about common symbols is collected for later use. For; each function or data symbol, the associated section is loaded into memory; and the symbol is stored in a symbol table map data structure. When the; iteration is complete, a section is emitted for the common symbols. Next, RuntimeDyldImpl::loadObject iterates through the sections in the; object image and for each section iterates through the relocations for; that sections. For each relocation, it calls the format-specific; processRelocationRef method, which will examine the relocation and store; it in one of two data structures, a section-based relocation list map and; an external symbol relocation map. .. image:: MCJIT-load-object.png. When RuntimeDyldImpl::loadObject returns, all of the code and data; sections for the object will have been loaded into memory allocated by the; memory manager and relocation information will have been prepared, but the; relocations have not yet been applied and the generated code is still not; ready to be executed. [Currently (as of August 2013) the MCJIT engine will immediately apply; relocations when loadObject comp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:4550,load,loaded,4550,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,1,['load'],['loaded']
Performance,"ithub.com/llvm/llvm-project/blob/main/llvm/include/llvm/Transforms/IPO/LowerTypeTests.h. ``!vcall_visibility`` Metadata; ==============================. In order to allow removing unused function pointers from vtables, we need to; know whether every virtual call which could use it is known to the compiler, or; whether another translation unit could introduce more calls through the vtable.; This is not the same as the linkage of the vtable, because call sites could be; using a pointer of a more widely-visible base class. For example, consider this; code:. .. code-block:: c++. __attribute__((visibility(""default""))); struct A {; virtual void f();; };. __attribute__((visibility(""hidden""))); struct B : A {; virtual void f();; };. With LTO, we know that all code which can see the declaration of ``B`` is; visible to us. However, a pointer to a ``B`` could be cast to ``A*`` and passed; to another linkage unit, which could then call ``f`` on it. This call would; load from the vtable for ``B`` (using the object pointer), and then call; ``B::f``. This means we can't remove the function pointer from ``B``'s vtable,; or the implementation of ``B::f``. However, if we can see all code which knows; about any dynamic base class (which would be the case if ``B`` only inherited; from classes with hidden visibility), then this optimisation would be valid. This concept is represented in IR by the ``!vcall_visibility`` metadata; attached to vtable objects, with the following values:. .. list-table::; :header-rows: 1; :widths: 10 90. * - Value; - Behavior. * - 0 (or omitted); - **Public**; Virtual function calls using this vtable could be made from external; code. * - 1; - **Linkage Unit**; All virtual function calls which might use this vtable are in the; current LTO unit, meaning they will be in the current module once; LTO linking has been performed. * - 2; - **Translation Unit**; All virtual function calls which might use this vtable are in the; current module. In addition, all functio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:9292,load,load,9292,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst,1,['load'],['load']
Performance,"itizer are not undefined behavior,; but are often unintentional.; - ``-fsanitize=integer-divide-by-zero``: Integer division by zero.; - ``-fsanitize=nonnull-attribute``: Passing null pointer as a function; parameter which is declared to never be null.; - ``-fsanitize=null``: Use of a null pointer or creation of a null; reference.; - ``-fsanitize=nullability-arg``: Passing null as a function parameter; which is annotated with ``_Nonnull``.; - ``-fsanitize=nullability-assign``: Assigning null to an lvalue which; is annotated with ``_Nonnull``.; - ``-fsanitize=nullability-return``: Returning null from a function with; a return type annotated with ``_Nonnull``.; - ``-fsanitize=objc-cast``: Invalid implicit cast of an ObjC object pointer; to an incompatible type. This is often unintentional, but is not undefined; behavior, therefore the check is not a part of the ``undefined`` group.; Currently only supported on Darwin.; - ``-fsanitize=object-size``: An attempt to potentially use bytes which; the optimizer can determine are not part of the object being accessed.; This will also detect some types of undefined behavior that may not; directly access memory, but are provably incorrect given the size of; the objects involved, such as invalid downcasts and calling methods on; invalid pointers. These checks are made in terms of; ``__builtin_object_size``, and consequently may be able to detect more; problems at higher optimization levels.; - ``-fsanitize=pointer-overflow``: Performing pointer arithmetic which; overflows, or where either the old or new pointer value is a null pointer; (or in C, when they both are).; - ``-fsanitize=return``: In C++, reaching the end of a; value-returning function without returning a value.; - ``-fsanitize=returns-nonnull-attribute``: Returning null pointer; from a function which is declared to never return null.; - ``-fsanitize=shift``: Shift operators where the amount shifted is; greater or equal to the promoted bit-width of the left hand side; o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst:7115,optimiz,optimizer,7115,interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UndefinedBehaviorSanitizer.rst,1,['optimiz'],['optimizer']
Performance,"itly ``int *__bidi_indexable buf``, carrying the bounds; information passed from the return value of malloc, which is necessary to insert; bounds checking for ``buf[i]``. .. code-block:: c. void *__sized_by(size) malloc(size_t size);. int *__counted_by(n) get_array_with_0_to_n_1(size_t n) {; int *buf = malloc(sizeof(int) * n);; for (size_t i = 0; i < n; ++i); buf[i] = i;; return buf;; }. Annotations for sentinel-delimited arrays; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A C string is an array of characters. The null terminator  the first null; character ('\0') element in the array  marks the end of the string.; ``-fbounds-safety`` provides ``__null_terminated`` to annotate C strings and the; generalized form ``__terminated_by(T)`` to annotate pointers and arrays with an; end marked by a sentinel value. The model prevents dereferencing a; ``__terminated_by`` pointer beyond its end. Calculating the location of the end; (i.e., the address of the sentinel value), requires reading the entire array in; memory and would have some performance costs. To avoid an unintended performance; hit, the model puts some restrictions on how these pointers can be used.; ``__terminated_by`` pointers cannot be indexed and can only be incremented one; element at a time. To allow these operations, the pointers must be explicitly; converted to ``__indexable`` pointers using the intrinsic function; ``__unsafe_terminated_by_to_indexable(P, T)`` (or; ``__unsafe_null_terminated_to_indexable(P)``) which converts the; ``__terminated_by`` pointer ``P`` to an ``__indexable`` pointer. * ``__null_terminated`` : The pointer or array is terminated by ``NULL`` or; ``0``. Modifying the terminator or incrementing the pointer beyond it is; prevented at run time. * ``__terminated_by(T)`` : The pointer or array is terminated by ``T`` which is; a constant expression. Accessing or incrementing the pointer beyond the; terminator is not allowed. This is a generalization of ``__null_terminated``; which is defin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:18424,perform,performance,18424,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['perform'],['performance']
Performance,"itrary location description (such as a vector register); is required. The offset operations provide this ability since they can be used; to compute a location description on the stack. It could be possible to define ``DW_OP_plus``, ``DW_OP_plus_uconst``, and; ``DW_OP_minus`` to operate on location descriptions to avoid needing; ``DW_OP_LLVM_offset`` and ``DW_OP_LLVM_offset_uconst``. However, this is not; proposed since currently the arithmetic operations are defined to require values; of the same base type and produces a result with the same base type. Allowing; these operations to act on location descriptions would permit the first operand; to be a location description and the second operand to be an integral value; type, or vice versa, and return a location description. This complicates the; rules for implicit conversions between default address space memory location; descriptions and generic base type values. Currently the rules would convert; such a location description to the memory address value and then perform two's; compliment wrap around arithmetic. If the result was used as a location; description, it would be implicitly converted back to a default address space; memory location description. This is different to the overflow rules on location; descriptions. To allow control, an operation that converts a memory location; description to an address integral type value would be required. Keeping a; separation of location description operations and arithmetic operations avoids; this semantic complexity. See ``DW_OP_LLVM_offset``, ``DW_OP_LLVM_offset_uconst``, and; ``DW_OP_LLVM_bit_offset`` in; :ref:`amdgpu-dwarf-general-location-description-operations`. 2.5 Generalize Creation of Undefined Location Descriptions; ----------------------------------------------------------. Current DWARF uses an empty expression to indicate an undefined location; description. Since; :ref:`amdgpu-dwarf-allow-location-description-on-the-dwarf-evaluation-stack`; allows location desc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:13952,perform,perform,13952,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['perform']
Performance,"its are off, no memory is accessed. .. _int_mload:. '``llvm.masked.load.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The loaded data is a vector of any integer, floating-point or pointer data type. ::. declare <16 x float> @llvm.masked.load.v16f32.p0(ptr <ptr>, i32 <alignment>, <16 x i1> <mask>, <16 x float> <passthru>); declare <2 x double> @llvm.masked.load.v2f64.p0(ptr <ptr>, i32 <alignment>, <2 x i1> <mask>, <2 x double> <passthru>); ;; The data is a vector of pointers; declare <8 x ptr> @llvm.masked.load.v8p0.p0(ptr <ptr>, i32 <alignment>, <8 x i1> <mask>, <8 x ptr> <passthru>). Overview:; """""""""""""""""". Reads a vector from memory according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. The masked-off lanes in the result vector are taken from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is the alignment of the source location. It must be a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the base pointer and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.load``' intrinsic is designed for conditional reading of selected vector elements in a single IR operation. It is useful for targets that support vector masked loads and allows vectorizing predicated basic blocks on these targets. Other targets may support this intrinsic differently, for example by lowering it into a sequence of branches that guard scalar load operations.; The result of this operation is equivalent to a regular vector load instruction followed by a 'select' between the loaded",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:844099,load,load,844099,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"its hold?. There are three (interesting) possible answers: undefined, zero extended, or; sign extended. The number of bits in question depends on the data-type that; the front-end is referencing (typically i1/i8/i16/i32). Knowing the answer to this is important for two reasons: 1) we want to be able; to implement the ABI correctly. If we need to sign extend the result according; to the ABI, we really really do need to do this to preserve correctness. 2); this information is often useful for optimization purposes, and we want the; mid-level optimizers to be able to process this (e.g. eliminate redundant; extensions). For example, lets pretend that X86 requires the caller to properly extend the; result of a return (I'm not sure this is the case, but the argument doesn't; depend on this). Given this, we should compile this:. int a();; short b() { return a(); }. into:. _b:; 	subl	$12, %esp; 	call	L_a$stub; 	addl	$12, %esp; 	cwtl; 	ret. An optimization example is that we should be able to eliminate the explicit; sign extension in this example:. short y();; int z() {; return ((int)y() << 16) >> 16;; }. _z:; 	subl	$12, %esp; 	call	_y; 	;; movswl %ax, %eax -> not needed because eax is already sext'd; 	addl	$12, %esp; 	ret. //===----------------------------------------------------------------------===//; // What we have right now.; //===----------------------------------------------------------------------===//. Currently, these sorts of things are modelled by compiling a function to return; the small type and a signext/zeroext marker is used. For example, we compile; Z into:. define i32 @z() nounwind {; entry:; 	%0 = tail call signext i16 (...)* @y() nounwind; 	%1 = sext i16 %0 to i32; 	ret i32 %1; }. and b into:. define signext i16 @b() nounwind {; entry:; 	%0 = tail call i32 (...)* @a() nounwind		; <i32> [#uses=1]; 	%retval12 = trunc i32 %0 to i16		; <i16> [#uses=1]; 	ret i16 %retval12; }. This has some problems: 1) the actual precise semantics are really poorly; defined ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendedIntegerResults.txt:1426,optimiz,optimization,1426,interpreter/llvm-project/llvm/docs/ExtendedIntegerResults.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendedIntegerResults.txt,1,['optimiz'],['optimization']
Performance,"its, and so forth. ``LDR`` and ``LD1``; ===================. .. figure:: ARM-BE-ldr.png; :align: right. Big endian vector load using ``LDR``. A vector is a consecutive sequence of items that are operated on simultaneously. To load a 64-bit vector, 64 bits need to be read from memory. In little endian mode, we can do this by just performing a 64-bit load - ``LDR q0, [foo]``. However if we try this in big endian mode, because of the byte swapping the lane indices end up being swapped! The zero'th item as laid out in memory becomes the n'th lane in the vector. .. figure:: ARM-BE-ld1.png; :align: right. Big endian vector load using ``LD1``. Note that the lanes retain the correct ordering. Because of this, the instruction ``LD1`` performs a vector load but performs byte swapping not on the entire 64 bits, but on the individual items within the vector. This means that the register content is the same as it would have been on a little endian system. It may seem that ``LD1`` should suffice to perform vector loads on a big endian machine. However there are pros and cons to the two approaches that make it less than simple which register format to pick. There are two options:. 1. The content of a vector register is the same *as if* it had been loaded with an ``LDR`` instruction.; 2. The content of a vector register is the same *as if* it had been loaded with an ``LD1`` instruction. Because ``LD1 == LDR + REV`` and similarly ``LDR == LD1 + REV`` (on a big endian system), we can simulate either type of load with the other type of load plus a ``REV`` instruction. So we're not deciding which instructions to use, but which format to use (which will then influence which instruction is best to use). .. The 'clearer' container is required to make the following section header come after the floated; images above.; .. container:: clearer. Note that throughout this section we only mention loads. Stores have exactly the same problems as their associated loads, so have been skipped for brev",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:3561,perform,perform,3561,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,2,"['load', 'perform']","['loads', 'perform']"
Performance,"ity. Major JSROOT functions are located in `main.mjs` module and can be imported like:. ```javascript; <script type='module'>; import { openFile, draw } from 'https://root.cern/js/latest/modules/main.mjs';; let filename = ""https://root.cern/js/files/hsimple.root"";; let file = await openFile(filename);; let obj = await file.readObject(""hpxpy;1"");; await draw(""drawing"", obj, ""colz"");; </script>; ```. Here the default location `https://root.cern/js/latest/` is specified. One always can install JSROOT on private web server.; When JSROOT is used with THttpServer, the address looks like:. ```javascript; <script type='module'>; import { httpRequest, draw } from 'http://your_root_server:8080/jsrootsys/modules/main.mjs';; let obj = await httpRequest('http://your_root_server:8080/Objects/hist/root.json','object');; await draw('drawing', obj, 'hist');; </script>; ```. Loading main module is enough to get public JSROOT functionality - reading files and drawing objects.; One also can load some special components directly like:. ```javascript; <script type='module'>; import { HierarchyPainter } from 'https://root.cern/js/latest/modules/gui.mjs';. let h = new HierarchyPainter(""example"", ""myTreeDiv"");. // configure 'simple' in provided <div> element; // one also can specify ""grid2x2"" or ""flex"" or ""tabs""; h.setDisplay(""simple"", ""myMainDiv"");. // open file and display element; await h.openRootFile('../../files/hsimple.root');; await h.display('hpxpy;1"",""colz');; </script>; ```. After script loading one can configure different parameters in `gStyle` object.; It is instance of the `TStyle` object and behaves like `gStyle` variable in ROOT. For instance,; to change stat format using to display value in stats box:. ```javascript; import { gStyle } from 'https://root.cern/js/latest/modules/main.mjs';; gStyle.fStatFormat = '7.5g';; ```. There is also `settings` object which contains all other JSROOT settings. For instance,; one can configure custom format for different axes:. ```javascript;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:35074,load,load,35074,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['load'],['load']
Performance,"ivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18414,load,load,18414,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,2,['load'],['load']
Performance,"ive execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; orl %eax, %edi; ```. While an addition happens to the loaded (potentially secret) value, that; doesn't leak any data and we then immediately harden it. ###### Hardening of loaded values deferred down the data-invariant expression graph. We can generalize the previous idea and sink the hardening down the expression; graph across as many data-invariant operations as desirable. This can use very; conservative rules for whether something is data-invariant. The primary goal; should be to handle multiple loads with a single hardening instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate without leaking.; addl 4(%rsi), %edi # Continue without leaking.; addl 8(%rsi), %edi; orl %eax, %edi # Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks infor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:26668,load,loads,26668,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance,"ive username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still destroyed at the end of the query, but there was no; memory advantage in TH1::Add wrt TH1::Merge.; Make sure that the performance tree is removed from the output; list when saved to the output file. Solves a segv at quit.; Decouple from registered TChains in already TProof::Close(); allows; to avoid possible crash at exit ('.q') occuring after the recent; revision of the socket cleanup policy.; In XrdProofd, fix a few issues with option 'xpd.multiuser'.; In TXSocket::ProcessUnsolicitedMsg, fix an issue preventig server; messages to be displayed during setup, i.e. when the XrdClientConn; instance is not yet defined.; In XrdProofd, fix the behavior of the 'xpd.allowedusers' and; 'xpd.allowedgroups' directives. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:4071,perform,performance,4071,proof/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html,2,['perform'],['performance']
Performance,"iven type metadata; identifier, it is one of the following (the choice of which is unspecified):. 1. The function pointer that would have been loaded from an arbitrarily chosen; (through an unspecified mechanism) pointer associated with the type; metadata. 2. If the function has a non-void return type, a pointer to a function that; returns an unspecified value without causing side effects. If the function's return value's second element is false, the value of the; first element is undefined. .. _type.checked.load.relative:. '``llvm.type.checked.load.relative``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare {ptr, i1} @llvm.type.checked.load.relative(ptr %ptr, i32 %offset, metadata %type) argmemonly nounwind readonly. Overview:; """""""""""""""""". The ``llvm.type.checked.load.relative`` intrinsic loads a relative pointer to a; function from a virtual table pointer using metadata. Otherwise, its semantic is; identical to the ``llvm.type.checked.load`` intrinsic. A relative pointer is a pointer to an offset to the pointed to value. The; address of the underlying pointer of the relative pointer is obtained by adding; the offset to the address of the offset value. '``llvm.arithmetic.fence``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.arithmetic.fence(<type> <op>). Overview:; """""""""""""""""". The purpose of the ``llvm.arithmetic.fence`` intrinsic; is to prevent the optimizer from performing fast-math optimizations,; particularly reassociation,; between the argument and the expression that contains the argument.; It can be used to preserve the parentheses in the source language. Arguments:; """""""""""""""""""". The ``llvm.arithmetic.fence`` intrinsic takes only one argument.; The argument and the return value are floating-point numbers,; or vector floating-point numbers, of the same type. Semantics:; """""""""""""""""""". This intrinsic returns the value of its operand. The optimizer can optimize; the argument, bu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:940246,load,load,940246,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"ivergent* otherwise. Correspondingly,; a branch is said to be a uniform branch if its condition is uniform,; and it is a divergent branch otherwise. Whether threads are *converged* or not depends on the paths they take; through the control flow graph. Threads take different outgoing edges; at a *divergent branch*. Divergent branches constrain; program transforms such as changing the CFG or moving a convergent; operation to a different point of the CFG. Performing these; transformations across a divergent branch can change the sets of; threads that execute convergent operations convergently. While these; constraints are out of scope for this document, the described; *uniformity analysis* allows these transformations to identify; uniform branches where these constraints do not hold. Convergence and; uniformity are inter-dependent: When threads diverge at a divergent; branch, they may later *reconverge* at a common program point.; Subsequent operations are performed convergently, but the inputs may; be non-uniform, thus producing divergent outputs. Uniformity is also useful by itself on targets that execute threads in; groups with shared execution resources (e.g. waves, warps, or; subgroups):. - Uniform outputs can potentially be computed or stored on shared; resources.; - These targets must ""linearize"" a divergent branch to ensure that; each side of the branch is followed by the corresponding threads in; the same group. But linearization is unnecessary at uniform; branches, since the whole group of threads follows either one side; of the branch or the other. This document presents a definition of convergence that is reasonable; for real targets and is compatible with the currently implicit; semantics of convergent operations in LLVM IR. This is accompanied by; a *uniformity analysis* that extends previous work on divergence analysis; [DivergenceSPMD]_ to cover irreducible control-flow. .. [DivergenceSPMD] Julian Rosemann, Simon Moll, and Sebastian; Hack. 2021. An Abstr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst:1518,perform,performed,1518,interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ConvergenceAndUniformity.rst,1,['perform'],['performed']
Performance,"ix - use alternative color for shapes with default black color; 6. Fix - correctly handle pcon/pgon shape with rmin==rmax on top or bottom side. ## Changes in 4.4; 1. Fix faces orientation for all TGeo shapes.; 2. Improve TGeoTorus creation - handle all parameters combinations; 3. Implement TGeoCompositeShape, using ThreeCSG.js; 4. Fix problem with color palette when switch to 3D mode (#28); 5. Use nested CSS classes to avoid conflicts with other libraries (#29); 6. Let move and resize TFrame; 7. Improve TH1/TH2 drawings; - draw all histograms points in the range (no any skipped bins); - minimize SVG code for drawing (up to factor 100); - gives significant speedup in drawings; 8. SVG code improvement for TGraph, TF1, TAxis drawings; 9. Provide new tooltip kind; - created only when needed (minimizing SVG code); - tooltip can be drawn for every object in the frame; - touch devices are supported; 10. Fix - let draw same object on the canvas with different options; 11. Create cached list of known class methods. It can be extended by users.; 12. Use of cached methods improves binary I/O performance by 20%; 13. Support TGaxis; 14. Project now can be obtained via 'bower install jsroot'; 15. Support 'scat' and 'text' draw options for TH2; 16. Support in binary I/O zipped buffer bigger than 16M; 17. Correctly handle in binary I/O pointer on TArray object (like in THnSparseArrayChunk). ## Changes in 4.3; 1. Implement TGeoCtub, TGeoParaboloid and TGeoHype shapes; 2. Support TGeoTube with Rmin==0; 3. Exclude empty faces in TGeoArb8; 4. Improve TGeoSphere creation - handle all parameters combinations; 5. Introduce JSROOT.cleanup() function to safely clear all drawn objects; 6. Fix wrong resize method in 'tabs' and 'collapsible' layouts; 7. Fix canvas resize problem (issue #27); 8. Fix zero-height canvas when draw TGeo in collapsible layout; 9. Fix problem of simultaneous move TGeo drawings and canvas in flexible layout. ## Changes in 4.2; 1. Significant performance improvements i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:57248,cache,cached,57248,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['cache'],['cached']
Performance,"ixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:2123,Optimiz,Optimization,2123,tmva/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html,2,['Optimiz'],"['Optimization', 'OptimizeAllMethods']"
Performance,"izations------ optimizations -. -----------------------------------------------------------------------------------------------;  ;  source file ;  ; -----------------------------------------------------------------------------------------------; ---------------------------------------;  ;  ;  imported code ;  ;  ; ---------------------------------------. It would be very unfortunate if we end up with worse performance after using modules.; The main concern is that when we compile a source file, the compiler needs to see the function body; of imported module units so that it can perform IPO (InterProcedural Optimization, primarily inlining; in practice) to optimize functions in current source file with the help of the information provided by; the imported module units.; In other words, the imported code would be processed again and again in importee units; by optimizations (including IPO itself).; The optimizations before IPO and the IPO itself are the most time-consuming part in whole compilation process.; So from this perspective, we might not be able to get the improvements described in the theory.; But we could still save the time for optimizations after IPO and the whole backend. Overall, at ``O0`` the implementations of functions defined in a module will not impact module users,; but at higher optimization levels the definitions of such functions are provided to user compilations for the; purposes of optimization (but definitions of these functions are still not included in the use's object file)-; this means the build speedup at higher optimization levels may be lower than expected given ``O0`` experience,; but does provide by more optimization opportunities. Interoperability with Clang Modules; -----------------------------------. We **wish** to support clang modules and standard c++ modules at the same time,; but the mixed using form is not well used/tested yet. Please file new github issues as you find interoperability problems.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:42886,optimiz,optimizations,42886,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,5,['optimiz'],"['optimization', 'optimizations']"
Performance,"ize of the byte block B can be inferred from the type D; definition, it is encoded explicitly into the operation so that the; operation can be parsed easily without reference to the* ``.debug_info``; *section.*. 8. ``DW_OP_LLVM_push_lane`` *New*. ``DW_OP_LLVM_push_lane`` pushes the current lane as a value with the generic; type. *For source languages that are implemented using a SIMT execution model,; this is the zero-based lane number that corresponds to the source language; thread of execution upon which the user is focused.*. The value must be greater than or equal to 0 and less than the value of the; ``DW_AT_LLVM_lanes`` attribute, otherwise the DWARF expression is; ill-formed. See :ref:`amdgpu-dwarf-low-level-information`. 9. ``DW_OP_LLVM_push_iteration`` *New*. ``DW_OP_LLVM_push_iteration`` pushes the current iteration as a value with; the generic type. *For source language implementations with optimizations that cause multiple; loop iterations to execute concurrently, this is the zero-based iteration; number that corresponds to the source language concurrent loop iteration; upon which the user is focused.*. The value must be greater than or equal to 0 and less than the value of the; ``DW_AT_LLVM_iterations`` attribute, otherwise the DWARF expression is; ill-formed. See :ref:`amdgpu-dwarf-low-level-information`. .. _amdgpu-dwarf-arithmetic-logical-operations:. A.2.5.4.3.2 Arithmetic and Logical Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.4. .. _amdgpu-dwarf-type-conversions-operations:. A.2.5.4.3.3 Type Conversion Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.6. .. _amdgpu-dwarf-general-operations:. A.2.5.4.3.4 Special Value Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces parts of DWARF Version 5 sections 2.5.1.2, 2.5.1.3, and; 2.5.1.7. There are these special value ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:85891,optimiz,optimizations,85891,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,3,"['concurren', 'optimiz']","['concurrent', 'concurrently', 'optimizations']"
Performance,"izer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:7470,load,loads,7470,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['load'],['loads']
Performance,"ject(); ROOT.SetOwnership( o, False ) # True to own, False to release; ```. #### Memory Management by Hand. If needed, you can explicitly destroy a ROOT object that you own through; its associated **`TClass`**:. ``` {.cpp}; myobject.IsA().Destructor(myobject); ```. which will send out the deletion notification to the system (thus you do; not need to care anymore at this point about Python reference counting,; the object will go, even if it's reference count it non-zero), and free; the memory. ### Performance. The performance of `PyROOT` when programming with ROOT in Python is; similar to that of Cling. Differences occur mainly because of differences; in the respective languages: C++ is much harder to parse, but once; parsed, it is much easier to optimize. Consequently, individual calls to; ROOT are typically faster from `PyROOT`, whereas loops are typically; slower. When programming in Python, the modus operandi is to consider; performance generally ""good enough"" on the outset, and when it turns out; that, it is not good enough; the performance critical part is converted; into C/C++ in an extension module. The school of thought where; pre-mature optimization is the root of all evil should find this way of; working very satisfying. In addition, if you look at their history, you; will see that many of the standard Python modules have followed this; path. Your code should always make maximum use of ROOT facilities; such that; most of the time is spending in compiled code. This goes even for very; simple things: e.g. do not compute invariant masses in Python, use; **`TLorentzVector`** instead. Moreover, before you start optimizing,; make sure that you have run a profiler to find out where the bottlenecks; are. Some performance, without cost in terms of programmer effort, may; be gained by using `psyco`, see the next link:; <http://psyco.sourceforge.net>, a Python just in time compiler (JIT).; Note, however, that `psyco` is limited to Intel i386 CPUs. Since `psyco`; optim",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:22754,perform,performance,22754,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,2,['perform'],['performance']
Performance,"ject::Streamer`, and the **`TObject`** part; of the class is not streamed to the file. This is useful in case you do; not use the **`TObject`** `fBits` and `fUniqueID `data members. You gain; space on the file, and you do not loose functionality if you do not use; the `fBits` and `fUniqueID. `See ""The Role of TObject"" on the use of; `fBits` and `fUniqueID`. ### Streaming a TClonesArray. When writing a **`TClonesArray`** it bypasses by default the; `Streamer `of the member class and uses a more efficient internal; mechanism to write the members to the file. You can override the default; and specify that the member class `Streamer `is used by setting the; `TClonesArray::BypassStreamer` bit to false:. ``` {.cpp}; TClonesArray *fTracks;; fTracks->BypassStreamer(kFALSE); // use the member Streamer; ```. When the `kBypassStreamer` bit is set, the automatically generated; `Streamer `can call directly the method **`TClass::WriteBuffer`**.; Bypassing the `Streamer` improves the performance when writing/reading; the objects in the **`TClonesArray`**. However, the drawback is when a; **`TClonesArray`** is written with `split=0` bypassing the `Streamer`,; the `StreamerInfo `of the class in the array being optimized, one cannot; later use the **`TClonesArray`** with `split > 0`. For example, there is; a problem with the following scenario: a class `Foo` has a; **`TClonesArray`** of `Bar` objects the `Foo` object is written with; `split=0` to `Tree` `T1`. In this case the `StreamerInfo` for the class; `Bar` is created in optimized mode in such a way that data members of; the same type are written as an array improving the I/O performance. In; a new program, `T1` is read and a new `Tree` `T2` is created with the; object `Foo` in `split > 1`. When the `T2 `branch is created, the `StreamerInfo` for the class `Bar`; is created with no optimization (mandatory for the split mode). The; optimized Bar `StreamerInfo` is going to be used to read the; **`TClonesArray`** in `T1`. The result ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:54030,perform,performance,54030,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['perform'],['performance']
Performance,"jectLayer to link the object file produced by our compiler. So far we have learned how to optimize and compile our LLVM IR, but we have; not focused on when compilation happens. Our current REPL optimizes and; compiles each function as soon as it is referenced by any other code,; regardless of whether it is ever called at runtime. In the next chapter we; will introduce a fully lazy compilation, in which functions are not compiled; until they are first called at run-time. At this point the trade-offs get much; more interesting: the lazier we are, the quicker we can start executing the; first function, but the more often we will have to pause to compile newly; encountered functions. If we only code-gen lazily, but optimize eagerly, we; will have a longer startup time (as everything is optimized at that time) but; relatively short pauses as each function just passes through code-gen. If we; both optimize and code-gen lazily we can start executing the first function; more quickly, but we will have longer pauses as each function has to be both; optimized and code-gen'd when it is first executed. Things become even more; interesting if we consider interprocedural optimizations like inlining, which; must be performed eagerly. These are complex trade-offs, and there is no; one-size-fits all solution to them, but by providing composable layers we leave; the decisions to the person implementing the JIT, and make it easy for them to; experiment with different configurations. `Next: Adding Per-function Lazy Compilation <BuildingAJIT3.html>`_. Full Code Listing; =================. Here is the complete code listing for our running example with an; IRTransformLayer added to enable optimization. To build this example, use:. .. code-block:: bash. # Compile; clang++ -g toy.cpp `llvm-config --cxxflags --ldflags --system-libs --libs core orcjit native` -O3 -o toy; # Run; ./toy. Here is the code:. .. literalinclude:: ../../examples/Kaleidoscope/BuildingAJIT/Chapter2/KaleidoscopeJIT.h; :",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:11202,optimiz,optimize,11202,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,2,['optimiz'],"['optimize', 'optimized']"
Performance,"jects defined in a; session; therefore, users must not try to control their deletion. It; contains lists of media, materials, transformations, shapes and volumes.; A special case is the one of geometrical transformations. When creating; a matrix or a translation, this is by default owned by external objects.; The manager class becomes owner of all transformations used for; positioning volumes. In order to force the ownership for other; transformations, one can use TGeoMatrix::RegisterYourself() method. Do; not be therefore surprised that some transformations cannot be found by; name when creating a composite shape for instance if you did not; register them after creation. Logical nodes (positioned volumes) are created and destroyed by the; TGeoVolume class. Physical nodes and their global transformations; are subjected to a caching mechanism due to the sometimes very large; memory requirements of logical graph expansion. The total number of; physical instances of volumes triggers the caching mechanism and the; cache manager is a client of TGeoManager. The manager class also; controls the drawing/checking package (TGeoPainter client). This; is linked with %ROOT graphical libraries loaded on demand in order to; control visualization actions. \anchor GP02; ## Navigation and Tracking. Tracking is the feature allowing the transport of a given particle; knowing its kinematics. A state is determined by any combination of the; position \f$\vec{r}\f$ and direction \f$\vec{n}\f$ with respect to the world; reference frame. The direction \f$\vec{n}\f$ must be a unit vector having as; components the director cosines. The full classification of a given; state will provide the following information: the deepest physical node; containing the position vector, the distance to the closest boundary; along the direction vector, the next physical node after propagating the; current point with this distance and the safety distance to the nearest; boundary. This information allows the propa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:60983,cache,cache,60983,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['cache'],['cache']
Performance,"jects. Here are some suggestions to debugging your pass; with GDB. For sake of discussion, I'm going to assume that you are debugging a; transformation invoked by :program:`opt`, although nothing described here; depends on that. Setting a breakpoint in your pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. First thing you do is start gdb on the opt process:. .. code-block:: console. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakpoint in our pass yet; (the shared object isn't loaded until runtime), we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:53292,load,loaded,53292,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,2,['load'],['loaded']
Performance,"jects. The annotation can be created from the TGLViewer editor; (""Guides"" tab). After that it can be dragged around the screen, edited; or closed. TGLAxisPainter - reimplemented to completely separate; label and tick-mark positioning code from the rendering itself. TGLSAViewer - when exporting an image properly take into; account image extension if it was typed by the user. TGLFont now uses the same font-naming scheme as the rest; of ROOT (had to specify font-file names before). Overlay-object management has been improved. Allow clipping object to be fixed by user - until now it was updated; on every redraw. See TGLViewer::SetClipAutoUpdate(). Eve. TEveElement - add context-menu functions allowing the; source-object to be printed, dumped or exported to CINT. TEveTrack - added flag for locking of current; track-points - the track will not be re-extrapolated automatically; even when the extrapolation parameters are changed. TEveTrack - removed ALICE specific ImportXyzz(); functions for loading of kinematics, hits and clusters associated with; a track. These were calling macros that were not available in ROOT. Several improvements in rendering of coordinate axes; in TEveCaloLego and TEveProjectionAxes. New class TEveJetCone for display of circular and; elliptic jet-cones clipped to the calorimeter's inner surface. Add support for extraction of composite-shape tesselations. A new; class TEveGeoPolyShape has been introduced to make this; tesselation serializable. See example; in tutorials/eve/csgdemo.C. Generalize representation of EVE-window title-bar - it can be; modified to display user-provided icons, menus or buttons. TEveWindowPack now supports registration of sub-frames; with weights that determine relative sub-frame length along the pack's; major direction. TEveUtil::SetColorBrightnes() now scales colors; according to screen-gamma transformation formula. Some examples using the GUI recorder have been added to the; tutorials. See macros tutorials/eve/*_playback.C.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v524/index.html:4119,load,loading,4119,graf3d/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v524/index.html,2,['load'],['loading']
Performance,"just use if you're; not sure). The bug description should contain the following information:. * All information necessary to reproduce the problem.; * The reduced test-case that triggers the bug.; * The location where you obtained LLVM (if not from our Git; repository). Thanks for helping us make LLVM better!. .. _crashes the compiler:. Crashing Bugs; =============. More often than not, bugs in the compiler cause it to crash---often due to; an assertion failure of some sort. The most important piece of the puzzle; is to figure out if it is crashing in the Clang front-end or if it is one of; the LLVM libraries (e.g. the optimizer or code generator) that has; problems. To figure out which component is crashing (the front-end, middle-end; optimizer, or backend code generator), run the ``clang`` command line as you; were when the crash occurred, but with the following extra command line; options:. * ``-emit-llvm -Xclang -disable-llvm-passes``: If ``clang`` still crashes when; passed these options (which disable the optimizer and code generator), then; the crash is in the front-end. Jump ahead to :ref:`front-end bugs; <frontend-crash>`. * ``-emit-llvm``: If ``clang`` crashes with this option (which disables; the code generator), you found a middle-end optimizer bug. Jump ahead to; :ref:`middle-end bugs <middleend-crash>`. * Otherwise, you have a backend code generator crash. Jump ahead to :ref:`code; generator bugs <backend-crash>`. .. _frontend-crash:. Front-end bugs; --------------. On a ``clang`` crash, the compiler will dump a preprocessed file and a script; to replay the ``clang`` command. For example, you should see something like. .. code-block:: text. PLEASE ATTACH THE FOLLOWING FILES TO THE BUG REPORT:; Preprocessed source(s) and associated run script(s) are located at:; clang: note: diagnostic msg: /tmp/foo-xxxxxx.c; clang: note: diagnostic msg: /tmp/foo-xxxxxx.sh. The `creduce <https://github.com/csmith-project/creduce>`_ tool helps to; reduce the preprocessed",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:2092,optimiz,optimizer,2092,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['optimiz'],['optimizer']
Performance,"k C++ class SClass-; // no streamer; ```. - **`!`** : tells `rootcling` **not** to generate the; `operator>>(`**`TBuffer`** `&b,MyClass *&obj)` method for this; class. This is necessary to be able to write pointers to objects of; classes not inheriting from **`TObject`**. ``` {.cpp}; #pragma link C++ class SClass!; // no >> operator; // or; #pragma link C++ class SClass-!; // no streamer, no >> operator; ```. - **+** : in ROOT version 1 and 2 tells `rootcling` to generate a; `Streamer` with extra byte count information. This adds an integer; to each object in the output buffer, but it allows for powerful; error correction in case a `Streamer` method is out of sync with; data in the file. The `+` option is mutual exclusive with both the; `-` and `!` options. IMPORTANT NOTE: In ROOT Version 3 and later, a ""+"" after the class name; tells `rootcling` to use the new I/O system. The byte count check is; always added. The new I/O system has many advantages including support; automatic schema evolution, full support for STL collections and better; run-time performance. We strongly recommend using it. ``` {.cpp}; #pragma link C++ class SClass+; // add byte count; ```. For information on `Streamers` see ""Input/Output"". To get help on; `rootcling` type on the UNIX command line: **`rootcling -h`**. #### The Order Matters. When using template classes, the order of the pragma statements matters.; For example, here is a template class `Tmpl` and a normal class `Norm`,; which holds a specialized instance of a `Tmpl`:. ``` {.cpp}; class Norm {; private:; Tmpl<int>* fIntTmpl;; public:; ...; };; ```. Then in `Linkdef.h,` the pragma statements must be ordered by listing; all specializations before any classes that need them:. ``` {.cpp}; // Correct Linkdef.h ordering; ...; #pragma link C++ class Tmpl<int>;; #pragma link C++ class Norm;; ...; ```. And not vice versa:. ``` {.cpp}; // Bad Linkdef.h ordering; ...; #pragma link C++ class Norm;; #pragma link C++ class Tmpl<int>;; ...; ```. In",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md:22579,perform,performance,22579,documentation/users-guide/AddingaClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md,1,['perform'],['performance']
Performance,"k like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24459,load,load,24459,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,['load'],['load']
Performance,"k stuff where possible. As such, we will choose; to run a few per-function optimizations as the user types the function; in. If we wanted to make a ""static Kaleidoscope compiler"", we would use; exactly the code we have now, except that we would defer running the; optimizer until the entire file has been parsed. In addition to the distinction between function and module passes, passes can be; divided into transform and analysis passes. Transform passes mutate the IR, and; analysis passes compute information that other passes can use. In order to add; a transform pass, all analysis passes it depends upon must be registered in; advance. In order to get per-function optimizations going, we need to set up a; `FunctionPassManager <../../WritingAnLLVMPass.html#what-passmanager-doesr>`_ to hold; and organize the LLVM optimizations that we want to run. Once we have; that, we can add a set of optimizations to run. We'll need a new; FunctionPassManager for each module that we want to optimize, so we'll; add to a function created in the previous chapter (``InitializeModule()``):. .. code-block:: c++. void InitializeModuleAndManagers(void) {; // Open a new context and module.; TheContext = std::make_unique<LLVMContext>();; TheModule = std::make_unique<Module>(""KaleidoscopeJIT"", *TheContext);; TheModule->setDataLayout(TheJIT->getDataLayout());. // Create a new builder for the module.; Builder = std::make_unique<IRBuilder<>>(*TheContext);. // Create new pass and analysis managers.; TheFPM = std::make_unique<FunctionPassManager>();; TheLAM = std::make_unique<LoopAnalysisManager>();; TheFAM = std::make_unique<FunctionAnalysisManager>();; TheCGAM = std::make_unique<CGSCCAnalysisManager>();; TheMAM = std::make_unique<ModuleAnalysisManager>();; ThePIC = std::make_unique<PassInstrumentationCallbacks>();; TheSI = std::make_unique<StandardInstrumentations>(*TheContext,; /*DebugLogging*/ true);; TheSI->registerCallbacks(*ThePIC, TheMAM.get());; ... After initializing the global module ``The",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:5495,optimiz,optimize,5495,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimize']
Performance,"k the validity of a given geometry is shooting random; points. This can be called with the method; **`TGeoVolume`**`::RandomPoints()` and it draws a volume with the current; visualization settings. Random points are generated in the bounding box; of the drawn volume. The points are drawn with the color of their; deepest container. Only points inside visible nodes are drawn. ![Random rays](pictures/030001E2.png). A ray tracing method can be called `TGeoVolume::RandomRays()`. This; shoots rays from a given point in the local reference frame with random; directions. The intersections with displayed nodes appear as segments; having the color of the touched node. ## The Drawing Package. ![](pictures/030001E3.png)The modeller provides a powerful drawing; package, supporting several different options of visualization. A; library separated from the main one provides all functionality being; linked with the underlying ROOT visualization system. This library is; dynamically loaded by the plug-in manager only when drawing features are; requested. The geometrical structures that can be visualized are volumes; and volume hierarchies. The main component of the visualization system is volume primitive; painting in a ROOT pad. Starting from this one, several specific options; or subsystems are available, like: X3D viewing using hidden line and; surface removal algorithms, OpenGL viewing\* or ray tracing. The method `TGeoManager::GetGeomPainter()`loads the painting library in; memory. This is generally not needed since it is called automatically by; `TGeoVolume::Draw()` as well as by few other methods setting; visualization attributes. ### Drawing Volumes and Hierarchies of Volumes. The first thing one would like to do after building some geometry is to; visualize the volume tree. This provides the fastest validation check; for most common coding or design mistakes. As soon as the geometry is; successfully closed, one should draw it starting from the top-level; volume:. ``` {.cpp}; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:136665,load,loaded,136665,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['load'],['loaded']
Performance,"k traces. Therefore, it should be used with care,; and only if absolutely required; for example for certain code that cannot; tolerate any instrumentation and resulting side-effects. This attribute; overrides ``no_sanitize(""thread"")``. Ignorelist; ----------. ThreadSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress data race reports; in the specified source files or functions. Unlike functions marked with; ``no_sanitize(""thread"")`` attribute, ignored functions are not instrumented; at all. This can lead to false positives due to missed synchronization via; atomic operations and missed stack frames in reports. Limitations; -----------. * ThreadSanitizer uses more real memory than a native run. At the default; settings the memory overhead is 5x plus 1Mb per each thread. Settings with 3x; (less accurate analysis) and 9x (more accurate analysis) overhead are also; available.; * ThreadSanitizer maps (but does not reserve) a lot of virtual address space.; This means that tools like ``ulimit`` may not work as usually expected.; * Libc/libstdc++ static linking is not supported.; * Non-position-independent executables are not supported. Therefore, the; ``fsanitize=thread`` flag will cause Clang to act as though the ``-fPIE``; flag had been supplied if compiling without ``-fPIC``, and as though the; ``-pie`` flag had been supplied if linking an executable. Current Status; --------------. ThreadSanitizer is in beta stage. It is known to work on large C++ programs; using pthreads, but we do not promise anything (yet). C++11 threading is; supported with llvm libc++. The test suite is integrated into CMake build; and can be run with ``make check-tsan`` command. We are actively working on enhancing the tool --- stay tuned. Any help,; especially in the form of minimized standalone tests is more than welcome. More Information; ----------------; `<https://github.com/google/sanitizers/wiki/ThreadSanitizerCppManual>`_; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSanitizer.rst:5038,tune,tuned,5038,interpreter/llvm-project/clang/docs/ThreadSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSanitizer.rst,1,['tune'],['tuned']
Performance,"k-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the L1 cache.; Therefore, they do not use the sc0 bit for coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:287290,cache,cache,287290,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"k-group; in bytes. This does not; include any dynamically; allocated local address; space memory that may be; added when the kernel is; dispatched.; 63:32 4 bytes PRIVATE_SEGMENT_FIXED_SIZE The amount of fixed; private address space; memory required for a; work-item in bytes. When; this cannot be predicted,; code object v4 and older; sets this value to be; higher than the minimum; requirement.; 95:64 4 bytes KERNARG_SIZE The size of the kernarg; memory pointed to by the; AQL dispatch packet. The; kernarg memory is used to; pass arguments to the; kernel. * If the kernarg pointer in; the dispatch packet is NULL; then there are no kernel; arguments.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is 0 then the kernarg; memory size is; unspecified.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:159831,optimiz,optimize,159831,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['optimiz'],['optimize']
Performance,k.h; clang-tools-extra/clang-tidy/objc/PropertyDeclarationCheck.h; clang-tools-extra/clang-tidy/objc/SuperSelfCheck.cpp; clang-tools-extra/clang-tidy/objc/SuperSelfCheck.h; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.cpp; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.h; clang-tools-extra/clang-tidy/openmp/OpenMPTidyModule.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.h; clang-tools-extra/clang-tidy/performance/FasterStringFindCheck.cpp; clang-tools-extra/clang-tidy/performance/ForRangeCopyCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.h; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.h; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.cpp; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.h; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.cpp; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.h; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.cpp; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.h; clang-tools-extra/clang-tidy/performance/PerformanceTidyModule.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.h; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.cpp; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.h; clang-tools-extra/clang-tidy/performance/UnnecessaryCopyInitializat,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:65205,perform,performance,65205,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['perform'],['performance']
Performance,"k:: c++. struct S {; char c;; int i;; struct T {; float f[2];; } t;; };. const int offset_to_i = __builtin_offsetof(struct S, i);; const int ext1 = __builtin_offsetof(struct U { int i; }, i); // C extension; const int offset_to_subobject = __builtin_offsetof(struct S, t.f[1]);. **Description**:. This builtin is usable in an integer constant expression which returns a value; of type ``size_t``. The value returned is the offset in bytes to the subobject; designated by the member-designator from the beginning of an object of type; ``type-name``. Clang extends the required standard functionality in the; following way:. * In C language modes, the first argument may be the definition of a new type.; Any type declared this way is scoped to the nearest scope containing the call; to the builtin. Query for this feature with ``__has_builtin(__builtin_offsetof)``. ``__builtin_call_with_static_chain``; ------------------------------------. ``__builtin_call_with_static_chain`` is used to perform a static call while; setting updating the static chain register. **Syntax**:. .. code-block:: c++. T __builtin_call_with_static_chain(T expr, void* ptr). **Example of Use**:. .. code-block:: c++. auto v = __builtin_call_with_static_chain(foo(3), foo);. **Description**:. This builtin returns ``expr`` after checking that ``expr`` is a non-member; static call expression. The call to that expression is made while using ``ptr``; as a function pointer stored in a dedicated register to implement *static chain*; calling convention, as used by some language to implement closures or nested; functions. Query for this feature with ``__has_builtin(__builtin_call_with_static_chain)``. ``__builtin_readcyclecounter``; ------------------------------. ``__builtin_readcyclecounter`` is used to access the cycle counter register (or; a similar low-latency, high-accuracy clock) on those targets that support it. **Syntax**:. .. code-block:: c++. __builtin_readcyclecounter(). **Example of Use**:. .. code-block:: ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:102095,perform,perform,102095,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['perform'],['perform']
Performance,"k:: gas. load r5, [r0]; load r6, [r1]; Loading from 0xa0463440 to 0xa0463447. but would not match the text:. .. code-block:: gas. load r5, [r0]; load r7, [r1]; Loading from 0xa0463440 to 0xa0463443. Due to ``7`` being unequal to ``5 + 1`` and ``a0463443`` being unequal to; ``a0463440 + 7``. A numeric variable can also be defined to the result of a numeric expression,; in which case the numeric expression constraint is checked and if verified the; variable is assigned to the value. The unified syntax for both checking a; numeric expression and capturing its value into a numeric variable is thus; ``[[#%<fmtspec>,<NUMVAR>: <constraint> <expr>]]`` with each element as; described previously. One can use this syntax to make a testcase more; self-describing by using variables instead of values:. .. code-block:: gas. ; CHECK: mov r[[#REG_OFFSET:]], 0x[[#%X,FIELD_OFFSET:12]]; ; CHECK-NEXT: load r[[#]], [r[[#REG_BASE:]], r[[#REG_OFFSET]]]. which would match:. .. code-block:: gas. mov r4, 0xC; load r6, [r5, r4]. The ``--enable-var-scope`` option has the same effect on numeric variables as; on string variables. Important note: In its current implementation, an expression cannot use a; numeric variable defined earlier in the same CHECK directive. FileCheck Pseudo Numeric Variables; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Sometimes there's a need to verify output that contains line numbers of the; match file, e.g. when testing compiler diagnostics. This introduces a certain; fragility of the match file structure, as ""``CHECK:``"" lines contain absolute; line numbers in the same file, which have to be updated whenever line numbers; change due to text addition or deletion. To support this case, FileCheck expressions understand the ``@LINE`` pseudo; numeric variable which evaluates to the line number of the CHECK pattern where; it is found. This way match patterns can be put near the relevant test lines and include; relative line number references, for example:. .. code-block:: c++. // C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:33305,load,load,33305,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['load'],['load']
Performance,"kages; 2. Use generic naming convention - all class names always starts from; capital letter like ""ObjectPainter"", all function names starts from small; letter like ""painter.getObjectHint()""; 3. Rename JSRootCore.js -> JSRoot.core.js, eliminate all URL parameters.; Loading of extra JSROOT functionality should be done via JSROOT.require() method; All other scripts uses similar naming convention.; 4. JSROOT.draw()/JSROOT.redraw() functions returns Promise, deprecate callback parameter; 5. Introduce JSROOT.httpRequest() function which returns Promise instance, deprecate; JSROOT.NewHttpRequest() function; 6. JSROOT.openFile() returns Promise with file instance, deprecate callback parameter; 7. Provide new code loader via JSROOT.require(); - introduces clean dependencies in JSROOT code; - by default uses plain script loading emulating require.js behavior; - can use require.js when available; - uses require() method when running inside node.js; - supports openui5 sap.ui.require loader if available before JSRoot.core.js; - deprecates old JSROOT.AssertPrerequisites() function; 8. Upgrade d3.js to v6.1.1, skip support of older versions; 9. Upgrade three.js to r121:; - SoftwareRenderer deprecated and removed; - let use WebGL for browser, batch and node.js (via headless-gl); - support r3d_gl, r3d_img, r3d_svg rendering options for TGeo and histograms; - keep support of SVGRendered as backup solution; 10. Upgrade MathJax.js to version 3.1.1; - reliably works in browser and node.js!; - all latex/mathjax related methods moved to special JSRoot.latex.js script, loaded on demand; 11. Update jquery to 3.5.1, openui5 to 1.82.2; 12. Use JS classes only in few places - performance is not good enough compared to Object.prototype; 13. Deprecate IE support; 14. Deprecate bower package manager; 15. Add support of ZSTD compression - works only on https://root.cern/js/ website; 16. Add support of log2 scale for axes drawing, v7 can have arbitrary log base; 17. Improve TH2 col drawings for la",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:25694,load,loader,25694,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['load'],['loader']
Performance,"ke sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In addition, a getter and a setter methods are provided to check the status and enable/disable implic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9977,cache,cache,9977,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,2,['cache'],"['cache', 'cachesize']"
Performance,"ked; work-item Add product; IDs names. ``gfx1151`` ``amdgcn`` APU - cumode - Architected *TBA*; - wavefrontsize64 flat; scratch .. TODO::; - Packed; work-item Add product; IDs names. ``gfx1200`` ``amdgcn`` dGPU - cumode - Architected *TBA*; - wavefrontsize64 flat; scratch .. TODO::; - Packed; work-item Add product; IDs names. ``gfx1201`` ``amdgcn`` dGPU - cumode - Architected *TBA*; - wavefrontsize64 flat; scratch .. TODO::; - Packed; work-item Add product; IDs names. =========== =============== ============ ===== ================= =============== =============== ======================. .. _amdgpu-target-features:. Target Features; ---------------. Target features control how code is generated to support certain; processor specific features. Not all target features are supported by; all processors. The runtime must ensure that the features supported by; the device used to execute the code match the features enabled when; generating the code. A mismatch of features may result in incorrect; execution, or a reduction in performance. The target features supported by each processor is listed in; :ref:`amdgpu-processor-table`. Target features are controlled by exactly one of the following Clang; options:. ``-mcpu=<target-id>`` or ``--offload-arch=<target-id>``. The ``-mcpu`` and ``--offload-arch`` can specify the target feature as; optional components of the target ID. If omitted, the target feature has the; ``any`` value. See :ref:`amdgpu-target-id`. ``-m[no-]<target-feature>``. Target features not specified by the target ID are specified using a; separate option. These target features can have an ``on`` or ``off``; value. ``on`` is specified by omitting the ``no-`` prefix, and; ``off`` is specified by including the ``no-`` prefix. The default; if not specified is ``off``. For example:. ``-mcpu=gfx908:xnack+``; Enable the ``xnack`` feature.; ``-mcpu=gfx908:xnack-``; Disable the ``xnack`` feature.; ``-mcumode``; Enable the ``cumode`` feature.; ``-mno-cumode``; Disable the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:15605,perform,performance,15605,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performance']
Performance,"ker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which adds ``extern ""C""`` around the header. Library files can be aggregated by linking all relevant ones to a single; library to load.; Using the linker for this purpose allows regular system features such as; ``rpath`` and envars such as ``LD_LIBRARY_PATH`` to be applied as usual.; Note that any mechanism that exposes the library symbols will work.; For example, you could also use the standard module ``ctypes`` through; ``ctypes.CDLL`` with the ``ctypes.RTLD_GLOBAL`` option. To explore, start from ``cppyy.gbl`` to access your namespaces, classes,; functions, etc., etc. directly; or use python's ``dir`` (or tab-completion); to see what is available.; Use python's ``help`` to see list the methods and data members of classes and; see the interfaces of functions. Now try this out for some of your own headers, libraries, and APIs!. .. _`zlib`: https://en.wikipedia.org/wiki/Zlib; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:2123,load,load,2123,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,1,['load'],['load']
Performance,"kip it installation with `npm i --production`; 25. Fix - correct scaling of axis labels when tilt them by 25 degree, make this angle configurable; 26. Fix - legend multi-columns drawing and labels scaling; 27. Fix - graph ""B"" bar widths as in native ROOT; 28. Fix - use pad and not frame size for `TText` / `TLatex` scaling; 29. Fix - properly handle ""NB"" (no border) draw option for `TPave` classes; 30. Fix - do not draw histogram title with AXIS draw option; 31. Fix - correct scaling of custom axis labels; 32. Fix - shrink axis labels like 0.20 -> 0.2 or 10^0 -> 1; 33. Fix - copy axis attributes from histogram z scale to palette; 34. Fix - let handle derived from TH1/TH2 classes as histograms #269. ## Changes in 7.4.3; 1. Fix - correctly use GMT specifier in time format; 2. Fix - logical error in `decodeUrl`; 3. Fix - member-wise streaming of std::map #262. ## Changes in 7.4.2; 1. Fix - unzoom z on lego2 plots; 2. Fix - browsing TLists with nullptr inside; 3. Fix - check NaN values when performing TTree::Draw(); 4. Fix - support standard log function in TF1/TF2. ## Changes in 7.4.1; 1. Fix - context menu position on lego plots; 2. Fix - add missing math functions Chebyshev0 and normalized Gaus; 3. Fix - correctly render TPolyLine3D; 4. Fix - properly add interactive resize elements for paves and frame; 5. Fix - drag and drop handling on tabs layout. ## Changes in 7.4.0; 1. Upgrade d3.js v7.6.1 -> v7.8.4; 2. Upgrade three.js r146 -> r151; 3. Support `[cutg]` draw option for TH2; 4. Correctly handle `same0` draw option for TH2; 5. Fix several issues with axis reverse order, support on lego plots; 6. Support more kinds of log scales - ln and logN where N is any positive integer; 7. Adjust TAxis title positioning to native ROOT behavior; 8. Add interactivity (moving, context menu) for TLine, TBox, TText, TLatex, TDiamond, TGaxis, TASImage; 9. Use new gStyle attributes for candle and violin plots; 10. Implement autoplace for TLegend, also via context menu; 11. Change algor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:11664,perform,performing,11664,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['perform'],['performing']
Performance,"kmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory oper",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:256610,load,loads,256610,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"known to be dereferenceable; prior to a call to a function with the ``nofree`` attribute are still; known to be dereferenceable after the call. The capturing condition is; necessary in environments where the function might communicate the; pointer to another thread which then deallocates the memory. Alternatively,; ``nosync`` would ensure such communication cannot happen and even captured; pointers cannot be freed by the function. A ``nofree`` function is explicitly allowed to free memory which it; allocated or (if not ``nosync``) arrange for another thread to free; memory on it's behalf. As a result, perhaps surprisingly, a ``nofree``; function can return a pointer to a previously deallocated memory object.; ``noimplicitfloat``; Disallows implicit floating-point code. This inhibits optimizations that; use floating-point code and floating-point registers for operations that are; not nominally floating-point. LLVM instructions that perform floating-point; operations or require access to floating-point registers may still cause; floating-point code to be generated. Also inhibits optimizations that create SIMD/vector code and registers from; scalar code such as vectorization or memcpy/memset optimization. This; includes integer vectors. Vector instructions present in IR may still cause; vector code to be generated.; ``noinline``; This attribute indicates that the inliner should never inline this; function in any situation. This attribute may not be used together; with the ``alwaysinline`` attribute.; ``nomerge``; This attribute indicates that calls to this function should never be merged; during optimization. For example, it will prevent tail merging otherwise; identical code sequences that raise an exception or terminate the program.; Tail merging normally reduces the precision of source location information,; making stack traces less useful for debugging. This attribute gives the; user control over the tradeoff between code size and debug information; precision.; ``n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:90314,perform,perform,90314,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"krestore.p5 <int_stackrestore>` Implemented, must use the alloca address space. :ref:`llvm.get.fpmode.i32 <int_get_fpmode>` The natural floating-point mode type is i32. This; implemented by extracting relevant bits out of the MODE; register with s_getreg_b32. The first 10 bits are the; core floating-point mode. Bits 12:18 are the exception; mask. On gfx9+, bit 23 is FP16_OVFL. Bitfields not; relevant to floating-point instructions are 0s. :ref:`llvm.get.rounding<int_get_rounding>` AMDGPU supports two separately controllable rounding; modes depending on the floating-point type. One; controls float, and the other controls both double and; half operations. If both modes are the same, returns; one of the standard return values. If the modes are; different, returns one of :ref:`12 extended values; <amdgpu-rounding-mode-enumeration-values-table>`; describing the two modes. To nearest, ties away from zero is not a supported; mode. The raw rounding mode values in the MODE; register do not exactly match the FLT_ROUNDS values,; so a conversion is performed. llvm.amdgcn.wave.reduce.umin Performs an arithmetic unsigned min reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:38217,perform,performed,38217,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance,"l %eax, %edi; ```. Other useful patterns may be to fold the load into the `or` instruction itself; at the cost of a register-to-register copy. There are some challenges with deploying this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-chan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24612,load,load,24612,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,['load'],['load']
Performance,"l = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so the above example is only representative, not literal). The; ``ImplicitNullChecks`` pass runs during codegen, if; ``-enable-implicit-null-checks`` is passed to ``llc``. The ``ImplicitNullChecks`` pass adds entries to the; ``__llvm_faultmaps`` section described above as needed. ``make.implicit`` metadata; --------------------------. Making null checks implicit is an aggressive optimization, and it can; be a net performance pessimization if too many memory operations end; up faulting because of it. A language runtime typically needs to; ensure that only a negligible number of implicit null checks actually; fault once the application has reached a steady state. A standard way; of doing this is by healing failed implicit null checks into explicit; null checks via code patching or recompilation. It follows that there; are two requirements an explicit null check needs to satisfy for it to; be profitable to convert it to an implicit null check:. 1. The case where the pointer is actually null (i.e. the ""failing""; case) is extremely rare. 2. The failing path heals the implicit null check into an explicit; null check so that the application does not repeatedly page; fault. The frontend is expected to mark branches that satisfy (1) and (2); using a ``!make.implicit`` metadata node (the actual content of the; metadata node is ignored). Only branches that are marked with; ``!make.implicit`` metadata are con",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:3198,optimiz,optimization,3198,interpreter/llvm-project/llvm/docs/FaultMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"l ROOT Facility classes. - `libPython` provides the interface to Python. - \*`libRFIO` is the interface to CERN RFIO remote I/O system. - \*`libRGL` is the interface to OpenGL. - `libReflex` is the runtime type database library used by Cling. - `libRint` is the interactive interface to ROOT (provides command; prompt). - `libRIO` provides the functionality to write and read objects to; and from ROOT files. - `libRooFit` is the RooFit fitting framework. - `libRuby` is the interface to Ruby. - `libSpectrum` provides functionality for spectral analysis. - \*`libThread` is the interface to TThread classes. - `libTMVA` contains the multivariate analysis toolkit. - `libTree` is the TTree object container system. - `libTreePlayer` is the TTree drawing classes. - `libTreeViewer` is the graphical TTree query interface. #### Library Dependencies. ![ROOT libraries dependencies](pictures/03000005.png). The libraries are designed and organized to minimize dependencies,; such that you can load just enough code for the task at hand rather; than having to load all libraries or one monolithic chunk. The core; library (`libCore.so`) contains the essentials; it is a part of all; ROOT applications. In the Figure 1-2 you see that libCore.so is made; up of base classes, container classes, meta information classes,; operating system specific classes, and the ZIP algorithm used for; compression of the ROOT files. The Cling library (`libCling.so`) is also needed in all ROOT; applications, and even by `libCore`. A; program referencing only **`TObject`** only needs `libCore`;; `libCling` will be opened automatically. To add the ability to read and write; ROOT objects one also has to load `libRIO`. As one would expect, none of that; depends on graphics or the GUI. Library dependencies have different consequences; depending on whether; you try to build a binary, or you just try to access a class that is; defined in a library. #### Linktime Library Dependencies. When building your own executable ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:16107,load,load,16107,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,2,['load'],['load']
Performance,"l ``ensureOptimizedUses()``. Initially it was not possible to optimize ``MemoryDef``\ s in the same way, as we; restricted ``MemorySSA`` to one operand per access.; This was changed and ``MemoryDef``\ s now keep two operands.; The first one, the defining access, is; always the previous ``MemoryDef`` or ``MemoryPhi`` in the same basic block, or; the last one in a dominating predecessor if the current block doesn't have any; other accesses writing to memory. This is needed for walking Def chains.; The second operand is the optimized access, if there was a previous call on the; walker's ``getClobberingMemoryAccess(MA)``. This API will cache information; as part of ``MA``.; Optimizing all ``MemoryDef``\ s has quadratic time complexity and is not done; by default. A walk of the uses for any MemoryDef can find the accesses that were optimized; to it.; A code snippet for such a walk looks like this:. .. code-block:: c++. MemoryDef *Def; // find who's optimized or defining for this MemoryDef; for (auto& U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *DefUser = cast_of_null<MemoryDef>MA); if (DefUser->isOptimized() && DefUser->getOptimized() == Def) {; // User who is optimized to Def; } else {; // User who's defining access is Def; optimized to something else or not optimized.; }; }. When ``MemoryUse``\ s are optimized, for a given store, you can find all loads; clobbered by that store by walking the immediate and transitive uses of; the store. .. code-block:: c++. checkUses(MemoryAccess *Def) { // Def can be a MemoryDef or a MemoryPhi.; for (auto& U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *MU = cast_of_null<MemoryUse>MA) {; // Process MemoryUse as needed.; }; else {; // Process MemoryDef or MemoryPhi as needed. // As a user can come up twice, as an optimized access and defining; // access, keep a visited list. // Check transitive uses as needed; checkUses (MA); // use a worklist for an iterative ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:12912,optimiz,optimized,12912,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimized']
Performance,"l address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load sc0=1; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_inv. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:296401,load,load,296401,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"l be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6814,perform,performed,6814,roofit/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html,2,['perform'],['performed']
Performance,"l data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:249704,load,load,249704,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"l field, e.g.; ```; auto model = RNTupleModel::Create();; auto fvec = model->MakeField<std::vector<float>>(""vec"");. auto aliasVec = RFieldBase::Create(""aliasVec"", ""std::vector<float>"").Unwrap();; model->AddProjectedField(std::move(aliasVec), [](const std::string &fieldName) {; if (fieldName == ""aliasVec"") return ""vec"";; else return ""vec._0"";; });; ```; Projected fields are stored as part of the metadata. - Improvements on the internal `RField` value API. The `RFieldValue` class has been deprecated in favor of `RField::Value` and the related interfaces have changed accordingly (see [#13219](https://github.com/root-project/root/pull/13219) and [#13264](https://github.com/root-project/root/pull/13264)).; If you were not using `RField::(Read|Append)` directly, this change should not impact you. - The new `RNTupleImporter` class provides automatic conversion of TTree to RNTuple.; Note that not all of the C++ types supported in TTree are currently supported in RNTuple. - Many bug fixes and performance improvements. Please, report any issues regarding the abovementioned features should you encounter them.; RNTuple is still experimental and is scheduled to become production grade by end of 2024.; Thus, we appreciate feedback and suggestions for improvement. ## Histogram Libraries. ## Math Libraries. ### Minuit2 is now the default minimizer. Many ROOT-based frameworks and users employ Minuit2 as the minimizer of choice for a long time already.; Therefore, Minuit2 is now the default minimizer used by ROOT.; This affects also **RooFit**, which inherits the default minimizer from ROOT Math. The default can be changed back to the old Minuit implementation as follows:; ```c++; ROOT::Math::MinimizerOptions::SetDefaultMinimizer(""Minuit"");; ```. Alternatively, you can add this line to your `~/.rootrc` file:; ```; Root.Fitter: Minuit; ```. ### Behavior change of `TMath::AreEqualAbs()`. The `TMath::AreEqualAbs()` compares two numbers for equality within a certain absolute range.; So fa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:9696,perform,performance,9696,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['perform'],['performance']
Performance,"l memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:289424,cache,cache,289424,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['cache'],"['cache', 'caches']"
Performance,"l memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:236842,cache,cache,236842,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"l not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_inv.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:325785,perform,performing,325785,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"l on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx9",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:205070,load,load,205070,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"l one past the last operation of the stream is reached. The result of the evaluation is:. * If an operation has an evaluation error, or an operation evaluates an; expression that has an evaluation error, then the result is an evaluation; error. * If the current result kind specifies a location description, then:. * If the stack is empty, the result is a location description with one; undefined location description. *This rule is for backwards compatibility with DWARF Version 5 which has no; explicit operation to create an undefined location description, and uses an; empty operation expression for this purpose.*. * If the top stack entry is a location description, or can be converted; to one (see :ref:`amdgpu-dwarf-memory-location-description-operations`),; then the result is that, possibly converted, location description. Any other; entries on the stack are discarded. * Otherwise the DWARF expression is ill-formed. .. note::. Could define this case as returning an implicit location description as; if the ``DW_OP_implicit`` operation is performed. * If the current result kind specifies a value, then:. * If the top stack entry is a value, or can be converted to one (see; :ref:`amdgpu-dwarf-memory-location-description-operations`), then the result; is that, possibly converted, value. Any other entries on the stack are; discarded. * Otherwise the DWARF expression is ill-formed. * If the current result kind is not specified, then:. * If the stack is empty, the result is a location description with one; undefined location description. *This rule is for backwards compatibility with DWARF Version 5 which has no; explicit operation to create an undefined location description, and uses an; empty operation expression for this purpose.*. .. note::. This rule is consistent with the rule above for when a location; description is requested. However, GDB appears to report this as an error; and no GDB tests appear to cause an empty stack for this case. * Otherwise, the top stack entr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:66147,perform,performed,66147,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['performed']
Performance,"l output). Phases are well known compilation; steps, such as ""preprocess"", ""compile"", ""assemble"", ""link"", etc. #. **Bind: Tool & Filename Selection**. This stage (in conjunction with the Translate stage) turns the tree; of Actions into a list of actual subprocess to run. Conceptually, the; driver performs a top down matching to assign Action(s) to Tools. The; ToolChain is responsible for selecting the tool to perform a; particular action; once selected the driver interacts with the tool; to see if it can match additional actions (for example, by having an; integrated preprocessor). Once Tools have been selected for all actions, the driver determines; how the tools should be connected (for example, using an inprocess; module, pipes, temporary files, or user provided filenames). If an; output file is required, the driver also computes the appropriate; file name (the suffix and file location depend on the input types and; options such as ``-save-temps``). The driver interacts with a ToolChain to perform the Tool bindings.; Each ToolChain contains information about all the tools needed for; compilation for a particular architecture, platform, and operating; system. A single driver invocation may query multiple ToolChains; during one compilation in order to interact with tools for separate; architectures. The results of this stage are not computed directly, but the driver; can print the results via the ``-ccc-print-bindings`` option. For; example:. .. code-block:: console. $ clang -ccc-print-bindings -arch i386 -arch ppc t0.c; # ""i386-apple-darwin9"" - ""clang"", inputs: [""t0.c""], output: ""/tmp/cc-Sn4RKF.s""; # ""i386-apple-darwin9"" - ""darwin::Assemble"", inputs: [""/tmp/cc-Sn4RKF.s""], output: ""/tmp/cc-gvSnbS.o""; # ""i386-apple-darwin9"" - ""darwin::Link"", inputs: [""/tmp/cc-gvSnbS.o""], output: ""/tmp/cc-jgHQxi.out""; # ""ppc-apple-darwin9"" - ""gcc::Compile"", inputs: [""t0.c""], output: ""/tmp/cc-Q0bTox.s""; # ""ppc-apple-darwin9"" - ""gcc::Assemble"", inputs: [""/tmp/cc-Q0bTox.s""], output: ""/t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:9382,perform,perform,9382,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['perform'],['perform']
Performance,"l passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:3713,perform,perform,3713,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,1,['perform'],['perform']
Performance,"l runtime (including; decompression time) in the uncompressed and compressed cases. ## Interpreting results:. ### There are three possible scenarios when using rootreadspeed, namely:. - The 'Real Time' is significantly lower than your own analysis runtime.; This would imply your actual application code is dominating the runtime of your analysis,; ie. your analysis logic or framework is taking up the time.; The best way to decrease the runtime would be to optimize your code (or the framework's),; parallelize it onto multiple threads if possible (for example with; [RDataFrame](https://root.cern/doc/master/classROOT_1_1RDataFrame.html); and [EnableImplicitMT](https://root.cern/doc/master/namespaceROOT.html#a06f2b8b216b615e5abbc872c9feff40f)); or switch to a machine with a more performant CPU.; - The 'Real Time' is significantly higher than 'CPU Time / number of threads'*.; If the real time is higher than the CPU time per core it implies the reading of data is the; bottleneck, as the CPU cores are wasting time waiting for data to arrive from your disk/drive; or network connection in order to decompress it.; The best way to decrease your runtime would be transferring the data you need onto a faster; storage medium (ie. a faster disk/drive such as an SSD, or connecting to a faster network; for remote file access), or to use a compression algorithm with a higher compression ratio,; possibly at the cost of the decompression rate.; Changing the number of threads is unlikely to help, and in fact using too many threads may; degrade performance if they make requests to different regions of your local storage. ; * If no '--threads' argument was provided this is 1, otherwise it is the minimum of the value; provided and the number of threads your CPU can run in parallel. It is worth noting that -; on shared systems or if running other heavy applications - the number of your own threads; running at any time may be lower than the limit due to demand on the CPU.; - The 'Real Time' is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md:1837,bottleneck,bottleneck,1837,tree/readspeed/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md,1,['bottleneck'],['bottleneck']
Performance,"l show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13936,optimiz,optimizations,13936,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['optimiz'],['optimizations']
Performance,"l, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on NVIDIA GPUs.; Many of the 64-bit divides in our benchmarks have a divisor and dividend; which fit in 32-bits at runtime. This optimization provides a fast path for; this common case. * Aggressive loop unrolling and function inlining -- Loop unrolling and; function inlining need to be more aggressive for GPUs than for CPUs because; control flow transfer in GPU is more expensive. More aggressive unrolling and; inlining also promote other optimizations, such as constant propagation and; SROA, which sometimes speed up code by over 10x. (Programmers can force unrolling and inline using clang's `loop unrolling pragmas; <https://clang.llvm.org/docs/AttributeReference.html#pragma-unroll-pragma-nounroll>`_; and ``__attribute__((always_inline))``.). Publication; ===========. The team at Google published a paper in CGO 2016 detailing the optimizations; they'd made to clang/LLVM. Note that ""gpucc"" is no longer a meaningful name:; The relevant tools are now just vanilla clang/LLVM. | `gpucc: An Open-Source GPGPU Compiler <http://dl.acm.org/citation.cfm?id=2854041>`_; | Jingyue Wu, Artem Belevich, Eli Bendersky, Mark Heffernan, Chris Leary, Jacques Pienaar, Bjarke Roune, Rob Springer, Xuetian Weng, Robert Hundt; | *Proceedings of the 2016 International Symposium on Code Generation and Optimization (CGO 2016)*; |; | `Slides from the CGO talk <http://wujingyue.github.io/docs/gpucc-talk.pdf>`_; |; | `Tutorial given at CGO <http://wujingyue.github.io/do",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:19938,optimiz,optimizations,19938,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,1,['optimiz'],['optimizations']
Performance,"l. ## Status and usage. **Status**: Experimental work in progress. Enabling is strongly advised against; except for development and testing. **Enable in Clang**: `-Xclang -fexperimental-assignment-tracking`. That causes Clang to get LLVM to run the pass `declare-to-assign`. The pass; converts conventional debug intrinsics to assignment tracking metadata and sets; the module flag `debug-info-assignment-tracking` to the value `i1 true`. To; check whether assignment tracking is enabled for a module call; `isAssignmentTrackingEnabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to know where in IR it is appropriate to use a memory location for a; variable, each assignment marker must in some way refer to the store, if any; (or multiple!), that performs the assignment. That way, the position of the; store and marker can be considered together when making that choice. Another; important benefit of referring to the store is that we can then build a two-way; mapping of stores<->markers that can be used to find markers that need to be; updated when stores are modified. An `llvm.dbg.assign` marker that is not linked to any instruction signals that; the store that performed the assignment has been optimised out, and therefore; the memory location will not be valid for at least some part of the program. Here's the `llvm.dbg.assign` signature. Each parameter is wrapped in; `MetadataAsValue`, and `Value *` type parameters are first wrapped in; `ValueAsMetadata`:. ```; void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression); ```. The first three paramete",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:2166,perform,performs,2166,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md,1,['perform'],['performs']
Performance,"l. .. option:: -fcommon, -fno-common. This flag specifies that variables without initializers get common linkage.; It can be disabled with :option:`-fno-common`. .. option:: -ftls-model=<model>. Set the default thread-local storage (TLS) model to use for thread-local; variables. Valid values are: ""global-dynamic"", ""local-dynamic"",; ""initial-exec"" and ""local-exec"". The default is ""global-dynamic"". The default; model can be overridden with the tls_model attribute. The compiler will try; to choose a more efficient model if possible. .. option:: -flto, -flto=full, -flto=thin, -emit-llvm. Generate output files in LLVM formats, suitable for link time optimization.; When used with :option:`-S` this generates LLVM intermediate language; assembly files, otherwise this generates LLVM bitcode format object files; (which may be passed to the linker depending on the stage selection options). The default for :option:`-flto` is ""full"", in which the; LLVM bitcode is suitable for monolithic Link Time Optimization (LTO), where; the linker merges all such modules into a single combined module for; optimization. With ""thin"", :doc:`ThinLTO <../ThinLTO>`; compilation is invoked instead. .. note::. On Darwin, when using :option:`-flto` along with :option:`-g` and; compiling and linking in separate steps, you also need to pass; ``-Wl,-object_path_lto,<lto-filename>.o`` at the linking step to instruct the; ld64 linker not to delete the temporary object file generated during Link; Time Optimization (this flag is automatically passed to the linker by Clang; if compilation and linking are done in a single step). This allows debugging; the executable as well as generating the ``.dSYM`` bundle using :manpage:`dsymutil(1)`. Driver Options; ~~~~~~~~~~~~~~. .. option:: -###. Print (but do not run) the commands to run for this compilation. .. option:: --help. Display available options. .. option:: -Qunused-arguments. Do not emit any warnings for unused driver arguments. .. option:: -Wa,<args>. Pass ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:15532,optimiz,optimization,15532,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['optimiz'],['optimization']
Performance,"l.gc.relocate.p1i8(token %token, i32 7, i32 8); %p = getelementptr i8, i8 addrspace(1)* %gep, i64 -20000; ret i8 addrspace(1)* %p; }. Note that in this example %p and %obj.relocate are the same address and we; could replace one with the other, potentially removing the derived pointer; from the live set at the safepoint entirely. .. _gc_transition_args:. GC Transitions; ^^^^^^^^^^^^^^^^^^. As a practical consideration, many garbage-collected systems allow code that is; collector-aware (""managed code"") to call code that is not collector-aware; (""unmanaged code""). It is common that such calls must also be safepoints, since; it is desirable to allow the collector to run during the execution of; unmanaged code. Furthermore, it is common that coordinating the transition from; managed to unmanaged code requires extra code generation at the call site to; inform the collector of the transition. In order to support these needs, a; statepoint may be marked as a GC transition, and data that is necessary to; perform the transition (if any) may be provided as additional arguments to the; statepoint. Note that although in many cases statepoints may be inferred to be GC; transitions based on the function symbols involved (e.g. a call from a; function with GC strategy ""foo"" to a function with GC strategy ""bar""),; indirect calls that are also GC transitions must also be supported. This; requirement is the driving force behind the decision to require that GC; transitions are explicitly marked. Let's revisit the sample given above, this time treating the call to ``@foo``; as a GC transition. Depending on our target, the transition code may need to; access some extra state in order to inform the collector of the transition.; Let's assume a hypothetical GC--somewhat unimaginatively named ""hypothetical-gc""; --that requires that a TLS variable must be written to before and after a call; to unmanaged code. The resulting relocation sequence is:. .. code-block:: llvm. @flag = thread_local glo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:16900,perform,perform,16900,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['perform'],['perform']
Performance,"l.widenable.condition(); %guard_cond = and i1 %cond, %widenable_cond; br i1 %guard_cond, label %guarded, label %deopt. with. .. code-block:: text. %widenable_cond = call i1 @llvm.experimental.widenable.condition(); %new_cond = and i1 %any_other_cond, %widenable_cond; %new_guard_cond = and i1 %cond, %new_cond; br i1 %new_guard_cond, label %guarded, label %deopt. for this branch. Here `%any_other_cond` is an arbitrarily chosen; well-defined `i1` value. By making guard widening, we may; impose stricter conditions on `guarded` block and bail to the; deopt when the new condition is not met. Lowering:; """""""""""""""""". Default lowering strategy is replacing the result of; call of ``@llvm.experimental.widenable.condition`` with; constant `true`. However it is always correct to replace; it with any other `i1` value. Any pass can; freely do it if it can benefit from non-default lowering. '``llvm.load.relative``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.load.relative.iN(ptr %ptr, iN %offset) nounwind memory(argmem: read). Overview:; """""""""""""""""". This intrinsic loads a 32-bit value from the address ``%ptr + %offset``,; adds ``%ptr`` to that value and returns it. The constant folder specifically; recognizes the form of this intrinsic and the constant initializers it may; load from; if a loaded constant initializer is known to have the form; ``i32 trunc(x - %ptr)``, the intrinsic call is folded to ``x``. LLVM provides that the calculation of such a constant initializer will; not overflow at link time under the medium code model if ``x`` is an; ``unnamed_addr`` function. However, it does not provide this guarantee for; a constant initializer folded into a function body. This intrinsic can be; used to avoid the possibility of overflows when loading from such a constant. .. _llvm_sideeffect:. '``llvm.sideeffect``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.sideeffect() inaccessiblememonly nounwind willre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:950827,load,load,950827,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"l/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local. 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); Must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have compl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:375793,load,load,375793,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"l/generic; load/store/load; atomic/store atomic/; atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_gl0_inv.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:371451,cache,cache,371451,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"l2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:253111,load,load,253111,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"l; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:225787,perform,performing,225787,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"lClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False  Print method-specific help message. CreateMVAPdfs No False  Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False  Events with negative weights are ignored in the training (but are included for testing and performance evaluation). NCycles No 3000  Number of training cycles. HiddenLayers No N,N-1  Specification of hidden layer architecture. Configuration options for MVA method :. Configuration options reference for MVA method: KNN. Option Array Default value Predefined values Description. V No False  Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None  List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False  Print method-specific help message. CreateMVAPdfs No False  Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False  Events with negative weights are ignored in the training (but are included for testing and performance evaluation). nkNN No 20  Number of k-nearest neighbors. BalanceDepth No 6  Binary tree balance depth. ScaleFrac No 0.8  Fraction of events used to compute variable width. SigmaFact No 1  Scale factor for sigma in Gaussian kernel. Kernel No Gaus  Use polynomial (=Poln) or Gaussian (=Gaus) kernel. Trim No False  Use equal number of signal and background events. UseKernel No False  Use polynomial kernel weight. UseWeight No T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:9811,perform,performed,9811,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['perform'],['performed']
Performance,"lISel <https://llvm.org/docs/GlobalISel/index.html>`_ is another; instruction selection framework. .. _SelectionDAG:. Introduction to SelectionDAGs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG provides an abstraction for code representation in a way that; is amenable to instruction selection using automatic techniques; (e.g. dynamic-programming based optimal pattern matching selectors). It is also; well-suited to other phases of code generation; in particular, instruction; scheduling (SelectionDAG's are very close to scheduling DAGs post-selection).; Additionally, the SelectionDAG provides a host representation where a large; variety of very-low-level (but target-independent) `optimizations`_ may be; performed; ones which require extensive information about the instructions; efficiently supported by the target. The SelectionDAG is a Directed-Acyclic-Graph whose nodes are instances of the; ``SDNode`` class. The primary payload of the ``SDNode`` is its operation code; (Opcode) that indicates what operation the node performs and the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operands, which are edges to; the node defining the used value. Because nodes may define multiple values,; edges are represented by instances of the ``SDValue`` class, which is a; ``<SDNode, unsigned>`` pair, indicating the node and result value being used,; respectively. Each value produced by an ``SDNode`` has an associated ``MVT``; (Machine Value Type) indicating what the type of the value is. SelectionDAGs contain two different kinds of values: those that represent data; flow and those that represent control flow depende",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:34395,perform,performs,34395,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['perform'],['performs']
Performance,"label %bb7, label %bb. bb:		; preds = %entry; 	%tmp6 = add i32 %b, %a		; <i32> [#uses=1]; 	ret i32 %tmp6. bb7:		; preds = %entry; 	%tmp10 = sub i32 %a, %c		; <i32> [#uses=1]; 	ret i32 %tmp10; }. to:. foo: # @foo; # %bb.0: # %entry; 	movl	4(%esp), %ecx; 	cmpb	$0, 16(%esp); 	je	.LBB0_2; # %bb.1: # %bb; 	movl	8(%esp), %eax; 	addl	%ecx, %eax; 	ret; .LBB0_2: # %bb7; 	movl	12(%esp), %edx; 	movl	%ecx, %eax; 	subl	%edx, %eax; 	ret. There's an obviously unnecessary movl in .LBB0_2, and we could eliminate a; couple more movls by putting 4(%esp) into %eax instead of %ecx. //===---------------------------------------------------------------------===//. Take the following:. target datalayout = ""e-p:32:32:32-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:32:64-f32:32:32-f64:32:64-v64:64:64-v128:128:128-a0:0:64-f80:128:128-S128""; target triple = ""i386-apple-darwin8""; @in_exit.4870.b = internal global i1 false		; <i1*> [#uses=2]; define fastcc void @abort_gzip() noreturn nounwind {; entry:; 	%tmp.b.i = load i1* @in_exit.4870.b		; <i1> [#uses=1]; 	br i1 %tmp.b.i, label %bb.i, label %bb4.i; bb.i:		; preds = %entry; 	tail call void @exit( i32 1 ) noreturn nounwind ; 	unreachable; bb4.i:		; preds = %entry; 	store i1 true, i1* @in_exit.4870.b; 	tail call void @exit( i32 1 ) noreturn nounwind ; 	unreachable; }; declare void @exit(i32) noreturn nounwind . This compiles into:; _abort_gzip: ## @abort_gzip; ## %bb.0: ## %entry; 	subl	$12, %esp; 	movb	_in_exit.4870.b, %al; 	cmpb	$1, %al; 	jne	LBB0_2. We somehow miss folding the movb into the cmpb. //===---------------------------------------------------------------------===//. We compile:. int test(int x, int y) {; return x-y-1;; }. into (-m64):. _test:; 	decl	%edi; 	movl	%edi, %eax; 	subl	%esi, %eax; 	ret. it would be better to codegen as: x+~y (notl+addl). //===---------------------------------------------------------------------===//. This code:. int foo(const char *str,...); {; __builtin_va_list a; int x;; __builtin_va_start(a,str); x = __builtin_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:25861,load,load,25861,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['load']
Performance,"label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.01 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.01; }. The mem2reg pass implements the standard ""iterated dominance frontier""; algorithm for constructing SSA form and has a number of optimizations; that speed up (very common) degenerate cases. The mem2reg optimization; pass is the answer to dealing with mutable variables, and we highly; recommend that you depend on it. Note that mem2reg only works on; variables in certain circumstances:. #. mem2reg is alloca-driven: it looks for allocas and if it can handle; them, it promotes them. It does not apply to global variables or heap; allocations.; #. mem2reg only looks for alloca instructions in the entry block of the; function. Being in the entry block guarantees that the alloca is only; executed once, which makes analysis simpler.; #. mem2reg only promotes allocas whose uses are direct loads and stores.; If the address of the stack object is passed to a function, or if any; funny pointer arithmetic is involved, the alloca will not be; promoted.; #. mem2reg only works on allocas of `first; class <../../LangRef.html#first-class-types>`_ values (such as pointers,; scalars and vectors), and only if the array size of the allocation is; 1 (or missing in the .ll file). mem2reg is not capable of promoting; structs or arrays to registers. Note that the ""sroa"" pass is; more powerful and can promote structs, ""unions"", and arrays in many; cases. All of these properties are easy to satisfy for most imperative; languages, and we'll illustrate it below with Kaleidoscope. The final; question you may be asking is: should I bother with this nonsense for my; front-end? Wouldn't it be better if I just did SSA construction; directly, avoiding use of the mem2reg optimization pass? In short, we; strongly recommend that you use this technique for building SSA form,; unless",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:8156,load,loads,8156,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['loads']
Performance,"labels like: http://jsroot.gsi.de/dev/?nobrowser&file=../files/atlas.root&item=LEDShapeHeightCorr_Gain0;1&opt=col. ## Changes in 3.7; 1. Support of X axis with custom labels like: http://jsroot.gsi.de/dev/?nobrowser&json=../files/hist_xlabels.json; 2. Extend functionality of JSROOT.addDrawFunc() function. One could register type-specific; `make_request` and `after_request` functions; `icon`, `prereq`, `script`, `monitor` properties.; This let add more custom elements to the generic gui, implemented with JSROOT.HierarchyPainter; 3. Provide full support of require.js. One could load now JSRootCore.js script like:. <script type=""text/javascript"" src=""require.js"" data-main=""scripts/JSRootCore.js""></script>. After this several modules are defined and can be used with syntax like:. require(['JSRootPainter'], function(jsroot) { /*any user code*/});. Also inside JSROOT require.js used to load all dependencies. ## Changes in 3.6; 1. Try to provide workaround for websites where require.js already loaded.; This makes problem by direct loading of jquery and jquery-ui; 2. Provide workaround for older version of jquery-ui; 3. Prompt for input of command arguments; 4. After command execution one could automatically reload hierarchy (_hreload property) or; update view of displayed object (_update_item property); 5. Use HierarchyPainter for implementing draw.htm. This let us handle; all different kinds of extra attributes in central place; 6. Fix problem in tabs layout - new tab should be add to direct child; 7. When drawing several tabs, activate frame before drawing - only then; real frame size will be set; 8. Fix problem with GetBBox - it only can be used for visible elements in mozilla.; 9. Support drawing of fit parameters in stat box, use (as far as possible) stat and; fit format for statistic display; 10. Implement 'g' formatting kind for stat box output - one need to checks; significant digits when producing output.; 11. Support new draw options for TGraph: 'C', 'B1', '0', '",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:63919,load,loaded,63919,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['load'],['loaded']
Performance,"lable on Haswell and; Zen processors, there is an instruction for shifting that does not set any; flags: `shrx`. We can use this and the `lea` instruction to implement analogous; code sequences to the above ones. However, these are still very marginally; slower, as there are fewer ports able to dispatch shift instructions in most; modern x86 processors than there are for `or` instructions. Fast, single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; shrxq %rax, %rsi, %rsi # Shift away bits if misspeculating.; movl (%rsi), %edi; ```. This will collapse the register to zero or one, and everything but the offset; in the addressing mode to be less than or equal to 9. This means the full; address can only be guaranteed to be less than `(1 << 31) + 9`. The OS may wish; to protect an extra page of the low address space to account for this. ##### Optimizations. A very large portion of the cost for this approach comes from checking loads in; this way, so it is important to work to optimize this. However, beyond making; the instruction sequences to *apply* the checks efficient (for example by; avoiding `pushfq` and `popfq` sequences), the only significant optimization is; to check fewer loads without introducing a vulnerability. We apply several; techniques to accomplish that. ###### Don't check loads from compile-time constant stack offsets. We implement this optimization on x86 by skipping the checking of loads which; use a fixed frame pointer offset. The result of this optimization is that patterns like reloading a spilled; register or accessing a global field don't get checked. This is a very; significant performance win. ###### Don't check dependent loads. A core part of why this mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:34575,load,loads,34575,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,"['load', 'optimiz']","['loads', 'optimize']"
Performance,"languages, use one or more; ``--offload-arch=<target-id>`` Clang options to specify the target IDs of the; code to generate for the offload code regions. The tool chain may perform multiple compilations of a translation unit to; produce separate code objects for the host and potentially multiple offloaded; devices. The ``clang-offload-bundler`` tool may be used as part of the tool; chain to combine these multiple code objects into a single bundled code object. The tool chain may use a bundled code object as an intermediate step so that; each tool chain step consumes and produces a single file as in traditional; non-heterogeneous tool chains. The bundled code object contains the code objects; for the host and all the offload devices. A bundled code object may also be used to bundle just the offloaded code; objects, and embedded as data into the host code object. The host compilation; includes an ``init`` function that will use the runtime corresponding to the; offload kind (see :ref:`clang-offload-kind-table`) to load the offload code; objects appropriate to the devices present when the host program is executed. :program:`clang-offload-bundler` is located in; `clang/tools/clang-offload-bundler`. .. code-block:: console. $ clang-offload-bundler -help; OVERVIEW: A tool to bundle several input files of the specified type <type>; referring to the same source file but different targets into a single; one. The resulting file can also be unbundled into different files by; this tool if -unbundle is provided. USAGE: clang-offload-bundler [options]. OPTIONS:. Generic Options:. --help - Display available options (--help-hidden for more); --help-list - Display list of available options (--help-list-hidden for more); --version - Display the version of this program. clang-offload-bundler options:. --### - Print any external commands that are to be executed instead of actually executing them - for testing purposes.; --allow-missing-bundles - Create empty files if bundles are missing",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst:1221,load,load,1221,interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,1,['load'],['load']
Performance,"lar; shared variables. (`Java Specification; <http://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html>`_). * gcc-compatible ``__sync_*`` builtins. (`Description; <https://gcc.gnu.org/onlinedocs/gcc/_005f_005fsync-Builtins.html>`_). * Other scenarios with atomic semantics, including ``static`` variables with; non-trivial constructors in C++. Atomic and volatile in the IR are orthogonal; ""volatile"" is the C/C++ volatile,; which ensures that every volatile load and store happens and is performed in the; stated order. A couple examples: if a SequentiallyConsistent store is; immediately followed by another SequentiallyConsistent store to the same; address, the first store can be erased. This transformation is not allowed for a; pair of volatile stores. On the other hand, a non-volatile non-atomic load can; be moved across a volatile load freely, but not an Acquire load. This document is intended to provide a guide to anyone either writing a frontend; for LLVM or working on optimization passes for LLVM with a guide for how to deal; with instructions with special semantics in the presence of concurrency. This; is not intended to be a precise guide to the semantics; the details can get; extremely complicated and unreadable, and are not usually necessary. .. _Optimization outside atomic:. Optimization outside atomic; ===========================. The basic ``'load'`` and ``'store'`` allow a variety of optimizations, but can; lead to undefined results in a concurrent environment; see `NotAtomic`_. This; section specifically goes into the one optimizer restriction which applies in; concurrent environments, which gets a bit more of an extended description; because any optimization dealing with stores needs to be aware of it. From the optimizer's point of view, the rule is that if there are not any; instructions with atomic ordering involved, concurrency does not matter, with; one exception: if a variable might be visible to another thread or signal; handler, a store cannot b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:2086,optimiz,optimization,2086,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,"['concurren', 'optimiz']","['concurrency', 'optimization']"
Performance,"laration. It marks the declaration as a reference to an absolute symbol,; which causes the backend to use absolute relocations for the symbol even; in position independent code, and expresses the possible ranges that the; global variable's *address* (not its value) is in, in the same format as; ``range`` metadata, with the extension that the pair ``all-ones,all-ones``; may be used to represent the full set. Example (assuming 64-bit pointers):. .. code-block:: llvm. @a = external global i8, !absolute_symbol !0 ; Absolute symbol in range [0,256); @b = external global i8, !absolute_symbol !1 ; Absolute symbol in range [0,2^64). ...; !0 = !{ i64 0, i64 256 }; !1 = !{ i64 -1, i64 -1 }. '``callees``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^. ``callees`` metadata may be attached to indirect call sites. If ``callees``; metadata is attached to a call site, and any callee is not among the set of; functions provided by the metadata, the behavior is undefined. The intent of; this metadata is to facilitate optimizations such as indirect-call promotion.; For example, in the code below, the call instruction may only target the; ``add`` or ``sub`` functions:. .. code-block:: llvm. %result = call i64 %binop(i64 %x, i64 %y), !callees !0. ...; !0 = !{ptr @add, ptr @sub}. '``callback``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^. ``callback`` metadata may be attached to a function declaration, or definition.; (Call sites are excluded only due to the lack of a use case.) For ease of; exposition, we'll refer to the function annotated w/ metadata as a broker; function. The metadata describes how the arguments of a call to the broker are; in turn passed to the callback function specified by the metadata. Thus, the; ``callback`` metadata provides a partial description of a call site inside the; broker function with regards to the arguments of a call to the broker. The only; semantic restriction on the broker function itself is that it is not allowed to; inspect or modify arguments referenced in the ``callbac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:287418,optimiz,optimizations,287418,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"large blocks of data and large number of parameters. The other one is based on a calculation of the system of linear equations; using Stiefel-Hestens method [10]. It converges faster than the awmi; algorithm, however, it is not suitable to fit large number of parameters. ## 1-DIMENSIONAL SPECTRA. The quantity to be minimized in the fitting procedure for one-dimensional spectrum is defined as. $$ \chi^2 = \frac{1}{N-M}\sum_{i=1}^{N}\frac{[y_i-f(i,a)]^2}{y_i} $$. where `i` is the channel in the fitted spectrum, `N` is the number of; channels in the fitting subregion, `M` is the number of free parameters,; `y_i` is the content of the `i`-th channel, `a` is a vector of the; parameters being fitted and `f(i,a)` is a fitting or peak shape function. Instead of the weighting coefficient `y_i` in the denominator of the formula; given above, one can use also the value of `f(i,a)`. It is suitable for; data with poor statistics [11], [12]. The third statistic to be optimized, which is implemented in the fitting; functions, is the Maximum Likelihood Method. It is up to the user; to select a suitable statistic. After differentiating chi^2 we obtain the following `M` simultaneous; equations:. $$ \sum_{i=1}^{N}; \frac{y_i-f(i,a^{(t)})}{y_i}; \frac{\partial f(i,a^t)}{\partial a_k}=; \sum_{j=1}^{M}\sum_{i=1}^{N}; \frac{\partial f(i,a^{(t)})}{\partial a_j}; \frac{\partial f(i,a^{(t)})}{\partial a_k}; \Delta a_j^{(t)} $$. - in gamma-ray spectra we have to fit together tens, hundreds of peaks; simultaneously that sometimes represent thousands of parameters. - the calculation of the inversion matrix of such a size is; practically impossible. - the awmi method is based on the assumption that the off-diagonal; terms in the matrix A are equal to zero. $$; \Delta a_{k}^{(t+1)} = \alpha^{(t)}; \frac{; \sum_{i=1}^{N} \frac{e_{i}^{(t)}}{y_i}\frac{\partial f(i,a^{(t)})}{\partial a_k}; }{; \sum_{i=1}^{N} \left[ \frac{\partial f(i,a^{(t)})}{\partial a_k}\right]^2\frac{1}{y_i}; }; $$. where the erro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:38364,optimiz,optimized,38364,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['optimiz'],['optimized']
Performance,"lass, as it is a collection of static functions that can be applied to any combination of pdf and dataset.; This class does essentially the same as `constOptimizeTestStatistic` did on a `RooNLLVar`, except that it has been factored out into a separate class. ### Usage example: apply constant term optimization on pdf and dataset inside a likelihood; Applying the default `ConstantTermsOptimizer` optimization routines on the pdf and dataset inside a `RooAbsL` likelihood is as simple as:. ``` {.cpp}; likelihood.constOptimizeTestStatistic();; ```; This applies constant term optimization to the cloned pdf and dataset inside the likelihood object.; It will not modify anything outside of the likelihood. Optimization can also be activated through the minimizer, which may be more familiar to most users.; Given the `RooMinimizer` object `m` as defined in the example above, we can do:; ``` {.cpp}; m.optimizeConst(2);; ```. For the adventurous user, it is also possible to apply constant term optimization to a pdf and dataset directly without needing a likelihood object, e.g. given some `RooArgSet` set of observables `normSet`:; ``` {.cpp}; bool applyTrackingOpt = true;; ConstantTermsOptimizer::enableConstantTermsOptimization(&pdf, &normSet, dataset, applyTrackingOpt);; ```; We refer to RooFit documentation for more about ""tracking optimization"" which can be enabled or disabled using the final boolean parameter. ## Caveats; This package is still under development.; Some functionality that users of `RooAbsPdf::fitTo` or `RooAbsPdf::createNLL` were used to has not yet been ported to this namespace.; However, the functionality that is implemented has been tested thoroughly for a set of common usage patterns and should work as expected. The classes implemented here will give the exact same numerical results for most fits.; One notable exception is fitting _simultaneous_ pdfs with a _constrained_ term _when using offsetting_.; Because offsetting is handled differently in the `TestStat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md:11016,optimiz,optimization,11016,roofit/doc/developers/test_statistics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md,1,['optimiz'],['optimization']
Performance,"lasses; - supports different versions of class in the same file; - support members like ClassName* fField; //[fCnt]; - support const char*; - support fixed-size array of TString, TObject and TNamed; 2. Many new draw options for different classes are supported:; - TGraph - 'z', 'x', '||', '[]', '>', '|>', '5', 'X+', 'Y+'; - TH1 - '*', 'L', 'LF2', 'B', 'B1', 'TEXT', 'E0', 'E3', 'E4', 'EX0', 'X+', 'Y+'; - TH2 - 'E', 'col1', 'box', 'box1', 'surf3', 'surf7', 'base0'; - TH2 - 'same' with 'box', 'col', 'cont', 'lego', 'surf'; - TH3 - 'scat', use by default; - TF1/TF2 - 'nosave' to ignore saved buffer; - TCanvas - logx/y/z, gridx/y, tickx/y; - THStack - 'lego' and other 3D draw options; 3. Implement drawing of TProfile2D, TF2, TGraph2D, TGraph2DErrors and TMarker; 4. Fix - correctly place TGAxis relative to frame (when exists); 5. When superimpose items, one can specify individual options; ...&item=histo1+histo2&opt=hist+e1; ...&item=[histo1,histo2]&opt=[hist,e1]; 6. Support loading of TStyle object, providing in URL; ...&style=item_name or ...&style=json_file_name; All values are copied directly to JSROOT.gStyle object.; 7. Add callback argument into JSROOT.draw() function.; Function will be called after drawing of object is completed.; Painter for drawn object will be provided as first argument (or null in case of error).; 8. Improve cleanup of JSROOT objects. ## Changes in 4.7.1; 1. Workaround for MathJax output - scaling not always works in Firefox; 2. Fix - bin scaling for box draw option for TH2 and TH3 histograms; 3. Fix - increase points limits for contour plots; 4. Fix - position of 3D canvas in WebKit browsers; 5. Fix - use abs bin content in RMS calculations; 6. Fix - support char star* and object arrays in I/O; 7. Fix - correct decoding of TAxis time offset; 8. Fix - checksum reading for foreign classes. ## Changes in 4.7.0; 1. Implement simple TTree::Draw over single leaf (#80); Support basic types, fixed-size arrays and several vector types; 2. Display of TEve",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:50704,load,loading,50704,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['load'],['loading']
Performance,"lat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any precedin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216193,load,load,216193,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"late path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that theyll be fine). It is also used to provide a; contract to the back end saying either this load/store has this alignment, or; it is undefined behavior. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesnt make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:5774,load,loads,5774,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['load'],['loads']
Performance,"lates,; since they generally need to have a qualifier applied to the before being; used. .. _arc.method-families:. Method families; ===============. An Objective-C method may fall into a :arc-term:`method family`, which is a; conventional set of behaviors ascribed to it by the Cocoa conventions. A method is in a certain method family if:. * it has a ``objc_method_family`` attribute placing it in that family; or if; not that,; * it does not have an ``objc_method_family`` attribute placing it in a; different or no family, and; * its selector falls into the corresponding selector family, and; * its signature obeys the added restrictions of the method family. A selector is in a certain selector family if, ignoring any leading; underscores, the first component of the selector either consists entirely of; the name of the method family or it begins with that name followed by a; character other than a lowercase letter. For example, ``_perform:with:`` and; ``performWith:`` would fall into the ``perform`` family (if we recognized one),; but ``performing:with`` would not. The families and their added restrictions are:. * ``alloc`` methods must return a retainable object pointer type.; * ``copy`` methods must return a retainable object pointer type.; * ``mutableCopy`` methods must return a retainable object pointer type.; * ``new`` methods must return a retainable object pointer type.; * ``init`` methods must be instance methods and must return an Objective-C; pointer type. Additionally, a program is ill-formed if it declares or; contains a call to an ``init`` method whose return type is neither ``id`` nor; a pointer to a super-class or sub-class of the declaring class (if the method; was declared on a class) or the static receiver type of the call (if it was; declared on a protocol). .. admonition:: Rationale. There are a fair number of existing methods with ``init``-like selectors; which nonetheless don't follow the ``init`` conventions. Typically these; are either accidental ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:68029,perform,performWith,68029,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,3,['perform'],"['perform', 'performWith', 'performing']"
Performance,"laying the object; described by this buffer. If either does not meet this requirement the; object may not be displayed. #### Scene Rebuilds. `TBuffer3D::AddObject` is not an explicit command to the viewer - it may; for various reasons decide to ignore it:. - It already has the object internally cached. - The object falls outside some 'interest' limits of the viewer; camera. - The object is too small to be worth drawing. In all these cases `TBuffer3D::AddObject()` returns kNone, as it does; for successful addition, indicating it does not require further; information about this object. Hence you should not try to make any; assumptions about what the viewer did with the object. The viewer may; decide to force the client to rebuild (republish) the scene, obtaining a; different collection of objects, if the internal viewer state changes; .e.g. significant camera move. It does this presently by forcing a; repaint on the attached **`TPad`** object - hence you should attach you; master geometry object to the pad (via `TObject::Draw()`), and perform; the publishing to the viewer in response to **`TObject::Paint()`**. #### Physical IDs. TVirtualViewer3D provides for two methods of object addition:. ``` {.cpp}; virtual Int_t AddObject(const TBuffer3D &buffer,; Bool_t * addChildren = 0); virtual Int_t AddObject(UInt_t physicalID,; const TBuffer3D & buffer,; Bool_t *addChildren = 0); ```. If you use the first (simple) case a viewer using logical/physical pairs; will generate sequential IDs for each physical object internally. Scene; rebuilds will require destruction and recreation of all physical; objects. For the second you can specify an identifier from the client; side, which must be unique and stable - i.e. the IDs of a published; object is consistent, regardless of changes in termination of contained; child geometry branches. In this case the viewer can safely cache the; physical objects across scene rebuilds, discarding those no longer of; interest. #### Child Objects. In ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:137459,perform,perform,137459,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['perform'],['perform']
Performance,"lculation of such a constant initializer will; not overflow at link time under the medium code model if ``x`` is an; ``unnamed_addr`` function. However, it does not provide this guarantee for; a constant initializer folded into a function body. This intrinsic can be; used to avoid the possibility of overflows when loading from such a constant. .. _llvm_sideeffect:. '``llvm.sideeffect``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.sideeffect() inaccessiblememonly nounwind willreturn. Overview:; """""""""""""""""". The ``llvm.sideeffect`` intrinsic doesn't perform any operation. Optimizers; treat it as having side effects, so it can be inserted into a loop to; indicate that the loop shouldn't be assumed to terminate (which could; potentially lead to the loop being optimized away entirely), even if it's; an infinite loop with no other side effects. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". This intrinsic actually does nothing, but optimizers must assume that it; has externally observable side effects. '``llvm.is.constant.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use llvm.is.constant with any argument type. ::. declare i1 @llvm.is.constant.i32(i32 %operand) nounwind memory(none); declare i1 @llvm.is.constant.f32(float %operand) nounwind memory(none); declare i1 @llvm.is.constant.TYPENAME(TYPE %operand) nounwind memory(none). Overview:; """""""""""""""""". The '``llvm.is.constant``' intrinsic will return true if the argument; is known to be a manifest compile-time constant. It is guaranteed to; fold to either true or false before generating machine code. Semantics:; """""""""""""""""""". This intrinsic generates no code. If its argument is known to be a; manifest compile-time constant value, then the intrinsic will be; converted to a constant true value. Otherwise, it will be converted to; a constant false value. In particular, note that if the argument is a constant expression;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:952293,optimiz,optimizers,952293,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizers']
Performance,"ld a relocatable precompiled header, place your headers into a; subdirectory whose structure mimics the installed location. For example,; if you want to build a precompiled header for the header ``mylib.h``; that will be installed into ``/usr/include``, create a subdirectory; ``build/usr/include`` and place the header ``mylib.h`` into that; subdirectory. If ``mylib.h`` depends on other headers, then they can be; stored within ``build/usr/include`` in a way that mimics the installed; location. Building a relocatable precompiled header requires two additional; arguments. First, pass the ``--relocatable-pch`` flag to indicate that; the resulting PCH file should be relocatable. Second, pass; ``-isysroot /path/to/build``, which makes all includes for your library; relative to the build directory. For example:. .. code-block:: console. # clang -x c-header --relocatable-pch -isysroot /path/to/build /path/to/build/mylib.h mylib.h.pch. When loading the relocatable PCH file, the various headers used in the; PCH file are found from the system header root. For example, ``mylib.h``; can be found in ``/usr/include/mylib.h``. If the headers are installed; in some other system root, the ``-isysroot`` option can be used provide; a different system root from which the headers will be based. For; example, ``-isysroot /Developer/SDKs/MacOSX10.4u.sdk`` will look for; ``mylib.h`` in ``/Developer/SDKs/MacOSX10.4u.sdk/usr/include/mylib.h``. Relocatable precompiled headers are intended to be used in a limited; number of cases where the compilation environment is tightly controlled; and the precompiled header cannot be generated after headers have been; installed. .. _controlling-fp-behavior:. Controlling Floating Point Behavior; -----------------------------------. Clang provides a number of ways to control floating point behavior, including; with command line options and source pragmas. This section; describes the various floating point semantic modes and the corresponding options. .. csv-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:49260,load,loading,49260,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['load'],['loading']
Performance,"ld be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested values must; be loaded. Direct locations can communicate the address if an alloca,; while Indirect locations handle register spills. For example:. .. code-block:: none. entry:; %a = alloca i64...; llvm.experimental.stackmap(i64 <ID>, i32 <shadowBytes>, ptr %a). The runtime can determine this alloca's relative location on the; stack immediately after compilation, or at any time thereafter. This; differs from Register and Indirect locations, because the runtime can; only read the values in those locations when execution reaches the; instruction address of the stack map. This functionality requir",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:19119,optimiz,optimizations,19119,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,2,"['load', 'optimiz']","['loads', 'optimizations']"
Performance,"ld be released during the C++; call to allow multi-threading.; The default is ``False``. * ``__useffi__``: a flag that every C++ overload carries and determines; whether generated wrappers or direct foreign functions should be used.; This is for PyPy only; the flag has no effect on CPython. * ``__sig2exc__``: a flag that every C++ overload carries and determines; whether C++ signals (such as SIGABRT) should be converted into Python; exceptions. * ``__cpp_name__``: a string that every C++ bound class carries and contains; the actual C++ name (as opposed to ``__name__`` which has the Python name).; This can be useful for template instantiations, documentation, etc. * ``__cpp_template__``: a back-reference to the template used to instantiate; a templated class.; This variable only exists if the class was dynamically instantiated from; Python at least once. `STL algorithms`; ----------------. It is usually easier to use a Python equivalent or code up the effect of an; STL algorithm directly, but when operating on a large container, calling an; STL algorithm may offer better performance.; It is important to note that all STL algorithms are templates and need the; correct types to be properly instantiated.; STL containers offer typedefs to obtain those exact types and these should; be used rather than relying on the usual implicit conversions of Python types; to C++ ones.; For example, as there is no ``char`` type in Python, the ``std::remove`` call; below can not be instantiated using a Python string, but the; ``std::string::value_type`` must be used instead:. .. code-block:: python. >>> cppstr = cppyy.gbl.std.string; >>> n = cppstr('this is a C++ string'); >>> print(n); this is a C++ string; >>> n.erase(cppyy.gbl.std.remove(n.begin(), n.end(), cppstr.value_type(' '))); <cppyy.gbl.__wrap_iter<char*> object at 0x7fba35d1af50>; >>> print(n); thisisaC++stringing; >>>. `Reduced typing`; ----------------. Note: ``from cppyy.interactive import *`` is no longer supported for CP",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:3137,perform,performance,3137,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,1,['perform'],['performance']
Performance,"ld combine to x & -9. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(unsigned a) {return a * 0x11111111 >> 28 & 1;}; Should combine to ""a * 0x88888888 >> 31"". Currently not optimized; with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(char* x) {if ((*x & 32) == 0) return b();}; There's an unnecessary zext in the generated code with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(unsigned long long x) {return 40 * (x >> 1);}; Should combine to ""20 * (((unsigned)x) & -2)"". Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int g(int x) { return (x - 10) < 0; }; Should combine to ""x <= 9"" (the sub has nsw). Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int g(int x) { return (x + 10) < 0; }; Should combine to ""x < -10"" (the add has nsw). Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int f(int i, int j) { return i < j + 1; }; int g(int i, int j) { return j > i - 1; }; Should combine to ""i <= j"" (the add/sub has nsw). Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned f(unsigned x) { return ((x & 7) + 1) & 15; }; The & 15 part should be optimized away, it doesn't change the result. Currently; not optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. This was noticed in the entryblock for grokdeclarator in 403.gcc:. %tmp = icmp eq i32 %decl_context, 4 ; %de",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:26756,optimiz,optimized,26756,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['optimiz'],['optimized']
Performance,"ld its data, and; it calls back to general heap allocation when required. Since it owns its data,; it is very safe to use and supports full mutation of the string. Like SmallVector's, the big downside to SmallString is their sizeof. While they; are optimized for small strings, they themselves are not particularly small.; This means that they work great for temporary scratch buffers on the stack, but; should not generally be put into the heap: it is very rare to see a SmallString; as the member of a frequently-allocated heap data structure or returned; by-value. .. _dss_stdstring:. std::string; ^^^^^^^^^^^. The standard C++ std::string class is a very general class that (like; SmallString) owns its underlying data. sizeof(std::string) is very reasonable; so it can be embedded into heap data structures and returned by-value. On the; other hand, std::string is highly inefficient for inline editing (e.g.; concatenating a bunch of stuff together) and because it is provided by the; standard library, its performance characteristics depend a lot of the host; standard library (e.g. libc++ and MSVC provide a highly optimized string class,; GCC contains a really slow implementation). The major disadvantage of std::string is that almost every operation that makes; them larger can allocate memory, which is slow. As such, it is better to use; SmallVector or Twine as a scratch buffer, but then use std::string to persist; the result. .. _ds_set:. Set-Like Containers (std::set, SmallSet, SetVector, etc); --------------------------------------------------------. Set-like containers are useful when you need to canonicalize multiple values; into a single representation. There are several different choices for how to do; this, providing various trade-offs. .. _dss_sortedvectorset:. A sorted 'vector'; ^^^^^^^^^^^^^^^^^. If you intend to insert a lot of elements, then do a lot of queries, a great; approach is to use an std::vector (or other sequential container) with; std::sort+std::uniqu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:76269,perform,performance,76269,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['performance']
Performance,"ld only; be used in situations where the 'strip' utility would be used, such as reducing; code size or making it harder to reverse engineer code. ``tailcallelim``: Tail Call Elimination; ---------------------------------------. This file transforms calls of the current function (self recursion) followed by; a return instruction with a branch to the entry of the function, creating a; loop. This pass also implements the following extensions to the basic; algorithm:. #. Trivial instructions between the call and return do not prevent the; transformation from taking place, though currently the analysis cannot; support moving any really useful instructions (only dead ones).; #. This pass transforms functions that are prevented from being tail recursive; by an associative expression to use an accumulator variable, thus compiling; the typical naive factorial or fib implementation into efficient code.; #. TRE is performed if the function returns void, if the return returns the; result returned by the call, or if the function returns a run-time constant; on all exits from the function. It is possible, though unlikely, that the; return returns something else (like constant 0), and can still be TRE'd. It; can be TRE'd if *all other* return instructions in the function return the; exact same value.; #. If it can prove that callees do not access their caller stack frame, they; are marked as eligible for tail call elimination (by the code generator). Utility Passes; ==============. This section describes the LLVM Utility Passes. ``deadarghaX0r``: Dead Argument Hacking (BUGPOINT USE ONLY; DO NOT USE); -----------------------------------------------------------------------. Same as dead argument elimination, but deletes arguments to functions which are; external. This is only for use by :doc:`bugpoint <Bugpoint>`. ``extract-blocks``: Extract Basic Blocks From Module (for bugpoint use); -----------------------------------------------------------------------. This pass is used by bugpo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:39386,perform,performed,39386,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['perform'],['performed']
Performance,"le L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unorde",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:252228,load,load,252228,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"le conditional jump instructions; that use the same flags but handle different conditions. Naively, we could; consider each fallthrough between them an ""edge"" but this causes a much more; complex control flow graph. Instead, we accumulate the set of conditions; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22413,load,loads,22413,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance,"le gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:2650,perform,performance-portable,2650,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,1,['perform'],['performance-portable']
Performance,"le pass clean up dead defs for such calls, as it does; for stores. //===---------------------------------------------------------------------===//. Consider implementing optimizeSelect, optimizeCompareInstr, optimizeCondBranch,; optimizeLoadInstr, and/or getMachineCombinerPatterns. //===---------------------------------------------------------------------===//. Find a clean way to fix the problem which leads to the Shrink Wrapping pass; being run after the WebAssembly PEI pass. //===---------------------------------------------------------------------===//. When setting multiple local variables to the same constant, we currently get; code like this:. i32.const $4=, 0; i32.const $3=, 0. It could be done with a smaller encoding like this:. i32.const $push5=, 0; local.tee $push6=, $4=, $pop5; local.copy $3=, $pop6. //===---------------------------------------------------------------------===//. WebAssembly registers are implicitly initialized to zero. Explicit zeroing is; therefore often redundant and could be optimized away. //===---------------------------------------------------------------------===//. Small indices may use smaller encodings than large indices.; WebAssemblyRegColoring and/or WebAssemblyRegRenumbering should sort registers; according to their usage frequency to maximize the usage of smaller encodings. //===---------------------------------------------------------------------===//. Many cases of irreducible control flow could be transformed more optimally; than via the transform in WebAssemblyFixIrreducibleControlFlow.cpp. It may also be worthwhile to do transforms before register coloring,; particularly when duplicating code, to allow register coloring to be aware of; the duplication. //===---------------------------------------------------------------------===//. WebAssemblyRegStackify could use AliasAnalysis to reorder loads and stores more; aggressively. //===---------------------------------------------------------------------===//. WebAssemblyRe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt:4338,optimiz,optimized,4338,interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/WebAssembly/README.txt,2,['optimiz'],['optimized']
Performance,"le throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; Now TMonaLisaWriter keeps internally track of every; activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; Additionally, it's now finalized the infrastructure able to; measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; Now, the hook for the Close() func triggers sending of a; packet containing various information about the performance related to; that file only.; Added support also for performance monitoring when writing. RGLITE: A ROOT GRID interface. RGLite plug-in - a ROOT plug-in module, which implements the ROOT Grid; interface and offers to ROOT users possibilities to perform a number of; operations using gLite middleware from within ROOT. Supported features:. Workload Management System operations:; ; job submission  normal, DAG and parametric; jobs (gLite; WMProxy API), ; smart look-up algorithm for WMP-Endpoints, ; job status querying (gLite LB API), ; job output retrieving (Globus GridFTP). . File Catalog operations (gLite/LCG LFC API):; ; smart session manager, ; set/query the current working catalog directory, ; list files, directories and their stats, ; add/remove files in a catalog namespace, ; add/remove directories, ; add/remove replicas from a given file. . An executive logging. ; Support of an external XML configuration file with; according XML; schema. . Usage examples:. Job operations. // loading RGLite plug-in. TGrid::Connect(""glite"");; // submitting Grid job. TGridJob *job = gGrid->Submit(""JDLs/simple.jdl"");; // getting status object. TGridJobStatus *status = job->GetJobStatus();; // getting status of the jo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html:3189,perform,perform,3189,net/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html,2,['perform'],['perform']
Performance,"le to ( -O3 -static -fomit-frame-pointer):; _x:; movzwl 4(%esp), %eax; movd %eax, %xmm0; movaps _a, %xmm1; pslld %xmm0, %xmm1; movaps %xmm1, _a; ret; _y:; movd 4(%esp), %xmm0; movaps _a, %xmm1; pslld %xmm0, %xmm1; movaps %xmm1, _a; ret. ""y"" looks good, but ""x"" does silly movzwl stuff around into a GPR. It seems; like movd would be sufficient in both cases as the value is already zero ; extended in the 32-bit stack slot IIRC. For signed short, it should also be; save, as a really-signed value would be undefined for pslld. //===---------------------------------------------------------------------===//. #include <math.h>; int t1(double d) { return signbit(d); }. This currently compiles to:; 	subl	$12, %esp; 	movsd	16(%esp), %xmm0; 	movsd	%xmm0, (%esp); 	movl	4(%esp), %eax; 	shrl	$31, %eax; 	addl	$12, %esp; 	ret. We should use movmskp{s|d} instead. //===---------------------------------------------------------------------===//. CodeGen/X86/vec_align.ll tests whether we can turn 4 scalar loads into a single; (aligned) vector load. This functionality has a couple of problems. 1. The code to infer alignment from loads of globals is in the X86 backend,; not the dag combiner. This is because dagcombine2 needs to be able to see; through the X86ISD::Wrapper node, which DAGCombine can't really do.; 2. The code for turning 4 x load into a single vector load is target ; independent and should be moved to the dag combiner.; 3. The code for turning 4 x load into a vector load can only handle a direct ; load from a global or a direct load from the stack. It should be generalized; to handle any load from P, P+4, P+8, P+12, where P can be anything.; 4. The alignment inference code cannot handle loads from globals in non-static; mode because it doesn't look through the extra dyld stub load. If you try; vec_align.ll without -relocation-model=static, you'll see what I mean. //===---------------------------------------------------------------------===//. We should lower store(fneg(load p),",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:11443,load,loads,11443,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,4,['load'],"['load', 'loads']"
Performance,"le to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a working pass,; you would go ahead and make it do the cool transformations you want. Once you; get it all working and tested, it may become useful to find out how fast your; pass is. The :ref:`PassManager <writing-an-llvm-pass-passmanager>` provides a; nice command line option (:option:`-time-passes`) that allows you to get; information about the execution time of your pass along with the other passes; you queue up. For example:. .. code",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:8904,load,load,8904,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['load'],['load']
Performance,"le vector,; ``idx`` is first scaled by the result type's runtime scaling factor. Elements; ``idx`` through (``idx`` + num_elements(result_type) - 1) must be valid vector; indices. If this condition cannot be determined statically but is false at; runtime, then the result vector is a :ref:`poison value <poisonvalues>`. The; ``idx`` parameter must be a vector index constant type (for most targets this; will be an integer pointer type). '``llvm.experimental.vector.reverse``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <2 x i8> @llvm.experimental.vector.reverse.v2i8(<2 x i8> %a); declare <vscale x 4 x i32> @llvm.experimental.vector.reverse.nxv4i32(<vscale x 4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.experimental.vector.reverse.*``' intrinsics reverse a vector.; The intrinsic takes a single vector and returns a vector of matching type but; with the original lane order reversed. These intrinsics work for both fixed; and scalable vectors. While this intrinsic is marked as experimental the; recommended way to express reverse operations for fixed-width vectors is still; to use a shufflevector, as that may allow for more optimization opportunities. Arguments:; """""""""""""""""""". The argument to this intrinsic must be a vector. '``llvm.experimental.vector.deinterleave2``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare {<2 x double>, <2 x double>} @llvm.experimental.vector.deinterleave2.v4f64(<4 x double> %vec1); declare {<vscale x 4 x i32>, <vscale x 4 x i32>} @llvm.experimental.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> %vec1). Overview:; """""""""""""""""". The '``llvm.experimental.vector.deinterleave2``' intrinsic constructs two; vectors by deinterleaving the even and odd lanes of the input vector. This intrinsic works for both fixed and scalable vectors. While this intrinsic; supports all vector types the recom",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:666500,scalab,scalable,666500,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance,"le. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ==========================; **Release** For Speed No No Users of LLVM and Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; =========================== ============= ========== ========== ==========================. * Optimizations make LLVM/Clang run faster, but can be an impediment for; step-by-step debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:7014,optimiz,optimization,7014,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['optimiz'],['optimization']
Performance,"le. (Equivalent to ``-fmodule-map-file=<resource dir>/include/module.modulemap``). ``-fimplicit-module-maps``; Enable implicit search for module map files named ``module.modulemap`` and similar. This option is implied by ``-fmodules``. If this is disabled with ``-fno-implicit-module-maps``, module map files will only be loaded if they are explicitly specified via ``-fmodule-map-file`` or transitively used by another module map file. ``-fmodules-cache-path=<directory>``; Specify the path to the modules cache. If not provided, Clang will select a system-appropriate default. ``-fno-autolink``; Disable automatic linking against the libraries associated with imported modules. ``-fmodules-ignore-macro=macroname``; Instruct modules to ignore the named macro when selecting an appropriate module variant. Use this for macros defined on the command line that don't affect how modules are built, to improve sharing of compiled module files. ``-fmodules-prune-interval=seconds``; Specify the minimum delay (in seconds) between attempts to prune the module cache. Module cache pruning attempts to clear out old, unused module files so that the module cache itself does not grow without bound. The default delay is large (604,800 seconds, or 7 days) because this is an expensive operation. Set this value to 0 to turn off pruning. ``-fmodules-prune-after=seconds``; Specify the minimum time (in seconds) for which a file in the module cache must be unused (according to access time) before module pruning will remove it. The default delay is large (2,678,400 seconds, or 31 days) to avoid excessive module rebuilding. ``-module-file-info <module file name>``; Debugging aid that prints information about a given module file (with a ``.pcm`` extension), including the language and preprocessor options that particular module variant was built with. ``-fmodules-decluse``; Enable checking of module ``use`` declarations. ``-fmodule-name=module-id``; Consider a source file as a part of the given module. ``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:15537,cache,cache,15537,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['cache'],['cache']
Performance,"le. But it may produce surprising results if the; debugging code depends on consistent use of ``NDEBUG`` also in other translation units. Definitions consistency; ^^^^^^^^^^^^^^^^^^^^^^^. The C++ language defines that same declarations in different translation units should have; the same definition, as known as ODR (One Definition Rule). Prior to modules, the translation; units don't dependent on each other and the compiler itself can't perform a strong; ODR violation check. With the introduction of modules, now the compiler have; the chance to perform ODR violations with language semantics across translation units. However, in the practice, we found the existing ODR checking mechanism is not stable; enough. Many people suffers from the false positive ODR violation diagnostics, AKA,; the compiler are complaining two identical declarations have different definitions; incorrectly. Also the true positive ODR violations are rarely reported.; Also we learned that MSVC don't perform ODR check for declarations in the global module; fragment. So in order to get better user experience, save the time checking ODR and keep consistent; behavior with MSVC, we disabled the ODR check for the declarations in the global module; fragment by default. Users who want more strict check can still use the; ``-Xclang -fno-skip-odr-check-in-gmf`` flag to get the ODR check enabled. It is also; encouraged to report issues if users find false positive ODR violations or false negative ODR; violations with the flag enabled. ABI Impacts; -----------. The declarations in a module unit which are not in the global module fragment have new linkage names. For example,. .. code-block:: c++. export module M;; namespace NS {; export int foo();; }. The linkage name of ``NS::foo()`` would be ``_ZN2NSW1M3fooEv``.; This couldn't be demangled by previous versions of the debugger or demangler.; As of LLVM 15.x, users can utilize ``llvm-cxxfilt`` to demangle this:. .. code-block:: console. $ llvm-cxxfilt _ZN2NSW",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:17773,perform,perform,17773,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,1,['perform'],['perform']
Performance,"le. Intended for debugging purposes only. ``!setdagarg(``\ *dag*\ ``,``\ *key*\ ``,``\ *arg*\ ``)``; This operator produces a DAG node with the same operator and arguments as; *dag*, but replacing the value of the argument specified by the *key* with; *arg*. That *key* could be either an integer index or a string name. ``!setdagname(``\ *dag*\ ``,``\ *key*\ ``,``\ *name*\ ``)``; This operator produces a DAG node with the same operator and arguments as; *dag*, but replacing the name of the argument specified by the *key* with; *name*. That *key* could be either an integer index or a string name. ``!setdagop(``\ *dag*\ ``,`` *op*\ ``)``; This operator produces a DAG node with the same arguments as *dag*, but with its; operator replaced with *op*. Example: ``!setdagop((foo 1, 2), bar)`` results in ``(bar 1, 2)``. ``!shl(``\ *a*\ ``,`` *count*\ ``)``; This operator shifts *a* left logically by *count* bits and produces the resulting; value. The operation is performed on a 64-bit integer; the result; is undefined for shift counts outside 0...63. ``!size(``\ *a*\ ``)``; This operator produces the size of the string, list, or dag *a*.; The size of a DAG is the number of arguments; the operator does not count. ``!sra(``\ *a*\ ``,`` *count*\ ``)``; This operator shifts *a* right arithmetically by *count* bits and produces the resulting; value. The operation is performed on a 64-bit integer; the result; is undefined for shift counts outside 0...63. ``!srl(``\ *a*\ ``,`` *count*\ ``)``; This operator shifts *a* right logically by *count* bits and produces the resulting; value. The operation is performed on a 64-bit integer; the result; is undefined for shift counts outside 0...63. ``!strconcat(``\ *str1*\ ``,`` *str2*\ ``, ...)``; This operator concatenates the string arguments *str1*, *str2*, etc., and; produces the resulting string. ``!sub(``\ *a*\ ``,`` *b*\ ``)``; This operator subtracts *b* from *a* and produces the arithmetic difference. ``!subst(``\ *target*\ ``,`` *repl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:71443,perform,performed,71443,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['performed']
Performance,"le:. If JITDylib ``JD`` contains definitions for symbols ``foo_body`` and; ``bar_body``, we can create lazy entry points ``Foo`` and ``Bar`` in JITDylib; ``JD2`` by calling:. .. code-block:: c++. auto ReexportFlags = JITSymbolFlags::Exported | JITSymbolFlags::Callable;; JD2.define(; lazyReexports(CallThroughMgr, StubsMgr, JD,; SymbolAliasMap({; { Mangle(""foo""), { Mangle(""foo_body""), ReexportedFlags } },; { Mangle(""bar""), { Mangle(""bar_body""), ReexportedFlags } }; }));. A full example of how to use lazyReexports with the LLJIT class can be found at; ``llvm/examples/OrcV2Examples/LLJITWithLazyReexports``. Supporting Custom Compilers; ===========================. TBD. .. _transitioning_orcv1_to_orcv2:. Transitioning from ORCv1 to ORCv2; =================================. Since LLVM 7.0, new ORC development work has focused on adding support for; concurrent JIT compilation. The new APIs (including new layer interfaces and; implementations, and new utilities) that support concurrency are collectively; referred to as ORCv2, and the original, non-concurrent layers and utilities; are now referred to as ORCv1. The majority of the ORCv1 layers and utilities were renamed with a 'Legacy'; prefix in LLVM 8.0, and have deprecation warnings attached in LLVM 9.0. In LLVM; 12.0 ORCv1 will be removed entirely. Transitioning from ORCv1 to ORCv2 should be easy for most clients. Most of the; ORCv1 layers and utilities have ORCv2 counterparts [2]_ that can be directly; substituted. However there are some design differences between ORCv1 and ORCv2; to be aware of:. 1. ORCv2 fully adopts the JIT-as-linker model that began with MCJIT. Modules; (and other program representations, e.g. Object Files) are no longer added; directly to JIT classes or layers. Instead, they are added to ``JITDylib``; instances *by* layers. The ``JITDylib`` determines *where* the definitions; reside, the layers determine *how* the definitions will be compiled.; Linkage relationships between ``JITDylibs`` determine h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:19367,concurren,concurrency,19367,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,2,['concurren'],"['concurrency', 'concurrent']"
Performance,"le:. volatile store i32 -1, i32* inttoptr (i32 1342210076 to i32*), align 4,; !tbaa; !0; volatile store i32 -1, i32* inttoptr (i32 1342341148 to i32*), align 4,; !tbaa; !0. is compiled and optimized to:. movw r0, #32796; mov.w r1, #-1; movt r0, #20480; str r1, [r0]; movw r0, #32796 @ <= this MOVW is not needed, value is there already; movt r0, #20482; str r1, [r0]. //===---------------------------------------------------------------------===//. Improve codegen for select's:; if (x != 0) x = 1; if (x == 1) x = 1. ARM codegen used to look like this:; mov r1, r0; cmp r1, #1; mov r0, #0; moveq r0, #1. The naive lowering select between two different values. It should recognize the; test is equality test so it's more a conditional move rather than a select:; cmp r0, #1; movne r0, #0. Currently this is a ARM specific dag combine. We probably should make it into a; target-neutral one. //===---------------------------------------------------------------------===//. Optimize unnecessary checks for zero with __builtin_clz/ctz. Those builtins; are specified to be undefined at zero, so portable code must check for zero; and handle it as a special case. That is unnecessary on ARM where those; operations are implemented in a way that is well-defined for zero. For; example:. int f(int x) { return x ? __builtin_clz(x) : sizeof(int)*8; }. should just be implemented with a CLZ instruction. Since there are other; targets, e.g., PPC, that share this behavior, it would be best to implement; this in a target-independent way: we should probably fold that (when using; ""undefined at zero"" semantics) to set the ""defined at zero"" bit and have; the code generator expand out the right code. //===---------------------------------------------------------------------===//. Clean up the test/MC/ARM files to have more robust register choices. R0 should not be used as a register operand in the assembler tests as it's then; not possible to distinguish between a correct encoding and a missing operand; en",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:20692,Optimiz,Optimize,20692,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['Optimiz'],['Optimize']
Performance,"learning methods added in TMVA and based on the Python Scikit-Learn package. ## RooFit Libraries; . ## 2D Graphics Libraries. ### THistPainter. Improve the algorithm to compute the lower limit of an axis in log scale when its; real lower limit is 0. The problem was reported in ROOT-7414. Using the `COL` option with histograms having some negative bins; the empty bins; (containing 0) are drawn. In some cases one wants to not draw empty bins; (containing 0) of histograms having a negative minimum. The option `1`, used with; the option `COL`, allows to do that. Implement the Log option for `CANDLE` plots as requested; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20225&p=87006#p87006). ### TTeXDump. From Dmitry Kalinkin (via github): Fix file corruption in `TTeXDump::DrawPolyMarker`; The current implementation of `TTeXDump` uses `TVirtualPS::PrintFast` based methods; to output TeX markup with automatic line-wraps. Yet these methods are optimized for; PostScript format where there are a lot of space characters that are used for newline; placement. Current `TTeXDump::DrawPolyMarker` would often produce a long contiguous lines; that trigger a forceful linewrap that can happen in the middle of real number constant; (ignored by latex) or even in the middle of latex command (producing incorrect file).; One solution would be to rewrite TTeXDump using only `PrintRaw` (that you can't mix; with `PrintStr/PrintFast/WriteReal`). The other would be to fix `PrintFast` to not; introduce forced newline. The third option is less intrusive and just adds additional; spaces to provide clues for the proper line wrapping (this is the one implemented in; this change). ### TLatex. Make sure the line width used to draw `#sqrt` is always >= 1. When a global text alignment was set the `TLatex`characters `#minus`, `#plus`,; `#mp`, `#hbar`, and `#backslash` were mis-aligned. The following macro demonstrate; the problem:. ``` {.cpp}; {; gStyle->SetTextAlign(22);; TLatex t(.5,.5,""#minus100 #",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:15339,optimiz,optimized,15339,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['optimiz'],['optimized']
Performance,"leased after they've been used. A computation history depends on a pointer value ``P`` if it:. * performs a pointer comparison with ``P``,; * loads from ``P``,; * stores to ``P``,; * depends on a pointer value ``Q`` derived via pointer arithmetic; from ``P`` (including an instance-variable or field access), or; * depends on a pointer value ``Q`` loaded from ``P``. Dependency applies only to values derived directly or indirectly from; a particular expression result and does not occur merely because a; separate pointer value dynamically aliases ``P``. Furthermore, this; dependency is not carried by values that are stored to objects. .. admonition:: Rationale. The restrictions on dependency are intended to make this analysis; feasible by an optimizer with only incomplete information about a; program. Essentially, dependence is carried to ""obvious"" uses of a; pointer. Merely passing a pointer argument to a function does not; itself cause dependence, but since generally the optimizer will not; be able to prove that the function doesn't depend on that parameter,; it will be forced to conservatively assume it does. Dependency propagates to values loaded from a pointer because those; values might be invalidated by deallocating the object. For; example, given the code ``__strong id x = p->ivar;``, ARC must not; move the release of ``p`` to between the load of ``p->ivar`` and the; retain of that value for storing into ``x``. Dependency does not propagate through stores of dependent pointer; values because doing so would allow dependency to outlive the; full-expression which produced the original value. For example, the; address of an instance variable could be written to some global; location and then freely accessed during the lifetime of the local,; or a function could return an inner pointer of an object and store; it to a local. These cases would be potentially impossible to; reason about and so would basically prevent any optimizations based; on imprecise lifetime. There ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:80762,optimiz,optimizer,80762,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizer']
Performance,"lect <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_rint:. '``llvm.vp.rint.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.rint.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.rint.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.rint.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point rint of a vector of floating-point values. Arguments:; """""""""""""""""""". The first operand and the result have the same vector of floating-point type.; The second operand is the vector mask and has the same number of elements as the; result vector type. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.rint``' intrinsic performs floating-point rint; (:ref:`rint <int_rint>`) of the first vector operand on each enabled lane.; The result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.rint.v4f32(<4 x float> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.rint.v4f32(<4 x float> %a); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_nearbyint:. '``llvm.vp.nearbyint.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.nearbyint.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.nearbyint.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.nearbyint.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:824999,perform,performs,824999,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"lector, this functionality is restricted to generating machine code; which can interoperate with a collector provided externally. .. _prefixdata:. Prefix Data; -----------. Prefix data is data associated with a function which the code; generator will emit immediately before the function's entrypoint.; The purpose of this feature is to allow frontends to associate; language-specific runtime metadata with specific functions and make it; available through the function pointer while still allowing the; function pointer to be called. To access the data for a given function, a program may bitcast the; function pointer to a pointer to the constant's type and dereference; index -1. This implies that the IR symbol points just past the end of; the prefix data. For instance, take the example of a function annotated; with a single ``i32``,. .. code-block:: llvm. define void @f() prefix i32 123 { ... }. The prefix data can be referenced as,. .. code-block:: llvm. %a = getelementptr inbounds i32, ptr @f, i32 -1; %b = load i32, ptr %a. Prefix data is laid out as if it were an initializer for a global variable; of the prefix data's type. The function will be placed such that the; beginning of the prefix data is aligned. This means that if the size; of the prefix data is not a multiple of the alignment size, the; function's entrypoint will not be aligned. If alignment of the; function's entrypoint is desired, padding must be added to the prefix; data. A function may have prefix data but no body. This has similar semantics; to the ``available_externally`` linkage in that the data may be used by the; optimizers but will not be emitted in the object file. .. _prologuedata:. Prologue Data; -------------. The ``prologue`` attribute allows arbitrary code (encoded as bytes) to; be inserted prior to the function body. This can be used for enabling; function hot-patching and instrumentation. To maintain the semantics of ordinary function calls, the prologue data must; have a particular forma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:73290,load,load,73290,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"lee-save stack frame offset. * ``getReservedRegs`` --- Returns a bitset indexed by physical register; numbers, indicating if a particular register is unavailable. * ``hasFP`` --- Return a Boolean indicating if a function should have a; dedicated frame pointer register. * ``eliminateCallFramePseudoInstr`` --- If call frame setup or destroy pseudo; instructions are used, this can be called to eliminate them. * ``eliminateFrameIndex`` --- Eliminate abstract frame indices from; instructions that may use them. * ``emitPrologue`` --- Insert prologue code into the function. * ``emitEpilogue`` --- Insert epilogue code into the function. .. _instruction-set:. Instruction Set; ===============. During the early stages of code generation, the LLVM IR code is converted to a; ``SelectionDAG`` with nodes that are instances of the ``SDNode`` class; containing target instructions. An ``SDNode`` has an opcode, operands, type; requirements, and operation properties. For example, is an operation; commutative, does an operation load from memory. The various operation node; types are described in the ``include/llvm/CodeGen/SelectionDAGNodes.h`` file; (values of the ``NodeType`` enum in the ``ISD`` namespace). TableGen uses the following target description (``.td``) input files to; generate much of the code for instruction definition:. * ``Target.td`` --- Where the ``Instruction``, ``Operand``, ``InstrInfo``, and; other fundamental classes are defined. * ``TargetSelectionDAG.td`` --- Used by ``SelectionDAG`` instruction selection; generators, contains ``SDTC*`` classes (selection DAG type constraint),; definitions of ``SelectionDAG`` nodes (such as ``imm``, ``cond``, ``bb``,; ``add``, ``fadd``, ``sub``), and pattern support (``Pattern``, ``Pat``,; ``PatFrag``, ``PatLeaf``, ``ComplexPattern``. * ``XXXInstrFormats.td`` --- Patterns for definitions of target-specific; instructions. * ``XXXInstrInfo.td`` --- Target-specific definitions of instruction templates,; condition codes, and instructio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:27843,load,load,27843,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['load'],['load']
Performance,"lem with matrix calculations in Eve classes (#206); 2. Fix errors in TNodejsFile (#208); 3. Fix TGraph tooltips handling; 4. Fix TH2Poly tooltips handling. ## Changes in 6.0.0; 1. Major release with:; - incompatible changes in API; - heavy use of Promise class; - upgrade all used packages; 2. Use generic naming convention - all class names always starts from; capital letter like ""ObjectPainter"", all function names starts from small; letter like ""painter.getObjectHint()""; 3. Rename JSRootCore.js -> JSRoot.core.js, eliminate all URL parameters.; Loading of extra JSROOT functionality should be done via JSROOT.require() method; All other scripts uses similar naming convention.; 4. JSROOT.draw()/JSROOT.redraw() functions returns Promise, deprecate callback parameter; 5. Introduce JSROOT.httpRequest() function which returns Promise instance, deprecate; JSROOT.NewHttpRequest() function; 6. JSROOT.openFile() returns Promise with file instance, deprecate callback parameter; 7. Provide new code loader via JSROOT.require(); - introduces clean dependencies in JSROOT code; - by default uses plain script loading emulating require.js behavior; - can use require.js when available; - uses require() method when running inside node.js; - supports openui5 sap.ui.require loader if available before JSRoot.core.js; - deprecates old JSROOT.AssertPrerequisites() function; 8. Upgrade d3.js to v6.1.1, skip support of older versions; 9. Upgrade three.js to r121:; - SoftwareRenderer deprecated and removed; - let use WebGL for browser, batch and node.js (via headless-gl); - support r3d_gl, r3d_img, r3d_svg rendering options for TGeo and histograms; - keep support of SVGRendered as backup solution; 10. Upgrade MathJax.js to version 3.1.1; - reliably works in browser and node.js!; - all latex/mathjax related methods moved to special JSRoot.latex.js script, loaded on demand; 11. Update jquery to 3.5.1, openui5 to 1.82.2; 12. Use JS classes only in few places - performance is not good enough compare",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:25423,load,loader,25423,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['load'],['loader']
Performance,"lement any of these optimizations, I assume that we; could do them a translation unit at a time, just as GCC does now. This; would lead to a pipeline like this:. Static optimizations, xlation unit at a time:; .c --GCC--> .llvm --llvmopt--> .llvm . Link time optimizations:; .llvm --llvm-ld--> .llvm --llvm-link-opt--> .llvm . Of course, many optimizations could be shared between llvmopt and; llvm-link-opt, but the wouldn't need to be shared... Thus compile time; could be faster, because we are using a ""smarter"" IR (SSA based). > BTW, about SGI, ""borrowing"" SSA-based optimizations from one compiler and; > putting it into another is not necessarily easier than re-doing it.; > Optimization code is usually heavily tied in to the specific IR they use. Understood. The only reason that I brought this up is because SGI's IR is; more similar to LLVM than it is different in many respects (SSA based,; relatively low level, etc), and could be easily adapted. Also their; optimizations are written in C++ and are actually somewhat; structured... of course it would be no walk in the park, but it would be; much less time consuming to adapt, say, SSA-PRE than to rewrite it. > But your larger point is valid that adding SSA based optimizations is; > feasible and should be fun. (Again, link time cost is the issue.). Assuming linktime cost wasn't an issue, the question is: ; Does using GCC's backend buy us anything?. > It also occurs to me that GCC is probably doing quite a bit of back-end; > optimization (step 16 in your list). Do you have a breakdown of that?. Not really. The irritating part of GCC is that it mixes it all up and; doesn't have a clean separation of concerns. A lot of the ""back end; optimization"" happens right along with other data optimizations (ie, CSE; of machine specific things). As far as REAL back end optimizations go, it looks something like this:. 1. Instruction combination: try to make CISCy instructions, if available; 2. Register movement: try to get registers in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt:1354,optimiz,optimizations,1354,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,1,['optimiz'],['optimizations']
Performance,"lename:. Source Filename; ---------------. The *source filename* string is set to the original module identifier,; which will be the name of the compiled source file when compiling from; source through the clang front end, for example. It is then preserved through; the IR and bitcode. This is currently necessary to generate a consistent unique global; identifier for local functions used in profile data, which prepends the; source file name to the local function name. The syntax for the source file name is simply:. .. code-block:: text. source_filename = ""/path/to/source.c"". .. _typesystem:. Type System; ===========. The LLVM type system is one of the most important features of the; intermediate representation. Being typed enables a number of; optimizations to be performed on the intermediate representation; directly, without having to do extra analyses on the side before the; transformation. A strong type system makes it easier to read the; generated code and enables novel analyses and transformations that are; not feasible to perform on normal three address code representations. .. _t_void:. Void Type; ---------. :Overview:. The void type does not represent any value and has no size. :Syntax:. ::. void. .. _t_function:. Function Type; -------------. :Overview:. The function type can be thought of as a function signature. It consists of a; return type and a list of formal parameter types. The return type of a function; type is a void type or first class type --- except for :ref:`label <t_label>`; and :ref:`metadata <t_metadata>` types. :Syntax:. ::. <returntype> (<parameter list>). ...where '``<parameter list>``' is a comma-separated list of type; specifiers. Optionally, the parameter list may include a type ``...``, which; indicates that the function takes a variable number of arguments. Variable; argument functions can access their arguments with the :ref:`variable argument; handling intrinsic <int_varargs>` functions. '``<returntype>``' is any type; except :ref:`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:165638,perform,perform,165638,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"ler will dump a preprocessed file and a script; to replay the ``clang`` command. For example, you should see something like. .. code-block:: text. PLEASE ATTACH THE FOLLOWING FILES TO THE BUG REPORT:; Preprocessed source(s) and associated run script(s) are located at:; clang: note: diagnostic msg: /tmp/foo-xxxxxx.c; clang: note: diagnostic msg: /tmp/foo-xxxxxx.sh. The `creduce <https://github.com/csmith-project/creduce>`_ tool helps to; reduce the preprocessed file down to the smallest amount of code that still; replicates the problem. You're encouraged to use creduce to reduce the code; to make the developers' lives easier. The; ``clang/utils/creduce-clang-crash.py`` script can be used on the files; that clang dumps to help with automating creating a test to check for the; compiler crash. `cvise <https://github.com/marxin/cvise>`_ is an alternative to ``creduce``. .. _middleend-crash:. Middle-end optimization bugs; ----------------------------. If you find that a bug crashes in the optimizer, compile your test-case to a; ``.bc`` file by passing ""``-emit-llvm -O1 -Xclang -disable-llvm-passes -c -o; foo.bc``"". The ``-O1`` is important because ``-O0`` adds the ``optnone``; function attribute to all functions and many passes don't run on ``optnone``; functions. Then run:. .. code-block:: bash. opt -O3 foo.bc -disable-output. If this doesn't crash, please follow the instructions for a :ref:`front-end; bug <frontend-crash>`. If this does crash, then you should be able to debug this with the following; :doc:`bugpoint <Bugpoint>` command:. .. code-block:: bash. bugpoint foo.bc -O3. Run this, then file a bug with the instructions and reduced .bc; files that bugpoint emits. If bugpoint doesn't reproduce the crash, ``llvm-reduce`` is an alternative; way to reduce LLVM IR. Create a script that repros the crash and run:. .. code-block:: bash. llvm-reduce --test=path/to/script foo.bc. which should produce reduced IR that reproduces the crash. Be warned the; ``llvm-reduce`` is st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:3599,optimiz,optimizer,3599,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['optimiz'],['optimizer']
Performance,"ler. Disable scheduling after register allocation. .. option:: -disable-spill-fusing. Disable fusing of spill code into instructions. .. option:: -jit-enable-eh. Exception handling should be enabled in the just-in-time compiler. .. option:: -join-liveintervals. Coalesce copies (default=true). .. option:: -nozero-initialized-in-bss. Don't place zero-initialized symbols into the BSS section. .. option:: -pre-RA-sched=scheduler. Instruction schedulers available (before register allocation):. .. code-block:: text. =default: Best scheduler for the target; =none: No scheduling: breadth first sequencing; =simple: Simple two pass scheduling: minimize critical path and maximize processor utilization; =simple-noitin: Simple two pass scheduling: Same as simple except using generic latency; =list-burr: Bottom-up register reduction list scheduling; =list-tdrr: Top-down register reduction list scheduling; =list-td: Top-down list scheduler. .. option:: -regalloc=allocator. Register allocator to use (default=linearscan). .. code-block:: text. =bigblock: Big-block register allocator; =linearscan: linear scan register allocator; =local: local register allocator; =simple: simple register allocator. .. option:: -relocation-model=model. Choose relocation model from:. .. code-block:: text. =default: Target default relocation model; =static: Non-relocatable code; =pic: Fully relocatable, position independent code; =dynamic-no-pic: Relocatable external references, non-relocatable code. .. option:: -spiller. Spiller to use (default=local). .. code-block:: text. =simple: simple spiller; =local: local spiller. .. option:: -x86-asm-syntax=syntax. Choose style of code to emit from X86 backend:. .. code-block:: text. =att: Emit AT&T-style assembly; =intel: Emit Intel-style assembly. EXIT STATUS; -----------. If :program:`lli` fails to load the program, it will exit with an exit code of 1.; Otherwise, it will return the exit code of the program it executes. SEE ALSO; --------. :manpage:`llc(1)`; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:5674,load,load,5674,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,1,['load'],['load']
Performance,"les and Functions have one of the following types of; linkage:. ``private``; Global values with ""``private``"" linkage are only directly; accessible by objects in the current module. In particular, linking; code into a module with a private global value may cause the; private to be renamed as necessary to avoid collisions. Because the; symbol is private to the module, all references can be updated. This; doesn't show up in any symbol table in the object file.; ``internal``; Similar to private, but the value shows as a local symbol; (``STB_LOCAL`` in the case of ELF) in the object file. This; corresponds to the notion of the '``static``' keyword in C.; ``available_externally``; Globals with ""``available_externally``"" linkage are never emitted into; the object file corresponding to the LLVM module. From the linker's; perspective, an ``available_externally`` global is equivalent to; an external declaration. They exist to allow inlining and other; optimizations to take place given knowledge of the definition of the; global, which is known to be somewhere outside the module. Globals; with ``available_externally`` linkage are allowed to be discarded at; will, and allow inlining and other optimizations. This linkage type is; only allowed on definitions, not declarations.; ``linkonce``; Globals with ""``linkonce``"" linkage are merged with other globals of; the same name when linkage occurs. This can be used to implement; some forms of inline functions, templates, or other code which must; be generated in each translation unit that uses it, but where the; body may be overridden with a more definitive definition later.; Unreferenced ``linkonce`` globals are allowed to be discarded. Note; that ``linkonce`` linkage does not actually allow the optimizer to; inline the body of this function into callers because it doesn't; know if this definition of the function is the definitive definition; within the program or whether it will be overridden by a stronger; definition. To enable inl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:8259,optimiz,optimizations,8259,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"les-cache-path``), and reuse them as prebuilt implicit modules by passing ``-fprebuilt-module-path`` and ``-fprebuilt-implicit-modules``. .. code-block:: sh. rm -rf prebuilt; mkdir prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -DENABLE_A; find prebuilt -name ""*.pcm""; # prebuilt/1AYBIGPM8R2GA/A-3L1K4LUA6O31.pcm; # prebuilt/1AYBIGPM8R2GA/B-3L1K4LUA6O31.pcm; # prebuilt/VH0YZMF1OIRK/A-3L1K4LUA6O31.pcm; # prebuilt/VH0YZMF1OIRK/B-3L1K4LUA6O31.pcm; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -DENABLE_A. Finally we want to allow implicit modules for configurations that were not prebuilt. When using the clang driver a module cache path is implicitly selected. Using ``-cc1``, we simply add use the ``-fmodules-cache-path`` option. .. code-block:: sh. clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -fmodules-cache-path=cache; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -fmodules-cache-path=cache -DENABLE_A; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -fmodules-cache-path=cache -DENABLE_A -DOTHER_OPTIONS. This way, a single directory containing multiple variants of modules can be prepared and reused. The options configuring the module cache are independent of other options. Module Semantics; ================. Modules are modeled as if each submodule were a separate translation unit, and a module import makes names from the other translation unit visible. Each su",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:23274,cache,cache,23274,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['cache'],['cache']
Performance,"les. These 3D and 4D; vectors are different from vectors of the linear algebra package, which; describe generic N-dimensional vectors. Similar functionality is; currently provided by the CLHEP <Vector> and <Geometry> packages and the; ROOT Physics vector classes (See ""Physics Vectors""). It also re-uses; concepts and ideas from the CMS; [Common Vector package](Common Vector package). In contrast to CLHEP or; the ROOT physics libraries, `GenVector` provides class templates for; modeling the vectors. The user can control how the vector is internally; represented. This is expressed by a choice of coordinate system, which; is supplied as a template parameter when the vector is constructed.; Furthermore, each coordinate system is itself a template, so that the; user can specify the underlying scalar type. The `GenVector` classes do not inherit from **`TObject`**, therefore; cannot be used as in the case of the physics vector classes in ROOT; collections. In addition, to optimize performances, no virtual destructors are; provided. In the following paragraphs, the main characteristics of; `GenVector` are described. A more detailed description of all the; `GenVector` classes is available also at; <http://seal.cern.ch/documents/mathlib/GenVector.pdf>. ### Main Characteristics. #### Optimal Runtime Performances. We try to minimize any overhead in the run-time performance. We have; deliberately avoided the use of any virtual function and even virtual; destructors in the classes. In addition, as much as possible functions; are defined as inline. For this reason, we have chosen to use template; classes to implement the `GenVector` concepts instead of abstract or; base classes and virtual functions. It is then recommended to avoid; using the `GenVector` classes polymorphically and developing classes; inheriting from them. #### Points and Vector Concept. Mathematically vectors and points are two distinct concepts. They have; different transformations, as vectors only rotate while po",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:68576,optimiz,optimize,68576,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,2,"['optimiz', 'perform']","['optimize', 'performances']"
Performance,"less of that; implementation, however. For example, if a1.cpp and a2.cpp both define a; function ""foo"" then ORCv2 will generate a duplicate definition error. On the; other hand, if a1.cpp and b1.cpp both define ""foo"" there is no error (different; dynamic libraries may define the same symbol). If main.cpp refers to ""foo"", it; should bind to the definition in LibA rather than the one in LibB, since; main.cpp is part of the ""main"" dylib, and the main dylib links against LibA; before LibB. Many JIT clients will have no need for this strict adherence to the usual; ahead-of-time linking rules, and should be able to get by just fine by putting; all of their code in a single JITDylib. However, clients who want to JIT code; for languages/projects that traditionally rely on ahead-of-time linking (e.g.; C++) will find that this feature makes life much easier. Symbol lookup in ORC serves two other important functions, beyond providing; addresses for symbols: (1) It triggers compilation of the symbol(s) searched for; (if they have not been compiled already), and (2) it provides the; synchronization mechanism for concurrent compilation. The pseudo-code for the; lookup process is:. .. code-block:: none. construct a query object from a query set and query handler; lock the session; lodge query against requested symbols, collect required materializers (if any); unlock the session; dispatch materializers (if any). In this context a materializer is something that provides a working definition; of a symbol upon request. Usually materializers are just wrappers for compilers,; but they may also wrap a jit-linker directly (if the program representation; backing the definitions is an object file), or may even be a class that writes; bits directly into memory (for example, if the definitions are; stubs). Materialization is the blanket term for any actions (compiling, linking,; splatting bits, registering with runtimes, etc.) that are required to generate a; symbol definition that is safe to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:9483,concurren,concurrent,9483,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['concurren'],['concurrent']
Performance,"lete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the TFileMerger needs to handle the input files in more than one pass for example when there is more than 1000 input files or the -n option is passed to hadd.; Fix support for emulated class that derived from an abstract class.; This can happen when reading a file containing an ancient; class layout where the derived class is no longer provided in the; compiled code but the abstract base class is still provided. It also happens when using schema evolution rules on a class derived; from an abstract base class (in which case the system introduce; implicitly an emulated class deriving from the same base classes; as the evolved from class). To fix the issue, we introduce the TClass::GetStreamerInfoAbstractEmulated; which will return a StreamerInfo representing an emulated version of the; class even if it is loaded. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:5040,load,loaded,5040,tree/doc/v534/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html,2,['load'],['loaded']
Performance,"lete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointer",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37706,load,loads,37706,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,['load'],['loads']
Performance,"lethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx10-gfx11:. Memory Model GFX10-GFX11; ++++++++++++++++++++++++. For GFX10-GFX11:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple work-group processors (WGP).; * Each WGP has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same; WGP. In CU wavefront execution mode the wavefronts may be executed by; different SIMDs in the same CU. In WGP wavefront execution mode the; wavefronts may be executed by different SIMDs in different CUs in the same; WGP.; * Each WGP has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a WGP are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; WGP. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations.; Completion of load/store/sample operations are reported to a wavefront in; execution order of other load/store/sample operations performed by that; wavefront.; * The vector memory operations access a vector L0 cache. There is a single L0; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:335801,perform,performed,335801,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance,"ley; National Laboratory, U.S. Dept. of Energy nor the names of its contributors; may be used to endorse or promote products derived from this software without; specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS; ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED; TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR; PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS; BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE; GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION); HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT; LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY; OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF; SUCH DAMAGE. You are under no obligation whatsoever to provide any bug fixes,; patches, or upgrades to the features, functionality or performance of; the source code (""Enhancements"") to anyone; however, if you choose to; make your Enhancements available either publicly, or directly to; Lawrence Berkeley National Laboratory, without imposing a separate; written license agreement for such Enhancements, then you hereby grant; the following license: a non-exclusive, royalty-free perpetual license; to install, use, modify, prepare derivative works, incorporate into; other computer software, distribute, and sublicense such Enhancements; or derivative works thereof, in binary and source code form. Additional copyright holders; ----------------------------. In addition to LBNL/UC Berkeley, this package contains files copyrighted by; one or more of the following people and organizations, and licensed under; the same conditions (except for some compatible licenses as retained in the; source code):. CERN; Antonio Cuni; Aditi Dutta; Shaheed Haque; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/LICENSE.txt:1855,perform,performance,1855,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/LICENSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/LICENSE.txt,1,['perform'],['performance']
Performance,"lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:268995,load,loads,268995,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"liasee expression. ``unnamed_addr`` ones are only guaranteed to point; to the same content. If the ``local_unnamed_addr`` attribute is given, the address is known to; not be significant within the module. Since aliases are only a second name, some restrictions apply, of which; some can only be checked when producing an object file:. * The expression defining the aliasee must be computable at assembly; time. Since it is just a name, no relocations can be used. * No alias in the expression can be weak as the possibility of the; intermediate alias being overridden cannot be represented in an; object file. * If the alias has the ``available_externally`` linkage, the aliasee must be an; ``available_externally`` global value; otherwise the aliasee can be an; expression but no global value in the expression can be a declaration, since; that would require a relocation, which is not possible. * If either the alias or the aliasee may be replaced by a symbol outside the; module at link time or runtime, any optimization cannot replace the alias with; the aliasee, since the behavior may be different. The alias may be used as a; name guaranteed to point to the content in the current module. .. _langref_ifunc:. IFuncs; -------. IFuncs, like as aliases, don't create any new data or func. They are just a new; symbol that is resolved at runtime by calling a resolver function. On ELF platforms, IFuncs are resolved by the dynamic linker at load time. On; Mach-O platforms, they are lowered in terms of ``.symbol_resolver`` functions,; which lazily resolve the callee the first time they are called. IFunc may have an optional :ref:`linkage type <linkage>` and an optional; :ref:`visibility style <visibility>`. Syntax::. @<Name> = [Linkage] [PreemptionSpecifier] [Visibility] ifunc <IFuncTy>, <ResolverTy>* @<Resolver>; [, partition ""name""]. .. _langref_comdats:. Comdats; -------. Comdat IR provides access to object file COMDAT/section group functionality; which represents interrelated section",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:44469,optimiz,optimization,44469,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"libraries get confused if you don't; # explicitly specify an architecture setting with the Xcode generator.; set(CMAKE_OSX_ARCHITECTURES ""x86_64""); endif(). project(LLVM; VERSION ${LLVM_VERSION_MAJOR}.${LLVM_VERSION_MINOR}.${LLVM_VERSION_PATCH}; LANGUAGES C CXX ASM). if (NOT DEFINED CMAKE_INSTALL_LIBDIR AND DEFINED LLVM_LIBDIR_SUFFIX); # Must go before `include(GNUInstallDirs)`.; set(CMAKE_INSTALL_LIBDIR ""lib${LLVM_LIBDIR_SUFFIX}""); endif(). # Must go after `DEFINED LLVM_LIBDIR_SUFFIX` check.; set(LLVM_LIBDIR_SUFFIX """" CACHE STRING ""Define suffix of library directory name (32/64)"" ). # Must go after `project(..)`.; include(GNUInstallDirs). # This C++ standard is required to build LLVM.; set(LLVM_REQUIRED_CXX_STANDARD 17). # If we find that the cache contains CMAKE_CXX_STANDARD it means that it's a old CMakeCache.txt; # and we can just inform the user and then reset it.; if($CACHE{CMAKE_CXX_STANDARD} AND $CACHE{CMAKE_CXX_STANDARD} LESS ${LLVM_REQUIRED_CXX_STANDARD}); message(WARNING ""Resetting cache value for CMAKE_CXX_STANDARD to ${LLVM_REQUIRED_CXX_STANDARD}""); unset(CMAKE_CXX_STANDARD CACHE); endif(). # if CMAKE_CXX_STANDARD is still set after the cache unset above it means that the user requested it; # and we allow it to be set to something newer than the required standard but otherwise we fail.; if(DEFINED CMAKE_CXX_STANDARD AND CMAKE_CXX_STANDARD LESS ${LLVM_REQUIRED_CXX_STANDARD}); message(FATAL_ERROR ""Requested CMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD} which is less than the required ${LLVM_REQUIRED_CXX_STANDARD}.""); endif(). set(CMAKE_CXX_STANDARD ${LLVM_REQUIRED_CXX_STANDARD} CACHE STRING ""C++ standard to conform to""); set(CMAKE_CXX_STANDARD_REQUIRED YES). if (CYGWIN); # Cygwin is a bit stricter and lack things like 'strdup', 'stricmp', etc in; # c++xx mode.; set(CMAKE_CXX_EXTENSIONS YES); else(); set(CMAKE_CXX_EXTENSIONS NO); endif(). if (NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES); message(FATAL_ERROR ""; No build type selected. You need to pass ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:2911,cache,cache,2911,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['cache'],['cache']
Performance,"library; for combined constructs; (e.g. ``#pragma omp parallel for simd``) the non-simd directives and clauses; will be ignored. This can be disabled with `-fno-openmp-simd`. Controlling implementation limits; ---------------------------------. .. option:: -fopenmp-use-tls. Controls code generation for OpenMP threadprivate variables. In presence of; this option all threadprivate variables are generated the same way as thread; local variables, using TLS support. If `-fno-openmp-use-tls`; is provided or target does not support TLS, code generation for threadprivate; variables relies on OpenMP runtime library. .. _opencl:. OpenCL Features; ===============. Clang can be used to compile OpenCL kernels for execution on a device; (e.g. GPU). It is possible to compile the kernel into a binary (e.g. for AMDGPU); that can be uploaded to run directly on a device (e.g. using; `clCreateProgramWithBinary; <https://www.khronos.org/registry/OpenCL/specs/opencl-1.1.pdf#111>`_) or; into generic bitcode files loadable into other toolchains. Compiling to a binary using the default target from the installation can be done; as follows:. .. code-block:: console. $ echo ""kernel void k(){}"" > test.cl; $ clang test.cl. Compiling for a specific target can be done by specifying the triple corresponding; to the target, for example:. .. code-block:: console. $ clang --target=nvptx64-unknown-unknown test.cl; $ clang --target=amdgcn-amd-amdhsa -mcpu=gfx900 test.cl. Compiling to bitcode can be done as follows:. .. code-block:: console. $ clang -c -emit-llvm test.cl. This will produce a file `test.bc` that can be used in vendor toolchains; to perform machine code generation. Note that if compiled to bitcode for generic targets such as SPIR/SPIR-V,; portable IR is produced that can be used with various vendor; tools as well as open source tools such as `SPIRV-LLVM Translator; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator>`_; to produce SPIR-V binary. More details are provided in `the offline",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:140745,load,loadable,140745,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['load'],['loadable']
Performance,"lications and machine configurations this; may be too aggressive, in which case the amount of parallelism can; be reduced to ``N`` via:. - gold:; ``-Wl,-plugin-opt,jobs=N``; - ld64:; ``-Wl,-mllvm,-threads=N``; - ld.lld, ld64.lld:; ``-Wl,--thinlto-jobs=N``; - lld-link:; ``/opt:lldltojobs=N``. Other possible values for ``N`` are:. - 0:; Use one thread per physical core (default); - 1:; Use a single thread only (disable multi-threading); - all:; Use one thread per logical core (uses all hyper-threads). Incremental; -----------; .. _incremental:. ThinLTO supports fast incremental builds through the use of a cache,; which currently must be enabled through a linker option. - gold (as of LLVM 4.0):; ``-Wl,-plugin-opt,cache-dir=/path/to/cache``; - ld64 (supported since clang 3.9 and Xcode 8) and Mach-O ld64.lld (as of LLVM; 15.0):; ``-Wl,-cache_path_lto,/path/to/cache``; - ELF ld.lld (as of LLVM 5.0):; ``-Wl,--thinlto-cache-dir=/path/to/cache``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocache:/path/to/cache``. Cache Pruning; -------------. To help keep the size of the cache under control, ThinLTO supports cache; pruning. Cache pruning is supported with gold, ld64, and lld, but currently only; gold and lld allow you to control the policy with a policy string. The cache; policy must be specified with a linker option. - gold (as of LLVM 6.0):; ``-Wl,-plugin-opt,cache-policy=POLICY``; - ELF ld.lld (as of LLVM 5.0), Mach-O ld64.lld (as of LLVM 15.0):; ``-Wl,--thinlto-cache-policy=POLICY``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocachepolicy:POLICY``. A policy string is a series of key-value pairs separated by ``:`` characters.; Possible key-value pairs are:. - ``cache_size=X%``: The maximum size for the cache directory is ``X`` percent; of the available space on the disk. Set to 100 to indicate no limit,; 50 to indicate that the cache size will not be left over half the available; disk space. A value over 100 is invalid. A value of 0 disables the percentage; size-based prun",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:5034,cache,cache,5034,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,1,['cache'],['cache']
Performance,"lihood fits.; 	These classes are templated on the type of function interface they implement (see later). User convenient typedefs are also provided.; 	They derive from the common generic interface multi-dimensional for function evaluation, `ROOT::Math::IBaseFunctionMultiDim`. In addition the fitter classes make uses of the generic interfaces for parametric function evaluations, `ROOT::Math::IParametricFunctionMultiDim`; to define the fit model function and use the `ROOT::Math::Minimizer` interface to perform the minimization of the objective function.; More information about the function interface and the multi-dimensional minimization in ROOT is given in the Mathematical Library chapter. Here we present a detailed description of the `ROOT::Fit` classes and how to use them.; Using these classes instead of the interface provided directly in the ROOT data objects, like `TH1::Fit` allow are more fine control; to configure and customise the fits. For example, using these classes a combined fit of several histograms can be performed. To understand how these class work, let's go through a simple example, such as fitting an histogram. When fitting an histogram, instead of using `TH1::Fit` we will show in the following hot wo use the `ROOT::Fit` classes.; We will show how to perform the following different type of fits with the histogram data:; * a least square fit using the observed errors (Neyman chi-squared);; * a least square fit using the expected errors from the function (Pearson chi-squared);; * a binned likelihood fit;; * an extended unbinned likelihood fits, if the histogram has been set to store in the buffer the original data used to fill it. Let's go through all the steps required for performing these fits using the `ROOT::Fit::Fitter` class.; These steps are:; 1. Create the input fit data object.; 2. Create the input model function.; 3. Configure the fit.; 4. Perform the data fitting.; 5. Examine the result. ### Creating the input fit data. We have two types of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:28662,perform,performed,28662,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['perform'],['performed']
Performance,"like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. On",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42517,load,load,42517,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,3,"['load', 'queue']","['load', 'queue']"
Performance,"liminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; Thissolves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the way results are transferred and merged:. Output objects are added to the same TMessage until a; HWM is reached (default 1MB; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; Reasonably small histograms (GetSize() <; MsgSizeHWM) are merged in one-go at the end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:; ;   root [n] p->Process(...);    ... ;    Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:6625,Optimiz,Optimize,6625,proof/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html,1,['Optimiz'],['Optimize']
Performance,"ling class names will be resolved only when; :program:`llvm-exegesis` is compiled in debug mode, else only the class id will; be shown. This does not invalidate any of the analysis results though. OPTIONS; -------. .. option:: --help. Print a summary of command line options. .. option:: --opcode-index=<LLVM opcode index>. Specify the opcode to measure, by index. Specifying `-1` will result; in measuring every existing opcode. See example 1 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --opcode-name=<opcode name 1>,<opcode name 2>,... Specify the opcode to measure, by name. Several opcodes can be specified as; a comma-separated list. See example 1 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --snippets-file=<filename>. Specify the custom code snippet to measure. See example 2 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --mode=[latency|uops|inverse_throughput|analysis]. Specify the run mode. Note that some modes have additional requirements and options. `latency` mode can be make use of either RDTSC or LBR.; `latency[LBR]` is only available on X86 (at least `Skylake`).; To run in `latency` mode, a positive value must be specified; for `x86-lbr-sample-period` and `--repetition-mode=loop`. In `analysis` mode, you also need to specify at least one of the; `-analysis-clusters-output-file=` and `-analysis-inconsistencies-output-file=`. .. option:: --benchmark-phase=[prepare-snippet|prepare-and-assemble-snippet|assemble-measured-code|measure]. By default, when `-mode=` is specified, the generated snippet will be executed; and measured, and that requires that we are running on the hardware for which; the snippet was generated, and that supports performance measurements.; However, it is possible to stop at some stage before measuring. Choices are:; * ``prepare-snippet``: Only generate the minimal instruction sequence.; * ``prepa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:9958,latency,latency,9958,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['latency'],['latency']
Performance,"ling convention is `swifttailcc` or `swiftcc`:. - Only these ABI-impacting attributes attributes are allowed: sret, byval,; swiftself, and swiftasync.; - Prototypes are not required to match. Tail call optimization for calls marked ``tail`` is guaranteed to occur if; the following conditions are met:. - Caller and callee both have the calling convention ``fastcc`` or ``tailcc``.; - The call is in tail position (ret immediately follows call and ret; uses value of call or is void).; - Option ``-tailcallopt`` is enabled,; ``llvm::GuaranteedTailCallOpt`` is ``true``, or the calling convention; is ``tailcc``; - `Platform-specific constraints are; met. <CodeGenerator.html#tailcallopt>`_. #. The optional ``notail`` marker indicates that the optimizers should not add; ``tail`` or ``musttail`` markers to the call. It is used to prevent tail; call optimization from being performed on the call. #. The optional ``fast-math flags`` marker indicates that the call has one or more; :ref:`fast-math flags <fastmath>`, which are optimization hints to enable; otherwise unsafe floating-point optimizations. Fast-math flags are only valid; for calls that return a floating-point scalar or vector type, or an array; (nested to any depth) of floating-point scalar or vector types. #. The optional ""cconv"" marker indicates which :ref:`calling; convention <callingconv>` the call should use. If none is; specified, the call defaults to using C calling conventions. The; calling convention of the call must match the calling convention of; the target function, or else the behavior is undefined.; #. The optional :ref:`Parameter Attributes <paramattrs>` list for return; values. Only '``zeroext``', '``signext``', and '``inreg``' attributes; are valid here.; #. The optional addrspace attribute can be used to indicate the address space; of the called function. If it is not specified, the program address space; from the :ref:`datalayout string<langref_datalayout>` will be used.; #. '``ty``': the type of the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:475766,optimiz,optimization,475766,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['optimiz'],"['optimization', 'optimizations']"
Performance,"ling convention requires the hidden argument to be returned by; the callee. //===---------------------------------------------------------------------===//. We can definitely do a better job on BB placements to eliminate some branches.; It's very common to see llvm generated assembly code that looks like this:. LBB3:; ...; LBB4:; ...; beq LBB3; b LBB2. If BB4 is the only predecessor of BB3, then we can emit BB3 after BB4. We can; then eliminate beq and turn the unconditional branch to LBB2 to a bne. See McCat/18-imp/ComputeBoundingBoxes for an example. //===---------------------------------------------------------------------===//. Pre-/post- indexed load / stores:. 1) We should not make the pre/post- indexed load/store transform if the base ptr; is guaranteed to be live beyond the load/store. This can happen if the base; ptr is live out of the block we are performing the optimization. e.g. mov r1, r2; ldr r3, [r1], #4; ... vs. ldr r3, [r2]; add r1, r2, #4; ... In most cases, this is just a wasted optimization. However, sometimes it can; negatively impact the performance because two-address code is more restrictive; when it comes to scheduling. Unfortunately, liveout information is currently unavailable during DAG combine; time. 2) Consider spliting a indexed load / store into a pair of add/sub + load/store; to solve #1 (in TwoAddressInstructionPass.cpp). 3) Enhance LSR to generate more opportunities for indexed ops. 4) Once we added support for multiple result patterns, write indexed loads; patterns instead of C++ instruction selection code. 5) Use VLDM / VSTM to emulate indexed FP load / store. //===---------------------------------------------------------------------===//. Implement support for some more tricky ways to materialize immediates. For; example, to get 0xffff8000, we can use:. mov r9, #&3f8000; sub r9, r9, #&400000. //===---------------------------------------------------------------------===//. We sometimes generate multiple add / sub instructions to u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:8566,optimiz,optimization,8566,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['optimiz'],['optimization']
Performance,"lipping shapes. Note that these; shapes are considered defined in the current `MARS`. Composite shapes; may be used.; 2. `gGeoManager->SetClippingShape(clip1);`; One can activate or deactivate clipping at any time:; `gGeoManager->SetClipping(flag);`; 3. Perform ray-tracing:` gGeoManager->GetTopVolume()->Raytrace();`. One can redo the steps 2-3 as many times as needed. Let us look how the; rootgeom.C example looks clipped with a tube. \image html geometry014.png ""Ray-tracing example with box-clipping"". \anchor GP05; ## Representing Misalignments of the Ideal Geometry. The ideal positioning of a detector does not match its position in the; experimental hall. This generally happens not only for the detector; modules, but also for their components. The accurate knowledge of the; detector real misalignments can be extremely important for getting close; to its designed resolution and the expected tracking efficiency.; `TGeo` offers tools for representing positioning misalignments,; applying them to the ideal geometry and performing navigation under; these conditions. Detector tracking algorithms can then directly query; the geometry for navigation purposes or for retrieving actual; misalignment information. \anchor GP05a; ### Physical Nodes. Physical nodes are the actual ""touchable"" objects in the geometry,; representing actually a path of positioned volumes starting with the; top node: `path=/TOP/A_1/B_4/C_3` , where `A`, `B`, `C` represent names; of volumes. The number of physical nodes is given by the total number of; possible of branches in the geometry hierarchy. In case of detector; geometries and specially for calorimeters this number can be of the; order 106-109, therefore it is impossible to create all physical nodes; as objects in memory. In `TGeo`, physical nodes are represented by; the class TGeoPhysicalNode and can be created on demand for; alignment purposes:. ~~~{.cpp}; TGeoPhysicalNode(const char* path); ~~~. The knowledge of the path to the objects that ne",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:106482,perform,performing,106482,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performing']
Performance,"list(LENGTH pytutorials nAfterVeto). message(STATUS ""${nAfterVeto}/${nTotal} python tutorials have been activated.""). #---Python tutorials dependencies--------------------------------------; set(pyroot-ntuple1-depends tutorial-pyroot-hsimple-py); set(pyroot-h1ReadAndDraw-depends tutorial-pyroot-hsimple-py); set(pyroot-benchmarks-depends tutorial-pyroot-hsimple-py; tutorial-pyroot-fit1-py; tutorial-pyroot-na49view-py; tutorial-pyroot-h1ReadAndDraw-py; tutorial-pyroot-ntuple1-py); set(pyroot-fit1-depends tutorial-hist-fillrandom-py); set(pyroot-na49view-depends tutorial-pyroot-geometry-py); set(roofit-rf503_wspaceread-depends tutorial-roofit-rf502_wspacewrite-py); set(roofit-rf618_mixture_models-depends tutorial-dataframe-df106_HiggsToFourLeptons-py). # Avoid a race condition: make sure Python tutorial is run after C++ tutorial; set(roofit-rf104_classfactory-depends tutorial-roofit-rf104_classfactory); set(roofit-rf512_wsfactory_oper-depends tutorial-roofit-rf512_wsfactory_oper); set (tmva-TMVA_Higgs_Classification-depends tutorial-tmva-TMVA_Higgs_Classification); set (tmva-TMVA_CNN_Classification-depends tutorial-tmva-TMVA_CNN_Classification); set (tmva-TMVA_RNN_Classification-depends tutorial-tmva-TMVA_RNN_Classification). #----------------------------------------------------------------------; # List requirements for python tutorials.; # To add a new requirement, add a glob expression that's named requires_<packageName>,; # and add it to the list ""fixtureLists"" below.; file(GLOB requires_numpy RELATIVE ${CMAKE_CURRENT_SOURCE_DIR}; dataframe/df026_AsNumpyArrays.py; dataframe/df032_RDFFromNumpy.py; fit/combinedFit.py; fit/multifit.py; roofit/rf409_NumPyPandasToRooFit.py); file(GLOB requires_numba RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} pyroot/pyroot004_NumbaDeclare.py); file(GLOB requires_pandas RELATIVE ${CMAKE_CURRENT_SOURCE_DIR}; dataframe/df026_AsNumpyArrays.py; roofit/rf409_NumPyPandasToRooFit.py); file(GLOB requires_keras RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} tmva/k",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tutorials/CMakeLists.txt:31435,race condition,race condition,31435,tutorials/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/CMakeLists.txt,1,['race condition'],['race condition']
Performance,"lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88245,optimiz,optimization,88245,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['optimiz'],['optimization']
Performance,"lit - LLVM Integrated Tester; ============================. .. program:: lit. SYNOPSIS; --------. :program:`lit` [*options*] [*tests*]. DESCRIPTION; -----------. :program:`lit` is a portable tool for executing LLVM and Clang style test; suites, summarizing their results, and providing indication of failures.; :program:`lit` is designed to be a lightweight testing tool with as simple a; user interface as possible. :program:`lit` should be run with one or more *tests* to run specified on the; command line. Tests can be either individual test files or directories to; search for tests (see :ref:`test-discovery`). Each specified test will be executed (potentially concurrently) and once all; tests have been run :program:`lit` will print summary information on the number; of tests which passed or failed (see :ref:`test-status-results`). The; :program:`lit` program will execute with a non-zero exit code if any tests; fail. By default :program:`lit` will use a succinct progress display and will only; print summary information for test failures. See :ref:`output-options` for; options controlling the :program:`lit` progress display and output. :program:`lit` also includes a number of options for controlling how tests are; executed (specific features may depend on the particular test format). See; :ref:`execution-options` for more information. Finally, :program:`lit` also supports additional options for only running a; subset of the options specified on the command line, see; :ref:`selection-options` for more information. :program:`lit` parses options from the environment variable ``LIT_OPTS`` after; parsing options from the command line. ``LIT_OPTS`` is primarily useful for; supplementing or overriding the command-line options supplied to :program:`lit`; by ``check`` targets defined by a project's build system. :program:`lit` can also read options from response files which are specified as; inputs using the ``@path/to/file.rsp`` syntax. Arguments read from a file must; be one p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:667,concurren,concurrently,667,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['concurren'],['concurrently']
Performance,"lit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:281108,load,load,281108,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,4,['load'],['load']
Performance,"lity guarantees for the raw; profile format. Raw profiles may be dependent on the specific compiler; revision used to generate them. It's inadvisable to store raw profiles for; long periods of time. * Tools must retain **backwards** compatibility with indexed profile formats.; These formats are not forwards-compatible: i.e, a tool which uses format; version X will not be able to understand format version (X+k). * Tools must also retain **backwards** compatibility with the format of the; coverage mappings emitted into instrumented binaries. These formats are not; forwards-compatible. * The JSON coverage export format has a (major, minor, patch) version triple.; Only a major version increment indicates a backwards-incompatible change. A; minor version increment is for added functionality, and patch version; increments are for bugfixes. Impact of llvm optimizations on coverage reports; ================================================. llvm optimizations (such as inlining or CFG simplification) should have no; impact on coverage report quality. This is due to the fact that the mapping; from source regions to profile counters is immutable, and is generated before; the llvm optimizer kicks in. The optimizer can't prove that profile counter; instrumentation is safe to delete (because it's not: it affects the profile the; program emits), and so leaves it alone. Note that this coverage feature does not rely on information that can degrade; during the course of optimization, such as debug info line tables. Using the profiling runtime without static initializers; =======================================================. By default the compiler runtime uses a static initializer to determine the; profile output path and to register a writer function. To collect profiles; without using static initializers, do this manually:. * Export a ``int __llvm_profile_runtime`` symbol from each instrumented shared; library and executable. When the linker finds a definition of this symbol, it; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:14717,optimiz,optimizations,14717,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['optimiz'],['optimizations']
Performance,"ll SGPR registers except the clobbered registers of SGPR4-31.; * VGPR40-47; * VGPR56-63; * VGPR72-79; * VGPR88-95; * VGPR104-111; * VGPR120-127; * VGPR136-143; * VGPR152-159; * VGPR168-175; * VGPR184-191; * VGPR200-207; * VGPR216-223; * VGPR232-239; * VGPR248-255. .. note::. Except the argument registers, the VGPRs clobbered and the preserved; registers are intermixed at regular intervals in order to keep a; similar ratio independent of the number of allocated VGPRs. * GFX90A: All AGPR registers except the clobbered registers AGPR0-31.; * Lanes of all VGPRs that are inactive at the call site. For the AMDGPU backend, an inter-procedural register allocation (IPRA); optimization may mark some of clobbered SGPR and VGPR registers as; preserved if it can be determined that the called function does not change; their value. 2. The PC is set to the RA provided on entry.; 3. MODE register: *TBD*.; 4. All other registers are clobbered.; 5. Any necessary ``s_waitcnt`` has been performed to ensure memory accessed by; function is available to the caller. .. TODO::. - How are function results returned? The address of structured types is passed; by reference, but what about other types?. The function input arguments are made up of the formal arguments explicitly; declared by the source language function plus the implicit input arguments used; by the implementation. The source language input arguments are:. 1. Any source language implicit ``this`` or ``self`` argument comes first as a; pointer type.; 2. Followed by the function formal arguments in left to right source order. The source language result arguments are:. 1. The function result argument. The source language input or result struct type arguments that are less than or; equal to 16 bytes, are decomposed recursively into their base type fields, and; each field is passed as if a separate argument. For input arguments, if the; called function requires the struct to be in memory, for example because its; address is taken, then",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:391481,perform,performed,391481,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance,"ll be cast implicitly, if; possible, to the type of the local variable to which they are assigned. `Bind(TObject* obj,const char* label)` - transfer a ROOT object from the; Cling to the Python interpreter, where it will be referenced with a; variable called ""`label`"". `Prompt()` - Transfer the interactive prompt to Python. With the ROOT v4.00/06 and later, the **`TPython`** class will be loaded; automatically on use, for older editions, the `libPyROOT.so` needs to be; loaded first with `gSystem->Load()` before use. Refer back to the other; example of the use of **`TPython`** that was given in ""Access to Python; from ROOT"". To show in detail how Python access can be used, an example Python; module is needed, as follows:. ``` {.cpp}; print('creating class MyPyClass ... '); class MyPyClass:; def __init__(self):; print('in MyPyClass.__init__'); self._browser = None; def gime(self, what):; return what; ```. This module can now be loaded into a Cling session, the class used to; instantiate objects, and their member functions called for showing how; different types can cross:. ``` {.cpp}; root[] TPython::LoadMacro(""MyPyClass.py"");; creating class MyPyClass ...; root[] MyPyClass m;; in MyPyClass.__init__; root[] char* s = m.gime(""aap"");; root[] s; (char* 0x41ee7754)""aap""; ```. Note that the `LoadMacro()` call makes the class automatically; available, such that it can be used directly. Otherwise, a; `gROOT->GetClass()` call is required first. #### Callbacks. The simplest way of setting a callback to Python from Cling, e.g. for a; button, is by providing the execution string. See for example; `tutorials/pyroot/demo.py` that comes with the ROOT installation:. ``` {.cpp}; # [..]; bar = ROOT.TControlBar('vertical','Demos'); bar.AddButton('Help on Demos',r'TPython::Exec(""execfile('demoshelp.py')"");','Click Here For Help on Running the Demos'); bar.AddButton('browser',r'TPython::Exec(""b = Tbrowser()"");','Start the ROOT browser'); # [..]; ```. Here, the callback is a string that wil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:17825,load,loaded,17825,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['load'],['loaded']
Performance,"ll be lowered to a platform-specific; sequence. This calling convention aims to minimize overhead in the caller by; preserving as many registers as possible (all the registers that are; preserved on the fast path, composed of the entry and exit blocks). This calling convention behaves identical to the `C` calling convention on; how arguments and return values are passed, but it uses a different set of; caller/callee-saved registers. Given that each platform has its own lowering sequence, hence its own set; of preserved registers, we can't use the existing `PreserveMost`. - On X86-64 the callee preserves all general purpose registers, except for; RDI and RAX.; ""``tailcc``"" - Tail callable calling convention; This calling convention ensures that calls in tail position will always be; tail call optimized. This calling convention is equivalent to fastcc,; except for an additional guarantee that tail calls will be produced; whenever possible. `Tail calls can only be optimized when this, the fastcc,; the GHC or the HiPE convention is used. <CodeGenerator.html#tail-call-optimization>`_; This calling convention does not support varargs and requires the prototype of; all callees to exactly match the prototype of the function definition.; ""``swiftcc``"" - This calling convention is used for Swift language.; - On X86-64 RCX and R8 are available for additional integer returns, and; XMM2 and XMM3 are available for additional FP/vector returns.; - On iOS platforms, we use AAPCS-VFP calling convention.; ""``swifttailcc``""; This calling convention is like ``swiftcc`` in most respects, but also the; callee pops the argument area of the stack so that mandatory tail calls are; possible as in ``tailcc``.; ""``cfguard_checkcc``"" - Windows Control Flow Guard (Check mechanism); This calling convention is used for the Control Flow Guard check function,; calls to which can be inserted before indirect calls to check that the call; target is a valid function address. The check function has no re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:21199,optimiz,optimized,21199,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimized']
Performance,"ll call; MCJIT::finalizeObject to complete the remapping process. Final Preparations; ==================. When MCJIT::finalizeObject is called, MCJIT calls; RuntimeDyld::resolveRelocations. This function will attempt to locate any; external symbols and then apply all relocations for the object. External symbols are resolved by calling the memory manager's; getPointerToNamedFunction method. The memory manager will return the; address of the requested symbol in the target address space. (Note, this; may not be a valid pointer in the host process.) RuntimeDyld will then; iterate through the list of relocations it has stored which are associated; with this symbol and invoke the resolveRelocation method which, through an; format-specific implementation, will apply the relocation to the loaded; section memory. Next, RuntimeDyld::resolveRelocations iterates through the list of; sections and for each section iterates through a list of relocations that; have been saved which reference that symbol and call resolveRelocation for; each entry in this list. The relocation list here is a list of; relocations for which the symbol associated with the relocation is located; in the section associated with the list. Each of these locations will; have a target location at which the relocation will be applied that is; likely located in a different section. .. image:: MCJIT-resolve-relocations.png. Once relocations have been applied as described above, MCJIT calls; RuntimeDyld::getEHFrameSection, and if a non-zero result is returned; passes the section data to the memory manager's registerEHFrames method.; This allows the memory manager to call any desired target-specific; functions, such as registering the EH frame information with a debugger. Finally, MCJIT calls the memory manager's finalizeMemory method. In this; method, the memory manager will invalidate the target code cache, if; necessary, and apply final permissions to the memory pages it has; allocated for code and data memory.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:8607,cache,cache,8607,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,1,['cache'],['cache']
Performance,"ll render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this RO",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23398,load,loaded,23398,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['load'],['loaded']
Performance,"ll use it rather; than the tree from which it was created. - `void Init(TTree *tree) -` it is called by the constructor to; initialize the tree for reading. It associates each branch with the; corresponding leaf data member. - `~MyClass() - `the destructor, nothing special. - `Int_t GetEntry(Int_t entry) -` it loads the class with the entry; specified. Once you have executed `GetEntry`, the leaf data members; in `MyClass` are set to the values of the entry. For example,; `GetEntry(12)` loads the 13th event into the event data member of; `MyClass` (note that the first entry is 0). `GetEntry` returns the; number of bytes read from the file. In case the same entry is read; twice, ROOT does not have to do any I/O. In this case `GetEntry`; returns 1. It does not return 0, because many people assume a return; of 0 means an error has occurred while reading. - `Int_t LoadTree(Int_t entry)` and `void Notify()` - these two; methods are related to chains. `LoadTree` will load the tree; containing the specified entry from a chain of trees. Notify is; called by `LoadTree` to adjust the branch addresses. - `void Loop()` - it is the skeleton method that loops through each; entry of the tree. This is interesting to us, because we will need; to customize it for our analysis. ### MyClass.C. `MyClass::Loop` consists of a for-loop calling `GetEntry` for each; entry. In the template, the numbers of bytes are added up, but it does; nothing else. If we were to execute it now, there would be no output. ``` {.cpp}; void MyClass::Loop() {; if (fChain == 0) return;. Int_t nentries = Int_t(fChain->GetEntries());; Int_t nbytes = 0, nb = 0;; for (Int_t jentry=0; jentry<nentries;jentry++) {; Int_t ientry = LoadTree(jentry);; // in case of a TChain , ientry is the entry number in the; // current file; nb = fChain->GetEntry(jentry); nbytes += nb;; // if (Cut(ientry) < 0) continue;; }; }; ```. At the beginning of the file are instructions about reading selected; branches. They are not reprinted here,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:127724,load,load,127724,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['load']
Performance,"ll; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:262298,perform,performing,262298,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"llc building x86_64 code aren't; incredibly helpful if you're going to be targeting ARM. By default, the script above does two things to get solid coverage. It:. - runs all of Clang and LLVM's lit tests, and; - uses the instrumented Clang to build Clang, LLVM, and all of the other; LLVM subprojects available to it. Together, these should give you:. - solid coverage of building C++,; - good coverage of building C,; - great coverage of running optimizations,; - great coverage of the backend for your host's architecture, and; - some coverage of other architectures (if other arches are supported backends). Altogether, this should cover a diverse set of uses for Clang and LLVM. If you; have very specific needs (e.g. your compiler is meant to compile a large browser; for four different platforms, or similar), you may want to do something else.; This is configurable in the script itself. Building Clang with PGO; =======================. If you prefer to not use the script or the cmake cache, this briefly goes over; how to build Clang/LLVM with PGO. First, you should have at least LLVM, Clang, and compiler-rt checked out; locally. Next, at a high level, you're going to need to do the following:. 1. Build a standard Release Clang and the relevant libclang_rt.profile library; 2. Build Clang using the Clang you built above, but with instrumentation; 3. Use the instrumented Clang to generate profiles, which consists of two steps:. - Running the instrumented Clang/LLVM/lld/etc. on tasks that represent how; users will use said tools.; - Using a tool to convert the ""raw"" profiles generated above into a single,; final PGO profile. 4. Build a final release Clang (along with whatever other binaries you need); using the profile collected from your benchmark. In more detailed steps:. 1. Configure a Clang build as you normally would. It's highly recommended that; you use the Release configuration for this, since it will be used to build; another Clang. Because you need Clang and support",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWithPGO.rst:2876,cache,cache,2876,interpreter/llvm-project/llvm/docs/HowToBuildWithPGO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildWithPGO.rst,1,['cache'],['cache']
Performance,"lling convention; specified for the call. The calling convention of any pair of dynamic; caller/callee must match, or the behavior of the program is undefined.; The following calling conventions are supported by LLVM, and more may be; added in the future:. ""``ccc``"" - The C calling convention; This calling convention (the default if no other calling convention; is specified) matches the target C calling conventions. This calling; convention supports varargs function calls and tolerates some; mismatch in the declared prototype and implemented declaration of; the function (as does normal C).; ""``fastcc``"" - The fast calling convention; This calling convention attempts to make calls as fast as possible; (e.g. by passing things in registers). This calling convention; allows the target to use whatever tricks it wants to produce fast; code for the target, without having to conform to an externally; specified ABI (Application Binary Interface). `Tail calls can only; be optimized when this, the tailcc, the GHC or the HiPE convention is; used. <CodeGenerator.html#tail-call-optimization>`_ This calling; convention does not support varargs and requires the prototype of all; callees to exactly match the prototype of the function definition.; ""``coldcc``"" - The cold calling convention; This calling convention attempts to make code in the caller as; efficient as possible under the assumption that the call is not; commonly executed. As such, these calls often preserve all registers; so that the call does not break any live ranges in the caller side.; This calling convention does not support varargs and requires the; prototype of all callees to exactly match the prototype of the; function definition. Furthermore the inliner doesn't consider such function; calls for inlining.; ""``ghccc``"" - GHC convention; This calling convention has been implemented specifically for use by; the `Glasgow Haskell Compiler (GHC) <http://www.haskell.org/ghc>`_.; It passes everything in registers, going ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:12803,optimiz,optimized,12803,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimized']
Performance,"lling the ``emit`` method of its base; layer. For example, in this tutorial our IRTransformLayer calls through to; our IRCompileLayer to compile the transformed IR, and our IRCompileLayer in; turn calls our ObjectLayer to link the object file produced by our compiler. So far we have learned how to optimize and compile our LLVM IR, but we have; not focused on when compilation happens. Our current REPL optimizes and; compiles each function as soon as it is referenced by any other code,; regardless of whether it is ever called at runtime. In the next chapter we; will introduce a fully lazy compilation, in which functions are not compiled; until they are first called at run-time. At this point the trade-offs get much; more interesting: the lazier we are, the quicker we can start executing the; first function, but the more often we will have to pause to compile newly; encountered functions. If we only code-gen lazily, but optimize eagerly, we; will have a longer startup time (as everything is optimized at that time) but; relatively short pauses as each function just passes through code-gen. If we; both optimize and code-gen lazily we can start executing the first function; more quickly, but we will have longer pauses as each function has to be both; optimized and code-gen'd when it is first executed. Things become even more; interesting if we consider interprocedural optimizations like inlining, which; must be performed eagerly. These are complex trade-offs, and there is no; one-size-fits all solution to them, but by providing composable layers we leave; the decisions to the person implementing the JIT, and make it easy for them to; experiment with different configurations. `Next: Adding Per-function Lazy Compilation <BuildingAJIT3.html>`_. Full Code Listing; =================. Here is the complete code listing for our running example with an; IRTransformLayer added to enable optimization. To build this example, use:. .. code-block:: bash. # Compile; clang++ -g toy.cpp `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:11018,optimiz,optimize,11018,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,2,['optimiz'],"['optimize', 'optimized']"
Performance,"lling the function. ``` {.cpp}; TEntryList::GetEntryList(const char *treename, const char *filename); ```. and then be used to construct a new **`TEntryList`** for a new; **`TChain`**, or processed independently as normal **`TEntryList`**(s); for **`TTree`**(s). This modularity makes **`TEntryList`** much better; suited for PROOF processing than the **`TEventList`**. #### Using an Event List. A **`TEventList`** or a **`TEntryList`** can be used to limit the; **`TTree`** to the events in the list. The methods `SetEventList` and; `SetEntryList` tell the tree to use the list and hence limit all; subsequent calls to `Draw`, `Scan`, `Process`, `Query`, `Principal` and; `CopyTree` methods to the entries in the list. In general, it affects; the `GetEntryNumber` method and all functions using it for looping over; the tree entries. The `GetEntry` and `GetEntries` methods are not; affected. Note, that in the `SetEventList` method, the **`TEventList`**; argument is internally transformed into a **`TEntryList`**, and this; operation, in case of a **`TChain`**, requires loading of all the tree; headers. In this example, we create a list with all entries with more; than 600 tracks and then set it so that the tree will use this list. To; reset the **`TTree`** to use all events use `SetEventList(0)` or; `SetEntryList(0)`. 1. Let's look at an example. First, open the file and draw the; `fNtrack`. ``` {.cpp}; root[] TFile *f = new TFile(""Event.root"");; root[] TTree *T = (TTree*)f->Get(""T"");; root[] T->Draw(""fNtrack"");; ```. 2. Now, put the entries with over 600 tracks into a **`TEntryList`**; called `myList`. We get the list from the current directory and assign; it to a variable list. ``` {.cpp}; root[] T->Draw("">>myList"",""fNtrack > 600"",""entrylist"");; root[] TEntryList *list=(TEntryList*)gDirectory->Get(""myList"");; ```. 3. Instruct the tree **`T`** to use the new list and draw it again. Note; that this is exactly the same `Draw` command. The list limits the; entries. ``` {.cpp}; ro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:111240,load,loading,111240,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['loading']
Performance,"llocas, we'll use a helper; function that ensures that the allocas are created in the entry block of; the function:. .. code-block:: c++. /// CreateEntryBlockAlloca - Create an alloca instruction in the entry block of; /// the function. This is used for mutable variables etc.; static AllocaInst *CreateEntryBlockAlloca(Function *TheFunction,; const std::string &VarName) {; IRBuilder<> TmpB(&TheFunction->getEntryBlock(),; TheFunction->getEntryBlock().begin());; return TmpB.CreateAlloca(Type::getDoubleTy(*TheContext), nullptr,; VarName);; }. This funny looking code creates an IRBuilder object that is pointing at; the first instruction (.begin()) of the entry block. It then creates an; alloca with the expected name and returns it. Because all values in; Kaleidoscope are doubles, there is no need to pass in a type to use. With this in place, the first functionality change we want to make belongs to; variable references. In our new scheme, variables live on the stack, so; code generating a reference to them actually needs to produce a load; from the stack slot:. .. code-block:: c++. Value *VariableExprAST::codegen() {; // Look this variable up in the function.; AllocaInst *A = NamedValues[Name];; if (!A); return LogErrorV(""Unknown variable name"");. // Load the value.; return Builder->CreateLoad(A->getAllocatedType(), A, Name.c_str());; }. As you can see, this is pretty straightforward. Now we need to update; the things that define the variables to set up the alloca. We'll start; with ``ForExprAST::codegen()`` (see the `full code listing <#id1>`_ for; the unabridged code):. .. code-block:: c++. Function *TheFunction = Builder->GetInsertBlock()->getParent();. // Create an alloca for the variable in the entry block.; AllocaInst *Alloca = CreateEntryBlockAlloca(TheFunction, VarName);. // Emit the start code first, without 'variable' in scope.; Value *StartVal = Start->codegen();; if (!StartVal); return nullptr;. // Store the value into the alloca.; Builder->CreateStore(StartV",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:13843,load,load,13843,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance,"llocated by mechanisms provided by LLVM. A pointer value is *based* on another pointer value according to the; following rules:. - A pointer value formed from a scalar ``getelementptr`` operation is *based* on; the pointer-typed operand of the ``getelementptr``.; - The pointer in lane *l* of the result of a vector ``getelementptr`` operation; is *based* on the pointer in lane *l* of the vector-of-pointers-typed operand; of the ``getelementptr``.; - The result value of a ``bitcast`` is *based* on the operand of the; ``bitcast``.; - A pointer value formed by an ``inttoptr`` is *based* on all pointer; values that contribute (directly or indirectly) to the computation of; the pointer's value.; - The ""*based* on"" relationship is transitive. Note that this definition of *""based""* is intentionally similar to the; definition of *""based""* in C99, though it is slightly weaker. LLVM IR does not associate types with memory. The result type of a; ``load`` merely indicates the size and alignment of the memory from; which to load, as well as the interpretation of the value. The first; operand type of a ``store`` similarly only indicates the size and; alignment of the store. Consequently, type-based alias analysis, aka TBAA, aka; ``-fstrict-aliasing``, is not applicable to general unadorned LLVM IR.; :ref:`Metadata <metadata>` may be used to encode additional information; which specialized optimization passes may use to implement type-based; alias analysis. .. _pointercapture:. Pointer Capture; ---------------. Given a function call and a pointer that is passed as an argument or stored in; the memory before the call, a pointer is *captured* by the call if it makes a; copy of any part of the pointer that outlives the call.; To be precise, a pointer is captured if one or more of the following conditions; hold:. 1. The call stores any bit of the pointer carrying information into a place,; and the stored bits can be read from the place by the caller after this call; exits. .. code-bloc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:143323,load,load,143323,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['load'],['load']
Performance,"llocated during its execution; without this retain and release. Since it's extremely uncommon to actually; do so, even unintentionally, and since there's no natural way for the; programmer to remove this retain/release pair otherwise (as there is for; other parameters by, say, making the variable ``objc_externally_retained`` or; qualifying it with ``__unsafe_unretained``), we chose to make this optimizing; assumption and shift some amount of risk to the user. .. _arc.misc.enumeration:. Fast enumeration iteration variables; ------------------------------------. If a variable is declared in the condition of an Objective-C fast enumeration; loop, and the variable has no explicit ownership qualifier, then it is; implicitly :ref:`externally-retained <arc.misc.externally_retained>` so that; objects encountered during the enumeration are not actually retained and; released. .. admonition:: Rationale. This is an optimization made possible because fast enumeration loops promise; to keep the objects retained during enumeration, and the collection itself; cannot be synchronously modified. It can be overridden by explicitly; qualifying the variable with ``__strong``, which will make the variable; mutable again and cause the loop to retain the objects it encounters. .. _arc.misc.blocks:. Blocks; ------. The implicit ``const`` capture variables created when evaluating a block; literal expression have the same ownership semantics as the local variables; they capture. The capture is performed by reading from the captured variable; and initializing the capture variable with that value; the capture variable is; destroyed when the block literal is, i.e. at the end of the enclosing scope. The :ref:`inference <arc.ownership.inference>` rules apply equally to; ``__block`` variables, which is a shift in semantics from non-ARC, where; ``__block`` variables did not implicitly retain during capture. ``__block`` variables of retainable object owner type are moved off the stack; by initializin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:95799,optimiz,optimization,95799,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimization']
Performance,"llocator; ---------; Scudo was designed with security in mind, but aims at striking a good balance; between security and performance. It was designed to be highly tunable and; configurable, and while we provide some default configurations, we encourage; consumers to come up with the parameters that will work best for their use; cases. The allocator combines several components that serve distinct purposes:. - the Primary allocator: fast and efficient, it services smaller allocation; sizes by carving reserved memory regions into blocks of identical size. There; are currently two Primary allocators implemented, specific to 32 and 64 bit; architectures. It is configurable via compile time options. - the Secondary allocator: slower, it services larger allocation sizes via the; memory mapping primitives of the underlying operating system. Secondary backed; allocations are surrounded by Guard Pages. It is also configurable via compile; time options. - the thread specific data Registry: defines how local caches operate for each; thread. There are currently two models implemented: the exclusive model where; each thread holds its own caches (using the ELF TLS); or the shared model; where threads share a fixed size pool of caches. - the Quarantine: offers a way to delay the deallocation operations, preventing; blocks to be immediately available for reuse. Blocks held will be recycled; once certain size criteria are reached. This is essentially a delayed freelist; which can help mitigate some use-after-free situations. This feature is fairly; costly in terms of performance and memory footprint, is mostly controlled by; runtime options and is disabled by default. Allocations Header; ------------------; Every chunk of heap memory returned to an application by the allocator will be; preceded by a header. This has two purposes:. - being to store various information about the chunk, that can be leveraged to; ensure consistency of the heap operations;. - being able to detect potentia",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:1815,cache,caches,1815,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['cache'],['caches']
Performance,"llowed by glue nodes. A SelectionDAG has designated ""Entry"" and ""Root"" nodes. The Entry node is; always a marker node with an Opcode of ``ISD::EntryToken``. The Root node is; the final side-effecting node in the token chain. For example, in a single basic; block function it would be the return node. One important concept for SelectionDAGs is the notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a target is one that only uses supported; operations and supported types. On a 32-bit PowerPC, for example, a DAG with a; value of type i1, i8, i16, or i64 would be illegal, as would a DAG that uses a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:36974,perform,performs,36974,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['perform'],['performs']
Performance,"llowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract machine model comes for collectors; which need to model potentially relocatable objects. For a compiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the opt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:5968,load,load,5968,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,2,['load'],"['load', 'loaded']"
Performance,"llowing syntax will set a bisect limit for LTO transformations:. ::. # When using lld, or ld64 (macOS); clang -flto -Wl,-mllvm,-opt-bisect-limit=256 my_file.o my_other_file.o; # When using Gold; clang -flto -Wl,-plugin-opt,-opt-bisect-limit=256 my_file.o my_other_file.o. LTO passes are run by a library instance invoked by the linker. Therefore any; passes run in the primary driver compilation phase are not affected by options; passed via '-Wl,-plugin-opt' and LTO passes are not affected by options; passed to the driver-invoked LLVM invocation via '-mllvm'. Passing ``-opt-bisect-print-ir-path=path/foo.ll`` will dump the IR to; ``path/foo.ll`` when -opt-bisect-limit starts skipping passes. Bisection Index Values; ======================. The granularity of the optimizations associated with a single index value is; variable. Depending on how the optimization pass has been instrumented the; value may be associated with as much as all transformations that would have; been performed by an optimization pass on an IR unit for which it is invoked; (for instance, during a single call of runOnFunction for a FunctionPass) or as; little as a single transformation. The index values may also be nested so that; if an invocation of the pass is not skipped individual transformations within; that invocation may still be skipped. The order of the values assigned is guaranteed to remain stable and consistent; from one run to the next up to and including the value specified as the limit.; Above the limit value skipping of optimizations can cause a change in the; numbering, but because all optimizations above the limit are skipped this; is not a problem. When an opt-bisect index value refers to an entire invocation of the run; function for a pass, the pass will query whether or not it should be skipped; each time it is invoked and each invocation will be assigned a unique value.; For example, if a FunctionPass is used with a module containing three functions; a different index value will b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst:3620,optimiz,optimization,3620,interpreter/llvm-project/llvm/docs/OptBisect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst,3,"['optimiz', 'perform']","['optimization', 'performed']"
Performance,"llowing targets (currently never natively):. * 32-bit ARM; * 64-bit ARM (AArch64); * RISC-V; * X86 (when SSE2 is available). (For X86, SSE2 is available on 64-bit and all recent 32-bit processors.). ``__fp16`` and ``_Float16`` both use the binary16 format from IEEE; 754-2008, which provides a 5-bit exponent and an 11-bit significand; (counting the implicit leading 1). ``__bf16`` uses the `bfloat16; <https://en.wikipedia.org/wiki/Bfloat16_floating-point_format>`_ format,; which provides an 8-bit exponent and an 8-bit significand; this is the same; exponent range as `float`, just with greatly reduced precision. ``_Float16`` and ``__bf16`` follow the usual rules for arithmetic; floating-point types. Most importantly, this means that arithmetic operations; on operands of these types are formally performed in the type and produce; values of the type. ``__fp16`` does not follow those rules: most operations; immediately promote operands of type ``__fp16`` to ``float``, and so; arithmetic operations are defined to be performed in ``float`` and so result in; a value of type ``float`` (unless further promoted because of other operands).; See below for more information on the exact specifications of these types. When compiling arithmetic on ``_Float16`` and ``__bf16`` for a target without; native support, Clang will perform the arithmetic in ``float``, inserting; extensions and truncations as necessary. This can be done in a way that; exactly matches the operation-by-operation behavior of native support,; but that can require many extra truncations and extensions. By default,; when emulating ``_Float16`` and ``__bf16`` arithmetic using ``float``, Clang; does not truncate intermediate operands back to their true type unless the; operand is the result of an explicit cast or assignment. This is generally; much faster but can generate different results from strict operation-by-operation; emulation. Usually the results are more precise. This is permitted by the; C and C++ standards ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:32015,perform,performed,32015,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['perform'],['performed']
Performance,"llowing the; compiler to use a more efficient but less accurate method of computing; it. ULP is defined as follows:. If ``x`` is a real number that lies between two finite consecutive; floating-point numbers ``a`` and ``b``, without being equal to one; of them, then ``ulp(x) = |b - a|``, otherwise ``ulp(x)`` is the; distance between the two non-equal finite floating-point numbers; nearest ``x``. Moreover, ``ulp(NaN)`` is ``NaN``. The metadata node shall consist of a single positive float type number; representing the maximum relative error, for example:. .. code-block:: llvm. !0 = !{ float 2.5 } ; maximum acceptable inaccuracy is 2.5 ULPs. .. _range-metadata:. '``range``' Metadata; ^^^^^^^^^^^^^^^^^^^^. ``range`` metadata may be attached only to ``load``, ``call`` and ``invoke`` of; integer or vector of integer types. It expresses the possible ranges the loaded; value or the value returned by the called function at this call site is in. If; the loaded or returned value is not in the specified range, a poison value is; returned instead. The ranges are represented with a flattened list of integers.; The loaded value or the value returned is known to be in the union of the ranges; defined by each consecutive pair. Each pair has the following properties:. - The type must match the scalar type of the instruction.; - The pair ``a,b`` represents the range ``[a,b)``.; - Both ``a`` and ``b`` are constants.; - The range is allowed to wrap.; - The range should not represent the full or empty set. That is,; ``a!=b``. In addition, the pairs must be in signed order of the lower bound and; they must be non-contiguous. For vector-typed instructions, the range is applied element-wise. Examples:. .. code-block:: llvm. %a = load i8, ptr %x, align 1, !range !0 ; Can only be 0 or 1; %b = load i8, ptr %y, align 1, !range !1 ; Can only be 255 (-1), 0 or 1; %c = call i8 @foo(), !range !2 ; Can only be 0, 1, 3, 4 or 5; %d = invoke i8 @bar() to label %cont; unwind label %lpad, !range !3 ; Can",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:285024,load,loaded,285024,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loaded']
Performance,"llowing; buffer_wbinvl1_vol.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently mo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:268309,load,load,268309,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"lls is really just an; application of the existing C/C++ rule about calling functions through an; incompatible function type, but it's useful to state it explicitly. .. _arc.object.operands.retained-return-values:. Retained return values; ^^^^^^^^^^^^^^^^^^^^^^. A function or method which returns a retainable object pointer type may be; marked as returning a retained value, signifying that the caller expects to take; ownership of a +1 retain count. This is done by adding the; ``ns_returns_retained`` attribute to the function or method declaration, like; so:. .. code-block:: objc. id foo(void) __attribute((ns_returns_retained));; - (id) foo __attribute((ns_returns_retained));. This attribute is part of the type of the function or method. When returning from such a function or method, ARC retains the value at the; point of evaluation of the return statement, before leaving all local scopes. When receiving a return result from such a function or method, ARC releases the; value at the end of the full-expression it is contained within, subject to the; usual optimizations for local values. .. admonition:: Rationale. This formalizes direct transfers of ownership from a callee to a caller. The; most common scenario this models is the retained return from ``init``,; ``alloc``, ``new``, and ``copy`` methods, but there are other cases in the; frameworks. After optimization there are typically no extra retains and; releases required. Methods in the ``alloc``, ``copy``, ``init``, ``mutableCopy``, and ``new``; :ref:`families <arc.method-families>` are implicitly marked; ``__attribute__((ns_returns_retained))``. This may be suppressed by explicitly; marking the method ``__attribute__((ns_returns_not_retained))``. It is undefined behavior if the method to which an Objective-C message send; statically resolves has different retain semantics on its result from the; method it dynamically resolves to. It is undefined behavior if a block or; function call is made through a static type wi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:19917,optimiz,optimizations,19917,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizations']
Performance,"llvm-cxxmap - Mangled name remapping tool; =========================================. .. program:: llvm-cxxmap. SYNOPSIS; --------. :program:`llvm-cxxmap` [*options*] *symbol-file-1* *symbol-file-2*. DESCRIPTION; -----------. The :program:`llvm-cxxmap` tool performs fuzzy matching of C++ mangled names,; based on a file describing name components that should be considered equivalent. The symbol files should contain a list of C++ mangled names (one per line).; Blank lines and lines starting with ``#`` are ignored. The output is a list; of pairs of equivalent symbols, one per line, of the form. .. code-block:: none. <symbol-1> <symbol-2>. where ``<symbol-1>`` is a symbol from *symbol-file-1* and ``<symbol-2>`` is; a symbol from *symbol-file-2*. Mappings for which the two symbols are identical; are omitted. OPTIONS; -------. .. program:: llvm-cxxmap. .. option:: -remapping-file=file, -r=file. Specify a file containing a list of equivalence rules that should be used; to determine whether two symbols are equivalent. Required.; See :ref:`remapping-file`. .. option:: -output=file, -o=file. Specify a file to write the list of matched names to. If unspecified, the; list will be written to stdout. .. option:: -Wambiguous. Produce a warning if there are multiple equivalent (but distinct) symbols in; *symbol-file-2*. .. option:: -Wincomplete. Produce a warning if *symbol-file-1* contains a symbol for which there is no; equivalent symbol in *symbol-file-2*. .. _remapping-file:. REMAPPING FILE; --------------. The remapping file is a text file containing lines of the form. .. code-block:: none. fragmentkind fragment1 fragment2. where ``fragmentkind`` is one of ``name``, ``type``, or ``encoding``,; indicating whether the following mangled name fragments are; <`name <http://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangle.name>`_>s,; <`type <http://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangle.type>`_>s, or; <`encoding <http://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangle.en",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cxxmap.rst:258,perform,performs,258,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cxxmap.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cxxmap.rst,1,['perform'],['performs']
Performance,"llvm-diff - LLVM structural 'diff'; ==================================. .. program:: llvm-diff. SYNOPSIS; --------. **llvm-diff** [*options*] *module 1* *module 2* [*global name ...*]. DESCRIPTION; -----------. **llvm-diff** compares the structure of two LLVM modules, primarily; focusing on differences in function definitions. Insignificant; differences, such as changes in the ordering of globals or in the; names of local values, are ignored. An input module will be interpreted as an assembly file if its name; ends in '.ll'; otherwise it will be read in as a bitcode file. If a list of global names is given, just the values with those names; are compared; otherwise, all global values are compared, and; diagnostics are produced for globals which only appear in one module; or the other. **llvm-diff** compares two functions by comparing their basic blocks,; beginning with the entry blocks. If the terminators seem to match,; then the corresponding successors are compared; otherwise they are; ignored. This algorithm is very sensitive to changes in control flow,; which tend to stop any downstream changes from being detected. **llvm-diff** is intended as a debugging tool for writers of LLVM; passes and frontends. It does not have a stable output format. EXIT STATUS; -----------. If **llvm-diff** finds no differences between the modules, it will exit; with 0 and produce no output. Otherwise it will exit with a non-zero; value. BUGS; ----. Many important differences, like changes in linkage or function; attributes, are not diagnosed. Changes in memory behavior (for example, coalescing loads) can cause; massive detected differences in blocks.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-diff.rst:1602,load,loads,1602,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-diff.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-diff.rst,1,['load'],['loads']
Performance,"llvm-exegesis - LLVM Machine Instruction Benchmark; ==================================================. .. program:: llvm-exegesis. SYNOPSIS; --------. :program:`llvm-exegesis` [*options*]. DESCRIPTION; -----------. :program:`llvm-exegesis` is a benchmarking tool that uses information available; in LLVM to measure host machine instruction characteristics like latency,; throughput, or port decomposition. Given an LLVM opcode name and a benchmarking mode, :program:`llvm-exegesis`; generates a code snippet that makes execution as serial (resp. as parallel) as; possible so that we can measure the latency (resp. inverse throughput/uop decomposition); of the instruction.; The code snippet is jitted and, unless requested not to, executed on the; host subtarget. The time taken (resp. resource usage) is measured using; hardware performance counters. The result is printed out as YAML; to the standard output. The main goal of this tool is to automatically (in)validate the LLVM's TableDef; scheduling models. To that end, we also provide analysis of the results. :program:`llvm-exegesis` can also benchmark arbitrary user-provided code; snippets. SUPPORTED PLATFORMS; -------------------. :program:`llvm-exegesis` currently only supports X86 (64-bit only), ARM (AArch64; only), MIPS, and PowerPC (PowerPC64LE only) on Linux for benchmarking. Not all; benchmarking functionality is guaranteed to work on every platform.; :program:`llvm-exegesis` also has a separate analysis mode that is supported; on every platform that LLVM is. SNIPPET ANNOTATIONS; -------------------. :program:`llvm-exegesis` supports benchmarking arbitrary snippets of assembly.; However, benchmarking these snippets often requires some setup so that they; can execute properly. :program:`llvm-exegesis` has five annotations and some; additional utilities to help with setup so that snippets can be benchmarked; properly. * `LLVM-EXEGESIS-DEFREG <register name>` - Adding this annotation to the text; assembly snippet to be be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:362,latency,latency,362,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,5,"['latency', 'perform', 'throughput']","['latency', 'performance', 'throughput']"
Performance,"llvm-mca - LLVM Machine Code Analyzer; =====================================. .. program:: llvm-mca. SYNOPSIS; --------. :program:`llvm-mca` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-mca` is a performance analysis tool that uses information; available in LLVM (e.g. scheduling models) to statically measure the performance; of machine code in a specific CPU. Performance is measured in terms of throughput as well as processor resource; consumption. The tool currently works for processors with a backend for which; there is a scheduling model available in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:213,perform,performance,213,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,5,"['perform', 'throughput']","['performance', 'throughput']"
Performance,"llvm-opt-report - generate optimization report from YAML; ========================================================. .. program:: llvm-opt-report. SYNOPSIS; --------. :program:`llvm-opt-report` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-opt-report` is a tool to generate an optimization report from YAML optimization record files. You need to create an input YAML optimization record file before running :program:`llvm-opt-report`. It provides information on the execution time, memory usage, and other details of each optimization pass. .. code-block:: console. $ clang -c foo.c -o foo.o -O3 -fsave-optimization-record. Then, you create a report using the :program:`llvm-opt-report` command with the YAML optimization record file :file:`foo.opt.yaml` as input. .. code-block:: console. $ llvm-opt-report foo.opt.yaml -o foo.lst. foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:27,optimiz,optimization,27,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,8,['optimiz'],"['optimization', 'optimization-record']"
Performance,"llvm-otool - Mach-O dumping tool; ================================. .. program:: llvm-otool. SYNOPSIS; --------. :program:`llvm-otool` [*option...*] *[file...]*. DESCRIPTION; -----------. :program:`llvm-otool` is a tool for dumping Mach-O files. It attempts to be command-line-compatible and output-compatible with macOS's; :program:`otool`. OPTIONS; -------. .. option:: -arch <value>. Select slice of universal Mach-O file. .. option:: -chained_fixups. Print chained fixup information. .. option:: -C. Print linker optimization hints. .. option:: -dyld_info. Print bind and rebase information. .. option:: -D. Print shared library id. .. option:: -d. Print data section. .. option:: -f. Print universal headers. .. option:: -G. Print data-in-code table. .. option:: --help-hidden. Print help for hidden flags. .. option:: --help. Print help. .. option:: -h. Print mach header. .. option:: -I. Print indirect symbol table. .. option:: -j. Print opcode bytes. .. option:: -L. Print used shared libraries. .. option:: -l. Print load commands. .. option:: -mcpu=<value>. Select cpu for disassembly. .. option:: -o. Print Objective-C segment. .. option:: -P. Print __TEXT,__info_plist section as strings. .. option:: -p <function name>. Start disassembly at <function name>. .. option:: -r. Print relocation entries. .. option:: -s <segname> <sectname>. Print contents of section. .. option:: -t. Print text section. .. option:: --version. Print version. .. option:: -V. Symbolize disassembled operands (implies :option:`-v`). .. option:: -v. Verbose output / disassemble when printing text sections. .. option:: -X. Omit leading addresses or headers. .. option:: -x. Print all text sections. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. EXIT STATUS; -----------. :program:`llvm-otool` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst:517,optimiz,optimization,517,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst,1,['optimiz'],['optimization']
Performance,"llvm-profgen - LLVM SPGO profile generation tool; ================================================. .. program:: llvm-profgen. SYNOPSIS; --------. :program:`llvm-profgen` [*commands*] [*options*]. DESCRIPTION; -----------. The :program:`llvm-profgen` utility generates a profile data file; from given perf script data files for sample-based profile guided; optimization(SPGO). COMMANDS; --------; At least one of the following commands are required:. .. option:: --perfscript=<string[,string,...]>. Path of perf-script trace created by Linux perf tool with `script`; command(the raw perf.data should be profiled with -b). .. option:: --binary=<string[,string,...]>. Path of the input profiled binary files. .. option:: --output=<string>. Path of the output profile file. OPTIONS; -------; :program:`llvm-profgen` supports the following options:. .. option:: --format=[text|binary|extbinary|compbinary|gcc]. Specify the format of the generated profile. Supported <format> are `text`,; `binary`, `extbinary`, `compbinary`, `gcc`, see `llvm-profdata` for more; descriptions of the format. .. option:: --show-mmap-events. Print mmap events. .. option:: --show-disassembly. Print disassembled code. .. option:: --x86-asm-syntax=[att|intel]. Specify whether to print assembly code in AT&T syntax (the default) or Intel; syntax.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profgen.rst:357,optimiz,optimization,357,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profgen.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profgen.rst,1,['optimiz'],['optimization']
Performance,"llvm-tli-checker - TargetLibraryInfo vs library checker; =======================================================. .. program:: llvm-tli-checker. SYNOPSIS; --------. :program:`llvm-tli-checker` [*options*] [*library-file...*]. DESCRIPTION; -----------. :program:`llvm-tli-checker` compares TargetLibraryInfo's opinion of the; availability of library functions against the set of functions exported; by the specified library files, reporting any disagreements between TLI's; opinion and whether the function is actually present. This is primarily; useful for vendors to ensure the TLI for their target is correct, and; the compiler will not ""optimize"" some code sequence into a library call; that is not actually available. EXAMPLE; -------. .. code-block:: console. $ llvm-tli-checker --triple x86_64-scei-ps4 example.so; TLI knows 466 symbols, 235 available for 'x86_64-scei-ps4'. Looking for symbols in 'example.so'; Found 235 global function symbols in 'example.so'; Found a grand total of 235 library symbols; << TLI yes SDK no: '_ZdaPv' aka operator delete[](void*); >> TLI no SDK yes: '_ZdaPvj' aka operator delete[](void*, unsigned int); << Total TLI yes SDK no: 1; >> Total TLI no SDK yes: 1; == Total TLI yes SDK yes: 234; FAIL: LLVM TLI doesn't match SDK libraries. OPTIONS; -------. .. option:: --dump-tli. Print ""available""/""not available"" for each library function, according to; TargetLibraryInfo's information for the specified triple, and exit. This; option does not read any input files. .. option:: --help, -h. Print a summary of command line options and exit. .. option:: --libdir=<directory>. A base directory to prepend to each library file path. This is handy; when there are a number of library files all in the same directory, or; a list of input filenames are kept in a response file. .. option:: --report=<level>. The amount of information to report. <level> can be summary, discrepancy,; or full. A summary report gives only the count of matching and mis-matching; symbols; d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst:640,optimiz,optimize,640,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst,1,['optimiz'],['optimize']
Performance,"llvm.assume <int_assume>`. An assume operand bundle has the form:. ::. ""<tag>""([ <arguments>] ]). In the case of function or parameter attributes, the operand bundle has the; restricted form:. ::. ""<tag>""([ <holds for value> [, <attribute argument>] ]). * The tag of the operand bundle is usually the name of attribute that can be; assumed to hold. It can also be `ignore`, this tag doesn't contain any; information and should be ignored.; * The first argument if present is the value for which the attribute hold.; * The second argument if present is an argument of the attribute. If there are no arguments the attribute is a property of the call location. For example:. .. code-block:: llvm. call void @llvm.assume(i1 true) [""align""(ptr %val, i32 8)]. allows the optimizer to assume that at location of call to; :ref:`llvm.assume <int_assume>` ``%val`` has an alignment of at least 8. .. code-block:: llvm. call void @llvm.assume(i1 %cond) [""cold""(), ""nonnull""(ptr %val)]. allows the optimizer to assume that the :ref:`llvm.assume <int_assume>`; call location is cold and that ``%val`` may not be null. Just like for the argument of :ref:`llvm.assume <int_assume>`, if any of the; provided guarantees are violated at runtime the behavior is undefined. While attributes expect constant arguments, assume operand bundles may be; provided a dynamic value, for example:. .. code-block:: llvm. call void @llvm.assume(i1 true) [""align""(ptr %val, i32 %align)]. If the operand bundle value violates any requirements on the attribute value,; the behavior is undefined, unless one of the following exceptions applies:. * ``""align""`` operand bundles may specify a non-power-of-two alignment; (including a zero alignment). If this is the case, then the pointer value; must be a null pointer, otherwise the behavior is undefined. In addition to allowing operand bundles encoding function and parameter; attributes, an assume operand bundle my also encode a ``separate_storage``; operand bundle. This has the for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:124477,optimiz,optimizer,124477,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance,"llvm.experimental.constrained.fcmps``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <ty2>; @llvm.experimental.constrained.fcmp(<type> <op1>, <type> <op2>,; metadata <condition code>,; metadata <exception behavior>); declare <ty2>; @llvm.experimental.constrained.fcmps(<type> <op1>, <type> <op2>,; metadata <condition code>,; metadata <exception behavior>). Overview:; """""""""""""""""". The '``llvm.experimental.constrained.fcmp``' and; '``llvm.experimental.constrained.fcmps``' intrinsics return a boolean; value or vector of boolean values based on comparison of its operands. If the operands are floating-point scalars, then the result type is a; boolean (:ref:`i1 <t_integer>`). If the operands are floating-point vectors, then the result type is a; vector of boolean with the same number of elements as the operands being; compared. The '``llvm.experimental.constrained.fcmp``' intrinsic performs a quiet; comparison operation while the '``llvm.experimental.constrained.fcmps``'; intrinsic performs a signaling comparison operation. Arguments:; """""""""""""""""""". The first two arguments to the '``llvm.experimental.constrained.fcmp``'; and '``llvm.experimental.constrained.fcmps``' intrinsics must be; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>`; of floating-point values. Both arguments must have identical types. The third argument is the condition code indicating the kind of comparison; to perform. It must be a metadata string with one of the following values:. .. _fcmp_md_cc:. - ""``oeq``"": ordered and equal; - ""``ogt``"": ordered and greater than; - ""``oge``"": ordered and greater than or equal; - ""``olt``"": ordered and less than; - ""``ole``"": ordered and less than or equal; - ""``one``"": ordered and not equal; - ""``ord``"": ordered (no nans); - ""``ueq``"": unordered or equal; - ""``ugt``"": unordered or greater than; - ""``uge``"": unordered or greater than or equal; - ""``ult``"": unordere",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:883988,perform,performs,883988,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"llvm.memset.element.unordered.atomic.*``' intrinsic sets the ``len`` bytes of; memory starting at the destination location to the given ``value``. The memory is; set with a sequence of store operations where each access is guaranteed to be a; multiple of ``element_size`` bytes wide and aligned at an ``element_size`` boundary. The order of the assignment is unspecified. Only one write is issued to the; destination buffer per element. It is well defined to have concurrent reads and; writes to the destination provided those reads and writes are unordered atomic; when specified. This intrinsic does not provide any additional ordering guarantees over those; provided by a set of unordered stores to the destination. Lowering:; """""""""""""""""". In the most general case call to the '``llvm.memset.element.unordered.atomic.*``' is; lowered to a call to the symbol ``__llvm_memset_element_unordered_atomic_*``. Where '*'; is replaced with an actual element size. The optimizer is allowed to inline the memory assignment when it's profitable to do so. Objective-C ARC Runtime Intrinsics; ----------------------------------. LLVM provides intrinsics that lower to Objective-C ARC runtime entry points.; LLVM is aware of the semantics of these functions, and optimizes based on that; knowledge. You can read more about the details of Objective-C ARC `here; <https://clang.llvm.org/docs/AutomaticReferenceCounting.html>`_. '``llvm.objc.autorelease``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.autorelease(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_autorelease <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-autorelease>`_. '``llvm.objc.autoreleasePoolPop``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.autoreleasePoolPop(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_autoreleasePoolPop <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:965963,optimiz,optimizer,965963,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance,"llvm.smul.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.smul.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.smul.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.smul.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.smul.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """""""""""""""""". The '``llvm.smul.with.overflow``' family of intrinsic functions perform; a signed multiplication of the two arguments, and indicate whether an; overflow occurred during the signed multiplication. Arguments:; """""""""""""""""""". The arguments (%a and %b) and the first element of the result structure; may be of integer types of any bit width, but they must have the same; bit width. The second element of the result structure must be of type; ``i1``. ``%a`` and ``%b`` are the two values that will undergo signed; multiplication. Semantics:; """""""""""""""""""". The '``llvm.smul.with.overflow``' family of intrinsic functions perform; a signed multiplication of the two arguments. They return a structure ---; the first element of which is the multiplication, and the second element; of which is a bit specifying if the signed multiplication resulted in an; overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.smul.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. '``llvm.umul.with.overflow.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.umul.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.umul.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.umul.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.umul.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.umul.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """"",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:608452,perform,perform,608452,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"llvm.vector.extract``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. ; Extract fixed type from scalable type; declare <4 x float> @llvm.vector.extract.v4f32.nxv4f32(<vscale x 4 x float> %vec, i64 <idx>); declare <2 x double> @llvm.vector.extract.v2f64.nxv2f64(<vscale x 2 x double> %vec, i64 <idx>). ; Extract scalable type from scalable type; declare <vscale x 2 x float> @llvm.vector.extract.nxv2f32.nxv4f32(<vscale x 4 x float> %vec, i64 <idx>). ; Extract fixed type from fixed type; declare <2 x double> @llvm.vector.extract.v2f64.v4f64(<4 x double> %vec, i64 <idx>). Overview:; """""""""""""""""". The '``llvm.vector.extract.*``' intrinsics extract a vector from within another; vector starting from a given index. The return type must be explicitly; specified. Conceptually, this can be used to decompose a scalable vector into; non-scalable parts, however this intrinsic can also be used on purely fixed; types. Scalable vectors can only be extracted from other scalable vectors. Arguments:; """""""""""""""""""". The ``vec`` is the vector from which we will extract a subvector. The ``idx`` specifies the starting element number within ``vec`` from which a; subvector is extracted. ``idx`` must be a constant multiple of the known-minimum; vector length of the result type. If the result type is a scalable vector,; ``idx`` is first scaled by the result type's runtime scaling factor. Elements; ``idx`` through (``idx`` + num_elements(result_type) - 1) must be valid vector; indices. If this condition cannot be determined statically but is false at; runtime, then the result vector is a :ref:`poison value <poisonvalues>`. The; ``idx`` parameter must be a vector index constant type (for most targets this; will be an integer pointer type). '``llvm.experimental.vector.reverse``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <2 x i8> @llvm.experimental.vector.reverse.v2i8(<",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:665154,scalab,scalable,665154,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance,"lly allocated when the hardware creates work-groups of wavefronts, and; freed when all the wavefronts of a work-group have terminated. The data store; (DS) instructions can be used to access it. The private memory space uses the hardware scratch memory support. If the kernel; uses scratch, then the hardware allocates memory that is accessed using; wavefront lane dword (4 byte) interleaving. The mapping used from private; address to physical address is:. ``wavefront-scratch-base +; (private-address * wavefront-size * 4) +; (wavefront-lane-id * 4)``. There are different ways that the wavefront scratch base address is determined; by a wavefront (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). This; memory can be accessed in an interleaved manner using buffer instruction with; the scratch buffer descriptor and per wavefront scratch offset, by the scratch; instructions, or by flat instructions. If each lane of a wavefront accesses the; same private address, the interleaving results in adjacent dwords being accessed; and hence requires fewer cache lines to be fetched. Multi-dword access is not; supported except by flat and scratch instructions in GFX9-GFX11. The generic address space uses the hardware flat address support available in; GFX7-GFX11. This uses two fixed ranges of virtual addresses (the private and; local apertures), that are outside the range of addressible global memory, to; map from a flat address to a private or local address. FLAT instructions can take a flat address and access global, private (scratch); and group (LDS) memory depending on if the address is within one of the; aperture ranges. Flat access to scratch requires hardware aperture setup and; setup in the kernel prologue (see; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`). Flat access to LDS requires; hardware aperture setup and M0 (GFX7-GFX8) register setup (see; :ref:`amdgpu-amdhsa-kernel-prolog-m0`). To convert between a segment address and a flat address the base address of the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:155236,cache,cache,155236,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"lly dispatched call sent to this; receiver because the function definition is considered to be fully resolved. * ``DynamicDispatchModeConservative`` - Models the case where the dynamic type; information is assumed to be incorrect, for example, implies that the method; definition is overridden in a subclass. In such cases, ExprEngine does not; inline the methods sent to the receiver (MemoryRegion), even if a candidate; definition is available. This mode is conservative about simulating the; effects of a call. Going forward along the symbolic execution path, ExprEngine consults the mode; of the receiver's MemRegion to make decisions on whether the calls should be; inlined or not, which ensures that there is at most one split per region. At a high level, ""bifurcation mode"" allows for increased semantic coverage in; cases where the parent method contains code which is only executed when the; class is subclassed. The disadvantages of this mode are a (considerable?); performance hit and the possibility of false positives on the path where the; conservative mode is used. Objective-C Message Heuristics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ExprEngine relies on a set of heuristics to partition the set of Objective-C; method calls into those that require bifurcation and those that do not. Below; are the cases when the DynamicTypeInfo of the object is considered precise; (cannot be a subclass):. - If the object was created with +alloc or +new and initialized with an -init; method. - If the calls are property accesses using dot syntax. This is based on the; assumption that children rarely override properties, or do so in an; essentially compatible way. - If the class interface is declared inside the main source file. In this case; it is unlikely that it will be subclassed. - If the method is not declared outside of main source file, either by the; receiver's class or by any superclasses. C++ Caveats; ^^^^^^^^^^^. C++11 [class.cdtor]p4 describes how the vtable of an object is modified",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst:14666,perform,performance,14666,interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,1,['perform'],['performance']
Performance,"lly; very efficient and do not incur a large runtime overhead. The; sample data collected by the profiler can be used during compilation; to determine what the most executed areas of the code are. Using the data from a sample profiler requires some changes in the way; a program is built. Before the compiler can use profiling information,; the code needs to execute under the profiler. The following is the; usual build cycle when using sample profilers for optimization:. 1. Build the code with source line table information. You can use all the; usual build flags that you always build your application with. The only; requirement is that you add ``-gline-tables-only`` or ``-g`` to the; command line. This is important for the profiler to be able to map; instructions back to source line locations. .. code-block:: console. $ clang++ -O2 -gline-tables-only code.cc -o code. 2. Run the executable under a sampling profiler. The specific profiler; you use does not really matter, as long as its output can be converted; into the format that the LLVM optimizer understands. Currently, there; exists a conversion tool for the Linux Perf profiler; (https://perf.wiki.kernel.org/), so these examples assume that you; are using Linux Perf to profile your code. .. code-block:: console. $ perf record -b ./code. Note the use of the ``-b`` flag. This tells Perf to use the Last Branch; Record (LBR) to record call chains. While this is not strictly required,; it provides better call information, which improves the accuracy of; the profile data. 3. Convert the collected profile data to LLVM's sample profile format.; This is currently supported via the AutoFDO converter ``create_llvm_prof``.; It is available at https://github.com/google/autofdo. Once built and; installed, you can convert the ``perf.data`` file to LLVM using; the command:. .. code-block:: console. $ create_llvm_prof --binary=./code --out=code.prof. This will read ``perf.data`` and the binary file ``./code`` and emit; the profile d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:93270,optimiz,optimizer,93270,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizer']
Performance,"load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. load atomic acquire - agent - generic 1. flat_load sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must hap",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:297158,load,load,297158,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['cache', 'load']","['cache', 'load']"
Performance,"loat B) {; return A+B;; }. into:. _f32: ## @f32; 	movdqa	%xmm0, %xmm2; 	addss	%xmm1, %xmm2; 	pshufd	$1, %xmm1, %xmm1 ## xmm1 = xmm1[1,0,0,0]; 	pshufd	$1, %xmm0, %xmm3 ## xmm3 = xmm0[1,0,0,0]; 	addss	%xmm1, %xmm3; 	movaps	%xmm2, %xmm0; 	unpcklps	%xmm3, %xmm0 ## xmm0 = xmm0[0],xmm3[0],xmm0[1],xmm3[1]; 	ret. seems silly when it could just be one addps. //===---------------------------------------------------------------------===//. Expand libm rounding functions inline: Significant speedups possible.; http://gcc.gnu.org/ml/gcc-patches/2006-10/msg00909.html. //===---------------------------------------------------------------------===//. When compiled with unsafemath enabled, ""main"" should enable SSE DAZ mode and; other fast SSE modes. //===---------------------------------------------------------------------===//. Think about doing i64 math in SSE regs on x86-32. //===---------------------------------------------------------------------===//. This testcase should have no SSE instructions in it, and only one load from; a constant pool:. double %test3(bool %B) {; %C = select bool %B, double 123.412, double 523.01123123; ret double %C; }. Currently, the select is being lowered, which prevents the dag combiner from; turning 'select (load CPI1), (load CPI2)' -> 'load (select CPI1, CPI2)'. The pattern isel got this one right. //===---------------------------------------------------------------------===//. Lower memcpy / memset to a series of SSE 128 bit move instructions when it's; feasible. //===---------------------------------------------------------------------===//. Codegen:; if (copysign(1.0, x) == copysign(1.0, y)); into:; if (x^y & mask); when using SSE. //===---------------------------------------------------------------------===//. Use movhps to update upper 64-bits of a v4sf value. Also movlps on lower half; of a v4sf value. //===---------------------------------------------------------------------===//. Better codegen for vector_shuffles like this { x, 0, 0, 0 } o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:2561,load,load,2561,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,2,['load'],['load']
Performance,"lobal 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensure",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:320590,cache,cache,320590,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"lobal variables <globalvars>` and; :ref:`functions <functionstructure>` are always implicitly valid; (link-time) constants. These constants are explicitly referenced when; the :ref:`identifier for the global <identifiers>` is used and always have; :ref:`pointer <t_pointer>` type. For example, the following is a legal LLVM; file:. .. code-block:: llvm. @X = global i32 17; @Y = global i32 42; @Z = global [2 x ptr] [ ptr @X, ptr @Y ]. .. _undefvalues:. Undefined Values; ----------------. The string '``undef``' can be used anywhere a constant is expected, and; indicates that the user of the value may receive an unspecified; bit-pattern. Undefined values may be of any type (other than '``label``'; or '``void``') and be used anywhere a constant is permitted. .. note::. A '``poison``' value (described in the next section) should be used instead of; '``undef``' whenever possible. Poison values are stronger than undef, and; enable more optimizations. Just the existence of '``undef``' blocks certain; optimizations (see the examples below). Undefined values are useful because they indicate to the compiler that; the program is well defined no matter what value is used. This gives the; compiler more freedom to optimize. Here are some examples of; (potentially surprising) transformations that are valid (in pseudo IR):. .. code-block:: llvm. %A = add %X, undef; %B = sub %X, undef; %C = xor %X, undef; Safe:; %A = undef; %B = undef; %C = undef. This is safe because all of the output bits are affected by the undef; bits. Any output bit can have a zero or one depending on the input bits. .. code-block:: llvm. %A = or %X, undef; %B = and %X, undef; Safe:; %A = -1; %B = 0; Safe:; %A = %X ;; By choosing undef as 0; %B = %X ;; By choosing undef as -1; Unsafe:; %A = undef; %B = undef. These logical operations have bits that are not always affected by the; input. For example, if ``%X`` has a zero bit, then the output of the; '``and``' operation will always be a zero for that bit, no matter ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:191265,optimiz,optimizations,191265,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"lobal; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:250775,load,loads,250775,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"loc(i32 %size); br label %coro.begin; coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %dyn.alloc ]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi); br label %loop; loop:; %n.val = phi i32 [ %n, %coro.begin ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; store i32 %n.val, ptr %promise; %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. A coroutine consumer can rely on the `coro.promise`_ intrinsic to access the; coroutine promise. .. code-block:: llvm. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4); %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val0 = load i32, ptr %promise.addr; call void @print(i32 %val0); call void @llvm.coro.resume(ptr %hdl); %val1 = load i32, ptr %promise.addr; call void @print(i32 %val1); call void @llvm.coro.resume(ptr %hdl); %val2 = load i32, ptr %promise.addr; call void @print(i32 %val2); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. After example in this section is compiled, result of the compilation will be:. .. code-block:: llvm. define i32 @main() {; entry:; tail call void @print(i32 4); tail call void @print(i32 5); tail call void @print(i32 6); ret i32 0; }. .. _final:; .. _final suspend:. Final Suspend; -------------. A coroutine author or a frontend may designate a particular suspend to be final,; by setting the second argument of the `coro.suspend`_ intrinsic to `true`.; Such a suspend point has two properties:. * it is possible to check whether a suspended coroutine is at the final suspend; point via `coro.done`_ intrinsic;. * a resumption of a coroutine stopped at the final suspend point leads to; undefined behavior. The only possible action for a coroutine at a final; suspend point is dest",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:23995,load,load,23995,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['load'],['load']
Performance,"local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214937,load,loads,214937,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local. 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); Must happen after; preceding; global/generic load; atomic/; atomic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:375266,load,load,375266,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L0 and L1 caches at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is accessed as MTYPE UC (uncached) to avoid; needing to invalidate the L2 cache.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC (non-coherent). Since the private address space is only accessed; by a single thread, and is always write-before-read, there is never a need to; invalidate these entries from the L0 or L1 caches. Wavefronts are executed in native mode with in-order reporting of loads and; sample instructions. In this mode vmcnt reports completion of load, atomic with; return and sample instructions in order, and the vscnt reports the completion of; store and atomic without return in order. See ``MEM_ORDERED`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`. Wavefronts can be executed in WGP or CU wavefront execution mode:. * In WGP wavefront execution mode the wavefronts of a work-group are executed; on the SIMDs of both CUs of the WGP. Therefore, explicit management of the per; CU L0 caches is required for work-group synchronization. Also accesses to L1; at work-group scope need to be explicitly ordered as the accesses from; different CUs are not ordered.; * In CU wavefront execution mode the wavefronts of a work-group are executed on; the SIMDs of a single CU of the WGP. Therefore, all global memory access by; the work-group access the same L0 which in turn ensures L1 accesses are; ordered and so do not require explicit m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:341884,load,loads,341884,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX90A; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241756,cache,cache,241756,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX940, GFX941, GFX942; are defined in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx940-gfx941-gfx942-table`. .. table:: AMDHSA Memory Model Code Sequences GFX940, GFX941, GFX942; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx940-gfx941-gfx942-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX940, GFX941, GFX942; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:291774,cache,cache,291774,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"locations. Without this flags, all remarks are kept. .. option:: --remarks-output-format <format>. Specify the format to be used when serializing the linked remarks. .. option:: --remarks-prepend-path <path>. Specify a directory to prepend the paths of the external remark files. .. option:: --reproducer <mode>. Specify the reproducer generation mode. Valid options are 'GenerateOnExit',; 'GenerateOnCrash', 'Use', 'Off'. .. option:: --statistics. Print statistics about the contribution of each object file to the linked; debug info. This prints a table after linking with the object file name, the; size of the debug info in the object file (in bytes) and the size contributed; (in bytes) to the linked dSYM. The table is sorted by the output size listing; the object files with the largest contribution first. .. option:: --symbol-map <bcsymbolmap>. Update the existing dSYMs inplace using symbol map specified. .. option:: -s, --symtab. Dumps the symbol table found in *executable* or object file(s) and exits. .. option:: -S. Output textual assembly instead of a binary dSYM companion file. .. option:: --toolchain <toolchain>. Embed the toolchain in the dSYM bundle's property list. .. option:: -u, --update. Update an existing dSYM file to contain the latest accelerator tables and; other DWARF optimizations. This option will rebuild the '.apple_names' and; '.apple_types' hashed accelerator tables. .. option:: --use-reproducer <path>. Use the object files from the given reproducer path. Alias for; --reproducer=Use. .. option:: --verbose. Display verbose information when linking. .. option:: --verify. Run the DWARF verifier on the linked DWARF debug info. .. option:: -v, --version. Display the version of the tool. .. option:: -y. Treat *executable* as a YAML debug-map rather than an executable. EXIT STATUS; -----------. :program:`dsymutil` returns 0 if the DWARF debug information was linked; successfully. Otherwise, it returns 1. SEE ALSO; --------. :manpage:`llvm-dwarfdump(1)`; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/dsymutil.rst:5273,optimiz,optimizations,5273,interpreter/llvm-project/llvm/docs/CommandGuide/dsymutil.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/dsymutil.rst,1,['optimiz'],['optimizations']
Performance,"lock afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you dont specify alignment, but may",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3708,load,load,3708,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['load'],['load']
Performance,"lock:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } else {; for (int i = 0; i < n; i+=1) // unversioned loop; A[i] = B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop Interchange; ----------------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The default optimization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transformation pass should be reported to the user. The transformation; passes themselves cannot be responsible for this reporting because they; might not be in the pipeline, there might be multiple passes able to; apply a transformation (e.g. ``LoopInterchange`` and Polly) or a; transformation attribute may be 'hidden' inside another",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:13872,perform,performs,13872,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['perform'],['performs']
Performance,"lock:: llvm. define i32 @example() {; entry:; %X = alloca i32 ; type of %X is i32*.; ...; %tmp = load i32, i32* %X ; load the stack value %X from the stack.; %tmp2 = add i32 %tmp, 1 ; increment it; store i32 %tmp2, i32* %X ; store it back; ... This code shows an example of how you can declare and manipulate a stack; variable in the LLVM IR. Stack memory allocated with the alloca; instruction is fully general: you can pass the address of the stack slot; to functions, you can store it in other variables, etc. In our example; above, we could rewrite the example to use the alloca technique to avoid; using a PHI node:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; %X = alloca i32 ; type of %X is i32*.; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; store i32 %X.0, i32* %X ; Update X; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; store i32 %X.1, i32* %X ; Update X; br label %cond_next. cond_next:; %X.2 = load i32, i32* %X ; Read X; ret i32 %X.2; }. With this, we have discovered a way to handle arbitrary mutable; variables without the need to create Phi nodes at all:. #. Each mutable variable becomes a stack allocation.; #. Each read of the variable becomes a load from the stack.; #. Each update of the variable becomes a store to the stack.; #. Taking the address of a variable just uses the stack address; directly. While this solution has solved our immediate problem, it introduced; another one: we have now apparently introduced a lot of stack traffic; for very simple and common operations, a major performance problem.; Fortunately for us, the LLVM optimizer has a highly-tuned optimization; pass named ""mem2reg"" that handles this case, promoting allocas like this; into SSA registers, inserting Phi nodes as appropriate. If you run this; example through the pass, for example, you'll get:. .. code-block:: bash.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:5939,load,load,5939,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance,"lock:: objc. id objc_initWeak(id *object, id value) {; *object = nil;; return objc_storeWeak(object, value);; }. Returns the value of ``object`` after the call. Does not need to be atomic with respect to calls to ``objc_storeWeak`` on; ``object``. .. _arc.runtime.objc_loadWeak:. ``id objc_loadWeak(id *object);``; ---------------------------------. *Precondition:* ``object`` is a valid pointer which either contains a null; pointer or has been registered as a ``__weak`` object. If ``object`` is registered as a ``__weak`` object, and the last value stored; into ``object`` has not yet been deallocated or begun deallocation, retains and; autoreleases that value and returns it. Otherwise returns null. Equivalent to; the following code:. .. code-block:: objc. id objc_loadWeak(id *object) {; return objc_autorelease(objc_loadWeakRetained(object));; }. Must be atomic with respect to calls to ``objc_storeWeak`` on ``object``. .. admonition:: Rationale. Loading weak references would be inherently prone to race conditions without; the retain. .. _arc.runtime.objc_loadWeakRetained:. ``id objc_loadWeakRetained(id *object);``; -----------------------------------------. *Precondition:* ``object`` is a valid pointer which either contains a null; pointer or has been registered as a ``__weak`` object. If ``object`` is registered as a ``__weak`` object, and the last value stored; into ``object`` has not yet been deallocated or begun deallocation, retains; that value and returns it. Otherwise returns null. Must be atomic with respect to calls to ``objc_storeWeak`` on ``object``. .. _arc.runtime.objc_moveWeak:. ``void objc_moveWeak(id *dest, id *src);``; ------------------------------------------. *Precondition:* ``src`` is a valid pointer which either contains a null pointer; or has been registered as a ``__weak`` object. ``dest`` is a valid pointer; which has not been registered as a ``__weak`` object. ``dest`` is initialized to be equivalent to ``src``, potentially registering it; with",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:111830,race condition,race conditions,111830,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['race condition'],['race conditions']
Performance,"lock:: text. %r = call i8 @llvm.fshl.i8(i8 %x, i8 %y, i8 %z) ; %r = i8: msb_extract((concat(x, y) << (z % 8)), 8); %r = call i8 @llvm.fshl.i8(i8 255, i8 0, i8 15) ; %r = i8: 128 (0b10000000); %r = call i8 @llvm.fshl.i8(i8 15, i8 15, i8 11) ; %r = i8: 120 (0b01111000); %r = call i8 @llvm.fshl.i8(i8 0, i8 255, i8 8) ; %r = i8: 0 (0b00000000). .. _int_fshr:. '``llvm.fshr.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.fshr`` on any; integer bit width or any vector of integer elements. Not all targets; support all bit widths or vector types, however. ::. declare i8 @llvm.fshr.i8 (i8 %a, i8 %b, i8 %c); declare i64 @llvm.fshr.i64(i64 %a, i64 %b, i64 %c); declare <2 x i32> @llvm.fshr.v2i32(<2 x i32> %a, <2 x i32> %b, <2 x i32> %c). Overview:; """""""""""""""""". The '``llvm.fshr``' family of intrinsic functions performs a funnel shift right:; the first two values are concatenated as { %a : %b } (%a is the most significant; bits of the wide value), the combined value is shifted right, and the least; significant bits are extracted to produce a result that is the same size as the; original arguments. If the first 2 arguments are identical, this is equivalent; to a rotate right operation. For vector types, the operation occurs for each; element of the vector. The shift argument is treated as an unsigned amount; modulo the element size of the arguments. Arguments:; """""""""""""""""""". The first two arguments are the values to be concatenated. The third; argument is the shift amount. The arguments may be any integer type or a; vector with integer element type. All arguments and the return value must; have the same type. Example:; """""""""""""""". .. code-block:: text. %r = call i8 @llvm.fshr.i8(i8 %x, i8 %y, i8 %z) ; %r = i8: lsb_extract((concat(x, y) >> (z % 8)), 8); %r = call i8 @llvm.fshr.i8(i8 255, i8 0, i8 15) ; %r = i8: 254 (0b11111110); %r = call i8 @llvm.fshr.i8(i8 15, i8 15, i8 11) ; %r = i8: 225 (0b11100001); %r = call i8 @llvm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:598571,perform,performs,598571,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"longer holds, to obtain a new pointer; value that does not carry the invariant information. It is an experimental; intrinsic, which means that its semantics might change in the future. Arguments:; """""""""""""""""""". The ``llvm.strip.invariant.group`` takes only one argument, which is a pointer; to the memory. Semantics:; """""""""""""""""""". Returns another pointer that aliases its argument but which has no associated; ``invariant.group`` metadata.; It does not read any memory and can be speculated. .. _constrainedfp:. Constrained Floating-Point Intrinsics; -------------------------------------. These intrinsics are used to provide special handling of floating-point; operations when specific rounding mode or floating-point exception behavior is; required. By default, LLVM optimization passes assume that the rounding mode is; round-to-nearest and that floating-point exceptions will not be monitored.; Constrained FP intrinsics are used to support non-default rounding modes and; accurately preserve exception behavior without compromising LLVM's ability to; optimize FP code when the default behavior is used. If any FP operation in a function is constrained then they all must be; constrained. This is required for correct LLVM IR. Optimizations that; move code around can create miscompiles if mixing of constrained and normal; operations is done. The correct way to mix constrained and less constrained; operations is to use the rounding mode and exception handling metadata to; mark constrained intrinsics as having LLVM's default behavior. Each of these intrinsics corresponds to a normal floating-point operation. The; data arguments and the return value are the same as the corresponding FP; operation. The rounding mode argument is a metadata string specifying what; assumptions, if any, the optimizer can make when transforming constant; values. Some constrained FP intrinsics omit this argument. If required; by the intrinsic, this argument must be one of the following strings:. ::. ""round.dyn",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:867631,optimiz,optimize,867631,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimize']
Performance,"lookup by name table, and in the CFI Common Information Entry; (CIE). See :ref:`amdgpu-dwarf-full-and-partial-compilation-unit-entries`,; :ref:`amdgpu-dwarf-name-index-section-header`, and; :ref:`amdgpu-dwarf-structure_of-call-frame-information`. 2.16 Support Embedding Source Text for Online Compilation; ---------------------------------------------------------. AMDGPU supports programming languages that include online compilation where the; source text may be created at runtime. For example, the OpenCL and HIP language; runtimes support online compilation. To support is, a way to embed the source; text in the debug information is provided. See :ref:`amdgpu-dwarf-line-number-information`. 2.17 Allow MD5 Checksums to be Optionally Present; -------------------------------------------------. In DWARF Version 5 the file timestamp and file size can be optional, but if the; MD5 checksum is present it must be valid for all files. This is a problem if; using link time optimization to combine compilation units where some have MD5; checksums and some do not. Therefore, sSupport to allow MD5 checksums to be; optionally present in the line table is added. See :ref:`amdgpu-dwarf-line-number-information`. 2.18 Add the HIP Programing Language; ------------------------------------. The HIP programming language [:ref:`HIP <amdgpu-dwarf-HIP>`], which is supported; by the AMDGPU, is added. See :ref:`amdgpu-dwarf-language-names-table`. 2.19 Support for Source Language Optimizations that Result in Concurrent Iteration Execution; --------------------------------------------------------------------------------------------. A compiler can perform loop optimizations that result in the generated code; executing multiple iterations concurrently. For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of one iteration to hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SI",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:32189,optimiz,optimization,32189,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimization']
Performance,"lookup is no longer handled by layers. Instead, there is a; ``lookup`` method on JITDylib that takes a list of JITDylibs to scan. .. code-block:: c++. ExecutionSession ES;; JITDylib &JD1 = ...;; JITDylib &JD2 = ...;. auto Sym = ES.lookup({&JD1, &JD2}, ES.intern(""_main""));. 6. The removeModule/removeObject methods are replaced by; ``ResourceTracker::remove``.; See the subsection `How to remove code`_. For code examples and suggestions of how to use the ORCv2 APIs, please see; the section `How-tos`_. How-tos; =======. How to manage symbol strings; ----------------------------. Symbol strings in ORC are uniqued to improve lookup performance, reduce memory; overhead, and allow symbol names to function as efficient keys. To get the; unique ``SymbolStringPtr`` for a string value, call the; ``ExecutionSession::intern`` method:. .. code-block:: c++. ExecutionSession ES;; /// ...; auto MainSymbolName = ES.intern(""main"");. If you wish to perform lookup using the C/IR name of a symbol you will also; need to apply the platform linker-mangling before interning the string. On; Linux this mangling is a no-op, but on other platforms it usually involves; adding a prefix to the string (e.g. '_' on Darwin). The mangling scheme is; based on the DataLayout for the target. Given a DataLayout and an; ExecutionSession, you can create a MangleAndInterner function object that; will perform both jobs for you:. .. code-block:: c++. ExecutionSession ES;; const DataLayout &DL = ...;; MangleAndInterner Mangle(ES, DL);. // ... // Portable IR-symbol-name lookup:; auto Sym = ES.lookup({&MainJD}, Mangle(""main""));. How to create JITDylibs and set up linkage relationships; --------------------------------------------------------. In ORC, all symbol definitions reside in JITDylibs. JITDylibs are created by; calling the ``ExecutionSession::createJITDylib`` method with a unique name:. .. code-block:: c++. ExecutionSession ES;; auto &JD = ES.createJITDylib(""libFoo.dylib"");. The JITDylib is owned by the ``Ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:22394,perform,perform,22394,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['perform'],['perform']
Performance,"loop (15 mins) after client disconnectionsAvoid potential deadlocks when trying to remove a node from a clusterCorrect matching of incoming connection with previously dropped connectionCorrect export of cluster identificationCorrectly propagate information about files that could not be stagedPrevent endsess deadlock when parallel streams stall due to large WAN RTTFix infinite wait for primary login that will never; happen if you are a manager without a meta-managerPrevent annoying (but not deadly) infinite loop should a; server go offline that is subject to a locate request display.Client sideBetter handling of errno, especially for parallel streamsAllow the client to cycle through all the remaining valid security protocols in the list of protocols returned by the serverMake the readahead strategy more conservativeFix a rare race condition happening when destroying instances with outstanding open requestsEnforce cache coherency in the case of reads+writes in the same fileCorrectly guess the filesize of a file opened for writing in sync modeMake server host name check more flexible for GSI authenticationFix some relevant issues with cache handling on the client, including arare but fatal bug in; determining the cache holes list and the end of a cache lookupMore complete detection of async read errorsGeneralFix problem in handling the return code; ofX509_REQ_verify; inXrdCryptosslX509Req.ccAvoid SEGV when doing an lsd admin command with; authenticated xrootd clientsClose race conditions that allowed a supervisor/manager; to subscribe without declaring a data port. Initialize nostage state in; XrdCmsState to prevent erroneous state declaration during; initialization.Fix a problem with the subject name of proxies of level; > 1; this was creating a failure when a Globus application was; trying to use the proxy certificateFix a problem with cache refreshing in XrdSutCache; affecting automatic reloading of password filesFor now, turn off IPV6 processing as it seems to cr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v524/index.html:2164,race condition,race condition,2164,net/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v524/index.html,10,"['cache', 'race condition']","['cache', 'race condition']"
Performance,"loop on the base of the number of events written instead of the number of bytes written.; New function TTree::OptimizeBaskets. void TTree::OptimizeBaskets(Int_t maxMemory, Float_t minComp, Option_t *option). This function may be called after having filled some entries in a Tree; using the information in the existing branch buffers, it will reassign; new branch buffer sizes to optimize time and memory.; The function computes the best values for branch buffer sizes such that; the total buffer sizes is less than maxMemory and nearby entries written; at the same time.; In case the branch compression factor for the data written so far is less; than compMin, the compression is disabled. if option =""d"" an analysis report is printed.; This function may also be called on an existing Tree to figure out the best values; given the information in the Tree header. TFile f(""myfile.root"");; TTree *T = (TTree*)f.Get(""mytreename"");; T->Print(); //show the branch buffer sizes before optimization; T->OptimizeBaskets(10000000,1,""d"");; T->Print(); //show the branch buffer sizes after optimization. New interface functions to customize the TreeCache; virtual void AddBranchToCache(const char *bname, Bool_t subbranches = kFALSE);; virtual void AddBranchToCache(TBranch *branch, Bool_t subbranches = kFALSE);; virtual void PrintCacheStats(Option_t* option = """") const;; virtual void SetParallelUnzip(Bool_t opt=kTRUE);; virtual void SetCacheEntryRange(Long64_t first, Long64_t last);; virtual void SetCacheLearnEntries(Int_t n=10);; virtual void StopCacheLearningPhase();; New functionality AutoFlush (and changes to AutoSave). Implement a new member fAutoFlush in TTree with its getter and setter:. void TTree::SetAutoFlush(Long64_t autof). The logic of the AutoFlush mechanism is optimized such that the TreeCache; will read always up to the point where FlushBaskets has been called.; This minimizes the number of cases where one has to seek backward when reading. This function may be called at the start ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:5188,optimiz,optimization,5188,tree/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html,5,"['Optimiz', 'optimiz']","['OptimizeBaskets', 'optimization']"
Performance,"loop vectorizer in which case; ``%base`` is the first element of the vector induction variable (VIV) and; ``%n`` is the loop tripcount. Thus, these intrinsics perform an element-wise; less than comparison of VIV with the loop tripcount, producing a mask of; true/false values representing active/inactive vector lanes, except if the VIV; overflows in which case they return false in the lanes where the VIV overflows.; The arguments are scalar types to accommodate scalable vector types, for which; it is unknown what the type of the step vector needs to be that enumerate its; lanes without overflow. This mask ``%m`` can e.g. be used in masked load/store instructions. These; intrinsics provide a hint to the backend. I.e., for a vector loop, the; back-edge taken count of the original scalar loop is explicit as the second; argument. Examples:; """""""""""""""""". .. code-block:: llvm. %active.lane.mask = call <4 x i1> @llvm.get.active.lane.mask.v4i1.i64(i64 %elem0, i64 429); %wide.masked.load = call <4 x i32> @llvm.masked.load.v4i32.p0v4i32(<4 x i32>* %3, i32 4, <4 x i1> %active.lane.mask, <4 x i32> poison). .. _int_experimental_vp_splice:. '``llvm.experimental.vp.splice``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <2 x double> @llvm.experimental.vp.splice.v2f64(<2 x double> %vec1, <2 x double> %vec2, i32 %imm, <2 x i1> %mask, i32 %evl1, i32 %evl2); declare <vscale x 4 x i32> @llvm.experimental.vp.splice.nxv4i32(<vscale x 4 x i32> %vec1, <vscale x 4 x i32> %vec2, i32 %imm, <vscale x 4 x i1> %mask, i32 %evl1, i32 %evl2). Overview:; """""""""""""""""". The '``llvm.experimental.vp.splice.*``' intrinsic is the vector length; predicated version of the '``llvm.experimental.vector.splice.*``' intrinsic. Arguments:; """""""""""""""""""". The result and the first two arguments ``vec1`` and ``vec2`` are vectors with; the same type. The third argument ``imm`` is an immediate signed integer that; indicates the offset index. The fo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:779134,load,load,779134,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"low the final store to do the; store. See GCC PR27313 for more details. Note that this is valid to xform even; with the new C++ memory model, since mc[k] is previously loaded and later; stored. //===---------------------------------------------------------------------===//. [SCALAR PRE]; There are many PRE testcases in testsuite/gcc.dg/tree-ssa/ssa-pre-*.c in the; GCC testsuite. //===---------------------------------------------------------------------===//. There are some interesting cases in testsuite/gcc.dg/tree-ssa/pred-comm* in the; GCC testsuite. For example, we get the first example in predcom-1.c, but ; miss the second one:. unsigned fib[1000];; unsigned avg[1000];. __attribute__ ((noinline)); void count_averages(int n) {; int i;; for (i = 1; i < n; i++); avg[i] = (((unsigned long) fib[i - 1] + fib[i] + fib[i + 1]) / 3) & 0xffff;; }. which compiles into two loads instead of one in the loop. predcom-2.c is the same as predcom-1.c. predcom-3.c is very similar but needs loads feeding each other instead of; store->load. //===---------------------------------------------------------------------===//. [ALIAS ANALYSIS]. Type based alias analysis:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=14705. We should do better analysis of posix_memalign. At the least it should; no-capture its pointer argument, at best, we should know that the out-value; result doesn't point to anything (like malloc). One example of this is in; SingleSource/Benchmarks/Misc/dt.c. //===---------------------------------------------------------------------===//. Interesting missed case because of control flow flattening (should be 2 loads):; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=26629; With: llvm-gcc t2.c -S -o - -O0 -emit-llvm | llvm-as | ; opt -mem2reg -gvn -instcombine | llvm-dis; we miss it because we need 1) CRIT EDGE 2) MULTIPLE DIFFERENT; VALS PRODUCED BY ONE BLOCK OVER DIFFERENT PATHS. //===---------------------------------------------------------------------===//. http://gcc.gnu.org",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:35396,load,loads,35396,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,4,['load'],"['load', 'loads']"
Performance,"lowering it into a sequence of branches that guard scalar store operations. Memory Use Markers; ------------------. This class of intrinsics provides information about the; :ref:`lifetime of memory objects <objectlifetime>` and ranges where variables; are immutable. .. _int_lifestart:. '``llvm.lifetime.start``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.lifetime.start(i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.lifetime.start``' intrinsic specifies the start of a memory; object's lifetime. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is variable sized. The second argument is a pointer; to the object. Semantics:; """""""""""""""""""". If ``ptr`` is a stack-allocated object and it points to the first byte of; the object, the object is initially marked as dead.; ``ptr`` is conservatively considered as a non-stack-allocated object if; the stack coloring algorithm that is used in the optimization pipeline cannot; conclude that ``ptr`` is a stack-allocated object. After '``llvm.lifetime.start``', the stack object that ``ptr`` points is marked; as alive and has an uninitialized value.; The stack object is marked as dead when either; :ref:`llvm.lifetime.end <int_lifeend>` to the alloca is executed or the; function returns. After :ref:`llvm.lifetime.end <int_lifeend>` is called,; '``llvm.lifetime.start``' on the stack object can be called again.; The second '``llvm.lifetime.start``' call marks the object as alive, but it; does not change the address of the object. If ``ptr`` is a non-stack-allocated object, it does not point to the first; byte of the object or it is a stack object that is already alive, it simply; fills all bytes of the object with ``poison``. .. _int_lifeend:. '``llvm.lifetime.end``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.lifetime.end(i64 <size>, ptr nocapture <ptr>). Overview:; """"""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:861762,optimiz,optimization,861762,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"lowing ""string"" options are available:. +---------------------------------+----------------+-------------------------------------------------+; | Option | Default | Description |; +---------------------------------+----------------+-------------------------------------------------+; | quarantine_size_kb | 0 | The size (in Kb) of quarantine used to delay |; | | | the actual deallocation of chunks. Lower value |; | | | may reduce memory usage but decrease the |; | | | effectiveness of the mitigation; a negative |; | | | value will fallback to the defaults. Setting |; | | | *both* this and thread_local_quarantine_size_kb |; | | | to zero will disable the quarantine entirely. |; +---------------------------------+----------------+-------------------------------------------------+; | quarantine_max_chunk_size | 0 | Size (in bytes) up to which chunks can be |; | | | quarantined. |; +---------------------------------+----------------+-------------------------------------------------+; | thread_local_quarantine_size_kb | 0 | The size (in Kb) of per-thread cache use to |; | | | offload the global quarantine. Lower value may |; | | | reduce memory usage but might increase |; | | | contention on the global quarantine. Setting |; | | | *both* this and quarantine_size_kb to zero will |; | | | disable the quarantine entirely. |; +---------------------------------+----------------+-------------------------------------------------+; | dealloc_type_mismatch | false | Whether or not we report errors on |; | | | malloc/delete, new/free, new/delete[], etc. |; +---------------------------------+----------------+-------------------------------------------------+; | delete_size_mismatch | true | Whether or not we report errors on mismatch |; | | | between sizes of new and delete. |; +---------------------------------+----------------+-------------------------------------------------+; | zero_contents | false | Whether or not we zero chunk contents on |; | | | allocation. |; +--------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:9425,cache,cache,9425,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['cache'],['cache']
Performance,"lowing rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - system *none* 1. buffer_wbl2 sc0=1 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:328537,load,load,328537,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"lowing values:. .. _fcmp_md_cc:. - ""``oeq``"": ordered and equal; - ""``ogt``"": ordered and greater than; - ""``oge``"": ordered and greater than or equal; - ""``olt``"": ordered and less than; - ""``ole``"": ordered and less than or equal; - ""``one``"": ordered and not equal; - ""``ord``"": ordered (no nans); - ""``ueq``"": unordered or equal; - ""``ugt``"": unordered or greater than; - ""``uge``"": unordered or greater than or equal; - ""``ult``"": unordered or less than; - ""``ule``"": unordered or less than or equal; - ""``une``"": unordered or not equal; - ""``uno``"": unordered (either nans). *Ordered* means that neither operand is a NAN while *unordered* means; that either operand may be a NAN. The fourth argument specifies the exception behavior as described above. Semantics:; """""""""""""""""""". ``op1`` and ``op2`` are compared according to the condition code given; as the third argument. If the operands are vectors, then the; vectors are compared element by element. Each comparison performed; always yields an :ref:`i1 <t_integer>` result, as follows:. .. _fcmp_md_cc_sem:. - ""``oeq``"": yields ``true`` if both operands are not a NAN and ``op1``; is equal to ``op2``.; - ""``ogt``"": yields ``true`` if both operands are not a NAN and ``op1``; is greater than ``op2``.; - ""``oge``"": yields ``true`` if both operands are not a NAN and ``op1``; is greater than or equal to ``op2``.; - ""``olt``"": yields ``true`` if both operands are not a NAN and ``op1``; is less than ``op2``.; - ""``ole``"": yields ``true`` if both operands are not a NAN and ``op1``; is less than or equal to ``op2``.; - ""``one``"": yields ``true`` if both operands are not a NAN and ``op1``; is not equal to ``op2``.; - ""``ord``"": yields ``true`` if both operands are not a NAN.; - ""``ueq``"": yields ``true`` if either operand is a NAN or ``op1`` is; equal to ``op2``.; - ""``ugt``"": yields ``true`` if either operand is a NAN or ``op1`` is; greater than ``op2``.; - ""``uge``"": yields ``true`` if either operand is a NAN or ``op1`` is; greater th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:885538,perform,performed,885538,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"lowup_coincident`` sets the loop attributes of; all loops without loop-carried dependencies (i.e. vectorizable loops).; There might be more than one such loops. If not defined, the loops will; inherit the original loop's attributes. ``llvm.loop.distribute.followup_sequential`` sets the loop attributes of the; loop with potentially unsafe dependencies. There should be at most one; such loop. If not defined, the loop will inherit the original loop's; attributes. ``llvm.loop.distribute.followup_fallback`` defines the loop attributes; for the fallback loop, which is a copy of the original loop for when; loop versioning is required. If undefined, the fallback loop inherits; all attributes from the original loop. Attributes defined in ``llvm.loop.distribute.followup_all`` are added to; all of the aforementioned output loops. It is recommended to add ``llvm.loop.disable_nonforced`` to; ``llvm.loop.distribute.followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } else {; for (int i = 0; i < n; i+=1) // unversioned loop; A[i] = B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop Interchange; ----------------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The def",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:12698,optimiz,optimized,12698,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['optimiz'],['optimized']
Performance,"lp build times over Make, particularly for highly; parallel builds. LLD helps to reduce both link times and memory usage; during linking significantly. With a build machine with sufficient; parallelism, link times tend to dominate critical path of the build, and are; thus worth optimizing. Use CCache and NOT incremental builds; Using ccache materially improves average build times. Incremental builds; can be slightly faster, but introduce the risk of build corruption due to; e.g. state changes, etc... At this point, the recommendation is not to; use incremental builds and instead use ccache as the latter captures the; majority of the benefit with less risk of false positives. One of the non-obvious benefits of using ccache is that it makes the; builder less sensitive to which projects are being monitored vs built.; If a change triggers a build request, but doesn't change the build output; (e.g. doc changes, python utility changes, etc..), the build will entirely; hit in cache and the build request will complete in just the testing time. With multiple workers, it is tempting to try to configure a shared cache; between the workers. Experience to date indicates this is difficult to; well, and that having local per-worker caches gets most of the benefit; anyways. We don't currently recommend shared caches. CCache does depend on the builder hardware having sufficient IO to access; the cache with reasonable access times - i.e. a fast disk, or enough memory; for a RAM cache, etc.. For builders without, incremental may be your best; option, but is likely to require higher ongoing involvement from the; sponsor. Enable batch builds; As a last resort, you can configure your builder to batch build requests.; This makes the build failure notifications markedly less actionable, and; should only be done once all other reasonable measures have been taken. Leave it on the staging buildmaster; While most of this section has been biased towards builders intended for; the main buildmast",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:11739,cache,cache,11739,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['cache'],['cache']
Performance,"ls are flushed to positive zero. The default value depends on the target. For most targets, defaults to; ``ieee``. .. option:: -f[no-]strict-float-cast-overflow. When a floating-point value is not representable in a destination integer; type, the code has undefined behavior according to the language standard.; By default, Clang will not guarantee any particular result in that case.; With the 'no-strict' option, Clang will saturate towards the smallest and; largest representable integer values instead. NaNs will be converted to zero.; Defaults to ``-fstrict-float-cast-overflow``. .. option:: -f[no-]math-errno. Require math functions to indicate errors by setting errno.; The default varies by ToolChain. ``-fno-math-errno`` allows optimizations; that might cause standard C math functions to not set ``errno``.; For example, on some systems, the math function ``sqrt`` is specified; as setting ``errno`` to ``EDOM`` when the input is negative. On these; systems, the compiler cannot normally optimize a call to ``sqrt`` to use; inline code (e.g. the x86 ``sqrtsd`` instruction) without additional; checking to ensure that ``errno`` is set appropriately.; ``-fno-math-errno`` permits these transformations. On some targets, math library functions never set ``errno``, and so; ``-fno-math-errno`` is the default. This includes most BSD-derived; systems, including Darwin. .. option:: -f[no-]trapping-math. Control floating point exception behavior. ``-fno-trapping-math`` allows optimizations that assume that floating point operations cannot generate traps such as divide-by-zero, overflow and underflow. - The option ``-ftrapping-math`` behaves identically to ``-ffp-exception-behavior=strict``.; - The option ``-fno-trapping-math`` behaves identically to ``-ffp-exception-behavior=ignore``. This is the default. .. option:: -ffp-contract=<value>. Specify when the compiler is permitted to form fused floating-point; operations, such as fused multiply-add (FMA). Fused operations are; permitte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:55873,optimiz,optimize,55873,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimize']
Performance,"ls can be run on a set of Poisson data or Gaussian over flat with model considering optionally the nuisance parameters. The data can be generated with the rs500 tutorials. HybridCalculator. In the constructor the signature passing a name and a title string has been removed, for being consistent with all the other calculator classes. Name and title can be set optionally using the SetName and SetTitle methods. Please note that this change is not backward compatible.; Add the option to use binned generation (via SetGenerateBinned).; An estimated of the error in the obtained p values is now computed in the HybridResult class thanks to Matthias Wolf. The errors can be obtained with HybridResult::CLbError(), HybridResult::CLsplusbError() or HybridResult::CLsError().; A new tutorial has been added for showing the usage of the hybrid calculator: rs505_HybridCalculator_significance.C. new class HypoTestInverter. New class for performing an hypothesis test inversion by scanning; the hypothesis test results of the HybridCalculator for; various values of the parameter of interest. An upper (or lower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:14574,perform,performing,14574,roofit/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html,2,['perform'],['performing']
Performance,ls-extra/clang-tidy/performance/FasterStringFindCheck.cpp; clang-tools-extra/clang-tidy/performance/ForRangeCopyCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.h; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.h; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.cpp; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.h; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.cpp; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.h; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.cpp; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.h; clang-tools-extra/clang-tidy/performance/PerformanceTidyModule.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.h; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.cpp; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.h; clang-tools-extra/clang-tidy/performance/UnnecessaryCopyInitialization.cpp; clang-tools-extra/clang-tidy/performance/UnnecessaryValueParamCheck.cpp; clang-tools-extra/clang-tidy/performance/UnnecessaryValueParamCheck.h; clang-tools-extra/clang-tidy/plugin/ClangTidyPlugin.cpp; clang-tools-extra/clang-tidy/portability/PortabilityTidyModule.cpp; clang-tools-extra/clang-tidy/portability/RestrictSystemIncludesCheck.cpp; clang-tools-extra/clang-tidy/portability/SIMDIntrinsicsCheck.cpp; clang-tools-extra/clang-tidy/readability/AvoidConstParamsInDecls,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:65687,perform,performance,65687,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['perform'],['performance']
Performance,"lso be used as an offset with Private; segment address when using the Scratch Segment Buffer. Since FLAT_SCRATCH_LO is in units of 256 bytes, the offset must be right; shifted by 8 before moving into FLAT_SCRATCH_HI. FLAT_SCRATCH_HI corresponds to SGPRn-4 on GFX7, and SGPRn-6 on GFX8 (where; SGPRn is the highest numbered SGPR allocated to the wavefront).; FLAT_SCRATCH_HI is multiplied by 256 (as it is in units of 256 bytes) and; added to ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to calculate the per wavefront; FLAT SCRATCH BASE in flat memory instructions that access the scratch; aperture.; 2. The second word of Flat Scratch Init is 32-bit byte size of a single; work-items scratch memory usage. CP obtains this from the runtime, and it is always a multiple of DWORD. CP; checks that the value in the kernel dispatch packet Private Segment Byte; Size is not larger and requests the runtime to increase the queue's scratch; size if necessary. CP directly loads from the kernel dispatch packet Private Segment Byte Size; field and rounds up to a multiple of DWORD. Having CP load it once avoids; loading it at the beginning of every wavefront. The kernel prolog code must move it to FLAT_SCRATCH_LO which is SGPRn-3 on; GFX7 and SGPRn-5 on GFX8. FLAT_SCRATCH_LO is used as the FLAT SCRATCH SIZE; in flat memory instructions. * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Absolute flat scratch*:. If the kernel or any function it calls may use flat operations to access; scratch memory, the prolog code must set up the FLAT_SCRATCH register pair; (FLAT_SCRATCH_LO/FLAT_SCRATCH_HI which are in SGPRn-4/SGPRn-3). Initialization; uses Flat Scratch Init and Scratch Wavefront Offset SGPR registers (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`):. The Flat Scratch Init is the 64-bit address of the base of scratch backing; memory being managed by SPI for the queue executing the kernel dispatch. CP obtains this from the runtime. The kernel prolog must add the v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:196048,load,loads,196048,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"lso optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%rax``, then the value may be in either ``%al`` or; ``%ah``. It doesn't matter in practice, because the runtime will; simply save ``%rax``. However, if the stackmap reports 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a contract between an LLVM SVN revision and; the runtime. It is currently experimental and may change in the short; term, but minimizing the need to update the runtime is; important. Consequently, the stack map design is motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to parse the data; immediately after compiling a module and encode the information in its; own format. Since the runtime controls the allocation of sections, it; can reuse the same stack map space for multiple modules. Stackmap support is currently only implemented for 64-bit; platforms. However, a 32-bit implementation should be able to use the; same format with an insignificant amount of wasted space. .. _stackmap-section:. Stack Map Section; ^^^^^^^^^^^^^^^^^. A JIT compiler can easily access this section by providing its own; memory manager via the LLVM C API;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:15298,optimiz,optimize,15298,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['optimiz'],['optimize']
Performance,"lt ; mkdir prebuilt ; rm -rf prebuilt_a ; mkdir prebuilt_a; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -fdisable-module-hash; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt_a -fdisable-module-hash -DENABLE_A; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt_a -DENABLE_A. Instead of managing the different module versions manually, we can build implicit modules in a given cache path (using ``-fmodules-cache-path``), and reuse them as prebuilt implicit modules by passing ``-fprebuilt-module-path`` and ``-fprebuilt-implicit-modules``. .. code-block:: sh. rm -rf prebuilt; mkdir prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -DENABLE_A; find prebuilt -name ""*.pcm""; # prebuilt/1AYBIGPM8R2GA/A-3L1K4LUA6O31.pcm; # prebuilt/1AYBIGPM8R2GA/B-3L1K4LUA6O31.pcm; # prebuilt/VH0YZMF1OIRK/A-3L1K4LUA6O31.pcm; # prebuilt/VH0YZMF1OIRK/B-3L1K4LUA6O31.pcm; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -DENABLE_A. Finally we want to allow implicit modules for configurations that were not prebuilt. When using the clang driver a module cache path is implicitly selected. Using ``-cc1``, we simply add use the ``-fmodules-cache-path`` option. .. code-block:: sh. clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -fmodules-cache-path=cache; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-pat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:22642,cache,cache-path,22642,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['cache'],['cache-path']
Performance,"lt target will be used. .. option:: -mcpu=?, -mtune=?. Acts as an alias for :option:`--print-supported-cpus`. .. option:: -mcpu=help, -mtune=help. Acts as an alias for :option:`--print-supported-cpus`. .. option:: -march=<cpu>. Specify that Clang should generate code for a specific processor family; member and later. For example, if you specify -march=i486, the compiler is; allowed to generate instructions that are valid on i486 and later processors,; but which may not exist on earlier ones. Code Generation Options; ~~~~~~~~~~~~~~~~~~~~~~~. .. option:: -O0, -O1, -O2, -O3, -Ofast, -Os, -Oz, -Og, -O, -O4. Specify which optimization level to use:. :option:`-O0` Means ""no optimization"": this level compiles the fastest and; generates the most debuggable code. :option:`-O1` Somewhere between :option:`-O0` and :option:`-O2`. :option:`-O2` Moderate level of optimization which enables most; optimizations. :option:`-O3` Like :option:`-O2`, except that it enables optimizations that; take longer to perform or that may generate larger code (in an attempt to; make the program run faster). :option:`-Ofast` Enables all the optimizations from :option:`-O3` along; with other aggressive optimizations that may violate strict compliance with; language standards. :option:`-Os` Like :option:`-O2` with extra optimizations to reduce code; size. :option:`-Oz` Like :option:`-Os` (and thus :option:`-O2`), but reduces code; size further. :option:`-Og` Like :option:`-O1`. In future versions, this option might; disable different optimizations in order to improve debuggability. :option:`-O` Equivalent to :option:`-O1`. :option:`-O4` and higher. Currently equivalent to :option:`-O3`. .. option:: -g, -gline-tables-only, -gmodules. Control debug information output. Note that Clang debug information works; best at :option:`-O0`. When more than one option starting with `-g` is; specified, the last one wins:. :option:`-g` Generate debug information. :option:`-gline-tables-only` Generate only line table ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:10824,optimiz,optimizations,10824,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,2,"['optimiz', 'perform']","['optimizations', 'perform']"
Performance,"lt). Emit the profile using a binary encoding. For instrumentation-based profile; the output format is the indexed binary format. .. option:: --extbinary. Emit the profile using an extensible binary encoding. This option can only; be used with sample-based profile. The extensible binary encoding can be; more compact with compression enabled and can be loaded faster than the; default binary encoding. .. option:: --text. Emit the profile in text mode. This option can also be used with both; sample-based and instrumentation-based profile. When this option is used; the profile will be dumped in the text format that is parsable by the profile; reader. .. option:: --gcc. Emit the profile using GCC's gcov format (Not yet supported). .. option:: --sparse[=true|false]. Do not emit function records with 0 execution count. Can only be used in; conjunction with -instr. Defaults to false, since it can inhibit compiler; optimization during PGO. .. option:: --num-threads=<N>, -j. Use N threads to perform profile merging. When N=0, llvm-profdata auto-detects; an appropriate number of threads to use. This is the default. .. option:: --failure-mode=[any|all]. Set the failure mode. There are two options: 'any' causes the merge command to; fail if any profiles are invalid, and 'all' causes the merge command to fail; only if all profiles are invalid. If 'all' is set, information from any; invalid profiles is excluded from the final merged product. The default; failure mode is 'any'. .. option:: --prof-sym-list=<path>. Specify a file which contains a list of symbols to generate profile symbol; list in the profile. This option can only be used with sample-based profile; in extbinary format. The entries in this file are newline-separated. .. option:: --compress-all-sections=[true|false]. Compress all sections when writing the profile. This option can only be used; with sample-based profile in extbinary format. .. option:: --use-md5=[true|false]. Use MD5 to represent string in name table wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:3907,perform,perform,3907,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,1,['perform'],['perform']
Performance,"lt. 2. Align Cost & Execute: each VPlan must support both estimating the cost and; generating the output IR code, such that the cost estimation evaluates the; to-be-generated code reliably. 3. Support vectorizing additional constructs:. a. Outer-loop vectorization. In particular, VPlan must be able to model the; control-flow of the output IR which may include multiple basic-blocks and; nested loops.; b. SLP vectorization.; c. Combinations of the above, including nested vectorization: vectorizing; both an inner loop and an outer-loop at the same time (each with its own; VF and UF), mixed vectorization: vectorizing a loop with SLP patterns; inside [4]_, (re)vectorizing input IR containing vector code.; d. Function vectorization [2]_. 4. Support multiple candidates efficiently. In particular, similar candidates; related to a range of possible VF's and UF's must be represented efficiently.; Potential versioning needs to be supported efficiently. 5. Support vectorizing idioms, such as interleaved groups of strided loads or; stores. This is achieved by modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruction; patterns. Definitions; ===========; The low-level design of VPlan comprises of the following classes. :LoopVectorizationPlanner:; A LoopVectorizationPlanner is designed to handle the vectorization of a loop; or a loop nest. It ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:3197,load,loads,3197,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['load'],['loads']
Performance,"lt_type) - 1) must be valid vector; indices. If this condition cannot be determined statically but is false at; runtime, then the result vector is a :ref:`poison value <poisonvalues>`. The; ``idx`` parameter must be a vector index constant type (for most targets this; will be an integer pointer type). '``llvm.experimental.vector.reverse``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <2 x i8> @llvm.experimental.vector.reverse.v2i8(<2 x i8> %a); declare <vscale x 4 x i32> @llvm.experimental.vector.reverse.nxv4i32(<vscale x 4 x i32> %a). Overview:; """""""""""""""""". The '``llvm.experimental.vector.reverse.*``' intrinsics reverse a vector.; The intrinsic takes a single vector and returns a vector of matching type but; with the original lane order reversed. These intrinsics work for both fixed; and scalable vectors. While this intrinsic is marked as experimental the; recommended way to express reverse operations for fixed-width vectors is still; to use a shufflevector, as that may allow for more optimization opportunities. Arguments:; """""""""""""""""""". The argument to this intrinsic must be a vector. '``llvm.experimental.vector.deinterleave2``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare {<2 x double>, <2 x double>} @llvm.experimental.vector.deinterleave2.v4f64(<4 x double> %vec1); declare {<vscale x 4 x i32>, <vscale x 4 x i32>} @llvm.experimental.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> %vec1). Overview:; """""""""""""""""". The '``llvm.experimental.vector.deinterleave2``' intrinsic constructs two; vectors by deinterleaving the even and odd lanes of the input vector. This intrinsic works for both fixed and scalable vectors. While this intrinsic; supports all vector types the recommended way to express this operation for; fixed-width vectors is still to use a shufflevector, as that may allow for more; optimization ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:666701,optimiz,optimization,666701,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"ltin_usubll_overflow(unsigned long long x, unsigned long long y, unsigned long long *diff);; bool __builtin_umul_overflow (unsigned x, unsigned y, unsigned *prod);; bool __builtin_umull_overflow (unsigned long x, unsigned long y, unsigned long *prod);; bool __builtin_umulll_overflow(unsigned long long x, unsigned long long y, unsigned long long *prod);; bool __builtin_sadd_overflow (int x, int y, int *sum);; bool __builtin_saddl_overflow (long x, long y, long *sum);; bool __builtin_saddll_overflow(long long x, long long y, long long *sum);; bool __builtin_ssub_overflow (int x, int y, int *diff);; bool __builtin_ssubl_overflow (long x, long y, long *diff);; bool __builtin_ssubll_overflow(long long x, long long y, long long *diff);; bool __builtin_smul_overflow (int x, int y, int *prod);; bool __builtin_smull_overflow (long x, long y, long *prod);; bool __builtin_smulll_overflow(long long x, long long y, long long *prod);. Each builtin performs the specified mathematical operation on the; first two arguments and stores the result in the third argument. If; possible, the result will be equal to mathematically-correct result; and the builtin will return 0. Otherwise, the builtin will return; 1 and the result will be equal to the unique value that is equivalent; to the mathematically-correct result modulo two raised to the *k*; power, where *k* is the number of bits in the result type. The; behavior of these builtins is well-defined for all argument values. The first three builtins work generically for operands of any integer type,; including boolean types. The operands need not have the same type as each; other, or as the result. The other builtins may implicitly promote or; convert their operands before performing the operation. Query for this feature with ``__has_builtin(__builtin_add_overflow)``, etc. Floating point builtins; ---------------------------------------. ``__builtin_isfpclass``; -----------------------. ``__builtin_isfpclass`` is used to test if the speci",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:128372,perform,performs,128372,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['perform'],['performs']
Performance,"ltiple times to add multiple sections. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --binary-architecture <arch>, -B. Ignored for compatibility. .. option:: --disable-deterministic-archives, -U. Use real values for UIDs, GIDs and timestamps when updating archive member; headers. .. option:: --discard-all, -x. Remove most local symbols from the output. Different file formats may limit; this to a subset of the local symbols. For example, file and section symbols in; ELF objects will not be discarded. Additionally, remove all debug sections. .. option:: --dump-section <section>=<file>. Dump the contents of section ``<section>`` into the file ``<file>``. Can be; specified multiple times to dump multiple sections to different files.; ``<file>`` is unrelated to the input and output files provided to; :program:`llvm-objcopy` and as such the normal copying and editing; operations will still be performed. No operations are performed on the sections; prior to dumping them. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --enable-deterministic-archives, -D. Enable deterministic mode when copying archives, i.e. use 0 for archive member; header UIDs, GIDs and timestamp fields. On by default. .. option:: --help, -h. Print a summary of command line options. .. option:: --only-keep-debug. Produce a debug file as the output that only preserves contents of sections; useful for debugging purposes. For ELF objects, this removes the contents of `SHF_ALLOC` sections that are not; `SHT_NOTE` by making them `SHT_NOBITS` and shrinking the program headers where; possible. .. option:: --only-section <section>, -j. Remove all sections from the output, except for sections named ``<section>``.; Can be specified multiple times to keep multiple sections. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --redefine-sym <old>=<new>. Rename",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:2522,perform,performed,2522,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,1,['perform'],['performed']
Performance,"ltmp = fmul double %addtmp, %addtmp1; ret double %multmp; }. In this case, the LHS and RHS of the multiplication are the same value.; We'd really like to see this generate ""``tmp = x+3; result = tmp*tmp;``""; instead of computing ""``x+3``"" twice. Unfortunately, no amount of local analysis will be able to detect and; correct this. This requires two transformations: reassociation of; expressions (to make the add's lexically identical) and Common; Subexpression Elimination (CSE) to delete the redundant add instruction.; Fortunately, LLVM provides a broad range of optimizations that you can; use, in the form of ""passes"". LLVM Optimization Passes; ========================. LLVM provides many optimization passes, which do many different sorts of; things and have different tradeoffs. Unlike other systems, LLVM doesn't; hold to the mistaken notion that one set of optimizations is right for; all languages and for all situations. LLVM allows a compiler implementor; to make complete decisions about what optimizations to use, in which; order, and in what situation. As a concrete example, LLVM supports both ""whole module"" passes, which; look across as large of body of code as they can (often a whole file,; but if run at link time, this can be a substantial portion of the whole; program). It also supports and includes ""per-function"" passes which just; operate on a single function at a time, without looking at other; functions. For more information on passes and how they are run, see the; `How to Write a Pass <../../WritingAnLLVMPass.html>`_ document and the; `List of LLVM Passes <../../Passes.html>`_. For Kaleidoscope, we are currently generating functions on the fly, one; at a time, as the user types them in. We aren't shooting for the; ultimate optimization experience in this setting, but we also want to; catch the easy and quick stuff where possible. As such, we will choose; to run a few per-function optimizations as the user types the function; in. If we wanted to make a ""stat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:3667,optimiz,optimizations,3667,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimizations']
Performance,"ltw $XT, $XB, $UIM"", IIC_VecPerm, []>;. . No SDAG, intrinsic, builtin are required?. - Load/Store Vector: lxv stxv; . Has likely SDAG match:; (set v?:$XT, (load ix16addr:$src)); (set v?:$XT, (store ix16addr:$dst)). . Need define ix16addr in PPCInstrInfo.td; ix16addr: 16-byte aligned, see ""def memrix16"" in PPCInstrInfo.td. - Load/Store Vector Indexed: lxvx stxvx; . Has likely SDAG match:; (set v?:$XT, (load xoaddr:$src)); (set v?:$XT, (store xoaddr:$dst)). - Load/Store DWord: lxsd stxsd; . Similar to lxsdx/stxsdx:; def LXSDX : XX1Form<31, 588,; (outs vsfrc:$XT), (ins memrr:$src),; ""lxsdx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (load xoaddr:$src))]>;. . (set f64:$XT, (load iaddrX4:$src)); (set f64:$XT, (store iaddrX4:$dst)). - Load/Store SP, with conversion from/to DP: lxssp stxssp; . Similar to lxsspx/stxsspx:; def LXSSPX : XX1Form<31, 524, (outs vssrc:$XT), (ins memrr:$src),; ""lxsspx $XT, $src"", IIC_LdStLFD,; [(set f32:$XT, (load xoaddr:$src))]>;. . (set f32:$XT, (load iaddrX4:$src)); (set f32:$XT, (store iaddrX4:$dst)). - Load as Integer Byte/Halfword & Zero Indexed: lxsibzx lxsihzx; . Similar to lxsiwzx:; def LXSIWZX : XX1Form<31, 12, (outs vsfrc:$XT), (ins memrr:$src),; ""lxsiwzx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (PPClfiwzx xoaddr:$src))]>;. . (set f64:$XT, (PPClfiwzx xoaddr:$src)). - Store as Integer Byte/Halfword Indexed: stxsibx stxsihx; . Similar to stxsiwx:; def STXSIWX : XX1Form<31, 140, (outs), (ins vsfrc:$XT, memrr:$dst),; ""stxsiwx $XT, $dst"", IIC_LdStSTFD,; [(PPCstfiwx f64:$XT, xoaddr:$dst)]>;. . (PPCstfiwx f64:$XT, xoaddr:$dst). - Load Vector Halfword*8/Byte*16 Indexed: lxvh8x lxvb16x; . Similar to lxvd2x/lxvw4x:; def LXVD2X : XX1Form<31, 844,; (outs vsrc:$XT), (ins memrr:$src),; ""lxvd2x $XT, $src"", IIC_LdStLFD,; [(set v2f64:$XT, (int_ppc_vsx_lxvd2x xoaddr:$src))]>;. . (set v8i16:$XT, (int_ppc_vsx_lxvh8x xoaddr:$src)); (set v16i8:$XT, (int_ppc_vsx_lxvb16x xoaddr:$src)). - Store Vector Halfword*8/Byte*16 Indexed: stxvh8x stxvb16x; . Similar to stxv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt:18189,load,load,18189,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,2,['load'],['load']
Performance,"lude the x86 back-end, or some tests; will fail. .. code-block:: bash. cmake $LLVM_SRC_DIR -DCMAKE_BUILD_TYPE=Release \; -DLLVM_TARGETS_TO_BUILD=""ARM;X86;AArch64"". Other options you can use are:. .. code-block:: bash. Use Ninja instead of Make: ""-G Ninja""; Build with assertions on: ""-DLLVM_ENABLE_ASSERTIONS=True""; Local (non-sudo) install path: ""-DCMAKE_INSTALL_PREFIX=$HOME/llvm/install""; CPU flags: ""DCMAKE_C_FLAGS=-mcpu=cortex-a15"" (same for CXX_FLAGS). After that, just typing ``make -jN`` or ``ninja`` will build everything.; ``make -jN check-all`` or ``ninja check-all`` will run all compiler tests. For; running the test suite, please refer to :doc:`TestingGuide`. #. If you are building LLVM/Clang on an ARM board with 1G of memory or less,; please use ``gold`` rather then GNU ``ld``. In any case it is probably a good; idea to set up a swap partition, too. .. code-block:: bash. $ sudo ln -sf /usr/bin/ld /usr/bin/ld.gold. #. ARM development boards can be unstable and you may experience that cores; are disappearing, caches being flushed on every big.LITTLE switch, and; other similar issues. To help ease the effect of this, set the Linux; scheduler to ""performance"" on **all** cores using this little script:. .. code-block:: bash. # The code below requires the package 'cpufrequtils' to be installed.; for ((cpu=0; cpu<`grep -c proc /proc/cpuinfo`; cpu++)); do; sudo cpufreq-set -c $cpu -g performance; done. Remember to turn that off after the build, or you may risk burning your; CPU. Most modern kernels don't need that, so only use it if you have; problems. #. Running the build on SD cards is ok, but they are more prone to failures; than good quality USB sticks, and those are more prone to failures than; external hard-drives (those are also a lot faster). So, at least, you; should consider to buy a fast USB stick. On systems with a fast eMMC,; that's a good option too. #. Make sure you have a decent power supply (dozens of dollars worth) that can; provide *at least* 4 ampe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst:2413,cache,caches,2413,interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToBuildOnARM.rst,1,['cache'],['caches']
Performance,"lue based on the iteration; index modulo the vectorization size. This cannot be expressed by ``DW_OP_piece``; and ``DW_OP_bit_piece`` which only allow constant offsets to be expressed. Therefore, a new operator is defined that takes two location descriptions, an; offset and a size, and creates a composite that effectively uses the second; location description as an overlay of the first, positioned according to the; offset and size. See ``DW_OP_LLVM_overlay`` and ``DW_OP_LLVM_bit_overlay`` in; :ref:`amdgpu-dwarf-composite-location-description-operations`. Consider an array that has been partially registerized such that the currently; processed elements are held in registers, whereas the remainder of the array; remains in memory. Consider the loop in this C function, for example:. .. code::; :number-lines:. extern void foo(uint32_t dst[], uint32_t src[], int len) {; for (int i = 0; i < len; ++i); dst[i] += src[i];; }. Inside the loop body, the machine code loads ``src[i]`` and ``dst[i]`` into; registers, adds them, and stores the result back into ``dst[i]``. Considering the location of ``dst`` and ``src`` in the loop body, the elements; ``dst[i]`` and ``src[i]`` would be located in registers, all other elements are; located in memory. Let register ``R0`` contain the base address of ``dst``,; register ``R1`` contain ``i``, and register ``R2`` contain the registerized; ``dst[i]`` element. We can describe the location of ``dst`` as a memory location; with a register location overlaid at a runtime offset involving ``i``:. .. code::; :number-lines:. // 1. Memory location description of dst elements located in memory:; DW_OP_breg0 0. // 2. Register location description of element dst[i] is located in R2:; DW_OP_reg2. // 3. Offset of the register within the memory of dst:; DW_OP_breg1 0; DW_OP_lit4; DW_OP_mul. // 4. The size of the register element:; DW_OP_lit4. // 5. Make a composite location description for dst that is the memory #1 with; // the register #2 positioned as an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:37173,load,loads,37173,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['load'],['loads']
Performance,"lue that is live across the; loop boundary, single entry PHI nodes are inserted to each of the exit blocks; [#lcssa-construction]_ in order to ""close"" these values inside the loop.; In particular, consider the following loop:. .. code-block:: C. c = ...;; for (...) {; if (c); X1 = ...; else; X2 = ...; X3 = phi(X1, X2); // X3 defined; }. ... = X3 + 4; // X3 used, i.e. live; // outside the loop. In the inner loop, the X3 is defined inside the loop, but used; outside of it. In Loop Closed SSA form, this would be represented as follows:. .. code-block:: C. c = ...;; for (...) {; if (c); X1 = ...; else; X2 = ...; X3 = phi(X1, X2);; }; X4 = phi(X3);. ... = X4 + 4;. This is still valid LLVM; the extra phi nodes are purely redundant,; but all LoopPass'es are required to preserve them.; This form is ensured by the LCSSA (:ref:`-lcssa <passes-lcssa>`); pass and is added automatically by the LoopPassManager when; scheduling a LoopPass.; After the loop optimizations are done, these extra phi nodes; will be deleted by :ref:`-instcombine <passes-instcombine>`. Note that an exit block is outside of a loop, so how can such a phi ""close""; the value inside the loop since it uses it outside of it ? First of all,; for phi nodes, as; `mentioned in the LangRef <https://llvm.org/docs/LangRef.html#id311>`_:; ""the use of each incoming value is deemed to occur on the edge from the; corresponding predecessor block to the current block"". Now, an; edge to an exit block is considered outside of the loop because; if we take that edge, it leads us clearly out of the loop. However, an edge doesn't actually contain any IR, so in source code,; we have to choose a convention of whether the use happens in; the current block or in the respective predecessor. For LCSSA's purpose,; we consider the use happens in the latter (so as to consider the; use inside) [#point-of-use-phis]_. The major benefit of LCSSA is that it makes many other loop optimizations; simpler. First of all, a simple observation is that",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:11943,optimiz,optimizations,11943,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['optimiz'],['optimizations']
Performance,"lue(metadata i32 *%addr2, metadata !3, metadata !DIExpression()), !dbg !5; %loaded2 = load i32, i32* %addr2, !dbg !5; %add = add i32 %bar.0, 1, !dbg !5; call void @llvm.dbg.value(metadata i32 %add, metadata !3, metadata !DIExpression()), !dbg !5; %added = add i32 %loaded1, %loaded2; %cond = icmp ult i32 %added, %bar.0, !dbg !5; br i1 %cond, label %bb1, label %bb2, !dbg !5. bb2: ; preds = %bb1; ret i32 0, !dbg !5; }. If one compiles this IR with ``llc -o - -start-after=codegen-prepare -stop-after=expand-isel-pseudos -mtriple=x86_64--``, the following MIR is produced:. .. code-block:: text. bb.0.entry:; successors: %bb.1(0x80000000); liveins: $rdi. %2:gr64 = COPY $rdi; %3:gr32 = MOV32r0 implicit-def dead $eflags; DBG_VALUE 0, $noreg, !3, !DIExpression(), debug-location !5. bb.1.bb1:; successors: %bb.1(0x7c000000), %bb.2(0x04000000). %0:gr32 = PHI %3, %bb.0, %1, %bb.1; DBG_VALUE %0, $noreg, !3, !DIExpression(), debug-location !5; DBG_VALUE %2, $noreg, !3, !DIExpression(DW_OP_plus_uconst, 4, DW_OP_stack_value), debug-location !5; %4:gr32 = MOV32rm %2, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); %5:gr64_nosp = MOVSX64rr32 %0, debug-location !5; DBG_VALUE $noreg, $noreg, !3, !DIExpression(), debug-location !5; %1:gr32 = INC32r %0, implicit-def dead $eflags, debug-location !5; DBG_VALUE %1, $noreg, !3, !DIExpression(), debug-location !5; %6:gr32 = ADD32rm %4, %2, 4, killed %5, 0, $noreg, implicit-def dead $eflags :: (load 4 from %ir.addr2); %7:gr32 = SUB32rr %6, %0, implicit-def $eflags, debug-location !5; JB_1 %bb.1, implicit $eflags, debug-location !5; JMP_1 %bb.2, debug-location !5. bb.2.bb2:; %8:gr32 = MOV32r0 implicit-def dead $eflags; $eax = COPY %8, debug-location !5; RET 0, $eax, debug-location !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:31113,load,load,31113,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['load'],['load']
Performance,"lue. Arguments:; """""""""""""""""""". The argument and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``log2``' function but without; trapping or setting ``errno``. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. .. _int_fma:. '``llvm.fma.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.fma`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.fma.f32(float %a, float %b, float %c); declare double @llvm.fma.f64(double %a, double %b, double %c); declare x86_fp80 @llvm.fma.f80(x86_fp80 %a, x86_fp80 %b, x86_fp80 %c); declare fp128 @llvm.fma.f128(fp128 %a, fp128 %b, fp128 %c); declare ppc_fp128 @llvm.fma.ppcf128(ppc_fp128 %a, ppc_fp128 %b, ppc_fp128 %c). Overview:; """""""""""""""""". The '``llvm.fma.*``' intrinsics perform the fused multiply-add operation. Arguments:; """""""""""""""""""". The arguments and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``fma``' function but without; trapping or setting ``errno``. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. .. _int_fabs:. '``llvm.fabs.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.fabs`` on any; floating-point or vector of floating-point type. Not all targets support; all types however. ::. declare float @llvm.fabs.f32(float %Val); declare double @llvm.fabs.f64(double %Val); declare x86_fp80 @llvm.fabs.f80(x86_fp80 %Val); declare fp128 @llvm.fabs.f128(fp128 %Val); declare ppc_fp128 @llvm.fabs.ppcf128(ppc_fp128 %Val). Overview:; """""""""""""""""". The '``llvm.fabs.*``' intrinsics return the absolute value of the; operand. Arguments:; """""""""""""""""""". The argument and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:570972,perform,perform,570972,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"lue. The; address of the underlying pointer of the relative pointer is obtained by adding; the offset to the address of the offset value. '``llvm.arithmetic.fence``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <type>; @llvm.arithmetic.fence(<type> <op>). Overview:; """""""""""""""""". The purpose of the ``llvm.arithmetic.fence`` intrinsic; is to prevent the optimizer from performing fast-math optimizations,; particularly reassociation,; between the argument and the expression that contains the argument.; It can be used to preserve the parentheses in the source language. Arguments:; """""""""""""""""""". The ``llvm.arithmetic.fence`` intrinsic takes only one argument.; The argument and the return value are floating-point numbers,; or vector floating-point numbers, of the same type. Semantics:; """""""""""""""""""". This intrinsic returns the value of its operand. The optimizer can optimize; the argument, but the optimizer cannot hoist any component of the operand; to the containing context, and the optimizer cannot move the calculation of; any expression in the containing context into the operand. '``llvm.donothing``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.donothing() nounwind memory(none). Overview:; """""""""""""""""". The ``llvm.donothing`` intrinsic doesn't perform any operation. It's one of only; three intrinsics (besides ``llvm.experimental.patchpoint`` and; ``llvm.experimental.gc.statepoint``) that can be called with an invoke; instruction. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". This intrinsic does nothing, and it's removed by optimizers and ignored; by codegen. '``llvm.experimental.deoptimize``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare type @llvm.experimental.deoptimize(...) [ ""deopt""(...) ]. Overview:; """""""""""""""""". This intrinsic, together with :ref:`deoptimization operand bundles; <deopt_opbundles>`, allow frontends to express transfer of control and; frame-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:941215,optimiz,optimizer,941215,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,4,['optimiz'],"['optimize', 'optimizer']"
Performance,"lues with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the base pointer and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.load``' intrinsic is designed for conditional reading of selected vector elements in a single IR operation. It is useful for targets that support vector masked loads and allows vectorizing predicated basic blocks on these targets. Other targets may support this intrinsic differently, for example by lowering it into a sequence of branches that guard scalar load operations.; The result of this operation is equivalent to a regular vector load instruction followed by a 'select' between the loaded and the passthru values, predicated on the same mask. However, using this intrinsic prevents exceptions on memory access to masked-off lanes. ::. %res = call <16 x float> @llvm.masked.load.v16f32.p0(ptr %ptr, i32 4, <16 x i1>%mask, <16 x float> %passthru). ;; The result of the two following instructions is identical aside from potential memory access exception; %loadlal = load <16 x float>, ptr %ptr, align 4; %res = select <16 x i1> %mask, <16 x float> %loadlal, <16 x float> %passthru. .. _int_mstore:. '``llvm.masked.store.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The data stored in memory is a vector of any integer, floating-point or pointer data type. ::. declare void @llvm.masked.store.v8i32.p0 (<8 x i32> <value>, ptr <ptr>, i32 <alignment>, <8 x i1> <mask>); declare void @llvm.masked.store.v16f32.p0(<16 x float> <value>, ptr <ptr>, i32 <alignment>, <16 x i1> <mask>); ;; The data is a vector of pointers; declare void @llvm.masked.store.v8p0.p0 (<8 x ptr> <value>, ptr <ptr>, i32 <alignment>, <8 x i1> <mask>). Overview:; """""""""""""""""". Writes a vector to memory according to the provided mask. The mask holds a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:845263,load,load,845263,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"lues; specified by `SetMaximum()` and `SetMinimum()`.; * In `TMarker3DBox` when a box marker has a size equal to zero it is not painted.; Painting it produced a dot with the X11 backend.; * New class `TRatioPlot` implemented by Paul Gessinger <hello@paulgessinger.com>.; Class for displaying ratios, differences and fit residuals. `TRatioPlot` has two constructors, one which accepts two histograms, and is responsible; for setting up the calculation of ratios and differences. This calculation is in part; delegated to `TEfficiency`. A single option can be given as a parameter, that is; used to determine which procedure is chosen. The remaining option string is then; passed through to the calculation, if applicable. Several examples illustrate how to use this class. See:; `$ROOTSYS/tutorials/hist/ratioplot?.C`. * New option ""I"" allowing to draw TGraph with invisible axis (used by `TRatioPlot`);. ## New histogram drawing options. ### COL2; COL2 is a new rendering technique providing potential performance improvements; compared to the standard COL option. The performance comparison of the COL2 to; the COL option depends on the histogram and the size of the rendering region in; the current pad. In general, a small (approx. less than 100 bins per axis),; sparsely populated TH2 will render faster with the COL option. However, for larger histograms (approx. more than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:21852,perform,performance,21852,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['perform'],['performance']
Performance,"lume in our geometry, but since any volume; needs to have an associated medium, we will create a dummy one. You can; safely ignore the following lines for the time being, since materials; and media will be explained in detail later on. ``` {.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""Vacuum"",0,0,0);; root[] TGeoMedium *med = new TGeoMedium(""Vacuum"",1,mat);; ```. We can finally make our volume having a box shape. Note that the world; volume does not need to be a box - it can be any other shape. Generally,; boxes and tubes are the most recommendable shapes for this purpose due; to their fast navigation algorithms. ``` {.cpp}; root[] TGeoVolume *top=gGeoManager->MakeBox(""Top"",med,10.,10.,10.);; ```. The default units are in centimeters. Now we want to make this volume; our world. We have to do this operation **before** closing the geometry. ``` {.cpp}; root[] gGeoManager->SetTopVolume(top);; ```. This should be enough, but it is not since always after defining some; geometry hierarchy, **`TGeo`** needs to build some optimization; structures and perform some checks. Note the messages posted after the; statement is executed. We will describe the corresponding operations; later. ``` {.cpp}; root[] gGeoManager->CloseGeometry();; ```. Now we are really done with geometry building stage, but we would like; to see our simple world:. ``` {.cpp}; root[] top->SetLineColor(kMagenta);; root[] gGeoManager->SetTopVisible(); // the TOP is invisible; root[] top->Draw();; ```. ### Example 2: A Geometrical Hierarchy Look and Feel. Before going further, let us get a look and feel of interacting with the; modeller. For this, we will use one of the examples illustrating the; geometry package. To get an idea on the geometry structure created in; this example, just look at the link:; <http://root.cern.ch/root/html/tutorials/geom/rootgeom.C.html>. You will; notice that this is a bit more complex that just creating the ""world""; since several other volumes are created and put together i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:3766,optimiz,optimization,3766,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,2,"['optimiz', 'perform']","['optimization', 'perform']"
Performance,"lvm --llvmopt--> .llvm . Link time optimizations:; .llvm --llvm-ld--> .llvm --llvm-link-opt--> .llvm . Of course, many optimizations could be shared between llvmopt and; llvm-link-opt, but the wouldn't need to be shared... Thus compile time; could be faster, because we are using a ""smarter"" IR (SSA based). > BTW, about SGI, ""borrowing"" SSA-based optimizations from one compiler and; > putting it into another is not necessarily easier than re-doing it.; > Optimization code is usually heavily tied in to the specific IR they use. Understood. The only reason that I brought this up is because SGI's IR is; more similar to LLVM than it is different in many respects (SSA based,; relatively low level, etc), and could be easily adapted. Also their; optimizations are written in C++ and are actually somewhat; structured... of course it would be no walk in the park, but it would be; much less time consuming to adapt, say, SSA-PRE than to rewrite it. > But your larger point is valid that adding SSA based optimizations is; > feasible and should be fun. (Again, link time cost is the issue.). Assuming linktime cost wasn't an issue, the question is: ; Does using GCC's backend buy us anything?. > It also occurs to me that GCC is probably doing quite a bit of back-end; > optimization (step 16 in your list). Do you have a breakdown of that?. Not really. The irritating part of GCC is that it mixes it all up and; doesn't have a clean separation of concerns. A lot of the ""back end; optimization"" happens right along with other data optimizations (ie, CSE; of machine specific things). As far as REAL back end optimizations go, it looks something like this:. 1. Instruction combination: try to make CISCy instructions, if available; 2. Register movement: try to get registers in the right places for the; architecture to avoid register to register moves. For example, try to get; the first argument of a function to naturally land in %o0 for sparc.; 3. Instruction scheduling: 'nuff said :); 4. Registe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt:1611,optimiz,optimizations,1611,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,1,['optimiz'],['optimizations']
Performance,"lvm.smul.fix.sat.i4(i4 7, i4 4, i32 2) ; %res = 7; %res = call i4 @llvm.smul.fix.sat.i4(i4 -8, i4 5, i32 2) ; %res = -8; %res = call i4 @llvm.smul.fix.sat.i4(i4 -8, i4 -2, i32 1) ; %res = 7. ; Scale can affect the saturation result; %res = call i4 @llvm.smul.fix.sat.i4(i4 2, i4 4, i32 0) ; %res = 7 (2 x 4 -> clamped to 7); %res = call i4 @llvm.smul.fix.sat.i4(i4 2, i4 4, i32 1) ; %res = 4 (1 x 2 = 2). '``llvm.umul.fix.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.umul.fix.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.umul.fix.sat.i16(i16 %a, i16 %b, i32 %scale); declare i32 @llvm.umul.fix.sat.i32(i32 %a, i32 %b, i32 %scale); declare i64 @llvm.umul.fix.sat.i64(i64 %a, i64 %b, i32 %scale); declare <4 x i32> @llvm.umul.fix.sat.v4i32(<4 x i32> %a, <4 x i32> %b, i32 %scale). Overview; """""""""""""""""". The '``llvm.umul.fix.sat``' family of intrinsic functions perform unsigned; fixed point saturating multiplication on 2 arguments of the same scale. Arguments; """""""""""""""""""". The arguments (%a and %b) and the result may be of integer types of any bit; width, but they must have the same bit width. ``%a`` and ``%b`` are the two; values that will undergo unsigned fixed point multiplication. The argument; ``%scale`` represents the scale of both operands, and must be a constant; integer. Semantics:; """""""""""""""""""". This operation performs fixed point multiplication on the 2 arguments of a; specified scale. The result will also be returned in the same scale specified; in the third argument. If the result value cannot be precisely represented in the given scale, the; value is rounded up or down to the closest representable value. The rounding; direction is unspecified. The maximum value this operation can clamp to is the largest unsigned value; representable by the bit width of the first 2 arguments. The minimum value is the; smallest unsigned value representable by this bit width (",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:628082,perform,perform,628082,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"lvm.vp.is.fpclass.nxv2f16(<vscale x 2 x half> %x, i32 3, <vscale x 2 x i1> %m, i32 %evl). .. _int_mload_mstore:. Masked Vector Load and Store Intrinsics; ---------------------------------------. LLVM provides intrinsics for predicated vector load and store operations. The predicate is specified by a mask operand, which holds one bit per vector element, switching the associated vector lane on or off. The memory addresses corresponding to the ""off"" lanes are not accessed. When all bits of the mask are on, the intrinsic is identical to a regular vector load or store. When all bits are off, no memory is accessed. .. _int_mload:. '``llvm.masked.load.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The loaded data is a vector of any integer, floating-point or pointer data type. ::. declare <16 x float> @llvm.masked.load.v16f32.p0(ptr <ptr>, i32 <alignment>, <16 x i1> <mask>, <16 x float> <passthru>); declare <2 x double> @llvm.masked.load.v2f64.p0(ptr <ptr>, i32 <alignment>, <2 x i1> <mask>, <2 x double> <passthru>); ;; The data is a vector of pointers; declare <8 x ptr> @llvm.masked.load.v8p0.p0(ptr <ptr>, i32 <alignment>, <8 x i1> <mask>, <8 x ptr> <passthru>). Overview:; """""""""""""""""". Reads a vector from memory according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. The masked-off lanes in the result vector are taken from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is the alignment of the source location. It must be a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the base pointer and the type of the '``passthr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:843495,load,load,843495,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"lvm/source/root. For a given development platform there can be more than one adequate; generator. If you use Visual Studio, ""NMake Makefiles"" is a generator you can use; for building with NMake. By default, CMake chooses the most specific generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible val",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:6093,cache,cache,6093,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['cache'],['cache']
Performance,"ly at the specified; address will not be the first instruction in the snippet. Using this; annotation requires the subprocess execution mode. This is useful in; cases where the memory accessed by the snippet depends on the location; of the snippet, like RIP-relative addressing. EXAMPLE 1: benchmarking instructions; ------------------------------------. Assume you have an X86-64 machine. To measure the latency of a single; instruction, run:. .. code-block:: bash. $ llvm-exegesis --mode=latency --opcode-name=ADD64rr. Measuring the uop decomposition or inverse throughput of an instruction works similarly:. .. code-block:: bash. $ llvm-exegesis --mode=uops --opcode-name=ADD64rr; $ llvm-exegesis --mode=inverse_throughput --opcode-name=ADD64rr. The output is a YAML document (the default is to write to stdout, but you can; redirect the output to a file using `--benchmarks-file`):. .. code-block:: none. ---; key:; opcode_name: ADD64rr; mode: latency; config: ''; cpu_name: haswell; llvm_triple: x86_64-unknown-linux-gnu; num_repetitions: 10000; measurements:; - { key: latency, value: 1.0058, debug_string: '' }; error: ''; info: 'explicit self cycles, selecting one aliasing configuration.; Snippet:; ADD64rr R8, R8, R10; '; ... To measure the latency of all instructions for the host architecture, run:. .. code-block:: bash. $ llvm-exegesis --mode=latency --opcode-index=-1. EXAMPLE 2: benchmarking a custom code snippet; ---------------------------------------------. To measure the latency/uops of a custom piece of code, you can specify the; `snippets-file` option (`-` reads from standard input). .. code-block:: bash. $ echo ""vzeroupper"" | llvm-exegesis --mode=uops --snippets-file=-. Real-life code snippets typically depend on registers or memory.; :program:`llvm-exegesis` checks the liveliness of registers (i.e. any register; use has a corresponding def or is a ""live in""). If your code depends on the; value of some registers, you need to use snippet annotations to ensure setup; i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:5384,latency,latency,5384,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,2,['latency'],['latency']
Performance,"ly by (or fused with) other floating-point; operations. That is, the bits of the floating-point value are not examined. .. _int_fmuladd:. '``llvm.fmuladd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.fmuladd.f32(float %a, float %b, float %c); declare double @llvm.fmuladd.f64(double %a, double %b, double %c). Overview:; """""""""""""""""". The '``llvm.fmuladd.*``' intrinsic functions represent multiply-add; expressions that can be fused if the code generator determines that (a) the; target instruction set has support for a fused operation, and (b) that the; fused operation is more efficient than the equivalent, separate pair of mul; and add instructions. Arguments:; """""""""""""""""""". The '``llvm.fmuladd.*``' intrinsics each take three arguments: two; multiplicands, a and b, and an addend c. Semantics:; """""""""""""""""""". The expression:. ::. %0 = call float @llvm.fmuladd.f32(%a, %b, %c). is equivalent to the expression a \* b + c, except that it is unspecified; whether rounding will be performed between the multiplication and addition; steps. Fusion is not guaranteed, even if the target platform supports it.; If a fused multiply-add is required, the corresponding; :ref:`llvm.fma <int_fma>` intrinsic function should be used instead.; This never sets errno, just as '``llvm.fma.*``'. Examples:; """""""""""""""""". .. code-block:: llvm. %r2 = call float @llvm.fmuladd.f32(float %a, float %b, float %c) ; yields float:r2 = (a * b) + c. Hardware-Loop Intrinsics; ------------------------. LLVM support several intrinsics to mark a loop as a hardware-loop. They are; hints to the backend which are required to lower these intrinsics further to target; specific instructions, or revert the hardware-loop to a normal loop if target; specific restriction are not met and a hardware-loop can't be generated. These intrinsics may be modified in the future and are not intended to be used; outside the backend. Thus, front-end and mid-level optimizations should not be; generatin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:642089,perform,performed,642089,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"ly emit DWARF unwind when compact unwind encodings; aren't available. This is the default for arm64.; * ``always`` - Always emit DWARF unwind regardless.; * ``default`` - Use the platform-specific default (``always`` for all; non-arm64-platforms). ``no-compact-unwind`` is a performance optimization -- Clang will emit smaller; object files that are more quickly processed by the linker. This may cause; binary compatibility issues on older x86_64 targets, however, so use it with; caution. .. _configuration-files:. Configuration files; -------------------. Configuration files group command-line options and allow all of them to be; specified just by referencing the configuration file. They may be used, for; example, to collect options required to tune compilation for particular; target, such as ``-L``, ``-I``, ``-l``, ``--sysroot``, codegen options, etc. Configuration files can be either specified on the command line or loaded; from default locations. If both variants are present, the default configuration; files are loaded first. The command line option ``--config=`` can be used to specify explicit; configuration files in a Clang invocation. If the option is used multiple times,; all specified files are loaded, in order. For example:. ::. clang --config=/home/user/cfgs/testing.txt; clang --config=debug.cfg --config=runtimes.cfg. If the provided argument contains a directory separator, it is considered as; a file path, and options are read from that file. Otherwise the argument is; treated as a file name and is searched for sequentially in the directories:. - user directory,; - system directory,; - the directory where Clang executable resides. Both user and system directories for configuration files are specified during; clang build using CMake parameters, ``CLANG_CONFIG_FILE_USER_DIR`` and; ``CLANG_CONFIG_FILE_SYSTEM_DIR`` respectively. The first file found is used.; It is an error if the required file cannot be found. The default configuration files are searched for in ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:31022,load,loaded,31022,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['load'],['loaded']
Performance,"ly even ensure explicitly specified physical registers are; unique, so specifying multiple physical registers as alternatives, like; ``{r11}{r12},{r11}{r12}``, will assign r11 to both operands, not at all what was; intended.). Supported Constraint Code List; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The constraint codes are, in general, expected to behave the same way they do in; GCC. LLVM's support is often implemented on an 'as-needed' basis, to support C; inline asm code which was supported by GCC. A mismatch in behavior between LLVM; and GCC likely indicates a bug in LLVM. Some constraint codes are typically supported by all targets:. - ``r``: A register in the target's general purpose register class.; - ``m``: A memory address operand. It is target-specific what addressing modes; are supported, typical examples are register, or register + register offset,; or register + immediate offset (of some target-specific size).; - ``p``: An address operand. Similar to ``m``, but used by ""load address""; type instructions without touching memory.; - ``i``: An integer constant (of target-specific width). Allows either a simple; immediate, or a relocatable value.; - ``n``: An integer constant -- *not* including relocatable values.; - ``s``: An integer constant, but allowing *only* relocatable values.; - ``X``: Allows an operand of any kind, no constraint whatsoever. Typically; useful to pass a label for an asm branch or call. .. FIXME: but that surely isn't actually okay to jump out of an asm; block without telling llvm about the control transfer???). - ``{register-name}``: Requires exactly the named physical register. Other constraints are target-specific:. AArch64:. - ``z``: An immediate integer 0. Outputs ``WZR`` or ``XZR``, as appropriate.; - ``I``: An immediate integer valid for an ``ADD`` or ``SUB`` instruction,; i.e. 0 to 4095 with optional shift by 12.; - ``J``: An immediate integer that, when negated, is valid for an ``ADD`` or; ``SUB`` instruction, i.e. -1 to -4095 with optio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:221141,load,load,221141,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"ly features documented below. For further; information related to the semantics of the builtins, please refer to the `WebAssembly Specification <https://webassembly.github.io/spec/core/>`_.; In this section, when we refer to reference types, we are referring to; WebAssembly reference types, not C++ reference types unless stated; otherwise. ``__builtin_wasm_table_set``; ----------------------------. This builtin function stores a value in a WebAssembly table.; It takes three arguments.; The first argument is the table to store a value into, the second; argument is the index to which to store the value into, and the; third argument is a value of reference type to store in the table.; It returns nothing. .. code-block:: c++. static __externref_t table[0];; extern __externref_t JSObj;. void store(int index) {; __builtin_wasm_table_set(table, index, JSObj);; }. ``__builtin_wasm_table_get``; ----------------------------. This builtin function is the counterpart to ``__builtin_wasm_table_set``; and loads a value from a WebAssembly table of reference typed values.; It takes 2 arguments.; The first argument is a table of reference typed values and the; second argument is an index from which to load the value. It returns; the loaded reference typed value. .. code-block:: c++. static __externref_t table[0];. __externref_t load(int index) {; __externref_t Obj = __builtin_wasm_table_get(table, index);; return Obj;; }. ``__builtin_wasm_table_size``; -----------------------------. This builtin function returns the size of the WebAssembly table.; Takes the table as an argument and returns an unsigned integer (``size_t``); with the current table size. .. code-block:: c++. typedef void (*__funcref funcref_t)();; static __funcref table[0];. size_t getSize() {; return __builtin_wasm_table_size(table);; }. ``__builtin_wasm_table_grow``; -----------------------------. This builtin function grows the WebAssembly table by a certain amount.; Currently, as all WebAssembly tables created in C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:92665,load,loads,92665,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['load'],['loads']
Performance,"ly implemented allowing a label at the end of a compound statement,; and now we've implemented allowing a label to be followed by a declaration; instead of a statement.; - Implemented; `N2940 <https://www.open-std.org/jtc1/sc22/wg14/www/docs/n2940.pdf>`_ which; removes support for trigraphs in C23 and later. In earlier language modes,; trigraphs remain enabled by default in conforming modes (e.g. ``-std=c17``); and disabled by default in GNU and Microsoft modes (e.g., ``-std=gnu17`` or; ``-fms-compatibility``). If needed, you can enable trigraphs by passing; ``-ftrigraphs``. Non-comprehensive list of changes in this release; -------------------------------------------------. * Clang now has a ``__builtin_vectorelements()`` function that determines the number of elements in a vector.; For fixed-sized vectors, e.g., defined via ``__attribute__((vector_size(N)))`` or ARM NEON's vector types; (e.g., ``uint16x8_t``), this returns the constant number of elements at compile-time.; For scalable vectors, e.g., SVE or RISC-V V, the number of elements is not known at compile-time and is; determined at runtime.; * The ``__datasizeof`` keyword has been added. It is similar to ``sizeof``; except that it returns the size of a type ignoring tail padding.; * ``__builtin_classify_type()`` now classifies ``_BitInt`` values as the return value ``18``; and vector types as return value ``19``, to match GCC 14's behavior.; * The default value of `_MSC_VER` was raised from 1920 to 1933.; * Since MSVC 19.33 added undocumented attribute ``[[msvc::constexpr]]``, this release adds the attribute as well. * Added ``#pragma clang fp reciprocal``. * The version of Unicode used by Clang (primarily to parse identifiers) has been updated to 15.1. * Clang now defines macro ``__LLVM_INSTR_PROFILE_GENERATE`` when compiling with; PGO instrumentation profile generation, and ``__LLVM_INSTR_PROFILE_USE`` when; compiling with PGO profile use. New Compiler Flags; ------------------. * ``-fverify-intermediate-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:14318,scalab,scalable,14318,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['scalab'],['scalable']
Performance,"ly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. op",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4292,load,load,4292,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['load', 'queue']","['load', 'queue']"
Performance,"ly shortly before termination to ; insure closing of files and sockets before the unload of any library.; New collection 'ClosedObjects' holding pointers to TFile or TSocket that; have been closed but not deleted it. In the case of TSocket, they are added only; if they are closed by the CloseFiles.; Add a Close member function to TProofMgr since it is added to the list of socket.; Migrate the closing of files from various to a single place (T*System::Exit).; Fill in the implementation of TROOT::FindObjectAnyFile.; Mark TROOT as TObject::kInvalidObject as soon as its destructor starts,; in order to be able to veto some action later on (like autoloading). TSystem. Better handle the cases where the information in the rootmap file is (almost) empty. ; Avoid infinite loop if one of the dependent library is missing. Meta. Add new fast accessors to Merge routines (See the I/O package for more details.; Improve error message in case a schema evolution rule can not be loaded when the library is loaded; (from the generic 'it conflicts with one of the other rules' to 'the target member ... is unknown'.; Add the ability to explicitly forbid (or allow) the splitting of a class; (TClass::SetSplit ) so that user can inforce the use of a custom streamer in all possible split cases.; Improve the performance of TProcessUUID::AddUUID by reintroducing the THashList.; This significanly improve the performance of reading file with very large number of ; directories (A file with 100,000 directories was traversed in more than 8 minutes; and is now traversed in 15s) without noticeable affecting small files. TFolder. Several enhancement and clarification to TFolder::FindFullPathName. TStyle. Add the fill color attribute (SetLegendFillColor() and the font; attribute (SetLegendFont(). A new TStyle called ""Modern"" has been implemented. It can be set with:. gROOT->SetStyle(""Modern"");; ; It has very little decoration. It was made looking at the default styles; usually used by the experiments.; ; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html:1580,load,loaded,1580,core/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html,4,['load'],['loaded']
Performance,"ly, the narrower the target the better. E.g. if your target can parse several data formats, split it into several targets, one per format. Fuzzer Usage; ------------. Recent versions of Clang (starting from 6.0) include libFuzzer, and no extra installation is necessary. In order to build your fuzzer binary, use the `-fsanitize=fuzzer` flag during the; compilation and linking. In most cases you may want to combine libFuzzer with; AddressSanitizer_ (ASAN), UndefinedBehaviorSanitizer_ (UBSAN), or both. You can; also build with MemorySanitizer_ (MSAN), but support is experimental::. clang -g -O1 -fsanitize=fuzzer mytarget.c # Builds the fuzz target w/o sanitizers; clang -g -O1 -fsanitize=fuzzer,address mytarget.c # Builds the fuzz target with ASAN; clang -g -O1 -fsanitize=fuzzer,signed-integer-overflow mytarget.c # Builds the fuzz target with a part of UBSAN; clang -g -O1 -fsanitize=fuzzer,memory mytarget.c # Builds the fuzz target with MSAN. This will perform the necessary instrumentation, as well as linking with the libFuzzer library.; Note that ``-fsanitize=fuzzer`` links in the libFuzzer's ``main()`` symbol. If modifying ``CFLAGS`` of a large project, which also compiles executables; requiring their own ``main`` symbol, it may be desirable to request just the; instrumentation without linking::. clang -fsanitize=fuzzer-no-link mytarget.c. Then libFuzzer can be linked to the desired driver by passing in; ``-fsanitize=fuzzer`` during the linking stage. .. _libfuzzer-corpus:. Corpus; ------. Coverage-guided fuzzers like libFuzzer rely on a corpus of sample inputs for the; code under test. This corpus should ideally be seeded with a varied collection; of valid and invalid inputs for the code under test; for example, for a graphics; library the initial corpus might hold a variety of different small PNG/JPG/GIF; files. The fuzzer generates random mutations based around the sample inputs in; the current corpus. If a mutation triggers execution of a previously-uncovered; pat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:3507,perform,perform,3507,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['perform'],['perform']
Performance,"lysisIntroImages/OutputParameterIdentificationLattice.svg). To determine whether a statement reads or writes a field we can implement; symbolic evaluation of `DeclRefExpr`s, `LValueToRValue` casts, pointer; dereference operator and `MemberExpr`s. ### Using data flow results to identify output parameters. Let's take a look at how we use data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields proven to be overwritten in the; exit basic block of the function. ```c++; struct Customer {; int account_id;; std::string name;; };. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:18999,perform,perform,18999,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['perform'],['perform']
Performance,"m Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:150211,load,loaded,150211,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['load', 'queue']","['loaded', 'queue']"
Performance,"m a longer vector. G_BUILD_VECTOR, G_BUILD_VECTOR_TRUNC; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Create a vector from multiple scalar registers. No implicit; conversion is performed (i.e. the result element type must be the; same as all source operands). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTL",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:14440,perform,perform,14440,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,1,['perform'],['perform']
Performance,"m is lost. The more general issue; here, is that the LLVM type system uses ""structural equivalence"" instead; of ""name equivalence"". Another place this surprises people is if you; have two types in a high-level language that have the same structure; (e.g. two different structs that have a single int field): these types; will compile down into a single LLVM type and it will be impossible to; tell what it came from. Second, while LLVM does lose information, LLVM is not a fixed target: we; continue to enhance and improve it in many different ways. In addition; to adding new features (LLVM did not always support exceptions or debug; info), we also extend the IR to capture important information for; optimization (e.g. whether an argument is sign or zero extended,; information about pointers aliasing, etc). Many of the enhancements are; user-driven: people want LLVM to include some specific feature, so they; go ahead and extend it. Third, it is *possible and easy* to add language-specific optimizations,; and you have a number of choices in how to do it. As one trivial; example, it is easy to add language-specific optimization passes that; ""know"" things about code compiled for a language. In the case of the C; family, there is an optimization pass that ""knows"" about the standard C; library functions. If you call ""exit(0)"" in main(), it knows that it is; safe to optimize that into ""return 0;"" because C specifies what the; 'exit' function does. In addition to simple library knowledge, it is possible to embed a; variety of other language-specific information into the LLVM IR. If you; have a specific need and run into a wall, please bring the topic up on; the llvm-dev list. At the very worst, you can always treat LLVM as if it; were a ""dumb code generator"" and implement the high-level optimizations; you desire in your front-end, on the language-specific AST. Tips and Tricks; ===============. There is a variety of useful tips and tricks that you come to know after; working on/wi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst:10350,optimiz,optimizations,10350,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,1,['optimiz'],['optimizations']
Performance,"m to change; the default value for fAutoFlush. CASE 1 : autof > 0. autof is the number of consecutive entries after which TTree::Fill will; flush all branch buffers to disk. CASE 2 : autof < 0. When filling the Tree the branch buffers will be flushed to disk when; more than autof bytes have been written to the file. At the first FlushBaskets; TTree::Fill will replace fAutoFlush by the current value of fEntries. Calling this function with autof < 0 is interesting when it is hard to estimate; the size of one entry. This value is also independent of the Tree. When calling SetAutoFlush with no arguments, the; default value is -30000000, ie that the first AutoFlush will be done when; 30 MBytes of data are written to the file. CASE 3 : autof = 0; The AutoFlush mechanism is disabled. Flushing the buffers at regular intervals optimize the location of; consecutive entries on the disk. Changed the default value of AutoSave from 10 to 30 MBytes. New class TTreePerfStats; This new class is an important tool to measure the I/O performance of a Tree.; It shows the locations in the file when reading a Tree. In particular it is easy; to see the performance of the Tree Cache. The results can be:. drawn in a canvas.; printed on standard output.; saved to a file for processing later. Example of use; {; TFile *f = TFile::Open(""RelValMinBias-GEN-SIM-RECO.root"");; T = (TTree*)f->Get(""Events"");; Long64_t nentries = T->GetEntries();; T->SetCacheSize(10000000);; T->AddBranchToCache(""*"");. TTreePerfStats *ps= new TTreePerfStats(""ioperf"",T);. for (Int_t i=0;i<nentries;i++) {; T->GetEntry(i);; }; ps->SaveAs(""atlas_perf.root"");; }. then, in a root interactive session, one can do:. root > TFile f(""atlas_perf.root"");; root > ioperf->Draw();; root > ioperf->Print();. The Draw or Print functions print the following information:. TreeCache = TTree cache size in MBytes; N leaves = Number of leaves in the TTree; ReadTotal = Total number of zipped bytes read; ReadUnZip = Total number of unzipped bytes ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:7251,perform,performance,7251,tree/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html,2,['perform'],['performance']
Performance,"m which elements are collected and written to memory. The second operand is the base pointer for the store, it has the same underlying type as the element of the input vector operand. The third operand is the mask, a vector of boolean values. The mask and the input vector must have the same number of vector elements. Semantics:; """""""""""""""""""". The '``llvm.masked.compressstore``' intrinsic is designed for compressing data in memory. It allows to collect elements from possibly non-adjacent lanes of a vector and store them contiguously in memory in one IR operation. It is useful for targets that support compressing store operations and allows vectorizing loops with cross-iteration dependences like in the following example:. .. code-block:: c. // In this loop we load elements from A and store them consecutively in B; double *A, B; int *C;; for (int i = 0; i < size; ++i) {; if (C[i] != 0); B[j++] = A[i]; }. .. code-block:: llvm. ; Load elements from A.; %Tmp = call <8 x double> @llvm.masked.load.v8f64.p0(ptr %Aptr, i32 8, <8 x i1> %Mask, <8 x double> poison); ; Store all selected elements consecutively in array B; call <void> @llvm.masked.compressstore.v8f64(<8 x double> %Tmp, ptr %Bptr, <8 x i1> %Mask). ; %Bptr should be increased on each iteration according to the number of '1' elements in the Mask.; %MaskI = bitcast <8 x i1> %Mask to i8; %MaskIPopcnt = call i8 @llvm.ctpop.i8(i8 %MaskI); %MaskI64 = zext i8 %MaskIPopcnt to i64; %BNextInd = add i64 %BInd, %MaskI64. Other targets may support this intrinsic differently, for example, by lowering it into a sequence of branches that guard scalar store operations. Memory Use Markers; ------------------. This class of intrinsics provides information about the; :ref:`lifetime of memory objects <objectlifetime>` and ranges where variables; are immutable. .. _int_lifestart:. '``llvm.lifetime.start``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.lifetime.start(i64 <size>, ptr nocapture <ptr>)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:860186,load,load,860186,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"m-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle acc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42457,load,load,42457,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['load'],['load']
Performance,"m.memcpy.i32(; i8* getelementptr ([10 x i8]* @out.4543, i32 0, i32 0),; i8* getelementptr ([7 x i8]* @""\01LC28700"", i32 0, i32 0), i32 7, i32 1) ; %101 = call@printf(i8* ... @out.4543, i32 0, i32 0)) nounwind . It is basically doing:. memcpy(globalarray, ""string"");; printf(..., globalarray);; ; Anyway, by knowing that printf just reads the memory and forward substituting; the string directly into the printf, this eliminates reads from globalarray.; Since this pattern occurs frequently in crafty (due to the ""DisplayTime"" and; other similar functions) there are many stores to ""out"". Once all the printfs; stop using ""out"", all that is left is the memcpy's into it. This should allow; globalopt to remove the ""stored only"" global. //===---------------------------------------------------------------------===//. This code:. define inreg i32 @foo(i8* inreg %p) nounwind {; %tmp0 = load i8* %p; %tmp1 = ashr i8 %tmp0, 5; %tmp2 = sext i8 %tmp1 to i32; ret i32 %tmp2; }. could be dagcombine'd to a sign-extending load with a shift.; For example, on x86 this currently gets this:. 	movb	(%eax), %al; 	sarb	$5, %al; 	movsbl	%al, %eax. while it could get this:. 	movsbl	(%eax), %eax; 	sarl	$5, %eax. //===---------------------------------------------------------------------===//. GCC PR31029:. int test(int x) { return 1-x == x; } // --> return false; int test2(int x) { return 2-x == x; } // --> return x == 1 ?. Always foldable for odd constants, what is the rule for even?. //===---------------------------------------------------------------------===//. PR 3381: GEP to field of size 0 inside a struct could be turned into GEP; for next field in struct (which is at same address). For example: store of float into { {{}}, float } could be turned into a store to; the float directly. //===---------------------------------------------------------------------===//. The arg promotion pass should make use of nocapture to make its alias analysis; stuff much more precise. //===-------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:42524,load,load,42524,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['load']
Performance,"m/test/*``:. Add test cases for your test cases to the test suite. Once the intrinsic has been added to the system, you must add code generator; support for it. Generally you must do the following steps:. Add support to the .td file for the target(s) of your choice in; ``lib/Target/*/*.td``. This is usually a matter of adding a pattern to the .td file that matches the; intrinsic, though it may obviously require adding the instructions you want to; generate as well. There are lots of examples in the PowerPC and X86 backend; to follow. Adding a new SelectionDAG node; ==============================. As with intrinsics, adding a new SelectionDAG node to LLVM is much easier than; adding a new instruction. New nodes are often added to help represent; instructions common to many targets. These nodes often map to an LLVM; instruction (add, sub) or intrinsic (byteswap, population count). In other; cases, new nodes have been added to allow many targets to perform a common task; (converting between floating point and integer representation) or capture more; complicated behavior in a single node (rotate). #. ``include/llvm/CodeGen/ISDOpcodes.h``:. Add an enum value for the new SelectionDAG node. #. ``lib/CodeGen/SelectionDAG/SelectionDAG.cpp``:. Add code to print the node to ``getOperationName``. If your new node can be; evaluated at compile time when given constant arguments (such as an add of a; constant with another constant), find the ``getNode`` method that takes the; appropriate number of arguments, and add a case for your node to the switch; statement that performs constant folding for nodes that take the same number; of arguments as your new node. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add code to `legalize, promote, and expand; <CodeGenerator.html#selectiondag_legalize>`_ the node as necessary. At a; minimum, you will need to add a case statement for your node in; ``LegalizeOp`` which calls LegalizeOp on the node's operands, and returns a; new node if any of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:3775,perform,perform,3775,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,1,['perform'],['perform']
Performance,"m/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:303479,load,load,303479,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"m1, _a; ret; _y:; movd 4(%esp), %xmm0; movaps _a, %xmm1; pslld %xmm0, %xmm1; movaps %xmm1, _a; ret. ""y"" looks good, but ""x"" does silly movzwl stuff around into a GPR. It seems; like movd would be sufficient in both cases as the value is already zero ; extended in the 32-bit stack slot IIRC. For signed short, it should also be; save, as a really-signed value would be undefined for pslld. //===---------------------------------------------------------------------===//. #include <math.h>; int t1(double d) { return signbit(d); }. This currently compiles to:; 	subl	$12, %esp; 	movsd	16(%esp), %xmm0; 	movsd	%xmm0, (%esp); 	movl	4(%esp), %eax; 	shrl	$31, %eax; 	addl	$12, %esp; 	ret. We should use movmskp{s|d} instead. //===---------------------------------------------------------------------===//. CodeGen/X86/vec_align.ll tests whether we can turn 4 scalar loads into a single; (aligned) vector load. This functionality has a couple of problems. 1. The code to infer alignment from loads of globals is in the X86 backend,; not the dag combiner. This is because dagcombine2 needs to be able to see; through the X86ISD::Wrapper node, which DAGCombine can't really do.; 2. The code for turning 4 x load into a single vector load is target ; independent and should be moved to the dag combiner.; 3. The code for turning 4 x load into a vector load can only handle a direct ; load from a global or a direct load from the stack. It should be generalized; to handle any load from P, P+4, P+8, P+12, where P can be anything.; 4. The alignment inference code cannot handle loads from globals in non-static; mode because it doesn't look through the extra dyld stub load. If you try; vec_align.ll without -relocation-model=static, you'll see what I mean. //===---------------------------------------------------------------------===//. We should lower store(fneg(load p), q) into an integer load+xor+store, which; eliminates a constant pool load. For example, consider:. define i64 @ccosf(float %z.0, float ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:11568,load,loads,11568,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,2,['load'],['loads']
Performance,"m:. '``llvm.vector.reduce.fminimum.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vector.reduce.fminimum.v4f32(<4 x float> %a); declare double @llvm.vector.reduce.fminimum.v2f64(<2 x double> %a). Overview:; """""""""""""""""". The '``llvm.vector.reduce.fminimum.*``' intrinsics do a floating-point; ``MIN`` reduction of a vector, returning the result as a scalar. The return type; matches the element-type of the vector input. This instruction has the same comparison semantics as the '``llvm.minimum.*``'; intrinsic. That is, this intrinsic propagates NaNs and -0.0 is considered less; than +0.0. If any element of the vector is a NaN, the result is NaN. Arguments:; """"""""""""""""""""; The argument to this intrinsic must be a vector of floating-point values. '``llvm.vector.insert``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. ; Insert fixed type into scalable type; declare <vscale x 4 x float> @llvm.vector.insert.nxv4f32.v4f32(<vscale x 4 x float> %vec, <4 x float> %subvec, i64 <idx>); declare <vscale x 2 x double> @llvm.vector.insert.nxv2f64.v2f64(<vscale x 2 x double> %vec, <2 x double> %subvec, i64 <idx>). ; Insert scalable type into scalable type; declare <vscale x 4 x float> @llvm.vector.insert.nxv4f64.nxv2f64(<vscale x 4 x float> %vec, <vscale x 2 x float> %subvec, i64 <idx>). ; Insert fixed type into fixed type; declare <4 x double> @llvm.vector.insert.v4f64.v2f64(<4 x double> %vec, <2 x double> %subvec, i64 <idx>). Overview:; """""""""""""""""". The '``llvm.vector.insert.*``' intrinsics insert a vector into another vector; starting from a given index. The return type matches the type of the vector we; insert into. Conceptually, this can be used to build a scalable vector out of; non-scalable vectors, however this intrinsic can also be used on purely fixed; types. Scalable vectors can only be inserted into other scalable vectors. Arguments:; """"""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:662403,scalab,scalable,662403,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance,"m; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; local load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_wa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:378177,load,load,378177,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"m; different CUs are not ordered.; * In CU wavefront execution mode the wavefronts of a work-group are executed on; the SIMDs of a single CU of the WGP. Therefore, all global memory access by; the work-group access the same L0 which in turn ensures L1 accesses are; ordered and so do not require explicit management of the caches for; work-group synchronization. See ``WGP_MODE`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table` and; :ref:`amdgpu-target-features`. The code sequences used to implement the memory model for GFX10-GFX11 are defined in; table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table`. .. table:: AMDHSA Memory Model Code Sequences GFX10-GFX11; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX10-GFX11; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; slc=1 dlc=1. - If GFX10, omit dlc=1. - volatile. 1. buffer/global/flat_load; glc=1 dlc=1. 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1 dlc=1. - If GFX10, omit dlc=1. - volatile. 1. buffer/global/flat_store; dlc=1. - If GFX10, omit dlc=1. 2. s_waitcnt vscnt(0). - Must happen before; any following ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:343714,load,load,343714,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ma No 0.1  Width (wrt volume size) of Gaussian kernel estimator. NormTree No False  Normalize binary search tree. Configuration options for MVA method :. Configuration options reference for MVA method: FDA. Option Array Default value Predefined values Description. V No False  Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None  List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False  Print method-specific help message. CreateMVAPdfs No False  Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False  Events with negative weights are ignored in the training (but are included for testing and performance evaluation). Formula No (0)  The discrimination formula. ParRanges No ()  Parameter ranges. FitMethod No MINUIT MC, GA, SA, MINUIT Optimisation Method. Converger No None None, MINUIT FitMethod uses Converger to improve result. Configuration options for MVA method :. Configuration options reference for MVA method: LD. Option Array Default value Predefined values Description. V No False  Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None  List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False  Print method-specifi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:5996,perform,performance,5996,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['perform'],['performance']
Performance,"machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L0 and L1 caches at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is accessed as MTYPE UC (uncached) to avoid; needing to invalidate the L2 cache.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC (non-coherent). Since the private address space is only accessed; by a single thread, and is always write-before-read, there is never a need to; invalidate these entries from the L0 or L1 caches. Wavefronts are executed in native mode with in-order reporting of loads and; sample instructions. In this mode vmcnt reports completion of load, atomic with; return and sample instructions in order, and the vscnt reports the completion of; store and atomic without return in order. See ``MEM_ORDERED`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`. Wavefronts can be executed in WGP ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:341215,cache,caches,341215,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"mage html geometry008.png ""Overlap checking"". This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ~~~{.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision);; myNode->CheckOverlaps(precision);; ~~~. Here precision represents the desired maximum accepted overlap value in; centimeters (default value is 0.1). This tool checks all possible; significant pairs of candidates inside a given volume (not declared as; overlapping or division volumes). The check is performed by verifying; the mesh representation of one candidate against the shape of the other.; This sort of check cannot identify all possible overlapping topologies,; but it works for more than 95% and is much faster than the usual; shape-to-shape comparison. For a 100% reliability, one can perform the; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion *A)* is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap *B)* is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. On",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:93760,perform,perform,93760,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,2,['perform'],['perform']
Performance,"make an R?"". ***`A:`*** Well, in real life some objects have much more complex shapes; that an ***`R`***. The modeller cannot just know all of them; the idea; is to make a complex object by using elementary building blocks that; have known shapes (called ***`primitive shapes`***). Gluing these; together in the appropriate way is the user responsibility. ***`Q:`*** ""I am getting the global picture but not making much out of it... There; are also a lot of calls to TGeoVolume::AddNode() that I do not understand."". ***`A:`*** A volume is positioned inside another one by using this; method. The relative geometrical transformation as well as a copy number; must be specified. When positioned, a volume becomes a ***`node`*** of; its container and a new object of the class **`TGeoNode`** is; automatically created. This method is therefore the key element for the; creation of a hierarchical link between two volumes. As it will be; described further on in this document, there are few other methods; performing similar actions, but let us keep things simple for the time; being. In addition, notice that there are some visualization-related; calls in the example followed by a final `TGeoVolume::Draw() `call for; the top volume. These are explained in details in the section; ""Visualization Settings and Attributes"". At this point, you will; probably like to see how this geometry looks like. You just need to run; the example and you will get the following picture that you can rotate; using the mouse; or you can zoom / move it around (see what the Help; menu of the GL window displays). ``` {.cpp}; % root rootgeom.C; ```. ![](pictures/020001B1.jpg). Now let us browse the hierarchy that was just created. Start a browser; and double-click on the item simple1 representing the; ***`gGeoManager`*** object. Note that right click opens the context menu; of the manager class where several global methods are available. ``` {.cpp}; root[] new TBrowser;; ```. ![](pictures/020001B2.jpg). The folde",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:8061,perform,performing,8061,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performing']
Performance,"mal) pointers in that they convert integers to and from; corresponding pointer types, but there are additional implications to be; aware of. Because the bit-representation of a non-integral pointer may; not be stable, two identical casts of the same operand may or may not; return the same value. Said differently, the conversion to or from the; non-integral type depends on environmental state in an implementation; defined manner. If the frontend wishes to observe a *particular* value following a cast, the; generated IR must fence with the underlying environment in an implementation; defined manner. (In practice, this tends to require ``noinline`` routines for; such operations.). From the perspective of the optimizer, ``inttoptr`` and ``ptrtoint`` for; non-integral types are analogous to ones on integral types with one; key exception: the optimizer may not, in general, insert new dynamic; occurrences of such casts. If a new cast is inserted, the optimizer would; need to either ensure that a) all possible values are valid, or b); appropriate fencing is inserted. Since the appropriate fencing is; implementation defined, the optimizer can't do the latter. The former is; challenging as many commonly expected properties, such as; ``ptrtoint(v)-ptrtoint(v) == 0``, don't hold for non-integral types.; Similar restrictions apply to intrinsics that might examine the pointer bits,; such as :ref:`llvm.ptrmask<int_ptrmask>`. . The alignment information provided by the frontend for a non-integral pointer; (typically using attributes or metadata) must be valid for every possible ; representation of the pointer. .. _globalvars:. Global Variables; ----------------. Global variables define regions of memory allocated at compilation time; instead of run-time. Global variable definitions must be initialized. Global variables in other translation units can also be declared, in which; case they don't have an initializer. Global variables can optionally specify a :ref:`linkage type <linkage>",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:29670,optimiz,optimizer,29670,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance,"mall amount of memory |; | | that can be reclaimed. |; | | The value is ignored. |; +---------------------------+-------------------------------------------------------+; | M_PURGE_ALL | Same as M_PURGE but will force release all possible |; | | memory regardless of how long it takes. |; | | The value is ignored. |; +---------------------------+-------------------------------------------------------+; | M_MEMTAG_TUNING | Tunes the allocator's choice of memory tags to make |; | | it more likely that a certain class of memory errors |; | | will be detected. The value argument should be one of |; | | the enumerators of ``scudo_memtag_tuning``. |; +---------------------------+-------------------------------------------------------+; | M_THREAD_DISABLE_MEM_INIT | Tunes the per-thread memory initialization, 0 being |; | | the normal behavior, 1 disabling the automatic heap |; | | initialization. |; +---------------------------+-------------------------------------------------------+; | M_CACHE_COUNT_MAX | Set the maximum number of entries than can be cached |; | | in the Secondary cache. |; +---------------------------+-------------------------------------------------------+; | M_CACHE_SIZE_MAX | Sets the maximum size of entries that can be cached |; | | in the Secondary cache. |; +---------------------------+-------------------------------------------------------+; | M_TSDS_COUNT_MAX | Increases the maximum number of TSDs that can be used |; | | up to the limit specified at compile time. |; +---------------------------+-------------------------------------------------------+. Error Types; ===========. The allocator will output an error message, and potentially terminate the; process, when an unexpected behavior is detected. The output usually starts with; ``""Scudo ERROR:""`` followed by a short summary of the problem that occurred as; well as the pointer(s) involved. Once again, Scudo is meant to be a mitigation,; and might not be the most useful of tools to help you root",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:13988,cache,cached,13988,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,2,['cache'],"['cache', 'cached']"
Performance,"managing the bundled entry code object. See; :ref:`clang-offload-kind-table`. .. table:: Bundled Code Object Offload Kind; :name: clang-offload-kind-table. ============= ==============================================================; Offload Kind Description; ============= ==============================================================; host Host code object. ``clang-offload-bundler`` always includes; this entry as the first bundled code object entry. For an; embedded bundled code object this entry is not used by the; runtime and so is generally an empty code object. hip Offload code object for the HIP language. Used for all; HIP language offload code objects when the; ``clang-offload-bundler`` is used to bundle code objects as; intermediate steps of the tool chain. Also used for AMD GPU; code objects before ABI version V4 when the; ``clang-offload-bundler`` is used to create a *fat binary*; to be loaded by the HIP runtime. The fat binary can be; loaded directly from a file, or be embedded in the host code; object as a data section with the name ``.hip_fatbin``. hipv4 Offload code object for the HIP language. Used for AMD GPU; code objects with at least ABI version V4 when the; ``clang-offload-bundler`` is used to create a *fat binary*; to be loaded by the HIP runtime. The fat binary can be; loaded directly from a file, or be embedded in the host code; object as a data section with the name ``.hip_fatbin``. openmp Offload code object for the OpenMP language extension.; ============= ==============================================================. **target-triple**; The target triple of the code object. See `Target Triple; <https://clang.llvm.org/docs/CrossCompilation.html#target-triple>`_. The bundler accepts target triples with or without the optional environment; field:. ``<arch><sub>-<vendor>-<sys>``, or; ``<arch><sub>-<vendor>-<sys>-<env>``. However, in order to standardize outputs for tools that consume bitcode; bundles, bundles written by the bundler internally ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst:8796,load,loaded,8796,interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,1,['load'],['loaded']
Performance,"mand in the canvas File menu pops-up a print dialog where; the user can specify a preferred print command and the printer name. ![](pictures/0300002D.png). Both print parameters can be set via the new Print.Command and; Print.Printer rootrc resources as follows:. ```; # Printer settings.; WinNT.*.Print.Command: AcroRd32.exe; Unix.*.Print.Command: xprint -P%p %f; Print.Printer: 32-rb205-hp; Print.Directory: .; ```. If the `%p` and `%f` are specified as a part of the print command,; they will be replaced by the specified printer name and the file name.; All other parameters will be kept as they are written. A print button; is available in the canvas toolbar (activated via View menu/Toolbar). ## The ROOT Command Line. We have briefly touched on how to use the command line. There are; different types of commands. 1. Cling commands start with ""`.`"". ``` {.cpp}; root[] .? //this command will list all the Cling commands; root[] .L <filename> //load [filename]; root[] .x <filename> //load and execute [filename]; ```. 2. SHELL commands start with ""`.!`"" for example:. ``` {.cpp}; root[] .! ls; ```. 3. C++ commands follow C++ syntax (almost). ``` {.cpp}; root[] TBrowser *b = new TBrowser(); ```. ### Multi-line Commands. You can use the command line to execute multi-line commands. To begin; a multi-line command you must type a single left curly bracket `{`,; and to end it you must type a single right curly bracket `}`.; For example:. ``` {.cpp}; root[] {; end with '}'> Int_t j = 0;; end with '}'> for (Int_t i = 0; i < 3; i++); end with '}'> {; end with '}'> j= j + i;; end with '}'> cout << ""i = "" << i << "", j = "" << j << endl;; end with '}'> }; end with '}'> }; i = 0, j = 0; i = 1, j = 1; i = 2, j = 3; ```. It is more convenient to edit a script than the command line, and if; your multi line commands are getting unmanageable, you may want to; start with a script instead. ### Cling Extensions. We should say that some things are not standard C++. The Cling; interpreter has severa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md:25574,load,load,25574,documentation/users-guide/GettingStarted.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/GettingStarted.md,1,['load'],['load']
Performance,"mantics:; """""""""""""""""""". The '``llvm.get.active.lane.mask.*``' intrinsics are semantically equivalent; to:. ::. %m[i] = icmp ult (%base + i), %n. where ``%m`` is a vector (mask) of active/inactive lanes with its elements; indexed by ``i``, and ``%base``, ``%n`` are the two arguments to; ``llvm.get.active.lane.mask.*``, ``%icmp`` is an integer compare and ``ult``; the unsigned less-than comparison operator. Overflow cannot occur in; ``(%base + i)`` and its comparison against ``%n`` as it is performed in integer; numbers and not in machine numbers. If ``%n`` is ``0``, then the result is a; poison value. The above is equivalent to:. ::. %m = @llvm.get.active.lane.mask(%base, %n). This can, for example, be emitted by the loop vectorizer in which case; ``%base`` is the first element of the vector induction variable (VIV) and; ``%n`` is the loop tripcount. Thus, these intrinsics perform an element-wise; less than comparison of VIV with the loop tripcount, producing a mask of; true/false values representing active/inactive vector lanes, except if the VIV; overflows in which case they return false in the lanes where the VIV overflows.; The arguments are scalar types to accommodate scalable vector types, for which; it is unknown what the type of the step vector needs to be that enumerate its; lanes without overflow. This mask ``%m`` can e.g. be used in masked load/store instructions. These; intrinsics provide a hint to the backend. I.e., for a vector loop, the; back-edge taken count of the original scalar loop is explicit as the second; argument. Examples:; """""""""""""""""". .. code-block:: llvm. %active.lane.mask = call <4 x i1> @llvm.get.active.lane.mask.v4i1.i64(i64 %elem0, i64 429); %wide.masked.load = call <4 x i32> @llvm.masked.load.v4i32.p0v4i32(<4 x i32>* %3, i32 4, <4 x i1> %active.lane.mask, <4 x i32> poison). .. _int_experimental_vp_splice:. '``llvm.experimental.vp.splice``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overload",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:778307,perform,perform,778307,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"marking functions with this. ""amdgpu-no-workitem-id-y"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workitem.id.y intrinsic. ""amdgpu-no-workitem-id-z"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workitem.id.z intrinsic. ""amdgpu-no-workgroup-id-x"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.x intrinsic. ""amdgpu-no-workgroup-id-y"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.y intrinsic. ""amdgpu-no-workgroup-id-z"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.z intrinsic. ""amdgpu-no-dispatch-ptr"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.dispatch.ptr intrinsic. ""amdgpu-no-implicitarg-ptr"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.implicitarg.ptr intrinsic. ""amdgpu-no-dispatch-id"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.dispatch.id intrinsic. ""amdgpu-no-queue-ptr"" Similar to amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.queue.ptr intrinsic. Note that unlike the other ABI hint; attributes, the queue pointer may be required in situations where the; intrinsic call does not directly appear in the program. Some subtargets; require the queue pointer for to handle some addrspacecasts, as well; as the llvm.amdgcn.is.shared, llvm.amdgcn.is.private, llvm.trap, and; llvm.debug intrinsics. ""amdgpu-no-hostcall-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to the hostcall buffer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-heap-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to an initialized memory buffer; that conforms to the requirements of the malloc/free device library V1; version implementation. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:49598,queue,queue-ptr,49598,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue-ptr']
Performance,"mask, <4 x float> %t, <4 x float> poison. .. _int_vp_fabs:. '``llvm.vp.fabs.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.fabs.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.fabs.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.fabs.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point absolute value of a vector of floating-point values. Arguments:; """""""""""""""""""". The first operand and the result have the same vector of floating-point type.; The second operand is the vector mask and has the same number of elements as the; result vector type. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.fabs``' intrinsic performs floating-point absolute value; (:ref:`fabs <int_fabs>`) of the first vector operand on each enabled lane. The; result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.fabs.v4f32(<4 x float> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.fabs.v4f32(<4 x float> %a); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_sqrt:. '``llvm.vp.sqrt.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.sqrt.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.sqrt.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.sqrt.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point square root ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:742452,perform,performs,742452,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_and:. '``llvm.vp.and.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.and.v16i32 (<16 x i32> <left_op>, <16 x i32> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.and.nxv4i32 (<vscale x 4 x i32> <left_op>, <vscale x 4 x i32> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.and.v256i64 (<256 x i64> <left_op>, <256 x i64> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Vector-predicated and. Arguments:; """""""""""""""""""". The first two operands and the result have the same vector of integer type. The; third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.and``' intrinsic performs a bitwise and (:ref:`and <i_or>`) of; the first two operands on each enabled lane. The result on disabled lanes is; a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.and.v4i32(<4 x i32> %a, <4 x i32> %b, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = and <4 x i32> %a, %b; %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_xor:. '``llvm.vp.xor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.xor.v16i32 (<16 x i32> <left_op>, <16 x i32> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.xor.nxv4i32 (<vscale x 4 x i32> <left_op>, <vscale x 4 x i32> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.xor.v256i64 (<256 x i64> <left_op>, <256 x i64> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:714072,perform,performs,714072,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"matching type but; with the original lane order reversed. These intrinsics work for both fixed; and scalable vectors. While this intrinsic is marked as experimental the; recommended way to express reverse operations for fixed-width vectors is still; to use a shufflevector, as that may allow for more optimization opportunities. Arguments:; """""""""""""""""""". The argument to this intrinsic must be a vector. '``llvm.experimental.vector.deinterleave2``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare {<2 x double>, <2 x double>} @llvm.experimental.vector.deinterleave2.v4f64(<4 x double> %vec1); declare {<vscale x 4 x i32>, <vscale x 4 x i32>} @llvm.experimental.vector.deinterleave2.nxv8i32(<vscale x 8 x i32> %vec1). Overview:; """""""""""""""""". The '``llvm.experimental.vector.deinterleave2``' intrinsic constructs two; vectors by deinterleaving the even and odd lanes of the input vector. This intrinsic works for both fixed and scalable vectors. While this intrinsic; supports all vector types the recommended way to express this operation for; fixed-width vectors is still to use a shufflevector, as that may allow for more; optimization opportunities. For example:. .. code-block:: text. {<2 x i64>, <2 x i64>} llvm.experimental.vector.deinterleave2.v4i64(<4 x i64> <i64 0, i64 1, i64 2, i64 3>); ==> {<2 x i64> <i64 0, i64 2>, <2 x i64> <i64 1, i64 3>}. Arguments:; """""""""""""""""""". The argument is a vector whose type corresponds to the logical concatenation of; the two result types. '``llvm.experimental.vector.interleave2``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x double> @llvm.experimental.vector.interleave2.v4f64(<2 x double> %vec1, <2 x double> %vec2); declare <vscale x 8 x i32> @llvm.experimental.vector.interleave2.nxv8i32(<vscale x 4 x i32> %vec1, <vscale x 4 x i32> %vec2). Overview:; """""""""""""""""". The '``llvm.exp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:667412,scalab,scalable,667412,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance,"math-only`` implies:. * ``-fhonor-infinities``; * ``-fhonor-nans``. Defaults to ``-fno-finite-math-only``. .. option:: -f[no-]rounding-math. Force floating-point operations to honor the dynamically-set rounding mode by default. The result of a floating-point operation often cannot be exactly represented in the result type and therefore must be rounded. IEEE 754 describes different rounding modes that control how to perform this rounding, not all of which are supported by all implementations. C provides interfaces (``fesetround`` and ``fesetenv``) for dynamically controlling the rounding mode, and while it also recommends certain conventions for changing the rounding mode, these conventions are not typically enforced in the ABI. Since the rounding mode changes the numerical result of operations, the compiler must understand something about it in order to optimize floating point operations. Note that floating-point operations performed as part of constant initialization are formally performed prior to the start of the program and are therefore not subject to the current rounding mode. This includes the initialization of global variables and local ``static`` variables. Floating-point operations in these contexts will be rounded using ``FE_TONEAREST``. - The option ``-fno-rounding-math`` allows the compiler to assume that the rounding mode is set to ``FE_TONEAREST``. This is the default.; - The option ``-frounding-math`` forces the compiler to honor the dynamically-set rounding mode. This prevents optimizations which might affect results if the rounding mode changes or is different from the default; for example, it prevents floating-point operations from being reordered across most calls and prevents constant-folding when the result is not exactly representable. .. option:: -ffp-model=<value>. Specify floating point behavior. ``-ffp-model`` is an umbrella; option that encompasses functionality provided by other, single; purpose, floating point options. Valid values are:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:61223,perform,performed,61223,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,['perform'],['performed']
Performance,"mber of load and stores, or 2) custom lower memcpy (of small size) to; be ldmia / stmia. I think option 2 is better but the current register; allocator cannot allocate a chunk of registers at a time. A feasible temporary solution is to use specific physical registers at the; lowering time for small (<= 4 words?) transfer size. * ARM CSRet calling convention requires the hidden argument to be returned by; the callee. //===---------------------------------------------------------------------===//. We can definitely do a better job on BB placements to eliminate some branches.; It's very common to see llvm generated assembly code that looks like this:. LBB3:; ...; LBB4:; ...; beq LBB3; b LBB2. If BB4 is the only predecessor of BB3, then we can emit BB3 after BB4. We can; then eliminate beq and turn the unconditional branch to LBB2 to a bne. See McCat/18-imp/ComputeBoundingBoxes for an example. //===---------------------------------------------------------------------===//. Pre-/post- indexed load / stores:. 1) We should not make the pre/post- indexed load/store transform if the base ptr; is guaranteed to be live beyond the load/store. This can happen if the base; ptr is live out of the block we are performing the optimization. e.g. mov r1, r2; ldr r3, [r1], #4; ... vs. ldr r3, [r2]; add r1, r2, #4; ... In most cases, this is just a wasted optimization. However, sometimes it can; negatively impact the performance because two-address code is more restrictive; when it comes to scheduling. Unfortunately, liveout information is currently unavailable during DAG combine; time. 2) Consider spliting a indexed load / store into a pair of add/sub + load/store; to solve #1 (in TwoAddressInstructionPass.cpp). 3) Enhance LSR to generate more opportunities for indexed ops. 4) Once we added support for multiple result patterns, write indexed loads; patterns instead of C++ instruction selection code. 5) Use VLDM / VSTM to emulate indexed FP load / store. //===----------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:8212,load,load,8212,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,2,['load'],['load']
Performance,"mcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:272582,load,load,272582,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"md; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. Besides providing initial values, the initial ``DEFINE:`` directives for the; parameter substitutions in the above example serve a second purpose: they; establish the substitution order so that both ``%{check}`` and its parameters; expand as desired. There's a simple way to remember the required definition; order in a test file: define a substitution before any substitution that might; refer to it. In general, substitution expansion behaves as follows:. - Upon arriving at each ``RUN:`` line, lit expands all substitutions in that; ``RUN:`` line using their current values from the substitution list. No; substitution expansion is performed immediately at ``DEFINE:`` and; ``REDEFINE:`` directives except ``%(line)``, ``%(line+<number>)``, and; ``%(line-<number>)``.; - When expanding substitutions in a ``RUN:`` line, lit makes only one pass; through the substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:31207,perform,performed,31207,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['perform'],['performed']
Performance,"me is used:. ``<base>.opt.<format>.thin.<num>.<format>``. Darwin-only: when used for generating a linked binary from a source file; (through an intermediate object file), the driver will invoke `cc1` to; generate a temporary object file. The temporary remark file will be emitted; next to the object file, which will then be picked up by `dsymutil` and; emitted in the .dSYM bundle. This is available for all formats except YAML. For example:. ``clang -fsave-optimization-record=bitstream in.c -o out`` will generate. * ``/var/folders/43/9y164hh52tv_2nrdxrj31nyw0000gn/T/a-9be59b.o``. * ``/var/folders/43/9y164hh52tv_2nrdxrj31nyw0000gn/T/a-9be59b.opt.bitstream``. * ``out``. * ``out.dSYM/Contents/Resources/Remarks/out``. Darwin-only: compiling for multiple architectures will use the following; scheme:. ``<base>-<arch>.opt.<format>``. Note that this is incompatible with passing the; :option:`-foptimization-record-file` option. .. option:: -foptimization-record-file. Control the file to which optimization reports are written. This implies; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`. On Darwin platforms, this is incompatible with passing multiple; ``-arch <arch>`` options. .. option:: -foptimization-record-passes. Only include passes which match a specified regular expression. When optimization reports are being output (see; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`), this; option controls the passes that will be included in the final report. If this option is not used, all the passes are included in the optimization; record. .. _opt_fdiagnostics-show-hotness:. .. option:: -f[no-]diagnostics-show-hotness. Enable profile hotness information in diagnostic line. This option controls whether Clang prints the profile hotness associated; with diagnostics in the presence of profile-guided optimization information.; This is currently supported with optimization remarks (see; :ref:`Options to Emit Optimization Reports <rpass>`). The hotness",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:13141,optimiz,optimization,13141,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance,"me of the domain. Note that if the name is a; string then it can be combined across functions and translation units. A; self-reference can be used to create globally unique domain names. A; descriptive string may optionally be provided as a second list entry. The metadata identifying each scope is also itself a list containing two or; three entries. The first entry is the name of the scope. Note that if the name; is a string then it can be combined across functions and translation units. A; self-reference can be used to create globally unique scope names. A metadata; reference to the scope's domain is the second entry. A descriptive string may; optionally be provided as a third list entry. For example,. .. code-block:: llvm. ; Two scope domains:; !0 = !{!0}; !1 = !{!1}. ; Some scopes in these domains:; !2 = !{!2, !0}; !3 = !{!3, !0}; !4 = !{!4, !1}. ; Some scope lists:; !5 = !{!4} ; A list containing only scope !4; !6 = !{!4, !3, !2}; !7 = !{!3}. ; These two instructions don't alias:; %0 = load float, ptr %c, align 4, !alias.scope !5; store float %0, ptr %arrayidx.i, align 4, !noalias !5. ; These two instructions also don't alias (for domain !1, the set of scopes; ; in the !alias.scope equals that in the !noalias list):; %2 = load float, ptr %c, align 4, !alias.scope !5; store float %2, ptr %arrayidx.i2, align 4, !noalias !6. ; These two instructions may alias (for domain !0, the set of scopes in; ; the !noalias list is not a superset of, or equal to, the scopes in the; ; !alias.scope list):; %2 = load float, ptr %c, align 4, !alias.scope !6; store float %0, ptr %arrayidx.i, align 4, !noalias !7. '``fpmath``' Metadata; ^^^^^^^^^^^^^^^^^^^^^. ``fpmath`` metadata may be attached to any instruction of floating-point; type. It can be used to express the maximum acceptable error in the; result of that instruction, in ULPs, thus potentially allowing the; compiler to use a more efficient but less accurate method of computing; it. ULP is defined as follows:. If ``x`` is a re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:283202,load,load,283202,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"me). Physically,; a point that is INSIDE a **`TGeoShapeAssembly`** is always inside one of; the components, so a **`TGeoVolumeAssembly`** does not need to have a; medium. Due to the self-containment of assemblies, they are very; practical to use when a container is hard to define due to possible; overlaps during positioning. For instance, it is very easy creating; honeycomb structures. A very useful example for creating and using; assemblies can be found at:; <http://root.cern.ch/root/html/examples/assembly.C.html>`.`. Creation of an assembly is very easy: one has just to create a; **`TGeoVolumeAssembly`** object and position the components inside as; for any volume:. ``` {.cpp}; TGeoVolume *vol = new TGeoVolumeAssembly(name);; vol->AddNode(vdaughter1, cpy1, matrix1);; vol->AddNode(vdaughter2, cpy2, matrix2);; ```. Note that components cannot be declared as ""overlapping"" and that a; component can be an assembly volume. For existing flat volume; structures, one can define assemblies to force a hierarchical structure; therefore optimizing the performance. Usage of assemblies does NOT imply; penalties in performance, but in some cases, it can be observed that it; is not as performing as bounding the structure in a container volume; with a simple shape. Choosing a normal container is therefore; recommended whenever possible. ![Assemblies of volumes](pictures/080001CF.png). ### Geometrical Transformations. All geometrical transformations handled by the modeller are provided as; a built-in package. This was designed to minimize memory requirements; and optimize performance of point/vector master-to-local and; local-to-master computation. We need to have in mind that a; transformation in **`TGeo`** has two major use-cases. The first one is; for defining the placement of a volume with respect to its container; reference frame. This frame will be called 'master' and the frame of the; positioned volume - 'local'. If `T` is a transformation used for; positioning volume daughter",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:90629,optimiz,optimizing,90629,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,2,"['optimiz', 'perform']","['optimizing', 'performance']"
Performance,"me; underlying object (for more information on the *based on* terminology see; :ref:`the pointer aliasing rules <pointeraliasing>`). The intrinsic only captures the pointer argument through the return value. .. _int_threadlocal_address:. '``llvm.threadlocal.address``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.threadlocal.address(ptr) nounwind willreturn memory(none). Arguments:; """""""""""""""""""". The first argument is a pointer, which refers to a thread local global. Semantics:; """""""""""""""""""". The address of a thread local global is not a constant, since it depends on; the calling thread. The `llvm.threadlocal.address` intrinsic returns the; address of the given thread local global in the calling thread. .. _int_vscale:. '``llvm.vscale``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 llvm.vscale.i32(); declare i64 llvm.vscale.i64(). Overview:; """""""""""""""""". The ``llvm.vscale`` intrinsic returns the value for ``vscale`` in scalable; vectors such as ``<vscale x 16 x i8>``. Semantics:; """""""""""""""""""". ``vscale`` is a positive value that is constant throughout program; execution, but is unknown at compile time.; If the result value does not fit in the result type, then the result is; a :ref:`poison value <poisonvalues>`. Stack Map Intrinsics; --------------------. LLVM provides experimental intrinsics to support runtime patching; mechanisms commonly desired in dynamic language JITs. These intrinsics; are described in :doc:`StackMaps`. Element Wise Atomic Memory Intrinsics; -------------------------------------. These intrinsics are similar to the standard library memory intrinsics except; that they perform memory transfer as a sequence of atomic memory accesses. .. _int_memcpy_element_unordered_atomic:. '``llvm.memcpy.element.unordered.atomic``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.memcpy.element.unordered.atomi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:956249,scalab,scalable,956249,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance,"mean. //===---------------------------------------------------------------------===//. We should lower store(fneg(load p), q) into an integer load+xor+store, which; eliminates a constant pool load. For example, consider:. define i64 @ccosf(float %z.0, float %z.1) nounwind readonly {; entry:; %tmp6 = fsub float -0.000000e+00, %z.1		; <float> [#uses=1]; %tmp20 = tail call i64 @ccoshf( float %tmp6, float %z.0 ) nounwind readonly; ret i64 %tmp20; }; declare i64 @ccoshf(float %z.0, float %z.1) nounwind readonly. This currently compiles to:. LCPI1_0:					# <4 x float>; 	.long	2147483648	# float -0; 	.long	2147483648	# float -0; 	.long	2147483648	# float -0; 	.long	2147483648	# float -0; _ccosf:; 	subl	$12, %esp; 	movss	16(%esp), %xmm0; 	movss	%xmm0, 4(%esp); 	movss	20(%esp), %xmm0; 	xorps	LCPI1_0, %xmm0; 	movss	%xmm0, (%esp); 	call	L_ccoshf$stub; 	addl	$12, %esp; 	ret. Note the load into xmm0, then xor (to negate), then store. In PIC mode,; this code computes the pic base and does two loads to do the constant pool ; load, so the improvement is much bigger. The tricky part about this xform is that the argument load/store isn't exposed; until post-legalize, and at that point, the fneg has been custom expanded into ; an X86 fxor. This means that we need to handle this case in the x86 backend; instead of in target independent code. //===---------------------------------------------------------------------===//. Non-SSE4 insert into 16 x i8 is atrociously bad. //===---------------------------------------------------------------------===//. <2 x i64> extract is substantially worse than <2 x f64>, even if the destination; is memory. //===---------------------------------------------------------------------===//. INSERTPS can match any insert (extract, imm1), imm2 for 4 x float, and insert; any number of 0.0 simultaneously. Currently we only use it for simple; insertions. See comments in LowerINSERT_VECTOR_ELT_SSE4. //===-----------------------------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:13318,load,loads,13318,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,4,['load'],"['load', 'loads']"
Performance,"mechanisms and interfaces provided by LLVM to; support accurate garbage collection. Goals and non-goals; -------------------. LLVM's intermediate representation provides :ref:`garbage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected languages including Scheme, ML, Java, C#,; Perl, Python, Lua, Ruby, other scripting languages, and more. Note that LLVM **does not itself provide a garbage collector** --- this should; be part of your language's runtime library. LLVM provides a framework for; describing the garbage collectors requirements to the compiler. In particular,; LLVM provides support for generating stack maps at call sites, polling for a; safepoint, and emitting load and store barriers. You can also extend LLVM -; possibly through a loadable :ref:`code generation plugins <plugin>` - to; generate code and data structures which conforms to the *binary interface*; specified by the *runtime library*. This is similar to the relationship between; LLVM and DWARF debugging info, for example. The difference primarily lies in; the lack of an established standard in the domain of garbage collection --- thus; the need for a flexible extension mechanism. The aspects of the binary interface with which LLVM's GC support is; concerned are:. * Creation of GC safepoints within code where collection is allowed to execute; safely. * Computation of the stack map. For each safe point in the code, object; references within the stack frame must be identified so that the collector may; traverse and perhaps update them. * Write barriers when storing object references to the heap. These are commonly; used to optimize increm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:5956,load,load,5956,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['load']
Performance,"med as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the L1 cache.; Therefore, they do not use the sc0 bit for coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Theref",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:286737,cache,cache,286737,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"member and later. For example, if you specify -march=i486, the compiler is; allowed to generate instructions that are valid on i486 and later processors,; but which may not exist on earlier ones. Code Generation Options; ~~~~~~~~~~~~~~~~~~~~~~~. .. option:: -O0, -O1, -O2, -O3, -Ofast, -Os, -Oz, -Og, -O, -O4. Specify which optimization level to use:. :option:`-O0` Means ""no optimization"": this level compiles the fastest and; generates the most debuggable code. :option:`-O1` Somewhere between :option:`-O0` and :option:`-O2`. :option:`-O2` Moderate level of optimization which enables most; optimizations. :option:`-O3` Like :option:`-O2`, except that it enables optimizations that; take longer to perform or that may generate larger code (in an attempt to; make the program run faster). :option:`-Ofast` Enables all the optimizations from :option:`-O3` along; with other aggressive optimizations that may violate strict compliance with; language standards. :option:`-Os` Like :option:`-O2` with extra optimizations to reduce code; size. :option:`-Oz` Like :option:`-Os` (and thus :option:`-O2`), but reduces code; size further. :option:`-Og` Like :option:`-O1`. In future versions, this option might; disable different optimizations in order to improve debuggability. :option:`-O` Equivalent to :option:`-O1`. :option:`-O4` and higher. Currently equivalent to :option:`-O3`. .. option:: -g, -gline-tables-only, -gmodules. Control debug information output. Note that Clang debug information works; best at :option:`-O0`. When more than one option starting with `-g` is; specified, the last one wins:. :option:`-g` Generate debug information. :option:`-gline-tables-only` Generate only line table debug information. This; allows for symbolicated backtraces with inlining information, but does not; include any information about variables, their locations or types. :option:`-gmodules` Generate debug information that contains external; references to types defined in Clang modules or precompiled he",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:11163,optimiz,optimizations,11163,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['optimiz'],['optimizations']
Performance,"memcpy.i32(i8* %endptr, ; i8* getelementptr ([5 x i8]* @""\01LC42"", i32 0, i32 0), i32 5, i32 1); %3074 = call i32 @strlen(i8* %endptr) nounwind readonly ; ; This is interesting for a couple reasons. First, in this:. The memcpy+strlen strlen can be replaced with:. %3074 = call i32 @strlen([5 x i8]* @""\01LC42"") nounwind readonly . Because the destination was just copied into the specified memory buffer. This,; in turn, can be constant folded to ""4"". In other code, it contains:. %endptr6978 = bitcast i8* %endptr69 to i32* ; store i32 7107374, i32* %endptr6978, align 1; %3167 = call i32 @strlen(i8* %endptr69) nounwind readonly . Which could also be constant folded. Whatever is producing this should probably; be fixed to leave this as a memcpy from a string. Further, eon also has an interesting partially redundant strlen call:. bb8: ; preds = %_ZN18eonImageCalculatorC1Ev.exit; %682 = getelementptr i8** %argv, i32 6 ; <i8**> [#uses=2]; %683 = load i8** %682, align 4 ; <i8*> [#uses=4]; %684 = load i8* %683, align 1 ; <i8> [#uses=1]; %685 = icmp eq i8 %684, 0 ; <i1> [#uses=1]; br i1 %685, label %bb10, label %bb9. bb9: ; preds = %bb8; %686 = call i32 @strlen(i8* %683) nounwind readonly ; %687 = icmp ugt i32 %686, 254 ; <i1> [#uses=1]; br i1 %687, label %bb10, label %bb11. bb10: ; preds = %bb9, %bb8; %688 = call i32 @strlen(i8* %683) nounwind readonly . This could be eliminated by doing the strlen once in bb8, saving code size and; improving perf on the bb8->9->10 path. //===---------------------------------------------------------------------===//. I see an interesting fully redundant call to strlen left in 186.crafty:InputMove; which looks like:; %movetext11 = getelementptr [128 x i8]* %movetext, i32 0, i32 0 ; . bb62: ; preds = %bb55, %bb53; %promote.0 = phi i32 [ %169, %bb55 ], [ 0, %bb53 ] ; %171 = call i32 @strlen(i8* %movetext11) nounwind readonly align 1; %172 = add i32 %171, -1 ; <i32> [#uses=1]; %173 = getelementptr [128 x i8]* %movetext, i32 0, i32 %172 . ... no sto",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:39496,load,load,39496,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,4,['load'],['load']
Performance,"memory addresses and stored into the elements of a vector according to the mask. ::. declare <16 x float> @llvm.masked.expandload.v16f32 (ptr <ptr>, <16 x i1> <mask>, <16 x float> <passthru>); declare <2 x i64> @llvm.masked.expandload.v2i64 (ptr <ptr>, <2 x i1> <mask>, <2 x i64> <passthru>). Overview:; """""""""""""""""". Reads a number of scalar values sequentially from memory location provided in '``ptr``' and spreads them in a vector. The '``mask``' holds a bit for each vector lane. The number of elements read from memory is equal to the number of '1' bits in the mask. The loaded elements are positioned in the destination vector according to the sequence of '1' and '0' bits in the mask. E.g., if the mask vector is '10010001', ""expandload"" reads 3 values from memory addresses ptr, ptr+1, ptr+2 and places them in lanes 0, 3 and 7 accordingly. The masked-off lanes are filled by elements from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. It has the same underlying type as the element of the returned vector. The second operand, mask, is a vector of boolean values with the same number of elements as the return type. The third is a pass-through value that is used to fill the masked-off lanes of the result. The return type and the type of the '``passthru``' operand have the same vector type. Semantics:; """""""""""""""""""". The '``llvm.masked.expandload``' intrinsic is designed for reading multiple scalar values from adjacent memory addresses into possibly non-adjacent vector lanes. It is useful for targets that support vector expanding loads and allows vectorizing loop with cross-iteration dependency like in the following example:. .. code-block:: c. // In this loop we load from B and spread the elements into array A.; double *A, B; int *C;; for (int i = 0; i < size; ++i) {; if (C[i] != 0); A[i] = B[j++];; }. .. code-block:: llvm. ; Load several elements from array B and expand them in a vector.; ; The n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:856358,load,load,856358,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"memory, or; * the shadow memory tag is actually a short granule size, the value being loaded; is in bounds of the granule and the pointer tag is equal to the last byte of; the granule. Pointer tags between 1 to `TG-1` are possible and are as likely as any other; tag. This means that these tags in memory have two interpretations: the full; tag interpretation (where the pointer tag is between 1 and `TG-1` and the; last byte of the granule is ordinary data) and the short tag interpretation; (where the pointer tag is stored in the granule). When HWASAN detects an error near a memory tag between 1 and `TG-1`, it; will show both the memory tag and the last byte of the granule. Currently,; it is up to the user to disambiguate the two possibilities. Instrumentation; ===============. Memory Accesses; ---------------; In the majority of cases, memory accesses are prefixed with a call to; an outlined instruction sequence that verifies the tags. The code size; and performance overhead of the call is reduced by using a custom calling; convention that. * preserves most registers, and; * is specialized to the register containing the address, and the type and; size of the memory access. Currently, the following sequence is used:. .. code-block:: none. // int foo(int *a) { return *a; }; // clang -O2 --target=aarch64-linux-android30 -fsanitize=hwaddress -S -o - load.c; [...]; foo:; stp x30, x20, [sp, #-16]!; adrp x20, :got:__hwasan_shadow // load shadow address from GOT into x20; ldr x20, [x20, :got_lo12:__hwasan_shadow]; bl __hwasan_check_x0_2_short_v2 // call outlined tag check; // (arguments: x0 = address, x20 = shadow base;; // ""2"" encodes the access type and size); ldr w0, [x0] // inline load; ldp x30, x20, [sp], #16; ret. [...]; __hwasan_check_x0_2_short_v2:; sbfx x16, x0, #4, #52 // shadow offset; ldrb w16, [x20, x16] // load shadow tag; cmp x16, x0, lsr #56 // extract address tag, compare with shadow tag; b.ne .Ltmp0 // jump to short tag handler on mismatch; .Ltmp1:; ret; .Ltm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:3372,perform,performance,3372,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['perform'],['performance']
Performance,"memory-deallocation function (``free``, for example); on a memory allocation which existed before the call. As a result, uncaptured pointers that are known to be dereferenceable; prior to a call to a function with the ``nofree`` attribute are still; known to be dereferenceable after the call. The capturing condition is; necessary in environments where the function might communicate the; pointer to another thread which then deallocates the memory. Alternatively,; ``nosync`` would ensure such communication cannot happen and even captured; pointers cannot be freed by the function. A ``nofree`` function is explicitly allowed to free memory which it; allocated or (if not ``nosync``) arrange for another thread to free; memory on it's behalf. As a result, perhaps surprisingly, a ``nofree``; function can return a pointer to a previously deallocated memory object.; ``noimplicitfloat``; Disallows implicit floating-point code. This inhibits optimizations that; use floating-point code and floating-point registers for operations that are; not nominally floating-point. LLVM instructions that perform floating-point; operations or require access to floating-point registers may still cause; floating-point code to be generated. Also inhibits optimizations that create SIMD/vector code and registers from; scalar code such as vectorization or memcpy/memset optimization. This; includes integer vectors. Vector instructions present in IR may still cause; vector code to be generated.; ``noinline``; This attribute indicates that the inliner should never inline this; function in any situation. This attribute may not be used together; with the ``alwaysinline`` attribute.; ``nomerge``; This attribute indicates that calls to this function should never be merged; during optimization. For example, it will prevent tail merging otherwise; identical code sequences that raise an exception or terminate the program.; Tail merging normally reduces the precision of source location information,; making sta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:90163,optimiz,optimizations,90163,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"ment *elem,; Double_t weight);; void TGeoMixture::DefineElement(Int_t iel, Int_t z, Int_t natoms);; ~~~. or:. ~~~{.cpp}; void AddElement(TGeoMaterial* mat, Double_t weight);; void AddElement(TGeoElement* elem, Double_t weight);; void AddElement(TGeoElement* elem, Int_t natoms);; void AddElement(Double_t a, Double_t z, Double_t weight); ~~~. - `iel:` index of the element` [0,nel-1]`; - `a` and `z:` the atomic mass and charge; - `weight:` proportion by mass of the elements; - `natoms`: number of atoms of the element in the molecule making the; mixture. The radiation length is automatically computed when all elements are; defined. Since tracking MC provide several other ways to create; materials/mixtures, the materials classes are likely to evolve as the; interfaces to these engines are being developed. Generally in the; process of tracking material properties are not enough and more specific; media properties have to be defined. These highly depend on the MC; performing tracking and sometimes allow the definition of different; media properties (e.g. energy or range cuts) for the same material. \anchor GM00b; ### Radionuclides. A new class TGeoElementRN was introduced in this version to; provide support for radioactive nuclides and their decays. A database of; 3162 radionuclides can be loaded on demand via the table of elements; (TGeoElementTable class). One can make then materials/mixtures; based on these radionuclides and use them in a geometry. ~~~{.cpp}; root[] TGeoManager *geom = new TGeoManager(""geom"",""radionuclides"");; root[] TGeoElementTable *table = geom->GetElementTable();; root[] TGeoElementRN *c14 = table->GetElementRN(14,6); // A,Z; root[] c14->Print();; 6-C-014 ENDF=60140; A=14; Z=6; Iso=0; Level=0[MeV]; Dmass=3.0199[MeV];; Hlife=1.81e+11[s] J/P=0+; Abund=0; Htox=5.8e-10; Itox=5.8e-10; Stat=0; Decay modes:; BetaMinus Diso: 0 BR: 100.000% Qval: 0.1565; ~~~. One can make materials or mixtures from radionuclides:. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md:4776,perform,performing,4776,geom/geom/doc/materials.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/materials.md,1,['perform'],['performing']
Performance,"ment* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An example of a branch with an object allocated and; owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = new Event();; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. TTreeFormula (TTree::Draw, TTree::Scan). Fix CollectionTree->Scan(""reco_ee_et[][2]:reco_ee_et[0][2]""); where reco_ee_et is a vector<vector<double> > See http://root.cern/phpBB2/viewtopic.php?t=6536; Insure that the formula that are used as indices or as argument to special functions have their branch(es) loaded once. This fixes http://root.cern/phpBB2/viewtopic.php?p=27080#27080; Correct the drawing of ""X[1]:X[5]"" when X is a vector< vector<float> >; and X[1].size()!=X[5].size(). (reported at http://root.cern/phpBB2/viewtopic.php?p=27070); Correct the passing of NaN to function being called by TTree::Draw. Splitting STL collections of pointers; STL collection of pointers can now be split by calling. TBranch *branch = tree->Branch( branchname, STLcollection, buffsize, splitlevel ). where STLcollection is the address of a pointer to std::vector, std::list,; std::deque, std::set or std::multiset containing pointers to objects.; and where the splitlevel is a value bigger than 100 then the collection; will be written in split mode. Ie. if it contains objects of any; types deriving from TTrack this function will sort the objects; basing on their type and store them in separate branches in split; mode.; The ROOT test example in ROOTSYS/test",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:3515,load,loaded,3515,tree/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html,2,['load'],['loaded']
Performance,"ment, even though it may read or write the memory that the; pointer points to if accessed through other pointers. If a function reads from or writes to a readnone pointer argument, the; behavior is undefined. ``readonly``; This attribute indicates that the function does not write through this; pointer argument, even though it may write to the memory that the pointer; points to. If a function writes to a readonly pointer argument, the behavior is; undefined. ``writeonly``; This attribute indicates that the function may write to, but does not read; through this pointer argument (even though it may read from the memory that; the pointer points to). If a function reads from a writeonly pointer argument, the behavior is; undefined. ``writable``; This attribute is only meaningful in conjunction with ``dereferenceable(N)``; or another attribute that implies the first ``N`` bytes of the pointer; argument are dereferenceable. In that case, the attribute indicates that the first ``N`` bytes will be; (non-atomically) loaded and stored back on entry to the function. This implies that it's possible to introduce spurious stores on entry to; the function without introducing traps or data races. This does not; necessarily hold throughout the whole function, as the pointer may escape; to a different thread during the execution of the function. See also the; :ref:`atomic optimization guide <Optimization outside atomic>`. The ""other attributes"" that imply dereferenceability are; ``dereferenceable_or_null`` (if the pointer is non-null) and the; ``sret``, ``byval``, ``byref``, ``inalloca``, ``preallocated`` family of; attributes. Note that not all of these combinations are useful, e.g.; ``byval`` arguments are known to be writable even without this attribute. The ``writable`` attribute cannot be combined with ``readnone``,; ``readonly`` or a ``memory`` attribute that does not contain; ``argmem: write``. ``dead_on_unwind``; At a high level, this attribute indicates that the pointer argum",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:70149,load,loaded,70149,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loaded']
Performance,"ments of; release. 2. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:374248,load,load,374248,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ments that match; the standard C99 library as being the C99 library functions, and may; perform optimizations or generate code for them under that assumption.; This is something we'd like to change in the future to provide better; support for freestanding environments and non-C-based languages. .. _i_va_arg:. '``va_arg``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <resultval> = va_arg <va_list*> <arglist>, <argty>. Overview:; """""""""""""""""". The '``va_arg``' instruction is used to access arguments passed through; the ""variable argument"" area of a function call. It is used to implement; the ``va_arg`` macro in C. Arguments:; """""""""""""""""""". This instruction takes a ``va_list*`` value and the type of the; argument. It returns a value of the specified argument type and; increments the ``va_list`` to point to the next argument. The actual; type of ``va_list`` is target specific. Semantics:; """""""""""""""""""". The '``va_arg``' instruction loads an argument of the specified type; from the specified ``va_list`` and causes the ``va_list`` to point to; the next argument. For more information, see the variable argument; handling :ref:`Intrinsic Functions <int_varargs>`. It is legal for this instruction to be called in a function which does; not take a variable number of arguments, for example, the ``vfprintf``; function. ``va_arg`` is an LLVM instruction instead of an :ref:`intrinsic; function <intrinsics>` because it takes a type as an argument. Example:; """""""""""""""". See the :ref:`variable argument processing <int_varargs>` section. Note that the code generator does not yet fully support va\_arg on many; targets. Also, it does not currently support va\_arg with aggregate; types on any target. .. _i_landingpad:. '``landingpad``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <resultval> = landingpad <resultty> <clause>+; <resultval> = landingpad <resultty> cleanup <clause>*. <clause> := catch <type> <value>; <clause> := filter <array constant type> <array co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:479680,load,loads,479680,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loads']
Performance,"ments; the operator does not count. ``!sra(``\ *a*\ ``,`` *count*\ ``)``; This operator shifts *a* right arithmetically by *count* bits and produces the resulting; value. The operation is performed on a 64-bit integer; the result; is undefined for shift counts outside 0...63. ``!srl(``\ *a*\ ``,`` *count*\ ``)``; This operator shifts *a* right logically by *count* bits and produces the resulting; value. The operation is performed on a 64-bit integer; the result; is undefined for shift counts outside 0...63. ``!strconcat(``\ *str1*\ ``,`` *str2*\ ``, ...)``; This operator concatenates the string arguments *str1*, *str2*, etc., and; produces the resulting string. ``!sub(``\ *a*\ ``,`` *b*\ ``)``; This operator subtracts *b* from *a* and produces the arithmetic difference. ``!subst(``\ *target*\ ``,`` *repl*\ ``,`` *value*\ ``)``; This operator replaces all occurrences of the *target* in the *value* with; the *repl* and produces the resulting value. The *value* can; be a string, in which case substring substitution is performed. The *value* can be a record name, in which case the operator produces the *repl*; record if the *target* record name equals the *value* record name; otherwise it; produces the *value*. ``!substr(``\ *string*\ ``,`` *start*\ [``,`` *length*]\ ``)``; This operator extracts a substring of the given *string*. The starting; position of the substring is specified by *start*, which can range; between 0 and the length of the string. The length of the substring; is specified by *length*; if not specified, the rest of the string is; extracted. The *start* and *length* arguments must be integers. ``!tail(``\ *a*\ ``)``; This operator produces a new list with all the elements; of the list *a* except for the zeroth one. (See also ``!head``.). ``!tolower(``\ *a*\ ``)``; This operator converts a string input *a* to lower case. ``!toupper(``\ *a*\ ``)``; This operator converts a string input *a* to upper case. ``!xor(``\ *a*\ ``,`` *b*\ ``, ...)``; This operato",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:72692,perform,performed,72692,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['performed']
Performance,"menus for x/y axis, add some items similar to native ROOT menus; 7. Introduce context menu for TPaveStats, let switch single elements in the box; 8. Enable usage of all context menus on touch devices; 9. Implement JSROOT.Math.Prob function, provides probability value in stat box; 10. Introduce context menu for color palette (z axis); 11. Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6. ## Changes in 3.8; 1. Let use HTML element pointer in JSROOT.draw function like:; JSROOT.draw(document.getElementsByTagName(""div"")[0], obj, ""hist"");; Normally unique identifier was used before, which is not required any longer.; Of course, old functionality with element identifier will work as well.; 2. TreePlayer can also be used for trees, which not yet read from the file.; Requires appropriate changes in TRootSniffer class.; 3. Fix error in I/O with members like: `Double_t *fArr; //[fN]`; 4. Introduce JSROOT.OpenFile function. It loads I/O functionality automatically,; therefore can be used directly after loading JSRootCore.js script; 5. Same is done with JSROOT.draw function. It is defined in the JSRootCore.js; and can be used directly. Makes usage of JSROOT easier; 6. Introduce JSRootPainter.more.js script, where painters for auxiliary classes; will be implemented.; 7. Implement painter for TEllipse, TLine, TArrow classes; 8. Fix several problems with markers drawing; implement plus, asterisk, mult symbols.; 9. Implement custom layout, which allows to configure user-defined layout for displayed objects; 10. Fix errors with scaling of axis labels.; 11. Support also Y axis with custom labels like: http://jsroot.gsi.de/dev/?nobrowser&file=../files/atlas.root&item=LEDShapeHeightCorr_Gain0;1&opt=col. ## Changes in 3.7; 1. Support of X axis with custom labels like: http://jsroot.gsi.de/dev/?nobrowser&json=../files/hist_xlabels.json; 2. Extend functionality of JSROOT.addDrawFunc() function. One could register type-specific; `make_request` and `after_request` fu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:62249,load,loads,62249,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,2,['load'],"['loading', 'loads']"
Performance,"merge instruction locations if it replaces multiple; instructions with a single merged instruction, *and* that merged instruction; does not correspond to any of the original instructions' locations. The API to; use is ``Instruction::applyMergedLocation``. The purpose of this rule is to ensure that a) the single merged instruction; has a location with an accurate scope attached, and b) to prevent misleading; single-stepping (or breakpoint) behavior. Often, merged instructions are memory; accesses which can trap: having an accurate scope attached greatly assists in; crash triage by identifying the (possibly inlined) function where the bad; memory access occurred. This rule is also meant to assist SamplePGO by banning; scenarios in which a sample of a block containing a merged instruction is; misattributed to a block containing one of the instructions-to-be-merged. Examples of transformations that should follow this rule include:. * Merging identical loads/stores which occur on both sides of a CFG diamond; (see the ``MergedLoadStoreMotion`` pass). * Merging identical loop-invariant stores (see the LICM utility; ``llvm::promoteLoopAccessesToScalars``). * Peephole optimizations which combine multiple instructions together, like; ``(add (mul A B) C) => llvm.fma.f32(A, B, C)``. Note that the location of; the ``fma`` does not exactly correspond to the locations of either the; ``mul`` or the ``add`` instructions. Examples of transformations for which this rule *does not* apply include:. * Block-local peepholes which delete redundant instructions, like; ``(sext (zext i8 %x to i16) to i32) => (zext i8 %x to i32)``. The inner; ``zext`` is modified but remains in its block, so the rule for; :ref:`preserving locations<WhenToPreserveLocation>` should apply. * Converting an if-then-else CFG diamond into a ``select``. Preserving the; debug locations of speculated instructions can make it seem like a condition; is true when it's not (or vice versa), which leads to a confusing; single-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst:4101,load,loads,4101,interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,1,['load'],['loads']
Performance,"mes in my tree but just something inside."". **A:** By default, TGeoVolume::Draw() paints the content of; a given volume three levels down. You can change this by using:; gGeoManager::SetVisLevel(n);. Not only that, but none of the volumes at intermediate levels (0-2) are; visible on the drawing unless they are final leaves' on their branch; (e.g. have no other volumes positioned inside). This behavior is the; default one and corresponds to leaves' global visualization mode; (`TGeoManager::fVisOption = 1`). In order to see on the screen the; intermediate containers, one can change this mode:; gGeoManager->SetVisOption(0). **Q:** ""Volumes are highlighted when moving the mouse over their vertices. What does it mean?"". **A:** Indeed, moving the mouse close to some volume vertices; selects it. By checking the `Event Status` entry in the root canvas; `Options` menu, you will see exactly which is the selected node in the; bottom right. Right-clicking when a volume is selected will open its; context menu where several actions can be performed (e.g. drawing it). **Q:** ""OK, but now I do not want to see all the geometry, but just a particular volume and its content. How can I do this?"". **A:** Once you have set a convenient global visualization option; and level, what you need is just call the `Draw()` method of your; interesting volume. You can do this either by interacting with the; expanded tree of volumes in a ROOT browser (where the context menu of; any volume is available), either by getting a pointer to it (e.g. by; name): `gGeoManager->GetVolume(""vol_name"")->Draw();`. \anchor GP04b; ### Visualization Settings and Attributes. Supposing you now understand the basic things to do for drawing the; geometry or parts of it, you still might be not happy and wishing to; have more control on it. We will describe below how you can fine-tune some; settings. Since the corresponding attributes are flags belonging to; volume and node objects, you can change them at any time (even ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:100956,perform,performed,100956,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performed']
Performance,"meters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact that when performing a hypothesis test for discovery the null is background-only, but when performing an inverted hypothesis test the null is a signal+background model. The new convention is that the p-value for both the null and the alternate are taken from the same tail (as specified by the test statistic). Both CLs+b and CLb are equivalent to these p-values, and the HypoTestResult has a simple switch SetBackgroundIsAlt() to specify the pairing between (null p-value, alternate p-value) and (CLb, CLs+b). HypoTestInverter, HypoTestInverterResult, HypoTestInverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the Hy",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:2772,perform,performing,2772,roofit/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html,4,['perform'],['performing']
Performance,"mic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If CU wavefront execution; mode, omit.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If CU wavefront execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1 dlc=1. - If GFX11, omit dlc=1. 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_gl*_inv.; - Ensures the load; has completed; before invalidating; the caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:347111,load,loads,347111,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"mic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:232786,load,load,232786,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"mic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:357956,load,load,357956,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"mic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acq_rel - agent - generic 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. flat_atomic; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); mu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:322974,perform,performing,322974,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"mic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 3. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc1=1; store atomic release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; sc0=1 sc1=1; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the follo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:309502,load,load,309502,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"mic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246096,load,load,246096,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"mily of instructions for string; operations. The TRANSLATE ones are probably more difficult to exploit. --. We don't take full advantage of builtins like fabsl because the calling; conventions require f128s to be returned by invisible reference. --. ADD LOGICAL WITH SIGNED IMMEDIATE could be useful when we need to; produce a carry. SUBTRACT LOGICAL IMMEDIATE could be useful when we; need to produce a borrow. (Note that there are no memory forms of; ADD LOGICAL WITH CARRY and SUBTRACT LOGICAL WITH BORROW, so the high; part of 128-bit memory operations would probably need to be done; via a register.). --. We don't use ICM, STCM, or CLM. --. We don't use ADD (LOGICAL) HIGH, SUBTRACT (LOGICAL) HIGH,; or COMPARE (LOGICAL) HIGH yet. --. DAGCombiner doesn't yet fold truncations of extended loads. Functions like:. unsigned long f (unsigned long x, unsigned short *y); {; return (x << 32) | *y;; }. therefore end up as:. sllg %r2, %r2, 32; llgh %r0, 0(%r3); lr %r2, %r0; br %r14. but truncating the load would give:. sllg %r2, %r2, 32; lh %r2, 0(%r3); br %r14. --. Functions like:. define i64 @f1(i64 %a) {; %and = and i64 %a, 1; ret i64 %and; }. ought to be implemented as:. lhi %r0, 1; ngr %r2, %r0; br %r14. but two-address optimizations reverse the order of the AND and force:. lhi %r0, 1; ngr %r0, %r2; lgr %r2, %r0; br %r14. CodeGen/SystemZ/and-04.ll has several examples of this. --. Out-of-range displacements are usually handled by loading the full; address into a register. In many cases it would be better to create; an anchor point instead. E.g. for:. define void @f4a(i128 *%aptr, i64 %base) {; %addr = add i64 %base, 524288; %bptr = inttoptr i64 %addr to i128 *; %a = load volatile i128 *%aptr; %b = load i128 *%bptr; %add = add i128 %a, %b; store i128 %add, i128 *%aptr; ret void; }. (from CodeGen/SystemZ/int-add-08.ll) we load %base+524288 and %base+524296; into separate registers, rather than using %base+524288 as a base for both. --. Dynamic stack allocations round the size to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt:2237,load,load,2237,interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/SystemZ/README.txt,2,['load'],['load']
Performance,"minate call instructions entirely. The real power of this pass is that it provides context-sensitive mod/ref; information for call instructions. This allows the optimizer to know that calls; to a function do not clobber or read the value of the global, allowing loads and; stores to be eliminated. .. note::. This pass is somewhat limited in its scope (only support non-address taken; globals), but is very quick analysis. The ``-steens-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^. The ``-steens-aa`` pass implements a variation on the well-known ""Steensgaard's; algorithm"" for interprocedural alias analysis. Steensgaard's algorithm is a; unification-based, flow-insensitive, context-insensitive, and field-insensitive; alias analysis that is also very scalable (effectively linear time). The LLVM ``-steens-aa`` pass implements a ""speculatively field-**sensitive**""; version of Steensgaard's algorithm using the Data Structure Analysis framework.; This gives it substantially more precision than the standard algorithm while; maintaining excellent analysis scalability. .. note::. ``-steens-aa`` is available in the optional ""poolalloc"" module. It is not part; of the LLVM core. The ``-ds-aa`` pass; ^^^^^^^^^^^^^^^^^^^. The ``-ds-aa`` pass implements the full Data Structure Analysis algorithm. Data; Structure Analysis is a modular unification-based, flow-insensitive,; context-**sensitive**, and speculatively field-**sensitive** alias; analysis that is also quite scalable, usually at ``O(n * log(n))``. This algorithm is capable of responding to a full variety of alias analysis; queries, and can provide context-sensitive mod/ref information as well. The; only major facility not implemented so far is support for must-alias; information. .. note::. ``-ds-aa`` is available in the optional ""poolalloc"" module. It is not part of; the LLVM core. The ``-scev-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^. The ``-scev-aa`` pass implements AliasAnalysis queries by translating them into; ScalarEvolution queries. This g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:26005,scalab,scalability,26005,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['scalab'],['scalability']
Performance,"mine the location of values at a specific position in; the code. LLVM does not maintain any mapping between those values and; any higher-level entity. The runtime must be able to interpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:17972,load,loads,17972,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['load'],['loads']
Performance,"mined statically but is false at runtime, then the result vector; is a :ref:`poison value <poisonvalues>`. '``llvm.vector.extract``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. ; Extract fixed type from scalable type; declare <4 x float> @llvm.vector.extract.v4f32.nxv4f32(<vscale x 4 x float> %vec, i64 <idx>); declare <2 x double> @llvm.vector.extract.v2f64.nxv2f64(<vscale x 2 x double> %vec, i64 <idx>). ; Extract scalable type from scalable type; declare <vscale x 2 x float> @llvm.vector.extract.nxv2f32.nxv4f32(<vscale x 4 x float> %vec, i64 <idx>). ; Extract fixed type from fixed type; declare <2 x double> @llvm.vector.extract.v2f64.v4f64(<4 x double> %vec, i64 <idx>). Overview:; """""""""""""""""". The '``llvm.vector.extract.*``' intrinsics extract a vector from within another; vector starting from a given index. The return type must be explicitly; specified. Conceptually, this can be used to decompose a scalable vector into; non-scalable parts, however this intrinsic can also be used on purely fixed; types. Scalable vectors can only be extracted from other scalable vectors. Arguments:; """""""""""""""""""". The ``vec`` is the vector from which we will extract a subvector. The ``idx`` specifies the starting element number within ``vec`` from which a; subvector is extracted. ``idx`` must be a constant multiple of the known-minimum; vector length of the result type. If the result type is a scalable vector,; ``idx`` is first scaled by the result type's runtime scaling factor. Elements; ``idx`` through (``idx`` + num_elements(result_type) - 1) must be valid vector; indices. If this condition cannot be determined statically but is false at; runtime, then the result vector is a :ref:`poison value <poisonvalues>`. The; ``idx`` parameter must be a vector index constant type (for most targets this; will be an integer pointer type). '``llvm.experimental.vector.reverse``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sy",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:664998,scalab,scalable,664998,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['scalab'],['scalable']
Performance,"mis-behaving passes, you; can debug incorrect code generation by either LLC or the JIT, using; ``bugpoint``. The process ``bugpoint`` follows in this case is to try to; narrow the code down to a function that is miscompiled by one or the other; method, but since for correctness, the entire program must be run,; ``bugpoint`` will compile the code it deems to not be affected with the C; Backend, and then link in the shared object it generates. To debug the JIT:. .. code-block:: bash. bugpoint -run-jit -output=[correct output file] [bitcode file] \; --tool-args -- [arguments to pass to lli] \; --args -- [program arguments]. Similarly, to debug the LLC, one would run:. .. code-block:: bash. bugpoint -run-llc -output=[correct output file] [bitcode file] \; --tool-args -- [arguments to pass to llc] \; --args -- [program arguments]. **Special note:** if you are debugging MultiSource or SPEC tests that; already exist in the ``llvm/test`` hierarchy, there is an easier way to; debug the JIT, LLC, and CBE, using the pre-written Makefile targets, which; will pass the program options specified in the Makefiles:. .. code-block:: bash. cd llvm/test/../../program; make bugpoint-jit. At the end of a successful ``bugpoint`` run, you will be presented; with two bitcode files: a *safe* file which can be compiled with the C; backend and the *test* file which either LLC or the JIT; mis-codegenerates, and thus causes the error. To reproduce the error that ``bugpoint`` found, it is sufficient to do; the following:. #. Regenerate the shared object from the safe bitcode file:. .. code-block:: bash. llc -march=c safe.bc -o safe.c; gcc -shared safe.c -o safe.so. #. If debugging LLC, compile test bitcode native and link with the shared; object:. .. code-block:: bash. llc test.bc -o test.s; gcc test.s safe.so -o test.llc; ./test.llc [program options]. #. If debugging the JIT, load the shared object and supply the test; bitcode:. .. code-block:: bash. lli -load=safe.so test.bc [program options]; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:11216,load,load,11216,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,2,['load'],['load']
Performance,"mit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0);",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:225615,load,load,225615,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"mm4. According to this report, the dot-product kernel has been executed 300 times,; for a total of 900 simulated instructions. The total number of simulated micro; opcodes (uOps) is also 900. The report is structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:16353,throughput,throughput,16353,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['throughput'],['throughput']
Performance,"mmed with the third i32 operand. The; i1 fourth operand is used to clamp the output.; When applicable (e.g. no clamping), this is lowered into; v_dot2c_i32_i16 for targets which support it. llvm.amdgcn.sdot4 Provides direct access to v_dot4_i32_i8 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot4c_i32_i8 for targets which support it.; RDNA3 does not offer v_dot4_i32_i8, and rather offers; v_dot4_i32_iu8 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sdot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot8c_i32_i4 for targets which support it.; RDNA3 does not offer v_dot8_i32_i4, and rather offers; v_dot4_i32_iu4 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:41083,perform,performs,41083,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performs']
Performance,mmediate substatement. - Fixed an issue that a benign assertion might hit when instantiating a pack expansion; inside a lambda. (`#61460 <https://github.com/llvm/llvm-project/issues/61460>`_); - Fix crash during instantiation of some class template specializations within class; templates. Fixes (`#70375 <https://github.com/llvm/llvm-project/issues/70375>`_); - Fix crash during code generation of C++ coroutine initial suspend when the return; type of await_resume is not trivially destructible.; Fixes (`#63803 <https://github.com/llvm/llvm-project/issues/63803>`_); - ``__is_trivially_relocatable`` no longer returns true for non-object types; such as references and functions.; Fixes (`#67498 <https://github.com/llvm/llvm-project/issues/67498>`_); - Fix crash when the object used as a ``static_assert`` message has ``size`` or ``data`` members; which are not member functions.; - Support UDLs in ``static_assert`` message.; - Fixed false positive error emitted by clang when performing qualified name; lookup and the current class instantiation has dependent bases.; Fixes (`#13826 <https://github.com/llvm/llvm-project/issues/13826>`_); - Fix a ``clang-17`` regression where a templated friend with constraints is not; properly applied when its parameters reference an enclosing non-template class.; Fixes (`#71595 <https://github.com/llvm/llvm-project/issues/71595>`_); - Fix the name of the ifunc symbol emitted for multiversion functions declared with the; ``target_clones`` attribute. This addresses a linker error that would otherwise occur; when these functions are referenced from other TUs.; - Fixes compile error that double colon operator cannot resolve macro with parentheses.; Fixes (`#64467 <https://github.com/llvm/llvm-project/issues/64467>`_); - Clang's ``-Wchar-subscripts`` no longer warns on chars whose values are known non-negative constants.; Fixes (`#18763 <https://github.com/llvm/llvm-project/issues/18763>`_); - Fix crash due to incorrectly allowing conversion functi,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:41312,perform,performing,41312,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['perform'],['performing']
Performance,"mmon standard C library functions `never access memory or only read; memory`_.; * Pointers that obviously point to constant globals ""``pointToConstantMemory``"".; * Function calls can not modify or references stack allocations if they never; escape from the function that allocates them (a common case for automatic; arrays). The ``-globalsmodref-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This pass implements a simple context-sensitive mod/ref and alias analysis for; internal global variables that don't ""have their address taken"". If a global; does not have its address taken, the pass knows that no pointers alias the; global. This pass also keeps track of functions that it knows never access; memory or never read memory. This allows certain optimizations (e.g. GVN) to; eliminate call instructions entirely. The real power of this pass is that it provides context-sensitive mod/ref; information for call instructions. This allows the optimizer to know that calls; to a function do not clobber or read the value of the global, allowing loads and; stores to be eliminated. .. note::. This pass is somewhat limited in its scope (only support non-address taken; globals), but is very quick analysis. The ``-steens-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^. The ``-steens-aa`` pass implements a variation on the well-known ""Steensgaard's; algorithm"" for interprocedural alias analysis. Steensgaard's algorithm is a; unification-based, flow-insensitive, context-insensitive, and field-insensitive; alias analysis that is also very scalable (effectively linear time). The LLVM ``-steens-aa`` pass implements a ""speculatively field-**sensitive**""; version of Steensgaard's algorithm using the Data Structure Analysis framework.; This gives it substantially more precision than the standard algorithm while; maintaining excellent analysis scalability. .. note::. ``-steens-aa`` is available in the optional ""poolalloc"" module. It is not part; of the LLVM core. The ``-ds-aa`` pass; ^^^^^^^^^^^^^^^^^^^. The ``-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:25116,optimiz,optimizer,25116,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,2,"['load', 'optimiz']","['loads', 'optimizer']"
Performance,"mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246600,load,load,246600,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"modified / constrained; (as an example, think that if ``x = MemoryDef(...)``; and ``MemoryUse(x)`` are in the same loop, the use can't; be hoisted outside alone). Another useful way of looking at it is in terms of memory versions.; In that view, operands of a given ``MemoryAccess`` are the version; of the entire memory before the operation, and if the access produces; a value (i.e. ``MemoryDef/MemoryPhi``),; the value is the new version of the memory after the operation. .. code-block:: llvm. define void @foo() {; entry:; %p1 = alloca i8; %p2 = alloca i8; %p3 = alloca i8; ; 1 = MemoryDef(liveOnEntry); store i8 0, ptr %p3; br label %while.cond. while.cond:; ; 6 = MemoryPhi({entry,1},{if.end,4}); br i1 undef, label %if.then, label %if.else. if.then:; ; 2 = MemoryDef(6); store i8 0, ptr %p1; br label %if.end. if.else:; ; 3 = MemoryDef(6); store i8 1, ptr %p2; br label %if.end. if.end:; ; 5 = MemoryPhi({if.then,2},{if.else,3}); ; MemoryUse(5); %1 = load i8, ptr %p1; ; 4 = MemoryDef(5); store i8 2, ptr %p2; ; MemoryUse(1); %2 = load i8, ptr %p3; br label %while.cond; }. The ``MemorySSA`` IR is shown in comments that precede the instructions they map; to (if such an instruction exists). For example, ``1 = MemoryDef(liveOnEntry)``; is a ``MemoryAccess`` (specifically, a ``MemoryDef``), and it describes the LLVM; instruction ``store i8 0, ptr %p3``. Other places in ``MemorySSA`` refer to this; particular ``MemoryDef`` as ``1`` (much like how one can refer to ``load i8, ptr; %p1`` in LLVM with ``%1``). Again, ``MemoryPhi``\ s don't correspond to any LLVM; Instruction, so the line directly below a ``MemoryPhi`` isn't special. Going from the top down:. - ``6 = MemoryPhi({entry,1},{if.end,4})`` notes that, when entering; ``while.cond``, the reaching definition for it is either ``1`` or ``4``. This; ``MemoryPhi`` is referred to in the textual IR by the number ``6``.; - ``2 = MemoryDef(6)`` notes that ``store i8 0, ptr %p1`` is a definition,; and its reaching definition before it ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:6088,load,load,6088,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,2,['load'],['load']
Performance,"modify-write instructions, the root node in the isel match is; the store, and isel has no way for the use of the EFLAGS result of the; arithmetic to be remapped to the new node. Add and subtract instructions set OF on signed overflow and CF on unsiged; overflow, while test instructions always clear OF and CF. In order to; replace a test with an add or subtract in a situation where OF or CF is; needed, codegen must be able to prove that the operation cannot see; signed or unsigned overflow, respectively. //===---------------------------------------------------------------------===//. memcpy/memmove do not lower to SSE copies when possible. A silly example is:; define <16 x float> @foo(<16 x float> %A) nounwind {; 	%tmp = alloca <16 x float>, align 16; 	%tmp2 = alloca <16 x float>, align 16; 	store <16 x float> %A, <16 x float>* %tmp; 	%s = bitcast <16 x float>* %tmp to i8*; 	%s2 = bitcast <16 x float>* %tmp2 to i8*; 	call void @llvm.memcpy.i64(i8* %s, i8* %s2, i64 64, i32 16); 	%R = load <16 x float>* %tmp2; 	ret <16 x float> %R; }. declare void @llvm.memcpy.i64(i8* nocapture, i8* nocapture, i64, i32) nounwind. which compiles to:. _foo:; 	subl	$140, %esp; 	movaps	%xmm3, 112(%esp); 	movaps	%xmm2, 96(%esp); 	movaps	%xmm1, 80(%esp); 	movaps	%xmm0, 64(%esp); 	movl	60(%esp), %eax; 	movl	%eax, 124(%esp); 	movl	56(%esp), %eax; 	movl	%eax, 120(%esp); 	movl	52(%esp), %eax; <many many more 32-bit copies>; 	movaps	(%esp), %xmm0; 	movaps	16(%esp), %xmm1; 	movaps	32(%esp), %xmm2; 	movaps	48(%esp), %xmm3; 	addl	$140, %esp; 	ret. On Nehalem, it may even be cheaper to just use movups when unaligned than to; fall back to lower-granularity chunks. //===---------------------------------------------------------------------===//. Implement processor-specific optimizations for parity with GCC on these; processors. GCC does two optimizations:. 1. ix86_pad_returns inserts a noop before ret instructions if immediately; preceded by a conditional branch or is the target of a jump.; 2. ix86_avo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:31992,load,load,31992,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['load'],['load']
Performance,"more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:7866,perform,performing,7866,roofit/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html,2,['perform'],['performing']
Performance,"more freedom to optimize. Here are some examples of; (potentially surprising) transformations that are valid (in pseudo IR):. .. code-block:: llvm. %A = add %X, undef; %B = sub %X, undef; %C = xor %X, undef; Safe:; %A = undef; %B = undef; %C = undef. This is safe because all of the output bits are affected by the undef; bits. Any output bit can have a zero or one depending on the input bits. .. code-block:: llvm. %A = or %X, undef; %B = and %X, undef; Safe:; %A = -1; %B = 0; Safe:; %A = %X ;; By choosing undef as 0; %B = %X ;; By choosing undef as -1; Unsafe:; %A = undef; %B = undef. These logical operations have bits that are not always affected by the; input. For example, if ``%X`` has a zero bit, then the output of the; '``and``' operation will always be a zero for that bit, no matter what; the corresponding bit from the '``undef``' is. As such, it is unsafe to; optimize or assume that the result of the '``and``' is '``undef``'.; However, it is safe to assume that all bits of the '``undef``' could be; 0, and optimize the '``and``' to 0. Likewise, it is safe to assume that; all the bits of the '``undef``' operand to the '``or``' could be set,; allowing the '``or``' to be folded to -1. .. code-block:: llvm. %A = select undef, %X, %Y; %B = select undef, 42, %Y; %C = select %X, %Y, undef; Safe:; %A = %X (or %Y); %B = 42 (or %Y); %C = %Y (if %Y is provably not poison; unsafe otherwise); Unsafe:; %A = undef; %B = undef; %C = undef. This set of examples shows that undefined '``select``' (and conditional; branch) conditions can go *either way*, but they have to come from one; of the two operands. In the ``%A`` example, if ``%X`` and ``%Y`` were; both known to have a clear low bit, then ``%A`` would have to have a; cleared low bit. However, in the ``%C`` example, the optimizer is; allowed to assume that the '``undef``' operand could be the same as; ``%Y`` if ``%Y`` is provably not '``poison``', allowing the whole '``select``'; to be eliminated. This is because '``poison``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:192487,optimiz,optimize,192487,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimize']
Performance,"more than one option starting with `-g` is; specified, the last one wins:. :option:`-g` Generate debug information. :option:`-gline-tables-only` Generate only line table debug information. This; allows for symbolicated backtraces with inlining information, but does not; include any information about variables, their locations or types. :option:`-gmodules` Generate debug information that contains external; references to types defined in Clang modules or precompiled headers instead; of emitting redundant debug type information into every object file. This; option transparently switches the Clang module format to object file; containers that hold the Clang module together with the debug information.; When compiling a program that uses Clang modules or precompiled headers,; this option produces complete debug information with faster compile; times and much smaller object files. This option should not be used when building static libraries for; distribution to other machines because the debug info will contain; references to the module cache on the machine the object files in the; library were built on. .. option:: -fstandalone-debug -fno-standalone-debug. Clang supports a number of optimizations to reduce the size of debug; information in the binary. They work based on the assumption that the; debug type information can be spread out over multiple compilation units.; For instance, Clang will not emit type definitions for types that are not; needed by a module and could be replaced with a forward declaration.; Further, Clang will only emit type info for a dynamic C++ class in the; module that contains the vtable for the class. The :option:`-fstandalone-debug` option turns off these optimizations.; This is useful when working with 3rd-party libraries that don't come with; debug information. This is the default on Darwin. Note that Clang will; never emit type information for types that are not referenced at all by the; program. .. option:: -feliminate-unused-debug-types. By",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:12734,cache,cache,12734,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['cache'],['cache']
Performance,"mory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:276110,load,loads,276110,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"move the specified section from the output. Can be specified multiple times; to remove multiple sections simultaneously. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --set-section-alignment <section>=<align>. Set the alignment of section ``<section>`` to ``<align>``. Can be specified; multiple times to update multiple sections. .. option:: --set-section-flags <section>=<flag>[,<flag>,...]. Set section properties in the output of section ``<section>`` based on the; specified ``<flag>`` values. Can be specified multiple times to update multiple; sections. Supported flag names are `alloc`, `load`, `noload`, `readonly`, `exclude`,; `debug`, `code`, `data`, `rom`, `share`, `contents`, `merge`, `strings`, and; `large`. Not all flags are meaningful for all object file formats or target; architectures. For ELF objects, the flags have the following effects:. - `alloc` = add the `SHF_ALLOC` flag.; - `load` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `readonly` = if this flag is not specified, add the `SHF_WRITE` flag.; - `exclude` = add the `SHF_EXCLUDE` flag.; - `code` = add the `SHF_EXECINSTR` flag.; - `merge` = add the `SHF_MERGE` flag.; - `strings` = add the `SHF_STRINGS` flag.; - `contents` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `large` = add the `SHF_X86_64_LARGE` on x86_64; rejected if the target; architecture is not x86_64. For COFF objects, the flags have the following effects:. - `alloc` = add the `IMAGE_SCN_CNT_UNINITIALIZED_DATA` and `IMAGE_SCN_MEM_READ`; flags, unless the `load` flag is specified.; - `noload` = add the `IMAGE_SCN_LNK_REMOVE` and `IMAGE_SCN_MEM_READ` flags.; - `readonly` = if this flag is not specified, add the `IMAGE_SCN_MEM_WRITE`; flag.; - `exclude` = add the `IMAGE_SCN_LNK_REMOVE` and `IMAGE_SCN_MEM_READ` flags.; - `debug` = add the `IMAGE_SCN_CNT_INITIALIZED_DATA`,; `IMAGE_SCN_MEM_DISCARDABLE` and `IMAGE_SCN_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:5181,load,load,5181,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,1,['load'],['load']
Performance,"movl	%esi, %edx; LBB0_4: ## %for.inc; 	addq	$16, %rdi; 	incq	%rsi; 	cmpq	%rsi, %rax; 	jne	LBB0_2. All things considered this isn't too bad, but we shouldn't need the movslq or; the shlq instruction, or the load folded into ucomisd every time through the; loop. On an x86-specific topic, if the loop can't be restructure, the movl should be a; cmov. //===---------------------------------------------------------------------===//. [STORE SINKING]. GCC PR37810 is an interesting case where we should sink load/store reload; into the if block and outside the loop, so we don't reload/store it on the; non-call path. for () {; *P += 1;; if (); call();; else; ...; ->; tmp = *P; for () {; tmp += 1;; if () {; *P = tmp;; call();; tmp = *P;; } else ...; }; *P = tmp;. We now hoist the reload after the call (Transforms/GVN/lpre-call-wrap.ll), but; we don't sink the store. We need partially dead store sinking. //===---------------------------------------------------------------------===//. [LOAD PRE CRIT EDGE SPLITTING]. GCC PR37166: Sinking of loads prevents SROA'ing the ""g"" struct on the stack; leading to excess stack traffic. This could be handled by GVN with some crazy; symbolic phi translation. The code we get looks like (g is on the stack):. bb2:		; preds = %bb1; ..; 	%9 = getelementptr %struct.f* %g, i32 0, i32 0		; 	store i32 %8, i32* %9, align bel %bb3. bb3:		; preds = %bb1, %bb2, %bb; 	%c_addr.0 = phi %struct.f* [ %g, %bb2 ], [ %c, %bb ], [ %c, %bb1 ]; 	%b_addr.0 = phi %struct.f* [ %b, %bb2 ], [ %g, %bb ], [ %b, %bb1 ]; 	%10 = getelementptr %struct.f* %c_addr.0, i32 0, i32 0; 	%11 = load i32* %10, align 4. %11 is partially redundant, an in BB2 it should have the value %8. GCC PR33344 and PR35287 are similar cases. //===---------------------------------------------------------------------===//. [LOAD PRE]. There are many load PRE testcases in testsuite/gcc.dg/tree-ssa/loadpre* in the; GCC testsuite, ones we don't get yet are (checked through loadpre25):. [CRIT EDGE BREAKING]; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:32575,LOAD,LOAD,32575,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['LOAD'],['LOAD']
Performance,"mpiler IR, as an on-disk bitcode representation; (suitable for fast loading by a Just-In-Time compiler), and as a human; readable assembly language representation. This allows LLVM to provide a; powerful intermediate representation for efficient compiler; transformations and analysis, while providing a natural means to debug; and visualize the transformations. The three different forms of LLVM are; all equivalent. This document describes the human readable; representation and notation. The LLVM representation aims to be light-weight and low-level while; being expressive, typed, and extensible at the same time. It aims to be; a ""universal IR"" of sorts, by being at a low enough level that; high-level ideas may be cleanly mapped to it (similar to how; microprocessors are ""universal IR's"", allowing many source languages to; be mapped to them). By providing type information, LLVM can be used as; the target of optimizations: for example, through pointer analysis, it; can be proven that a C automatic variable is never accessed outside of; the current function, allowing it to be promoted to a simple SSA value; instead of a memory location. .. _wellformed:. Well-Formedness; ---------------. It is important to note that this document describes 'well formed' LLVM; assembly language. There is a difference between what the parser accepts; and what is considered 'well formed'. For example, the following; instruction is syntactically okay, but not well formed:. .. code-block:: llvm. %x = add i32 1, %x. because the definition of ``%x`` does not dominate all of its uses. The; LLVM infrastructure provides a verification pass that may be used to; verify that an LLVM module is well formed. This pass is automatically; run by the parser after parsing input assembly and by the optimizer; before it outputs bitcode. The violations pointed out by the verifier; pass indicate bugs in transformation passes or input to the parser. .. _identifiers:. Identifiers; ===========. LLVM identifiers come",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:1560,optimiz,optimizations,1560,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"mpiler and required tools, then configures and builds the stage2 compiler; based on the settings in Apple-stage2.cmake. This pattern of using cache scripts to set complex settings, and specifically to; make later stage builds include cache scripts is common in our more advanced; build configurations. Multi-stage PGO; ===============. Profile-Guided Optimizations (PGO) is a really great way to optimize the code; clang generates. Our multi-stage PGO builds are a workflow for generating PGO; profiles that can be used to optimize clang. At a high level, the way PGO works is that you build an instrumented compiler,; then you run the instrumented compiler against sample source files. While the; instrumented compiler runs it will output a bunch of files containing; performance counters (.profraw files). After generating all the profraw files; you use llvm-profdata to merge the files into a single profdata file that you; can feed into the LLVM_PROFDATA_FILE option. Our PGO.cmake cache automates that whole process. You can use it for; configuration with CMake with the following command:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/PGO.cmake \; <path to source>/llvm. There are several additional options that the cache file also accepts to modify; the build, particularly the PGO_INSTRUMENT_LTO option. Setting this option to; Thin or Full will enable ThinLTO or full LTO respectively, further enhancing; the performance gains from a PGO build by enabling interprocedural; optimizations. For example, to run a CMake configuration for a PGO build; that also enables ThinTLO, use the following command:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/PGO.cmake \; -DPGO_INSTRUMENT_LTO=Thin \; <path to source>/llvm. By default, clang will generate profile data by compiling a simple; hello world program. You can also tell clang use an external; project for generating profile data that may be a better fit for your; use ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:5388,cache,cache,5388,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['cache'],['cache']
Performance,"mpiler transformations can break; conservative garbage collectors (though these seem rare in practice). Accurate garbage collectors do not suffer from any of these problems, but they; can suffer from degraded scalar optimization of the program. In particular,; because the runtime must be able to identify and update all pointers active in; the program, some optimizations are less effective. In practice, however, the; locality and performance benefits of using aggressive garbage collection; techniques dominates any low-level losses. This document describes the mechanisms and interfaces provided by LLVM to; support accurate garbage collection. Goals and non-goals; -------------------. LLVM's intermediate representation provides :ref:`garbage collection intrinsics; <gc_intrinsics>` that offer support for a broad class of collector models. For; instance, the intrinsics permit:. * semi-space collectors. * mark-sweep collectors. * generational collectors. * incremental collectors. * concurrent collectors. * cooperative collectors. * reference counting. We hope that the support built into the LLVM IR is sufficient to support a; broad class of garbage collected languages including Scheme, ML, Java, C#,; Perl, Python, Lua, Ruby, other scripting languages, and more. Note that LLVM **does not itself provide a garbage collector** --- this should; be part of your language's runtime library. LLVM provides a framework for; describing the garbage collectors requirements to the compiler. In particular,; LLVM provides support for generating stack maps at call sites, polling for a; safepoint, and emitting load and store barriers. You can also extend LLVM -; possibly through a loadable :ref:`code generation plugins <plugin>` - to; generate code and data structures which conforms to the *binary interface*; specified by the *runtime library*. This is similar to the relationship between; LLVM and DWARF debugging info, for example. The difference primarily lies in; the lack of an established",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:5334,concurren,concurrent,5334,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['concurren'],['concurrent']
Performance,"mple of Use**:. .. code-block:: c++. void init(float* data, size_t nbelems);; void process(float* data, size_t nbelems);; int foo(size_t n) {; auto mem = (float*)__builtin_alloca_with_align(; n * sizeof(float),; CHAR_BIT * alignof(float));; init(mem, n);; process(mem, n);; /* mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca_with_align`` is meant to be used to allocate a dynamic amount of memory; on the stack. It is similar to ``__builtin_alloca`` but accepts a second; argument whose value is the alignment constraint, as a power of 2 in *bits*. Query for this feature with ``__has_builtin(__builtin_alloca_with_align)``. .. _langext-__builtin_assume:. ``__builtin_assume``; --------------------. ``__builtin_assume`` is used to provide the optimizer with a boolean; invariant that is defined to be true. **Syntax**:. .. code-block:: c++. __builtin_assume(bool). **Example of Use**:. .. code-block:: c++. int foo(int x) {; __builtin_assume(x != 0);; // The optimizer may short-circuit this check using the invariant.; if (x == 0); return do_something();; return do_something_else();; }. **Description**:. The boolean argument to this function is defined to be true. The optimizer may; analyze the form of the expression provided as the argument and deduce from; that information used to optimize the program. If the condition is violated; during execution, the behavior is undefined. The argument itself is never; evaluated, so any side effects of the expression will be discarded. Query for this feature with ``__has_builtin(__builtin_assume)``. .. _langext-__builtin_assume_separate_storage:. ``__builtin_assume_separate_storage``; -------------------------------------. ``__builtin_assume_separate_storage`` is used to provide the optimizer with the; knowledge that its two arguments point to separately allocated objects. **Syntax**:. .. code-block:: c++. __builtin_assume_separate_storage(const volatile void *, const volatile void *). **Example of Use**:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:98929,optimiz,optimizer,98929,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizer']
Performance,"mplemented a helper tool [[7]]. The; tool detects (based on the include paths of the compiler) dependencies and; tries to generate the relevant vfs file. ## State of the union. Preloading all modules at start up time turn our motivating example into:. ```cpp; // ROOT prompt; root [] S *s; // #1: does not require a definition.; root [] foo::bar *baz1; // #2: does not require a definition.; root [] foo::bar baz2; // #3: requires a definition.; root [] TCanvas* c = new TCanvas(); // #4 requires a definition. ```. becomes equivalent to. ```cpp; // ROOT prompt; root [] import ROOT.*;; root [] import Foo.*;; root [] S *s; // #1: does not require a definition.; root [] foo::bar *baz1; // #2: does not require a definition.; root [] foo::bar baz2; // #3: requires a definition.; root [] TCanvas* c = new TCanvas(); // #4 requires a definition; ```. The implementation avoids recursive actions and relies on a well-defined (by; the C++ standard) behavior. Currently, this comes with a constant performance; overhead which we go in details bellow. ROOT uses the global module index (GMI) to avoid the performance overhead. ROOT; only preloads the set of C++ modules which are not present in the GMI. The; example becomes equivalent to:. ```cpp; // ROOT prompt; root [] import Foo.*; // Preload Foo if it is not in the GMI.; root [] S *s; // #1: does not require a definition.; root [] foo::bar *baz1; // #2: does not require a definition.; root [] foo::bar baz2; // #3: requires a definition.; root [] TCanvas* c = new TCanvas(); // #4 requires a definition; ```. Line #4 forces cling to send ROOT a callback that TCanvas in unknown but; the GMI resolves it to module Gpad, loads it and returns the control to cling. ### Performance; This section compares ROOT PCH technology with C++ Modules which is important but; unfair comparison. As we noted earlier, PCH is very efficient, it cannot be; extended to the experiments software stacks because of its design constraints.; On the contrary, the C++ Mo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:16570,perform,performance,16570,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['perform'],['performance']
Performance,"mplete types in templates; Templates with no valid instantiations; Default initialization of const; variable of a class type requires user-defined default; constructor; Parameter name lookup. C++11 compatibility. Deleted special member; functions. Objective-C++ compatibility. Implicit downcasts. Using class as a property name. C compatibility. C99 inline functions. By default, Clang builds C code in GNU C17 mode, so it uses standard C99; semantics for the inline keyword. These semantics are different; from those in GNU C89 mode, which is the default mode in versions of GCC; prior to 5.0. For example, consider the following code:. inline int add(int i, int j) { return i + j; }. int main() {; int i = add(4, 5);; return i;; }. In C99, inline means that a function's definition is; provided only for inlining, and that there is another definition; (without inline) somewhere else in the program. That; means that this program is incomplete, because if add; isn't inlined (for example, when compiling without optimization), then; main will have an unresolved reference to that other; definition. Therefore we'll get a (correct) link-time error like this:. Undefined symbols:; ""_add"", referenced from:; _main in cc-y1jXIr.o. By contrast, GNU C89 mode (used by default in older versions of GCC) is the; C89 standard plus a lot of extensions. C89 doesn't have an inline; keyword, but GCC recognizes it as an extension and just treats it as a hint to; the optimizer.; There are several ways to fix this problem:. Change add to a static inline; function. This is usually the right solution if only one; translation unit needs to use the function. static; inline functions are always resolved within the translation; unit, so you won't have to add a non-inline definition; of the function elsewhere in your program.; Remove the inline keyword from this definition of; add. The inline keyword is not required; for a function to be inlined, nor does it guarantee that it will be.; Some compilers ignore i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html:2041,optimiz,optimization,2041,interpreter/llvm-project/clang/www/compatibility.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html,2,['optimiz'],['optimization']
Performance,"mploy the retpoline mitigation, and on future x86 hardware (both Intel and; AMD) it is expected to become unnecessary due to hardware-based mitigation. When not using a retpoline, these edges will need independent protection from; variant #1 style attacks. The analogous approach to that used for conditional; control flow should work:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; switch (condition) {; case 0:; // Assuming ?: is implemented using branchless logic...; predicate_state = (condition != 0) ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; break;. case 1:; predicate_state = (condition != 1) ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; break;. // ...; }; }; ```. The core idea remains the same: validate the control flow using data-flow and; use that validation to check that loads cannot leak information along; misspeculated paths. Typically this involves passing the desired target of such; control flow across the edge and checking that it is correct afterwards. Note; that while it is tempting to think that this mitigates variant #2 attacks, it; does not. Those attacks go to arbitrary gadgets that don't include the checks. ### Variant #1.1 and #1.2 attacks: ""Bounds Check Bypass Store"". Beyond the core variant #1 attack, there are techniques to extend this attack.; The primary technique is known as ""Bounds Check Bypass Store"" and is discussed; in this research paper: https://people.csail.mit.edu/vlk/spectre11.pdf. We will analyze these two variants independently. First, variant #1.1 works by; speculatively storing over the return address after a bounds check bypass. This;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:10379,load,loaded,10379,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loaded']
Performance,"mposite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up Roo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3419,cache,cached,3419,roofit/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html,2,['cache'],['cached']
Performance,"mposition or inverse throughput of an instruction works similarly:. .. code-block:: bash. $ llvm-exegesis --mode=uops --opcode-name=ADD64rr; $ llvm-exegesis --mode=inverse_throughput --opcode-name=ADD64rr. The output is a YAML document (the default is to write to stdout, but you can; redirect the output to a file using `--benchmarks-file`):. .. code-block:: none. ---; key:; opcode_name: ADD64rr; mode: latency; config: ''; cpu_name: haswell; llvm_triple: x86_64-unknown-linux-gnu; num_repetitions: 10000; measurements:; - { key: latency, value: 1.0058, debug_string: '' }; error: ''; info: 'explicit self cycles, selecting one aliasing configuration.; Snippet:; ADD64rr R8, R8, R10; '; ... To measure the latency of all instructions for the host architecture, run:. .. code-block:: bash. $ llvm-exegesis --mode=latency --opcode-index=-1. EXAMPLE 2: benchmarking a custom code snippet; ---------------------------------------------. To measure the latency/uops of a custom piece of code, you can specify the; `snippets-file` option (`-` reads from standard input). .. code-block:: bash. $ echo ""vzeroupper"" | llvm-exegesis --mode=uops --snippets-file=-. Real-life code snippets typically depend on registers or memory.; :program:`llvm-exegesis` checks the liveliness of registers (i.e. any register; use has a corresponding def or is a ""live in""). If your code depends on the; value of some registers, you need to use snippet annotations to ensure setup; is performed properly. For example, the following code snippet depends on the values of XMM1 (which; will be set by the tool) and the memory buffer passed in RDI (live in). .. code-block:: none. # LLVM-EXEGESIS-LIVEIN RDI; # LLVM-EXEGESIS-DEFREG XMM1 42; vmulps	(%rdi), %xmm1, %xmm2; vhaddps	%xmm2, %xmm2, %xmm3; addq $0x10, %rdi. Example 3: benchmarking with memory annotations; -----------------------------------------------. Some snippets require memory setup in specific places to execute without; crashing. Setting up memory can be accom",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:5929,latency,latency,5929,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['latency'],['latency']
Performance,"mproved buffer checking for ``std::initializer_list``; * Add convenience functions ``argc()`` and ``argv()`` to ``cppyy.ll``; * Added ``nullptr`` comparisons for for typed ``nullptr``; * Support for ``using`` pointer types as template arguments; * Walk the full inheritance tree to find the overloads; * Allow ``__destruct__`` override in Python derived class; * Allow ``NULL`` function pointers to be returned as ``std::function`` objects; * Add Python traceback to C++ exception ``what()``. 2022-10-03: 2.4.1; -----------------. * Drop Numba extension entry point. 2022-06-29: 2.4.0; -----------------. * Support for free (templated) functions in Numba; * Basic support for unboxing C++ public data members in Numba; * Basic support for calling methods of C++ structs in Numba; * Added conventional `__cpp_reflex__` method for inspection in Numba; * Support for globally overloaded ordering operators; * Special cases for `__repr__`/`__str__` returning C++ stringy types; * Fix lookup of templates of function with template args; * Correct typing of int8_t/uint8_t enums; * Basic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu for avx; * Workaround for handling exceptions from JITed code on ARM; * Drop ``from cppyy.interactive import *`` from CPython 3.11; * Fix regression in converting `std::vector<T*` to `list`; * Update to the latest patch version of Cling (from 6.26.04). 2022-04-03: 2.3.1; -----------------; * Use portable type Py_ssize_t instead of ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:3854,optimiz,optimize,3854,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['optimiz'],['optimize']
Performance,"mproving performance especially for TTree::Map() by about 35%. This has been achieved with a better caching strategy for request strings(especially avoiding to recalculatethe auth base64 encoding), and with adrastic optimization inreadingthe response headers.; Fixes in the counting of the bytes read. TWebSystem. New implementation of TSystem allowing to use TSystem::AccessPathName() and GetPathInfo() to check if a web file exists and to get its size. Directory browsing is not available yet. NETX; ; TXNetFile. Several fixes and optimisations, mainly in the use of the cache; Fix an offset issue affecting the use of the cache with files in archives. TXNetSystem. A few optimizations in the use of retry mechanism, path locality checks, file online checks. XROOTD. Import a new version of XROOTD (20091202-0509); ; Fixes in bulk prepare and sync readv operations; Add support for 'make install' / 'make uninstall' and; other improvements in configure.classic; Several improvements / fixes:; ; reduced memory and CPU consumption;; extreme cp optimizations;; windows porting; new cache policies on the client side; new listingfeatures implemented recently in the 'cns' module.; optimizations in cmsd and cnsd (performance improvements); support for openssl 1.0.0 (required by Fedora 12). Support for if/else if/else/fi constructs; Several portability fixes; ; Support 32-bit builds with icc on 64-bit platforms; Improved detection of libreadline and lib(n)curses. Increase the flexibility for configuring with an external xrootd; ; Add standard switches to disentangle lib and inc dirs;    --with-xrootd-incdir=<path_to dir_containing_XrdVersion.hh>;    --with-xrootd-libdir=<path_to_dir_containing_xrootd_plugins_and_libs>; ; When; passing a global xrootd dir with --with-xrootd, check both; src/XrdVersion.hh and include/xrootd/XrdVersion.hh so that both build; and install distributions are supported. Fix a problem with the xrootd build when running make via 'sudo' (issue #47644). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v526/index.html:1118,optimiz,optimizations,1118,net/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v526/index.html,8,"['cache', 'optimiz', 'perform']","['cache', 'optimizations', 'performance']"
Performance,"ms in *list*. The; variable *acc* acts as the accumulator and is initialized to *init*.; The variable *var* is bound to each element in the *list*. The; expression is evaluated for each element and presumably uses *acc* and; *var* to calculate the accumulated value, which ``!foldl`` stores back in; *acc*. The type of *acc* is the same as *init*; the type of *var* is the; same as the elements of *list*; *expr* must have the same type as *init*. The following example computes the total of the ``Number`` field in the; list of records in ``RecList``::. int x = !foldl(0, RecList, total, rec, !add(total, rec.Number));. If your goal is to filter the list and produce a new list that includes only; some of the elements, see ``!filter``. ``!foreach(``\ *var*\ ``,`` *sequence*\ ``,`` *expr*\ ``)``; This operator creates a new ``list``/``dag`` in which each element is a; function of the corresponding element in the *sequence* ``list``/``dag``.; To perform the function, TableGen binds the variable *var* to an element; and then evaluates the expression. The expression presumably refers; to the variable *var* and calculates the result value. If you simply want to create a list of a certain length containing; the same value repeated multiple times, see ``!listsplat``. ``!ge(``\ *a*\ `,` *b*\ ``)``; This operator produces 1 if *a* is greater than or equal to *b*; 0 otherwise.; The arguments must be ``bit``, ``bits``, ``int``, or ``string`` values. ``!getdagarg<``\ *type*\ ``>(``\ *dag*\ ``,``\ *key*\ ``)``; This operator retrieves the argument from the given *dag* node by the; specified *key*, which is either an integer index or a string name. If that; argument is not convertible to the specified *type*, ``?`` is returned. ``!getdagname(``\ *dag*\ ``,``\ *index*\ ``)``; This operator retrieves the argument name from the given *dag* node by the; specified *index*. If that argument has no name associated, ``?`` is; returned. ``!getdagop(``\ *dag*\ ``)`` --or-- ``!getdagop<``\ *type*\ ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:64917,perform,perform,64917,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['perform']
Performance,"ms. Display symbols (variables, functions, etc) for each compiland. .. option:: -sym-types=<types>. Type of symbols to dump when -globals, -externals, or -module-syms is; specified. (default all). .. code-block:: text. =thunks - Display thunk symbols; =data - Display data symbols; =funcs - Display function symbols; =all - Display all symbols (default). .. option:: -symbol-order=<order>. For symbols dumped via the -module-syms, -globals, or -externals options, sort; the results in specified order. .. code-block:: text. =none - Undefined / no particular sort order; =name - Sort symbols by name; =size - Sort symbols by size. .. option:: -typedefs. Display typedef types. .. option:: -types. Display all types (implies -classes, -enums, -typedefs). Other Options; +++++++++++++. .. option:: -color-output. Force color output on or off. By default, color if used if outputting to a; terminal. .. option:: -load-address=<uint>. When displaying relative virtual addresses, assume the process is loaded at the; given address and display what would be the absolute address. .. _dump_subcommand:. dump; ~~~~. USAGE: :program:`llvm-pdbutil` dump [*options*] <input PDB file>. .. program:: llvm-pdbutil dump. Summary; ^^^^^^^^^^^. The **dump** subcommand displays low level information about the structure of a; PDB file. It is used heavily by LLVM's testing infrastructure, but can also be; used for PDB forensics. It serves a role similar to that of Microsoft's; `cvdump` tool. .. note::; The **dump** subcommand exposes internal details of the file format. As; such, the reader should be familiar with :doc:`/PDB/index` before using this; command. Options; ^^^^^^^. MSF Container Options; +++++++++++++++++++++. .. option:: -streams. dump a summary of all of the streams in the PDB file. .. option:: -stream-blocks. In conjunction with :option:`-streams`, add information to the output about; what blocks the specified stream occupies. .. option:: -summary. Dump MSF and PDB header information. Module ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:6897,load,loaded,6897,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,1,['load'],['loaded']
Performance,"mt_misc/register; % chmod u+x hello.bc (if needed); % ./hello.bc. This allows you to execute LLVM bitcode files directly. On Debian, you can also; use this command instead of the 'echo' command above:. .. code-block:: console. % sudo update-binfmts --install llvm /path/to/lli --magic 'BC'. .. _Program Layout:; .. _general layout:. Directory Layout; ================. One useful source of information about the LLVM source base is the LLVM `doxygen; <http://www.doxygen.org/>`_ documentation available at; `<https://llvm.org/doxygen/>`_. The following is a brief introduction to code; layout:. ``llvm/cmake``; --------------; Generates system build files. ``llvm/cmake/modules``; Build configuration for llvm user defined options. Checks compiler version and; linker flags. ``llvm/cmake/platforms``; Toolchain configuration for Android NDK, iOS systems and non-Windows hosts to; target MSVC. ``llvm/examples``; -----------------. - Some simple examples showing how to use LLVM as a compiler for a custom; language - including lowering, optimization, and code generation. - Kaleidoscope Tutorial: Kaleidoscope language tutorial run through the; implementation of a nice little compiler for a non-trivial language; including a hand-written lexer, parser, AST, as well as code generation; support using LLVM- both static (ahead of time) and various approaches to; Just In Time (JIT) compilation.; `Kaleidoscope Tutorial for complete beginner; <https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/index.html>`_. - BuildingAJIT: Examples of the `BuildingAJIT tutorial; <https://llvm.org/docs/tutorial/BuildingAJIT1.html>`_ that shows how LLVMs; ORC JIT APIs interact with other parts of LLVM. It also, teaches how to; recombine them to build a custom JIT that is suited to your use-case. ``llvm/include``; ----------------. Public header files exported from the LLVM library. The three main subdirectories:. ``llvm/include/llvm``. All LLVM-specific header files, and subdirectories for different porti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:34560,optimiz,optimization,34560,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['optimiz'],['optimization']
Performance,"much faster than the usual; shape-to-shape comparison. For a 100% reliability, one can perform the; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion A) is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap B) is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a **`TBrowser`**) held; by the manager class will be filled with **`TGeoOverlap`** objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing both candidate node names and a letter; (x-extrusion, o-overlap) representing the type. Double-clicking an; overlap item in a **`TBrowser`** produces a picture of the overlap; containing only the two overlapping nodes (one in blue and one in green); and having the critical vertices represented by red points. The picture; can be rotated/zoomed or drawn in X3d as any other v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:134176,perform,performed,134176,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance,"much more; > about the first one. 3. By focusing on a more low level virtual machine, we have much more room; for value add. The nice safe ""sandbox"" VM can be provided as a layer; on top of it. It also lets us focus on the more interesting compilers; related projects. > 2. Design issues to consider (an initial list that we should continue; > to modify). Note that I'm not trying to suggest actual solutions here,; > but just various directions we can pursue:. Understood. :). > a. A single-assignment VM, which we've both already been thinking; > about. Yup, I think that this makes a lot of sense. I am still intrigued,; however, by the prospect of a minimally allocated VM representation... I; think that it could have definite advantages for certain applications; (think very small machines, like PDAs). I don't, however, think that our; initial implementations should focus on this. :). Here are some other auxiliary goals that I think we should consider:. 1. Primary goal: Support a high performance dynamic compilation; system. This means that we have an ""ideal"" division of labor between; the runtime and static compilers. Of course, the other goals of the; system somewhat reduce the importance of this point (f.e. portability; reduces performance, but hopefully not much); 2. Portability to different processors. Since we are most familiar with; x86 and solaris, I think that these two are excellent candidates when; we get that far...; 3. Support for all languages & styles of programming (general purpose; VM). This is the point that disallows java style bytecodes, where all; array refs are checked for bounds, etc...; 4. Support linking between different language families. For example, call; C functions directly from Java without using the nasty/slow/gross JNI; layer. This involves several subpoints:; A. Support for languages that require garbage collectors and integration; with languages that don't. As a base point, we could insist on; always using a conservative GC, but implem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:3221,perform,performance,3221,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['perform'],['performance']
Performance,"mum set by; ``setMaxAtomicSizeInBitsSupported`` (which defaults to 0). On x86, all atomic loads generate a ``MOV``. SequentiallyConsistent stores; generate an ``XCHG``, other stores generate a ``MOV``. SequentiallyConsistent; fences generate an ``MFENCE``, other fences do not cause any code to be; generated. ``cmpxchg`` uses the ``LOCK CMPXCHG`` instruction. ``atomicrmw xchg``; uses ``XCHG``, ``atomicrmw add`` and ``atomicrmw sub`` use ``XADD``, and all; other ``atomicrmw`` operations generate a loop with ``LOCK CMPXCHG``. Depending; on the users of the result, some ``atomicrmw`` operations can be translated into; operations like ``LOCK AND``, but that does not work in general. On ARM (before v8), MIPS, and many other RISC architectures, Acquire, Release,; and SequentiallyConsistent semantics require barrier instructions for every such; operation. Loads and stores generate normal instructions. ``cmpxchg`` and; ``atomicrmw`` can be represented using a loop with LL/SC-style instructions; which take some sort of exclusive lock on a cache line (``LDREX`` and ``STREX``; on ARM, etc.). It is often easiest for backends to use AtomicExpandPass to lower some of the; atomic constructs. Here are some lowerings it can do:. * cmpxchg -> loop with load-linked/store-conditional; by overriding ``shouldExpandAtomicCmpXchgInIR()``, ``emitLoadLinked()``,; ``emitStoreConditional()``; * large loads/stores -> ll-sc/cmpxchg; by overriding ``shouldExpandAtomicStoreInIR()``/``shouldExpandAtomicLoadInIR()``; * strong atomic accesses -> monotonic accesses + fences by overriding; ``shouldInsertFencesForAtomic()``, ``emitLeadingFence()``, and; ``emitTrailingFence()``; * atomic rmw -> loop with cmpxchg or load-linked/store-conditional; by overriding ``expandAtomicRMWInIR()``; * expansion to __atomic_* libcalls for unsupported sizes.; * part-word atomicrmw/cmpxchg -> target-specific intrinsic by overriding; ``shouldExpandAtomicRMWInIR``, ``emitMaskedAtomicRMWIntrinsic``,; ``shouldExpandAtomicCmpX",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:20698,cache,cache,20698,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['cache'],['cache']
Performance,"must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.; movl (%rsi,%rcx), %edi; ```. This will result in a negative address near zero or in `offset` wrapping the; address space back to a small positive address. Small, negative addresses will; fault in user-mode for most operating systems, but targets which need the high; address space to be user accessible may need to adjust the exact sequence used; above. Additionally, the low addresses will need to be marked unrea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:29233,load,loads,29233,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance,"must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 3. buffer/global/flat_atomic sc1=1; atomicrmw release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; sc0=1 sc1=1; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:312430,load,load,312430,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:257386,load,load,257386,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"mutation of the string. Like SmallVector's, the big downside to SmallString is their sizeof. While they; are optimized for small strings, they themselves are not particularly small.; This means that they work great for temporary scratch buffers on the stack, but; should not generally be put into the heap: it is very rare to see a SmallString; as the member of a frequently-allocated heap data structure or returned; by-value. .. _dss_stdstring:. std::string; ^^^^^^^^^^^. The standard C++ std::string class is a very general class that (like; SmallString) owns its underlying data. sizeof(std::string) is very reasonable; so it can be embedded into heap data structures and returned by-value. On the; other hand, std::string is highly inefficient for inline editing (e.g.; concatenating a bunch of stuff together) and because it is provided by the; standard library, its performance characteristics depend a lot of the host; standard library (e.g. libc++ and MSVC provide a highly optimized string class,; GCC contains a really slow implementation). The major disadvantage of std::string is that almost every operation that makes; them larger can allocate memory, which is slow. As such, it is better to use; SmallVector or Twine as a scratch buffer, but then use std::string to persist; the result. .. _ds_set:. Set-Like Containers (std::set, SmallSet, SetVector, etc); --------------------------------------------------------. Set-like containers are useful when you need to canonicalize multiple values; into a single representation. There are several different choices for how to do; this, providing various trade-offs. .. _dss_sortedvectorset:. A sorted 'vector'; ^^^^^^^^^^^^^^^^^. If you intend to insert a lot of elements, then do a lot of queries, a great; approach is to use an std::vector (or other sequential container) with; std::sort+std::unique to remove duplicates. This approach works really well if; your usage pattern has these two distinct phases (insert then query), and can be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:76379,optimiz,optimized,76379,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['optimiz'],['optimized']
Performance,"mw that is; being released. 3. flat_atomic; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. flat_atomic sc1=1; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:324010,load,load,324010,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"myShapes->Draw(""ogl"");; ```. Valid option strings are:. - ""`ogl`"" : external GL viewer. - ""`x3d`"": external X3D viewer. - ""`pad`"": pad viewer. If no option is passed to `Draw()` then the ""`pad`"" is used by default.; If you already have content in a pad, which you would like to display in; one of the external viewers you can select from the canvas View menu /; View With, and pick the viewer type. ![Invoking external 3D viewers from canvas menus](pictures/030000D9.png). Note: A current limitation means that when an external viewer is created; the pad is no longer redrawn. When the external viewer is closed,; clicking in the pad will refresh. ### The GL Viewer. The GL Viewer uses <OpenGL> (or compliant libraries such as <Mesa3D>); to generate high quality, high-performance 3D renderings, with; sophisticated lighting, materials and rendering styles for 3D scenes.; Many users will be able to take advantage of hardware acceleration of; the underlying OpenGL commands by their computer's video card, resulting; is considerable performance gains - up to interactive manipulation of; 1000's of complex shapes in real-time. The GL Viewer is supported on all official ROOT platforms (assuming you; have suitable <OpenGL> libraries), and is the main 3D viewer, which; development effort is concentrated upon. As OpenGL is a trademark we; refer to our viewer built on this technology as the GL Viewer'. The; code for it can be found under `$ROOTSYS/gl`. ![The GL 3D Viewer](pictures/020000DA.jpg). You can manipulate the viewer via the GUI or via the base; **`TGLViewer`** object behind the interface. These are detailed below -; see also `$ROOTSYS/tutorials/gl/glViewerExercise.C`. #### Projections Modes (Cameras). The GL Viewer supports two basic types of camera, which affect how the; 3D world is projected onto the 2D render area:. - Perspective: Objects are drawn with characteristic foreshortening'; effect, where distant objects appear smaller than near ones. This is; useful for obtain",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:107530,perform,performance,107530,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['perform'],['performance']
Performance,"n %id, ptr %alloc); br label %loop; loop:; %n.val = phi i32 [ %n, %entry ], [ %inc, %loop ]; %inc = add nsw i32 %n.val, 1; call void @print(i32 %n.val); %0 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %0, label %suspend [i8 0, label %loop; i8 1, label %cleanup]; cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); call void @free(ptr %mem); br label %suspend; suspend:; %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none); ret ptr %hdl; }. The `entry` block establishes the coroutine frame. The `coro.size`_ intrinsic is; lowered to a constant representing the size required for the coroutine frame.; The `coro.begin`_ intrinsic initializes the coroutine frame and returns the; coroutine handle. The second parameter of `coro.begin` is given a block of memory; to be used if the coroutine frame needs to be allocated dynamically.; The `coro.id`_ intrinsic serves as coroutine identity useful in cases when the; `coro.begin`_ intrinsic get duplicated by optimization passes such as; jump-threading. The `cleanup` block destroys the coroutine frame. The `coro.free`_ intrinsic,; given the coroutine handle, returns a pointer of the memory block to be freed or; `null` if the coroutine frame was not allocated dynamically. The `cleanup`; block is entered when coroutine runs to completion by itself or destroyed via; call to the `coro.destroy`_ intrinsic. The `suspend` block contains code to be executed when coroutine runs to; completion or suspended. The `coro.end`_ intrinsic marks the point where; a coroutine needs to return control back to the caller if it is not an initial; invocation of the coroutine. The `loop` blocks represents the body of the coroutine. The `coro.suspend`_; intrinsic in combination with the following switch indicates what happens to; control flow when a coroutine is suspended (default case), resumed (case 0) or; destroyed (case 1). Coroutine Transformation; ------------------------. One of the steps of coroutine lowering is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:12812,optimiz,optimization,12812,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['optimiz'],['optimization']
Performance,"n 26000; lines of code. ```cpp; // Main.cpp; #include ""A.h""; int main() {; do();; return 0;; }. ```; Main.cpp, reuses code from libA by including libA's descriptor and links against; libA. The full descriptor can contain thousands of files expanding to millions; of lines of code -- a common case for framework libraries, for instance. ROOT goes further and enhances C++ by allowing the following code to work without; explicitly requiring to `#include <A.h>`. Currently, ROOT's lack of support of; line `#5` is a long-standing, known limitation that is lifted with modules. ```cpp; // ROOT prompt; root [] AStruct<float> S0; // #1: implicit loading of libA. Full descriptor required.; root [] AStruct<float>* S1; // #2: implicit loading of libA. No full descriptor required.; root [] if (gFile) S1->doIt(); // #3: implicit loading of libA. Full descriptor required.; root [] gSystem->Load(""libA""); // #4: explicit loading of libA. No full descriptor required.; root [] do(); // #5: error: implicit loading of libA is currently unsupported. ```. This pattern is not only used in the ROOT prompt but in I/O hotspots such as; `ShowMembers` and `TClass::IsA`. A naive implementation of this feature would require inclusion of all reachable; library descriptors (aka header files) at ROOT startup time. Of course this is; not feasible and ROOT inserts a set of optimizations to fence itself from the; costly full header inclusion. Unfortunately, several of them are home-grown and; in a few cases inaccurate (eg line #5) causing a noticeable technical debt. Here we will briefly describe the three common layers of optimizations: ROOT PCH,; ROOTMAP and RDICT. The ROOT precompiled header (PCH) reduces the CPU and memory cost for ROOT's; most used libraries. The precompiled header technology is well-understood since; decades [[4]]. It is an efficient on-disk representation of the state of the; compiler after parsing a set of headers. It can be loaded before starting the; next instance to avoid doing",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:5211,load,loading,5211,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['load'],['loading']
Performance,"n = load i32, ptr %n.addr, align 4. br i1 %switch, label %loop.resume, label %loop. loop.resume:; %sub = sub nsw i32 0, %n; call void @print(i32 %sub); br label %suspend; loop:; %inc = add nsw i32 %n, 1; store i32 %inc, ptr %n.addr, align 4; tail call void @print(i32 %inc); br label %suspend. suspend:; %storemerge = phi i8 [ 0, %loop ], [ 1, %loop.resume ]; store i8 %storemerge, ptr %index.addr, align 1; ret void; }. If different cleanup code needs to get executed for different suspend points,; a similar switch will be in the `f.destroy` function. .. note ::. Using suspend index in a coroutine state and having a switch in `f.resume` and; `f.destroy` is one of the possible implementation strategies. We explored; another option where a distinct `f.resume1`, `f.resume2`, etc. are created for; every suspend point, and instead of storing an index, the resume and destroy; function pointers are updated at every suspend. Early testing showed that the; current approach is easier on the optimizer than the latter so it is a; lowering strategy implemented at the moment. Distinct Save and Suspend; -------------------------. In the previous example, setting a resume index (or some other state change that; needs to happen to prepare a coroutine for resumption) happens at the same time as; a suspension of a coroutine. However, in certain cases, it is necessary to control; when coroutine is prepared for resumption and when it is suspended. In the following example, a coroutine represents some activity that is driven; by completions of asynchronous operations `async_op1` and `async_op2` which get; a coroutine handle as a parameter and resume the coroutine once async; operation is finished. .. code-block:: text. void g() {; for (;;); if (cond()) {; async_op1(<coroutine-handle>); // will resume once async_op1 completes; <suspend>; do_one();; }; else {; async_op2(<coroutine-handle>); // will resume once async_op2 completes; <suspend>; do_two();; }; }; }. In this case, coroutine should b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:20406,optimiz,optimizer,20406,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['optimiz'],['optimizer']
Performance,"n arbitrary value,; we are allowed to assume that it could be zero. Since a divide by zero; has *undefined behavior*, we are allowed to assume that the operation; does not execute at all. This allows us to delete the divide and all; code after it. Because the undefined operation ""can't happen"", the; optimizer can assume that it occurs in dead code. .. code-block:: text. a: store undef -> %X; b: store %X -> undef; Safe:; a: <deleted> (if the stored value in %X is provably not poison); b: unreachable. A store *of* an undefined value can be assumed to not have any effect;; we can assume that the value is overwritten with bits that happen to; match what was already there. This argument is only valid if the stored value; is provably not ``poison``. However, a store *to* an undefined; location could clobber arbitrary memory, therefore, it has undefined; behavior. Branching on an undefined value is undefined behavior.; This explains optimizations that depend on branch conditions to construct; predicates, such as Correlated Value Propagation and Global Value Numbering.; In case of switch instruction, the branch condition should be frozen, otherwise; it is undefined behavior. .. code-block:: llvm. Unsafe:; br undef, BB1, BB2 ; UB. %X = and i32 undef, 255; switch %X, label %ret [ .. ] ; UB. store undef, ptr %ptr; %X = load ptr %ptr ; %X is undef; switch i8 %X, label %ret [ .. ] ; UB. Safe:; %X = or i8 undef, 255 ; always 255; switch i8 %X, label %ret [ .. ] ; Well-defined. %X = freeze i1 undef; br %X, BB1, BB2 ; Well-defined (non-deterministic jump). .. _poisonvalues:. Poison Values; -------------. A poison value is a result of an erroneous operation.; In order to facilitate speculative execution, many instructions do not; invoke immediate undefined behavior when provided with illegal operands,; and return a poison value instead.; The string '``poison``' can be used anywhere a constant is expected, and; operations such as :ref:`add <i_add>` with the ``nsw`` flag can produce; a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:196062,optimiz,optimizations,196062,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"n before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1 dlc=1; - system; - If GFX11, omit dlc=1. 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_gl*_invl.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. 3. buffer_gl0_inv. - If OpenCL omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkmcnt(0) &; vm/vscnt(0). - If CU wavefront execution; mode, omit vm/vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_gl0_inv. - If CU wavefront ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:349053,load,load,349053,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"n before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:258588,perform,performing,258588,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"n bitcasting a pointer value to an arbitrary; pointer type. The types in a GEP serve only to define the parameters for the; underlying integer computation. They need not correspond with the actual type of; the underlying object. Furthermore, loads and stores don't have to use the same types as the type of; the underlying object. Types in this context serve only to specify memory size; and alignment. Beyond that there are merely a hint to the optimizer indicating; how the value will likely be used. Can I cast an object's address to integer and add it to null?; -------------------------------------------------------------. You can compute an address that way, but if you use GEP to do the add, you can't; use that pointer to actually access the object, unless the object is managed; outside of LLVM. The underlying integer computation is sufficiently defined; null has a defined; value --- zero --- and you can add whatever value you want to it. However, it's invalid to access (load from or store to) an LLVM-aware object; with such a pointer. This includes ``GlobalVariables``, ``Allocas``, and objects; pointed to by noalias pointers. If you really need this functionality, you can do the arithmetic with explicit; integer instructions, and use inttoptr to convert the result to an address. Most; of GEP's special aliasing rules do not apply to pointers computed from ptrtoint,; arithmetic, and inttoptr sequences. Can I compute the distance between two objects, and add that value to one address to compute the other address?; ---------------------------------------------------------------------------------------------------------------. As with arithmetic on null, you can use GEP to compute an address that way, but; you can't use that pointer to actually access the object if you do, unless the; object is managed outside of LLVM. Also as above, ptrtoint and inttoptr provide an alternative way to do this which; do not have this restriction. Can I do type-based alias analysis on LLVM ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:15848,load,load,15848,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['load'],['load']
Performance,"n definition:; define double @test(double %x) {; entry:; %addtmp = fadd double 3.000000e+00, %x; %addtmp1 = fadd double %x, 3.000000e+00; %multmp = fmul double %addtmp, %addtmp1; ret double %multmp; }. In this case, the LHS and RHS of the multiplication are the same value.; We'd really like to see this generate ""``tmp = x+3; result = tmp*tmp;``""; instead of computing ""``x+3``"" twice. Unfortunately, no amount of local analysis will be able to detect and; correct this. This requires two transformations: reassociation of; expressions (to make the add's lexically identical) and Common; Subexpression Elimination (CSE) to delete the redundant add instruction.; Fortunately, LLVM provides a broad range of optimizations that you can; use, in the form of ""passes"". LLVM Optimization Passes; ========================. LLVM provides many optimization passes, which do many different sorts of; things and have different tradeoffs. Unlike other systems, LLVM doesn't; hold to the mistaken notion that one set of optimizations is right for; all languages and for all situations. LLVM allows a compiler implementor; to make complete decisions about what optimizations to use, in which; order, and in what situation. As a concrete example, LLVM supports both ""whole module"" passes, which; look across as large of body of code as they can (often a whole file,; but if run at link time, this can be a substantial portion of the whole; program). It also supports and includes ""per-function"" passes which just; operate on a single function at a time, without looking at other; functions. For more information on passes and how they are run, see the; `How to Write a Pass <../../WritingAnLLVMPass.html>`_ document and the; `List of LLVM Passes <../../Passes.html>`_. For Kaleidoscope, we are currently generating functions on the fly, one; at a time, as the user types them in. We aren't shooting for the; ultimate optimization experience in this setting, but we also want to; catch the easy and quick stuff wher",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:3527,optimiz,optimizations,3527,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimizations']
Performance,"n failure may be listed (this behavior; might change in the future). Consider the following loop:. .. code-block:: c++. #pragma clang loop vectorize(enable); for (int i = 0; i < Length; i++) {; switch(A[i]) {; case 0: A[i] = i*2; break;; case 1: A[i] = i; break;; default: A[i] = 0;; }; }. The command line ``-Rpass-missed=loop-vectorize`` prints the remark:. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: vectorization is explicitly enabled [-Rpass-missed=loop-vectorize]. And the command line ``-Rpass-analysis=loop-vectorize`` indicates that the; switch statement cannot be vectorized. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: loop contains a switch statement [-Rpass-analysis=loop-vectorize]; switch(A[i]) {; ^. To ensure line and column numbers are produced include the command line options; ``-gline-tables-only`` and ``-gcolumn-info``. See the Clang `user manual; <https://clang.llvm.org/docs/UsersManual.html#options-to-emit-optimization-reports>`_; for details. Features; --------. The LLVM Loop Vectorizer has a number of features that allow it to vectorize; complex loops. Loops with unknown trip count; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer supports loops with an unknown trip count.; In the loop below, the iteration ``start`` and ``finish`` points are unknown,; and the Loop Vectorizer has a mechanism to vectorize loops that do not start; at zero. In this example, 'n' may not be a multiple of the vector width, and; the vectorizer has to execute the last few iterations as scalar code. Keeping; a scalar copy of the loop increases the code size. .. code-block:: c++. void bar(float *A, float* B, float K, int start, int end) {; for (int i = start; i < end; ++i); A[i] *= B[i] + K;; }. Runtime Checks of Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^. In the example below, if the pointers A and B point to consecutive addresses,; then it is illegal to vectorize the code because some elements of A will be; written before ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:4232,optimiz,optimization-reports,4232,interpreter/llvm-project/llvm/docs/Vectorizers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst,1,['optimiz'],['optimization-reports']
Performance,"n for JS code; 12. One can specify in JSROOT.AssertPrerequisites functionality which is required.; One could specify '2d', 'io' (default) or '3d'.; 13. Use new AssertPrerequisites functionality to load only required functionality.; 14. When displaying single element, one could specify draw options and monitor property like:; <http://localhost:8080/Files/job1.root/hpxpy/draw.htm?opt=col&monitor=2000>; Such link is best possibility to integrate display into different HTML pages,; using `<iframe/>` tag like:; `<iframe src=""http://localhost:8080/Files/job1.root/hpx/draw.htm""`; `style=""width: 800px; height:600px""></iframe>`; 15. Remove 'JSROOTIO.' prefix from _typename. Now real class name is used.; 16. Use in all scripts JSROOT as central 'namespace'; 17. Introduce context menu in 3D, use it for switch between 2D/3D modes; 18. Use own code to generate hierarchical structure in HTML, replace dtree.js which is; extremely slow for complex hierarchies. Dramatically improve performance for; structures with large (~1000) number of items.; 19. Deliver to the server title of the objects, display it as hint in the browser.; 20. Better handling of special characters in the hierarchies - allows to display; symbols like ' or "" in the file structure. ### July 2014; 1. Migration to d3.v3.js and jQuery v2.1.1; 2. Fix errors in filling of histogram statbox; 3. Possibility of move and resize of statbox, title, color palete; 4. Remove many (not all) global variables; 5. Example with direct usage of JSRootIO graphics; 6. Example of inserting ROOT graphics from THttpServer into `<iframe></iframe>`. ### May 2014; 1. This JSRootIO code together with THttpServer class included; in ROOT repository. ### March 2014; 1. Introduce TBuffer class, which plays similar role; as TBuffer in native ROOT I/O. Simplifies I/O logic,; reduce duplication of code in many places, fix errors.; Main advantage - one could try to keep code synchronous with C++.; 2. Avoid objects cloning when object referenced severa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:76128,perform,performance,76128,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['perform'],['performance']
Performance,"n handling must signal an invalid exception, and produce a; quiet NaN result. This function should always be implementable as multiplication by 1.0, provided; that the compiler does not constant fold the operation. Likewise, division by; 1.0 and ``llvm.minnum(x, x)`` are possible implementations. Addition with; -0.0 is also sufficient provided that the rounding mode is not -Infinity. ``@llvm.canonicalize`` must preserve the equality relation. That is:. - ``(@llvm.canonicalize(x) == x)`` is equivalent to ``(x == x)``; - ``(@llvm.canonicalize(x) == @llvm.canonicalize(y))`` is equivalent; to ``(x == y)``. Additionally, the sign of zero must be conserved:; ``@llvm.canonicalize(-0.0) = -0.0`` and ``@llvm.canonicalize(+0.0) = +0.0``. The payload bits of a NaN must be conserved, with two exceptions.; First, environments which use only a single canonical representation of NaN; must perform said canonicalization. Second, SNaNs must be quieted per the; usual methods. The canonicalization operation may be optimized away if:. - The input is known to be canonical. For example, it was produced by a; floating-point operation that is required by the standard to be canonical.; - The result is consumed only by (or fused with) other floating-point; operations. That is, the bits of the floating-point value are not examined. .. _int_fmuladd:. '``llvm.fmuladd.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare float @llvm.fmuladd.f32(float %a, float %b, float %c); declare double @llvm.fmuladd.f64(double %a, double %b, double %c). Overview:; """""""""""""""""". The '``llvm.fmuladd.*``' intrinsic functions represent multiply-add; expressions that can be fused if the code generator determines that (a) the; target instruction set has support for a fused operation, and (b) that the; fused operation is more efficient than the equivalent, separate pair of mul; and add instructions. Arguments:; """""""""""""""""""". The '``llvm.fmuladd.*``' intrinsics each take three arguments: two; multi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:640871,optimiz,optimized,640871,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimized']
Performance,"n has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence.; * On GFX10.3 and GFX11 a memory attached last level (MALL) cache exists for GPU memory.; The MALL cache is fully coherent with GPU memory and has no impact on system; coherence. All agents (GPU and CPU) access GPU memory through the MALL cache. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L0 and L1 caches at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is accessed as MTYPE UC (uncached) to avoid; needing to invalidate the L2 cache.; * On APU the kernarg backi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:340349,cache,caches,340349,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"n in diagnostic line. This option, which defaults to ""none"", controls whether or not Clang; prints the category associated with a diagnostic when emitting it.; Each diagnostic may or many not have an associated category, if it; has one, it is listed in the diagnostic categorization field of the; diagnostic line (in the []'s). For example, a format string warning will produce these three; renditions based on the setting of this option:. ::. t.c:3:11: warning: conversion specifies type 'char *' but the argument has type 'int' [-Wformat]; t.c:3:11: warning: conversion specifies type 'char *' but the argument has type 'int' [-Wformat,1]; t.c:3:11: warning: conversion specifies type 'char *' but the argument has type 'int' [-Wformat,Format String]. This category can be used by clients that want to group diagnostics; by category, so it should be a high level category. We want dozens; of these, not hundreds or thousands of them. .. _opt_fsave-optimization-record:. .. option:: -f[no-]save-optimization-record[=<format>]. Enable optimization remarks during compilation and write them to a separate; file. This option, which defaults to off, controls whether Clang writes; optimization reports to a separate file. By recording diagnostics in a file,; users can parse or sort the remarks in a convenient way. By default, the serialization format is YAML. The supported serialization formats are:. - .. _opt_fsave_optimization_record_yaml:. ``-fsave-optimization-record=yaml``: A structured YAML format. - .. _opt_fsave_optimization_record_bitstream:. ``-fsave-optimization-record=bitstream``: A binary format based on LLVM; Bitstream. The output file is controlled by :option:`-foptimization-record-file`. In the absence of an explicit output file, the file is chosen using the; following scheme:. ``<base>.opt.<format>``. where ``<base>`` is based on the output file of the compilation (whether; it's explicitly specified through `-o` or not) when used with `-c` or `-S`.; For example:. * ``clang",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:10831,optimiz,optimization-record,10831,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization-record']
Performance,"n instance; ofTProofDataSetManagerFile; managing the <sandbox>/datasets; area is created. The directive 'Proof.DataSetManager' can be used to; modify the settings forTProofDataSetManagerFile or to load a; different dataset manager; for example, to '/pool/datasets' as area for; the dataset information, the following directive can be added to the; xrootd config file; xpd.putrc Proof.DataSetManager file dir:/pool/datasets. Interface to TProofMgr::GetSessionLogs() in the dialog; box. The graphics layout of the logbox has been re-designed, with new; buttons to grep the logs and to save them to a file. It is also; possible to choose the range of lines to be displayed and the subset of; nodes.; ; Support for connection control base on the UNIX group; (new directive 'xpd.allowedgroups; <grp1>,<grp2>, ...'). Improvements:. ; In the case of mismatch between the expected and actual; number of processed events, send back to the client the list of failed; packets.; Implement the classic strategy of the TPacketizer in; TPacketizerAdaptive; the strategy can be changed from adaptive; (default) to TPacketizer with: ""PROOF_PacketizerStrategy"" parameter to; PROOF; The max workers per node can now be also set in the; xrootd config file with.    xpd.putrc; Packetizer.MaxWorkersPerNode: <desired number>. Make fCacheDir and fPackageDir controllable via directive; . Fixes. ; Two memory leaks in TProofServ affecting repeated runs; withing the same session. Fix a problem cleaning-up the input list on the workers; ; The type of ""PROOF_MaxSlavesPerNode"",; ""PROOF_ForceLocal"" and; ""PROOF_PacketAsAFraction"" parameters has been changed from; Long_t to Int_t.; TProofCondor plug-in:; ; Adapt the signatures of the main constructors of; TProofCondor and TProofPEAC; (and of the related plug-in handlers) to the one of TProof.; Add the possibility to trigger the load of a generic; TProof-derived plug-in via; a directive the xrootd config file 'xpd.proofplugin', e.g.; 'xpd.proofplugin condor:'. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v520/index.html:2372,load,load,2372,proof/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v520/index.html,2,['load'],['load']
Performance,"n instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42232,load,load,42232,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,3,"['load', 'queue']","['load', 'queue']"
Performance,"n instruction. This pass could also remap target-specific instructions when beneficial.; In the future, this could replace the ExeDepsFix pass, as we can directly; select the best variant for an instruction that's available on multiple banks. .. _api-registerbankinfo:. API: RegisterBankInfo; ^^^^^^^^^^^^^^^^^^^^^. The ``RegisterBankInfo`` class describes multiple aspects of register banks. * **Banks**: ``addRegBankCoverage`` --- which register bank covers each; register class. * **Cross-Bank Copies**: ``copyCost`` --- the cost of a ``COPY`` from one bank; to another. * **Default Mapping**: ``getInstrMapping`` --- the default bank assignments for; a given instruction. * **Alternative Mapping**: ``getInstrAlternativeMapping`` --- the other; possible bank assignments for a given instruction. ``TODO``:; All this information should eventually be static and generated by TableGen,; mostly using existing information augmented by bank descriptions. ``TODO``:; ``getInstrMapping`` is currently separate from ``getInstrAlternativeMapping``; because the latter is more expensive: as we move to static mapping info,; both methods should be free, and we should merge them. .. _regbankselect-modes:. RegBankSelect Modes; ^^^^^^^^^^^^^^^^^^^. ``RegBankSelect`` currently has two modes:. * **Fast** --- For each instruction, pick a target-provided ""default"" bank; assignment. This is the default at -O0. * **Greedy** --- For each instruction, pick the cheapest of several; target-provided bank assignment alternatives. We intend to eventually introduce an additional optimizing mode:. * **Global** --- Across multiple instructions, pick the cheapest combination of; bank assignments. ``NOTE``:; On AArch64, we are considering using the Greedy mode even at -O0 (or perhaps at; backend -O1): because :ref:`gmir-llt` doesn't distinguish floating point from; integer scalars, the default assignment for loads and stores is the integer; bank, introducing cross-bank copies on most floating point operations. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst:2096,optimiz,optimizing,2096,interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst,2,"['load', 'optimiz']","['loads', 'optimizing']"
Performance,"n layering, decent design, and keeping the libraries independent of; any specific client."". Currently, clang is divided into the following libraries and tool:. libsupport - Basic support library, from LLVM.; libsystem - System abstraction library, from LLVM.; libbasic - Diagnostics, SourceLocations, SourceBuffer abstraction,; file system caching for input source files.; libast - Provides classes to represent the C AST, the C type system,; builtin functions, and various helpers for analyzing and manipulating the; AST (visitors, pretty printers, etc).; liblex - Lexing and preprocessing, identifier hash table, pragma; handling, tokens, and macro expansion.; libparse - Parsing. This library invokes coarse-grained 'Actions'; provided by the client (e.g. libsema builds ASTs) but knows nothing about; ASTs or other client-specific data structures.; libsema - Semantic Analysis. This provides a set of parser actions; to build a standardized AST for programs.; libcodegen - Lower the AST to LLVM IR for optimization & code; generation.; librewrite - Editing of text buffers (important for code rewriting; transformation, like refactoring).; libanalysis - Static analysis support.; clang - A driver program, client of the libraries at various; levels. As an example of the power of this library based design.... If you wanted to; build a preprocessor, you would take the Basic and Lexer libraries. If you want; an indexer, you would take the previous two and add the Parser library and; some actions for indexing. If you want a refactoring, static analysis, or; source-to-source compiler tool, you would then add the AST building and; semantic analyzer libraries.; For more information about the low-level implementation details of the; various clang libraries, please see the ; clang Internals Manual. Support Diverse Clients. Clang is designed and built with many grand plans for how we can use it. The; driving force is the fact that we use C and C++ daily, and have to suffer due to; a lack of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html:5606,optimiz,optimization,5606,interpreter/llvm-project/clang/www/features.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html,2,['optimiz'],['optimization']
Performance,"n may not call any code in the current module. In general (without target specific context), the address space of a; volatile operation may not be changed. Different address spaces may; have different trapping behavior when dereferencing an invalid; pointer. The compiler may assume execution will continue after a volatile operation,; so operations which modify memory or may have undefined behavior can be; hoisted past a volatile operation. As an exception to the preceding rule, the compiler may not assume execution; will continue after a volatile store operation. This restriction is necessary; to support the somewhat common pattern in C of intentionally storing to an; invalid pointer to crash the program. In the future, it might make sense to; allow frontends to control this behavior. IR-level volatile loads and stores cannot safely be optimized into llvm.memcpy; or llvm.memmove intrinsics even when those intrinsics are flagged volatile.; Likewise, the backend should never split or merge target-legal volatile; load/store instructions. Similarly, IR-level volatile loads and stores cannot; change from integer to floating-point or vice versa. .. admonition:: Rationale. Platforms may rely on volatile loads and stores of natively supported; data width to be executed as single instruction. For example, in C; this holds for an l-value of volatile primitive type with native; hardware support, but not necessarily for aggregate types. The; frontend upholds these expectations, which are intentionally; unspecified in the IR. The rules above ensure that IR transformations; do not violate the frontend's contract with the language. .. _memmodel:. Memory Model for Concurrent Operations; --------------------------------------. The LLVM IR does not define any way to start parallel threads of; execution or to register signal handlers. Nonetheless, there are; platform-specific ways to create them, and we define LLVM IR's behavior; in their presence. This model is inspired by the C++ mem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:148088,load,load,148088,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"n memory; location, loads from that location return undef. Relevant standard; This is intended to match shared variables in C/C++, and to be used in any; other context where memory access is necessary, and a race is impossible. (The; precise definition is in `LangRef Memory Model <LangRef.html#memmodel>`_.). Notes for frontends; The rule is essentially that all memory accessed with basic loads and stores; by multiple threads should be protected by a lock or other synchronization;; otherwise, you are likely to run into undefined behavior. If your frontend is; for a ""safe"" language like Java, use Unordered to load and store any shared; variable. Note that NotAtomic volatile loads and stores are not properly; atomic; do not try to use them as a substitute. (Per the C/C++ standards,; volatile does provide some limited guarantees around asynchronous signals, but; atomics are generally a better solution.). Notes for optimizers; Introducing loads to shared variables along a codepath where they would not; otherwise exist is allowed; introducing stores to shared variables is not. See; `Optimization outside atomic`_. Notes for code generation; The one interesting restriction here is that it is not allowed to write to; bytes outside of the bytes relevant to a store. This is mostly relevant to; unaligned stores: it is not allowed in general to convert an unaligned store; into two aligned stores of the same width as the unaligned store. Backends are; also expected to generate an i8 store as an i8 store, and not an instruction; which writes to surrounding bytes. (If you are writing a backend for an; architecture which cannot satisfy these restrictions and cares about; concurrency, please send an email to llvm-dev.). Unordered; ---------. Unordered is the lowest level of atomicity. It essentially guarantees that races; produce somewhat sane results instead of having undefined behavior. It also; guarantees the operation to be lock-free, so it does not depend on the data; being part",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:7117,optimiz,optimizers,7117,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,"['load', 'optimiz']","['loads', 'optimizers']"
Performance,"n of **opt**. **--disable-{dce,simplifycfg}**. Do not run the specified passes to clean up and reduce the size of the test; program. By default, **bugpoint** uses these passes internally when attempting to; reduce test programs. If you're trying to find a bug in one of these passes,; **bugpoint** may crash. **--enable-valgrind**. Use valgrind to find faults in the optimization phase. This will allow; bugpoint to find otherwise asymptomatic problems caused by memory; mis-management. **-find-bugs**. Continually randomize the specified passes and run them on the test program; until a bug is found or the user kills **bugpoint**. **-help**. Print a summary of command line options. **--input** *filename*. Open *filename* and redirect the standard input of the test program, whenever; it runs, to come from that file. **--load** *plugin*. Load the dynamic object *plugin* into **bugpoint** itself. This object should; register new optimization passes. Once loaded, the object will add new command; line options to enable various optimizations. To see the new complete list of; optimizations, use the **-help** and **--load** options together; for example:. .. code-block:: bash. bugpoint --load myNewPass.so -help. **--mlimit** *megabytes*. Specifies an upper limit on memory usage of the optimization and codegen. Set; to zero to disable the limit. **--output** *filename*. Whenever the test program produces output on its standard output stream, it; should match the contents of *filename* (the ""reference output""). If you; do not use this option, **bugpoint** will attempt to generate a reference output; by compiling the program with the ""safe"" backend and running it. **--run-{int,jit,llc,custom}**. Whenever the test program is compiled, **bugpoint** should generate code for it; using the specified code generator. These options allow you to choose the; interpreter, the JIT compiler, the static native code compiler, or a; custom command (see **--exec-command**) respectively. **--safe-{ll",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst:3431,load,loaded,3431,interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/bugpoint.rst,2,"['load', 'optimiz']","['loaded', 'optimizations']"
Performance,n of LLVM. * ``ELFABIVERSION_AMDGPU_HSA_V3`` is used to specify the version of AMD HSA; runtime ABI for code object V3. Can no longer be emitted by this version of LLVM. * ``ELFABIVERSION_AMDGPU_HSA_V4`` is used to specify the version of AMD HSA; runtime ABI for code object V4. Specify using the Clang option; ``-mcode-object-version=4``. * ``ELFABIVERSION_AMDGPU_HSA_V5`` is used to specify the version of AMD HSA; runtime ABI for code object V5. Specify using the Clang option; ``-mcode-object-version=5``. This is the default code object; version if not specified. * ``ELFABIVERSION_AMDGPU_PAL`` is used to specify the version of AMD PAL; runtime ABI. * ``ELFABIVERSION_AMDGPU_MESA3D`` is used to specify the version of AMD MESA; 3D runtime ABI. ``e_type``; Can be one of the following values:. ``ET_REL``; The type produced by the AMDGPU backend compiler as it is relocatable code; object. ``ET_DYN``; The type produced by the linker as it is a shared code object. The AMD HSA runtime loader requires a ``ET_DYN`` code object. ``e_machine``; The value ``EM_AMDGPU`` is used for the machine for all processors supported; by the ``r600`` and ``amdgcn`` architectures (see; :ref:`amdgpu-processor-table`). The specific processor is specified in the; ``NT_AMD_HSA_ISA_VERSION`` note record for code object V2 (see; :ref:`amdgpu-note-records-v2`) and in the ``EF_AMDGPU_MACH`` bit field of the; ``e_flags`` for code object V3 and above (see; :ref:`amdgpu-elf-header-e_flags-table-v3` and; :ref:`amdgpu-elf-header-e_flags-table-v4-onwards`). ``e_entry``; The entry point is 0 as the entry points for individual kernels must be; selected in order to invoke them through AQL packets. ``e_flags``; The AMDGPU backend uses the following ELF header flags:. .. table:: AMDGPU ELF Header ``e_flags`` for Code Object V2; :name: amdgpu-elf-header-e_flags-v2-table. ===================================== ===== =============================; Name Value Description; ===================================== ===== ==,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:59352,load,loader,59352,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loader']
Performance,"n of TROOT::FindObjectAnyFile.; Mark TROOT as TObject::kInvalidObject as soon as its destructor starts,; in order to be able to veto some action later on (like autoloading). TSystem. Better handle the cases where the information in the rootmap file is (almost) empty. ; Avoid infinite loop if one of the dependent library is missing. Meta. Add new fast accessors to Merge routines (See the I/O package for more details.; Improve error message in case a schema evolution rule can not be loaded when the library is loaded; (from the generic 'it conflicts with one of the other rules' to 'the target member ... is unknown'.; Add the ability to explicitly forbid (or allow) the splitting of a class; (TClass::SetSplit ) so that user can inforce the use of a custom streamer in all possible split cases.; Improve the performance of TProcessUUID::AddUUID by reintroducing the THashList.; This significanly improve the performance of reading file with very large number of ; directories (A file with 100,000 directories was traversed in more than 8 minutes; and is now traversed in 15s) without noticeable affecting small files. TFolder. Several enhancement and clarification to TFolder::FindFullPathName. TStyle. Add the fill color attribute (SetLegendFillColor() and the font; attribute (SetLegendFont(). A new TStyle called ""Modern"" has been implemented. It can be set with:. gROOT->SetStyle(""Modern"");; ; It has very little decoration. It was made looking at the default styles; usually used by the experiments.; ; A new parameter Canvas.Style in etc/system.rootrc allows; to define the default style. If it is not specified, the Modern; style is used. To use the old default style one can set it to Classic or add. gROOT->SetStyle(""Classic"");; ; to your scripts. We seek feedback on improving the Modern style.; Please leave comments in the forum.; ; The following table shows the two plots hpx->Draw() and hpxpy->Draw(""colz""); in the ""Classic"" and ""Modern"" styles.; . Classic Style; Modern Style. An ot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html:2006,perform,performance,2006,core/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html,2,['perform'],['performance']
Performance,"n overloaded intrinsic. You can use '``llvm.annotation``' on; any integer bit width. ::. declare i8 @llvm.annotation.i8(i8 <val>, ptr <str>, ptr <str>, i32 <int>); declare i16 @llvm.annotation.i16(i16 <val>, ptr <str>, ptr <str>, i32 <int>); declare i32 @llvm.annotation.i32(i32 <val>, ptr <str>, ptr <str>, i32 <int>); declare i64 @llvm.annotation.i64(i64 <val>, ptr <str>, ptr <str>, i32 <int>); declare i256 @llvm.annotation.i256(i256 <val>, ptr <str>, ptr <str>, i32 <int>). Overview:; """""""""""""""""". The '``llvm.annotation``' intrinsic. Arguments:; """""""""""""""""""". The first argument is an integer value (result of some expression), the; second is a pointer to a global string, the third is a pointer to a; global string which is the source file name, and the last argument is; the line number. It returns the value of the first argument. Semantics:; """""""""""""""""""". This intrinsic allows annotations to be put on arbitrary expressions with; arbitrary strings. This can be useful for special purpose optimizations that; want to look for these annotations. These have no other defined use;; transformations preserve annotations on a best-effort basis but are allowed to; replace the intrinsic with its first argument without breaking semantics and the; intrinsic is completely dropped during instruction selection. '``llvm.codeview.annotation``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This annotation emits a label at its program point and an associated; ``S_ANNOTATION`` codeview record with some additional string metadata. This is; used to implement MSVC's ``__annotation`` intrinsic. It is marked; ``noduplicate``, so calls to this intrinsic prevent inlining and should be; considered expensive. ::. declare void @llvm.codeview.annotation(metadata). Arguments:; """""""""""""""""""". The argument should be an MDTuple containing any number of MDStrings. '``llvm.trap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.trap() cold noreturn nounwind. Ove",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:927318,optimiz,optimizations,927318,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"n performance, but in some cases, it can be observed that it; is not as performing as bounding the structure in a container volume; with a simple shape. Choosing a normal container is therefore; recommended whenever possible. \image html geometry006.png ""Assemblies of volumes"" width=600px. \anchor GP01c; ### Geometrical Transformations. All geometrical transformations handled by the modeller are provided as; a built-in package. This was designed to minimize memory requirements; and optimize performance of point/vector master-to-local and; local-to-master computation. We need to have in mind that a; transformation in **`TGeo`** has two major use-cases. The first one is; for defining the placement of a volume with respect to its container; reference frame. This frame will be called 'master' and the frame of the; positioned volume - 'local'. If `T` is a transformation used for; positioning volume daughters, then: `MASTER = T * LOCAL`. Therefore `T `is used to perform a local to master conversion, while; `T-1` for a master to local conversion. The second use case is the; computation of the global transformation of a given object in the; geometry. Since the geometry is built as 'volumes-inside-volumes', the; global transformation represents the pile-up of all local; transformations in the corresponding branch. Once a given object in the; hierarchy becomes the current one, the conversion from master to local; coordinates or the other way around can be done from the manager class. A general homogenous transformation is defined as a 4x4 matrix embedding; a rotation, a translation and a scale. The advantage of this description; is that each basic transformation can be represented as a homogenous; matrix, composition being performed as simple matrix multiplication. Rotation:. \f[; \left|\begin{array}{cccc}; r_{11} & r_{12} & r_{13} & 0 \\; r_{21} & r_{22} & r_{23} & 0 \\; r_{31} & r_{32} & r_{33} & 0 \\; 0 & 0 & 0 & 1; \end{array}; \right|; \f]. Translation:. \f[; \left|\begi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:51971,perform,perform,51971,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['perform']
Performance,"n prior to this effort and serves as the; baseline for performance. One attempt to address the performance overhead of this and make it more; realistic to deploy is [MSVC's /Qspectre; switch](https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/).; Their technique is to use static analysis within the compiler to only insert; `lfence` instructions into conditional edges at risk of attack. However,; [initial](https://arstechnica.com/gadgets/2018/02/microsofts-compiler-level-spectre-fix-shows-how-hard-this-problem-will-be-to-solve/); [analysis](https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html); has shown that this approach is incomplete and only catches a small and limited; subset of attackable patterns which happen to resemble very closely the initial; proofs of concept. As such, while its performance is acceptable, it does not; appear to be an adequate systematic mitigation. ## Performance Overhead. The performance overhead of this style of comprehensive mitigation is very; high. However, it compares very favorably with previously recommended; approaches such as the `lfence` instruction. Just as users can restrict the; scope of `lfence` to control its performance impact, this mitigation technique; could be restricted in scope as well. However, it is important to understand what it would cost to get a fully; mitigated baseline. Here we assume targeting a Haswell (or newer) processor and; using all of the tricks to improve performance (so leaves the low 2gb; unprotected and +/- 2gb surrounding any PC in the program). We ran both; Google's microbenchmark suite and a large highly-tuned server built using; ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:46481,perform,performance,46481,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance,"n reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This performs unsigned dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output. llvm.amdgcn.udot4 Provides direct access to v_dot4_u32_u8 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.sdot2 Provides direct access to v_dot2_i32_i16 across targets which; support such instructions. This performs signed dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output.; When applicable (e.g. no clamping), this is lowered into; v_dot2",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:39249,perform,performs,39249,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performs']
Performance,"n replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested range",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23703,load,loading,23703,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['load'],['loading']
Performance,"n several clipping shapes. Note that these shapes; are considered defined in the current `MARS`. Composite shapes may be; used. 2`. gGeoManager->SetClippingShape(clip1);`. One can activate or deactivate clipping at any time:; `gGeoManager->SetClipping(flag);`. 3. Perform ray-tracing:` gGeoManager->GetTopVolume()->Raytrace();`. One can redo the steps 2-3 as many times as needed. Let us look how the; ***`rootgeom`*** example looks clipped with a tube. ![Ray-tracing example with box-clipping](pictures/030001E5.png). ## Representing Misalignments of the Ideal Geometry. The ideal positioning of a detector does not match its position in the; experimental hall. This generally happens not only for the detector; modules, but also for their components. The accurate knowledge of the; detector real misalignments can be extremely important for getting close; to its designed resolution and the expected tracking efficiency.; **`TGeo`** offers tools for representing positioning misalignments,; applying them to the ideal geometry and performing navigation under; these conditions. Detector tracking algorithms can then directly query; the geometry for navigation purposes or for retrieving actual; misalignment information. ### Physical Nodes. Physical nodes are the actual ""touchable"" objects in the geometry,; representing actually a path of positioned volumes starting with the; top node: `path=/TOP/A_1/B_4/C_3` , where `A`, `B`, `C` represent names; of volumes. The number of physical nodes is given by the total number of; possible of branches in the geometry hierarchy. In case of detector; geometries and specially for calorimeters this number can be of the; order 106-109, therefore it is impossible to create all physical nodes; as objects in memory. In **`TGeo`**, physical nodes are represented by; the class **`TGeoPhysicalNode`** and can be created on demand for; alignment purposes:. ``` {.cpp}; TGeoPhysicalNode(const char* path); ```. The knowledge of the path to the objects that need",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:145936,perform,performing,145936,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performing']
Performance,"n the corresponding memory; page. If Addr is the target address, and V is the shadow value, then; the address of __cfi_check is calculated as. .. code-block:: none. __cfi_check = AlignUpTo(Addr, 4096) - (V + 1) * 4096. This works as long as __cfi_check is aligned by 4096 bytes and located; below any call targets in its DSO, but not more than 256MB apart from; them. CFI_SlowPath; ------------. The slow path check is implemented in a runtime support library as. .. code-block:: none. void __cfi_slowpath(uint64 CallSiteTypeId, void *TargetAddr); void __cfi_slowpath_diag(uint64 CallSiteTypeId, void *TargetAddr, void *DiagData). These functions loads a shadow value for ``TargetAddr``, finds the; address of ``__cfi_check`` as described above and calls; that. ``DiagData`` is an opaque pointer to diagnostic data which is; passed verbatim to ``__cfi_check``, and ``__cfi_slowpath`` passes; ``nullptr`` instead. Compiler-RT library contains reference implementations of slowpath; functions, but they have unresolvable issues with correctness and; performance in the handling of dlopen(). It is recommended that; platforms provide their own implementations, usually as part of libc; or libdl. Position-independent executable requirement; -------------------------------------------. Cross-DSO CFI mode requires that the main executable is built as PIE.; In non-PIE executables the address of an external function (taken from; the main executable) is the address of that functions PLT record in; the main executable. This would break the CFI checks. Backward-edge CFI for return statements (RCFI); ==============================================. This section is a proposal. As of March 2017 it is not implemented. Backward-edge control flow (`RET` instructions) can be hijacked; via overwriting the return address (`RA`) on stack.; Various mitigation techniques (e.g. `SafeStack`_, `RFG`_, `Intel CET`_); try to detect or prevent `RA` corruption on stack. RCFI enforces the expected control flow in s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst:23496,perform,performance,23496,interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrityDesign.rst,1,['perform'],['performance']
Performance,"n the following we will focus on the non-declared overlaps of type *A)*; and *B)* since this is the main source of errors during tracking. These; are generally non-intended overlaps due to coding mistakes or bad; geometry design. The checking package is loaded together with the; painter classes and contains an automated overlap checker. \image html geometry008.png ""Overlap checking"". This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ~~~{.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision);; myNode->CheckOverlaps(precision);; ~~~. Here precision represents the desired maximum accepted overlap value in; centimeters (default value is 0.1). This tool checks all possible; significant pairs of candidates inside a given volume (not declared as; overlapping or division volumes). The check is performed by verifying; the mesh representation of one candidate against the shape of the other.; This sort of check cannot identify all possible overlapping topologies,; but it works for more than 95% and is much faster than the usual; shape-to-shape comparison. For a 100% reliability, one can perform the; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion *A)* is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap *B)* is declared if:. - At least one vertex of a posit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:93464,perform,performed,93464,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performed']
Performance,"n the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with oth",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:237010,queue,queue,237010,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance,"n the pch.; * Avoid autoparse on IsForeign() if possible.; * Check for new-style empty pcm with key named ""EMPTY"" created since commit 90047b0cba6fd295f5c5722749a0d043fbc11ea5.; * Do not insert macro definition of `__ROOTCLING__` into the pch. ### Interpreter Library. * llvm / clang have been updated to r274612.; * The GCC5 ABI is now supported [ROOT-7947].; * Exceptions are now caught in the interactive ROOT session, instead of terminating ROOT.; * A ValuePrinter for tuple and pair has been added to visualise the content of these entities at the prompt.; * When interpreting dereferences of invalid pointers, cling will now complain (throw, actually) instead of crash.; * Resolve memory hoarding in some case of looking up functions [ROOT-8145]. ## Parallelism. * Three methods have been added to manage implicit multi-threading in ROOT: `ROOT::EnableImplicitMT(numthreads)`, `ROOT::DisableImplicitMT` and `ROOT::IsImplicitMTEnabled`. They can be used to enable, disable and check the status of the global implicit multi-threading in ROOT, respectively.; * Even if the default reduce function specified in the invocation of the `MapReduce` method of `TProcessExecutor` returns a pointer to a `TObject`, the return value of `MapReduce` is properly casted to the type returned by the map function.; * Add a new class named `TThreadExecutor` implementing a MapReduce framework sharing `TProcessExecutor` interface and based in tbb.; * Add a new class named `TExecutor` defining the MapReduce interface for `TProcessExecutor` and `TThreadExecutor`, who inherit from it.; * Remove all `TPool` signatures accepting collections as an argument with the exception of std::vector and initializer_lists. ; * Extend `TThreadExecutor` functionality offering parallel reduction given a binary operator as a reduction function.; * Add a new class named `TThreadedObject` which helps making objects thread private and merging them.; * Add tutorials showing how to fill randomly histograms using the `TProcessEx",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:5891,multi-thread,multi-threading,5891,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['multi-thread'],['multi-threading']
Performance,"n the value string. Next, use ``genreflex`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ genreflex MyClass.h --selection=myclass_selection.xml -o MyClass_rflx.cxx. From here, compile and link the generated dictionary file with the project; and/or system specific options and libraries into a shared library, using; ``cling-config`` for the relevant cppyy compiler/linker flags.; (For work on MS Windows, this `helper script`_ may be useful.); To continue the example, assuming Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:7549,load,loader,7549,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,1,['load'],['loader']
Performance,"n to TProofMgr since it is added to the list of socket.; Migrate the closing of files from various to a single place (T*System::Exit).; Fill in the implementation of TROOT::FindObjectAnyFile.; Mark TROOT as TObject::kInvalidObject as soon as its destructor starts,; in order to be able to veto some action later on (like autoloading). TSystem. Better handle the cases where the information in the rootmap file is (almost) empty. ; Avoid infinite loop if one of the dependent library is missing. Meta. Add new fast accessors to Merge routines (See the I/O package for more details.; Improve error message in case a schema evolution rule can not be loaded when the library is loaded; (from the generic 'it conflicts with one of the other rules' to 'the target member ... is unknown'.; Add the ability to explicitly forbid (or allow) the splitting of a class; (TClass::SetSplit ) so that user can inforce the use of a custom streamer in all possible split cases.; Improve the performance of TProcessUUID::AddUUID by reintroducing the THashList.; This significanly improve the performance of reading file with very large number of ; directories (A file with 100,000 directories was traversed in more than 8 minutes; and is now traversed in 15s) without noticeable affecting small files. TFolder. Several enhancement and clarification to TFolder::FindFullPathName. TStyle. Add the fill color attribute (SetLegendFillColor() and the font; attribute (SetLegendFont(). A new TStyle called ""Modern"" has been implemented. It can be set with:. gROOT->SetStyle(""Modern"");; ; It has very little decoration. It was made looking at the default styles; usually used by the experiments.; ; A new parameter Canvas.Style in etc/system.rootrc allows; to define the default style. If it is not specified, the Modern; style is used. To use the old default style one can set it to Classic or add. gROOT->SetStyle(""Classic"");; ; to your scripts. We seek feedback on improving the Modern style.; Please leave comments in the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html:1906,perform,performance,1906,core/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v530/index.html,2,['perform'],['performance']
Performance,"n values with the same number of elements as the return type.; The third is the explicit vector length of the operation. The return type and; underlying type of the base pointer are the same vector types. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.vp.load``' intrinsic reads a vector from memory in the same way as; the '``llvm.masked.load``' intrinsic, where the mask is taken from the; combination of the '``mask``' and '``evl``' operands in the usual VP way.; Certain '``llvm.masked.load``' operands do not have corresponding operands in; '``llvm.vp.load``': the '``passthru``' operand is implicitly ``poison``; the; '``alignment``' operand is taken as the ``align`` parameter attribute, if; provided. The default alignment is taken as the ABI alignment of the return; type as specified by the :ref:`datalayout string<langref_datalayout>`. Examples:; """""""""""""""""". .. code-block:: text. %r = call <8 x i8> @llvm.vp.load.v8i8.p0(ptr align 2 %ptr, <8 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %also.r = call <8 x i8> @llvm.masked.load.v8i8.p0(ptr %ptr, i32 2, <8 x i1> %mask, <8 x i8> poison). .. _int_vp_store:. '``llvm.vp.store``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare void @llvm.vp.store.v4f32.p0(<4 x float> %val, ptr %ptr, <4 x i1> %mask, i32 %evl); declare void @llvm.vp.store.nxv2i16.p0(<vscale x 2 x i16> %val, ptr %ptr, <vscale x 2 x i1> %mask, i32 %evl); declare void @llvm.vp.store.v8f32.p1(<8 x float> %val, ptr addrspace(1) %ptr, <8 x i1> %mask, i32 %evl); declare void @llvm.vp.store.nxv1i64.p6(<vscale x 1 x i64> %val, ptr addrspace(6) %ptr, <vscale x 1 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.vp.store.*``' intrinsic is the vector length predicated version of; the :ref:`llvm.masked.store <int_mstore>` intrinsic. Arguments:; """""""""""""""""""". The first ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:784677,load,load,784677,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"n variables. You can exploit the; bi-dimensional histogram classes provided by ROOT in a simple way.; Let's see how in this macro:. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/macro7.C; ```. Two kinds of plots are provided within the code, the first one; containing three-dimensional representations (Figure [5.4](#f54)) and the second one; projections and profiles (Figure [5.5](#f55)) of the bi-dimensional histogram. [f54]: figures/th2f.png ""f54""; <a name=""f54""></a>. ![Different ways of representing bi-dimensional; histograms.\label{f54}][f54]. [f55]: figures/proj_and_prof.png ""f55""; <a name=""f55""></a>. ![The projections and profiles of bi-dimensional; histograms.\label{f55}][f55]. When a projection is performed along the x (y) direction, for every bin; along the x (y) axis, all bin contents along the y (x) axis are summed; up (upper the plots of Figure [5.5](#f55)). When a profile is performed along the x (y); direction, for every bin along the x (y) axis, the average of all the; bin contents along the y (x) is calculated together with their RMS and; displayed as a symbol with error bar (lower two plots of Figure [5.5](#f55)). Correlations between the variables are quantified by the methods; `Double_t GetCovariance()` and `Double_t GetCorrelationFactor()`. \newpage. ## Multiple histograms ##. The class `THStack` allows to manipulate a set of histograms as a single entity.; It is a collection of `TH1` (or derived) objects. When drawn, the X and Y axis; ranges are automatically computed such as all the histograms will be visible.; Several drawing option are available for both 1D and 2D histograms. The next; macros shows how it looks for 2D histograms:. ``` {.cpp .numberLines}; @ROOT_INCLUDE_FILE macros/hstack.C; ```. - Line *4*: creates the stack. - Lines *4-18*: create two histograms to be added in the stack. - Lines *20-21*: add the histograms in the stack. - Line *23*: draws the stack as a lego plot. The colour distinguish the two histograms [5.6](#f56). [f56]: figures/h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/histograms.md:4169,perform,performed,4169,documentation/primer/histograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/histograms.md,1,['perform'],['performed']
Performance,"n when; visualizing or tracking the geometry are depicted in the `TOP_1` branch.; These are the nodes of the `physical` `tree` of positioned volumes; represented by TGeoNode objects. This hierarchy is a tree since a; node can have only one parent and several daughters. For a better; understanding of the hierarchy, have a look at TGeoManage. Just close now the `X3D` window and focus at the wire frame picture; drawn in a pad. Activate Options/Event Status. Moving the mouse in the; pad, you will notice that objects are sometimes changing color to red.; Volumes are highlighted in this way whenever the mouse pointer is close; enough to one of its vertices. When this happens, the corresponding; volume is selected and you will see in the bottom right size of the %ROOT; canvas its name, shape type and corresponding path in the physical tree.; Right clicking on the screen when a volume is selected will also open; its context menu (picking). Note that there are several actions that can; be performed both at view (no volume selected) and volume level. TView (mouse not selecting any volume):. - Click-and-drag rotates the view.; - Pressing some keys perform different actions:; - J/K - zoom / unzoom; - H, L, U, I - move the viewpoint; - Right click + `SetParallel` `()/SetPerspective` `()` - switch from; parallel to perspective view.; - Right click + `ShowAxis()` - show coordinate axes.; - Right click + `Centered/Left/Side/Top` - change view direction. TGeoVolume (mouse selecting a volume):. - Double click will focus the corresponding volume.; - Right click + `CheckOverlaps()` - run overlap checker on current; volume.; - Right click + `Draw` `()` - draw that volume according current; global visualization options; - Right click + `DrawOnly()` - draw only the selected volume.; - Right click + `InspectShape/Material()` - print info about shape or; material.; - Right click + `Raytrace()` - initiate a ray tracing algorithm on; current view.; - Right click + `RandomPoints/Rays()` - shoot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:14066,perform,performed,14066,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performed']
Performance,"n while ensuring that the value lives across the; call boundary. In the worst case, this may involve an ``autorelease``, but; callers must not assume that the value is actually in the autorelease pool. ARC performs no extra mandatory work on the caller side, although it may elect; to do something to shorten the lifetime of the returned value. .. admonition:: Rationale. It is common in non-ARC code to not return an autoreleased value; therefore; the convention does not force either path. It is convenient to not be; required to do unnecessary retains and autoreleases; this permits; optimizations such as eliding retain/autoreleases when it can be shown that; the original pointer will still be valid at the point of return. A method or function may be marked with; ``__attribute__((ns_returns_autoreleased))`` to indicate that it returns a; pointer which is guaranteed to be valid at least as long as the innermost; autorelease pool. There are no additional semantics enforced in the definition; of such a method; it merely enables optimizations in callers. .. _arc.objects.operands.casts:. Bridged casts; ^^^^^^^^^^^^^. A :arc-term:`bridged cast` is a C-style cast annotated with one of three; keywords:. * ``(__bridge T) op`` casts the operand to the destination type ``T``. If; ``T`` is a retainable object pointer type, then ``op`` must have a; non-retainable pointer type. If ``T`` is a non-retainable pointer type,; then ``op`` must have a retainable object pointer type. Otherwise the cast; is ill-formed. There is no transfer of ownership, and ARC inserts no retain; operations.; * ``(__bridge_retained T) op`` casts the operand, which must have retainable; object pointer type, to the destination type, which must be a non-retainable; pointer type. ARC retains the value, subject to the usual optimizations on; local values, and the recipient is responsible for balancing that +1.; * ``(__bridge_transfer T) op`` casts the operand, which must have; non-retainable pointer type, to the d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:22730,optimiz,optimizations,22730,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizations']
Performance,"n your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaustive. Restricted Operation Semantics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; #. Add nsw/nuw flags as appropriate. Reasoning about overflow is; generally hard for an optimizer so providing these facts from the frontend; can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferenceable/nonnull to function arguments and return; values as appropriate. #. Use pointer aliasing metadata, especially tbaa metadata, to communicate; otherwise-non-deducible pointer aliasing facts. #. Use inbounds on geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:11011,optimiz,optimizations,11011,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,2,"['optimiz', 'perform']","['optimizations', 'performed']"
Performance,"n't require new live intervals / registers. See 2003-05-31-LongShifts for; an example. //===---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0 x %obj] }** %array_addr; %nth_el = getelementptr { i32, [0 x %obj] }* %array, i32 0, i32 %n; %old = load %obj** %nth_el; %z = div i64 %x, %y; store %obj* %new, %obj** %nth_el. If the i64 division is lowered to a libcall, then a safe point will (must); appear for the call site. If a collection occurs, %array and %nth_el no longer; point into the correct object. The fix for this is to copy address calculations so that dependent pointers; are never live across safe point boundaries. But the loads cannot be copied; like this if there was an intervening store, so may be hard to get right. Only a concurrent mutator can trigger a collection at the libcall safe point.; So single-threaded programs do not have this requirement, even with a copying; collector. Still, LLVM optimizations would probably undo a front-end's careful; work. //===---------------------------------------------------------------------===//. The ocaml frametable structure supports liveness information. It would be good; to support it. //===---------------------------------------------------------------------===//. The FIXME in ComputeCommonTailLength in BranchFolding.cpp needs to be; revisited. The check is there to work around a misuse of directives in inline; assembly. //===---------------------------------------------------------------------===//. It would be good to detect collector/target compatibility instead of silently; doing the wrong thing. //===---------------------------------------------------------------------===//. It would be really ni",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:3494,load,loads,3494,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['load'],['loads']
Performance,"n, avoids kink for asymmetric uncert). The piece-wise logarithmic interpolation paired with a Gaussian constraint is equivalent to a log-normal constraint in a transformed version of the nuisance parameter. The benefit of this approach is that it is easy to avoid the normalization from taking on unphysical negative values. This is the prescription used by the CMS Higgs group, and agreed upon by the LHC Higgs Combination Group. There is not yet XML-based steering for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:1486,perform,performance,1486,roofit/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html,2,['perform'],['performance']
Performance,"n-atomic. Constant address space uses ``buffer/global_load`` instructions (or equivalent; scalar memory instructions). Since the constant address space contents do not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204226,optimiz,optimization,204226,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['optimiz'],"['optimization', 'optimization-constraints-table']"
Performance,"n-dag-isel generate tables to help identify the patterns matched. .. option:: -omit-comments. Make -gen-dag-isel omit comments. The default is false. .. option:: -gen-dfa-packetizer. Generate DFA Packetizer for VLIW targets. .. option:: -gen-directive-decl. Generate directive related declaration code (header file). .. option:: -gen-directive-gen. Generate directive related implementation code part. .. option:: -gen-directive-impl. Generate directive related implementation code. .. option:: -gen-disassembler. Generate disassembler. .. option:: -gen-emitter. Generate machine code emitter. .. option:: -gen-exegesis. Generate llvm-exegesis tables. .. option:: -gen-fast-isel. Generate a ""fast"" instruction selector. .. option:: -gen-global-isel. Generate GlobalISel selector. .. option:: -gisel-coverage-file=filename. Specify the file from which to retrieve coverage information. .. option:: -instrument-gisel-coverage. Make -gen-global-isel generate coverage instrumentation. .. option:: -optimize-match-table. Make -gen-global-isel generate an optimized version of the match table. .. option:: -warn-on-skipped-patterns. Make -gen-global-isel explain why a pattern was skipped for inclusion. .. option:: -gen-global-isel-combiner. Generate GlobalISel combiner. .. option:: -combiners=list. Make -gen-global-isel-combiner emit the specified combiners. .. option:: -gicombiner-debug-cxxpreds. Add debug comments to all C++ predicates emitted by -gen-global-isel-combiner. .. option:: -gicombiner-stop-after-parse. Make -gen-global-isel-combiner stop processing after parsing rules and dump state. .. option:: -gen-instr-info. Generate instruction descriptions. .. option:: -gen-instr-docs. Generate instruction documentation. .. option:: -gen-intrinsic-enums. Generate intrinsic enums. .. option:: -intrinsic-prefix=prefix. Make -gen-intrinsic-enums generate intrinsics with this target *prefix*. .. option:: -gen-intrinsic-impl. Generate intrinsic information. .. option:: -gen-opt-parser-defs.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:10627,optimiz,optimize-match-table,10627,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,1,['optimiz'],['optimize-match-table']
Performance,"n. Almost all; relevant classes can be found in libraries returned by; `root-config -glibs`; the graphics libraries are retuned by; `root-config --libs`. These commands are commonly used in `Makefiles`.; Using `root-config` instead of enumerating the libraries by hand; allows you to link them in a platform independent way. Also, if ROOT; library names change you will not need to change your Makefile. A batch program that does not have a graphic display, which creates,; fills, and saves histograms and trees, only needs to link the core; libraries (`libCore`, `libRIO`), `libHist` and `libTree`.; If ROOT needs access to other libraries, it loads them dynamically.; For example, if the **`TreeViewer`** is used, `libTreePlayer` and all; libraries `libTreePlayer` depends on are loaded also. The dependent; libraries are shown in the ROOT reference guide's library dependency; graph. The difference between reference guide `libHist` and; `libHistPainter` is that the former needs to be explicitly linked and; the latter will be loaded automatically at runtime when ROOT needs it,; by means of the Plugin Manager. plugin manager. In the Figure 1-2, the libraries represented by green boxes outside of; the core are loaded via the plugin manager plugin manager or; equivalent techniques, while the white ones are not. Of course, if one; wants to access a plugin library directly, it has to be explicitly; linked. An example of a plugin library is `libMinuit`. To create and; fill histograms you need to link `libHist.so`. If the code has a call; to fit the histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be im",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:18309,load,loaded,18309,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['load'],['loaded']
Performance,"n. For example, knowing that a; branch is taken very frequently helps the compiler make better decisions when; ordering basic blocks. Knowing that a function ``foo`` is called more; frequently than another function ``bar`` helps the inliner. Optimization; levels ``-O2`` and above are recommended for use of profile guided optimization. Clang supports profile guided optimization with two different kinds of; profiling. A sampling profiler can generate a profile with very low runtime; overhead, or you can build an instrumented version of the code that collects; more detailed profile information. Both kinds of profiles can provide execution; counts for instructions in the code and information on branches taken and; function invocation. Regardless of which kind of profiling you use, be careful to collect profiles; by running your code with inputs that are representative of the typical; behavior. Code that is not exercised in the profile will be optimized as if it; is unimportant, and the compiler may make poor optimization choices for code; that is disproportionately used while profiling. Differences Between Sampling and Instrumentation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Although both techniques are used for similar purposes, there are important; differences between the two:. 1. Profile data generated with one cannot be used by the other, and there is no; conversion tool that can convert one to the other. So, a profile generated; via ``-fprofile-generate`` or ``-fprofile-instr-generate`` must be used with; ``-fprofile-use`` or ``-fprofile-instr-use``. Similarly, sampling profiles; generated by external profilers must be converted and used with ``-fprofile-sample-use``; or ``-fauto-profile``. 2. Instrumentation profile data can be used for code coverage analysis and; optimization. 3. Sampling profiles can only be used for optimization. They cannot be used for; code coverage analysis. Although it would be technically possible to use; sampling profiles for cod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:90615,optimiz,optimized,90615,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,['optimiz'],"['optimization', 'optimized']"
Performance,"n. To represent this, a top level landing pad may exist to; filter out invalid types. To express this in LLVM code the :ref:`i_landingpad`; will have a filter clause. The clause consists of an array of type infos.; ``landingpad`` will return a negative value; if the exception does not match any of the type infos. If no match is found then; a call to ``__cxa_call_unexpected`` should be made, otherwise; ``_Unwind_Resume``. Each of these functions requires a reference to the; exception structure. Note that the most general form of a ``landingpad``; instruction can have any number of catch, cleanup, and filter clauses (though; having more than one cleanup is pointless). The LLVM C++ front-end can generate; such ``landingpad`` instructions due to inlining creating nested exception; handling scopes. Restrictions; ------------. The unwinder delegates the decision of whether to stop in a call frame to that; call frame's language-specific personality function. Not all unwinders guarantee; that they will stop to perform cleanups. For example, the GNU C++ unwinder; doesn't do so unless the exception is actually caught somewhere further up the; stack. In order for inlining to behave correctly, landing pads must be prepared to; handle selector results that they did not originally advertise. Suppose that a; function catches exceptions of type ``A``, and it's inlined into a function that; catches exceptions of type ``B``. The inliner will update the ``landingpad``; instruction for the inlined landing pad to include the fact that ``B`` is also; caught. If that landing pad assumes that it will only be entered to catch an; ``A``, it's in for a rude awakening. Consequently, landing pads must test for; the selector results they understand and then resume exception propagation with; the `resume instruction <LangRef.html#i_resume>`_ if none of the conditions; match. Exception Handling Intrinsics; =============================. In addition to the ``landingpad`` and ``resume`` instructions",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst:14219,perform,perform,14219,interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExceptionHandling.rst,1,['perform'],['perform']
Performance,"n.; root [] foo::bar baz2; // #3: requires a definition.; root [] TCanvas* c = new TCanvas(); // #4 requires a definition; ```. Line #4 forces cling to send ROOT a callback that TCanvas in unknown but; the GMI resolves it to module Gpad, loads it and returns the control to cling. ### Performance; This section compares ROOT PCH technology with C++ Modules which is important but; unfair comparison. As we noted earlier, PCH is very efficient, it cannot be; extended to the experiments software stacks because of its design constraints.; On the contrary, the C++ Modules can be used in third-party code where the PCH; is not available. The comparisons are to give a good metric when we are ready to switch ROOT to use; C++ Modules by default. However, since it is essentially the same technology,; optimizations of C++ Modules also affect the PCH. We have a few tricks up in; the sleeves to but they come with given trade-offs. #### Preloading of C++ Modules. The main focus for the technology preview was not in performance until recently.; We have invested some resources in optimizations and we would like to show you; (probably outdated) performance results:. * Memory footprint -- mostly due to importing all C++ Modules at startup; we see overhead which depends on the number of preloaded modules. For; ROOT it is between 40-60 MB depending on the concrete configuration.; When the workload increases we notice that the overall memory performance; decreases in number of cases.; * Execution times -- likewise we have an execution overhead. For ; workflows which take ms the slowdown can be 2x. Increasing of the work; to seconds shows 50-60% slowdowns. The performance is dependent on many factors such as configuration of ROOT and; workflow. You can read more at our Intel IPCC-ROOT Showcase presentation; here (pp 25-33)[[8]]. #### Loading C++ Modules on Demand. In long term, we should optimize the preloading of modules to be a no-op and; avoid recursive behavior based on identifier lookup",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:18025,perform,performance,18025,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['perform'],['performance']
Performance,"n.c -o main.o # <-- main.o is native object file; % clang -flto a.o main.o -o main # <-- standard link command with -flto. * In this example, the linker recognizes that ``foo2()`` is an externally; visible symbol defined in LLVM bitcode file. The linker completes its usual; symbol resolution pass and finds that ``foo2()`` is not used; anywhere. This information is used by the LLVM optimizer and it; removes ``foo2()``. * As soon as ``foo2()`` is removed, the optimizer recognizes that condition ``i; < 0`` is always false, which means ``foo3()`` is never used. Hence, the; optimizer also removes ``foo3()``. * And this in turn, enables linker to remove ``foo4()``. This example illustrates the advantage of tight integration with the; linker. Here, the optimizer can not remove ``foo3()`` without the linker's; input. Alternative Approaches; ----------------------. **Compiler driver invokes link time optimizer separately.**; In this model the link time optimizer is not able to take advantage of; information collected during the linker's normal symbol resolution phase.; In the above example, the optimizer can not remove ``foo2()`` without the; linker's input because it is externally visible. This in turn prohibits the; optimizer from removing ``foo3()``. **Use separate tool to collect symbol information from all object files.**; In this model, a new, separate, tool or library replicates the linker's; capability to collect information for link time optimization. Not only is; this code duplication difficult to justify, but it also has several other; disadvantages. For example, the linking semantics and the features provided; by the linker on various platform are not unique. This means, this new tool; needs to support all such features and platforms in one super tool or a; separate tool per platform is required. This increases maintenance cost for; link time optimizer significantly, which is not necessary. This approach; also requires staying synchronized with linker developments",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:3335,optimiz,optimizer,3335,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['optimiz'],['optimizer']
Performance,"n: ``Leave``); Leave the line breaking after attributes as is. .. code-block:: c++. [[maybe_unused]] const int i;; [[gnu::const]] [[maybe_unused]]; int j;. [[nodiscard]] inline int f();; [[gnu::const]] [[nodiscard]]; int g();. [[likely]] if (a); f();; else; g();. switch (b) {; [[unlikely]] case 1:; ++b;; break;; [[likely]]; default:; return;; }. * ``ABS_Never`` (in configuration: ``Never``); Never break after attributes. .. code-block:: c++. [[maybe_unused]] const int i;; [[gnu::const]] [[maybe_unused]] int j;. [[nodiscard]] inline int f();; [[gnu::const]] [[nodiscard]] int g();. [[likely]] if (a); f();; else; g();. switch (b) {; [[unlikely]] case 1:; ++b;; break;; [[likely]] default:; return;; }. .. _BreakAfterJavaFieldAnnotations:. **BreakAfterJavaFieldAnnotations** (``Boolean``) :versionbadge:`clang-format 3.8` :ref:` <BreakAfterJavaFieldAnnotations>`; Break after each annotation on a field in Java files. .. code-block:: java. true: false:; @Partial vs. @Partial @Mock DataLoad loader;; @Mock; DataLoad loader;. .. _BreakArrays:. **BreakArrays** (``Boolean``) :versionbadge:`clang-format 16` :ref:` <BreakArrays>`; If ``true``, clang-format will always break after a Json array ``[``; otherwise it will scan until the closing ``]`` to determine if it should; add newlines between elements (prettier compatible). .. note::. This is currently only for formatting JSON. .. code-block:: c++. true: false:; [ vs. [1, 2, 3, 4]; 1,; 2,; 3,; 4; ]. .. _BreakBeforeBinaryOperators:. **BreakBeforeBinaryOperators** (``BinaryOperatorStyle``) :versionbadge:`clang-format 3.6` :ref:` <BreakBeforeBinaryOperators>`; The way to wrap binary operators. Possible values:. * ``BOS_None`` (in configuration: ``None``); Break after operators. .. code-block:: c++. LooooooooooongType loooooooooooooooooooooongVariable =; someLooooooooooooooooongFunction();. bool value = aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa +; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa ==; aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:45534,load,loader,45534,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,2,['load'],['loader']
Performance,"n:. .. code-block:: console. % clang -flto -c a.c -o a.o # <-- a.o is LLVM bitcode file; % clang -c main.c -o main.o # <-- main.o is native object file; % clang -flto a.o main.o -o main # <-- standard link command with -flto. * In this example, the linker recognizes that ``foo2()`` is an externally; visible symbol defined in LLVM bitcode file. The linker completes its usual; symbol resolution pass and finds that ``foo2()`` is not used; anywhere. This information is used by the LLVM optimizer and it; removes ``foo2()``. * As soon as ``foo2()`` is removed, the optimizer recognizes that condition ``i; < 0`` is always false, which means ``foo3()`` is never used. Hence, the; optimizer also removes ``foo3()``. * And this in turn, enables linker to remove ``foo4()``. This example illustrates the advantage of tight integration with the; linker. Here, the optimizer can not remove ``foo3()`` without the linker's; input. Alternative Approaches; ----------------------. **Compiler driver invokes link time optimizer separately.**; In this model the link time optimizer is not able to take advantage of; information collected during the linker's normal symbol resolution phase.; In the above example, the optimizer can not remove ``foo2()`` without the; linker's input because it is externally visible. This in turn prohibits the; optimizer from removing ``foo3()``. **Use separate tool to collect symbol information from all object files.**; In this model, a new, separate, tool or library replicates the linker's; capability to collect information for link time optimization. Not only is; this code duplication difficult to justify, but it also has several other; disadvantages. For example, the linking semantics and the features provided; by the linker on various platform are not unique. This means, this new tool; needs to support all such features and platforms in one super tool or a; separate tool per platform is required. This increases maintenance cost for; link time optimizer significa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:3282,optimiz,optimizer,3282,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['optimiz'],['optimizer']
Performance,"n:: -print-imm-hex. Prefer hex format for numeric literals in the output assembly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4170,load,load,4170,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,3,"['load', 'queue']","['load', 'queue']"
Performance,"n:; - return the elements of v1 if the condition c is true and v2 if the condition c is false.; - return the elements of v1 if the condition c is true and sets the value v2 if the condition c is false.; - return the elements of v2 if the condition c is false and sets the value v1 if the condition c is true.; - return a vector with the value v2 if the condition c is false and sets the value v1 if the condition c is true. ## RooFit Libraries; - Add value printer for RooAbsArg and daughters.; - Add a Python version for the majority of the Tutorials. ## TMVA Library. ### Deep Learning. This release contains several fixes and improvement for the `MethodDL`. The `MethodDL` is also now the recommended class to use for Deep Learning in TMVA and is replacing the previous existing; `MethodDNN`, which is still available, but it has a limited functionality and it supports only dense layer. The new features of `MethodDL` are:. - Support training and evaluation of Convolutional layer on GPU; - Several ML optimizers are now included and they can be used in addition to SGD. These are ADAM (the new default), ADAGRAD,; RMSPROP, ADADELTA. A new option, *Optimizer* has been added in the option string used to define the training strategy options.; - Add support for regression in MethodDL; - Use single precision (float) types as the fundamental type for the neural network architecture. Double precision could be enabled, but it will require recompiling TMVA. ; - Support inference (network evaluation) in batch mode in addition to single event. Batch mode evaluation is now the default when used within the `TMVA::Factory` class (i.e. when calling; `Factory::TestAllMethod()` or `Factory::EvaluateAllMethods()`; - Support splitting the overall training data in Train and Validation data. The train data is used for finding the optimal network weight and the validation data is used to monitor the validation; error. The weights which are giving a minimal validation error will be stored. For the spli",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:13527,optimiz,optimizers,13527,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['optimiz'],['optimizers']
Performance,"n; ============. The constexpr interpreter aims to replace the existing tree evaluator in; clang, improving performance on constructs which are executed inefficiently; by the evaluator. The interpreter is activated using the following flags:. * ``-fexperimental-new-constant-interpreter`` enables the interpreter,; emitting an error if an unsupported feature is encountered. Bytecode Compilation; ====================. Bytecode compilation is handled in ``ByteCodeStmtGen.h`` for statements; and ``ByteCodeExprGen.h`` for expressions. The compiler has two different; backends: one to generate bytecode for functions (``ByteCodeEmitter``) and; one to directly evaluate expressions as they are compiled, without; generating bytecode (``EvalEmitter``). All functions are compiled to; bytecode, while toplevel expressions used in constant contexts are directly; evaluated since the bytecode would never be reused. This mechanism aims to; pave the way towards replacing the evaluator, improving its performance on; functions and loops, while being just as fast on single-use toplevel; expressions. The interpreter relies on stack-based, strongly-typed opcodes. The glue; logic between the code generator, along with the enumeration and; description of opcodes, can be found in ``Opcodes.td``. The opcodes are; implemented as generic template methods in ``Interp.h`` and instantiated; with the relevant primitive types by the interpreter loop or by the; evaluating emitter. Primitive Types; ---------------. * ``PT_{U|S}int{8|16|32|64}``. Signed or unsigned integers of a specific bit width, implemented using; the ```Integral``` type. * ``PT_{U|S}intFP``. Signed or unsigned integers of an arbitrary, but fixed width used to; implement integral types which are required by the target, but are not; supported by the host. Under the hood, they rely on APValue. The; ``Integral`` specialisation for these types is required by opcodes to; share an implementation with fixed integrals. * ``PT_Bool``. Representa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst:1095,perform,performance,1095,interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,1,['perform'],['performance']
Performance,"n; NSString *string2 = NSLocalizedString(@""LocalizedString"", @"" ""); // warn; NSString *string3 = NSLocalizedStringWithDefaultValue(; @""LocalizedString"", nil, [[NSBundle alloc] init], nil,@""""); // warn; }. .. _optin-osx-cocoa-localizability-NonLocalizedStringChecker:. optin.osx.cocoa.localizability.NonLocalizedStringChecker (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warns about uses of non-localized NSStrings passed to UI methods expecting localized NSStrings. .. code-block:: objc. NSString *alarmText =; NSLocalizedString(@""Enabled"", @""Indicates alarm is turned on"");; if (!isEnabled) {; alarmText = @""Disabled"";; }; UILabel *alarmStateLabel = [[UILabel alloc] init];. // Warning: User-facing text should use localized string macro; [alarmStateLabel setText:alarmText];. .. _optin-performance-GCDAntipattern:. optin.performance.GCDAntipattern; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for performance anti-patterns when using Grand Central Dispatch. .. _optin-performance-Padding:. optin.performance.Padding; """"""""""""""""""""""""""""""""""""""""""""""""""; Check for excessively padded structs. .. _optin-portability-UnixAPI:. optin.portability.UnixAPI; """"""""""""""""""""""""""""""""""""""""""""""""""; Finds implementation-defined behavior in UNIX/Posix functions. .. _security-checkers:. security; ^^^^^^^^. Security related checkers. .. _security-cert-env-InvalidPtr:. security.cert.env.InvalidPtr; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Corresponds to SEI CERT Rules `ENV31-C <https://wiki.sei.cmu.edu/confluence/display/c/ENV31-C.+Do+not+rely+on+an+environment+pointer+following+an+operation+that+may+invalidate+it>`_ and `ENV34-C <https://wiki.sei.cmu.edu/confluence/display/c/ENV34-C.+Do+not+store+pointers+returned+by+certain+functions>`_. * **ENV31-C**:; Rule is about the possible problem with ``main`` function's third argument, environment pointer,; ""envp"". When environment array is modified using some modification function; such as ``putenv``, ``setenv`` or others, It may happen that memory is rea",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:19484,perform,performance-Padding,19484,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['perform'],['performance-Padding']
Performance,"n; operation to apply, an address whose value to modify, an argument to the; operation. The operation must be one of the following keywords:. - xchg; - add; - sub; - and; - nand; - or; - xor; - max; - min; - umax; - umin; - fadd; - fsub; - fmax; - fmin; - uinc_wrap; - udec_wrap. For most of these operations, the type of '<value>' must be an integer; type whose bit width is a power of two greater than or equal to eight; and less than or equal to a target-specific size limit. For xchg, this; may also be a floating point or a pointer type with the same size constraints; as integers. For fadd/fsub/fmax/fmin, this must be a floating point type. The; type of the '``<pointer>``' operand must be a pointer to that type. If; the ``atomicrmw`` is marked as ``volatile``, then the optimizer is not; allowed to modify the number or order of execution of this; ``atomicrmw`` with other :ref:`volatile operations <volatile>`. Note: if the alignment is not greater or equal to the size of the `<value>`; type, the atomic operation is likely to require a lock and have poor; performance. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. If unspecified, the alignment is assumed to be equal to the; size of the '<value>' type. Note that this default alignment assumption is; different from the alignment used for the load/store instructions when align; isn't specified. A ``atomicrmw`` instruction can also take an optional; "":ref:`syncscope <syncscope>`"" argument. Semantics:; """""""""""""""""""". The contents of memory at the location specified by the '``<pointer>``'; operand are atomically read, modified, and written back. The original; value at the location is returned. The modification is specified by the; operation argument:. - xchg: ``*ptr = val``; - add: ``*ptr = *ptr + val``; - sub: ``*ptr = *ptr - val``; - and: ``*ptr = *ptr & val``; - nand: ``*ptr = ~(*ptr & val)``; - or: ``*ptr = *ptr | val``; - xor: ``*ptr = *ptr ^ val``; - max: ``*ptr = *ptr > va",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:430485,perform,performance,430485,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performance']
Performance,"n; passed through to the calculation, if applicable. Several examples illustrate how to use this class. See:; `$ROOTSYS/tutorials/hist/ratioplot?.C`. * New option ""I"" allowing to draw TGraph with invisible axis (used by `TRatioPlot`);. ## New histogram drawing options. ### COL2; COL2 is a new rendering technique providing potential performance improvements; compared to the standard COL option. The performance comparison of the COL2 to; the COL option depends on the histogram and the size of the rendering region in; the current pad. In general, a small (approx. less than 100 bins per axis),; sparsely populated TH2 will render faster with the COL option. However, for larger histograms (approx. more than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:22493,perform,performance,22493,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['perform'],['performance']
Performance,"nCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - system *none* 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:314927,load,load,314927,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"nable lvalue. .. _dss_sparsebitvector:. SparseBitVector; ^^^^^^^^^^^^^^^. The SparseBitVector container is much like BitVector, with one major difference:; Only the bits that are set, are stored. This makes the SparseBitVector much; more space efficient than BitVector when the set is sparse, as well as making; set operations O(number of set bits) instead of O(size of universe). The; downside to the SparseBitVector is that setting and testing of random bits is; O(N), and on large SparseBitVectors, this can be slower than BitVector. In our; implementation, setting or testing bits in sorted order (either forwards or; reverse) is O(1) worst case. Testing and setting bits within 128 bits (depends; on size) of the current bit is also O(1). As a general statement,; testing/setting bits in a SparseBitVector is O(distance away from last set bit). .. _dss_coalescingbitvector:. CoalescingBitVector; ^^^^^^^^^^^^^^^^^^^. The CoalescingBitVector container is similar in principle to a SparseBitVector,; but is optimized to represent large contiguous ranges of set bits compactly. It; does this by coalescing contiguous ranges of set bits into intervals. Searching; for a bit in a CoalescingBitVector is O(log(gaps between contiguous ranges)). CoalescingBitVector is a better choice than BitVector when gaps between ranges; of set bits are large. It's a better choice than SparseBitVector when find(); operations must have fast, predictable performance. However, it's not a good; choice for representing sets which have lots of very short ranges. E.g. the set; `{2*x : x \in [0, n)}` would be a pathological input. .. _utility_functions:. Useful Utility Functions; ========================. LLVM implements a number of general utility functions used across the; codebase. You can find the most common ones in ``STLExtras.h``; (`doxygen <https://llvm.org/doxygen/STLExtras_8h.html>`__). Some of these wrap; well-known C++ standard library functions, while others are unique to LLVM. .. _uf_iteration:. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:98920,optimiz,optimized,98920,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['optimiz'],['optimized']
Performance,"nabled with ``-debug-only=InstrSched``, even if the source lives in multiple; files. The name must not include a comma (,) as that is used to separate the; arguments of the ``-debug-only`` option. For performance reasons, -debug-only is not available in optimized build; (``--enable-optimized``) of LLVM. The ``DEBUG_WITH_TYPE`` macro is also available for situations where you would; like to set ``DEBUG_TYPE``, but only for one specific ``DEBUG`` statement. It; takes an additional first parameter, which is the type to use. For example, the; preceding example could be written as:. .. code-block:: c++. DEBUG_WITH_TYPE(""foo"", dbgs() << ""'foo' debug type\n"");; DEBUG_WITH_TYPE(""bar"", dbgs() << ""'bar' debug type\n"");. .. _Statistic:. The ``Statistic`` class & ``-stats`` option; -------------------------------------------. The ``llvm/ADT/Statistic.h`` (`doxygen; <https://llvm.org/doxygen/Statistic_8h_source.html>`__) file provides a class; named ``Statistic`` that is used as a unified way to keep track of what the LLVM; compiler is doing and how effective various optimizations are. It is useful to; see what optimizations are contributing to making a particular program run; faster. Often you may run your pass on some big program, and you're interested to see; how many times it makes a certain transformation. Although you can do this with; hand inspection, or some ad-hoc method, this is a real pain and not very useful; for big programs. Using the ``Statistic`` class makes it very easy to keep; track of this information, and the calculated information is presented in a; uniform manner with the rest of the passes being executed. There are many examples of ``Statistic`` uses, but the basics of using it are as; follows:. Define your statistic like this:. .. code-block:: c++. #define DEBUG_TYPE ""mypassname"" // This goes after any #includes.; STATISTIC(NumXForms, ""The # of times I did stuff"");. The ``STATISTIC`` macro defines a static variable, whose name is specified by; the first a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:46560,optimiz,optimizations,46560,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['optimiz'],['optimizations']
Performance,"nabled(const Module &M)` (from `llvm/IR/DebugInfo.h`). ## Design and implementation. ### Assignment markers: `llvm.dbg.assign`. `llvm.dbg.value`, a conventional debug intrinsic, marks out a position in the; IR where a variable takes a particular value. Similarly, Assignment Tracking; marks out the position of assignments with a new intrinsic called; `llvm.dbg.assign`. In order to know where in IR it is appropriate to use a memory location for a; variable, each assignment marker must in some way refer to the store, if any; (or multiple!), that performs the assignment. That way, the position of the; store and marker can be considered together when making that choice. Another; important benefit of referring to the store is that we can then build a two-way; mapping of stores<->markers that can be used to find markers that need to be; updated when stores are modified. An `llvm.dbg.assign` marker that is not linked to any instruction signals that; the store that performed the assignment has been optimised out, and therefore; the memory location will not be valid for at least some part of the program. Here's the `llvm.dbg.assign` signature. Each parameter is wrapped in; `MetadataAsValue`, and `Value *` type parameters are first wrapped in; `ValueAsMetadata`:. ```; void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression); ```. The first three parameters look and behave like an `llvm.dbg.value`. `ID` is a; reference to a store (see next section). `Address` is the destination address; of the store and it is modified by `AddressExpression`. An empty/undef/poison; address means the address component has been killed (the memory address is no; longer a valid location). LLVM currently encodes variable fragment information; in `DIExpression`s, so as an implementation quirk the `FragmentInfo` for; `Variable` is contained within `ValueExpression` only. The formal LLVM-IR signatu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:2588,perform,performed,2588,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md,1,['perform'],['performed']
Performance,"naged languages. While; the exact semantics of an operand bundle depend on the bundle tag,; there are certain limitations to how much the presence of an operand; bundle can influence the semantics of a program. These restrictions; are described as the semantics of an ""unknown"" operand bundle. As; long as the behavior of an operand bundle is describable within these; restrictions, LLVM does not need to have special knowledge of the; operand bundle to not miscompile programs containing it. - The bundle operands for an unknown operand bundle escape in unknown; ways before control is transferred to the callee or invokee.; - Calls and invokes with operand bundles have unknown read / write; effect on the heap on entry and exit (even if the call target specifies; a ``memory`` attribute), unless they're overridden with; callsite specific attributes.; - An operand bundle at a call site cannot change the implementation; of the called function. Inter-procedural optimizations work as; usual as long as they take into account the first two properties. More specific types of operand bundles are described below. .. _deopt_opbundles:. Deoptimization Operand Bundles; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Deoptimization operand bundles are characterized by the ``""deopt""``; operand bundle tag. These operand bundles represent an alternate; ""safe"" continuation for the call site they're attached to, and can be; used by a suitable runtime to deoptimize the compiled frame at the; specified call site. There can be at most one ``""deopt""`` operand; bundle attached to a call site. Exact details of deoptimization is; out of scope for the language reference, but it usually involves; rewriting a compiled frame into a set of interpreted frames. From the compiler's perspective, deoptimization operand bundles make; the call sites they're attached to at least ``readonly``. They read; through all of their pointer typed operands (even if they're not; otherwise escaped) and the entire visible heap. Deoptimizat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:118745,optimiz,optimizations,118745,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"nal for vectors with a boolean element type and; not implemented otherwise. Vector Builtins; ---------------. **Note: The implementation of vector builtins is work-in-progress and incomplete.**. In addition to the operators mentioned above, Clang provides a set of builtins; to perform additional operations on certain scalar and vector types. Let ``T`` be one of the following types:. * an integer type (as in C23 6.2.5p22), but excluding enumerated types and ``bool``; * the standard floating types float or double; * a half-precision floating point type, if one is supported on the target; * a vector type. For scalar types, consider the operation applied to a vector with a single element. *Vector Size*; To determine the number of elements in a vector, use ``__builtin_vectorelements()``.; For fixed-sized vectors, e.g., defined via ``__attribute__((vector_size(N)))`` or ARM; NEON's vector types (e.g., ``uint16x8_t``), this returns the constant number of; elements at compile-time. For scalable vectors, e.g., SVE or RISC-V V, the number of; elements is not known at compile-time and is determined at runtime. This builtin can; be used, e.g., to increment the loop-counter in vector-type agnostic loops. *Elementwise Builtins*. Each builtin returns a vector equivalent to applying the specified operation; elementwise to the input. Unless specified otherwise operation(0) = 0 and operation(infinity) = infinity. =========================================== ================================================================ =========================================; Name Operation Supported element types; =========================================== ================================================================ =========================================; T __builtin_elementwise_abs(T x) return the absolute value of a number x; the absolute value of signed integer and floating point types; the most negative integer remains the most negative integer; T __builtin_elementwise_fma(T x, T y",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:21630,scalab,scalable,21630,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['scalab'],['scalable']
Performance,"name, value, uncertainty. Once; all parameters are added to MnUserParameters, they can fix a parameter or; put limits on another one before handing them over to Minuit for; minimization. ### What the user can supply ###. Optionally the user can supply their own gradient calculator by; implementing the FCNGradientBase interface or supply a full covariance; matrix for input if one is available. The covariance matrix can be; supplied in form of a std::vector$<$double$>$ in packed storage format; (upper triangular), or in a more user-friendly way by using the; interface provided by the MnUserCovariance. ## Running a M minimization ##. Two use cases are addressed for minimization:. - The user just wants the function to be minimized in one go. - The user wants to minimize the $\mbox{FCN}$ in several; minimization steps, re-using the result of the preceeding; minimization in the next step and change parameters in between; (fix/release/put limits on them, etc.). How M minimizations can be performed is shown in [example:main]. ### Direct usage of minimizers ###. Minimizers such as the VariableMetricMinimizer are designed as; state-less minimization engines, which means that they do not depend on; the current function and its parameters. Any $\mbox{FCN}$ function; can be minimized with the same minimizer. The interface is restricted to; minimization and no parameter interaction is possible. ### Using an application (MnMigrad) ###. MnMigrad uses the VariableMetricMinimizer for minimization but allows as; well for parameter interaction by the user. An instance of MnMigrad is; specific to the current $\mbox{FCN}$ and user parameters. Any; parameter interaction of the user between two minimization steps will; make use of the result of the preceeding minimization in an optimal way.; The interface for parameters (see [api:parameters], [api:covariance] and; [api:state]) is forwardedin MnMigrad. ### Subsequent minimizations ###. M takes care that all information is treated in an optim",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:33830,perform,performed,33830,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['perform'],['performed']
Performance,"name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] Total number of buffer entries. [1] [2] [3] [4]; JALU01 0 0 20; JFPU01 17 18 18; JLSAGU 0 0 12. Retire Control Unit - number of cycles where we saw N instructions retired:; [# retired], [# cycles]; 0, 109 (17.9%); 1, 102 (16.7%); 2, 399 (65.4%). Total ROB Entries: 64; Max Used ROB Entries: 35 ( 54.7% ); Average Used ROB Entries per cy: 32 ( 50.0% ). Register File statistics:; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #1 -- JFpuPRF:; Number of physical registers: 72; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #2 -- JIntegerPRF:; Number of physical registers: 64; Total number of mappings created: 0; Max number of mappings used: 0. If we look at the *Dynamic Dispatch Stall Cycles* table, we see the counter for; SCHEDQ reports 272 cycles. This counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:30643,queue,queue,30643,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['queue'],['queue']
Performance,"ncat(%vec1, %vec2)`` starting at index ``imm``, whereas for a negative; immediate, it extracts ``-imm`` trailing elements from the first vector, and; the remaining elements from ``%vec2``. These intrinsics work for both fixed and scalable vectors. While this intrinsic; is marked as experimental, the recommended way to express this operation for; fixed-width vectors is still to use a shufflevector, as that may allow for more; optimization opportunities. For example:. .. code-block:: text. llvm.experimental.vector.splice(<A,B,C,D>, <E,F,G,H>, 1); ==> <B, C, D, E> index; llvm.experimental.vector.splice(<A,B,C,D>, <E,F,G,H>, -3); ==> <B, C, D, E> trailing elements. Arguments:; """""""""""""""""""". The first two operands are vectors with the same type. The start index is imm; modulo the runtime number of elements in the source vector. For a fixed-width; vector <N x eltty>, imm is a signed integer constant in the range; -N <= imm < N. For a scalable vector <vscale x N x eltty>, imm is a signed; integer constant in the range -X <= imm < X where X=vscale_range_min * N. '``llvm.experimental.stepvector``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This is an overloaded intrinsic. You can use ``llvm.experimental.stepvector``; to generate a vector whose lane values comprise the linear sequence; <0, 1, 2, ...>. It is primarily intended for scalable vectors. ::. declare <vscale x 4 x i32> @llvm.experimental.stepvector.nxv4i32(); declare <vscale x 8 x i16> @llvm.experimental.stepvector.nxv8i16(). The '``llvm.experimental.stepvector``' intrinsics are used to create vectors; of integers whose elements contain a linear sequence of values starting from 0; with a step of 1. This experimental intrinsic can only be used for vectors; with integer elements that are at least 8 bits in size. If the sequence value; exceeds the allowed limit for the element type then the result for that lane is; undefined. These intrinsics work for both fixed and scalable vectors. While this intrinsic; is ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:672207,scalab,scalable,672207,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance,"nce critical part is converted; into C/C++ in an extension module. The school of thought where; pre-mature optimization is the root of all evil should find this way of; working very satisfying. In addition, if you look at their history, you; will see that many of the standard Python modules have followed this; path. Your code should always make maximum use of ROOT facilities; such that; most of the time is spending in compiled code. This goes even for very; simple things: e.g. do not compute invariant masses in Python, use; **`TLorentzVector`** instead. Moreover, before you start optimizing,; make sure that you have run a profiler to find out where the bottlenecks; are. Some performance, without cost in terms of programmer effort, may; be gained by using `psyco`, see the next link:; <http://psyco.sourceforge.net>, a Python just in time compiler (JIT).; Note, however, that `psyco` is limited to Intel i386 CPUs. Since `psyco`; optimizes Python, not `PyROOT` calls; it generally does not improve; performance that much if most of your code consists of ROOT API calls.; Mathematical computations in Python, on the other hand, benefit a lot. Every call to a Python member function results in a lookup of that; member function and an association of this method with `'self'`.; Furthermore, a temporary object is created during this process that is; discarded after the method call. In inner loops, it may be worth your; while (up to 30%), to short-cut this process by looking up and binding; the method before the loop, and discarding it afterwards. Here is an; example:. ``` {.cpp}; hpx = TH1F('hpx','px',100,-4,4); hpxFill = hpx.Fill # cache bound method; for i in xrange(25000):; px = gRandom.Gaus(); hpxFill(px) # use bound method: no lookup needed; del hpxFill # done with cached method; ```. Note that if you do not discard the bound method, a reference to the; histogram will remain outstanding, and it will not be deleted when it; should be. It is therefore important to delete the met",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:23808,optimiz,optimizes,23808,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,2,"['optimiz', 'perform']","['optimizes', 'performance']"
Performance,"nce manual for the MIR serialization format, which is used to test; LLVM's code generation passes. :doc:`GlobalISel/index`; This describes the prototype instruction selection replacement, GlobalISel. :doc:`ConvergentOperations`; Description of ``convergent`` operation semantics and related intrinsics. =====================; Testing and Debugging; =====================. :doc:`LLVM Testing Infrastructure Guide <TestingGuide>`; A reference manual for using the LLVM testing infrastructure. :doc:`TestSuiteGuide`; Describes how to compile and run the test-suite benchmarks. :doc:`GwpAsan`; A sampled heap memory error detection toolkit designed for production use. ====; XRay; ====. :doc:`XRay`; High-level documentation of how to use XRay in LLVM. :doc:`XRayExample`; An example of how to debug an application with XRay. =================; Additional Topics; =================. :doc:`FaultMaps`; LLVM support for folding control flow into faulting machine instructions. :doc:`Atomics`; Information about LLVM's concurrency model. :doc:`ExceptionHandling`; This document describes the design and implementation of exception handling; in LLVM. :doc:`Extensions`; LLVM-specific extensions to tools and formats LLVM seeks compatibility with. :doc:`HowToSetUpLLVMStyleRTTI`; How to make ``isa<>``, ``dyn_cast<>``, etc. available for clients of your; class hierarchy. :doc:`BlockFrequencyTerminology`; Provides information about terminology used in the ``BlockFrequencyInfo``; analysis pass. :doc:`BranchWeightMetadata`; Provides information about Branch Prediction Information. :doc:`GetElementPtr`; Answers to some very frequent questions about LLVM's most frequently; misunderstood instruction. :doc:`ScudoHardenedAllocator`; A library that implements a security-hardened `malloc()`. :doc:`MemTagSanitizer`; Security hardening for production code aiming to mitigate memory; related vulnerabilities. Based on the Armv8.5-A Memory Tagging Extension. :doc:`Dependence Graphs <DependenceGraphs/index>`; A d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Reference.rst:3605,concurren,concurrency,3605,interpreter/llvm-project/llvm/docs/Reference.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Reference.rst,1,['concurren'],['concurrency']
Performance,"nce of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Other useful patterns may be to fold the load i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22726,load,loaded,22726,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loaded']
Performance,"nce that can be dumped to a file using ``--dump-object-to-disk``.; * ``measure``: Same as ``assemble-measured-code``, but also runs the measurement. .. option:: --x86-lbr-sample-period=<nBranches/sample>. Specify the LBR sampling period - how many branches before we take a sample.; When a positive value is specified for this option and when the mode is `latency`,; we will use LBRs for measuring.; On choosing the ""right"" sampling period, a small value is preferred, but throttling; could occur if the sampling is too frequent. A prime number should be used to; avoid consistently skipping certain blocks. .. option:: --x86-disable-upper-sse-registers. Using the upper xmm registers (xmm8-xmm15) forces a longer instruction encoding; which may put greater pressure on the frontend fetch and decode stages,; potentially reducing the rate that instructions are dispatched to the backend,; particularly on older hardware. Comparing baseline results with this mode; enabled can help determine the effects of the frontend and can be used to; improve latency and throughput estimates. .. option:: --repetition-mode=[duplicate|loop|min]. Specify the repetition mode. `duplicate` will create a large, straight line; basic block with `num-repetitions` instructions (repeating the snippet; `num-repetitions`/`snippet size` times). `loop` will, optionally, duplicate the; snippet until the loop body contains at least `loop-body-size` instructions,; and then wrap the result in a loop which will execute `num-repetitions`; instructions (thus, again, repeating the snippet; `num-repetitions`/`snippet size` times). The `loop` mode, especially with loop; unrolling tends to better hide the effects of the CPU frontend on architectures; that cache decoded instructions, but consumes a register for counting; iterations. If performing an analysis over many opcodes, it may be best to; instead use the `min` mode, which will run each other mode,; and produce the minimal measured result. .. option:: --num-repetiti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:12234,latency,latency,12234,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,2,"['latency', 'throughput']","['latency', 'throughput']"
Performance,"nce-paired-atomic); has completed; before invalidating; the caches. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-val",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:373837,load,load,373837,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"nce. We introduced an optimized infrastructure for reading objects using a StreamerInfo. Rather than driving the streaming using a switch statement inside TStreamerInfo::ReadBuffer,; the streaming is now driven using a simple loop over a sequence of configured StreamerInfo actions. This improves run-time performance by allowing a dramatic reduction in function calls and code; branches at the expense of some code duplication. There are 3 versions of this loop implemented in TBufferFile and overloaded in TBufferXML and TBufferSQL:. virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence, void *object);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);. The 1st version is optimized to read a single object. The 2nd version is optimized to read the content of TClonesArrays and vectors of pointers to objects. The 3rd version is used to streamed any collections. TBufferXML and TBufferSQL overload the loops to introduce extra code to help the buffer keep track of which streamer element is being streamed (this functionality is not used by TBufferFile.). A TStreamerInfoActions::TActionSequence is an ordered sequence of configured actions. A configured action has both an action which is a free standing function and a configuration object deriving; from TStreamerInfoActions::TConfiguration. The configuration contains information that is specific to the action; but varies from use to use, including the offset from the beginning of the object that needs to be updated.; Other examples of configuration include the number of bits requested for storing a Double32_t or its factor and minimum. When the sequence is intended for a collection, the sequence has a configuration object deriving; from TStreamerInfoActions::TLoopConfiguration which contains for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:3802,optimiz,optimized,3802,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,2,['optimiz'],['optimized']
Performance,"nces C++ by allowing the following code to work without; explicitly requiring to `#include <A.h>`. Currently, ROOT's lack of support of; line `#5` is a long-standing, known limitation that is lifted with modules. ```cpp; // ROOT prompt; root [] AStruct<float> S0; // #1: implicit loading of libA. Full descriptor required.; root [] AStruct<float>* S1; // #2: implicit loading of libA. No full descriptor required.; root [] if (gFile) S1->doIt(); // #3: implicit loading of libA. Full descriptor required.; root [] gSystem->Load(""libA""); // #4: explicit loading of libA. No full descriptor required.; root [] do(); // #5: error: implicit loading of libA is currently unsupported. ```. This pattern is not only used in the ROOT prompt but in I/O hotspots such as; `ShowMembers` and `TClass::IsA`. A naive implementation of this feature would require inclusion of all reachable; library descriptors (aka header files) at ROOT startup time. Of course this is; not feasible and ROOT inserts a set of optimizations to fence itself from the; costly full header inclusion. Unfortunately, several of them are home-grown and; in a few cases inaccurate (eg line #5) causing a noticeable technical debt. Here we will briefly describe the three common layers of optimizations: ROOT PCH,; ROOTMAP and RDICT. The ROOT precompiled header (PCH) reduces the CPU and memory cost for ROOT's; most used libraries. The precompiled header technology is well-understood since; decades [[4]]. It is an efficient on-disk representation of the state of the; compiler after parsing a set of headers. It can be loaded before starting the; next instance to avoid doing redundant work. At build time, rootcling (ROOT's; dictionary generator) creates such PCH file which is attached at ROOT startup; time. Its major drawback is the fact that if third-party users want to include; their libraries, they have to recompile it every time there is a change. RDICT files store some useful information (in particular about class offsets) i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:5569,optimiz,optimizations,5569,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['optimiz'],['optimizations']
Performance,"nces an histogram filled with weights will always draw the errors by default. If one desire to continue having the histogram drawn; without the errors, one should use the `hist` option: `h.Draw(""hist"")`.; If, for memory reason, one does not want to remove the internal array storing the bin errors (the bin sum of weight square), one can use the function `TH1::Sumw2(false)`. - The copy constructor is not anymore public for TH1. Before (in 5.34) this code was allowed by the compiler, although giving undefined behavior: now not anymore:. ``` {.cpp}; TH1D h1;; TH1 h2(h1);; ```; Now this code is not allowed anymore. It will give a compilation error.; The copy constructor of the derived classes (`TH1D` in this example) should instead be used.; This applies also for `TH2` and `TH3`.; In case you want to copy histograms using the TH1 interface, you can use either `TObject::Clone`, which uses the I/O system and can be unconvenient in some cases (e.g. in a multi-threaded; environment) or `TH1::Copy` which is public since some of the latest 5.34 revisions together with `TClass::New` as following:. ``` {.cpp}; TH1 * h2 = (TH1*) h1->IsA()->New();; h1->Copy(*h2);; ```; Note that `TH1::Copy` does not copy the attached list of functions, while `TH1::Clone()` does a deep copy also of the contained functions. - Add new method `TH1::GetNCells` to retrieve the total number of bins of an histogram including underflow and overflows. This is the product of all the bins in each dimension. - The methods `GetCellContent`, `GetCellError` and `SetCellContent` and `SetCellError` have been deprecated. Get/SetBinContent and Get/SetBinError should be instead used and they have exactly the; same functionality. - The following code should produce a plot. It did not. ``` {.cpp}; TH1F* h=new TH1F(""hist"", ""histogram"", 10, 0, 3);; h->FillRandom(""gaus"");; h->Draw(""same"");; ```; - Make sure histograms having quotes in title are properly saved in .C files. ### TH2, TH3. - Add new functions `TH2::QuantilesX` ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md:9101,multi-thread,multi-threaded,9101,hist/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v600/index.md,1,['multi-thread'],['multi-threaded']
Performance,"nclude <math.h>; int t1(double d) { return signbit(d); }. This currently compiles to:; 	subl	$12, %esp; 	movsd	16(%esp), %xmm0; 	movsd	%xmm0, (%esp); 	movl	4(%esp), %eax; 	shrl	$31, %eax; 	addl	$12, %esp; 	ret. We should use movmskp{s|d} instead. //===---------------------------------------------------------------------===//. CodeGen/X86/vec_align.ll tests whether we can turn 4 scalar loads into a single; (aligned) vector load. This functionality has a couple of problems. 1. The code to infer alignment from loads of globals is in the X86 backend,; not the dag combiner. This is because dagcombine2 needs to be able to see; through the X86ISD::Wrapper node, which DAGCombine can't really do.; 2. The code for turning 4 x load into a single vector load is target ; independent and should be moved to the dag combiner.; 3. The code for turning 4 x load into a vector load can only handle a direct ; load from a global or a direct load from the stack. It should be generalized; to handle any load from P, P+4, P+8, P+12, where P can be anything.; 4. The alignment inference code cannot handle loads from globals in non-static; mode because it doesn't look through the extra dyld stub load. If you try; vec_align.ll without -relocation-model=static, you'll see what I mean. //===---------------------------------------------------------------------===//. We should lower store(fneg(load p), q) into an integer load+xor+store, which; eliminates a constant pool load. For example, consider:. define i64 @ccosf(float %z.0, float %z.1) nounwind readonly {; entry:; %tmp6 = fsub float -0.000000e+00, %z.1		; <float> [#uses=1]; %tmp20 = tail call i64 @ccoshf( float %tmp6, float %z.0 ) nounwind readonly; ret i64 %tmp20; }; declare i64 @ccoshf(float %z.0, float %z.1) nounwind readonly. This currently compiles to:. LCPI1_0:					# <4 x float>; 	.long	2147483648	# float -0; 	.long	2147483648	# float -0; 	.long	2147483648	# float -0; 	.long	2147483648	# float -0; _ccosf:; 	subl	$12, %esp; 	movss	16(%esp)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:12049,load,load,12049,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,2,['load'],['load']
Performance,"nctionality out into the `ConstantTermsOptimizer` class.; In fact, it is not so much a class, as it is a collection of static functions that can be applied to any combination of pdf and dataset.; This class does essentially the same as `constOptimizeTestStatistic` did on a `RooNLLVar`, except that it has been factored out into a separate class. ### Usage example: apply constant term optimization on pdf and dataset inside a likelihood; Applying the default `ConstantTermsOptimizer` optimization routines on the pdf and dataset inside a `RooAbsL` likelihood is as simple as:. ``` {.cpp}; likelihood.constOptimizeTestStatistic();; ```; This applies constant term optimization to the cloned pdf and dataset inside the likelihood object.; It will not modify anything outside of the likelihood. Optimization can also be activated through the minimizer, which may be more familiar to most users.; Given the `RooMinimizer` object `m` as defined in the example above, we can do:; ``` {.cpp}; m.optimizeConst(2);; ```. For the adventurous user, it is also possible to apply constant term optimization to a pdf and dataset directly without needing a likelihood object, e.g. given some `RooArgSet` set of observables `normSet`:; ``` {.cpp}; bool applyTrackingOpt = true;; ConstantTermsOptimizer::enableConstantTermsOptimization(&pdf, &normSet, dataset, applyTrackingOpt);; ```; We refer to RooFit documentation for more about ""tracking optimization"" which can be enabled or disabled using the final boolean parameter. ## Caveats; This package is still under development.; Some functionality that users of `RooAbsPdf::fitTo` or `RooAbsPdf::createNLL` were used to has not yet been ported to this namespace.; However, the functionality that is implemented has been tested thoroughly for a set of common usage patterns and should work as expected. The classes implemented here will give the exact same numerical results for most fits.; One notable exception is fitting _simultaneous_ pdfs with a _constrained_ te",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md:10923,optimiz,optimizeConst,10923,roofit/doc/developers/test_statistics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md,1,['optimiz'],['optimizeConst']
Performance,nctions CPU; ROOT_EXECUTABLE(testLossFunctionsCpu TestLossFunctionsCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-Loss-Functions-Cpu COMMAND testLossFunctionsCpu). # DNN - Derivatives CPU; ROOT_EXECUTABLE(testDerivativesCpu TestDerivativesCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-Derivatives-Cpu COMMAND testDerivativesCpu). # DNN - Backpropagation CPU; ROOT_EXECUTABLE(testBackpropagationCpu TestBackpropagationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-Backpropagation-Cpu COMMAND testBackpropagationCpu). # DNN - BackpropagationDL CPU; ROOT_EXECUTABLE(testBackpropagationDLCpu TestBackpropagationDLCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-Backpropagation-DL-Cpu COMMAND testBackpropagationDLCpu). # DNN - Batch normalization; ROOT_EXECUTABLE(testBatchNormalizationCpu TestBatchNormalizationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-BatchNormalization-Cpu COMMAND testBatchNormalizationCpu). # DNN - Optimization CPU; ROOT_EXECUTABLE(testOptimizationCpu TestOptimizationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-Optimization-Cpu COMMAND testOptimizationCpu). # DNN - MethodDL SGD Optimization CPU; ROOT_EXECUTABLE(testMethodDLSGDOptimizationCpu TestMethodDLSGDOptimizationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-MethodDL-SGD-Optimization-Cpu COMMAND testMethodDLSGDOptimizationCpu). # DNN - MethodDL Adam Optimization CPU; ROOT_EXECUTABLE(testMethodDLAdamOptimizationCpu TestMethodDLAdamOptimizationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-MethodDL-Adam-Optimization-Cpu COMMAND testMethodDLAdamOptimizationCpu TIMEOUT 1800). # DNN - MethodDL Adagrad Optimization CPU; ROOT_EXECUTABLE(testMethodDLAdagradOptimizationCpu TestMethodDLAdagradOptimizationCpu.cxx LIBRARIES ${Libraries}); ROOT_ADD_TEST(TMVA-DNN-MethodDL-Adagrad-Optimization-Cpu COMMAND testMethodDLAdagradOptimizationCpu). # DNN - MethodDL RMSProp Optimization CPU; ROOT_EXECUTABLE(testMethodDLRMSPropOptimizationCpu TestMeth,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/DNN/CMakeLists.txt:5375,Optimiz,Optimization,5375,tmva/tmva/test/DNN/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/tmva/test/DNN/CMakeLists.txt,1,['Optimiz'],['Optimization']
Performance,"ncy; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %xmm3; |; | < loop carried >; |; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]. According to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26843,bottleneck,bottleneck-analysis,26843,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['bottleneck'],['bottleneck-analysis']
Performance,"nd classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many variables.; Bug fix in GaussTransformation which improves handling of gaussian tails. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:4022,perform,performance,4022,tmva/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html,2,['perform'],['performance']
Performance,"nd copy in the internal array; FitResult: the class now stores a map of the Minos error using as key the parameter index. If the Minos error has not been calculated for the parameter, FitResult::LowerError(i) and FitResult::UpperError(i) returns the parabolic error; ; Add a new class, MinimTransformFunction to perform a transformation of the function object to deal with limited and fixed variables.; This class uses the same transformation which are also used inside Minuit, a sin transformation for double bounded variables and a sqrt transformation for single bound variable defined in the class MinimizerVariableTransformation.; These classes can be used by minimizer which do not support internally the bounds (like the GSL minimizers).; . Add two new method in ROOT::Math::Minimizer class:; ; int Minimizer::CovMatrixStatus() : returning the status of the covariance matrix. Implemented by Minuit and Minuit2 and follows original Minuit code meaning: code = 0 (not calculated), 1 (approximated), 2 (matrix was made pos def) , 3 (accurate); ; bool Hesse(): to perform a full calculation of the Hessian matrix; . TMath. Fix a numerical problem in TMath::ErfcInverse for small input values. Now the normal quantile function is used for implementing it.; . MathMore. Fix 2 bugs in the quartic equation solver (see issue #49031).; ; A protection has been added against numerical errors which could cause NaN due to wrong inputs to an acos function. This problem appears also in the GSL cubic solver. A new GSL patched cubic function has been then added in MathMore.; ; A wrong statement (coming from the original CERNLIB code but not applicable in this case) has been removed.; . Add support for limited and fixed variables for all the GSL minimizers (""GSLMultiMin""), including the simulated annealing (""GSLSimAn"") and the non-linear least square fit methods (""GSLMultiFit"").; . SMatrix. Remove an unneeded check on the element value in the factorization routines used for inverting the matrices (",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html:2420,perform,perform,2420,math/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html,2,['perform'],['perform']
Performance,"nd flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the developers mailing list. Trace Analysis Tools; --------------------. We currently have the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:10225,queue,queue,10225,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['queue'],['queue']
Performance,"nd global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw-with-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; atomicrmw-no-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_gl0_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw-with-return-value; with an equal or; wider sync scope; and memory ordering; st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:352722,cache,cache,352722,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"nd global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:218075,load,load,218075,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"nd graph types have been added in the histogram library (libHist) and graph library:; ; ROOT::Fit::FillData( BinData & , const TH1 *, TF1 * ) for histograms (in libHist); ROOT::Fit::FillData( BinData & , const TGraph2D *, TF1 * ) for 2D graphs (in libHist); ROOT::Fit::FillData( BinData & , const TGraph *, TF1 * ) for all 1D graphs (in libGraf); ROOT::Fit::FillData( BinData & , const TMultiGraph *, TF1 * ) for multi-graphs (in libGraf); . MathCore Numerical Algorithms. Classes implementing numerical methods which can be used by all the other ROOT library have been added in MathCore. These originate mainly from methods present previously in the implementation of the TF1 class. Now they can be used also outside this class. In addition, in order to have a common entry point, interfaces classes for these numerical algorithms have been; included.; These interfaces are as well implemented by classes using the GSL library and located in the MathMore library. The library can be loaded automatically using the ROOT plug-in manager.; In detail, the new classes containing implementations present previously in TF1 are:. ; GaussIntegrator and GaussLegendreIntegrator for numerical integration of one-dimensional functions. The first class uses Gaussian 8 and 16 point quadrature approximation, it provides the translation of the CERNLIB algorithm; DGAUSS by Sigfried Kolbig, and it is used by the TF1::Integral method. The second one uses the Gauss Legendre quadrature formula. It is used by the TF1::IntegralFast method.; These classes implement both the same virtual interface as the adaptive integration methods provided by the MathMore library. They can all be created and used easily via the common class ROOT::Math::IntegratorOneDim providing the interfaces for numerical integration.; New template methods have been also included in the common Integration class in order to be able to integrate automatically any C++ callable object. ROOT::Math::RichardsonDerivator implementing numerical d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html:6503,load,loaded,6503,math/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v520/index.html,2,['load'],['loaded']
Performance,"nd handled like any other bound C++; object (or with ``Exception`` on the Python and ``std::exception`` on the; C++ side).; If the exception is not copyable, but derived from ``std::exception``, the; result of its ``what()`` reported with an instance of Python's ``Exception``.; In all other cases, including exceptions thrown from interpreted code (due to; limitations of the Clang JIT), the exception will turn into an instance of; ``Exception`` with a generic message. The standard C++ exceptions are explicitly not mapped onto standard Python; exceptions, since other than a few simple cases, the mapping is too crude to; be useful as the typical usage in each standard library is too different.; Thus, for example, a thrown ``std::runtime_error`` instance will become a; ``cppyy.gbl.std.runtime_error`` instance on the Python side (with Python's; ``Exception`` as its base class), not a ``RuntimeError`` instance. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. In addition, the examples require the ``throw`` to be in compiled code.; Save the following and build it into a shared library ``libfeatures.so`` (or; ``libfeatures.dll`` on MS Windows):. .. code-block:: C++. #include ""features.h"". void throw_an_error(int i) {; if (i) throw SomeError{""this is an error""};; throw SomeOtherError{""this is another error""};; }. And load the resulting library:. .. code-block:: python. >>> cppyy.load_library('libfeatures'); >>>. Then try it out:. .. code-block:: python. >>> cppyy.gbl.throw_an_error(1); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.SomeError: void ::throw_an_error(int i) =>; SomeError: this is an error; >>> . Note how the full type is preserved and how the result of ``what()`` is us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst:1834,load,loaded,1834,bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,1,['load'],['loaded']
Performance,"nd involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; WGP. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations.; Completion of load/store/sample operations are reported to a wavefront in; execution order of other load/store/sample operations performed by that; wavefront.; * The vector memory operations access a vector L0 cache. There is a single L0; cache per CU. Each SIMD of a CU accesses the same L0 cache. Therefore, no; special action is required for coherence between the lanes of a single; wavefront. However, a ``buffer_gl0_inv`` is required for coherence between; wavefronts executing in the same work-group as they may be executing on SIMDs; of different CUs that access different L0s. A ``buffer_gl0_inv`` is also; required for coherence between wavefronts executing in different work-groups; as they may be executing on different WGPs.; * The scalar memory operations access a scalar L0 cache shared by all wavefronts; on a WGP. The scalar and vector L0 caches are not coherent. However, scalar; operations are used in a restricted way so do not impact the memory model. See; :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory L0 caches use an L1 cache shared by all WGPs on; the same SA. Therefore, no special action is required for coherence between; the wavefronts of a single work-group. However, a ``buffer_gl1_inv`` is; required for coherence between ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:336877,cache,cache,336877,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"nd is also; executed after the contents of `/etc/shadow` is printed.; `Input: /etc/shadow ; ls /`. The analysis implemented in this checker points out this problem. One can protect against such attack by for example checking if the provided; input refers to a valid file and removing any invalid user input. .. code-block:: c. // No vulnerability anymore, but we still get the warning; void sanitizeFileName(char* filename){; if (access(filename,F_OK)){// Verifying user input; printf(""File does not exist\n"");; filename[0]='\0';; }; }; int main(int argc, char** argv) {; char cmd[2048] = ""/bin/cat "";; char filename[1024];; printf(""Filename:"");; scanf ("" %1023[^\n]"", filename); // The attacker can inject a shell escape here; sanitizeFileName(filename);// filename is safe after this point; if (!filename[0]); return -1;; strcat(cmd, filename);; system(cmd); // Superfluous Warning: Untrusted data is passed to a system call; }. Unfortunately, the checker cannot discover automatically that the programmer; have performed data sanitation, so it still emits the warning. One can get rid of this superfluous warning by telling by specifying the; sanitation functions in the taint configuration file (see; :doc:`user-docs/TaintAnalysisConfiguration`). .. code-block:: YAML. Filters:; - Name: sanitizeFileName; Args: [0]. The clang invocation to pass the configuration file location:. .. code-block:: bash. clang --analyze -Xclang -analyzer-config -Xclang alpha.security.taint.TaintPropagation:Config=`pwd`/taint_config.yml ... If you are validating your inputs instead of sanitizing them, or don't want to; mention each sanitizing function in our configuration,; you can use a more generic approach. Introduce a generic no-op `csa_mark_sanitized(..)` function to; tell the Clang Static Analyzer; that the variable is safe to be used on that analysis path. .. code-block:: c. // Marking sanitized variables safe.; // No vulnerability anymore, no warning. // User csa_mark_sanitize function is for the an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:68084,perform,performed,68084,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['perform'],['performed']
Performance,"nd it can be accompanied by a :ref:`section <remarkssection>`; in the object files to easily retrieve it. :doc:`llc <CommandGuide/llc>` and :doc:`opt <CommandGuide/opt>` support the; following options:. ``Basic options``. .. option:: -pass-remarks-output=<filename>. Enables the serialization of remarks to a file specified in <filename>. By default, the output is serialized to :ref:`YAML <yamlremarks>`. .. option:: -pass-remarks-format=<format>. Specifies the output format of the serialized remarks. Supported formats:. * :ref:`yaml <yamlremarks>` (default); * :ref:`yaml-strtab <yamlstrtabremarks>`; * :ref:`bitstream <bitstreamremarks>`. ``Content configuration``. .. option:: -pass-remarks-filter=<regex>. Only passes whose name match the given (POSIX) regular expression will be; serialized to the final output. .. option:: -pass-remarks-with-hotness. With PGO, include profile count in optimization remarks. .. option:: -pass-remarks-hotness-threshold. The minimum profile count required for an optimization remark to be; emitted. Other tools that support remarks:. :program:`llvm-lto`. .. option:: -lto-pass-remarks-output=<filename>; .. option:: -lto-pass-remarks-filter=<regex>; .. option:: -lto-pass-remarks-format=<format>; .. option:: -lto-pass-remarks-with-hotness; .. option:: -lto-pass-remarks-hotness-threshold. :program:`gold-plugin` and :program:`lld`. .. option:: -opt-remarks-filename=<filename>; .. option:: -opt-remarks-filter=<regex>; .. option:: -opt-remarks-format=<format>; .. option:: -opt-remarks-with-hotness. Serialization modes; ===================. There are two modes available for serializing remarks:. ``Separate``. In this mode, the remarks and the metadata are serialized separately. The; client is responsible for parsing the metadata first, then use the metadata; to correctly parse the remarks. ``Standalone``. In this mode, the remarks and the metadata are serialized to the same; stream. The metadata will always come before the remarks. The compiler does",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst:3308,optimiz,optimization,3308,interpreter/llvm-project/llvm/docs/Remarks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst,1,['optimiz'],['optimization']
Performance,"nd it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encoding` is specified. Below is an example of `-show-encoding` output for the dot-product kernel:. .. code-block:: none. Instruction Info:; [1]: #uOps; [2]: Latency; [3]: RThroughput; [4]: MayLoad; [5]: MayStore; [6]: HasSideEffects (U); [7]: Encoding Size. [1] [2] [3] [4] [5] [6] [7] Encodings: Instructions:; 1 2 1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18590,latency,latency,18590,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['latency', 'throughput']","['latency', 'throughput']"
Performance,"nd location of; external definitions in the source files in format `<USR-Length>:<USR> <File-Path>`:. .. code-block:: bash. $ clang-extdef-mapping -p . foo.cpp; 9:c:@F@foo# /path/to/your/project/foo.cpp; $ clang-extdef-mapping -p . foo.cpp > externalDefMap.txt. Now everything is available for the CTU analysis.; We have to feed Clang with CTU specific extra arguments:. .. code-block:: bash. $ pwd; /path/to/your/project; $ clang++ --analyze \; -Xclang -analyzer-config -Xclang experimental-enable-naive-ctu-analysis=true \; -Xclang -analyzer-config -Xclang ctu-dir=. \; -Xclang -analyzer-config -Xclang ctu-invocation-list=invocations.yaml \; -Xclang -analyzer-output=plist-multi-file \; main.cpp; main.cpp:5:12: warning: Division by zero; return 3 / foo();; ~~^~~~~~~; 1 warning generated.; $ # The plist file with the result is generated.; $ ls -F; compile_commands.json externalDefMap.txt foo.cpp main.cpp main.plist; $. This manual procedure is error-prone and not scalable, therefore to analyze real projects it is recommended to use; `CodeChecker` or `scan-build-py`. Automated CTU Analysis with CodeChecker; #######################################; The `CodeChecker <https://github.com/Ericsson/codechecker>`_ project fully supports automated CTU analysis with Clang.; Once we have set up the `PATH` environment variable and we activated the python `venv` then it is all it takes:. .. code-block:: bash. $ CodeChecker analyze --ctu --ctu-ast-loading-mode on-demand compile_commands.json -o reports; $ ls -F; compile_commands.json foo.cpp main.cpp reports/; $ tree reports; reports;  compile_cmd.json;  compiler_info.json;  foo.cpp_53f6fbf7ab7ec9931301524b551959e2.plist;  main.cpp_23db3d8df52ff0812e6e5a03071c8337.plist;  metadata.json;  unique_compile_commands.json. 0 directories, 6 files; $. The `plist` files contain the results of the analysis, which may be viewed with the regular analysis tools.; E.g. one may use `CodeChecker parse` to view the results in command l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/CrossTranslationUnit.rst:9891,scalab,scalable,9891,interpreter/llvm-project/clang/docs/analyzer/user-docs/CrossTranslationUnit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/CrossTranslationUnit.rst,1,['scalab'],['scalable']
Performance,"nd nested tuple) is the experimental evolution of TTree columnar data storage. RNTuple introduces; new interfaces that aim to be more robust. In particular, the new interfaces are type-safe through the use of; templates, and the ownership is well-defined through the use of smart pointers. For instance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:1020,optimiz,optimized,1020,tree/ntuple/v7/doc/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md,1,['optimiz'],['optimized']
Performance,"nd the current node or path has not; been changed by the user. #### Finding If Current State Is Changed For a New Point. One can find fast if a point different from the current one has or not; the same location inside the geometry tree. To do that, the new point; should not be introduced by using `TGeoManager::SetCurrentPoint()`; method, but rather by calling the specific method:. ``` {.cpp}; Bool_t TGeoManager::IsSameLocation(Double_t x,Double_t y,; Double_t z,Bool_t change=kFALSE);; ```. In the prototype above, `x, y` and `z` are the coordinates of the new; point. The modeller will check whether the current volume still contains; the new point or its location has changed in the geometry hierarchy. If; the new location is different, two actions are possible according to the; value of `change`:. - `change = kFALSE` (default) - the modeller does not change the; current state but just inform the caller about this change.; - `change = kTRUE` - the modeller will actually perform a new; `Where am I?' `search after finding out that the location has; changed. The current state will be actualized accordingly. Note that even when performing a normal search on the current state; after changing the current point coordinates (e.g.; `gGeoManager->FindNode(newX,newY,newZ)`), users can always query if the; previous state has changed by using a method having the same name but; without parameters:. ``` {.cpp}; Bool_t TGeoManager::IsSameLocation();; ```. #### Finding the Distance to the Next Boundary. All tracking engines need to compare the currently proposed physical; step with the maximum allowed distance in the current material. The; modeller provides this information by computing the distance to the; first boundary starting from the current point along a straight line.; The starting point and direction for this procedure are the ones; corresponding to the current state. The boundary search is initialized; inside the current volume and the crossed boundary can belong either to; t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:114984,perform,perform,114984,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['perform']
Performance,"nd x86-64 and x32 (see below).; - OSX 64 bit on x86-64. More platforms are expected to be available later; the lack of support; stems from Cling and Clang/LLVM not being ported to these platforms yet. To aleviate the pain for Windows users who want to try ROOT 6 we provide; a recipe on how to run ROOT 6 in a VM on Windows. Building ROOT also requires a C++11 compatible compiler, so one needs to either have installed gcc >= 4.8 or Clang >= 3.4. On most lecagy platforms these newer compilers are available via a special install.; See the [build prerequisites](https://root.cern/install/dependencies/) page. Despite that, an additional platform as been added: the [x32; psAPI](https://sites.google.com/site/x32abi/), called linuxx32gcc. It is; a regular x86-64 ABI but with shorter pointers (4 bytes instead of 8).; This reduces the addressable memory per process to 4GB - but that is; usally sufficient. The advantages are reduced memory consumption (due to; the smaller pointers) and increased performance compared to 32 bit; applications due to the availability of the 64 bit instructions. The; Clang developers mailing list archive [contains a good; comparison](http://clang-developers.42468.n3.nabble.com/Re-PATCH-add-x32-psABI-support-td4024297.html). To build and run binaries compiled in x32, toolchain support is needed.; That is available in the in binutils (2.22), GCC (4.8), glibc (2.16),; Linux kernel (3.4) and even GDB (7.5). These versions are not available; in regular distributions yet (except for [this beta Gentoo; distro](http://dev.gentoo.org/~vapier/x32/stage3-amd64-x32-20120605.tar.xz); built in x32); once they are, building and running x86-64 and x32; side-by-side will be possible. ## Build System; ROOT 6.00/00 can be built either using the classic ""./configure;make"" method or using CMake.; The CMake system has been completed for this version and should be functionally equivalent; to the classic one. The [detailed instructions](https://root.cern/install/build_from_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md:1217,perform,performance,1217,core/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md,1,['perform'],['performance']
Performance,"nd/or ``nsw`` keywords are present, the; result value of the ``add`` is a :ref:`poison value <poisonvalues>` if; unsigned and/or signed overflow, respectively, occurs. Example:; """""""""""""""". .. code-block:: text. <result> = add i32 4, %var ; yields i32:result = 4 + %var. .. _i_fadd:. '``fadd``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = fadd [fast-math flags]* <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``fadd``' instruction returns the sum of its two operands. Arguments:; """""""""""""""""""". The two arguments to the '``fadd``' instruction must be; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>` of; floating-point values. Both arguments must have identical types. Semantics:; """""""""""""""""""". The value produced is the floating-point sum of the two operands.; This instruction is assumed to execute in the default :ref:`floating-point; environment <floatenv>`.; This instruction can also take any number of :ref:`fast-math; flags <fastmath>`, which are optimization hints to enable otherwise; unsafe floating-point optimizations:. Example:; """""""""""""""". .. code-block:: text. <result> = fadd float 4.0, %var ; yields float:result = 4.0 + %var. .. _i_sub:. '``sub``' Instruction; ^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = sub <ty> <op1>, <op2> ; yields ty:result; <result> = sub nuw <ty> <op1>, <op2> ; yields ty:result; <result> = sub nsw <ty> <op1>, <op2> ; yields ty:result; <result> = sub nuw nsw <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``sub``' instruction returns the difference of its two operands. Note that the '``sub``' instruction is used to represent the '``neg``'; instruction present in most other intermediate representations. Arguments:; """""""""""""""""""". The two arguments to the '``sub``' instruction must be; :ref:`integer <t_integer>` or :ref:`vector <t_vector>` of integer values. Both; arguments must have identical types. Semantics:; """""""""""""""""""". The value produced is the integer difference of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:379171,optimiz,optimization,379171,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['optimiz'],"['optimization', 'optimizations']"
Performance,"nd; ^^^^^^. For a type without native support, a value may need to be broken down further,; rather than promoted. For an operation without native support, a combination; of other operations may be used to similar effect. In SPARC, the; floating-point sine and cosine trig operations are supported by expansion to; other operations, as indicated by the third parameter, ``Expand``, to; ``setOperationAction``:. .. code-block:: c++. setOperationAction(ISD::FSIN, MVT::f32, Expand);; setOperationAction(ISD::FCOS, MVT::f32, Expand);. Custom; ^^^^^^. For some operations, simple type promotion or operation expansion may be; insufficient. In some cases, a special intrinsic function must be implemented. For example, a constant value may require special treatment, or an operation; may require spilling and restoring registers in the stack and working with; register allocators. As seen in ``SparcISelLowering.cpp`` code below, to perform a type conversion; from a floating point value to a signed integer, first the; ``setOperationAction`` should be called with ``Custom`` as the third parameter:. .. code-block:: c++. setOperationAction(ISD::FP_TO_SINT, MVT::i32, Custom);. In the ``LowerOperation`` method, for each ``Custom`` operation, a case; statement should be added to indicate what function to call. In the following; code, an ``FP_TO_SINT`` opcode will call the ``LowerFP_TO_SINT`` method:. .. code-block:: c++. SDValue SparcTargetLowering::LowerOperation(SDValue Op, SelectionDAG &DAG) {; switch (Op.getOpcode()) {; case ISD::FP_TO_SINT: return LowerFP_TO_SINT(Op, DAG);; ...; }; }. Finally, the ``LowerFP_TO_SINT`` method is implemented, using an FP register to; convert the floating-point value to an integer. .. code-block:: c++. static SDValue LowerFP_TO_SINT(SDValue Op, SelectionDAG &DAG) {; assert(Op.getValueType() == MVT::i32);; Op = DAG.getNode(SPISD::FTOI, MVT::f32, Op.getOperand(0));; return DAG.getNode(ISD::BITCAST, MVT::i32, Op);; }. Legal; ^^^^^. The ``Legal`` ``LegalizeActi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:59962,perform,perform,59962,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['perform'],['perform']
Performance,"nd; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidatin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251135,load,load,251135,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"nded to provide a guide to anyone either writing a frontend; for LLVM or working on optimization passes for LLVM with a guide for how to deal; with instructions with special semantics in the presence of concurrency. This; is not intended to be a precise guide to the semantics; the details can get; extremely complicated and unreadable, and are not usually necessary. .. _Optimization outside atomic:. Optimization outside atomic; ===========================. The basic ``'load'`` and ``'store'`` allow a variety of optimizations, but can; lead to undefined results in a concurrent environment; see `NotAtomic`_. This; section specifically goes into the one optimizer restriction which applies in; concurrent environments, which gets a bit more of an extended description; because any optimization dealing with stores needs to be aware of it. From the optimizer's point of view, the rule is that if there are not any; instructions with atomic ordering involved, concurrency does not matter, with; one exception: if a variable might be visible to another thread or signal; handler, a store cannot be inserted along a path where it might not execute; otherwise. Take the following example:. .. code-block:: c. /* C code, for readability; run through clang -O2 -S -emit-llvm to get; equivalent IR */; int x;; void f(int* a) {; for (int i = 0; i < 100; i++) {; if (a[i]); x += 1;; }; }. The following is equivalent in non-concurrent situations:. .. code-block:: c. int x;; void f(int* a) {; int xtemp = x;; for (int i = 0; i < 100; i++) {; if (a[i]); xtemp += 1;; }; x = xtemp;; }. However, LLVM is not allowed to transform the former to the latter: it could; indirectly introduce undefined behavior if another thread can access ``x`` at; the same time. That thread would read `undef` instead of the value it was; expecting, which can lead to undefined behavior down the line. (This example is; particularly of interest because before the concurrency model was implemented,; LLVM would perform this transf",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:2854,optimiz,optimizer,2854,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,"['concurren', 'optimiz']","['concurrency', 'optimizer']"
Performance,"ndefined behavior if another thread can access ``x`` at; the same time. That thread would read `undef` instead of the value it was; expecting, which can lead to undefined behavior down the line. (This example is; particularly of interest because before the concurrency model was implemented,; LLVM would perform this transformation.). Note that speculative loads are allowed; a load which is part of a race returns; ``undef``, but does not have undefined behavior. Atomic instructions; ===================. For cases where simple loads and stores are not sufficient, LLVM provides; various atomic instructions. The exact guarantees provided depend on the; ordering; see `Atomic orderings`_. ``load atomic`` and ``store atomic`` provide the same basic functionality as; non-atomic loads and stores, but provide additional guarantees in situations; where threads and signals are involved. ``cmpxchg`` and ``atomicrmw`` are essentially like an atomic load followed by an; atomic store (where the store is conditional for ``cmpxchg``), but no other; memory operation can happen on any thread between the load and store. A ``fence`` provides Acquire and/or Release ordering which is not part; of another operation; it is normally used along with Monotonic memory; operations. A Monotonic load followed by an Acquire fence is roughly; equivalent to an Acquire load, and a Monotonic store following a; Release fence is roughly equivalent to a Release; store. SequentiallyConsistent fences behave as both an Acquire and a; Release fence, and additionally provide a total ordering with some; complicated guarantees, see the C++ standard for details. Frontends generating atomic instructions generally need to be aware of the; target to some degree; atomic instructions are guaranteed to be lock-free, and; therefore an instruction which is wider than the target natively supports can be; impossible to generate. .. _Atomic orderings:. Atomic orderings; ================. In order to achieve a balance between p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:4628,load,load,4628,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,['load'],['load']
Performance,"nderlying data itself. A requirement is that if data is loaded and then saved again (called a ""round trip""), the memory contents should be the same after the store as before the load. If a vector is loaded and is then bitconverted to a different vector type before storing, the round trip will currently be broken. Take for example this code sequence::. %0 = load <4 x i32> %x; %1 = bitcast <4 x i32> %0 to <2 x i64>; store <2 x i64> %1, <2 x i64>* %y. This would produce a code sequence such as that in the figure on the right. The mismatched ``LD1`` and ``ST1`` cause the stored data to differ from the loaded data. .. container:: clearer. When we see a bitcast from type ``X`` to type ``Y``, what we need to do is to change the in-register representation of the data to be *as if* it had just been loaded by a ``LD1`` of type ``Y``. .. image:: ARM-BE-bitcastsuccess.png; :align: right. Conceptually this is simple - we can insert a ``REV`` undoing the ``LD1`` of type ``X`` (converting the in-register representation to the same as if it had been loaded by ``LDR``) and then insert another ``REV`` to change the representation to be as if it had been loaded by an ``LD1`` of type ``Y``. For the previous example, this would be::. LD1 v0.4s, [x]. REV64 v0.4s, v0.4s // There is no REV128 instruction, so it must be synthesizedcd; EXT v0.16b, v0.16b, v0.16b, #8 // with a REV64 then an EXT to swap the two 64-bit elements. REV64 v0.2d, v0.2d; EXT v0.16b, v0.16b, v0.16b, #8. ST1 v0.2d, [y]. It turns out that these ``REV`` pairs can, in almost all cases, be squashed together into a single ``REV``. For the example above, a ``REV128 4s`` + ``REV128 2d`` is actually a ``REV64 4s``, as shown in the figure on the right. .. [1] One lane vectors may seem useless as a concept but they serve to distinguish between values held in general purpose registers and values held in NEON/VFP registers. For example, an ``i64`` would live in an ``x`` register, but ``<1 x i64>`` would live in a ``d`` register.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:11084,load,loaded,11084,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,2,['load'],['loaded']
Performance,"ndex.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly avoid costly checks (extra RecursiveRemove and lock). We removed the need to create a TThread object per thread in a multi-threaded application. Now ROOT can be used with any threading model (e.g. OpenMP, STL threads, TBB) transparently. All the internal synchronisation mechanisms of ROOT are activated by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TContext` which record the current directory; and will restore it at destruction time and does not change the current directory. The constructor for `TDirectory::TContext` that takes a single TDirectory pointer as; an argument was changed to set `gDirectory` to zero when being passed a null pointer;; previously it was interpreting a null pointer as a request to *not* change the current; directo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:2471,multi-thread,multi-threaded,2471,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['multi-thread'],['multi-threaded']
Performance,"ndicates that widening the scalars in one; of the types to a specific type would make it more legal. This action supports; both scalars and vectors. * ``fewerElementsIf()``, ``fewerElementsFor()``, etc. declare an instruction to be; illegal if the predicate is satisfied and indicates reducing the number of; vector elements in one of the types to a specific type would make it more; legal. This action supports vectors. * ``moreElementsIf()``, ``moreElementsFor()``, etc. declare an instruction to be illegal; if the predicate is satisfied and indicates increasing the number of vector; elements in one of the types to a specific type would make it more legal.; This action supports vectors. * ``lowerIf()``, ``lowerFor()``, etc. declare an instruction to be; illegal if the predicate is satisfied and indicates that replacing; it with equivalent instruction(s) would make it more legal. Support; for this action differs for each opcode. These may provide an; optional LegalizeMutation containing a type to attempt to perform; the expansion in a different type. * ``libcallIf()``, ``libcallFor()``, etc. declare an instruction to be illegal if the; predicate is satisfied and indicates that replacing it with a libcall would; make it more legal. Support for this action differs for; each opcode. * ``customIf()``, ``customFor()``, etc. declare an instruction to be illegal if the; predicate is satisfied and indicates that the backend developer will supply; a means of making it more legal. * ``unsupportedIf()``, ``unsupportedFor()``, etc. declare an instruction to be illegal; if the predicate is satisfied and indicates that there is no way to make it; legal and the compiler should fail. * ``fallback()`` falls back on an older API and should only be used while porting; existing code from that API. Rule Predicates; """""""""""""""""""""""""""""". The rule factories also have predicates in common:. * ``legal()``, ``lower()``, etc. are always satisfied. * ``legalIf()``, ``narrowScalarIf()``, etc. are satisf",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:7619,perform,perform,7619,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,1,['perform'],['perform']
Performance,"ndif. .. _arc.misc.self:. ``self``; --------. The ``self`` parameter variable of an non-init Objective-C method is considered; :ref:`externally-retained <arc.misc.externally_retained>` by the implementation.; It is undefined behavior, or at least dangerous, to cause an object to be; deallocated during a message send to that object. In an init method, ``self``; follows the :ref:``init family rules <arc.family.semantics.init>``. .. admonition:: Rationale. The cost of retaining ``self`` in all methods was found to be prohibitive, as; it tends to be live across calls, preventing the optimizer from proving that; the retain and release are unnecessary --- for good reason, as it's quite; possible in theory to cause an object to be deallocated during its execution; without this retain and release. Since it's extremely uncommon to actually; do so, even unintentionally, and since there's no natural way for the; programmer to remove this retain/release pair otherwise (as there is for; other parameters by, say, making the variable ``objc_externally_retained`` or; qualifying it with ``__unsafe_unretained``), we chose to make this optimizing; assumption and shift some amount of risk to the user. .. _arc.misc.enumeration:. Fast enumeration iteration variables; ------------------------------------. If a variable is declared in the condition of an Objective-C fast enumeration; loop, and the variable has no explicit ownership qualifier, then it is; implicitly :ref:`externally-retained <arc.misc.externally_retained>` so that; objects encountered during the enumeration are not actually retained and; released. .. admonition:: Rationale. This is an optimization made possible because fast enumeration loops promise; to keep the objects retained during enumeration, and the collection itself; cannot be synchronously modified. It can be overridden by explicitly; qualifying the variable with ``__strong``, which will make the variable; mutable again and cause the loop to retain the objects it e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:95279,optimiz,optimizing,95279,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizing']
Performance,"nding dead code behind A/B experiment flags. Finding dead code is a classic application of data flow analysis. Unused flags for A/B experiment hide dead code. However, this flavor of dead; code is invisible to the compiler because the flag can be turned on at any; moment. We could make a tool that deletes experiment flags. The user tells us which flag; they want to delete, and we assume that the it's value is a given constant. For example, the user could use the tool to remove `example_flag` from this; code:. ```c++; DEFINE_FLAG(std::string, example_flag, """", ""A sample flag."");. void Example() {; bool x = GetFlag(FLAGS_example_flag).empty();; f();; if (x) {; g();; } else {; h();; }; }; ```. The tool would simplify the code to:. ```c++; void Example() {; f();; g();; }; ```. We can solve this problem with a classic constant propagation lattice combined; with symbolic evaluation. ## Example: finding inefficient usages of associative containers. Real-world code often accidentally performs repeated lookups in associative; containers:. ```c++; map<int, Employee> xs;; xs[42]->name = ""..."";; xs[42]->title = ""..."";; ```. To find the above inefficiency we can use the available expressions analysis to; understand that `m[42]` is evaluated twice. ```c++; map<int, Employee> xs;; Employee &e = xs[42];; e->name = ""..."";; e->title = ""..."";; ```. We can also track the `m.contains()` check in the flow condition to find; redundant checks, like in the example below. ```c++; std::map<int, Employee> xs;; if (!xs.contains(42)) {; xs.insert({42, someEmployee});; }; ```. ## Example: refactoring types that implicitly convert to each other. Refactoring one strong type to another is difficult, but the compiler can help:; once you refactor one reference to the type, the compiler will flag other places; where this information flows with type mismatch errors. Unfortunately this; strategy does not work when you are refactoring types that implicitly convert to; each other, for example, replacing `i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:28858,perform,performs,28858,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['perform'],['performs']
Performance,"ndle my also encode a ``separate_storage``; operand bundle. This has the form:. .. code-block:: llvm. separate_storage(<val1>, <val2>)``. This indicates that no pointer :ref:`based <pointeraliasing>` on one of its; arguments can alias any pointer based on the other. Even if the assumed property can be encoded as a boolean value, like; ``nonnull``, using operand bundles to express the property can still have; benefits:. * Attributes that can be expressed via operand bundles are directly the; property that the optimizer uses and cares about. Encoding attributes as; operand bundles removes the need for an instruction sequence that represents; the property (e.g., `icmp ne ptr %p, null` for `nonnull`) and for the; optimizer to deduce the property from that instruction sequence.; * Expressing the property using operand bundles makes it easy to identify the; use of the value as a use in an :ref:`llvm.assume <int_assume>`. This then; simplifies and improves heuristics, e.g., for use ""use-sensitive""; optimizations. .. _ob_preallocated:. Preallocated Operand Bundles; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Preallocated operand bundles are characterized by the ``""preallocated""``; operand bundle tag. These operand bundles allow separation of the allocation; of the call argument memory from the call site. This is necessary to pass; non-trivially copyable objects by value in a way that is compatible with MSVC; on some targets. There can be at most one ``""preallocated""`` operand bundle; attached to a call site and it must have exactly one bundle operand, which is; a token generated by ``@llvm.call.preallocated.setup``. A call with this; operand bundle should not adjust the stack before entering the function, as; that will have been done by one of the ``@llvm.call.preallocated.*`` intrinsics. .. code-block:: llvm. %foo = type { i64, i32 }. ... %t = call token @llvm.call.preallocated.setup(i32 1); %a = call ptr @llvm.call.preallocated.arg(token %t, i32 0) preallocated(%foo); ; initialize %b; c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:126422,optimiz,optimizations,126422,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"ndle this. //===---------------------------------------------------------------------===//. Investigate lowering of sparse switch statements into perfect hash tables:; http://burtleburtle.net/bob/hash/perfect.html. //===---------------------------------------------------------------------===//. We should turn things like ""load+fabs+store"" and ""load+fneg+store"" into the; corresponding integer operations. On a yonah, this loop:. double a[256];; void foo() {; int i, b;; for (b = 0; b < 10000000; b++); for (i = 0; i < 256; i++); a[i] = -a[i];; }. is twice as slow as this loop:. long long a[256];; void foo() {; int i, b;; for (b = 0; b < 10000000; b++); for (i = 0; i < 256; i++); a[i] ^= (1ULL << 63);; }. and I suspect other processors are similar. On X86 in particular this is a; big win because doing this with integers allows the use of read/modify/write; instructions. //===---------------------------------------------------------------------===//. DAG Combiner should try to combine small loads into larger loads when ; profitable. For example, we compile this C++ example:. struct THotKey { short Key; bool Control; bool Shift; bool Alt; };; extern THotKey m_HotKey;; THotKey GetHotKey () { return m_HotKey; }. into (-m64 -O3 -fno-exceptions -static -fomit-frame-pointer):. __Z9GetHotKeyv: ## @_Z9GetHotKeyv; 	movq	_m_HotKey@GOTPCREL(%rip), %rax; 	movzwl	(%rax), %ecx; 	movzbl	2(%rax), %edx; 	shlq	$16, %rdx; 	orq	%rcx, %rdx; 	movzbl	3(%rax), %ecx; 	shlq	$24, %rcx; 	orq	%rdx, %rcx; 	movzbl	4(%rax), %eax; 	shlq	$32, %rax; 	orq	%rcx, %rax; 	ret. //===---------------------------------------------------------------------===//. We should add an FRINT node to the DAG to model targets that have legal; implementations of ceil/floor/rint. //===---------------------------------------------------------------------===//. Consider:. int test() {; long long input[8] = {1,0,1,0,1,0,1,0};; foo(input);; }. Clang compiles this into:. call void @llvm.memset.p0i8.i64(i8* %tmp, i8 0, i64 64, i32 16",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:13888,load,loads,13888,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,4,['load'],['loads']
Performance,"ndler Carruth - [chandlerc@google.com](mailto:chandlerc@google.com). ## Problem Statement. Recently, Google Project Zero and other researchers have found information leak; vulnerabilities by exploiting speculative execution in modern CPUs. These; exploits are currently broken down into three variants:; * GPZ Variant #1 (a.k.a. Spectre Variant #1): Bounds check (or predicate) bypass; * GPZ Variant #2 (a.k.a. Spectre Variant #2): Branch target injection; * GPZ Variant #3 (a.k.a. Meltdown): Rogue data cache load. For more details, see the Google Project Zero blog post and the Spectre research; paper:; * https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html; * https://spectreattack.com/spectre.pdf. The core problem of GPZ Variant #1 is that speculative execution uses branch; prediction to select the path of instructions speculatively executed. This path; is speculatively executed with the available data, and may load from memory and; leak the loaded values through various side channels that survive even when the; speculative execution is unwound due to being incorrect. Mispredicted paths can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will pre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:1043,load,load,1043,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,['load'],"['load', 'loaded']"
Performance,"nds checks:; // if (p + i < p || p + i + 1 > p + count) trap();; p[i] = i;; }; }. ``ConstraintElimination`` collects the following facts and determines if the; bounds checks can be safely removed:. * Inside the for-loop, ``0 <= i < count``, hence ``1 <= i + 1 <= count``.; * Pointer arithmetic ``p + count`` in the if-condition doesnt wrap.; * ``-fbounds-safety`` treats pointer arithmetic overflow as deterministically; twos complement computation, not an undefined behavior. Therefore,; getelementptr does not typically have inbounds keyword. However, the compiler; does emit inbounds for ``p + count`` in this case because; ``__counted_by(count)`` has the invariant that p has at least as many as; elements as count. Using this information, ``ConstraintElimination`` is able; to determine ``p + count`` doesnt wrap.; * Accordingly, ``p + i`` and ``p + i + 1`` also dont wrap.; * Therefore, ``p <= p + i`` and ``p + i + 1 <= p + count``.; * The if-condition simplifies to false and becomes dead code that the subsequent; optimization passes can remove. ``OptRemarks`` can be utilized to provide insights into performance tuning. It; has the capability to report on checks that it cannot eliminate, possibly with; reasons, allowing programmers to adjust their code to unlock further; optimizations. Debugging; =========. Internal bounds annotations; ---------------------------. Internal bounds annotations change a pointer into a wide pointer. The debugger; needs to understand that wide pointers are essentially pointers with a struct; layout. To handle this, a wide pointer is described as a record type in the; debug info. The type name has a special name prefix (e.g.,; ``__bounds_safety$bidi_indexable``) which can be recognized by a debug info; consumer to provide support that goes beyond showing the internal structure of; the wide pointer. There are no DWARF extensions needed to support wide pointers.; In our implementation, LLDB recognizes wide pointer types by name and; reconstruct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:7923,optimiz,optimization,7923,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['optimiz'],['optimization']
Performance,"nds on a pointer value ``Q`` derived via pointer arithmetic; from ``P`` (including an instance-variable or field access), or; * depends on a pointer value ``Q`` loaded from ``P``. Dependency applies only to values derived directly or indirectly from; a particular expression result and does not occur merely because a; separate pointer value dynamically aliases ``P``. Furthermore, this; dependency is not carried by values that are stored to objects. .. admonition:: Rationale. The restrictions on dependency are intended to make this analysis; feasible by an optimizer with only incomplete information about a; program. Essentially, dependence is carried to ""obvious"" uses of a; pointer. Merely passing a pointer argument to a function does not; itself cause dependence, but since generally the optimizer will not; be able to prove that the function doesn't depend on that parameter,; it will be forced to conservatively assume it does. Dependency propagates to values loaded from a pointer because those; values might be invalidated by deallocating the object. For; example, given the code ``__strong id x = p->ivar;``, ARC must not; move the release of ``p`` to between the load of ``p->ivar`` and the; retain of that value for storing into ``x``. Dependency does not propagate through stores of dependent pointer; values because doing so would allow dependency to outlive the; full-expression which produced the original value. For example, the; address of an instance variable could be written to some global; location and then freely accessed during the lifetime of the local,; or a function could return an inner pointer of an object and store; it to a local. These cases would be potentially impossible to; reason about and so would basically prevent any optimizations based; on imprecise lifetime. There are also uncommon enough to make it; reasonable to require the precise-lifetime annotation if someone; really wants to rely on them. Dependency does propagate through return values of poi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:80936,load,loaded,80936,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['load'],['loaded']
Performance,"ne documentation (code comments), please see:. > [roofit/roofitcore/src/RooFit/Detail/CodeSquashContext.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooFit/Detail/CodeSquashContext.cxx). ### b. RooFuncWrapper. > [roofit/roofitcore/inc/RooFuncWrapper.h](https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooFuncWrapper.h). This class wraps the generated C++ code in a RooFit object, so that it can be; used like other RooFit objects. It takes a function body as input and creates a callable function from it.; This allows users to evaluate the function and its derivatives efficiently. #### Helper Functions. - **loadParamsAndData()** extracts parameters and observables from the; provided data and prepares them for evaluation. - **declareAndDiffFunction()**: declare the function and create its; derivative. - **gradient()**: calculates the gradient of the function with respect to its; parameters. - **buildCode()**: generates the optimized code for evaluating the function; and its derivatives. - **dumpCode()**: prints the squashed code body to console (useful for; debugging). - **dumpGradient()**: prints the derivative code body to console (useful for; debugging). These functions will appear again in this document with more contextual; examples. For detailed in-line documentation (code comments), please see:. > [roofit/roofitcore/src/RooFuncWrapp9er.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooFuncWrapper.cxx). ## Appendix C - Helper functions discussed in this document. - **RooFit::Detail::CodeSquashContext::addResult()**: For a specific class, it; will add whatever is represented on the right-hand side (a function call, an; expression, etc.) to the result of this class, which can then be propagated in; the rest of the compute graph. A to call `addResult()`must be included in; `translate()` function. - Inputs: `key` (the name of the node to add the result for), `value` (the; new name to assi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:33898,optimiz,optimized,33898,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['optimiz'],['optimized']
Performance,"ne has or not; the same location inside the geometry tree. To do that, the new point; should not be introduced by using `TGeoManager::SetCurrentPoint()`; method, but rather by calling the specific method:. ``` {.cpp}; Bool_t TGeoManager::IsSameLocation(Double_t x,Double_t y,; Double_t z,Bool_t change=kFALSE);; ```. In the prototype above, `x, y` and `z` are the coordinates of the new; point. The modeller will check whether the current volume still contains; the new point or its location has changed in the geometry hierarchy. If; the new location is different, two actions are possible according to the; value of `change`:. - `change = kFALSE` (default) - the modeller does not change the; current state but just inform the caller about this change.; - `change = kTRUE` - the modeller will actually perform a new; `Where am I?' `search after finding out that the location has; changed. The current state will be actualized accordingly. Note that even when performing a normal search on the current state; after changing the current point coordinates (e.g.; `gGeoManager->FindNode(newX,newY,newZ)`), users can always query if the; previous state has changed by using a method having the same name but; without parameters:. ``` {.cpp}; Bool_t TGeoManager::IsSameLocation();; ```. #### Finding the Distance to the Next Boundary. All tracking engines need to compare the currently proposed physical; step with the maximum allowed distance in the current material. The; modeller provides this information by computing the distance to the; first boundary starting from the current point along a straight line.; The starting point and direction for this procedure are the ones; corresponding to the current state. The boundary search is initialized; inside the current volume and the crossed boundary can belong either to; the current node or to one of its daughters. The full prototype of the; method is:. ``` {.cpp}; TGeoNode *TGeoManager::FindNextBoundary(Double_t step=kBig);; ```. In the prototyp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:115142,perform,performing,115142,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performing']
Performance,"ne sends you; a patch privately, encourage them to submit it to the appropriate list first. Our previous version control system (subversion) did not distinguish between the; author and the committer like git does. As such, older commits used a different; attribution mechanism. The previous method was to include ""Patch by John Doe.""; in a separate line of the commit message and there are automated processes that; rely on this format. .. _IR backwards compatibility:. IR Backwards Compatibility; --------------------------. When the IR format has to be changed, keep in mind that we try to maintain some; backwards compatibility. The rules are intended as a balance between convenience; for llvm users and not imposing a big burden on llvm developers:. * The textual format is not backwards compatible. We don't change it too often,; but there are no specific promises. * Additions and changes to the IR should be reflected in; ``test/Bitcode/compatibility.ll``. * The current LLVM version supports loading any bitcode since version 3.0. * After each X.Y release, ``compatibility.ll`` must be copied to; ``compatibility-X.Y.ll``. The corresponding bitcode file should be assembled; using the X.Y build and committed as ``compatibility-X.Y.ll.bc``. * Newer releases can ignore features from older releases, but they cannot; miscompile them. For example, if nsw is ever replaced with something else,; dropping it would be a valid way to upgrade the IR. * Debug metadata is special in that it is currently dropped during upgrades. * Non-debug metadata is defined to be safe to drop, so a valid way to upgrade; it is to drop it. That is not very user friendly and a bit more effort is; expected, but no promises are made. C API Changes; -------------. * Stability Guarantees: The C API is, in general, a ""best effort"" for stability.; This means that we make every attempt to keep the C API stable, but that; stability will be limited by the abstractness of the interface and the; stability of the C++ AP",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:31830,load,loading,31830,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['load'],['loading']
Performance,"ne). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None  List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False  Print method-specific help message. CreateMVAPdfs No False  Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False  Events with negative weights are ignored in the training (but are included for testing and performance evaluation). TrainingMethod No BP BP, GA, BFGS Train with Back-Propagation (BP), BFGS Algorithm (BFGS), or Genetic Algorithm (GA - slower and worse). LearningRate No 0.02  ANN learning rate parameter. DecayRate No 0.01  Decay rate for learning parameter. TestRate No 10  Test for overtraining performed at each #th epochs. EpochMonitoring No False  Provide epoch-wise monitoring plots according to TestRate (caution: causes big ROOT output file!). Sampling No 1  Only 'Sampling' (randomly selected) events are trained each epoch. SamplingEpoch No 1  Sampling is used for the first 'SamplingEpoch' epochs, afterwards, all events are taken for training. SamplingImportance No 1  The sampling weights of events in epochs which successful (worse estimator than before) are multiplied with SamplingImportance, else they are divided. SamplingTraining No True  The training sample is sampled. SamplingTesting No False  The testing sample is sampled. ResetStep No 50  How often BFGS should reset history. Tau No 3  LineSearch size step. BPMode No sequential sequential, batch Back-propagation learning mode: sequential or batch. BatchSize No -1  Batch size: number of events/batch, only set if in Batch Mode, -1 for BatchSize=number_of_events. ConvergenceImprove No 1e-30  Minimum impro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:22539,perform,performed,22539,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['perform'],['performed']
Performance,"ned less-than comparison operator. Overflow cannot occur in; ``(%base + i)`` and its comparison against ``%n`` as it is performed in integer; numbers and not in machine numbers. If ``%n`` is ``0``, then the result is a; poison value. The above is equivalent to:. ::. %m = @llvm.get.active.lane.mask(%base, %n). This can, for example, be emitted by the loop vectorizer in which case; ``%base`` is the first element of the vector induction variable (VIV) and; ``%n`` is the loop tripcount. Thus, these intrinsics perform an element-wise; less than comparison of VIV with the loop tripcount, producing a mask of; true/false values representing active/inactive vector lanes, except if the VIV; overflows in which case they return false in the lanes where the VIV overflows.; The arguments are scalar types to accommodate scalable vector types, for which; it is unknown what the type of the step vector needs to be that enumerate its; lanes without overflow. This mask ``%m`` can e.g. be used in masked load/store instructions. These; intrinsics provide a hint to the backend. I.e., for a vector loop, the; back-edge taken count of the original scalar loop is explicit as the second; argument. Examples:; """""""""""""""""". .. code-block:: llvm. %active.lane.mask = call <4 x i1> @llvm.get.active.lane.mask.v4i1.i64(i64 %elem0, i64 429); %wide.masked.load = call <4 x i32> @llvm.masked.load.v4i32.p0v4i32(<4 x i32>* %3, i32 4, <4 x i1> %active.lane.mask, <4 x i32> poison). .. _int_experimental_vp_splice:. '``llvm.experimental.vp.splice``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <2 x double> @llvm.experimental.vp.splice.v2f64(<2 x double> %vec1, <2 x double> %vec2, i32 %imm, <2 x i1> %mask, i32 %evl1, i32 %evl2); declare <vscale x 4 x i32> @llvm.experimental.vp.splice.nxv4i32(<vscale x 4 x i32> %vec1, <vscale x 4 x i32> %vec2, i32 %imm, <vscale x 4 x i1> %mask, i32 %evl1, i32 %evl2). Overview:; """""""""""""""""". The '``llvm.ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:778794,load,load,778794,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"ned to fix these; issues. In order to solve these issues we need to:. * Have a format that can be mapped into memory from disk and used as is; * Lookups should be very fast; * Extensible table format so these tables can be made by many producers; * Contain all of the names needed for typical lookups out of the box; * Strict rules for the contents of tables. Table size is important and the accelerator table format should allow the reuse; of strings from common string tables so the strings for the names are not; duplicated. We also want to make sure the table is ready to be used as-is by; simply mapping the table into memory with minimal header parsing. The name lookups need to be fast and optimized for the kinds of lookups that; debuggers tend to do. Optimally we would like to touch as few parts of the; mapped table as possible when doing a name lookup and be able to quickly find; the name entry we are looking for, or discover there are no matches. In the; case of debuggers we optimized for lookups that fail most of the time. Each table that is defined should have strict rules on exactly what is in the; accelerator tables and documented so clients can rely on the content. Hash Tables; ^^^^^^^^^^^. Standard Hash Tables; """""""""""""""""""""""""""""""""""""""". Typical hash tables have a header, buckets, and each bucket points to the; bucket contents:. .. code-block:: none. .------------.; | HEADER |; |------------|; | BUCKETS |; |------------|; | DATA |; `------------'. The BUCKETS are an array of offsets to DATA for each hash:. .. code-block:: none. .------------.; | 0x00001000 | BUCKETS[0]; | 0x00002000 | BUCKETS[1]; | 0x00002200 | BUCKETS[2]; | 0x000034f0 | BUCKETS[3]; | | ...; | 0xXXXXXXXX | BUCKETS[n_buckets]; '------------'. So for ``bucket[3]`` in the example above, we have an offset into the table; 0x000034f0 which points to a chain of entries for the bucket. Each bucket must; contain a next pointer, full 32 bit hash value, the string itself, and the data; for the current string ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:60602,optimiz,optimized,60602,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimized']
Performance,"need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_inv sc1=1. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unord",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:305009,load,load,305009,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"nel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241017,cache,cache,241017,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"nel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX940, GFX941, GFX942; are defined in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx940-gfx941-gf",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:291035,cache,cache,291035,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"nel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory M",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:210529,cache,cache,210529,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"nel prolog. If a frame pointer is not required then all uses of the frame; pointer are replaced with immediate ``0`` offsets. .. _amdgpu-amdhsa-kernel-prolog-flat-scratch:. Flat Scratch; ++++++++++++. There are different methods used for initializing flat scratch:. * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Does not support generic address space*:. Flat scratch is not supported and there is no flat scratch register pair. * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Offset flat scratch*:. If the kernel or any function it calls may use flat operations to access; scratch memory, the prolog code must set up the FLAT_SCRATCH register pair; (FLAT_SCRATCH_LO/FLAT_SCRATCH_HI). Initialization uses Flat Scratch Init and; Scratch Wavefront Offset SGPR registers (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`):. 1. The low word of Flat Scratch Init is the 32-bit byte offset from; ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to the base of scratch backing memory; being managed by SPI for the queue executing the kernel dispatch. This is; the same value used in the Scratch Segment Buffer V# base address. CP obtains this from the runtime. (The Scratch Segment Buffer base address; is ``SH_HIDDEN_PRIVATE_BASE_VIMID`` plus this offset.). The prolog must add the value of Scratch Wavefront Offset to get the; wavefront's byte scratch backing memory offset from; ``SH_HIDDEN_PRIVATE_BASE_VIMID``. The Scratch Wavefront Offset must also be used as an offset with Private; segment address when using the Scratch Segment Buffer. Since FLAT_SCRATCH_LO is in units of 256 bytes, the offset must be right; shifted by 8 before moving into FLAT_SCRATCH_HI. FLAT_SCRATCH_HI corresponds to SGPRn-4 on GFX7, and SGPRn-6 on GFX8 (where; SGPRn is the highest numbered SGPR allocated to the wavefront).; FLAT_SCRATCH_HI is multiplied by 256 (as it is in units of 256 bytes) and; added to ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to calculate the per w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:194658,queue,queue,194658,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance,"neric, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw-with-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; atomicrmw-no-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_gl*_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; caches. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:354049,load,load,354049,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"neric; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgk",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251725,load,load,251725,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"neric; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt vscnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlet",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:356447,perform,performing,356447,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"nes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 1, i32 1, i32 1, i32 1>; %reduction = call i32 @llvm.vector.reduce.mul.v4i32(<4 x i32> %masked.a); %also.r = mul i32 %reduction, %start. .. _int_vp_reduce_fmul:. '``llvm.vp.reduce.fmul.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmul.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fmul.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MUL`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmul``' intrinsic performs the floating-point ``MUL``; reduction (:ref:`llvm.vector.reduce.fmul <int_vector_reduce_fmul>`) of the; vector operand ``val`` on each enabled lane, multiplying it by the scalar; `start_value``. Disabled lanes are treated as containing the neutral value; ``1.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to the starting value. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fmul; <int_vector_reduce_fmul>`) for more detail on the semantics. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float @llvm.vp.r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:755214,perform,performed,755214,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"new kinds of false positives. We'd like to know about; these, and any other problems you encounter. When you encounter an issue, please file a bug report.; checker-267; built: June 1, 2012; highlights:; Adds basic interprocedural analysis support for blocks.; checker-266; built: May 23, 2012; highlights:; Contains numerous stability fixes over checker-266, especially when analyzing C++11 code.; checker-265; built: May 8, 2012; highlights:; This release contains a fix for a major crasher introduced in checker-264, and various refinements to; improve the precision and reduce the false positive rate of the analyzer. It also enables a new unix.MallocSizeof check, which reports; inconsistencies between the casted type of the return value of a 'malloc/calloc/realloc' call and the operand; of sizeof expressions contained within its argument(s).; checker-264; built: April 26, 2012; highlights:; This release contains misc. bug fixes and performance enhancements over checker-263, including; a reduction of some kinds of false positives related to the malloc() checker.; checker-263; built: March 22, 2012; highlights:. Fixes several serious bugs with inter-procedural analysis, including a case where retain/releases would be ""double-counted"". checker-262; built: March 15, 2012; highlights:. Enables experimental interprocedural analysis (within a file), which greatly amplifies the analyzer's ability to find issues.; Many bug fixes to the malloc/free checker.; Support for new Objective-C NSArray/NSDictionary/NSNumber literals syntax, and Objective-C container subscripting. NOTE: This build contains new interprocedural analysis that allows the analyzer to find more complicated bugs that span function boundaries. It may have problems, performance issues, etc. We'd like to hear about them. checker-261; built: February 22, 2012; highlights:. Contains a new experimental malloc/free checker.; Better support for projects using ARC.; Warns about null pointers passed as arguments to C strin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:7916,perform,performance,7916,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,2,['perform'],['performance']
Performance,"newly introduced tuple-initialization; ```python; myHisto = myTdf.Histo1D(('histName', 'histTitle', 64, 0, 128), 'myColumn'); ```; - Add support for friend trees and chains. Just add the friends before passing the tree/chain to TDataFrame's constructor and refer to friend branches as usual. #### Fixes; - Fixed race condition: concurrent deletion of TTreeReader/TTreeReaderValue; - Fixed reading of c-style arrays from jitted transformations and actions; - Fixed writing of c-style arrays with `Snapshot`; - Improved checks for column name validity (throw if column does not exist and if `Define`d column overrides an already existing column). #### Other changes; - Improved documentation; - TDF now avoids performing virtual calls for parts of the analysis that are not jitted; - Removed ""custom column"" nodes from the internal functional graph therewith optimising its traversal; - Improvements in Cling drastically enhanced scaling and performance of TDF jitted code; - Test coverage has been increased with the introduction of google tests; - Interface change: users must now use TDF::TArrayBranch rather than std::array\_view to specify that the column being read is a c-style array TTree branch; - Interface change: `Min` and `Max` now return results as the same type specified as template parameter, or double if no template parameter was specified. ## Histogram Libraries; - Histogram-based fits are implicitly parallelized.; - Added new options to the histogram fitting interfaces to support explicit parallelization of the fit as well.; - `TF1` gradient evaluation supports vectorization.; - Refactor of `TF1` constructors, default initialization of its data members and fixed ambiguous TF1::operator().; - Extend `TFormula` parsing capabilities.; - The parsing of arguments for defining parametric function is improved. For example a Gaussian function in y can be defined as `gaus( y , [A], [Mean], [Sigma])`.; - One can define the function variables or parameters using another function o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:15124,perform,performing,15124,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,2,['perform'],"['performance', 'performing']"
Performance,"nfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load which happens to have the desired; offset and then successfully read memory in that region. This significantly; raises the burden on the attacker and limits the scope of attack but does not; eliminate it. To fully close the attack we must work with the operating system; to preclude mapping memory in the low two gigabytes of address space. ###### 64-bit load checking instructions. We can use the following instruction sequences to check loads. We set up `%r8`; in these examples to hold the special value of `-1` which will be `cmov`ed over; `%rax` in misspeculated paths. Single register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; movl (%rsi), %edi; ```. Two register addressing mode:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rsi # Mask the pointer if misspeculating.; orq %rax, %rcx # Mask the index if misspeculating.;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:28789,load,load,28789,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['load']
Performance,"nformation collected during the linker's normal symbol resolution phase.; In the above example, the optimizer can not remove ``foo2()`` without the; linker's input because it is externally visible. This in turn prohibits the; optimizer from removing ``foo3()``. **Use separate tool to collect symbol information from all object files.**; In this model, a new, separate, tool or library replicates the linker's; capability to collect information for link time optimization. Not only is; this code duplication difficult to justify, but it also has several other; disadvantages. For example, the linking semantics and the features provided; by the linker on various platform are not unique. This means, this new tool; needs to support all such features and platforms in one super tool or a; separate tool per platform is required. This increases maintenance cost for; link time optimizer significantly, which is not necessary. This approach; also requires staying synchronized with linker developments on various; platforms, which is not the main focus of the link time optimizer. Finally,; this approach increases end user's build time due to the duplication of work; done by this separate tool and the linker itself. Multi-phase communication between ``libLTO`` and linker; =======================================================. The linker collects information about symbol definitions and uses in various; link objects which is more accurate than any information collected by other; tools during typical build cycles. The linker collects this information by; looking at the definitions and uses of symbols in native .o files and using; symbol visibility information. The linker also uses user-supplied information,; such as a list of exported symbols. LLVM optimizer collects control flow; information, data flow information and knows much more about program structure; from the optimizer's point of view. Our goal is to take advantage of tight; integration between the linker and the optimizer by ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:4447,optimiz,optimizer,4447,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['optimiz'],['optimizer']
Performance,"ng -analyzer-config -Xclang experimental-enable-naive-ctu-analysis=true \; -Xclang -analyzer-config -Xclang ctu-dir=. \; -Xclang -analyzer-config -Xclang ctu-invocation-list=invocations.yaml \; -Xclang -analyzer-output=plist-multi-file \; main.cpp; main.cpp:5:12: warning: Division by zero; return 3 / foo();; ~~^~~~~~~; 1 warning generated.; $ # The plist file with the result is generated.; $ ls -F; compile_commands.json externalDefMap.txt foo.cpp main.cpp main.plist; $. This manual procedure is error-prone and not scalable, therefore to analyze real projects it is recommended to use; `CodeChecker` or `scan-build-py`. Automated CTU Analysis with CodeChecker; #######################################; The `CodeChecker <https://github.com/Ericsson/codechecker>`_ project fully supports automated CTU analysis with Clang.; Once we have set up the `PATH` environment variable and we activated the python `venv` then it is all it takes:. .. code-block:: bash. $ CodeChecker analyze --ctu --ctu-ast-loading-mode on-demand compile_commands.json -o reports; $ ls -F; compile_commands.json foo.cpp main.cpp reports/; $ tree reports; reports;  compile_cmd.json;  compiler_info.json;  foo.cpp_53f6fbf7ab7ec9931301524b551959e2.plist;  main.cpp_23db3d8df52ff0812e6e5a03071c8337.plist;  metadata.json;  unique_compile_commands.json. 0 directories, 6 files; $. The `plist` files contain the results of the analysis, which may be viewed with the regular analysis tools.; E.g. one may use `CodeChecker parse` to view the results in command line:. .. code-block:: bash. $ CodeChecker parse reports; [HIGH] /home/egbomrt/ctu_mini_raw_project/main.cpp:5:12: Division by zero [core.DivideZero]; return 3 / foo();; ^. Found 1 defect(s) in main.cpp. ----==== Summary ====----; -----------------------; Filename | Report count; -----------------------; main.cpp | 1; -----------------------; -----------------------; Severity | Report count; -----------------------; HIGH | 1; -----------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/CrossTranslationUnit.rst:10371,load,loading-mode,10371,interpreter/llvm-project/clang/docs/analyzer/user-docs/CrossTranslationUnit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/CrossTranslationUnit.rst,1,['load'],['loading-mode']
Performance,"ng IR to the JIT and making it available for execution. In; this initial implementation of our JIT we will make our modules ""available for; execution"" by adding them to the CompileLayer, which will it turn store the; Module in the main JITDylib. This process will create new symbol table entries; in the JITDylib for each definition in the module, and will defer compilation of; the module until any of its definitions is looked up. Note that this is not lazy; compilation: just referencing a definition, even if it is never used, will be; enough to trigger compilation. In later chapters we will teach our JIT to defer; compilation of functions until they're actually called. To add our Module we; must first wrap it in a ThreadSafeModule instance, which manages the lifetime of; the Module's LLVMContext (our Ctx member) in a thread-friendly way. In our; example, all modules will share the Ctx member, which will exist for the; duration of the JIT. Once we switch to concurrent compilation in later chapters; we will use a new context per module. Our last method is ``lookup``, which allows us to look up addresses for; function and variable definitions added to the JIT based on their symbol names.; As noted above, lookup will implicitly trigger compilation for any symbol; that has not already been compiled. Our lookup method calls through to; `ExecutionSession::lookup`, passing in a list of dylibs to search (in our case; just the main dylib), and the symbol name to search for, with a twist: We have; to *mangle* the name of the symbol we're searching for first. The ORC JIT; components use mangled symbols internally the same way a static compiler and; linker would, rather than using plain IR symbol names. This allows JIT'd code; to interoperate easily with precompiled code in the application or shared; libraries. The kind of mangling will depend on the DataLayout, which in turn; depends on the target platform. To allow us to remain portable and search based; on the un-mangled name,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst:11309,concurren,concurrent,11309,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,1,['concurren'],['concurrent']
Performance,"ng `Alias`, it is now possible to register homonymous aliases (alternative column names) in different branches of the computation graph, in line with the behavior of `Define` (until now, aliases were required to be unique in the whole computaton graph).; - The `Histo*D` methods now support the combination of scalar values and vector-like weight values. For each entry, the histogram is filled once for each weight, always with the same scalar value.; - The `Histo*D` methods do not work on columns of type `std::string` anymore. They used to fill the histogram with the integer value corresponding to each of the characters in the string. Please use `Fill` with a custom class to recover the old behavior if that was what was desired. ### Other improvements. - The scaling to a large amount of threads of computation graphs with many simple `Filter`s or `Define`s has been greatly improved, see also [this talk](https://indico.cern.ch/event/1036730/#1-a-performance-study-of-the-r) for more details; - The output format of `Display` has been significantly improved.; - The `Fill` method now correctly supports user-defined classes with arbitrary `Fill` signatures (see [#9428](https://github.com/root-project/root/issues/9428)). ### Experimental Distributed RDataFrame. The distributed RDataFrame module has been improved. Now it supports sending RDataFrame tasks to a [Dask](https://dask.org/) scheduler. Through Dask, RDataFrame can be also scaled to a cluster of machines managed through a batch system like HTCondor or Slurm. Here is an example:. ```python; import ROOT; from dask.distributed import Client; RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame. # In a Python script the Dask client needs to be initalized in a context; # Jupyter notebooks / Python session don't need this; if __name__ == ""__main__"":; client = Client(""SCHEDULER_ADDRESS""); df = RDataFrame(""mytree"",""myfile.root"", daskclient=client); # Proceed as usual; df.Define(""x"",""someoperation"").Histo1D(""x""); ```.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:9967,perform,performance-study-of-the-r,9967,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['perform'],['performance-study-of-the-r']
Performance,"ng ``-fprebuilt-module-path`` and ``-fprebuilt-implicit-modules``. .. code-block:: sh. rm -rf prebuilt; mkdir prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -DENABLE_A; find prebuilt -name ""*.pcm""; # prebuilt/1AYBIGPM8R2GA/A-3L1K4LUA6O31.pcm; # prebuilt/1AYBIGPM8R2GA/B-3L1K4LUA6O31.pcm; # prebuilt/VH0YZMF1OIRK/A-3L1K4LUA6O31.pcm; # prebuilt/VH0YZMF1OIRK/B-3L1K4LUA6O31.pcm; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -DENABLE_A. Finally we want to allow implicit modules for configurations that were not prebuilt. When using the clang driver a module cache path is implicitly selected. Using ``-cc1``, we simply add use the ``-fmodules-cache-path`` option. .. code-block:: sh. clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -fmodules-cache-path=cache; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -fmodules-cache-path=cache -DENABLE_A; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -fprebuilt-implicit-modules -fmodules-cache-path=cache -DENABLE_A -DOTHER_OPTIONS. This way, a single directory containing multiple variants of modules can be prepared and reused. The options configuring the module cache are independent of other options. Module Semantics; ================. Modules are modeled as if each submodule were a separate translation unit, and a module import makes names from the other translation unit visible. Each submodule starts with a new preprocessor state and an empty translation un",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:23359,cache,cache-path,23359,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['cache'],['cache-path']
Performance,"ng a Gaussian distribution. More examples like the one above are; distributed with ROOT under the `$ROOTSYS/tutorials` directory. ``` {.cpp}; # Example: displaying a ROOT histogram from Python; from ROOT import gRandom,TCanvas,TH1F. c1 = TCanvas('c1','Example',200,10,700,500); hpx = TH1F('hpx','px',100,-4,4). for i in xrange(25000):; px = gRandom.Gaus(); hpx.Fill(px). hpx.Draw(); c1.Update(); ```. ### Access to Python from ROOT. Access to Python objects from Cling is not completely fleshed out.; Currently, ROOT objects and built-in types can cross the boundary; between the two interpreters, but other objects are much more; restricted. For example, for a Python object to cross, it has to be a; class instance, and its class has to be known to Cling first (i.e. the; class has to cross first, before the instance can). All other; cross-coding is based on strings that are run on the Python interpreter; and vise-versa. With the ROOT v4.00/06 and later, the **`TPython`** class will be loaded; automatically on use, for older editions, the `libPyROOT.so` needs to be; loaded first before use. It is possible to switch between interpreters; by calling **`TPython::Prompt()`** on the ROOT side, while returning with; `^D` (`EOF`). State is preserved between successive switches, and string; based cross calls can nest as long as shared resources are properly; handled. ``` {.cpp}; // Example: accessing the Python interpreter from ROOT; // either load PyROOT explicitly or rely on auto-loading; root[] gSystem->Load( ""libPyROOT"" );; root[] TPython::Exec(""print1+1"");; 2. // create a TBrowser on the Python side, and transfer it back and forth; root[] TBrowser* b = (void*)TPython::Eval(""ROOT.TBrowser()"");; (class TObject*)0x8d1daa0; root[] TPython::Bind(b,""b"");. // builtin variables can cross-over (after the call i==2); root[] int i = TPython::Eval( ""1+1"" );; root[] i; (int)2; ```. ### Installation. There are several ways of obtaining `PyROOT`, and which is best depends; on your specific si",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:4517,load,loaded,4517,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['load'],['loaded']
Performance,"ng and optimizations for the specific C++ standard; library function in namespace ``std``. For example,; ``-fno-builtin-std-move_if_noexcept`` removes any special handling for the; :cpp:func:`std::move_if_noexcept` library function. For C standard library functions that the C++ standard library also provides; in namespace ``std``, use :option:`-fno-builtin-\<function\>` instead. .. option:: -fmath-errno. Indicate that math functions should be treated as updating :c:data:`errno`. .. option:: -fpascal-strings. Enable support for Pascal-style strings with ""\\pfoo"". .. option:: -fms-extensions. Enable support for Microsoft extensions. .. option:: -fmsc-version=. Set ``_MSC_VER``. When on Windows, this defaults to either the same value as; the currently installed version of cl.exe, or ``1933``. Not set otherwise. .. option:: -fborland-extensions. Enable support for Borland extensions. .. option:: -fwritable-strings. Make all string literals default to writable. This disables uniquing of; strings and other optimizations. .. option:: -flax-vector-conversions, -flax-vector-conversions=<kind>, -fno-lax-vector-conversions. Allow loose type checking rules for implicit vector conversions.; Possible values of <kind>:. - ``none``: allow no implicit conversions between vectors; - ``integer``: allow implicit bitcasts between integer vectors of the same; overall bit-width; - ``all``: allow implicit bitcasts between any vectors of the same; overall bit-width. <kind> defaults to ``integer`` if unspecified. .. option:: -fblocks. Enable the ""Blocks"" language feature. .. option:: -fobjc-abi-version=version. Select the Objective-C ABI version to use. Available versions are 1 (legacy; ""fragile"" ABI), 2 (non-fragile ABI 1), and 3 (non-fragile ABI 2). .. option:: -fobjc-nonfragile-abi-version=<version>. Select the Objective-C non-fragile ABI version to use by default. This will; only be used as the Objective-C ABI when the non-fragile ABI is enabled; (either via :option:`-fobjc-nonfragile-ab",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:7671,optimiz,optimizations,7671,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['optimiz'],['optimizations']
Performance,"ng dir. RFNrules No 2000  RFF: Mximum number of rules. RFNendnodes No 4  RFF: Average number of end nodes. Configuration options for MVA method :. Configuration options reference for MVA method: Likelihood. Option Array Default value Predefined values Description. V No False  Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None  List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False  Print method-specific help message. CreateMVAPdfs No False  Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False  Events with negative weights are ignored in the training (but are included for testing and performance evaluation). TransformOutput No False  Transform likelihood output by inverse sigmoid function. Configuration options for MVA method :. Configuration options reference for MVA method: MLP. Option Array Default value Predefined values Description. NCycles No 500  Number of training cycles. HiddenLayers No N,N-1  Specification of hidden layer architecture. NeuronType No sigmoid  Neuron activation function type. RandomSeed No 1  Random seed for initial synapse weights (0 means unique seed for each run; default value '1'). EstimatorType No MSE MSE, CE, linear, sigmoid, tanh, radial MSE (Mean Square Estimator) for Gaussian Likelihood or CE(Cross-Entropy) for Bernoulli Likelihood. NeuronInputType No sum sum, sqsum, abssum Neuron input function type. V No False  Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verb",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:20674,perform,performance,20674,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['perform'],['performance']
Performance,"ng icache pollution].; 2. Declaring a function nothrow causes catch blocks to be added to every; call that isnot provably nothrow. This makes them very slow.; 3. Extra extraneous exception edges reduce the opportunity for code; motion.; 4. EH is typically implemented with large lookup tables. Ours is going to; be much smaller (than the ""standard"" way of doing it) to start with,; but eliminating it entirely would be nice. :); 5. It is physically impossible to correctly put (accurate, correct); exception specifications on generic, templated code. But it is trivial; to analyze instantiations of said code.; 6. Most large C++ programs throw few exceptions. Most well designed; programs only throw exceptions in specific planned portions of the; code. Given our _planned_ model of handling exceptions, all of this would be; pretty trivial to eliminate through some pretty simplistic interprocedural; analysis. The DCE factor alone could probably be pretty significant. The; extra code motion opportunities could also be exploited though... Additionally, this optimization can be implemented in a straight forward; conservative manner, allowing libraries to be optimized or individual; files even (if there are leaf functions visible in the translation unit; that are called). I think it's a reasonable optimization that hasn't really been addressed; (because assembly is way too low level for this), and could have decent; payoffs... without being a overly complex optimization. After I wrote all of that, I found this page that is talking about; basically the same thing I just wrote, except that it is translation unit; at a time, tree based approach:; http://www.ocston.org/~jls/ehopt.html. but is very useful from ""expected gain"" and references perspective. Note; that their compiler is apparently unable to inline functions that use; exceptions, so there numbers are pretty worthless... also our results; would (hopefully) be better because it's interprocedural... What do you think?. -Chris. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-09-18-OptimizeExceptions.txt:1656,optimiz,optimization,1656,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-09-18-OptimizeExceptions.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-09-18-OptimizeExceptions.txt,4,['optimiz'],"['optimization', 'optimized']"
Performance,"ng of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a dataset URI containign wild; cards will return a grand dataset sum of all the datasets matching the; URI.; Add options to get a list of all dataset registered names; from ScanDataSets (option kList; the result is a TMap of {TObjString,; TObjString} with the second TObjString empty).Improved version of the PQ2 scripts; the scripts now invoke a dedicated ROOT application (named pq2) available under $ROOTSYS/bin .Add; support for recursive reading of group config files via the 'include; sub-file' directive. This allows to have a common part and, for; example, customize differently the quotas.Fix an issue with TTreeFriends. New tutorial showing how to usefriends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings.In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:5870,Optimiz,Optimize,5870,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,1,['Optimiz'],['Optimize']
Performance,"ng on language defaults.; If the actual block or workgroup size exceeds the limit at any point during; the execution, the behavior is undefined. For example, even if there is; only one active thread but the thread local id exceeds the limit, the; behavior is undefined. ""amdgpu-implicitarg-num-bytes""=""n"" Number of kernel argument bytes to add to the kernel; argument block size for the implicit arguments. This; varies by OS and language (for OpenCL see; :ref:`opencl-kernel-implicit-arguments-appended-for-amdhsa-os-table`).; ""amdgpu-num-sgpr""=""n"" Specifies the number of SGPRs to use. Generated by; the ``amdgpu_num_sgpr`` CLANG attribute [CLANG-ATTR]_.; ""amdgpu-num-vgpr""=""n"" Specifies the number of VGPRs to use. Generated by the; ``amdgpu_num_vgpr`` CLANG attribute [CLANG-ATTR]_.; ""amdgpu-waves-per-eu""=""m,n"" Specify the minimum and maximum number of waves per; execution unit. Generated by the ``amdgpu_waves_per_eu``; CLANG attribute [CLANG-ATTR]_. This is an optimization hint,; and the backend may not be able to satisfy the request. If; the specified range is incompatible with the function's; ""amdgpu-flat-work-group-size"" value, the implied occupancy; bounds by the workgroup size takes precedence. ""amdgpu-ieee"" true/false. GFX6-GFX11 Only; Specify whether the function expects the IEEE field of the; mode register to be set on entry. Overrides the default for; the calling convention.; ""amdgpu-dx10-clamp"" true/false. GFX6-GFX11 Only; Specify whether the function expects the DX10_CLAMP field of; the mode register to be set on entry. Overrides the default; for the calling convention. ""amdgpu-no-workitem-id-x"" Indicates the function does not depend on the value of the; llvm.amdgcn.workitem.id.x intrinsic. If a function is marked with this; attribute, or reached through a call site marked with this attribute,; the value returned by the intrinsic is undefined. The backend can; generally infer this during code generation, so typically there is no; benefit to frontends marking fun",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:47605,optimiz,optimization,47605,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['optimiz'],['optimization']
Performance,"ng out of bounds. Can I compare two values computed with GEPs?; --------------------------------------------. Yes. If both addresses are within the same allocated object, or; one-past-the-end, you'll get the comparison result you expect. If either is; outside of it, integer arithmetic wrapping may occur, so the comparison may not; be meaningful. Can I do GEP with a different pointer type than the type of the underlying object?; ----------------------------------------------------------------------------------. Yes. There are no restrictions on bitcasting a pointer value to an arbitrary; pointer type. The types in a GEP serve only to define the parameters for the; underlying integer computation. They need not correspond with the actual type of; the underlying object. Furthermore, loads and stores don't have to use the same types as the type of; the underlying object. Types in this context serve only to specify memory size; and alignment. Beyond that there are merely a hint to the optimizer indicating; how the value will likely be used. Can I cast an object's address to integer and add it to null?; -------------------------------------------------------------. You can compute an address that way, but if you use GEP to do the add, you can't; use that pointer to actually access the object, unless the object is managed; outside of LLVM. The underlying integer computation is sufficiently defined; null has a defined; value --- zero --- and you can add whatever value you want to it. However, it's invalid to access (load from or store to) an LLVM-aware object; with such a pointer. This includes ``GlobalVariables``, ``Allocas``, and objects; pointed to by noalias pointers. If you really need this functionality, you can do the arithmetic with explicit; integer instructions, and use inttoptr to convert the result to an address. Most; of GEP's special aliasing rules do not apply to pointers computed from ptrtoint,; arithmetic, and inttoptr sequences. Can I compute the distance b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:15309,optimiz,optimizer,15309,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['optimiz'],['optimizer']
Performance,"ng rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23556,load,loaded,23556,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['load'],['loaded']
Performance,"ng s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - system *none* 1. buffer_wbl2 sc0=1 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 1. s_waitcnt l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:327897,load,load,327897,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['cache', 'load']","['cache', 'load']"
Performance,"ng the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4461,optimiz,optimizations,4461,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,3,"['optimiz', 'perform']","['optimizations', 'perform']"
Performance,"ng this approach:; 1. Many loads on x86 are folded into other instructions. Separating them would; add very significant and costly register pressure with prohibitive; performance cost.; 1. Loads may not target a general purpose register requiring extra instructions; to map the state value into the correct register class, and potentially more; expensive instructions to mask the value in some way.; 1. The flags registers on x86 are very likely to be live, and challenging to; preserve cheaply.; 1. There are many more values loaded than pointers & indices used for loads. As; a consequence, hardening the result of a load requires substantially more; instructions than hardening the address of the load (see below). Despite these challenges, hardening the result of the load critically allows; the load to proceed and thus has dramatically less impact on the total; speculative / out-of-order potential of the execution. There are also several; interesting techniques to try and mitigate these challenges and make hardening; the results of loads viable in at least some cases. However, we generally; expect to fall back when unprofitable from hardening the loaded value to the; next approach of hardening the address itself. ###### Loads folded into data-invariant operations can be hardened after the operation. The first key to making this feasible is to recognize that many operations on; x86 are ""data-invariant"". That is, they have no (known) observable behavior; differences due to the particular input data. These instructions are often used; when implementing cryptographic primitives dealing with private key data; because they are not believed to provide any side-channels. Similarly, we can; defer hardening until after them as they will not in-and-of-themselves; introduce a speculative execution side-channel. This results in code sequences; that look like:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:24882,load,loads,24882,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance,"ng to stop after this step. This is; the default when the input is a header file. * **IR generation**: This converts the source-level intermediate representation; into an optimizer-specific intermediate representation (IR); for Clang, this; is LLVM IR.; The ``-emit-llvm`` flag instructs Clang to stop after this step. If combined; with ``-S``, Clang will produce textual LLVM IR; otherwise, it will produce; LLVM IR bitcode. * **Compiler backend**: This converts the intermediate representation; into target-specific assembly code.; The ``-S`` flag instructs Clang to stop after this step. * **Assembler**: This converts target-specific assembly code into; target-specific machine code object files.; The ``-c`` flag instructs Clang to stop after this step. * **Linker**: This combines multiple object files into a single image; (either a shared object or an executable). Clang provides all of these pieces other than the linker. When multiple; steps are performed by the same tool, it is common for the steps to be; fused together to avoid creating intermediate files. When given an output of one of the above steps as an input, earlier steps; are skipped (for instance, a ``.s`` file input will be assembled and linked). The Clang driver can be invoked with the ``-###`` flag (this argument will need; to be escaped under most shells) to see which commands it would run for the; above steps, without running them. The ``-v`` (verbose) flag will print the; commands in addition to running them. Clang frontend; --------------. The Clang frontend (``clang -cc1``) is used to compile C family languages. The; command-line interface of the frontend is considered to be an implementation; detail, intentionally has no external documentation, and is subject to change; without notice. Language frontends for other languages; --------------------------------------. Clang can be provided with inputs written in non-C-family languages. In such; cases, an external tool will be used to compile the input. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst:2616,perform,performed,2616,interpreter/llvm-project/clang/docs/Toolchain.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Toolchain.rst,1,['perform'],['performed']
Performance,"ng you use, be careful to collect profiles; by running your code with inputs that are representative of the typical; behavior. Code that is not exercised in the profile will be optimized as if it; is unimportant, and the compiler may make poor optimization choices for code; that is disproportionately used while profiling. Differences Between Sampling and Instrumentation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Although both techniques are used for similar purposes, there are important; differences between the two:. 1. Profile data generated with one cannot be used by the other, and there is no; conversion tool that can convert one to the other. So, a profile generated; via ``-fprofile-generate`` or ``-fprofile-instr-generate`` must be used with; ``-fprofile-use`` or ``-fprofile-instr-use``. Similarly, sampling profiles; generated by external profilers must be converted and used with ``-fprofile-sample-use``; or ``-fauto-profile``. 2. Instrumentation profile data can be used for code coverage analysis and; optimization. 3. Sampling profiles can only be used for optimization. They cannot be used for; code coverage analysis. Although it would be technically possible to use; sampling profiles for code coverage, sample-based profiles are too; coarse-grained for code coverage purposes; it would yield poor results. 4. Sampling profiles must be generated by an external tool. The profile; generated by that tool must then be converted into a format that can be read; by LLVM. The section on sampling profilers describes one of the supported; sampling profile formats. Using Sampling Profilers; ^^^^^^^^^^^^^^^^^^^^^^^^. Sampling profilers are used to collect runtime information, such as; hardware counters, while your application executes. They are typically; very efficient and do not incur a large runtime overhead. The; sample data collected by the profiler can be used during compilation; to determine what the most executed areas of the code are. Using the data from a sa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:91469,optimiz,optimization,91469,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance,ng-tools-extra/clang-tidy/objc/NSInvocationArgumentLifetimeCheck.h; clang-tools-extra/clang-tidy/objc/PropertyDeclarationCheck.h; clang-tools-extra/clang-tidy/objc/SuperSelfCheck.cpp; clang-tools-extra/clang-tidy/objc/SuperSelfCheck.h; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.cpp; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.h; clang-tools-extra/clang-tidy/openmp/OpenMPTidyModule.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.h; clang-tools-extra/clang-tidy/performance/FasterStringFindCheck.cpp; clang-tools-extra/clang-tidy/performance/ForRangeCopyCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.h; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.h; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.cpp; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.h; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.cpp; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.h; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.cpp; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.h; clang-tools-extra/clang-tidy/performance/PerformanceTidyModule.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.h; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.cpp; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.h; clan,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:65141,perform,performance,65141,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['perform'],['performance']
Performance,"ng; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229042,load,load,229042,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"ng; the cache. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. load atomic acquire - agent - generic 1. flat_load sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load sc0=1 sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_inv.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acqui",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:298611,cache,caches,298611,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"nglethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic sc1=1; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load sc0=1; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_inv. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:296062,load,load,296062,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ngs; ================. In order to achieve a balance between performance and necessary guarantees,; there are six levels of atomicity. They are listed in order of strength; each; level includes all the guarantees of the previous level except for; Acquire/Release. (See also `LangRef Ordering <LangRef.html#ordering>`_.). .. _NotAtomic:. NotAtomic; ---------. NotAtomic is the obvious, a load or store which is not atomic. (This isn't; really a level of atomicity, but is listed here for comparison.) This is; essentially a regular load or store. If there is a race on a given memory; location, loads from that location return undef. Relevant standard; This is intended to match shared variables in C/C++, and to be used in any; other context where memory access is necessary, and a race is impossible. (The; precise definition is in `LangRef Memory Model <LangRef.html#memmodel>`_.). Notes for frontends; The rule is essentially that all memory accessed with basic loads and stores; by multiple threads should be protected by a lock or other synchronization;; otherwise, you are likely to run into undefined behavior. If your frontend is; for a ""safe"" language like Java, use Unordered to load and store any shared; variable. Note that NotAtomic volatile loads and stores are not properly; atomic; do not try to use them as a substitute. (Per the C/C++ standards,; volatile does provide some limited guarantees around asynchronous signals, but; atomics are generally a better solution.). Notes for optimizers; Introducing loads to shared variables along a codepath where they would not; otherwise exist is allowed; introducing stores to shared variables is not. See; `Optimization outside atomic`_. Notes for code generation; The one interesting restriction here is that it is not allowed to write to; bytes outside of the bytes relevant to a store. This is mostly relevant to; unaligned stores: it is not allowed in general to convert an unaligned store; into two aligned stores of the same width as",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:6584,load,loads,6584,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['load'],['loads']
Performance,"nherit; from the double slider widgets and allow easy selection of a range and a; pointer value. The pointer position can be constrained into the selected; range or can be relative to it. ![](pictures/0300021D.png). To change the slider range value press the left mouse button near to the; left/right (top/bottom) edges of the slider. To change both values; simultaneously press the mouse button near to the slider center. To; change pointer value press the mouse on the pointer and drag it to the; desired position. ``` {.cpp}; fSlider = new TGTripleHSlider(parent,100,kDoubleScaleBoth,kSLD_ID,; kHorizontalFrame);; parent->AddFrame(fSlider,new TGLayoutHints(kLHintsExpandX,5,5,5,5));; fSlider->SetConstrained(kTRUE);; fSlider->SetRange(rmin, rmax);; fSlider->SetPosition(pmin, pmax);; fSlider ->SetPointerPosition(pvalue);; ```. ### Progress Bars. A progress bar is a widget that shows that an operation is in progress; and how much time is left. It is a long rectangular bar, initially; empty, that fills with a color as a process is being performed. The; filled-in area indicates the percentage of the process that has been; completed. You should use this widget for waits exceeding `one minute`.; For a very time consuming operation it is better to break the operation; into subtasks and provide a progress bar for each of them. ![](pictures/0200021E.jpg). A progress bar may be oriented horizontally or vertically. The; horizontally oriented progress bar fills with a color from left to; right; the vertically oriented - from bottom to top. A percent complete; message provides an indication of the completed part of the process. It; is a good practice to include some descriptive text of the process to; keep users informed and entertained while they are waiting for process; completion. The picture below shows the progress bars you can create using the; classes **`TGProgressBar`**, **`TGHProgressBar`**, and; **`TGHProgressBar`**. ``` {.cpp}; // vertical frame with three horizontal progress",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md:87946,perform,performed,87946,documentation/users-guide/WritingGUI.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/WritingGUI.md,1,['perform'],['performed']
Performance,"nitial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD excep",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:15508,load,load,15508,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,1,['load'],['load']
Performance,"nition Rule"" is supported by source; language). Keeps first type definition and removes other definitions,; potentially significantly reducing the size of output debug info. That option is enabled by default. .. option:: --help, -h. Print a summary of command line options. .. option:: --no-garbage-collection. Disable :option:`--garbage-collection`. .. option:: --no-odr-deduplication. Disable :option:`--odr-deduplication`. .. option:: --no-separate-debug-file. Disable :option:`--separate-debug-file`. .. option:: --num-threads=<n>, -j. Specifies the maximum number (`n`) of simultaneous threads to use; for processing. .. option:: --separate-debug-file. Generate separate file containing output debug info. Using; :program:`llvm-dwarfutil` with that option equals to the; following set of commands:. .. code-block:: console. :program:`llvm-objcopy` --only-keep-debug in-file out-file.debug; :program:`llvm-objcopy` --strip-debug in-file out-file; :program:`llvm-objcopy` --add-gnu-debuglink=out-file.debug out-file. .. option:: --tombstone=<value>. <value> can be one of the following values:. - `bfd`: zero for all addresses and [1,1] for DWARF v4 (or less) address ranges and exec. - `maxpc`: -1 for all addresses and -2 for DWARF v4 (or less) address ranges. - `universal`: both `bfd` and `maxpc`. - `exec`: match with address ranges of executable sections. The value `universal` is used by default. .. option:: --verbose. Enable verbose logging. This option disables multi-thread mode. .. option:: --verify. Run the DWARF verifier on the output DWARF debug info. .. option:: --version. Print the version of this program. SUPPORTED FORMATS; -----------------. The following formats are currently supported by :program:`llvm-dwarfutil`:. ELF. EXIT STATUS; -----------. :program:`llvm-dwarfutil` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-dwarfutil/>.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-dwarfutil.rst:2752,multi-thread,multi-thread,2752,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-dwarfutil.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-dwarfutil.rst,1,['multi-thread'],['multi-thread']
Performance,"nition of the keys included in that map.; =================== ============== ========= ======================================================================. .. .. table:: AMDPAL Code Object Pipeline Metadata Map; :name: amdgpu-amdpal-code-object-pipeline-metadata-map-table. ====================================== ============== ========= ===================================================; String Key Value Type Required? Description; ====================================== ============== ========= ===================================================; "".name"" string Source name of the pipeline.; "".type"" string Pipeline type, e.g. VsPs. Values include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, used for; e.g. pipeline cache lookup. The value is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for the definition of the keys included in that; map.; "".hardware_stages"" map Per-hardware stage metadata. See; :ref:`amdgpu-amdpal-code-object-hardware-stage-map-table`; for the definition of the keys included in that; map.; "".shader_functions"" map Per-shader function metadata. See; :ref:`amdgpu-amdpal-code-object-shader-function-map-table`; for the definition of the keys included in that; map.; "".registers"" map Required Hardware register configuration. See; :ref:`amdgpu-amdpal-code-object-register-map-table`; for the definition of the keys included in that; map.; "".user_data_limit"" integer Number of user data entries accessed by this; pipeline.; "".spill_threshold"" integer The user data spill threshold. 0xFFFF for; NoUserDataSpilling.; "".uses_viewport_array_index"" boolean I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:403969,cache,cache,403969,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"nits that do not include the definition. As SSA values, global variables define pointer values that are in scope; (i.e. they dominate) all basic blocks in the program. Global variables; always define a pointer to their ""content"" type because they describe a; region of memory, and all memory objects in LLVM are accessed through; pointers. Global variables can be marked with ``unnamed_addr`` which indicates; that the address is not significant, only the content. Constants marked; like this can be merged with other constants if they have the same; initializer. Note that a constant with significant address *can* be; merged with a ``unnamed_addr`` constant, the result being a constant; whose address is significant. If the ``local_unnamed_addr`` attribute is given, the address is known to; not be significant within the module. A global variable may be declared to reside in a target-specific; numbered address space. For targets that support them, address spaces; may affect how optimizations are performed and/or what target; instructions are used to access the variable. The default address space; is zero. The address space qualifier must precede any other attributes. LLVM allows an explicit section to be specified for globals. If the; target supports it, it will emit globals to the section specified.; Additionally, the global can placed in a comdat if the target has the necessary; support. External declarations may have an explicit section specified. Section; information is retained in LLVM IR for targets that make use of this; information. Attaching section information to an external declaration is an; assertion that its definition is located in the specified section. If the; definition is located in a different section, the behavior is undefined. LLVM allows an explicit code model to be specified for globals. If the; target supports it, it will emit globals in the code model specified,; overriding the code model used to compile the translation unit.; The allowed values ar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:32736,optimiz,optimizations,32736,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['optimiz', 'perform']","['optimizations', 'performed']"
Performance,"nk the object file produced by our compiler. So far we have learned how to optimize and compile our LLVM IR, but we have; not focused on when compilation happens. Our current REPL optimizes and; compiles each function as soon as it is referenced by any other code,; regardless of whether it is ever called at runtime. In the next chapter we; will introduce a fully lazy compilation, in which functions are not compiled; until they are first called at run-time. At this point the trade-offs get much; more interesting: the lazier we are, the quicker we can start executing the; first function, but the more often we will have to pause to compile newly; encountered functions. If we only code-gen lazily, but optimize eagerly, we; will have a longer startup time (as everything is optimized at that time) but; relatively short pauses as each function just passes through code-gen. If we; both optimize and code-gen lazily we can start executing the first function; more quickly, but we will have longer pauses as each function has to be both; optimized and code-gen'd when it is first executed. Things become even more; interesting if we consider interprocedural optimizations like inlining, which; must be performed eagerly. These are complex trade-offs, and there is no; one-size-fits all solution to them, but by providing composable layers we leave; the decisions to the person implementing the JIT, and make it easy for them to; experiment with different configurations. `Next: Adding Per-function Lazy Compilation <BuildingAJIT3.html>`_. Full Code Listing; =================. Here is the complete code listing for our running example with an; IRTransformLayer added to enable optimization. To build this example, use:. .. code-block:: bash. # Compile; clang++ -g toy.cpp `llvm-config --cxxflags --ldflags --system-libs --libs core orcjit native` -O3 -o toy; # Run; ./toy. Here is the code:. .. literalinclude:: ../../examples/Kaleidoscope/BuildingAJIT/Chapter2/KaleidoscopeJIT.h; :language: c++; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:11472,optimiz,optimizations,11472,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,3,"['optimiz', 'perform']","['optimization', 'optimizations', 'performed']"
Performance,"nk the store. We need partially dead store sinking. //===---------------------------------------------------------------------===//. [LOAD PRE CRIT EDGE SPLITTING]. GCC PR37166: Sinking of loads prevents SROA'ing the ""g"" struct on the stack; leading to excess stack traffic. This could be handled by GVN with some crazy; symbolic phi translation. The code we get looks like (g is on the stack):. bb2:		; preds = %bb1; ..; 	%9 = getelementptr %struct.f* %g, i32 0, i32 0		; 	store i32 %8, i32* %9, align bel %bb3. bb3:		; preds = %bb1, %bb2, %bb; 	%c_addr.0 = phi %struct.f* [ %g, %bb2 ], [ %c, %bb ], [ %c, %bb1 ]; 	%b_addr.0 = phi %struct.f* [ %b, %bb2 ], [ %g, %bb ], [ %b, %bb1 ]; 	%10 = getelementptr %struct.f* %c_addr.0, i32 0, i32 0; 	%11 = load i32* %10, align 4. %11 is partially redundant, an in BB2 it should have the value %8. GCC PR33344 and PR35287 are similar cases. //===---------------------------------------------------------------------===//. [LOAD PRE]. There are many load PRE testcases in testsuite/gcc.dg/tree-ssa/loadpre* in the; GCC testsuite, ones we don't get yet are (checked through loadpre25):. [CRIT EDGE BREAKING]; predcom-4.c. [PRE OF READONLY CALL]; loadpre5.c. [TURN SELECT INTO BRANCH]; loadpre14.c loadpre15.c . actually a conditional increment: loadpre18.c loadpre19.c. //===---------------------------------------------------------------------===//. [LOAD PRE / STORE SINKING / SPEC HACK]. This is a chunk of code from 456.hmmer:. int f(int M, int *mc, int *mpp, int *tpmm, int *ip, int *tpim, int *dpp,; int *tpdm, int xmb, int *bp, int *ms) {; int k, sc;; for (k = 1; k <= M; k++) {; mc[k] = mpp[k-1] + tpmm[k-1];; if ((sc = ip[k-1] + tpim[k-1]) > mc[k]) mc[k] = sc;; if ((sc = dpp[k-1] + tpdm[k-1]) > mc[k]) mc[k] = sc;; if ((sc = xmb + bp[k]) > mc[k]) mc[k] = sc;; mc[k] += ms[k];; }; }. It is very profitable for this benchmark to turn the conditional stores to mc[k]; into a conditional move (select instr in IR) and allow the final store to do the; stor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:33431,load,load,33431,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['load']
Performance,"nker and the optimizer by sharing this information; during various linking phases. Phase 1 : Read LLVM Bitcode Files; ---------------------------------. The linker first reads all object files in natural order and collects symbol; information. This includes native object files as well as LLVM bitcode files.; To minimize the cost to the linker in the case that all .o files are native; object files, the linker only calls ``lto_module_create()`` when a supplied; object file is found to not be a native object file. If ``lto_module_create()``; returns that the file is an LLVM bitcode file, the linker then iterates over the; module using ``lto_module_get_symbol_name()`` and; ``lto_module_get_symbol_attribute()`` to get all symbols defined and referenced.; This information is added to the linker's global symbol table. The lto* functions are all implemented in a shared object libLTO. This allows; the LLVM LTO code to be updated independently of the linker tool. On platforms; that support it, the shared object is lazily loaded. Phase 2 : Symbol Resolution; ---------------------------. In this stage, the linker resolves symbols using global symbol table. It may; report undefined symbol errors, read archive members, replace weak symbols, etc.; The linker is able to do this seamlessly even though it does not know the exact; content of input LLVM bitcode files. If dead code stripping is enabled then the; linker collects the list of live symbols. Phase 3 : Optimize Bitcode Files; --------------------------------. After symbol resolution, the linker tells the LTO shared object which symbols; are needed by native object files. In the example above, the linker reports; that only ``foo1()`` is used by native object files using; ``lto_codegen_add_must_preserve_symbol()``. Next the linker invokes the LLVM; optimizer and code generators using ``lto_codegen_compile()`` which returns a; native object file creating by merging the LLVM bitcode files and applying; various optimization passes.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:6381,load,loaded,6381,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['load'],['loaded']
Performance,"nker developments on various; platforms, which is not the main focus of the link time optimizer. Finally,; this approach increases end user's build time due to the duplication of work; done by this separate tool and the linker itself. Multi-phase communication between ``libLTO`` and linker; =======================================================. The linker collects information about symbol definitions and uses in various; link objects which is more accurate than any information collected by other; tools during typical build cycles. The linker collects this information by; looking at the definitions and uses of symbols in native .o files and using; symbol visibility information. The linker also uses user-supplied information,; such as a list of exported symbols. LLVM optimizer collects control flow; information, data flow information and knows much more about program structure; from the optimizer's point of view. Our goal is to take advantage of tight; integration between the linker and the optimizer by sharing this information; during various linking phases. Phase 1 : Read LLVM Bitcode Files; ---------------------------------. The linker first reads all object files in natural order and collects symbol; information. This includes native object files as well as LLVM bitcode files.; To minimize the cost to the linker in the case that all .o files are native; object files, the linker only calls ``lto_module_create()`` when a supplied; object file is found to not be a native object file. If ``lto_module_create()``; returns that the file is an LLVM bitcode file, the linker then iterates over the; module using ``lto_module_get_symbol_name()`` and; ``lto_module_get_symbol_attribute()`` to get all symbols defined and referenced.; This information is added to the linker's global symbol table. The lto* functions are all implemented in a shared object libLTO. This allows; the LLVM LTO code to be updated independently of the linker tool. On platforms; that support it, the share",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:5367,optimiz,optimizer,5367,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['optimiz'],['optimizer']
Performance,"nking) them into the `test-suite/test-suite-externals/xxx` directory (example: `test-suite/test-suite-externals/speccpu2000`); - using a configuration option such as `-D TEST_SUITE_SPEC2000_ROOT=path/to/speccpu2000`. You can find further information in the respective README files such as; `test-suite/External/SPEC/README`. For the SPEC benchmarks you can switch between the `test`, `train` and; `ref` input datasets via the `TEST_SUITE_RUN_TYPE` configuration option.; The `train` dataset is used by default. Custom Suites; -------------. You can build custom suites using the test-suite infrastructure. A custom suite; has a `CMakeLists.txt` file at the top directory. The `CMakeLists.txt` will be; picked up automatically if placed into a subdirectory of the test-suite or when; setting the `TEST_SUITE_SUBDIRS` variable:. ```bash; % cmake -DTEST_SUITE_SUBDIRS=path/to/my/benchmark-suite ../test-suite; ```. Profile Guided Optimization; ---------------------------. Profile guided optimization requires to compile and run twice. First the; benchmark should be compiled with profile generation instrumentation enabled; and setup for training data. The lit runner will merge the profile files; using `llvm-profdata` so they can be used by the second compilation run. Example:; ```bash; # Profile generation run using LLVM IR PGO:; % cmake -DTEST_SUITE_PROFILE_GENERATE=ON \; -DTEST_SUITE_USE_IR_PGO=ON \; -DTEST_SUITE_RUN_TYPE=train \; ../test-suite; % make; % llvm-lit .; # Use the profile data for compilation and actual benchmark run:; % cmake -DTEST_SUITE_PROFILE_GENERATE=OFF \; -DTEST_SUITE_PROFILE_USE=ON \; -DTEST_SUITE_RUN_TYPE=ref \; .; % make; % llvm-lit -o result.json .; ```. To use Clang frontend's PGO instead of LLVM IR PGO, set `-DTEST_SUITE_USE_IR_PGO=OFF`. The `TEST_SUITE_RUN_TYPE` setting only affects the SPEC benchmark suites. Cross Compilation and External Devices; --------------------------------------. ### Compilation. CMake allows to cross compile to a different target ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:10005,optimiz,optimization,10005,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,1,['optimiz'],['optimization']
Performance,"nly``. .. option:: -f[no-]approx-func. Allow certain math function calls (such as ``log``, ``sqrt``, ``pow``, etc); to be replaced with an approximately equivalent set of instructions; or alternative math function calls. For example, a ``pow(x, 0.25)``; may be replaced with ``sqrt(sqrt(x))``, despite being an inexact result; in cases where ``x`` is ``-0.0`` or ``-inf``.; Defaults to ``-fno-approx-func``. .. option:: -f[no-]signed-zeros. Allow optimizations that ignore the sign of floating point zeros.; Defaults to ``-fsigned-zeros``. .. option:: -f[no-]associative-math. Allow floating point operations to be reassociated.; Defaults to ``-fno-associative-math``. .. option:: -f[no-]reciprocal-math. Allow division operations to be transformed into multiplication by a; reciprocal. This can be significantly faster than an ordinary division; but can also have significantly less precision. Defaults to; ``-fno-reciprocal-math``. .. option:: -f[no-]unsafe-math-optimizations. Allow unsafe floating-point optimizations.; ``-funsafe-math-optimizations`` also implies:. * ``-fapprox-func``; * ``-fassociative-math``; * ``-freciprocal-math``; * ``-fno-signed-zeros``; * ``-fno-trapping-math``; * ``-ffp-contract=fast``. ``-fno-unsafe-math-optimizations`` implies:. * ``-fno-approx-func``; * ``-fno-associative-math``; * ``-fno-reciprocal-math``; * ``-fsigned-zeros``; * ``-ftrapping-math``; * ``-ffp-contract=on``; * ``-fdenormal-fp-math=ieee``. There is ambiguity about how ``-ffp-contract``,; ``-funsafe-math-optimizations``, and ``-fno-unsafe-math-optimizations``; behave when combined. Explanation in :option:`-fno-fast-math` also applies; to these options. Defaults to ``-fno-unsafe-math-optimizations``. .. option:: -f[no-]finite-math-only. Allow floating-point optimizations that assume arguments and results are; not NaNs or +-Inf. ``-ffinite-math-only`` defines the; ``__FINITE_MATH_ONLY__`` preprocessor macro.; ``-ffinite-math-only`` implies:. * ``-fno-honor-infinities``; * ``-fno-honor-na",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:59272,optimiz,optimizations,59272,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,"nment> [, !invariant.group !<empty_node>]; !<nontemp_node> = !{ i32 1 }; !<empty_node> = !{}; !<deref_bytes_node> = !{ i64 <dereferenceable_bytes> }; !<align_node> = !{ i64 <value_alignment> }. Overview:; """""""""""""""""". The '``load``' instruction is used to read from memory. Arguments:; """""""""""""""""""". The argument to the ``load`` instruction specifies the memory address from which; to load. The type specified must be a :ref:`first class <t_firstclass>` type of; known size (i.e. not containing an :ref:`opaque structural type <t_opaque>`). If; the ``load`` is marked as ``volatile``, then the optimizer is not allowed to; modify the number or order of execution of this ``load`` with other; :ref:`volatile operations <volatile>`. If the ``load`` is marked as ``atomic``, it takes an extra :ref:`ordering; <ordering>` and optional ``syncscope(""<target-scope>"")`` argument. The; ``release`` and ``acq_rel`` orderings are not valid on ``load`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic loads. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemporal`` does not have any; defined semantics for atomic loads. The optional constant ``align`` argument specifies the alignment of the; operation (that is, the alignment of the memory address). It is the; responsibility of the code emitter to ensure that the alignment information is; correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value highe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:413292,load,loads,413292,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loads']
Performance,"nner loop vectorizer is; enhanced with a feature that allows it to vectorize epilogue loops with a; vectorization and unroll factor combination that makes it more likely for small; trip count loops to still execute in vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.k.a. superword-level parallelism) is; to combine similar independent instructions; into vector instructions. Memory accesses, arithmetic operations, comparison; operations, PHI-nodes, can all be vectorized using this technique. For example, the following function performs very similar operations on its; inputs (a1, b1) and (a2, b2). The basic-block vectorizer may combin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:12712,tune,tuned,12712,interpreter/llvm-project/llvm/docs/Vectorizers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst,1,['tune'],['tuned']
Performance,"no need; for your front-end to build SSA form: LLVM provides highly tuned and; well tested support for this, though the way it works is a bit; unexpected for some. Why is this a hard problem?; ===========================. To understand why mutable variables cause complexities in SSA; construction, consider this extremely simple C example:. .. code-block:: c. int G, H;; int test(_Bool Condition) {; int X;; if (Condition); X = G;; else; X = H;; return X;; }. In this case, we have the variable ""X"", whose value depends on the path; executed in the program. Because there are two different possible values; for X before the return instruction, a PHI node is inserted to merge the; two values. The LLVM IR that we want for this example looks like this:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.2 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.2; }. In this example, the loads from the G and H global variables are; explicit in the LLVM IR, and they live in the then/else branches of the; if statement (cond\_true/cond\_false). In order to merge the incoming; values, the X.2 phi node in the cond\_next block selects the right value; to use based on where control flow is coming from: if control flow comes; from the cond\_false block, X.2 gets the value of X.1. Alternatively, if; control flow comes from cond\_true, it gets the value of X.0. The intent; of this chapter is not to explain the details of SSA form. For more; information, see one of the many `online; references <http://en.wikipedia.org/wiki/Static_single_assignment_form>`_. The question for this article is ""who places the phi nodes when lowering; assignments to mutable variables?"". The issue here is that LLVM",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:2221,load,load,2221,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance,"no; older than the; value read by the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:254638,load,load,254638,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"node>`` corresponding to a metadata node with one; ``i64`` entry.; See ``dereferenceable_or_null`` metadata :ref:`dereferenceable_or_null; <md_dereferenceable_or_null>`. The optional ``!align`` metadata must reference a single metadata name; ``<align_node>`` corresponding to a metadata node with one ``i64`` entry.; The existence of the ``!align`` metadata on the instruction tells the; optimizer that the value loaded is known to be aligned to a boundary specified; by the integer value in the metadata node. The alignment must be a power of 2.; This is analogous to the ''align'' attribute on parameters and return values.; This metadata can only be applied to loads of a pointer type. If the returned; value is not appropriately aligned at runtime, a poison value is returned; instead. The optional ``!noundef`` metadata must reference a single metadata name; ``<empty_node>`` corresponding to a node with no entries. The existence of; ``!noundef`` metadata on the instruction tells the optimizer that the value; loaded is known to be :ref:`well defined <welldefinedvalues>`.; If the value isn't well defined, the behavior is undefined. If the ``!noundef``; metadata is combined with poison-generating metadata like ``!nonnull``,; violation of that metadata constraint will also result in undefined behavior. Semantics:; """""""""""""""""""". The location of memory pointed to is loaded. If the value being loaded; is of scalar type then the number of bytes read does not exceed the; minimum number of bytes needed to hold all bits of the type. For; example, loading an ``i24`` reads at most three bytes. When loading a; value of a type like ``i20`` with a size that is not an integral number; of bytes, the result is undefined if the value was not originally; written using a store of the same type.; If the value being loaded is of aggregate type, the bytes that correspond to; padding may be accessed but are ignored, because it is impossible to observe; padding from the loaded aggregate value.; If ``<",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:417769,optimiz,optimizer,417769,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['load', 'optimiz']","['loaded', 'optimizer']"
Performance,"non-canonical form target ID allows the target features to be; specified in any order. The canonical form target ID requires the target; features to be specified in alphabetic order. .. _amdgpu-target-id-v2-v3:. Code Object V2 to V3 Target ID; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. The target ID syntax for code object V2 to V3 is the same as defined in `Clang; Offload Bundler <https://clang.llvm.org/docs/ClangOffloadBundler.html>`_ except; when used in the :ref:`amdgpu-assembler-directive-amdgcn-target` assembler; directive and the bundle entry ID. In those cases it has the following BNF; syntax:. .. code::. <target-id> ::== <processor> ( ""+"" <target-feature> )*. Where a target feature is omitted if *Off* and present if *On* or *Any*. .. note::. The code object V2 to V3 cannot represent *Any* and treats it the same as; *On*. .. _amdgpu-embedding-bundled-objects:. Embedding Bundled Code Objects; ------------------------------. AMDGPU supports the HIP and OpenMP languages that perform code object embedding; as described in `Clang Offload Bundler; <https://clang.llvm.org/docs/ClangOffloadBundler.html>`_. .. note::. The target ID syntax used for code object V2 to V3 for a bundle entry ID; differs from that used elsewhere. See :ref:`amdgpu-target-id-v2-v3`. .. _amdgpu-address-spaces:. Address Spaces; --------------. The AMDGPU architecture supports a number of memory address spaces. The address; space names use the OpenCL standard names, with some additions. The AMDGPU address spaces correspond to target architecture specific LLVM; address space numbers used in LLVM IR. The AMDGPU address spaces are described in; :ref:`amdgpu-address-spaces-table`. Only 64-bit process address spaces are; supported for the ``amdgcn`` target. .. table:: AMDGPU Address Spaces; :name: amdgpu-address-spaces-table. ===================================== =============== =========== ================ ======= ============================; .. 64-Bit Process Address Space; -----------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:21004,perform,perform,21004,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['perform']
Performance,"non-split mode.; In non-split mode, the full event must be read in memory. The times; reported in the table correspond to complete I/O operations necessary to; deal with **machine independent binary files**. On **Linux**, this also; includes byte-swapping operations. The ROOT file allows for direct; access to any event in the file and direct access to any part of an; event when split=1. Note also that the uncompressed file generated with split=0 is 48.7; Mbytes and only 47.17 Mbytes for the option split=1. The difference in; size is due to the object identification mechanism overhead when the; event is written to a single buffer. This overhead does not exist in; split mode because the branch buffers are optimized for homogeneous data; types. You can run the test programs on your architecture. The program; `Event` will report the write performance. You can measure the read; performance by executing the scripts `eventa` and `eventb`. The; performance depends not only of the processor type, but also of the disk; devices (local, NFS, AFS, etc.). ## Chains; \index{tree!chains}. A **`TChain`** object is a list of ROOT files containing the same tree.; As an example, assume we have three files called; `file1.root, file2.root, file3.root`. Each file contains one tree called; ""`T`"". We can create a chain with the following statements:. ``` {.cpp}; TChain chain(""T""); // name of the tree is the argument; chain.Add(""file1.root"");; chain.Add(""file2.root"");; chain.Add(""file3.root"");; ```. The name of the **`TChain`** will be the same as the name of the tree;; in this case it will be `""T"". Note that two `objects can have the same; name as long as they are not histograms in the same directory, because; there, the histogram names are used to build a hash table. The class; **`TChain`** is derived from the class **`TTree`**. For example, to; generate a histogram corresponding to the attribute ""`x`"" in tree ""`T`""; by processing sequentially the three files of this chain, we can use the;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:140042,perform,performance,140042,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['perform'],['performance']
Performance,"non-static data members of Objective-C++ non-union class types; * Objective-C++ objects and arrays of dynamic storage duration created; with the ``new`` or ``new[]`` operators and destroyed with the; corresponding ``delete`` or ``delete[]`` operator. They are not followed automatically for these objects:. * objects of dynamic storage duration created in other memory, such as; that returned by ``malloc``; * union members. .. admonition:: Rationale. ARC must perform special operations when initializing an object and; when destroying it. In many common situations, ARC knows when an; object is created and when it is destroyed and can ensure that these; operations are performed correctly. Otherwise, however, ARC requires; programmer cooperation to establish its initialization invariants; because it is infeasible for ARC to dynamically infer whether they; are intact. For example, there is no syntactic difference in C between; an assignment that is intended by the programmer to initialize a variable; and one that is intended to replace the existing value stored there,; but ARC must perform one operation or the other. ARC chooses to always; assume that objects are initialized (except when it is in charge of; initializing them) because the only workable alternative would be to; ban all code patterns that could potentially be used to access; uninitialized memory, and that would be too limiting. In practice,; this is rarely a problem because programmers do not generally need to; work with objects for which the requirements are not handled; automatically. Note that dynamically-allocated Objective-C++ arrays of; nontrivially-ownership-qualified type are not ABI-compatible with non-ARC; code because the non-ARC code will consider the element type to be POD.; Such arrays that are ``new[]``'d in ARC translation units cannot be; ``delete[]``'d in non-ARC translation units and vice-versa. .. _arc.ownership.restrictions.pass_by_writeback:. Passing to an out parameter by writeback; ^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:47569,perform,perform,47569,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['perform']
Performance,"non-template) classes,; using double as the scalar type to avoid too large numerical errors. The; transformations are grouped in rotations (in 3 dimensions), Lorentz; transformations and Poincare transformations, which are; translation`/`rotation combinations. Each group has several members; which may model physically equivalent transformations but with different; internal representations. Transformation classes can operate on all type; of vectors by using the operator `() `or the operator `*` and the; transformations can be combined via the operator `*`. The available; transformations are:. - 3D rotation classes. - rotation described by a 3x3 matrix (**`ROOT::Math::Rotation3D`**). - rotation described by Euler angles (**`ROOT::Math::EulerAngles`**). - rotation described by a direction axis and an angle; (**`ROOT::Math::AxisAngle`**). - rotation described by a quaternion (**`ROOT::Math::Quaternion`**). - optimized rotation around `x` (**`ROOT::Math::RotationX`**), `y`; (**`ROOT::Math::RotationY`**) and `z` (**`ROOT::Math::RotationZ`**); and described by just one angle. - 3D transformation: we describe the transformations defined as a; composition between a rotation and a translation using the class; **`ROOT::Math::Transform3D`**. It is important to note that; transformations act differently on vectors and points. The vectors only; rotate, therefore when applying a transformation (rotation +; translation) on a vector, only the rotation operates while the; translation has no effect. The **`Transform3D`** class interface is; similar to the one used in the CLHEP Geometry package (class; <HepGeom::Transform3D>). - Lorentz rotation:. - generic Lorentz rotation described by a `4x4` matrix containing a 3D; rotation part and a boost part (class; **`ROOT::Math::LorentzRotation`**). - a pure boost in an arbitrary direction and described by a 4x4; symmetric matrix or 10 numbers (class **`ROOT::Math::Boost`**). - boost along the axis:` x `(**`ROOT::Math::BoostX`**),; `y `(**`ROO",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:73455,optimiz,optimized,73455,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['optimiz'],['optimized']
Performance,"none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store atomic/; atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_gl0_inv.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:370523,load,load,370523,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"not equal. - Metadata ``!1`` has the ID ``!""bar""`` and the value '37'. The; behavior if two or more ``!""bar""`` flags are seen is to use the value; '37'. - Metadata ``!2`` has the ID ``!""qux""`` and the value '42'. The; behavior if two or more ``!""qux""`` flags are seen is to emit a; warning if their values are not equal. - Metadata ``!3`` has the ID ``!""qux""`` and the value:. ::. !{ !""foo"", i32 1 }. The behavior is to emit an error if the ``llvm.module.flags`` does not; contain a flag with the ID ``!""foo""`` that has the value '1' after linking is; performed. Synthesized Functions Module Flags Metadata; -------------------------------------------. These metadata specify the default attributes synthesized functions should have.; These metadata are currently respected by a few instrumentation passes, such as; sanitizers. These metadata correspond to a few function attributes with significant code; generation behaviors. Function attributes with just optimization purposes; should not be listed because the performance impact of these synthesized; functions is small. - ""frame-pointer"": **Max**. The value can be 0, 1, or 2. A synthesized function; will get the ""frame-pointer"" function attribute, with value being ""none"",; ""non-leaf"", or ""all"", respectively.; - ""function_return_thunk_extern"": The synthesized function will get the; ``fn_return_thunk_extern`` function attribute.; - ""uwtable"": **Max**. The value can be 0, 1, or 2. If the value is 1, a synthesized; function will get the ``uwtable(sync)`` function attribute, if the value is 2,; a synthesized function will get the ``uwtable(async)`` function attribute. Objective-C Garbage Collection Module Flags Metadata; ----------------------------------------------------. On the Mach-O platform, Objective-C stores metadata about garbage; collection in a special section called ""image info"". The metadata; consists of a version number and a bitmask specifying what types of; garbage collection are supported (if any) by the file. If two",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:331437,optimiz,optimization,331437,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"not have to be run, do not change state, and; never need to be updated. This is not a normal type of transformation or; analysis, but can provide information about the current compiler configuration. Although this pass class is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various transformations. ``ImmutablePass``\ es never invalidate other transformations, are never; invalidated, and are never ""run"". .. _writing-an-llvm-pass-ModulePass:. The ``ModulePass`` class; ------------------------. The `ModulePass <https://llvm.org/doxygen/classllvm_1_1ModulePass.html>`_ class; is the most general of all superclasses that you can use. Deriving from; ``ModulePass`` indicates that your pass uses the entire program as a unit,; referring to function bodies in no predictable order, or adding and removing; functions. Because nothing is known about the behavior of ``ModulePass``; subclasses, no optimization can be done for their execution. A module pass can use function level passes (e.g. dominators) using the; ``getAnalysis`` interface ``getAnalysis<DominatorTree>(llvm::Function *)`` to; provide the function to retrieve analysis result for, if the function pass does; not require any module or immutable passes. Note that this can only be done; for functions for which the analysis ran, e.g. in the case of dominators you; should only ask for the ``DominatorTree`` for function definitions, not; declarations. To write a correct ``ModulePass`` subclass, derive from ``ModulePass`` and; override the ``runOnModule`` method with the following signature:. The ``runOnModule`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnModule(Module &M) = 0;. The ``runOnModule`` method performs the interesting work of the pass. It; should return ``true`` if the module was modified by the transformation and; ``false`` otherwise. .. _writing-an-llvm-pass-Cal",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:13107,optimiz,optimization,13107,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['optimiz'],['optimization']
Performance,"now does) issuing a compilation error. #### Template class names; Cling no longer supports refering to a class template instantiation of a; class template that has all default template parameter without the \<\>.; With:. ``` {.cpp}; template <typename T = int> class templt {};; ```. With Cling (and any standard compliant compiler), using `*templt<>*` is; allowed (but `*templt*` is not). #### Namespace prefix of template parameters; Given `namespace N { class A; template <typename T> class B;}`, the name; `N::B<N::A>` is no longer ""shortened"" to `N::B<A>`. This affects the forward; and backward compatibility of files. #### Implicit dynamic up-casts; CINT would perform automatic upcasts to derived classes under certain contexts:. ``` {.cpp}; TH1* h1 = hpx; TH1F* h1f = h1;; ```. Cling does not allow this anymore. We might add this feature later if demand exists ([ROOT-4802](https://sft.its.cern.ch/jira/browse/ROOT-4802)). #### Using symbols that are only available at runtime: load libFoo; foo(); CINT was processing macros line by line; Cling compiles code.; When calling a function (or in general using a symbol) that is provided by a library loaded at runtime,; Cling will in some cases report an unresolved symbol:. ``` {.cpp}; #include ""Event.h""; void dynload() {; gSystem->Load(""libEvent"");; new Event();; }; ```. You will currently have to provide a rootmap file for libEvent (which also requires include; guards for Event.h). This might get fixed in a later version ([ROOT-4691](https://sft.its.cern.ch/jira/browse/ROOT-4691)). #### Using identifiers that are only available at runtime: gROOT->LoadMacro(""foo.h""); foo(); CINT was processing macros line by line; Cling compiles code.; During this compilation, Cling will not see identifiers provided by `gROOT->LoadMacro()`.; While this will covered by dynamic scopes, they are currently too limited to handle this.; Please `#include` the header instead. ### TInterpreter. ### TInterpreter. `TInterpreter::GetCurrentMacroName()` has ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md:3746,load,load,3746,core/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md,1,['load'],['load']
Performance,"nputs. Semantics:; """""""""""""""""""". The '``llvm.cttz``' intrinsic counts the trailing (least significant); zeros in a variable, or within each element of a vector. If ``src == 0``; then the result is the size in bits of the type of ``src`` if; ``is_zero_poison == 0`` and ``poison`` otherwise. For example,; ``llvm.cttz(2) = 1``. .. _int_overflow:. .. _int_fshl:. '``llvm.fshl.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.fshl`` on any; integer bit width or any vector of integer elements. Not all targets; support all bit widths or vector types, however. ::. declare i8 @llvm.fshl.i8 (i8 %a, i8 %b, i8 %c); declare i64 @llvm.fshl.i64(i64 %a, i64 %b, i64 %c); declare <2 x i32> @llvm.fshl.v2i32(<2 x i32> %a, <2 x i32> %b, <2 x i32> %c). Overview:; """""""""""""""""". The '``llvm.fshl``' family of intrinsic functions performs a funnel shift left:; the first two values are concatenated as { %a : %b } (%a is the most significant; bits of the wide value), the combined value is shifted left, and the most; significant bits are extracted to produce a result that is the same size as the; original arguments. If the first 2 arguments are identical, this is equivalent; to a rotate left operation. For vector types, the operation occurs for each; element of the vector. The shift argument is treated as an unsigned amount; modulo the element size of the arguments. Arguments:; """""""""""""""""""". The first two arguments are the values to be concatenated. The third; argument is the shift amount. The arguments may be any integer type or a; vector with integer element type. All arguments and the return value must; have the same type. Example:; """""""""""""""". .. code-block:: text. %r = call i8 @llvm.fshl.i8(i8 %x, i8 %y, i8 %z) ; %r = i8: msb_extract((concat(x, y) << (z % 8)), 8); %r = call i8 @llvm.fshl.i8(i8 255, i8 0, i8 15) ; %r = i8: 128 (0b10000000); %r = call i8 @llvm.fshl.i8(i8 15, i8 15, i8 11) ; %r = i8: 120 (0b01111000); %r = call i8 @llvm.f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:596861,perform,performs,596861,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance,"ns a fully qualified path to the backtrace library.; # We need to remove the path and the 'lib' prefix, to make it look like a; # regular short library name, suitable for appending to a -l link flag.; get_filename_component(Backtrace_LIBFILE ${Backtrace_LIBRARIES} NAME_WE); STRING(REGEX REPLACE ""^lib"" """" Backtrace_LIBFILE ${Backtrace_LIBFILE}); set(system_libs ${system_libs} ${Backtrace_LIBFILE}); endif(); if( LLVM_ENABLE_TERMINFO ); set(imported_libs ${imported_libs} Terminfo::terminfo); endif(); set(system_libs ${system_libs} ${LLVM_ATOMIC_LIB}); set(system_libs ${system_libs} ${LLVM_PTHREAD_LIB}); if( UNIX AND NOT (BEOS OR HAIKU) ); set(system_libs ${system_libs} m); endif(); if( UNIX AND ${CMAKE_SYSTEM_NAME} MATCHES ""SunOS"" ); set(system_libs ${system_libs} kstat socket); endif(); if( FUCHSIA ); set(system_libs ${system_libs} zircon); endif(); if ( HAIKU ); add_compile_definitions(_BSD_SOURCE); set(system_libs ${system_libs} bsd network); endif(); endif( MSVC OR MINGW ). # Delay load shell32.dll if possible to speed up process startup.; set (delayload_flags); if (MSVC); # When linking with Swift, `swiftc.exe` is used as the linker drive rather; # than invoking `link.exe` directly. In such a case, the flags should be; # marked as `-Xlinker` to pass them directly to the linker. As a temporary; # workaround simply elide the delay loading.; set (delayload_flags $<$<NOT:$<LINK_LANGUAGE:Swift>>:delayimp -delayload:shell32.dll -delayload:ole32.dll>); endif(). # Link Z3 if the user wants to build it.; if(LLVM_WITH_Z3); set(system_libs ${system_libs} ${Z3_LIBRARIES}); endif(). # Override the C runtime allocator on Windows and embed it into LLVM tools & libraries; if(LLVM_INTEGRATED_CRT_ALLOC); if (NOT CMAKE_MSVC_RUNTIME_LIBRARY OR CMAKE_MSVC_RUNTIME_LIBRARY MATCHES ""DLL$""); message(FATAL_ERROR ""LLVM_INTEGRATED_CRT_ALLOC only works with CMAKE_MSVC_RUNTIME_LIBRARY set to MultiThreaded or MultiThreadedDebug.""); endif(). string(REGEX REPLACE ""(/|\\\\)$"" """" LLVM_INTEGRATED_CR",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CMakeLists.txt:2914,load,load,2914,interpreter/llvm-project/llvm/lib/Support/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/CMakeLists.txt,1,['load'],['load']
Performance,"ns about the LLVM instruction set.; We should discuss some now, but can discuss many of them later, when we; revisit synchronization, type inference, and other issues.; (We have discussed some of the comments already.). o We should consider eliminating the type annotation in cases where it is; essentially obvious from the instruction type, e.g., in br, it is obvious; that the first arg. should be a bool and the other args should be labels:. 	br bool <cond>, label <iftrue>, label <iffalse>. I think your point was that making all types explicit improves clarity; and readability. I agree to some extent, but it also comes at the cost; of verbosity. And when the types are obvious from people's experience; (e.g., in the br instruction), it doesn't seem to help as much. o On reflection, I really like your idea of having the two different switch; types (even though they encode implementation techniques rather than; semantics). It should simplify building the CFG and my guess is it could; enable some significant optimizations, though we should think about which. o In the lookup-indirect form of the switch, is there a reason not to make; the val-type uint? Most HLL switch statements (including Java and C++); require that anyway. And it would also make the val-type uniform ; in the two forms of the switch. I did see the switch-on-bool examples and, while cute, we can just use; the branch instructions in that particular case. o I agree with your comment that we don't need 'neg'. o There's a trade-off with the cast instruction:; + it avoids having to define all the upcasts and downcasts that are; valid for the operands of each instruction (you probably have thought; of other benefits also); - it could make the bytecode significantly larger because there could; be a lot of cast operations. o Making the second arg. to 'shl' a ubyte seems good enough to me.; 255 positions seems adequate for several generations of machines; and is more compact than uint. o I still have some major con",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt:1057,optimiz,optimizations,1057,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt,1,['optimiz'],['optimizations']
Performance,"ns can be added or subtracted. ~~~{.cpp}; TGeoTranslation t1;; t1->SetTranslation(-5,10,4);; TGeoTranslation *t2 = new TGeoTranslation(4,3,10);; t2->Subtract(&t1);; ~~~. - Rotations (TGeoRotation class) represent a pure rotation. Data; members are `Double_t fRotationMatrix[3*3]`. Rotations can be; defined either by Euler angles, either, by GEANT3 angles:. ~~~{.cpp}; TGeoRotation *r1 = new TGeoRotation();; r1->SetAngles(phi,theta,psi); // all angles in degrees; ~~~. This represents the composition of: first a rotation about Z axis with; angle phi, then a rotation with theta about the rotated X axis, and; finally a rotation with `psi` about the new Z axis. ~~~{.cpp}; r1->SetAngles(th1,phi1,th2,phi2,th3,phi3); ~~~. This is a rotation defined in GEANT3 style. Theta and phi are the; spherical angles of each axis of the rotated coordinate system with; respect to the initial one. This construction allows definition of; malformed rotations, e.g. not orthogonal. A check is performed and an; error message is issued in this case. Specific utilities: determinant, inverse. - Scale transformations (TGeoScale class) - represent a scaled; shrinking/enlargement, possibly different on all axes. Data members:; `Double_t fScale[3]`. Not implemented yet.; - Combined transformations - represent a rotation followed by a; translation. Data members:; `Double_t fTranslation[3]`, `TGeoRotation *fRotation`. ~~~{.cpp}; TGeoRotation *rot = new TGeoRotation(""rot"",10,20,30);; TGeoTranslation trans;; ...; TGeoCombiTrans *c1 = new TGeoCombiTrans(trans,rot);; TGeoCombiTrans *c2 = new TGeoCombiTrans(""somename"",10,20,30,rot); ~~~. - General transformations: (TGeoHMatrix class) represent; combined transformations in any order.; - Identity transformation: (TGeoIdentity class) is a generic; identity transformation represented by a singleton class object; `gGeoIdentity`. \anchor GP01d; ### Ownership of Geometry Objects. The class TGeoManager class contains the entire API needed for; building and tracking ge",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:58782,perform,performed,58782,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performed']
Performance,"ns even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; orderin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231365,load,load,231365,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"ns for changing the rounding mode, these conventions are not typically enforced in the ABI. Since the rounding mode changes the numerical result of operations, the compiler must understand something about it in order to optimize floating point operations. Note that floating-point operations performed as part of constant initialization are formally performed prior to the start of the program and are therefore not subject to the current rounding mode. This includes the initialization of global variables and local ``static`` variables. Floating-point operations in these contexts will be rounded using ``FE_TONEAREST``. - The option ``-fno-rounding-math`` allows the compiler to assume that the rounding mode is set to ``FE_TONEAREST``. This is the default.; - The option ``-frounding-math`` forces the compiler to honor the dynamically-set rounding mode. This prevents optimizations which might affect results if the rounding mode changes or is different from the default; for example, it prevents floating-point operations from being reordered across most calls and prevents constant-folding when the result is not exactly representable. .. option:: -ffp-model=<value>. Specify floating point behavior. ``-ffp-model`` is an umbrella; option that encompasses functionality provided by other, single; purpose, floating point options. Valid values are: ``precise``, ``strict``,; and ``fast``.; Details:. * ``precise`` Disables optimizations that are not value-safe on; floating-point data, although FP contraction (FMA) is enabled; (``-ffp-contract=on``). This is the default behavior. This value resets; ``-fmath-errno`` to its target-dependent default.; * ``strict`` Enables ``-frounding-math`` and; ``-ffp-exception-behavior=strict``, and disables contractions (FMA). All; of the ``-ffast-math`` enablements are disabled. Enables; ``STDC FENV_ACCESS``: by default ``FENV_ACCESS`` is disabled. This option; setting behaves as though ``#pragma STDC FENV_ACCESS ON`` appeared at the; top of the sou",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:61804,optimiz,optimizations,61804,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,"ns of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the L1 cache.; Therefore, they do not use the sc0 bit for coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:286490,cache,cache,286490,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"ns should generate the same code on big-endian systems:. int g(int *j,int *l) { return memcmp(j,l,4); }; int h(int *j, int *l) { return *j - *l; }. this could be done in SelectionDAGISel.cpp, along with other special cases,; for 1,2,4,8 bytes. //===---------------------------------------------------------------------===//. It would be nice to revert this patch:; http://lists.llvm.org/pipermail/llvm-commits/Week-of-Mon-20060213/031986.html. And teach the dag combiner enough to simplify the code expanded before ; legalize. It seems plausible that this knowledge would let it simplify other; stuff too. //===---------------------------------------------------------------------===//. For vector types, DataLayout.cpp::getTypeInfo() returns alignment that is equal; to the type size. It works but can be overly conservative as the alignment of; specific vector types are target dependent. //===---------------------------------------------------------------------===//. We should produce an unaligned load from code like this:. v4sf example(float *P) {; return (v4sf){P[0], P[1], P[2], P[3] };; }. //===---------------------------------------------------------------------===//. Add support for conditional increments, and other related patterns. Instead; of:. 	movl 136(%esp), %eax; 	cmpl $0, %eax; 	je LBB16_2	#cond_next; LBB16_1:	#cond_true; 	incl _foo; LBB16_2:	#cond_next. emit:; 	movl	_foo, %eax; 	cmpl	$1, %edi; 	sbbl	$-1, %eax; 	movl	%eax, _foo. //===---------------------------------------------------------------------===//. Combine: a = sin(x), b = cos(x) into a,b = sincos(x). Expand these to calls of sin/cos and stores:; double sincos(double x, double *sin, double *cos);; float sincosf(float x, float *sin, float *cos);; long double sincosl(long double x, long double *sin, long double *cos);. Doing so could allow SROA of the destination pointers. See also:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=17687. This is now easily doable with MRVs. We could even make an intrinsic for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:3986,load,load,3986,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['load']
Performance,"ns to be; aware of. Because the bit-representation of a non-integral pointer may; not be stable, two identical casts of the same operand may or may not; return the same value. Said differently, the conversion to or from the; non-integral type depends on environmental state in an implementation; defined manner. If the frontend wishes to observe a *particular* value following a cast, the; generated IR must fence with the underlying environment in an implementation; defined manner. (In practice, this tends to require ``noinline`` routines for; such operations.). From the perspective of the optimizer, ``inttoptr`` and ``ptrtoint`` for; non-integral types are analogous to ones on integral types with one; key exception: the optimizer may not, in general, insert new dynamic; occurrences of such casts. If a new cast is inserted, the optimizer would; need to either ensure that a) all possible values are valid, or b); appropriate fencing is inserted. Since the appropriate fencing is; implementation defined, the optimizer can't do the latter. The former is; challenging as many commonly expected properties, such as; ``ptrtoint(v)-ptrtoint(v) == 0``, don't hold for non-integral types.; Similar restrictions apply to intrinsics that might examine the pointer bits,; such as :ref:`llvm.ptrmask<int_ptrmask>`. . The alignment information provided by the frontend for a non-integral pointer; (typically using attributes or metadata) must be valid for every possible ; representation of the pointer. .. _globalvars:. Global Variables; ----------------. Global variables define regions of memory allocated at compilation time; instead of run-time. Global variable definitions must be initialized. Global variables in other translation units can also be declared, in which; case they don't have an initializer. Global variables can optionally specify a :ref:`linkage type <linkage>`. Either global variable definitions or declarations may have an explicit section; to be placed in and may have an optio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:29850,optimiz,optimizer,29850,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance,"ns. Because metadata nodes are immutable (with the exception of; ``MDNode::replaceOperandWith`` which is dangerous to use on uniqued; metadata), in order to add or remove a loop attributes, a new ``MDNode``; must be created and assigned as the new ``llvm.loop`` metadata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attributes, any ``llvm.mem.parallel_loop_access`` reference must be; updated to the new LoopID. Transformation Metadata Structure; =================================. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:2290,optimiz,optimizer,2290,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['optimiz'],['optimizer']
Performance,"ns; --------------------------------------. The LLVM IR does not define any way to start parallel threads of; execution or to register signal handlers. Nonetheless, there are; platform-specific ways to create them, and we define LLVM IR's behavior; in their presence. This model is inspired by the C++ memory model. For a more informal introduction to this model, see the :doc:`Atomics`. We define a *happens-before* partial order as the least partial order; that. - Is a superset of single-thread program order, and; - When ``a`` *synchronizes-with* ``b``, includes an edge from ``a`` to; ``b``. *Synchronizes-with* pairs are introduced by platform-specific; techniques, like pthread locks, thread creation, thread joining,; etc., and by atomic instructions. (See also :ref:`Atomic Memory Ordering; Constraints <ordering>`). Note that program order does not introduce *happens-before* edges; between a thread and signals executing inside that thread. Every (defined) read operation (load instructions, memcpy, atomic; loads/read-modify-writes, etc.) R reads a series of bytes written by; (defined) write operations (store instructions, atomic; stores/read-modify-writes, memcpy, etc.). For the purposes of this; section, initialized globals are considered to have a write of the; initializer which is atomic and happens before any other read or write; of the memory in question. For each byte of a read R, R\ :sub:`byte`; may see any write to the same byte, except:. - If write\ :sub:`1` happens before write\ :sub:`2`, and; write\ :sub:`2` happens before R\ :sub:`byte`, then; R\ :sub:`byte` does not see write\ :sub:`1`.; - If R\ :sub:`byte` happens before write\ :sub:`3`, then; R\ :sub:`byte` does not see write\ :sub:`3`. Given that definition, R\ :sub:`byte` is defined as follows:. - If R is volatile, the result is target-dependent. (Volatile is; supposed to give guarantees which can support ``sig_atomic_t`` in; C/C++, and may be used for accesses to addresses that do not behave; like nor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:149742,load,load,149742,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['load'],"['load', 'loads']"
Performance,"ns; necessary for fallthrough and use a sequence of `cmovCC` instructions in a; single fallthrough edge to track it. Second, we trade register pressure for simpler `cmovCC` instructions by; allocating a register for the ""bad"" state. We could read that value from memory; as part of the conditional move instruction, however, this creates more; micro-ops and requires the load-store unit to be involved. Currently, we place; the value into a virtual register and allow the register allocator to decide; when the register pressure is sufficient to make it worth spilling to memory; and reloading. #### Hardening Loads. Once we have the predicate accumulated into a special value for correct vs.; misspeculated, we need to apply this to loads in a way that ensures they do not; leak secret data. There are two primary techniques for this: we can either; harden the loaded value to prevent observation, or we can harden the address; itself to prevent the load from occurring. These have significantly different; performance tradeoffs. ##### Hardening loaded values. The most appealing way to harden loads is to mask out all of the bits loaded.; The key requirement is that for each bit loaded, along the misspeculated path; that bit is always fixed at either 0 or 1 regardless of the value of the bit; loaded. The most obvious implementation uses either an `and` instruction with; an all-zero mask along misspeculated paths and an all-one mask along correct; paths, or an `or` instruction with an all-one mask along misspeculated paths; and an all-zero mask along correct paths. Other options become less appealing; such as multiplying by zero, or multiple shift instructions. For reasons we; elaborate on below, we end up suggesting you use `or` with an all-ones mask,; making the x86 instruction sequence look like the following:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; movl (%rsi), %edi # Load potentially secret data from %rsi.; orl %eax, %edi; ```. Ot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:22687,perform,performance,22687,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance,"ns; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259576,perform,performing,259576,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"nsString:@""h""];; but not; [NSString stringWithFormat:@""format""];. Matcher<ObjCMessageExpr>matchesSelectorStringRef RegExp, Regex::RegexFlags Flags = NoFlags; Matches ObjC selectors whose name contains; a substring matched by the given RegExp.; matcher = objCMessageExpr(matchesSelector(""loadHTMLStringmatches the outer message expr in the code below, but NOT the message; invocation for self.bodyView.; [self.bodyView loadHTMLString:html baseURL:NULL];. If the matcher is used in clang-query, RegexFlags parameter; should be passed as a quoted string. e.g: ""NoFlags"".; Flags can be combined with '|' example ""IgnoreCase | BasicRegex"". Matcher<ObjCMessageExpr>numSelectorArgsunsigned N; Matches when the selector has the specified number of arguments. matcher = objCMessageExpr(numSelectorArgs(0));; matches self.bodyView in the code below. matcher = objCMessageExpr(numSelectorArgs(2));; matches the invocation of ""loadHTMLString:baseURL:"" but not that; of self.bodyView; [self.bodyView loadHTMLString:html baseURL:NULL];. Matcher<ObjCMethodDecl>isClassMethod; Returns true when the Objective-C method declaration is a class method. Example; matcher = objcMethodDecl(isClassMethod()); matches; @interface I + (void)foo; @end; but not; @interface I - (void)bar; @end. Matcher<ObjCMethodDecl>isDefinition; Matches if a declaration has a body attached. Example matches A, va, fa; class A {};; class B; // Doesn't match, as it has no body.; int va;; extern int vb; // Doesn't match, as it doesn't define the variable.; void fa() {}; void fb(); // Doesn't match, as it has no body.; @interface X; - (void)ma; // Doesn't match, interface is declaration.; @end; @implementation X; - (void)ma {}; @end. Usable as: Matcher<TagDecl>, Matcher<VarDecl>, Matcher<FunctionDecl>,; Matcher<ObjCMethodDecl>. Matcher<ObjCMethodDecl>isInstanceMethod; Returns true when the Objective-C method declaration is an instance method. Example; matcher = objcMethodDecl(isInstanceMethod()); matches; @interface I - (void)bar; @e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:108692,load,loadHTMLString,108692,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,2,['load'],['loadHTMLString']
Performance,"nsfer control to the point immediately succeeding; the prologue data, without performing any other visible action. This allows; the inliner and other passes to reason about the semantics of the function; definition without needing to reason about the prologue data. Obviously this; makes the format of the prologue data highly target dependent. A trivial example of valid prologue data for the x86 architecture is ``i8 144``,; which encodes the ``nop`` instruction:. .. code-block:: text. define void @f() prologue i8 144 { ... }. Generally prologue data can be formed by encoding a relative branch instruction; which skips the metadata, as in this example of valid prologue data for the; x86_64 architecture, where the first two bytes encode ``jmp .+10``:. .. code-block:: text. %0 = type <{ i8, i8, ptr }>. define void @f() prologue %0 <{ i8 235, i8 8, ptr @md}> { ... }. A function may have prologue data but no body. This has similar semantics; to the ``available_externally`` linkage in that the data may be used by the; optimizers but will not be emitted in the object file. .. _personalityfn:. Personality Function; --------------------. The ``personality`` attribute permits functions to specify what function; to use for exception handling. .. _attrgrp:. Attribute Groups; ----------------. Attribute groups are groups of attributes that are referenced by objects within; the IR. They are important for keeping ``.ll`` files readable, because a lot of; functions will use the same set of attributes. In the degenerative case of a; ``.ll`` file that corresponds to a single ``.c`` file, the single attribute; group will capture the important command line flags used to build that file. An attribute group is a module-level object. To use an attribute group, an; object references the attribute group's ID (e.g. ``#37``). An object may refer; to more than one attribute group. In that situation, the attributes from the; different groups are merged. Here is an example of attribute groups for ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:75447,optimiz,optimizers,75447,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizers']
Performance,"nsic. You can use ``llvm.sadd.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.sadd.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.sadd.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.sadd.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.sadd.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """""""""""""""""". The '``llvm.sadd.with.overflow``' family of intrinsic functions perform; a signed addition of the two arguments, and indicate whether an overflow; occurred during the signed summation. Arguments:; """""""""""""""""""". The arguments (%a and %b) and the first element of the result structure; may be of integer types of any bit width, but they must have the same; bit width. The second element of the result structure must be of type; ``i1``. ``%a`` and ``%b`` are the two values that will undergo signed; addition. Semantics:; """""""""""""""""""". The '``llvm.sadd.with.overflow``' family of intrinsic functions perform; a signed addition of the two variables. They return a structure --- the; first element of which is the signed summation, and the second element; of which is a bit specifying if the signed summation resulted in an; overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.sadd.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. '``llvm.uadd.with.overflow.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.uadd.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.uadd.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.uadd.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.uadd.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.uadd.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """"""""""""""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:602024,perform,perform,602024,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"nsistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:374531,load,load,374531,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"nsistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LLVM_ENABLE_LTO* option on your stage-2 build to ``Thin`` or ``Full`` to enable; building LLVM with LTO. These option",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:7618,perform,performing,7618,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['perform'],['performing']
Performance,"nspection with `TBrowser`. - Store not only numbers, but also *objects* in the columns. In this section we will discuss briefly the `TNtuple` class, which is a; simplified version of the `TTree` class. A ROOT `TNtuple` object can; store rows of float entries. Let's tackle the problem according to the; usual strategy commenting a minimal example. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/write_ntuple_to_file.C; ```. This data written to this example n-tuple represents, in the statistical; sense, three independent variables (Potential or Voltage, Pressure and; Temperature), and one variable (Current) which depends on the others; according to very simple laws, and an additional Gaussian smearing. This; set of variables mimics a measurement of an electrical resistance while; varying pressure and temperature. Imagine your task now consists in finding the relations among the; variables -- of course without knowing the code used to generate them.; You will see that the possibilities of the `NTuple` class enable you to; perform this analysis task. Open the ROOT file (`cond_data.root`); written by the macro above in an interactive session and use a; `TBrowser` to interactively inspect it:. ``` {.cpp}; root[0] TBrowser b; ```; You find the columns of your n-tuple written as *leafs*. Simply clicking; on them you can obtain histograms of the variables!. Next, try the following commands at the shell prompt and in the; interactive ROOT shell, respectively:. ``` {.cpp}; > root conductivity_experiment.root; Attaching file conductivity_experiment.root as _file0...; root [0] cond_data->Draw(""Current:Potential""); ```. You just produced a correlation plot with one single line of code!. Try to extend the syntax typing for example. ``` {.cpp}; root [1] cond_data->Draw(""Current:Potential"",""Temperature<270""); ```. What do you obtain ?. Now try. ``` {.cpp}; root [2] cond_data->Draw(""Current/Potential:Temperature""); ```. It should have become clear from these examples how to navigate in such; a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:2902,perform,perform,2902,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['perform'],['perform']
Performance,"nstance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attributes, any ``llvm.mem.parallel_loop_access`` reference must be; updated to the new LoopID. Transformation Metadata Structure; =================================. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instance being unrolled. .. code-block:: llvm. br i1 %exitcond, label %for.exit, label %for.header, !llvm.loop !0; ...; !0 = distinct !{!0, !1, !2}; !1 = !{!""llvm.loop.vectorize.enable"", i1 true}; !2 = !{!""llvm.loop.disable_nonforced""}. After a transformation is applied, follow-up attributes are set on the; transformed and/or new loop(s). This allows additional attributes; including followup-transformations to be specified. Specifying multiple; transformations in th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:2802,optimiz,optimization,2802,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['optimiz'],['optimization']
Performance,"nstrInfo::loadRegFromStackSlot``. The indirect mapping shields the application developer from the complexities of; inserting load and store instructions. In order to map a virtual register to a; physical one, use ``VirtRegMap::assignVirt2Phys(vreg, preg)``. In order to map; a certain virtual register to memory, use; ``VirtRegMap::assignVirt2StackSlot(vreg)``. This method will return the stack; slot where ``vreg``'s value will be located. If it is necessary to map another; virtual register to the same stack slot, use; ``VirtRegMap::assignVirt2StackSlot(vreg, stack_location)``. One important point; to consider when using the indirect mapping, is that even if a virtual register; is mapped to memory, it still needs to be mapped to a physical register. This; physical register is the location where the virtual register is supposed to be; found before being stored or after being reloaded. If the indirect strategy is used, after all the virtual registers have been; mapped to physical registers or stack slots, it is necessary to use a spiller; object to place load and store instructions in the code. Every virtual that has; been mapped to a stack slot will be stored to memory after being defined and will; be loaded before being used. The implementation of the spiller tries to recycle; load/store instructions, avoiding unnecessary instructions. For an example of; how to invoke the spiller, see ``RegAllocLinearScan::runOnMachineFunction`` in; ``lib/CodeGen/RegAllocLinearScan.cpp``. Handling two address instructions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With very rare exceptions (e.g., function calls), the LLVM machine code; instructions are three address instructions. That is, each instruction is; expected to define at most one register, and to use at most two registers.; However, some architectures use two address instructions. In this case, the; defined register is also one of the used registers. For instance, an instruction; such as ``ADD %EAX, %EBX``, in X86 is actually equiva",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:65965,load,load,65965,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['load'],['load']
Performance,"nstruction aliases can also have a Requires clause to make them subtarget; specific. If the back-end supports it, the instruction printer can automatically emit the; alias rather than what's being aliased. It typically leads to better, more; readable code. If it's better to print out what's being aliased, then pass a '0'; as the third parameter to the InstAlias definition. Instruction Matching; --------------------. .. note::. To Be Written. .. _Implementations of the abstract target description interfaces:; .. _implement the target description:. Target-specific Implementation Notes; ====================================. This section of the document explains features or design decisions that are; specific to the code generator for a particular target. .. _tail call section:. Tail call optimization; ----------------------. Tail call optimization, callee reusing the stack of the caller, is currently; supported on x86/x86-64, PowerPC, AArch64, and WebAssembly. It is performed on; x86/x86-64, PowerPC, and AArch64 if:. * Caller and callee have the calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:86385,perform,performed,86385,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['perform'],['performed']
Performance,"nstruction-info. Enable the instruction info view. This is enabled by default. .. option:: -show-encoding. Enable the printing of instruction encodings within the instruction info view. .. option:: -show-barriers. Enable the printing of LoadBarrier and StoreBarrier flags within the; instruction info view. .. option:: -all-stats. Print all hardware statistics. This enables extra statistics related to the; dispatch logic, the hardware schedulers, the register file(s), and the retire; control unit. This option is disabled by default. .. option:: -all-views. Enable all the view. .. option:: -instruction-tables. Prints resource pressure information based on the static information; available from the processor model. This differs from the resource pressure; view because it doesn't require that the code is simulated. It instead prints; the theoretical uniform distribution of resource pressure for every; instruction in sequence. .. option:: -bottleneck-analysis. Print information about bottlenecks that affect the throughput. This analysis; can be expensive, and it is disabled by default. Bottlenecks are highlighted; in the summary view. Bottleneck analysis is currently not supported for; processors with an in-order backend. .. option:: -json. Print the requested views in valid JSON format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views refer to them by index. However, not all views are; currently supported. For example, the report from the bottleneck analysis is; not printed out in JSON. All the default views are currently supported. .. option:: -disable-cb. Force usage of the generic CustomBehaviour and InstrPostProcess classes rather; than using the target specific implementation. The generic classes never; detect any custom hazards or make any post processing modifications to; instructions. .. option:: -disable-im. Force usage of the generic InstrumentManager rather than using the target; spec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:6739,bottleneck,bottlenecks,6739,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['bottleneck', 'throughput']","['bottlenecks', 'throughput']"
Performance,"nstructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:282497,load,load,282497,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"nstructions; for the loop, which can enable folding of the scalar epilogue loop into the; main loop. The first operand is the string; ``llvm.loop.vectorize.predicate.enable`` and the second operand is a bit. If; the bit operand value is 1 vectorization is enabled. A value of 0 disables; vectorization:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.predicate.enable"", i1 0}; !1 = !{!""llvm.loop.vectorize.predicate.enable"", i1 1}. '``llvm.loop.vectorize.scalable.enable``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata selectively enables or disables scalable vectorization for the; loop, and only has any effect if vectorization for the loop is already enabled.; The first operand is the string ``llvm.loop.vectorize.scalable.enable``; and the second operand is a bit. If the bit operand value is 1 scalable; vectorization is enabled, whereas a value of 0 reverts to the default fixed; width vectorization:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.scalable.enable"", i1 0}; !1 = !{!""llvm.loop.vectorize.scalable.enable"", i1 1}. '``llvm.loop.vectorize.width``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata sets the target width of the vectorizer. The first; operand is the string ``llvm.loop.vectorize.width`` and the second; operand is an integer specifying the width. For example:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.width"", i32 4}. Note that setting ``llvm.loop.vectorize.width`` to 1 disables; vectorization of the loop. If ``llvm.loop.vectorize.width`` is set to; 0 or if the loop does not have this metadata the width will be; determined automatically. '``llvm.loop.vectorize.followup_vectorized``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata defines which loop attributes the vectorized loop will; have. See :ref:`transformation-metadata` for details. '``llvm.loop.vectorize.followup_epilogue``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:299004,scalab,scalable,299004,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance,"nstrumentation map from a binary, and return it as; YAML.; - ``account``: Performs basic function call accounting statistics with various; options for sorting, and output formats (supports CSV, YAML, and; console-friendly TEXT).; - ``convert``: Converts an XRay log file from one format to another. We can; convert from binary XRay traces (both basic and FDR mode) to YAML,; `flame-graph <https://github.com/brendangregg/FlameGraph>`_ friendly text; formats, as well as `Chrome Trace Viewer (catapult); <https://github.com/catapult-project/catapult>` formats.; - ``graph``: Generates a DOT graph of the function call relationships between; functions found in an XRay trace.; - ``stack``: Reconstructs function call stacks from a timeline of function; calls in an XRay trace. These subcommands use various library components found as part of the XRay; libraries, distributed with the LLVM distribution. These are:. - ``llvm/XRay/Trace.h`` : A trace reading library for conveniently loading; an XRay trace of supported forms, into a convenient in-memory representation.; All the analysis tools that deal with traces use this implementation.; - ``llvm/XRay/Graph.h`` : A semi-generic graph type used by the graph; subcommand to conveniently represent a function call graph with statistics; associated with edges and vertices.; - ``llvm/XRay/InstrumentationMap.h``: A convenient tool for analyzing the; instrumentation map in XRay-instrumented object files and binaries. The; ``extract`` and ``stack`` subcommands uses this particular library. Minimizing Binary Size; ----------------------. XRay supports several different instrumentation points including ``function-entry``,; ``function-exit``, ``custom``, and ``typed`` points. These can be enabled individually; using the ``-fxray-instrumentation-bundle=`` flag. For example if you only wanted to; instrument function entry and custom points you could specify:. ::. clang -fxray-instrument -fxray-instrumentation-bundle=function-entry,custom ... This ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:12353,load,loading,12353,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['load'],['loading']
Performance,"nstrumented; fun:malloc=discard. # tolower is a pure function.; fun:tolower=uninstrumented; fun:tolower=functional. # memcpy needs to copy the shadow from the source to the destination region.; # This is done in a custom function.; fun:memcpy=uninstrumented; fun:memcpy=custom. For instrumented functions, the ABI list supports a ``force_zero_labels``; category, which will make all stores and return values set zero labels.; Functions should never be labelled with both ``force_zero_labels``; and ``uninstrumented`` or any of the uninstrumented wrapper kinds. For example:. .. code-block:: none. # e.g. void writes_data(char* out_buf, int out_buf_len) {...}; # Applying force_zero_labels will force out_buf shadow to zero.; fun:writes_data=force_zero_labels. Compilation Flags; -----------------. * ``-dfsan-abilist`` -- The additional ABI list files that control how shadow; parameters are passed. File names are separated by comma.; * ``-dfsan-combine-pointer-labels-on-load`` -- Controls whether to include or; ignore the labels of pointers in load instructions. Its default value is true.; For example:. .. code-block:: c++. v = *p;. If the flag is true, the label of ``v`` is the union of the label of ``p`` and; the label of ``*p``. If the flag is false, the label of ``v`` is the label of; just ``*p``. * ``-dfsan-combine-pointer-labels-on-store`` -- Controls whether to include or; ignore the labels of pointers in store instructions. Its default value is; false. For example:. .. code-block:: c++. *p = v;. If the flag is true, the label of ``*p`` is the union of the label of ``p`` and; the label of ``v``. If the flag is false, the label of ``*p`` is the label of; just ``v``. * ``-dfsan-combine-offset-labels-on-gep`` -- Controls whether to propagate; labels of offsets in GEP instructions. Its default value is true. For example:. .. code-block:: c++. p += i;. If the flag is true, the label of ``p`` is the union of the label of ``p`` and; the label of ``i``. If the flag is false, the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst:5935,load,load,5935,interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizer.rst,2,['load'],['load']
Performance,"nsupported vector types to; value of supported types: splitting vector types, multiple times if necessary,; until a legal type is found, and extending vector types by adding elements to; the end to round them out to legal types (""widening""). If a vector gets split; all the way down to single-element parts with no supported vector type being; found, the elements are converted to scalars (""scalarizing""). A target implementation tells the legalizer which types are supported (and which; register class to use for them) by calling the ``addRegisterClass`` method in; its ``TargetLowering`` constructor. .. _legalize operations:; .. _Legalizer:. SelectionDAG Legalize Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the operations; that are natively supported by the target. Targets often have weird constraints, such as not supporting every operation on; every supported datatype (e.g. X86 does not support byte conditional moves and; PowerPC does not support sign-extending loads from a 16-bit memory location).; Legalize takes care of this by open-coding another sequence of operations to; emulate the operation (""expansion""), by promoting one type to a larger type that; supports the operation (""promotion""), or by using a target-specific hook to; implement the legalization (""custom""). A target implementation tells the legalizer which operations are not supported; (and which of the above three actions to take) by calling the; ``setOperationAction`` method in its ``TargetLowering`` constructor. If a target has legal vector types, it is expected to produce efficient machine; code for common forms of the shufflevector IR instruction using those types.; This may require custom legalization for SelectionDAG vector operations that; are created from the shufflevector IR. The shufflevector forms that should be; handled include:. * Vector select --- Each element of the vector is chosen from either of the; corresponding elements of the 2 inpu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:42718,load,loads,42718,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['load'],['loads']
Performance,"nsures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:238422,cache,cache,238422,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"nsures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vm/vscnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:350923,cache,caches,350923,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance,"nsw`` keywords are present, the; result value of the ``mul`` is a :ref:`poison value <poisonvalues>` if; unsigned and/or signed overflow, respectively, occurs. Example:; """""""""""""""". .. code-block:: text. <result> = mul i32 4, %var ; yields i32:result = 4 * %var. .. _i_fmul:. '``fmul``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = fmul [fast-math flags]* <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``fmul``' instruction returns the product of its two operands. Arguments:; """""""""""""""""""". The two arguments to the '``fmul``' instruction must be; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>` of; floating-point values. Both arguments must have identical types. Semantics:; """""""""""""""""""". The value produced is the floating-point product of the two operands.; This instruction is assumed to execute in the default :ref:`floating-point; environment <floatenv>`.; This instruction can also take any number of :ref:`fast-math; flags <fastmath>`, which are optimization hints to enable otherwise; unsafe floating-point optimizations:. Example:; """""""""""""""". .. code-block:: text. <result> = fmul float 4.0, %var ; yields float:result = 4.0 * %var. .. _i_udiv:. '``udiv``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = udiv <ty> <op1>, <op2> ; yields ty:result; <result> = udiv exact <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``udiv``' instruction returns the quotient of its two operands. Arguments:; """""""""""""""""""". The two arguments to the '``udiv``' instruction must be; :ref:`integer <t_integer>` or :ref:`vector <t_vector>` of integer values. Both; arguments must have identical types. Semantics:; """""""""""""""""""". The value produced is the unsigned integer quotient of the two operands. Note that unsigned integer division and signed integer division are; distinct operations; for signed integer division, use '``sdiv``'. Division by zero is undefined behavior. For vectors, if any element; of the divisor is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:384235,optimiz,optimization,384235,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['optimiz'],"['optimization', 'optimizations']"
Performance,"nt - generic 1. flat_load glc=1 dlc=1; - system; - If GFX11, omit dlc=1. 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_gl*_invl.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. 3. buffer_gl0_inv. - If OpenCL omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkmcnt(0) &; vm/vscnt(0). - If CU wavefront execution; mode, omit vm/vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:349190,load,loads,349190,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"nt of the stack slot to; form and the known alignment of the pointer specified to the call; site. If the alignment is not specified, then the code generator; makes a target-specific assumption. .. _attr_byref:. ``byref(<ty>)``. The ``byref`` argument attribute allows specifying the pointee; memory type of an argument. This is similar to ``byval``, but does; not imply a copy is made anywhere, or that the argument is passed; on the stack. This implies the pointer is dereferenceable up to; the storage size of the type. It is not generally permissible to introduce a write to an; ``byref`` pointer. The pointer may have any address space and may; be read only. This is not a valid attribute for return values. The alignment for an ``byref`` parameter can be explicitly; specified by combining it with the ``align`` attribute, similar to; ``byval``. If the alignment is not specified, then the code generator; makes a target-specific assumption. This is intended for representing ABI constraints, and is not; intended to be inferred for optimization use. .. _attr_preallocated:. ``preallocated(<ty>)``; This indicates that the pointer parameter should really be passed by; value to the function, and that the pointer parameter's pointee has; already been initialized before the call instruction. This attribute; is only valid on LLVM pointer arguments. The argument must be the value; returned by the appropriate; :ref:`llvm.call.preallocated.arg<int_call_preallocated_arg>` on non; ``musttail`` calls, or the corresponding caller parameter in ``musttail``; calls, although it is ignored during codegen. A non ``musttail`` function call with a ``preallocated`` attribute in; any parameter must have a ``""preallocated""`` operand bundle. A ``musttail``; function call cannot have a ``""preallocated""`` operand bundle. The preallocated attribute requires a type argument, which must be; the same as the pointee type of the argument. The preallocated attribute also supports specifying an alignment with t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:53282,optimiz,optimization,53282,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"nt projections.; All TEveProjection::ProjectPoint/Vector(...) functions have an; additional ""depth"" argument thus allowing the projected classes to; skip explicit setting of depth after the point has been projected; -- this could damage the 3rd component. Pre-scaling now supports 3 dimensions.; Abstract TEveProjected::SetDepth() has been split into two parts:; ; It has been implemented in the base class where it checks for; the projection type (2d) before calling the local function;; Abstract SetDepthLocal() has been added to provide the same; functionality. This allows for the 2d/3d check to be done in place only.; New projection class has been introduced: TEve3DProjection.; It performs pre-scaling and offsets the center.; To simplify the projection of lists TEveElementList has been made; projectable and corresponding TEveElementListProjected class; introduced. This also fixed the problem with render-state not being; propagated to projected classes. The check whether to project a sub-tree of elements is still performed.; TEveGeoShapeProjected has been introduced to represent the 3D; projection of a TEveGeoShape (2D projection is handled by; TEvePolygonSetProjected). Points, lines and tracks use the same projected class for both 2D; and 3D projections. An example showing this functionality has been added as a new tab in; projection_prescale.C.; TEveManager now allows simultaneous usage of several objects; editors. Simply click on the top name-button in object editor to; create a standalone editor for this object in a separate window. This; facilitates operation when several objects need to be modifed in; parallel.; New tutorial alice_vsd.C has been added. It shows; how to read Visualization Summary Data files (VSD).; Code for operating three view configuration (3D / RPhi / Rhoz); has been extracted from alice_esd.C tutorial; into MultiView.C tutorial. This is now also used; by alice_vsd.C and can serve as an example to those that; need to implement similar functiona",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v526/index.html:2867,perform,performed,2867,graf3d/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf3d/doc/v526/index.html,2,['perform'],['performed']
Performance,"nt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vm/vscnt(0) &; lgkmcnt(0). - If",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:368032,load,load,368032,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"nt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Mu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:271356,load,loads,271356,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"nt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/loa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:358804,load,load,358804,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"nt; tradeoff even when only used in a mixture of code. ##### Use an internal TLS location to pass predicate state. We can define a special thread-local value to hold the predicate state between; functions. This avoids direct ABI implications by using a side channel between; callers and callees to communicate the predicate state. It also allows implicit; zero-initialization of the state, which allows non-checked code to be the first; code executed. However, this requires a load from TLS in the entry block, a store to TLS; before every call and every ret, and a load from TLS after every call. As a; consequence it is expected to be substantially more expensive even than using; `%rsp` and potentially `lfence` within the function entry block. ##### Define a new ABI and/or calling convention. We could define a new ABI and/or calling convention to explicitly pass the; predicate state in and out of functions. This may be interesting if none of the; alternatives have adequate performance, but it makes deployment and adoption; dramatically more complex, and potentially infeasible. ## High-Level Alternative Mitigation Strategies. There are completely different alternative approaches to mitigating variant 1; attacks. [Most](https://lwn.net/Articles/743265/); [discussion](https://lwn.net/Articles/744287/) so far focuses on mitigating; specific known attackable components in the Linux kernel (or other kernels) by; manually rewriting the code to contain an instruction sequence that is not; vulnerable. For x86 systems this is done by either injecting an `lfence`; instruction along the code path which would leak data if executed speculatively; or by rewriting memory accesses to have branch-less masking to a known safe; region. On Intel systems, `lfence` [will prevent the speculative load of secret; data](https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf).; On AMD systems `lfence` is currently a no-op, but can be m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:43319,perform,performance,43319,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['perform'],['performance']
Performance,"nt_8 = 0 '\000'}}. In the above, the values of `v` and `a` are clearly expressed, as are the; temporary values for `await_counter` (`class_await_counter_1` and; `class_await_counter_2`) and `std::suspend_always` (; `struct_std__suspend_always_0` and `struct_std__suspend_always_3`). The index; of the current suspension point of the coroutine is emitted as `__coro_index`.; In the above example, the `__coro_index` value of `1` means the coroutine; stopped at the second suspend point (Note that `__coro_index` is zero indexed); which is the first `co_await await_counter{};` in `coro_task`. Note that the; first initial suspend point is the compiler generated; `co_await promise_type::initial_suspend()`. However, when optimizations are enabled, the printed result changes drastically:. .. parsed-literal::. {__resume_fn = 0x401280 <coro_task(int)>, __destroy_fn = 0x401390 <coro_task(int)>, __promise = {count = 1}, __int_32_0 = 43, __coro_index = 1 '\001'}. Unused values are optimized out, as well as the name of the local variable `a`.; The only information remained is the value of a 32 bit integer. In this simple; case, it seems to be pretty clear that `__int_32_0` represents `a`. However, it; is not true. An important note with optimization is that the value of a variable may not; properly express the intended value in the source code. For example:. .. code-block:: c++. static task coro_task(int v) {; int a = v;; co_await await_counter{};; a++; // __int_32_0 is 43 here; std::cout << a << ""\n"";; a++; // __int_32_0 is still 43 here; std::cout << a << ""\n"";; a++; // __int_32_0 is still 43 here!; std::cout << a << ""\n"";; co_await await_counter{};; a++; // __int_32_0 is still 43 here!!; std::cout << a << ""\n"";; a++; // Why is __int_32_0 still 43 here?; std::cout << a << ""\n"";; }. When debugging step-by-step, the value of `__int_32_0` seemingly does not; change, despite being frequently incremented, and instead is always `43`.; While this might be surprising, this is a result of t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst:8575,optimiz,optimized,8575,interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,1,['optimiz'],['optimized']
Performance,"nt_ppc_vsx_xxbrq v1i128:$XB)). - Vector Permute: xxperm xxpermr; . I have checked ""PPCxxswapd"" in PPCInstrVSX.td, but they are different; . Use intrinsic; (set v16i8:$XT, (int_ppc_vsx_xxperm v16i8:$XA, v16i8:$XB)); (set v16i8:$XT, (int_ppc_vsx_xxpermr v16i8:$XA, v16i8:$XB)). - Vector Splat Immediate Byte: xxspltib; . Similar to XXSPLTW:; def XXSPLTW : XX2Form_2<60, 164,; (outs vsrc:$XT), (ins vsrc:$XB, u2imm:$UIM),; ""xxspltw $XT, $XB, $UIM"", IIC_VecPerm, []>;. . No SDAG, intrinsic, builtin are required?. - Load/Store Vector: lxv stxv; . Has likely SDAG match:; (set v?:$XT, (load ix16addr:$src)); (set v?:$XT, (store ix16addr:$dst)). . Need define ix16addr in PPCInstrInfo.td; ix16addr: 16-byte aligned, see ""def memrix16"" in PPCInstrInfo.td. - Load/Store Vector Indexed: lxvx stxvx; . Has likely SDAG match:; (set v?:$XT, (load xoaddr:$src)); (set v?:$XT, (store xoaddr:$dst)). - Load/Store DWord: lxsd stxsd; . Similar to lxsdx/stxsdx:; def LXSDX : XX1Form<31, 588,; (outs vsfrc:$XT), (ins memrr:$src),; ""lxsdx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (load xoaddr:$src))]>;. . (set f64:$XT, (load iaddrX4:$src)); (set f64:$XT, (store iaddrX4:$dst)). - Load/Store SP, with conversion from/to DP: lxssp stxssp; . Similar to lxsspx/stxsspx:; def LXSSPX : XX1Form<31, 524, (outs vssrc:$XT), (ins memrr:$src),; ""lxsspx $XT, $src"", IIC_LdStLFD,; [(set f32:$XT, (load xoaddr:$src))]>;. . (set f32:$XT, (load iaddrX4:$src)); (set f32:$XT, (store iaddrX4:$dst)). - Load as Integer Byte/Halfword & Zero Indexed: lxsibzx lxsihzx; . Similar to lxsiwzx:; def LXSIWZX : XX1Form<31, 12, (outs vsfrc:$XT), (ins memrr:$src),; ""lxsiwzx $XT, $src"", IIC_LdStLFD,; [(set f64:$XT, (PPClfiwzx xoaddr:$src))]>;. . (set f64:$XT, (PPClfiwzx xoaddr:$src)). - Store as Integer Byte/Halfword Indexed: stxsibx stxsihx; . Similar to stxsiwx:; def STXSIWX : XX1Form<31, 140, (outs), (ins vsfrc:$XT, memrr:$dst),; ""stxsiwx $XT, $dst"", IIC_LdStSTFD,; [(PPCstfiwx f64:$XT, xoaddr:$dst)]>;. . (PPCstfiwx f64:$XT, xoaddr:$dst). -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt:17845,load,load,17845,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_P9.txt,2,['load'],['load']
Performance,"ntain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. // Declare plugin extension function declarations.; #define HANDLE_EXTENSION(Ext) llvm::PassPluginLibraryInfo get##Ext##PluginInfo();; #include ""llvm/Support/Extension.def"". ... // Register plugin extensions in PassBuilder.; #define HANDLE_EXTENSION(Ext) get##Ext##PluginInfo().RegisterPassBuilderCallbacks(PB);; #include ""llvm/Support/Extension.def"". To make ``PassBuilder`` aware of dynamically linked pass plugins:. .. code-block:: c++. // Load plugin dynamical",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:8042,load,loaded,8042,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,1,['load'],['loaded']
Performance,"ntains debug data, and is referenced by a GNU debug; link section, use the specified path as a basis for locating the debug data if; it cannot be found relative to the object. .. option:: --filter-markup. Reads from standard input, converts contained; :doc:`Symbolizer Markup </SymbolizerMarkupFormat>` into human-readable form,; and prints the results to standard output. The following markup elements are; not yet supported:. * ``{{{hexdict}}}``; * ``{{{dumpfile}}}``. The ``{{{bt}}}`` backtrace element reports frames using the following syntax:. ``#<number>[.<inline>] <address> <function> <file>:<line>:<col> (<module>+<relative address>)``. ``<inline>`` provides frame numbers for calls inlined into the caller; corresponding to ``<number>``. The inlined call numbers start at 1 and increase; from callee to caller. ``<address>`` is an address inside the call instruction to the function. The; address may not be the start of the instruction. ``<relative address>`` is; the corresponding virtual offset in the ``<module>`` loaded at that address. .. _llvm-symbolizer-opt-f:. .. option:: --functions [=<none|short|linkage>], -f. Specify the way function names are printed (omit function name, print short; function name, or print full linkage name, respectively). Defaults to; ``linkage``. .. option:: --help, -h. Show help and usage for this command. .. _llvm-symbolizer-opt-i:. .. option:: --inlining, --inlines, -i. If a source code location is in an inlined function, prints all the inlined; frames. This is the default. .. option:: --no-inlines. Don't print inlined frames. .. option:: --no-demangle. Don't print demangled function names. .. option:: --obj <path>, --exe, -e. Path to object file to be symbolized. If ``-`` is specified, read the object; directly from the standard input stream. Mutually exclusive with; :option:`--build-id`. .. _llvm-symbolizer-opt-output-style:. .. option:: --output-style <LLVM|GNU|JSON>. Specify the preferred output style. Defaults to ``LLVM``. When th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:7456,load,loaded,7456,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,1,['load'],['loaded']
Performance,"nted by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentall",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3483,optimiz,optimization,3483,roofit/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html,7,"['Optimiz', 'cache', 'optimiz']","['Optimize', 'cache', 'optimization']"
Performance,"nteger type that is larger than the bitwidth of the; sought type is used. If none of the specifications are larger than; the bitwidth then the largest integer type is used. For example,; given the default specifications above, the i7 type will use the; alignment of i8 (next largest) while both i65 and i256 will use the; alignment of i64 (largest specified). The function of the data layout string may not be what you expect.; Notably, this is not a specification from the frontend of what alignment; the code generator should use. Instead, if specified, the target data layout is required to match what; the ultimate *code generator* expects. This string is used by the; mid-level optimizers to improve code, and this only works if it matches; what the ultimate code generator uses. There is no way to generate IR; that does not embed this target-specific detail into the IR. If you; don't specify the string, the default specifications will be used to; generate a Data Layout and the optimization phases will operate; accordingly and introduce target specificity into the IR with respect to; these default specifications. .. _langref_triple:. Target Triple; -------------. A module may specify a target triple string that describes the target; host. The syntax for the target triple is simply:. .. code-block:: llvm. target triple = ""x86_64-apple-macosx10.7.0"". The *target triple* string consists of a series of identifiers delimited; by the minus sign character ('-'). The canonical forms are:. ::. ARCHITECTURE-VENDOR-OPERATING_SYSTEM; ARCHITECTURE-VENDOR-OPERATING_SYSTEM-ENVIRONMENT. This information is passed along to the backend so that it generates; code for the proper architecture. It's possible to override this on the; command line with the ``-mtriple`` command line option. .. _objectlifetime:. Object Lifetime; ----------------------. A memory object, or simply object, is a region of a memory space that is; reserved by a memory allocation such as :ref:`alloca <i_alloca>`, heap; al",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:139273,optimiz,optimization,139273,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"nter (to a structure), not a structure itself. #. Point #1 is evidenced by noticing the type of the second operand of the GEP; instruction (``%MyStruct``) which is ``ptr``. #. The first index, ``i64 0`` is required to step over the global variable; ``%MyStruct``. Since the second argument to the GEP instruction must always; be a value of pointer type, the first index steps through that pointer. A; value of 0 means 0 elements offset from that pointer. #. The second index, ``i32 1`` selects the second field of the structure (the; ``i32``). What is dereferenced by GEP?; ----------------------------. Quick answer: nothing. The GetElementPtr instruction dereferences nothing. That is, it doesn't access; memory in any way. That's what the Load and Store instructions are for. GEP is; only involved in the computation of addresses. For example, consider this:. .. code-block:: text. @MyVar = external global { i32, ptr }; ...; %idx = getelementptr { i32, ptr }, ptr @MyVar, i64 0, i32 1; %arr = load ptr, ptr %idx; %idx = getelementptr [40 x i32], ptr %arr, i64 0, i64 17. In this example, we have a global variable, ``@MyVar``, which is a pointer to; a structure containing a pointer. Let's assume that this inner pointer points; to an array of type ``[40 x i32]``. The above IR will first compute the address; of the inner pointer, then load the pointer, and then compute the address of; the 18th array element. This cannot be expressed in a single GEP instruction, because it requires; a memory dereference in between. However, the following example would work; fine:. .. code-block:: text. @MyVar = external global { i32, [40 x i32 ] }; ...; %idx = getelementptr { i32, [40 x i32] }, ptr @MyVar, i64 0, i32 1, i64 17. In this case, the structure does not contain a pointer and the GEP instruction; can index through the global variable, into the second field of the structure; and access the 18th ``i32`` in the array there. Why don't GEP x,0,0,1 and GEP x,1 alias?; ----------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:6703,load,load,6703,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['load'],['load']
Performance,"nter as an argument (which it; then propagates). This can sometimes be useful, allowing you to combine; several null checks into one. These five templates can be used with any classes, whether they have a v-table; or not. If you want to add support for these templates, see the document; :doc:`How to set up LLVM-style RTTI for your class hierarchy; <HowToSetUpLLVMStyleRTTI>`. .. _string_apis:. Passing strings (the ``StringRef`` and ``Twine`` classes); ---------------------------------------------------------. Although LLVM generally does not do much string manipulation, we do have several; important APIs which take strings. Two important examples are the Value class; -- which has names for instructions, functions, etc. -- and the ``StringMap``; class which is used extensively in LLVM and Clang. These are generic classes, and they need to be able to accept strings which may; have embedded null characters. Therefore, they cannot simply take a ``const; char *``, and taking a ``const std::string&`` requires clients to perform a heap; allocation which is usually unnecessary. Instead, many LLVM APIs use a; ``StringRef`` or a ``const Twine&`` for passing strings efficiently. .. _StringRef:. The ``StringRef`` class; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``StringRef`` data type represents a reference to a constant string (a; character array and a length) and supports the common operations available on; ``std::string``, but does not require heap allocation. It can be implicitly constructed using a C style null-terminated string, an; ``std::string``, or explicitly with a character pointer and length. For; example, the ``StringMap`` find function is declared as:. .. code-block:: c++. iterator find(StringRef Key);. and clients can call it using any one of:. .. code-block:: c++. Map.find(""foo""); // Lookup ""foo""; Map.find(std::string(""bar"")); // Lookup ""bar""; Map.find(StringRef(""\0baz"", 4)); // Lookup ""\0baz"". Similarly, APIs which need to return a string may return a ``StringRef``; ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:8203,perform,perform,8203,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['perform']
Performance,"nter**: used to reference memory allocated and managed by the; interpreter, being the only pointer kind which allows dereferencing in the; interpreter; * **ExternPointer**: points to memory which can be addressed, but not read by; the interpreter. It is equivalent to APValue, tracking a declaration and a path; of fields and indices into that allocation.; * **TargetPointer**: represents a target address derived from a base address; through pointer arithmetic, such as ``((int *)0x100)[20]``. Null pointers are; target pointers with a zero offset.; * **TypeInfoPointer**: tracks information for the opaque type returned by; ``typeid``; * **InvalidPointer**: is dummy pointer created by an invalid operation which; allows the interpreter to continue execution. Does not allow pointer; arithmetic or dereferencing. Besides the previously mentioned union, a number of other pointer-like types; have their own type:. * **ObjCBlockPointer** tracks Objective-C blocks; * **FnPointer** tracks functions and lazily caches their compiled version; * **MemberPointer** tracks C++ object members. Void pointers, which can be built by casting any of the aforementioned; pointers, are implemented as a union of all pointer types. The ``BitCast``; opcode is responsible for performing all legal conversions between these; types and primitive integers. BlockPointer; ~~~~~~~~~~~~. Block pointers track a ``Pointee``, the block to which they point, along; with a ``Base`` and an ``Offset``. The base identifies the innermost field,; while the offset points to an array element relative to the base (including; one-past-end pointers). The offset identifies the array element or field; which is referenced, while the base points to the outer object or array which; contains the field. These two fields allow all pointers to be uniquely; identified, disambiguated and characterised. As an example, consider the following structure:. .. code-block:: c. struct A {; struct B {; int x;; int y;; } b;; struct C {; int a;; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst:9835,cache,caches,9835,interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,1,['cache'],['caches']
Performance,"nter:; .. _object pointers:. **Object Pointer**; A pointer to an object such that the garbage collector is able to trace; references contained within the object. This term is used in opposition to; `derived pointer`_. P; -. **PGO**; Profile-Guided Optimization. **PR**; Problem report. A bug filed on `the LLVM Bug Tracking System; <https://bugs.llvm.org/enter_bug.cgi>`_. **PRE**; Partial Redundancy Elimination. R; -. **RAUW**. Replace All Uses With. The functions ``User::replaceUsesOfWith()``,; ``Value::replaceAllUsesWith()``, and; ``Constant::replaceUsesOfWithOnConstant()`` implement the replacement of one; Value with another by iterating over its def/use chain and fixing up all of; the pointers to point to the new value. See; also `def/use chains <ProgrammersManual.html#iterating-over-def-use-use-def-chains>`_. **Reassociation**; Rearranging associative expressions to promote better redundancy elimination; and other optimization. For example, changing ``(A+B-A)`` into ``(B+A-A)``,; permitting it to be optimized into ``(B+0)`` then ``(B)``. **RFC**; Request for Comment. An email sent to a project mailing list in order to; solicit feedback on a proposed change. .. _roots:; .. _stack roots:. **Root**; In garbage collection, a pointer variable lying outside of the `heap`_ from; which the collector begins its reachability analysis. In the context of code; generation, ""root"" almost always refers to a ""stack root"" --- a local or; temporary variable within an executing function. **RPO**; Reverse postorder. **RTTI**; Run-time Type Information. S; -. .. _safe point:. **Safe Point**; In garbage collection, it is necessary to identify `stack roots`_ so that; reachability analysis may proceed. It may be infeasible to provide this; information for every instruction, so instead the information is; calculated only at designated safe points. With a copying collector,; `derived pointers`_ must not be retained across safe points and `object; pointers`_ must be reloaded from stack roo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst:6958,optimiz,optimized,6958,interpreter/llvm-project/llvm/docs/Lexicon.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst,1,['optimiz'],['optimized']
Performance,"nteresting: GCC passes. Take a look at this document (which describes the order of optimizations; that GCC performs):. http://gcc.gnu.org/onlinedocs/gcc_17.html. The rundown is that after RTL generation, the following happens:. 1 . [t] jump optimization (jumps to jumps, etc); 2 . [t] Delete unreachable code; 3 . Compute live ranges for CSE; 4 . [t] Jump threading (jumps to jumps with identical or inverse conditions); 5 . [t] CSE; 6 . *** Conversion to SSA ; 7 . [t] SSA Based DCE; 8 . *** Conversion to LLVM; 9 . UnSSA; 10. GCSE; 11. LICM; 12. Strength Reduction; 13. Loop unrolling; 14. [t] CSE; 15. [t] DCE; 16. Instruction combination, register movement, scheduling... etc. I've marked optimizations with a [t] to indicate things that I believe to; be relatively trivial to implement in LLVM itself. The time consuming; things to reimplement would be SSA based PRE, Strength reduction & loop; unrolling... these would be the major things we would miss out on if we; did LLVM creation from tree code [inlining and other high level; optimizations are done on the tree representation]. Given the lack of ""strong"" optimizations that would take a long time to; reimplement, I am leaning a bit more towards creating LLVM from the tree; code. Especially given that SGI has GPL'd their compiler, including many; SSA based optimizations that could be adapted (besides the fact that their; code looks MUCH nicer than GCC :). Even if we choose to do LLVM code emission from RTL, we will almost; certainly want to move LLVM emission from step 8 down until at least CSE; has been rerun... which causes me to wonder if the SSA generation code; will still work (due to global variable dependencies and stuff). I assume; that it can be made to work, but might be a little more involved than we; would like. I'm continuing to look at the Tree -> RTL code. It is pretty gross; because they do some of the translation a statement at a time, and some; of it a function at a time... I'm not quite clear why and how ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt:1172,optimiz,optimizations,1172,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations.txt,1,['optimiz'],['optimizations']
Performance,"nternal global variables that don't ""have their address taken"". If a global; does not have its address taken, the pass knows that no pointers alias the; global. This pass also keeps track of functions that it knows never access; memory or never read memory. This allows certain optimizations (e.g. GVN) to; eliminate call instructions entirely. The real power of this pass is that it provides context-sensitive mod/ref; information for call instructions. This allows the optimizer to know that calls; to a function do not clobber or read the value of the global, allowing loads and; stores to be eliminated. .. note::. This pass is somewhat limited in its scope (only support non-address taken; globals), but is very quick analysis. The ``-steens-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^. The ``-steens-aa`` pass implements a variation on the well-known ""Steensgaard's; algorithm"" for interprocedural alias analysis. Steensgaard's algorithm is a; unification-based, flow-insensitive, context-insensitive, and field-insensitive; alias analysis that is also very scalable (effectively linear time). The LLVM ``-steens-aa`` pass implements a ""speculatively field-**sensitive**""; version of Steensgaard's algorithm using the Data Structure Analysis framework.; This gives it substantially more precision than the standard algorithm while; maintaining excellent analysis scalability. .. note::. ``-steens-aa`` is available in the optional ""poolalloc"" module. It is not part; of the LLVM core. The ``-ds-aa`` pass; ^^^^^^^^^^^^^^^^^^^. The ``-ds-aa`` pass implements the full Data Structure Analysis algorithm. Data; Structure Analysis is a modular unification-based, flow-insensitive,; context-**sensitive**, and speculatively field-**sensitive** alias; analysis that is also quite scalable, usually at ``O(n * log(n))``. This algorithm is capable of responding to a full variety of alias analysis; queries, and can provide context-sensitive mod/ref information as well. The; only major facility not implemented",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:25700,scalab,scalable,25700,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['scalab'],['scalable']
Performance,"nterrelated sections. Comdats have a name which represents the COMDAT key and a selection kind to; provide input on how the linker deduplicates comdats with the same key in two; different object files. A comdat must be included or omitted as a unit.; Discarding the whole comdat is allowed but discarding a subset is not. A global object may be a member of at most one comdat. Aliases are placed in the; same COMDAT that their aliasee computes to, if any. Syntax::. $<Name> = comdat SelectionKind. For selection kinds other than ``nodeduplicate``, only one of the duplicate; comdats may be retained by the linker and the members of the remaining comdats; must be discarded. The following selection kinds are supported:. ``any``; The linker may choose any COMDAT key, the choice is arbitrary.; ``exactmatch``; The linker may choose any COMDAT key but the sections must contain the; same data.; ``largest``; The linker will choose the section containing the largest COMDAT key.; ``nodeduplicate``; No deduplication is performed.; ``samesize``; The linker may choose any COMDAT key but the sections must contain the; same amount of data. - XCOFF and Mach-O don't support COMDATs.; - COFF supports all selection kinds. Non-``nodeduplicate`` selection kinds need; a non-local linkage COMDAT symbol.; - ELF supports ``any`` and ``nodeduplicate``.; - WebAssembly only supports ``any``. Here is an example of a COFF COMDAT where a function will only be selected if; the COMDAT key's section is the largest:. .. code-block:: text. $foo = comdat largest; @foo = global i32 2, comdat($foo). define void @bar() comdat($foo) {; ret void; }. In a COFF object file, this will create a COMDAT section with selection kind; ``IMAGE_COMDAT_SELECT_LARGEST`` containing the contents of the ``@foo`` symbol; and another COMDAT section with selection kind; ``IMAGE_COMDAT_SELECT_ASSOCIATIVE`` which is associated with the first COMDAT; section and contains the contents of the ``@bar`` symbol. As a syntactic sugar the ``$na",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:46455,perform,performed,46455,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"ntheses, and groups can be referenced in order using the dollar; sign with a number (`$1` for instance) in *subst*. Matching and substitution for multiple URL schemas are supported by; using in addition directives `dsmgrd.urlregex2` up to; `dsmgrd.urlregex4` which have the same syntax of this one. Example of URL translation via regexp:. > - Configuration line:; >; > dsmgrd.urlregex alien://(.*)$ root://xrd.cern.ch/$1; >; > - Source URL:; >; > alien:///alice/data/2012/LHC12b/000178209/ESDs/pass1/12000178209061.17/AliESDs.root; >; > - Resulting URL:; >; > root://xrd.cern.ch//alice/data/2012/LHC12b/000178209/ESDs/pass1/12000178209061.17/AliESDs.root; >; dsmgrd.sleepsecs *secs*; : Seconds to sleep between each loop. The dataset stager checks at; each loop the status of the managed transfers. Defaults to **30; seconds**. dsmgrd.scandseveryloops *n*; : Every `n` loops, the dataset repository is checked for newly; incoming staging requests. Defaults to **10**. dsmgrd.parallelxfrs *n*; : Number of concurrent transfers. Defaults to **8**. dsmgrd.stagecmd *shell\_command*; : Command to run in order to stage each file. It might be whatever you; want (executable, shell script...). If you add `$URLTOSTAGE` and/or; `$TREENAME` in the *shell\_command*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:3584,concurren,concurrent,3584,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,1,['concurren'],['concurrent']
Performance,"ntics:; """""""""""""""""""". The maximum value this operation can clamp to is the largest signed value; representable by the bit width of the arguments. The minimum value is the; smallest signed value representable by this bit width. Examples; """""""""""""""""". .. code-block:: llvm. %res = call i4 @llvm.sadd.sat.i4(i4 1, i4 2) ; %res = 3; %res = call i4 @llvm.sadd.sat.i4(i4 5, i4 6) ; %res = 7; %res = call i4 @llvm.sadd.sat.i4(i4 -4, i4 2) ; %res = -2; %res = call i4 @llvm.sadd.sat.i4(i4 -4, i4 -5) ; %res = -8. '``llvm.uadd.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.uadd.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.uadd.sat.i16(i16 %a, i16 %b); declare i32 @llvm.uadd.sat.i32(i32 %a, i32 %b); declare i64 @llvm.uadd.sat.i64(i64 %a, i64 %b); declare <4 x i32> @llvm.uadd.sat.v4i32(<4 x i32> %a, <4 x i32> %b). Overview; """""""""""""""""". The '``llvm.uadd.sat``' family of intrinsic functions perform unsigned; saturating addition on the 2 arguments. Arguments; """""""""""""""""""". The arguments (%a and %b) and the result may be of integer types of any bit; width, but they must have the same bit width. ``%a`` and ``%b`` are the two; values that will undergo unsigned addition. Semantics:; """""""""""""""""""". The maximum value this operation can clamp to is the largest unsigned value; representable by the bit width of the arguments. Because this is an unsigned; operation, the result will never saturate towards zero. Examples; """""""""""""""""". .. code-block:: llvm. %res = call i4 @llvm.uadd.sat.i4(i4 1, i4 2) ; %res = 3; %res = call i4 @llvm.uadd.sat.i4(i4 5, i4 6) ; %res = 11; %res = call i4 @llvm.uadd.sat.i4(i4 8, i4 8) ; %res = 15. '``llvm.ssub.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.ssub.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.ssub.sat.i16(i16 %a, i16 %b); declare i32 @llvm.ssub.sat.i32",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:612706,perform,perform,612706,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"ntics:; """""""""""""""""""". The maximum value this operation can clamp to is the largest signed value; representable by the bit width of the arguments. The minimum value is the; smallest signed value representable by this bit width. Examples; """""""""""""""""". .. code-block:: llvm. %res = call i4 @llvm.ssub.sat.i4(i4 2, i4 1) ; %res = 1; %res = call i4 @llvm.ssub.sat.i4(i4 2, i4 6) ; %res = -4; %res = call i4 @llvm.ssub.sat.i4(i4 -4, i4 5) ; %res = -8; %res = call i4 @llvm.ssub.sat.i4(i4 4, i4 -5) ; %res = 7. '``llvm.usub.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.usub.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.usub.sat.i16(i16 %a, i16 %b); declare i32 @llvm.usub.sat.i32(i32 %a, i32 %b); declare i64 @llvm.usub.sat.i64(i64 %a, i64 %b); declare <4 x i32> @llvm.usub.sat.v4i32(<4 x i32> %a, <4 x i32> %b). Overview; """""""""""""""""". The '``llvm.usub.sat``' family of intrinsic functions perform unsigned; saturating subtraction on the 2 arguments. Arguments; """""""""""""""""""". The arguments (%a and %b) and the result may be of integer types of any bit; width, but they must have the same bit width. ``%a`` and ``%b`` are the two; values that will undergo unsigned subtraction. Semantics:; """""""""""""""""""". The minimum value this operation can clamp to is 0, which is the smallest; unsigned value representable by the bit width of the unsigned arguments.; Because this is an unsigned operation, the result will never saturate towards; the largest possible value representable by this bit width. Examples; """""""""""""""""". .. code-block:: llvm. %res = call i4 @llvm.usub.sat.i4(i4 2, i4 1) ; %res = 1; %res = call i4 @llvm.usub.sat.i4(i4 2, i4 6) ; %res = 0. '``llvm.sshl.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sshl.sat``; on integers or vectors of integers of any bit width. ::. declare i16 @llvm.sshl.sat.i16(i16 %a, i16 %b); decl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:615199,perform,perform,615199,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance,"nto title and body separated by a blank line. * If you're not the original author, ensure the 'Author' property of the commit is; set to the original author and the 'Committer' property is set to yourself.; You can use a command similar to; ``git commit --amend --author=""John Doe <jdoe@llvm.org>""`` to correct the; author property if it is incorrect. See `Attribution of Changes`_ for more; information including the method we used for attribution before the project; migrated to git. In the rare situation where there are multiple authors, please use the `git; tag 'Co-authored-by:' to list the additional authors; <https://github.blog/2018-01-29-commit-together-with-co-authors/>`_. * The title should be concise. Because all commits are emailed to the list with; the first line as the subject, long titles are frowned upon. Short titles; also look better in `git log`. * When the changes are restricted to a specific part of the code (e.g. a; back-end or optimization pass), it is customary to add a tag to the; beginning of the line in square brackets. For example, ""[SCEV] ...""; or ""[OpenMP] ..."". This helps email filters and searches for post-commit; reviews. * The body, if it exists, should be separated from the title by an empty line. * The body should be concise, but explanatory, including a complete; reasoning. Unless it is required to understand the change, examples,; code snippets and gory details should be left to bug comments, web; review or the mailing list. * Text formatting and spelling should follow the same rules as documentation; and in-code comments, ex. capitalization, full stop, etc. * If the commit is a bug fix on top of another recently committed patch, or a; revert or reapply of a patch, include the git commit hash of the prior; related commit. This could be as simple as ""Revert commit NNNN because it; caused PR#"". * If the patch has been reviewed, add a link to its review page, as shown; `here <https://www.llvm.org/docs/Phabricator.html#committing-a-chang",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:16561,optimiz,optimization,16561,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['optimiz'],['optimization']
Performance,"ntrinsics return a pointer to a promise; from a coroutine handle. This argument only accepts constants. Semantics:; """""""""""""""""""". Using this intrinsic on a coroutine that does not have a coroutine promise; leads to undefined behavior. It is possible to read and modify coroutine; promise of the coroutine which is currently executing. The coroutine author and; a coroutine user are responsible to makes sure there is no data races. Example:; """""""""""""""". .. code-block:: llvm. define ptr @f(i32 %n) {; entry:; %promise = alloca i32; ; the second argument to coro.id points to the coroutine promise.; %id = call token @llvm.coro.id(i32 0, ptr %promise, ptr null, ptr null); ...; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc); ...; store i32 42, ptr %promise ; store something into the promise; ...; ret ptr %hdl; }. define i32 @main() {; entry:; %hdl = call ptr @f(i32 4) ; starts the coroutine and returns its handle; %promise.addr = call ptr @llvm.coro.promise(ptr %hdl, i32 4, i1 false); %val = load i32, ptr %promise.addr ; load a value from the promise; call void @print(i32 %val); call void @llvm.coro.destroy(ptr %hdl); ret i32 0; }. .. _coroutine intrinsics:. Coroutine Structure Intrinsics; ------------------------------; Intrinsics described in this section are used within a coroutine to describe; the coroutine structure. They should not be used outside of a coroutine. .. _coro.size:. 'llvm.coro.size' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.coro.size.i32(); declare i64 @llvm.coro.size.i64(). Overview:; """""""""""""""""". The '``llvm.coro.size``' intrinsic returns the number of bytes; required to store a `coroutine frame`_. This is only supported for; switched-resume coroutines. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". The `coro.size` intrinsic is lowered to a constant representing the size of; the coroutine frame. .. _coro.align:. 'llvm.coro.align' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; ::. declare i32 @llvm.cor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:30953,load,load,30953,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['load'],['load']
Performance,"ntrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above, consider proposing a piece; of metadata which provides the optimization hint you need. Such extensions are; relatively common and are generally well received by the community. You will; need to ensure that your proposal is sufficiently general so that it benefits; others if you wish to contribute it upstream. You should also consider describing the problem you're facing on `Discourse; <https://discourse.llvm.org>`_ and asking for advice.; It's entirely possible someone ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:13022,tune,tuned,13022,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['tune'],['tuned']
Performance,"ntroduced among the functions set: we define comparison; that answers for every two functions which of them is greater. It allows to; arrange functions into the binary tree. For every new function we check for equivalent in tree. If equivalent exists we fold such functions. If both functions are overridable,; we move the functionality into a new internal function and leave two; overridable thunks to it. If there is no equivalent, then we add this function to tree. Lookup routine has O(log(n)) complexity, while whole merging process has; complexity of O(n*log(n)). Read; :doc:`this <MergeFunctions>`; article for more details. ``mergereturn``: Unify function exit nodes; ------------------------------------------. Ensure that functions have at most one ``ret`` instruction in them.; Additionally, it keeps track of which node is the new exit node of the CFG. ``partial-inliner``: Partial Inliner; ------------------------------------. This pass performs partial inlining, typically by inlining an ``if`` statement; that surrounds the body of the function. ``reassociate``: Reassociate expressions; ----------------------------------------. This pass reassociates commutative expressions in an order that is designed to; promote better constant propagation, GCSE, :ref:`LICM <passes-licm>`, PRE, etc. For example: 4 + (x + 5)  x + (4 + 5). In the implementation of this algorithm, constants are assigned rank = 0,; function arguments are rank = 1, and other values are assigned ranks; corresponding to the reverse post order traversal of current function (starting; at 2), which effectively gives values in deep loops higher rank than values not; in loops. ``rel-lookup-table-converter``: Relative lookup table converter; ---------------------------------------------------------------. This pass converts lookup tables to PIC-friendly relative lookup tables. ``reg2mem``: Demote all values to stack slots; ---------------------------------------------. This file demotes all registers to memory",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:32189,perform,performs,32189,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['perform'],['performs']
Performance,"ntry in the branch and no lower than 8 bytes). TTree::Process. Add support for the flag TSelector::kAbortFile. TTree::Draw. The line width setting was missing in a few places.; Namely support the option 'a' for TGraphs in TTree::Draw (delegate the axis management to the TGraph object). TTreeSQL. Allow TTreeSQL to see temporary tables.; Avoid creating the unnecessary array fEntryOffset ... which when its content is always set to zero actually prevent reading text field with TTreeSQL.; Properly find the column even if they were not created by TTreeSQL itself. Fix the loading of data for the last column. Other. Update the branch split mechanism to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit).; In TChain::ls, print the name of the chain and indent the list of files (this fixes #79909).; When setting fBranch in the loaded basket, make sure to set it also for the first/only basket ; this prevents a crash when calling SetBasketSize for a split top level branch in a file produced by v4.00/08.; In TTree::Streamer, if the object we are reading in was already attached to a directory, let's make sure to unregister the object before setting fDirectory to zero.; Prevent TChainIndex and TTreeIndex from finding the branches from the friend tree when looking up the value in the master/parent TTree. This fixes #79166.; Update GetEntryNumberFriend and related functions to retun a Long64_t as needed.; Fix the case of a split collection which contains a class with one; data member which is an instance of a class with more than one base; class some of which are not split (for example if one the base class; is std::vector<int>).; Fix the problem reported at #11890; by making sure that TChain::ResetBranchAddress(TBranch*) also record the reset in the; chain's meta information about branches.; Allow the output name passed to MakeProxy to be either a classname (to which will be added .h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:3512,load,loaded,3512,tree/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html,2,['load'],['loaded']
Performance,"nts are fixed zeros. //===---------------------------------------------------------------------===//. This code generates ugly code, probably due to costs being off or something:. define void @test(float* %P, <4 x float>* %P2 ) {; %xFloat0.688 = load float* %P; %tmp = load <4 x float>* %P2; %inFloat3.713 = insertelement <4 x float> %tmp, float 0.0, i32 3; store <4 x float> %inFloat3.713, <4 x float>* %P2; ret void; }. Generates:. _test:; 	movl	8(%esp), %eax; 	movaps	(%eax), %xmm0; 	pxor	%xmm1, %xmm1; 	movaps	%xmm0, %xmm2; 	shufps	$50, %xmm1, %xmm2; 	shufps	$132, %xmm2, %xmm0; 	movaps	%xmm0, (%eax); 	ret. Would it be better to generate:. _test:; movl 8(%esp), %ecx; movaps (%ecx), %xmm0; 	xor %eax, %eax; pinsrw $6, %eax, %xmm0; pinsrw $7, %eax, %xmm0; movaps %xmm0, (%ecx); ret. ?. //===---------------------------------------------------------------------===//. Some useful information in the Apple Altivec / SSE Migration Guide:. http://developer.apple.com/documentation/Performance/Conceptual/; Accelerate_sse_migration/index.html. e.g. SSE select using and, andnot, or. Various SSE compare translations. //===---------------------------------------------------------------------===//. Add hooks to commute some CMPP operations. //===---------------------------------------------------------------------===//. Apply the same transformation that merged four float into a single 128-bit load; to loads from constant pool. //===---------------------------------------------------------------------===//. Floating point max / min are commutable when -enable-unsafe-fp-path is; specified. We should turn int_x86_sse_max_ss and X86ISD::FMIN etc. into other; nodes which are selected to max / min instructions that are marked commutable. //===---------------------------------------------------------------------===//. We should materialize vector constants like ""all ones"" and ""signbit"" with ; code like:. cmpeqps xmm1, xmm1 ; xmm1 = all-ones. and:; cmpeqps xmm1, xmm1 ; xmm1 = all-ones; psrlq x",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:9039,Perform,Performance,9039,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,1,['Perform'],['Performance']
Performance,"nts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the L1 cache.; Therefore, they do not use the sc0 bit for coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to servic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:286553,cache,cache,286553,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"nts to be stored. The number of elements to be stored is equal to the number of active bits in the mask. Arguments:; """""""""""""""""""". The first operand is the input vector, from which elements are collected and written to memory. The second operand is the base pointer for the store, it has the same underlying type as the element of the input vector operand. The third operand is the mask, a vector of boolean values. The mask and the input vector must have the same number of vector elements. Semantics:; """""""""""""""""""". The '``llvm.masked.compressstore``' intrinsic is designed for compressing data in memory. It allows to collect elements from possibly non-adjacent lanes of a vector and store them contiguously in memory in one IR operation. It is useful for targets that support compressing store operations and allows vectorizing loops with cross-iteration dependences like in the following example:. .. code-block:: c. // In this loop we load elements from A and store them consecutively in B; double *A, B; int *C;; for (int i = 0; i < size; ++i) {; if (C[i] != 0); B[j++] = A[i]; }. .. code-block:: llvm. ; Load elements from A.; %Tmp = call <8 x double> @llvm.masked.load.v8f64.p0(ptr %Aptr, i32 8, <8 x i1> %Mask, <8 x double> poison); ; Store all selected elements consecutively in array B; call <void> @llvm.masked.compressstore.v8f64(<8 x double> %Tmp, ptr %Bptr, <8 x i1> %Mask). ; %Bptr should be increased on each iteration according to the number of '1' elements in the Mask.; %MaskI = bitcast <8 x i1> %Mask to i8; %MaskIPopcnt = call i8 @llvm.ctpop.i8(i8 %MaskI); %MaskI64 = zext i8 %MaskIPopcnt to i64; %BNextInd = add i64 %BInd, %MaskI64. Other targets may support this intrinsic differently, for example, by lowering it into a sequence of branches that guard scalar store operations. Memory Use Markers; ------------------. This class of intrinsics provides information about the; :ref:`lifetime of memory objects <objectlifetime>` and ranges where variables; are immutable. .. _int_li",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:859954,load,load,859954,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"nts with negative weights are ignored in the training (but are included for testing and performance evaluation). Configuration options for MVA method :. Configuration options reference for MVA method: Fisher. Option Array Default value Predefined values Description. V No False  Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None  List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False  Print method-specific help message. CreateMVAPdfs No False  Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False  Events with negative weights are ignored in the training (but are included for testing and performance evaluation). Method No Fisher Fisher, Mahalanobis Discrimination method. Configuration options for MVA method :. Configuration options reference for MVA method: PDERS. Option Array Default value Predefined values Description. V No False  Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None  List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False  Print method-specific help message. CreateMVAPdfs No False  Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False  Events with ne",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:3318,perform,performance,3318,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,2,['perform'],['performance']
Performance,"nts:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X86 backend; ---------------. The X86 code generator lives in the ``lib/Target/X86`` directory. This code; generator is capable of targeting a variety of x86-32 and x86-64 processors, an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88378,optimiz,optimization,88378,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,2,"['optimiz', 'perform']","['optimization', 'performed']"
Performance,"numVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct mapping is nice,; but sometimes you can't or don't want to preserve the mapping, which is when you; would use it. Named Alternatives; ------------------. Another useful argument form is a named alternative style. We shall use this; style in our compiler to specify different debug levels that can be used.; Instead of each debug level being its own switch, we want to support the; following options, of which only one can be specified at a time:; ""``--debug-level=none``"", ""``--debug-level=quick``"",; ""``--debug-level=detailed``"". To do this, we use the exact same format as our; optimization level flags, but we also specify an option nam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:16280,optimiz,optimization,16280,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,5,['optimiz'],"['optimization', 'optimizations']"
Performance,"nup.; Usually used in the first line, so it is visible without opening the; actual commit email. O; -; .. _object pointer:; .. _object pointers:. **Object Pointer**; A pointer to an object such that the garbage collector is able to trace; references contained within the object. This term is used in opposition to; `derived pointer`_. P; -. **PGO**; Profile-Guided Optimization. **PR**; Problem report. A bug filed on `the LLVM Bug Tracking System; <https://bugs.llvm.org/enter_bug.cgi>`_. **PRE**; Partial Redundancy Elimination. R; -. **RAUW**. Replace All Uses With. The functions ``User::replaceUsesOfWith()``,; ``Value::replaceAllUsesWith()``, and; ``Constant::replaceUsesOfWithOnConstant()`` implement the replacement of one; Value with another by iterating over its def/use chain and fixing up all of; the pointers to point to the new value. See; also `def/use chains <ProgrammersManual.html#iterating-over-def-use-use-def-chains>`_. **Reassociation**; Rearranging associative expressions to promote better redundancy elimination; and other optimization. For example, changing ``(A+B-A)`` into ``(B+A-A)``,; permitting it to be optimized into ``(B+0)`` then ``(B)``. **RFC**; Request for Comment. An email sent to a project mailing list in order to; solicit feedback on a proposed change. .. _roots:; .. _stack roots:. **Root**; In garbage collection, a pointer variable lying outside of the `heap`_ from; which the collector begins its reachability analysis. In the context of code; generation, ""root"" almost always refers to a ""stack root"" --- a local or; temporary variable within an executing function. **RPO**; Reverse postorder. **RTTI**; Run-time Type Information. S; -. .. _safe point:. **Safe Point**; In garbage collection, it is necessary to identify `stack roots`_ so that; reachability analysis may proceed. It may be infeasible to provide this; information for every instruction, so instead the information is; calculated only at designated safe points. With a copying collector,;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst:6871,optimiz,optimization,6871,interpreter/llvm-project/llvm/docs/Lexicon.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst,1,['optimiz'],['optimization']
Performance,"nv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - system *none* 1. buffer_wbl2 sc0=1 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:329487,load,load,329487,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"nv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vm/vscnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw-with-return-valu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:351020,load,load,351020,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"nv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acq_rel - agent - generic 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. flat_atomic; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:322802,load,load,322802,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"nvalidating the; caches. 5. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; acquire-fence-paired; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:274859,load,load,274859,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"nvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:270964,perform,performing,270964,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"nwind ssp {; entry:; %0 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %1 = getelementptr %struct.bf* %0, i64 0, i32 1 ; <i16*> [#uses=1]; %2 = bitcast i16* %1 to i32* ; <i32*> [#uses=2]; %3 = load i32* %2, align 1 ; <i32> [#uses=1]; %4 = and i32 %3, -65537 ; <i32> [#uses=1]; store i32 %4, i32* %2, align 1; %5 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %6 = getelementptr %struct.bf* %5, i64 0, i32 1 ; <i16*> [#uses=1]; %7 = bitcast i16* %6 to i32* ; <i32*> [#uses=2]; %8 = load i32* %7, align 1 ; <i32> [#uses=1]; %9 = and i32 %8, -131073 ; <i32> [#uses=1]; store i32 %9, i32* %7, align 1; ret void; }. LLVM currently emits this:. movq bfi(%rip), %rax; andl $-65537, 8(%rax); movq bfi(%rip), %rax; andl $-131073, 8(%rax); ret. It could narrow the loads and stores to emit this:. movq bfi(%rip), %rax; andb $-2, 10(%rax); movq bfi(%rip), %rax; andb $-3, 10(%rax); ret. The trouble is that there is a TokenFactor between the store and the; load, making it non-trivial to determine if there's anything between; the load and the store which would prohibit narrowing. //===---------------------------------------------------------------------===//. This code:; void foo(unsigned x) {; if (x == 0) bar();; else if (x == 1) qux();; }. currently compiles into:; _foo:; 	movl	4(%esp), %eax; 	cmpl	$1, %eax; 	je	LBB0_3; 	testl	%eax, %eax; 	jne	LBB0_4. the testl could be removed:; _foo:; 	movl	4(%esp), %eax; 	cmpl	$1, %eax; 	je	LBB0_3; 	jb	LBB0_4. 0 is the only unsigned number < 1. //===---------------------------------------------------------------------===//. This code:. %0 = type { i32, i1 }. define i32 @add32carry(i32 %sum, i32 %x) nounwind readnone ssp {; entry:; %uadd = tail call %0 @llvm.uadd.with.overflow.i32(i32 %sum, i32 %x); %cmp = extractvalue %0 %uadd, 1; %inc = zext i1 %cmp to i32; %add = add i32 %x, %sum; %z.0 = add i32 %add, %inc; ret i32 %z.0; }. declare %0 @llvm.uadd.with.overflow.i32(i32, i32) nounwind readnone. compiles to:. _add32carry: ## @ad",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:38424,load,load,38424,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,4,['load'],['load']
Performance,"ny leaf to a histogram; it. The toolbar in the upper part can be used for user commands, changing; the drawing option and the histogram name. The lower part contains three; picture buttons that draw a histogram, stop the current command, and; refresh the tree. The three check buttons toggle the following:. `Hist`- the histogram drawing mode;. `Scan`- enables redirecting of `TTree::Scan `command in an ASCII file;. `Rec` - enables recording of the last issued command. - ![](pictures/020000F1.jpg) To draw more than one dimension you can drag; and drop any leaf to the `X,Y,Z` boxes"". Then push the Draw button,; witch is marked with the purple icon on the bottom left. - ![](pictures/030000F2.png) All commands can be interrupted at any time; by pressing this button. - ![](pictures/030000F3.png) The method **`TTree::Refresh`** is called by; pressing the refresh button in `TTreeViewer`. It redraws the current; exposed expression. Calling `TTree::Refresh` is useful when a tree is; produced by a writer process and concurrently analyzed by one or more; readers. - ![](pictures/030000F4.png) To add a cut/weight to the histogram, enter an; expression in the ""cut box"". The cut box is the one with the scissor; icon. Below them there are two text widgets for specifying the input and; output event lists. A Tree Viewer session is made by the list of; user-defined expressions and cuts, applying to a specified tree. A; session can be saved using File / `SaveSource` menu or the `SaveSource`; method from the context menu of the right panel. This will create a; macro having as default name `treeviewer.C` that can be ran at any time; to reproduce the session. Besides the list of user-defined expressions, a session may contain a; list of RECORDS. A record can be produced in the following way: dragging; leaves/expression on X/Y/Z; changing drawing options; clicking the RED; button on the bottom when happy with the histogram. NOTE that just double clicking a leaf will not produce a record: the;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:8404,concurren,concurrently,8404,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['concurren'],['concurrently']
Performance,"ny; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251192,load,loads,251192,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"nything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:6893,optimiz,optimizer,6893,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['optimiz'],['optimizer']
Performance,"o 0 are ignored by Cling.; * [[#14333](https://github.com/root-project/root/issues/14333)] - ""Empty plot"" for df014_CSVDataSource.C ; * [[#14331](https://github.com/root-project/root/issues/14331)] - Unexpected behaviour when using the Project3D function to make a TH2 from a TH3; * [[#14329](https://github.com/root-project/root/issues/14329)] - [RF] RDataFrameToRooFit - Clarification on returned object; * [[#14324](https://github.com/root-project/root/issues/14324)] - Compatibility Issue with thisroot.sh and zsh ; * [[#14320](https://github.com/root-project/root/issues/14320)] - [RF] Wrong analytic integrals when using Gaussians with sigma depending on the observable; * [[#14303](https://github.com/root-project/root/issues/14303)] - Test failure with `nbconvert-7.14`; * [[#14302](https://github.com/root-project/root/issues/14302)] - The command ""root --notebook"" is not allowed on Windows 11; * [[#14277](https://github.com/root-project/root/issues/14277)] - Cling triggers a huge number of `openat` calls when loading libraries; * [[#14263](https://github.com/root-project/root/issues/14263)] - [tmva] When using DNN_USE_CBLAS, CMakeLists should link publicly to gsl instead of privately; * [[#14256](https://github.com/root-project/root/issues/14256)] - TAxis::GetTicks and TAxis::SetTicks are inconsistent. Significantly so.; * [[#14244](https://github.com/root-project/root/issues/14244)] - String comparison operators defined in TString.h should be defined as constexpr; * [[#14229](https://github.com/root-project/root/issues/14229)] - [6.30] root-config --git-revision broken; * [[#14225](https://github.com/root-project/root/issues/14225)] - [RF] Segmentation fault in ROOT 6.30 workspace creation; * [[#14223](https://github.com/root-project/root/issues/14223)] - Extremely long startup time when loading dictionaries with pyroot; * [[#14219](https://github.com/root-project/root/issues/14219)] - [cling] Use deduction guides for llvm::ArrayRef; * [[#14211](https://github.com/roo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:33640,load,loading,33640,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['load'],['loading']
Performance,"o 10 bit type parameters and 6; floating-point parameters are supported.; - On *AArch64* only up to 4 32-bit floating-point parameters,; 4 64-bit floating-point parameters, and 10 bit type parameters; are supported.; - *RISCV64* only supports up to 11 bit type parameters, 4; 32-bit floating-point parameters, and 4 64-bit floating-point; parameters. This calling convention supports `tail call; optimization <CodeGenerator.html#tail-call-optimization>`_ but requires; both the caller and callee are using it.; ""``cc 11``"" - The HiPE calling convention; This calling convention has been implemented specifically for use by; the `High-Performance Erlang; (HiPE) <http://www.it.uu.se/research/group/hipe/>`_ compiler, *the*; native code compiler of the `Ericsson's Open Source Erlang/OTP; system <http://www.erlang.org/download.shtml>`_. It uses more; registers for argument passing than the ordinary C calling; convention and defines no callee-saved registers. The calling; convention properly supports `tail call; optimization <CodeGenerator.html#tail-call-optimization>`_ but requires; that both the caller and the callee use it. It uses a *register pinning*; mechanism, similar to GHC's convention, for keeping frequently; accessed runtime components pinned to specific hardware registers.; At the moment only X86 supports this convention (both 32 and 64; bit).; ""``anyregcc``"" - Dynamic calling convention for code patching; This is a special convention that supports patching an arbitrary code; sequence in place of a call site. This convention forces the call; arguments into registers but allows them to be dynamically; allocated. This can currently only be used with calls to; llvm.experimental.patchpoint because only this intrinsic records; the location of its arguments in a side table. See :doc:`StackMaps`.; ""``preserve_mostcc``"" - The `PreserveMost` calling convention; This calling convention attempts to make the code in the caller as; unintrusive as possible. This convention behaves i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:15358,optimiz,optimization,15358,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance,"o SNaN rather than QNaN. Similarly, if all input NaNs are preferred (or if; there are no input NaNs) and the target does not have any ""extra"" NaN payloads,; then the output NaN is guaranteed to be preferred. Floating-point math operations are allowed to treat all NaNs as if they were; quiet NaNs. For example, ""pow(1.0, SNaN)"" may be simplified to 1.0. Code that requires different behavior than this should use the; :ref:`Constrained Floating-Point Intrinsics <constrainedfp>`.; In particular, constrained intrinsics rule out the ""Unchanged NaN propagation""; case; they are guaranteed to return a QNaN. Unfortunately, due to hard-or-impossible-to-fix issues, LLVM violates its own; specification on some architectures:. - x86-32 without SSE2 enabled may convert floating-point values to x86_fp80 and; back when performing floating-point math operations; this can lead to results; with different precision than expected and it can alter NaN values. Since; optimizations can make contradicting assumptions, this can lead to arbitrary; miscompilations. See `issue #44218; <https://github.com/llvm/llvm-project/issues/44218>`_.; - x86-32 (even with SSE2 enabled) may implicitly perform such a conversion on; values returned from a function for some calling conventions. See `issue; #66803 <https://github.com/llvm/llvm-project/issues/66803>`_.; - Older MIPS versions use the opposite polarity for the quiet/signaling bit, and; LLVM does not correctly represent this. See `issue #60796; <https://github.com/llvm/llvm-project/issues/60796>`_. .. _fastmath:. Fast-Math Flags; ---------------. LLVM IR floating-point operations (:ref:`fneg <i_fneg>`, :ref:`fadd <i_fadd>`,; :ref:`fsub <i_fsub>`, :ref:`fmul <i_fmul>`, :ref:`fdiv <i_fdiv>`,; :ref:`frem <i_frem>`, :ref:`fcmp <i_fcmp>`), :ref:`phi <i_phi>`,; :ref:`select <i_select>` and :ref:`call <i_call>`; may use the following flags to enable otherwise unsafe; floating-point transformations. ``nnan``; No NaNs - Allow optimizations to assume the argume",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:160839,optimiz,optimizations,160839,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"o a > 15. */; if ((a & ~7) > 8); bar ();; }; void; rshift_gt (unsigned int a); {; /* This is equivalent to a > 23. */; if ((a >> 2) > 5); bar ();; }. All should simplify to a single comparison. All of these are; currently not optimized with ""clang -emit-llvm-bc | opt; -O3"". //===---------------------------------------------------------------------===//. From GCC Bug 32605:; int c(int* x) {return (char*)x+2 == (char*)x;}; Should combine to 0. Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"" (although llc can optimize it). //===---------------------------------------------------------------------===//. int a(unsigned b) {return ((b << 31) | (b << 30)) >> 31;}; Should be combined to ""((b >> 1) | b) & 1"". Currently not optimized; with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(unsigned x, unsigned y) { return x | (y & 1) | (y & 2);}; Should combine to ""x | (y & 3)"". Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b, int c) {return (~a & c) | ((c|a) & b);}; Should fold to ""(~a & c) | (a & b)"". Currently not optimized with; ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a,int b) {return (~(a|b))|a;}; Should fold to ""a|~b"". Currently not optimized with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b) {return (a&&b) || (a&&!b);}; Should fold to ""a"". Currently not optimized with ""clang -emit-llvm-bc; | opt -O3"". //===---------------------------------------------------------------------===//. int a(int a, int b, int c) {return (a&&b) || (!a&&c);}; Should fold to ""a ? b : c"", or at least something sane. Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===--------------------------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:24006,optimiz,optimized,24006,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['optimiz'],['optimized']
Performance,"o accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolved O(N^2) scaling problem in ```TTree::Draw()``` observed when a branch that contains a; large TClonesArray where each element contains another small vector container.; - `TTree::TTree()` now takes the `TDirectory*` that the tree should be constructed in.; Defaults to `gDirectory`, i.e. the default behavior did not change.; - To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced.; This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained; (the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory).; - Added ```TBranchProxy::GetEntries``` to support leaflist variable size array and added ```TBranchProxy::GetArrayLength```.; - In ```TBranch::Streamer``` insured that we never steam already basket already written to disk. ### TDataFrame. #### New features; - Add `Alias`, a facility to specify an alternative name for a given column: `auto histo = mytdf.Alias(""myAlias"", ""myColumn"").Histo1D(""myAlias"");`. Especially useful for pyROOT users to deal with column names that are not valid C++ identifiers (e.g. `Filter(""1branch > 0"") --> Alias(""1branch"", ""branch1"").Filter(""branch1 > 0"")`.; - Add `Cache`, a facility to cache `TDataFrame`s in memory. All or some columns can be cached. Two versions of the method are proposed: one which allo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:10110,load,loaded,10110,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['load'],['loaded']
Performance,"o align to 8 byte); uint16 : Padding; uint16 : NumLiveOuts; LiveOuts[NumLiveOuts]; uint16 : Dwarf RegNum; uint8 : Reserved; uint8 : Size in Bytes; }; uint32 : Padding (only if required to align to 8 byte); }. The first byte of each location encodes a type that indicates how to; interpret the ``RegNum`` and ``Offset`` fields as follows:. ======== ========== =================== ===========================; Encoding Type Value Description; -------- ---------- ------------------- ---------------------------; 0x1 Register Reg Value in a register; 0x2 Direct Reg + Offset Frame index value; 0x3 Indirect [Reg + Offset] Spilled value; 0x4 Constant Offset Small constant; 0x5 ConstIndex Constants[Offset] Large constant; ======== ========== =================== ===========================. In the common case, a value is available in a register, and the; ``Offset`` field will be zero. Values spilled to the stack are encoded; as ``Indirect`` locations. The runtime must load those values from a; stack address, typically in the form ``[BP + Offset]``. If an; ``alloca`` value is passed directly to a stack map intrinsic, then; LLVM may fold the frame index into the stack map as an optimization to; avoid allocating a register or stack slot. These frame indices will be; encoded as ``Direct`` locations in the form ``BP + Offset``. LLVM may; also optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:13899,load,load,13899,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['load'],['load']
Performance,"o be reused in the cache. The code; generator may select special instructions to save cache bandwidth, such; as the ``MOVNT`` instruction on x86. The optional ``!invariant.load`` metadata must reference a single; metadata name ``<empty_node>`` corresponding to a metadata node with no; entries. If a load instruction tagged with the ``!invariant.load``; metadata is executed, the memory location referenced by the load has; to contain the same value at all points in the program where the; memory location is dereferenceable; otherwise, the behavior is; undefined. The optional ``!invariant.group`` metadata must reference a single metadata name; ``<empty_node>`` corresponding to a metadata node with no entries.; See ``invariant.group`` metadata :ref:`invariant.group <md_invariant.group>`. The optional ``!nonnull`` metadata must reference a single; metadata name ``<empty_node>`` corresponding to a metadata node with no; entries. The existence of the ``!nonnull`` metadata on the; instruction tells the optimizer that the value loaded is known to; never be null. If the value is null at runtime, a poison value is returned; instead. This is analogous to the ``nonnull`` attribute on parameters and; return values. This metadata can only be applied to loads of a pointer type. The optional ``!dereferenceable`` metadata must reference a single metadata; name ``<deref_bytes_node>`` corresponding to a metadata node with one ``i64``; entry.; See ``dereferenceable`` metadata :ref:`dereferenceable <md_dereferenceable>`. The optional ``!dereferenceable_or_null`` metadata must reference a single; metadata name ``<deref_bytes_node>`` corresponding to a metadata node with one; ``i64`` entry.; See ``dereferenceable_or_null`` metadata :ref:`dereferenceable_or_null; <md_dereferenceable_or_null>`. The optional ``!align`` metadata must reference a single metadata name; ``<align_node>`` corresponding to a metadata node with one ``i64`` entry.; The existence of the ``!align`` metadata on the instruct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:416158,optimiz,optimizer,416158,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['load', 'optimiz']","['loaded', 'optimizer']"
Performance,"o emit verbose output about; what it's doing; two -v options emit more information. Redirecting the; output of scan-build to a text file (make sure to redirect standard; error) is useful for filing bug reports against scan-build or the; analyzer, as we can see the exact options (and files) passed to the analyzer.; For more comprehensible logs, don't perform a parallel build.; Run './configure' through scan-build; If an analyzed project uses an autoconf generated configure script,; you will probably need to run configure script through; scan-build in order to analyze the project.; Example. $ scan-build ./configure; $ scan-build --keep-cc make. The reason configure also needs to be run through; scan-build is because scan-build scans your source files by; interposing on the compiler. This interposition is currently done by; scan-build temporarily setting the environment variable CC to; ccc-analyzer. The program ccc-analyzer acts like a fake; compiler, forwarding its command line arguments over to the compiler to perform; regular compilation and clang to perform static analysis.; Running configure typically generates makefiles that have hardwired; paths to the compiler, and by running configure through; scan-build that path is set to ccc-analyzer. Analyzing iPhone Projects; Conceptually Xcode projects for iPhone applications are nearly the same as; their cousins for desktop applications. scan-build can analyze these; projects as well, but users often encounter problems with just building their; iPhone projects from the command line because there are a few extra preparative; steps they need to take (e.g., setup code signing).; Recommendation: use ""Build and Analyze""; The absolute easiest way to analyze iPhone projects is to use the; Analyze; feature in Xcode (which is based on the Clang Static Analyzer). There a; user can analyze their project right from a menu without most of the setup; described later.; Instructions are available on this; website on how to use open sou",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/scan-build.html:7662,perform,perform,7662,interpreter/llvm-project/clang/www/analyzer/scan-build.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/scan-build.html,4,['perform'],['perform']
Performance,"o hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SIMD; hardware to allow a single instruction to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vectorization for the compiler to generate code that; promotes portions of an array into vector registers. For example, if the; hardware ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:34096,concurren,concurrent,34096,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['concurren'],['concurrent']
Performance,"o not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204469,optimiz,optimization-constraints-table,204469,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['optimiz'],['optimization-constraints-table']
Performance,"o one of; the limits (expressed as the distance to nearest limit divided by; distance between limits). The user must therefore be aware of the fact; that, for example, if they put limits of (0, 1010) on a parameter, then; the values 0.0 and 1. 0 will be indistinguishable to the accuracy of; most machines. The transformation also affects the parameter error matrix, of course,; so Minuit does a transformation of the error matrix (and the; ''parabolic'' parameter errors) when there are parameter limits. Users; should however realize that the transformation is only a linear; approximation, and that it cannot give a meaningful result if one or; more parameters is very close to a limit, where; $\frac{\partial Pext}{\partial Pint} \neq 0$. Therefore, it is; recommended that:. - Limits on variable parameters should be used only when needed in; order to prevent the parameter from taking on unphysical values. - When a satisfactory minimum has been found using limits, the; limits should then be removed if possible, in order to perform or; re-perform the error analysis without limits. ### How to Get the Right Answer from Minuit. `Minuit` offers the user a choice of several minimization algorithms.; The `MIGRAD` algorithm is in general the best minimized for nearly all; functions. It is a variable-metric method with inexact line search, a; stable metric updating scheme, and checks for positive-definiteness.; Its main weakness is that it depends heavily on knowledge of the first; derivatives, and fails miserably if they are very inaccurate. If parameter limits are needed, in spite of the side effects, then the; user should be aware of the following techniques to alleviate problems; caused by limits:. #### Getting the Right Minimum with Limits. If MIGRAD converges normally to a point where no parameter is near one; of its limits, then the existence of limits has probably not prevented; `Minuit` from finding the right minimum. On the other hand, if one or; more parameters is near it",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:57377,perform,perform,57377,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,2,['perform'],['perform']
Performance,"o pad the coverage mapping; data to give it the 8 byte alignment. Encoding; ========. The per-function coverage mapping data is encoded as a stream of bytes,; with a simple structure. The structure consists of the encoding; `types <cvmtypes_>`_ like variable-length unsigned integers, that; are used to encode `File ID Mapping`_, `Counter Expressions`_ and; the `Mapping Regions`_. The format of the structure follows:. ``[file id mapping, counter expressions, mapping regions]``. The translation unit filenames are encoded using the same encoding; `types <cvmtypes_>`_ as the per-function coverage mapping data, with the; following structure:. ``[numFilenames : LEB128, filename0 : string, filename1 : string, ...]``. .. _cvmtypes:. Types; -----. This section describes the basic types that are used by the encoding format; and can appear after ``:`` in the ``[foo : type]`` description. .. _LEB128:. LEB128; ^^^^^^. LEB128 is an unsigned integer value that is encoded using DWARF's LEB128; encoding, optimizing for the case where values are small; (1 byte for values less than 128). .. _CoverageStrings:. Strings; ^^^^^^^. ``[length : LEB128, characters...]``. String values are encoded with a `LEB value <LEB128_>`_ for the length; of the string and a sequence of bytes for its characters. .. _file id mapping:. File ID Mapping; ---------------. ``[numIndices : LEB128, filenameIndex0 : LEB128, filenameIndex1 : LEB128, ...]``. File id mapping in a function's coverage mapping stream; contains the indices into the translation unit's filenames array. Counter; -------. ``[value : LEB128]``. A `coverage mapping counter`_ is stored in a single `LEB value <LEB128_>`_.; It is composed of two things --- the `tag <counter-tag_>`_; which is stored in the lowest 2 bits, and the `counter data`_ which is stored; in the remaining bits. .. _counter-tag:. Tag:; ^^^^. The counter's tag encodes the counter's kind; and, if the counter is an expression, the expression's kind.; The possible tag values are:. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:23064,optimiz,optimizing,23064,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,1,['optimiz'],['optimizing']
Performance,"o preprocessor or that use a lot of constants). On the other hand, the ``IRBuilder`` is limited by the fact that it does; all of its analysis inline with the code as it is built. If you take a; slightly more complex example:. ::. ready> def test(x) (1+2+x)*(x+(1+2));; ready> Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double 3.000000e+00, %x; %addtmp1 = fadd double %x, 3.000000e+00; %multmp = fmul double %addtmp, %addtmp1; ret double %multmp; }. In this case, the LHS and RHS of the multiplication are the same value.; We'd really like to see this generate ""``tmp = x+3; result = tmp*tmp;``""; instead of computing ""``x+3``"" twice. Unfortunately, no amount of local analysis will be able to detect and; correct this. This requires two transformations: reassociation of; expressions (to make the add's lexically identical) and Common; Subexpression Elimination (CSE) to delete the redundant add instruction.; Fortunately, LLVM provides a broad range of optimizations that you can; use, in the form of ""passes"". LLVM Optimization Passes; ========================. LLVM provides many optimization passes, which do many different sorts of; things and have different tradeoffs. Unlike other systems, LLVM doesn't; hold to the mistaken notion that one set of optimizations is right for; all languages and for all situations. LLVM allows a compiler implementor; to make complete decisions about what optimizations to use, in which; order, and in what situation. As a concrete example, LLVM supports both ""whole module"" passes, which; look across as large of body of code as they can (often a whole file,; but if run at link time, this can be a substantial portion of the whole; program). It also supports and includes ""per-function"" passes which just; operate on a single function at a time, without looking at other; functions. For more information on passes and how they are run, see the; `How to Write a Pass <../../WritingAnLLVMPass.html>`_ document and the; `L",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:3226,optimiz,optimizations,3226,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimizations']
Performance,"o the CodeView Library.; //===----------------------------------------------------------------------===//; There is some code in the CodeView reader that was extracted/adapted; from 'lib/DebugInfo/CodeView/SymbolDumper.cpp' that can be used. //===----------------------------------------------------------------------===//; // Use of std::unordered_set instead of std::set.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125784#inline-1221421. Replace the std::set usage for DeducedScopes, UnresolvedScopes and; IdentifiedNamespaces with std::unordered_set and get the benefit; of the O(1) while inserting/searching, as the order is not important. //===----------------------------------------------------------------------===//; // Optimize 'LVNamespaceDeduction::find' funtion.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125784#inline-1296195. Optimize the 'find' method to use the proposed code:. LVStringRefs::iterator Iter = std::find_if(Components.begin(), Components.end(),; [](StringRef Name) {; return IdentifiedNamespaces.find(Name) == IdentifiedNamespaces.end();; });; LVStringRefs::size_type FirstNonNamespace = std::distance(Components.begin(), Iter);. //===----------------------------------------------------------------------===//; // Move all the printing support to a common module.; //===----------------------------------------------------------------------===//; Factor out printing functionality from the logical elements into a; common module. //===----------------------------------------------------------------------===//; // Refactor 'LVBinaryReader::processLines'.; //===----------------------------------------------------------------------===//; https://reviews.llvm.org/D125783#inline-1246155; https://reviews.llvm.org/D137156. During the traversal of the debug information sections, we created the; logical lines representing the disassembl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt:6919,Optimiz,Optimize,6919,interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-debuginfo-analyzer/README.txt,1,['Optimiz'],['Optimize']
Performance,"o the top left corner of the target canvas you would have to reset the; coordinates of the cloned pad. ## Legends. Legends for a graph are obtained with a **`TLegend`** object. This; object points to markers, lines, boxes, histograms, graphs and represent; their marker, line, fill attributes. Any object that has a marker or; line or fill attribute may have an associated legend. A **`TLegend`** is; a panel with several entries (class **`TLegendEntry`**) and is created; by the constructor. ``` {.cpp}; TLegend(Double_t x1, Double_t y1, Double_t x2, Double_t y2,; const char *header, Option_t *option); ```. The legend is defined with default coordinates, border size and option.; The legend coordinates (NDC) in the current pad are `x1`, `y1`, `x2`,; `y2`. The default text attributes for the legend are:. - Alignment = 12 left adjusted and vertically centered. - Angle = 0 (degrees). - Color = 1 (black). - Size = calculate when number of entries is known. - Font = helvetica-medium-r-normal scalable font = 42, and bold = 62; for title. The title is a regular entry and supports **`TLatex`**. The default is; no title (`header = 0`). The options are the same as for **`TPave`**; by; default, they are ""`brand`"". Once the legend box is created, one has to; add the text with the `AddEntry()` method:. ``` {.cpp}; TLegendEntry* TLegend::AddEntry(TObject *obj,; const char *label,; Option_t *option); ```. The parameters are:. - `*obj `is a pointer to an object having marker, line, or fill; attributes (a histogram, or a graph). - `label` is the label to be associated to the object. - `option`:. - ""L"" draw line associated with line attributes of `obj`, if `obj`; inherits from **`TAttLine`**. - ""P"" draw poly-marker associated with marker attributes of `obj`, if; `obj` inherits **`TAttMarker`**. - ""F"" draw a box with fill associated with fill attributes of `obj`,; if `obj` inherits **`TAttFill`**. One may also use the other form of the method `AddEntry`:. ``` {.cpp}; TLegendEntry* TLegend::A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:90190,scalab,scalable,90190,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['scalab'],['scalable']
Performance,"o use; supported options are libstdc++ and; libc++. If not specified, platform default will be used. .. option:: -rtlib=<library>. Specify the compiler runtime library to use; supported options are libgcc and; compiler-rt. If not specified, platform default will be used. .. option:: -ansi. Same as -std=c89. .. option:: -ObjC, -ObjC++. Treat source input files as Objective-C and Object-C++ inputs respectively. .. option:: -trigraphs. Enable trigraphs. .. option:: -ffreestanding. Indicate that the file should be compiled for a freestanding, not a hosted,; environment. Note that it is assumed that a freestanding environment will; additionally provide `memcpy`, `memmove`, `memset` and `memcmp`; implementations, as these are needed for efficient codegen for many programs. .. option:: -fno-builtin. Disable special handling and optimizations of well-known library functions,; like :c:func:`strlen` and :c:func:`malloc`. .. option:: -fno-builtin-<function>. Disable special handling and optimizations for the specific library function.; For example, ``-fno-builtin-strlen`` removes any special handling for the; :c:func:`strlen` library function. .. option:: -fno-builtin-std-<function>. Disable special handling and optimizations for the specific C++ standard; library function in namespace ``std``. For example,; ``-fno-builtin-std-move_if_noexcept`` removes any special handling for the; :cpp:func:`std::move_if_noexcept` library function. For C standard library functions that the C++ standard library also provides; in namespace ``std``, use :option:`-fno-builtin-\<function\>` instead. .. option:: -fmath-errno. Indicate that math functions should be treated as updating :c:data:`errno`. .. option:: -fpascal-strings. Enable support for Pascal-style strings with ""\\pfoo"". .. option:: -fms-extensions. Enable support for Microsoft extensions. .. option:: -fmsc-version=. Set ``_MSC_VER``. When on Windows, this defaults to either the same value as; the currently installed version of cl.exe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:6432,optimiz,optimizations,6432,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['optimiz'],['optimizations']
Performance,"o zero.; Defaults to ``-fstrict-float-cast-overflow``. .. option:: -f[no-]math-errno. Require math functions to indicate errors by setting errno.; The default varies by ToolChain. ``-fno-math-errno`` allows optimizations; that might cause standard C math functions to not set ``errno``.; For example, on some systems, the math function ``sqrt`` is specified; as setting ``errno`` to ``EDOM`` when the input is negative. On these; systems, the compiler cannot normally optimize a call to ``sqrt`` to use; inline code (e.g. the x86 ``sqrtsd`` instruction) without additional; checking to ensure that ``errno`` is set appropriately.; ``-fno-math-errno`` permits these transformations. On some targets, math library functions never set ``errno``, and so; ``-fno-math-errno`` is the default. This includes most BSD-derived; systems, including Darwin. .. option:: -f[no-]trapping-math. Control floating point exception behavior. ``-fno-trapping-math`` allows optimizations that assume that floating point operations cannot generate traps such as divide-by-zero, overflow and underflow. - The option ``-ftrapping-math`` behaves identically to ``-ffp-exception-behavior=strict``.; - The option ``-fno-trapping-math`` behaves identically to ``-ffp-exception-behavior=ignore``. This is the default. .. option:: -ffp-contract=<value>. Specify when the compiler is permitted to form fused floating-point; operations, such as fused multiply-add (FMA). Fused operations are; permitted to produce more precise results than performing the same; operations separately. The C standard permits intermediate floating-point results within an; expression to be computed with more precision than their type would; normally allow. This permits operation fusing, and Clang takes advantage; of this by default. This behavior can be controlled with the ``FP_CONTRACT``; and ``clang fp contract`` pragmas. Please refer to the pragma documentation; for a description of how the pragmas interact with this option. Valid values are:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:56358,optimiz,optimizations,56358,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,"o,/path/to/cache``; - ELF ld.lld (as of LLVM 5.0):; ``-Wl,--thinlto-cache-dir=/path/to/cache``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocache:/path/to/cache``. Cache Pruning; -------------. To help keep the size of the cache under control, ThinLTO supports cache; pruning. Cache pruning is supported with gold, ld64, and lld, but currently only; gold and lld allow you to control the policy with a policy string. The cache; policy must be specified with a linker option. - gold (as of LLVM 6.0):; ``-Wl,-plugin-opt,cache-policy=POLICY``; - ELF ld.lld (as of LLVM 5.0), Mach-O ld64.lld (as of LLVM 15.0):; ``-Wl,--thinlto-cache-policy=POLICY``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocachepolicy:POLICY``. A policy string is a series of key-value pairs separated by ``:`` characters.; Possible key-value pairs are:. - ``cache_size=X%``: The maximum size for the cache directory is ``X`` percent; of the available space on the disk. Set to 100 to indicate no limit,; 50 to indicate that the cache size will not be left over half the available; disk space. A value over 100 is invalid. A value of 0 disables the percentage; size-based pruning. The default is 75%. - ``cache_size_bytes=X``, ``cache_size_bytes=Xk``, ``cache_size_bytes=Xm``,; ``cache_size_bytes=Xg``:; Sets the maximum size for the cache directory to ``X`` bytes (or KB, MB,; GB respectively). A value over the amount of available space on the disk; will be reduced to the amount of available space. A value of 0 disables; the byte size-based pruning. The default is no byte size-based pruning. Note that ThinLTO will apply both size-based pruning policies simultaneously,; and changing one does not affect the other. For example, a policy of; ``cache_size_bytes=1g`` on its own will cause both the 1GB and default 75%; policies to be applied unless the default ``cache_size`` is overridden. - ``cache_size_files=X``:; Set the maximum number of files in the cache directory. Set to 0 to indicate; no limit. The default is 1000000 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:5877,cache,cache,5877,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,1,['cache'],['cache']
Performance,"o-]reciprocal-math. Allow division operations to be transformed into multiplication by a; reciprocal. This can be significantly faster than an ordinary division; but can also have significantly less precision. Defaults to; ``-fno-reciprocal-math``. .. option:: -f[no-]unsafe-math-optimizations. Allow unsafe floating-point optimizations.; ``-funsafe-math-optimizations`` also implies:. * ``-fapprox-func``; * ``-fassociative-math``; * ``-freciprocal-math``; * ``-fno-signed-zeros``; * ``-fno-trapping-math``; * ``-ffp-contract=fast``. ``-fno-unsafe-math-optimizations`` implies:. * ``-fno-approx-func``; * ``-fno-associative-math``; * ``-fno-reciprocal-math``; * ``-fsigned-zeros``; * ``-ftrapping-math``; * ``-ffp-contract=on``; * ``-fdenormal-fp-math=ieee``. There is ambiguity about how ``-ffp-contract``,; ``-funsafe-math-optimizations``, and ``-fno-unsafe-math-optimizations``; behave when combined. Explanation in :option:`-fno-fast-math` also applies; to these options. Defaults to ``-fno-unsafe-math-optimizations``. .. option:: -f[no-]finite-math-only. Allow floating-point optimizations that assume arguments and results are; not NaNs or +-Inf. ``-ffinite-math-only`` defines the; ``__FINITE_MATH_ONLY__`` preprocessor macro.; ``-ffinite-math-only`` implies:. * ``-fno-honor-infinities``; * ``-fno-honor-nans``. ``-ffno-inite-math-only`` implies:. * ``-fhonor-infinities``; * ``-fhonor-nans``. Defaults to ``-fno-finite-math-only``. .. option:: -f[no-]rounding-math. Force floating-point operations to honor the dynamically-set rounding mode by default. The result of a floating-point operation often cannot be exactly represented in the result type and therefore must be rounded. IEEE 754 describes different rounding modes that control how to perform this rounding, not all of which are supported by all implementations. C provides interfaces (``fesetround`` and ``fesetenv``) for dynamically controlling the rounding mode, and while it also recommends certain conventions for changing th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:59957,optimiz,optimizations,59957,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,"o-called ""module"". A ""module"" is a single linked; binary, such as a loaded ELF file. Usually each module occupies a contiguous; range of memory. Here ``%i`` is the module ID which is used by other contextual elements to; refer to this module. The first ``%s`` is a human-readable identifier for the; module, such as an ELF ``DT_SONAME`` string or a file name; but it might be; empty. It's only for casual information. Only the module ID is used to refer; to this module in other contextual elements, never the ``%s`` string. The; ``module`` element defining a module ID must always be emitted before any; other elements that refer to that module ID, so that a filter never needs to; keep track of dangling references. The second ``%s`` is the module type and it; determines what the remaining fields are. The following module types are; supported:. * ``elf:%x``. Here ``%x`` encodes an ELF Build ID. The Build ID should refer to a single; linked binary. The Build ID string is the sole way to identify the binary from; which this module was loaded. Example::. {{{module:1:libc.so:elf:83238ab56ba10497}}}. ``{{{mmap:%p:%i:...}}}``. This contextual element is used to give information about a particular region; in memory. ``%p`` is the starting address and ``%i`` gives the size in hex of the; region of memory. The ``...`` part can take different forms to give different; information about the specified region of memory. The allowed forms are the; following:. * ``load:%i:%s:%p``. This subelement informs the filter that a segment was loaded from a module.; The module is identified by its module ID ``%i``. The ``%s`` is one or more of; the letters 'r', 'w', and 'x' (in that order and in either upper or lower; case) to indicate this segment of memory is readable, writable, and/or; executable. The symbolizing filter can use this information to guess whether; an address is a likely code address or a likely data address in the given; module. The remaining ``%p`` gives the module relative address",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:20028,load,loaded,20028,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,1,['load'],['loaded']
Performance,"o/cache``; - ld64 (supported since clang 3.9 and Xcode 8) and Mach-O ld64.lld (as of LLVM; 15.0):; ``-Wl,-cache_path_lto,/path/to/cache``; - ELF ld.lld (as of LLVM 5.0):; ``-Wl,--thinlto-cache-dir=/path/to/cache``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocache:/path/to/cache``. Cache Pruning; -------------. To help keep the size of the cache under control, ThinLTO supports cache; pruning. Cache pruning is supported with gold, ld64, and lld, but currently only; gold and lld allow you to control the policy with a policy string. The cache; policy must be specified with a linker option. - gold (as of LLVM 6.0):; ``-Wl,-plugin-opt,cache-policy=POLICY``; - ELF ld.lld (as of LLVM 5.0), Mach-O ld64.lld (as of LLVM 15.0):; ``-Wl,--thinlto-cache-policy=POLICY``; - COFF lld-link (as of LLVM 6.0):; ``/lldltocachepolicy:POLICY``. A policy string is a series of key-value pairs separated by ``:`` characters.; Possible key-value pairs are:. - ``cache_size=X%``: The maximum size for the cache directory is ``X`` percent; of the available space on the disk. Set to 100 to indicate no limit,; 50 to indicate that the cache size will not be left over half the available; disk space. A value over 100 is invalid. A value of 0 disables the percentage; size-based pruning. The default is 75%. - ``cache_size_bytes=X``, ``cache_size_bytes=Xk``, ``cache_size_bytes=Xm``,; ``cache_size_bytes=Xg``:; Sets the maximum size for the cache directory to ``X`` bytes (or KB, MB,; GB respectively). A value over the amount of available space on the disk; will be reduced to the amount of available space. A value of 0 disables; the byte size-based pruning. The default is no byte size-based pruning. Note that ThinLTO will apply both size-based pruning policies simultaneously,; and changing one does not affect the other. For example, a policy of; ``cache_size_bytes=1g`` on its own will cause both the 1GB and default 75%; policies to be applied unless the default ``cache_size`` is overridden. - ``cache_size_fil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst:5749,cache,cache,5749,interpreter/llvm-project/clang/docs/ThinLTO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThinLTO.rst,1,['cache'],['cache']
Performance,"o; come up with a precise partitioning in all cases without variables to; represent every pair of possible aliases. Thus, partitioning; precisely may require introducing at least N^2 new virtual variables,; phi nodes, etc. Each of these variables may be clobbered at multiple def sites. To give an example, if you were to split up struct fields into; individual variables, all aliasing operations that may-def multiple struct; fields, will may-def more than one of them. This is pretty common (calls,; copies, field stores, etc). Experience with SSA forms for memory in other compilers has shown that; it is simply not possible to do this precisely, and in fact, doing it; precisely is not worth it, because now all the optimizations have to; walk tons and tons of virtual variables and phi nodes. So we partition. At the point at which you partition, again,; experience has shown us there is no point in partitioning to more than; one variable. It simply generates more IR, and optimizations still; have to query something to disambiguate further anyway. As a result, LLVM partitions to one variable. Precision in practice; ^^^^^^^^^^^^^^^^^^^^^. In practice, there are implementation details in LLVM that also affect the; results' precision provided by ``MemorySSA``. For example, AliasAnalysis has various; caps, or restrictions on looking through phis which can affect what ``MemorySSA``; can infer. Changes made by different passes may make MemorySSA either ""overly; optimized"" (it can provide a more accurate result than if it were recomputed; from scratch), or ""under optimized"" (it could infer more if it were recomputed).; This can lead to challenges to reproduced results in isolation with a single pass; when the result relies on the state acquired by ``MemorySSA`` due to being updated by; multiple subsequent passes.; Passes that use and update ``MemorySSA`` should do so through the APIs provided by the; ``MemorySSAUpdater``, or through calls on the Walker.; Direct optimizations to ``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:18332,optimiz,optimizations,18332,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimizations']
Performance,"o; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_inv sc0=1 sc1=1. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. GFX940, GFX941; - wavefront - generic buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the follo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:306385,load,load,306385,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"o; impact on coverage report quality. This is due to the fact that the mapping; from source regions to profile counters is immutable, and is generated before; the llvm optimizer kicks in. The optimizer can't prove that profile counter; instrumentation is safe to delete (because it's not: it affects the profile the; program emits), and so leaves it alone. Note that this coverage feature does not rely on information that can degrade; during the course of optimization, such as debug info line tables. Using the profiling runtime without static initializers; =======================================================. By default the compiler runtime uses a static initializer to determine the; profile output path and to register a writer function. To collect profiles; without using static initializers, do this manually:. * Export a ``int __llvm_profile_runtime`` symbol from each instrumented shared; library and executable. When the linker finds a definition of this symbol, it; knows to skip loading the object which contains the profiling runtime's; static initializer. * Forward-declare ``void __llvm_profile_initialize_file(void)`` and call it; once from each instrumented executable. This function parses; ``LLVM_PROFILE_FILE``, sets the output path, and truncates any existing files; at that path. To get the same behavior without truncating existing files,; pass a filename pattern string to ``void __llvm_profile_set_filename(char; *)``. These calls can be placed anywhere so long as they precede all calls; to ``__llvm_profile_write_file``. * Forward-declare ``int __llvm_profile_write_file(void)`` and call it to write; out a profile. This function returns 0 when it succeeds, and a non-zero value; otherwise. Calling this function multiple times appends profile data to an; existing on-disk raw profile. In C++ files, declare these as ``extern ""C""``. Using the profiling runtime without a filesystem; ------------------------------------------------. The profiling runtime also supports",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:15781,load,loading,15781,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['load'],['loading']
Performance,"o=thin``; enabled and be statically linked into the program. This scheme is currently not compatible with cross-DSO CFI or the; Microsoft ABI. .. _cfi-ignorelist:. Ignorelist; ==========. A :doc:`SanitizerSpecialCaseList` can be used to relax CFI checks for certain; source files, functions and types using the ``src``, ``fun`` and ``type``; entity types. Specific CFI modes can be be specified using ``[section]``; headers. .. code-block:: bash. # Suppress all CFI checking for code in a file.; src:bad_file.cpp; src:bad_header.h; # Ignore all functions with names containing MyFooBar.; fun:*MyFooBar*; # Ignore all types in the standard library.; type:std::*; # Disable only unrelated cast checks for this function; [cfi-unrelated-cast]; fun:*UnrelatedCast*; # Disable CFI call checks for this function without affecting cast checks; [cfi-vcall|cfi-nvcall|cfi-icall]; fun:*BadCall*. .. _cfi-cross-dso:. Shared library support; ======================. Use **-f[no-]sanitize-cfi-cross-dso** to enable the cross-DSO control; flow integrity mode, which allows all CFI schemes listed above to; apply across DSO boundaries. As in the regular CFI, each DSO must be; built with ``-flto`` or ``-flto=thin``. Normally, CFI checks will only be performed for classes that have hidden LTO; visibility. With this flag enabled, the compiler will emit cross-DSO CFI; checks for all classes, except for those which appear in the CFI ignorelist; or which use a ``no_sanitize`` attribute. Design; ======. Please refer to the :doc:`design document<ControlFlowIntegrityDesign>`. Publications; ============. `Control-Flow Integrity: Principles, Implementations, and Applications <https://research.microsoft.com/pubs/64250/ccs05.pdf>`_.; Martin Abadi, Mihai Budiu, lfar Erlingsson, Jay Ligatti. `Enforcing Forward-Edge Control-Flow Integrity in GCC & LLVM <http://www.pcc.me.uk/~peter/acad/usenix14.pdf>`_.; Caroline Tice, Tom Roeder, Peter Collingbourne, Stephen Checkoway,; lfar Erlingsson, Luis Lozano, Geoff Pike.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst:18463,perform,performed,18463,interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,1,['perform'],['performed']
Performance,"oStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit objects has been reworked to present a more uniform look and feel.; The standard one-line result of the high-level Print() method without option now looks like. // Variable; x.Print() ;; RooRealVar::x = 0 L(-10 - 10) . // Function or p.d.f; gx.Print() ;; RooGaussian::gx[ x=x mean=m sigma=sx ] = 1. // Dataset; d.Print() ;; RooDataSet::gData[x,y] = 1000 entries. // RooPlot; frame.Print() ;; framex[x] = (RooHist::h_gData,RooCurve::g_Int[y]_Norm[x,y]_Comp[g]). Inside class RooPlot the default name of contained curves and histograms has been ; reworked in something more self descriptive as is shown in the above example. A usual,; a user supplied name can always be set by supplying the Name(const char*) argument; to plotOn(). Verbose printing with ""v"" options is mostly unchanged except for RooPlot. In addition; printing with the ""s"" option will show the 'old' standard printing mode, option ""t"" will show; tree structure printing (only for RooAbsArg), and option ""1"" will invoke inline printing, i.e; a one-line description without a trailing endl.; Data weighted projections of p.d.fs using the ProjWData() argument in RooAbsPdf::plotOn() are now calculated; with a new classes that derives from RooAbsOptTestStatistic and can thus implement the same evaluation; optimizations as are done for RooNLLVar and RooChi2Var. Specifically it is now possible to calculate projections; involving ProjWData() in parallel on multi-core hosts by adding the NumCPU(Int_t) argument to plotOn().; ; A new utility function has been added to allow cloning of entire tree expressions of; RooAbsArg objects, such as a composite p.d.f including component p.d.fs and; all its variables:. RooAbsArg* clonedTree = pdf.cloneTree() ;. All cloned leaf and branch nodes are owned by the returned head node of the expression.; Assorted minor fixes; ; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:19661,optimiz,optimizations,19661,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,2,['optimiz'],['optimizations']
Performance,"oad i32, i32* %X ; load the stack value %X from the stack.; %tmp2 = add i32 %tmp, 1 ; increment it; store i32 %tmp2, i32* %X ; store it back; ... This code shows an example of how you can declare and manipulate a stack; variable in the LLVM IR. Stack memory allocated with the alloca; instruction is fully general: you can pass the address of the stack slot; to functions, you can store it in other variables, etc. In our example; above, we could rewrite the example to use the alloca technique to avoid; using a PHI node:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; %X = alloca i32 ; type of %X is i32*.; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; store i32 %X.0, i32* %X ; Update X; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; store i32 %X.1, i32* %X ; Update X; br label %cond_next. cond_next:; %X.2 = load i32, i32* %X ; Read X; ret i32 %X.2; }. With this, we have discovered a way to handle arbitrary mutable; variables without the need to create Phi nodes at all:. #. Each mutable variable becomes a stack allocation.; #. Each read of the variable becomes a load from the stack.; #. Each update of the variable becomes a store to the stack.; #. Taking the address of a variable just uses the stack address; directly. While this solution has solved our immediate problem, it introduced; another one: we have now apparently introduced a lot of stack traffic; for very simple and common operations, a major performance problem.; Fortunately for us, the LLVM optimizer has a highly-tuned optimization; pass named ""mem2reg"" that handles this case, promoting allocas like this; into SSA registers, inserting Phi nodes as appropriate. If you run this; example through the pass, for example, you'll get:. .. code-block:: bash. $ llvm-as < example.ll | opt -passes=mem2reg | llvm-dis; @G = weak global i32 0; @H = weak global ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:6034,load,load,6034,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance,"oad-arch=<target-id>``; Clang compilation options to specify the kind of code to generate. It is also used as part of the bundle entry ID to identify the code object. See; :ref:`clang-bundle-entry-id`. Target ID syntax is defined by the following BNF syntax:. .. code::. <target-id> ::== <processor> ( "":"" <target-feature> ( ""+"" | ""-"" ) )*. Where:. **processor**; Is a the target specific processor or any alternative processor name. **target-feature**; Is a target feature name that is supported by the processor. Each target; feature must appear at most once in a target ID and can have one of three; values:. *Any*; Specified by omitting the target feature from the target ID.; A code object compiled with a target ID specifying the default; value of a target feature can be loaded and executed on a processor; configured with the target feature on or off. *On*; Specified by ``+``, indicating the target feature is enabled. A code; object compiled with a target ID specifying a target feature on; can only be loaded on a processor configured with the target feature on. *Off*; specified by ``-``, indicating the target feature is disabled. A code; object compiled with a target ID specifying a target feature off; can only be loaded on a processor configured with the target feature off. .. _compatibility-target-id:. Compatibility Rules for Target ID; ---------------------------------. A code object compiled for a Target ID is considered compatible for a; target, if:. * Their processor is same.; * Their feature set is compatible as defined above. There are two forms of target ID:. *Non-Canonical Form*; The non-canonical form is used as the input to user commands to allow the user; greater convenience. It allows both the primary and alternative processor name; to be used and the target features may be specified in any order. *Canonical Form*; The canonical form is used for all generated output to allow greater; convenience for tools that consume the information. It is also used for; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst:12302,load,loaded,12302,interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,1,['load'],['loaded']
Performance,"oad; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If CU wavefront execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1 dlc=1. - If GFX11, omit dlc=1. 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_gl*_inv.; - Ensures the load; has completed; before invalidating; the caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1 dlc=1; - system; - If GFX11, omit dlc=1. 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_gl*_invl.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:347702,load,loads,347702,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"oading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final library name explicitly, since it is; only in the separate linking step where these names are fixed and those names; may not match the default choice. With the mapping file in place, the above example can be rerun without; explicit loading of the dictionary:. .. code-block:: python. >>> import cppyy; >>> from cppyy.gbl import MyClass; >>> MyClass(42).get_int(); 42; >>>. .. _cppyy-generator:. Bindings collection; -------------------. ``cppyy-generator`` is a clang-based utility program which takes a set of C++; header files and generates a JSON output file describing the objects found in; them.; This output is intended to support more convenient access to a set of; cppyy-supported bindings::. $ cppyy-generator --help; usage: cppyy-generator [-h] [-v] [--flags FLAGS] [--libclang LIBCLANG]; output sources [sources ...]; ... This utility is mainly used as part of the; :doc:`CMake interface <cmake_interface>`. .. _`support for exporting all`: https://cmake.org/cmake/help/latest/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:9395,load,loading,9395,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,1,['load'],['loading']
Performance,"oads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41199,load,load,41199,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['cache', 'load']","['cache', 'load']"
Performance,"oads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:280581,load,load,280581,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"oads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vm/vscnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw-with-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:351076,load,loads,351076,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"obal data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; lo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248568,load,load,248568,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"obal; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:319373,load,load,319373,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"objc.destroyWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.destroyWeak(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_destroyWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-destroyweak-id-object>`_. '``llvm.objc.initWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.initWeak(ptr, ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_initWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-initweak>`_. '``llvm.objc.loadWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.loadWeak(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_loadWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-loadweak>`_. '``llvm.objc.loadWeakRetained``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.loadWeakRetained(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_loadWeakRetained <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-loadweakretained>`_. '``llvm.objc.moveWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.moveWeak(ptr, ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_moveWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-moveweak-id-dest-id-src>`_. '``llvm.objc.release``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.release(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_release <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-release-id-value>`_. '``llvm.objc.retain``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.retain(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_retain <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtim",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:969015,load,loadWeakRetained,969015,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loadWeakRetained']
Performance,"object and returns its address as; an integer value.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_capsule**: Takes a cppyy bound C++ object and returns its address as; a PyCapsule object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_cobject**: Takes a cppyy bound C++ object and returns its address as; a PyCObject object for Python2 and a PyCapsule object for Python3.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_ctypes**: Takes a cppyy bound C++ object and returns its address as; a ``ctypes.c_void_p`` object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. `ctypes`; --------. The `ctypes module`_ has been part of Python since version 2.5 and provides a; Python-side foreign function interface.; It is clunky to use and has very bad performance, but it is guaranteed to be; available.; It does not have a public C interface, only the Python one, but its internals; have been stable since its introduction, making it safe to use for tight and; efficient integration at the C level (with a few Python helpers to assure; lazy lookup). Objects from ``ctypes`` can be passed through arguments of functions that; take a pointer to a single C++ builtin, and ``ctypes`` pointers can be passed ; when a pointer-to-pointer is expected, e.g. for array out-parameters.; This leads to the following set of possible mappings:. ======================================== ========================================; C++ ctypes; ======================================== ========================================; by value (ex.: ``int``) ``.value`` (ex.: ``c_int(0).value``); by const reference (ex.: ``const int&``) ``.value`` (ex.: ``c_int(0).value``); by reference (ex.: ``int&``) direct (ex.: ``c_int(0)``); by pointer (ex.: ``int*``) direct (ex.: ``c_int(0)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:7355,perform,performance,7355,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,1,['perform'],['performance']
Performance,"object can be registered directly to the server with a [THttpServer::Register()](https://root.cern/doc/master/classTHttpServer.html#a73658daf379e87a4832fe9dc5c1483ed) call. Central point of integration - when and how THttpServer get access to data from a running application. By default it is done during the `gSystem->ProcessEvents()` call - THttpServer uses a synchronous timer which is activated every 100 ms. Such approach works perfectly when running macros in an interactive ROOT session. If an application runs in compiled code and does not contain `gSystem->ProcessEvents()` calls, two method are available. ### Asynchronous timer. The first method is to configure an asynchronous timer for the server, like for example:. ```cpp; serv->SetTimer(100, kFALSE);; ```. Then, the timer will be activated even without any gSystem->ProcessEvents() method call. The main advantage of such method is that the application code can be used without any modifications. But there is no control when access to the application data is performed. It could happen just in-between of **`TH1::Fill()`** calls and an histogram object may be incomplete. Therefore such method is not recommended. ### Regular calls of THttpServer::ProcessRequests() method. The second method is preferable - one just inserts in the application regular calls of the THttpServer::ProcessRequests() method, like:. ```cpp; serv->ProcessRequests();; ```. In such case, one can fully disable the timer of the server:. ```cpp; serv->SetTimer(0, kTRUE);; ```. ## Data access from command shell. The big advantage of the http protocol is that it is not only supported in web browsers, but also in many other applications. One could use http requests to directly access ROOT objects and data members from any kind of scripts. If one starts a server and register an object like for example:. ```cpp; auto serv = new THttpServer(""http:8080"");; TNamed* n1 = new TNamed(""obj"", ""title"");; serv->Register(""subfolder"", n1);; ```. One could request a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:13870,perform,performed,13870,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['perform'],['performed']
Performance,"object pointer type. Each qualifier specifies different; semantics for each of these operations. It is still undefined behavior to; access an object outside of its lifetime. A load or store with ""primitive semantics"" has the same semantics as the; respective operation would have on an ``void*`` lvalue with the same alignment; and non-ownership qualification. :arc-term:`Reading` occurs when performing a lvalue-to-rvalue conversion on an; object lvalue. * For ``__weak`` objects, the current pointee is retained and then released at; the end of the current full-expression. In particular, messaging a ``__weak``; object keeps the object retained until the end of the full expression. .. code-block:: objc. __weak MyObject *weakObj;. void foo() {; // weakObj is retained before the message send and released at the end of; // the full expression.; [weakObj m];; }. This must execute atomically with respect to assignments and to the final; release of the pointee.; * For all other objects, the lvalue is loaded with primitive semantics. :arc-term:`Assignment` occurs when evaluating an assignment operator. The; semantics vary based on the qualification:. * For ``__strong`` objects, the new pointee is first retained; second, the; lvalue is loaded with primitive semantics; third, the new pointee is stored; into the lvalue with primitive semantics; and finally, the old pointee is; released. This is not performed atomically; external synchronization must be; used to make this safe in the face of concurrent loads and stores.; * For ``__weak`` objects, the lvalue is updated to point to the new pointee,; unless the new pointee is an object currently undergoing deallocation, in; which case the lvalue is updated to a null pointer. This must execute; atomically with respect to other assignments to the object, to reads from the; object, and to the final release of the new pointee.; * For ``__unsafe_unretained`` objects, the new pointee is stored into the; lvalue using primitive semantics.; * F",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:38499,load,loaded,38499,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['load'],['loaded']
Performance,"object, which; is flushed to complete the process. If an ObjectCache is being used, the; image will be passed to the ObjectCache here. At this point, the ObjectBufferStream contains the raw object image.; Before the code can be executed, the code and data sections from this; image must be loaded into suitable memory, relocations must be applied and; memory permission and code cache invalidation (if required) must be completed. Object Loading; ==============. Once an object image has been obtained, either through code generation or; having been retrieved from an ObjectCache, it is passed to RuntimeDyld to; be loaded. The RuntimeDyld wrapper class examines the object to determine; its file format and creates an instance of either RuntimeDyldELF or; RuntimeDyldMachO (both of which derive from the RuntimeDyldImpl base; class) and calls the RuntimeDyldImpl::loadObject method to perform that; actual loading. .. image:: MCJIT-dyld-load.png. RuntimeDyldImpl::loadObject begins by creating an ObjectImage instance; from the ObjectBuffer it received. ObjectImage, which wraps the; ObjectFile class, is a helper class which parses the binary object image; and provides access to the information contained in the format-specific; headers, including section, symbol and relocation information. RuntimeDyldImpl::loadObject then iterates through the symbols in the; image. Information about common symbols is collected for later use. For; each function or data symbol, the associated section is loaded into memory; and the symbol is stored in a symbol table map data structure. When the; iteration is complete, a section is emitted for the common symbols. Next, RuntimeDyldImpl::loadObject iterates through the sections in the; object image and for each section iterates through the relocations for; that sections. For each relocation, it calls the format-specific; processRelocationRef method, which will examine the relocation and store; it in one of two data structures, a section-based relocation l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:4021,load,loadObject,4021,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,1,['load'],['loadObject']
Performance,"object. Multivariate Gaussian modeling of parameters estimates from a fit; You can now construct a multivariate Gaussian p.d.f on the parameters of a model that; represents the result of a fit, from any RooFitResult object. RooAbsPdf* paramPdf = fitresult->createHessePdf(RooArgSet(a,b)) ;. The returned object is an instance of the newly added class RooMultiVarGaussian, that can; model correlated Gaussian distributions in an arbitrary number of dimensions, given a; vector of mean values and a covariance matrix. Class RooMultivarGaussian implements analytical; integration as well as analytical partial integrals over the first 31 dimensions (if you have; that many) and implements in effect internal generation strategy for its observables. A new tutorial macro rf608_fitresultaspdf.C has been added to illustrate the use MV Gaussians constructed from a RooFitResult; Improved functionality of RooFFTConvPdf; The FFT convolution operator p.d.f. class RooFFTConvPdf has been substantially upgraded; for improved performance has several new options. For the overflow buffering, which aims to reduce cylical spillover from the FFT convolution,; a choice of three algorithms is now provided:. Extend the p.d.f. somewhat beyond its original domain (the new default); Fill the buffer 50/50 with the value of the p.d.f at the upper/lower bound of the convolution observable (the previous default); Mirror the p.d.f. over the boundary. The new default algorithm provides a more sensible result for p.d.f.s with significant; spillover issues, provided that the p.d.f. can be continuated beyond its original domain.; Convolution in non-observables is also explicitly supported now. One can e.g. construct a p.d.f; of the form G(x) = Int[dy] ( F(x,y) (*) H(y) ). A new tutorial macro rf211_paramconv illustrates; how such convolutions can be constructed; It is now also possible to express FFT convolutions in terms of other observables than the; convolution observable itself. A common occurrence of that s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:11080,perform,performance,11080,roofit/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html,2,['perform'],['performance']
Performance,"oc:`CMake` or :doc:`CMakePrimer`; documentation useful. Some of the things covered in this document are the inner; workings of the builds described in the :doc:`AdvancedBuilds` document. General Distribution Guidance; =============================. When building a distribution of a compiler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1438,perform,performance,1438,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['perform'],['performance']
Performance,"oca %Object*. ;; Tell LLVM that the stack space is a stack root.; ;; Java has type-tags on objects, so we pass null as metadata.; %tmp = bitcast %Object** %X to i8**; call void @llvm.gcroot(i8** %tmp, i8* null); ... ;; ""CodeBlock"" is the block corresponding to the start; ;; of the scope above.; CodeBlock:; ;; Java null-initializes pointers.; store %Object* null, %Object** %X. ... ;; As the pointer goes out of scope, store a null value into; ;; it, to indicate that the value is no longer live.; store %Object* null, %Object** %X; ... Reading and writing references in the heap; ------------------------------------------. Some collectors need to be informed when the mutator (the program that needs; garbage collection) either reads a pointer from or writes a pointer to a field; of a heap object. The code fragments inserted at these points are called *read; barriers* and *write barriers*, respectively. The amount of code that needs to; be executed is usually quite small and not on the critical path of any; computation, so the overall performance impact of the barrier is tolerable. Barriers often require access to the *object pointer* rather than the *derived; pointer* (which is a pointer to the field within the object). Accordingly,; these intrinsics take both pointers as separate arguments for completeness. In; this snippet, ``%object`` is the object pointer, and ``%derived`` is the derived; pointer:. .. code-block:: llvm. ;; An array type.; %class.Array = type { %class.Object, i32, [0 x %class.Object*] }; ... ;; Load the object pointer from a gcroot.; %object = load %class.Array** %object_addr. ;; Compute the derived pointer.; %derived = getelementptr %object, i32 0, i32 2, i32 %n. LLVM does not enforce this relationship between the object and derived pointer; (although a particular :ref:`collector strategy <plugin>` might). However, it; would be an unusual collector that violated it. The use of these intrinsics is naturally optional if the target GC does not; require t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:13204,perform,performance,13204,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['perform'],['performance']
Performance,"ocal *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:245975,load,load,245975,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"ocal storage. ; * If no '--threads' argument was provided this is 1, otherwise it is the minimum of the value; provided and the number of threads your CPU can run in parallel. It is worth noting that -; on shared systems or if running other heavy applications - the number of your own threads; running at any time may be lower than the limit due to demand on the CPU.; - The 'Real Time' is similar to 'CPU Time / number of threads' AND 'Compressed Throughput' is lower than expected; for your storage medium: this would imply that your CPU threads aren't decompressing data as fast as your storage; medium can provide it, and so decompression is the bottleneck.; The best way to decrease your runtime would be to utilise a system with a faster CPU, or make use; use of more threads when running, or use a compression algorithm with a higher decompression rate such as LZ4,; possibly at the cost of some extra file size. ### A note on caching. If your data is stored on a local disk, the system may cache some/all of the file in memory after it is; first read. If this is realistic of how your analysis will run - then there is no concern. However, if; you expect to only read files once in a while - and as such the files are unlikely to be in the cache -; consider clearing the cache before running rootreadspeed.; On Linux this can be done by running 'echo 3 > /proc/sys/vm/drop_caches' as a superuser,; or a specific file can be dropped from the cache with; `dd of=<FILENAME> oflag=nocache conv=notrunc,fdatasync count=0 > /dev/null 2>&1`. ### Known overhead of TTreeReader, RDataFrame. `rootreadspeed` is designed to read all data present in the specified branches, trees and files at the highest; possible speed. When the application bottleneck is not in the computations performed by analysis logic,; higher-level interfaces built on top of TTree such as TTreeReader and RDataFrame are known to add a significant; runtime overhead with respect to the runtimes reported by `rootreadspeed` (up to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md:3470,cache,cache,3470,tree/readspeed/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md,1,['cache'],['cache']
Performance,"ocalException is a function; implemented by the C++ support library. It returns the current exception ; object for the current thread. Note that we do not attempt to recycle the ; shutdown code from before, because performance of the mainline code is ; critically important. Also, obviously fooCleanup and barCleanup may be ; merged and one of them eliminated. This just shows how the code generator ; would most likely emit code. The bazCleanup label is more interesting. Because the exception may be caught; by the try block, we must dispatch to its handler... but it does not exist; on the call stack (it does not have a VM Call->Label mapping installed), so ; we must dispatch statically with a goto. The bazHandler thus appears as:. bazHandler:; d->~D(); // destruct D as it goes out of scope when entering catch clauses; goto TryHandler. In general, TryHandler is not the same as bazHandler, because multiple ; function calls could be made from the try block. In this case, trivial ; optimization could merge the two basic blocks. TryHandler is the code ; that actually determines the type of exception, based on the Exception object; itself. For this discussion, assume that the exception object contains *at; least*:. 1. A pointer to the RTTI info for the contained object; 2. A pointer to the dtor for the contained object; 3. The contained object itself. Note that it is necessary to maintain #1 & #2 in the exception object itself; because objects without virtual function tables may be thrown (as in this ; example). Assuming this, TryHandler would look something like this:. TryHandler: ; Exception *E = getThreadLocalException();; switch (E->RTTIType) {; case IntRTTIInfo:; ...int Stuff... // The action to perform from the catch block; break;; case DoubleRTTIInfo:; ...double Stuff... // The action to perform from the catch block; goto TryCleanup // This catch block rethrows the exception; break; // Redundant, eliminated by the optimizer; default:; goto TryCleanup // Exception not c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-05-18-ExceptionHandling.txt:5182,optimiz,optimization,5182,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-05-18-ExceptionHandling.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-05-18-ExceptionHandling.txt,1,['optimiz'],['optimization']
Performance,"ocate memory on the; stack while controlling its alignment. Memory is automatically freed upon; function termination. **Syntax**:. .. code-block:: c++. __builtin_alloca_with_align(size_t n, size_t align). **Example of Use**:. .. code-block:: c++. void init(float* data, size_t nbelems);; void process(float* data, size_t nbelems);; int foo(size_t n) {; auto mem = (float*)__builtin_alloca_with_align(; n * sizeof(float),; CHAR_BIT * alignof(float));; init(mem, n);; process(mem, n);; /* mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca_with_align`` is meant to be used to allocate a dynamic amount of memory; on the stack. It is similar to ``__builtin_alloca`` but accepts a second; argument whose value is the alignment constraint, as a power of 2 in *bits*. Query for this feature with ``__has_builtin(__builtin_alloca_with_align)``. .. _langext-__builtin_assume:. ``__builtin_assume``; --------------------. ``__builtin_assume`` is used to provide the optimizer with a boolean; invariant that is defined to be true. **Syntax**:. .. code-block:: c++. __builtin_assume(bool). **Example of Use**:. .. code-block:: c++. int foo(int x) {; __builtin_assume(x != 0);; // The optimizer may short-circuit this check using the invariant.; if (x == 0); return do_something();; return do_something_else();; }. **Description**:. The boolean argument to this function is defined to be true. The optimizer may; analyze the form of the expression provided as the argument and deduce from; that information used to optimize the program. If the condition is violated; during execution, the behavior is undefined. The argument itself is never; evaluated, so any side effects of the expression will be discarded. Query for this feature with ``__has_builtin(__builtin_assume)``. .. _langext-__builtin_assume_separate_storage:. ``__builtin_assume_separate_storage``; -------------------------------------. ``__builtin_assume_separate_storage`` is used to provide the optimizer with t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:98713,optimiz,optimizer,98713,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizer']
Performance,"ocates all paths starting with 'oldroot' to 'newroot' for the; entry-list 'enlnm' in file 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the TFileMerger needs to handle the input files in more than one pass for ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3334,cache,cache,3334,tree/doc/v534/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html,2,['cache'],['cache']
Performance,"ocess. The value name refers to a previously defined memory definition and; the address is a decimal number that specifies the address the memory; definition should start at. Note that a single memory definition can be; mapped multiple times. Using this annotation requires the subprocess; execution mode.; * `LLVM-EXEGESIS-SNIPPET-ADDRESS <address>` - This annotation allows for; setting the address where the beginning of the snippet to be executed will; be mapped in at. The address is given in hexadecimal. Note that the snippet; also includes setup code, so the instruction exactly at the specified; address will not be the first instruction in the snippet. Using this; annotation requires the subprocess execution mode. This is useful in; cases where the memory accessed by the snippet depends on the location; of the snippet, like RIP-relative addressing. EXAMPLE 1: benchmarking instructions; ------------------------------------. Assume you have an X86-64 machine. To measure the latency of a single; instruction, run:. .. code-block:: bash. $ llvm-exegesis --mode=latency --opcode-name=ADD64rr. Measuring the uop decomposition or inverse throughput of an instruction works similarly:. .. code-block:: bash. $ llvm-exegesis --mode=uops --opcode-name=ADD64rr; $ llvm-exegesis --mode=inverse_throughput --opcode-name=ADD64rr. The output is a YAML document (the default is to write to stdout, but you can; redirect the output to a file using `--benchmarks-file`):. .. code-block:: none. ---; key:; opcode_name: ADD64rr; mode: latency; config: ''; cpu_name: haswell; llvm_triple: x86_64-unknown-linux-gnu; num_repetitions: 10000; measurements:; - { key: latency, value: 1.0058, debug_string: '' }; error: ''; info: 'explicit self cycles, selecting one aliasing configuration.; Snippet:; ADD64rr R8, R8, R10; '; ... To measure the latency of all instructions for the host architecture, run:. .. code-block:: bash. $ llvm-exegesis --mode=latency --opcode-index=-1. EXAMPLE 2: benchmarking a custom ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:4841,latency,latency,4841,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['latency'],['latency']
Performance,"ocks. The copy operation ``Block_copy()`` is styled as a function that takes; an arbitrary Block reference and returns a Block reference of the same; type. The release operation, ``Block_release()``, is styled as a; function that takes an arbitrary Block reference and, if dynamically; matched to a Block copy operation, allows recovery of the referenced; allocated memory. The ``__block`` Storage Qualifier; =================================. In addition to the new Block type we also introduce a new storage; qualifier, :block-term:`__block`, for local variables. [testme: a; __block declaration within a block literal] The ``__block`` storage; qualifier is mutually exclusive to the existing local storage; qualifiers auto, register, and static. [testme] Variables qualified by; ``__block`` act as if they were in allocated storage and this storage; is automatically recovered after last use of said variable. An; implementation may choose an optimization where the storage is; initially automatic and only ""moved"" to allocated (heap) storage upon; a Block_copy of a referencing Block. Such variables may be mutated as; normal variables are. In the case where a ``__block`` variable is a Block one must assume; that the ``__block`` variable resides in allocated storage and as such; is assumed to reference a Block that is also in allocated storage; (that it is the result of a ``Block_copy`` operation). Despite this; there is no provision to do a ``Block_copy`` or a ``Block_release`` if; an implementation provides initial automatic storage for Blocks. This; is due to the inherent race condition of potentially several threads; trying to update the shared variable and the need for synchronization; around disposing of older values and copying new ones. Such; synchronization is beyond the scope of this language specification. Control Flow; ============. The compound statement of a Block is treated much like a function body; with respect to control flow in that goto, break, and continue do",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:7424,optimiz,optimization,7424,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['optimiz'],['optimization']
Performance,"ocs/AutomaticReferenceCounting.html#arc-runtime-objc-autoreleasereturnvalue>`_. '``llvm.objc.copyWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.copyWeak(ptr, ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_copyWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-copyweak-id-dest-id-src>`_. '``llvm.objc.destroyWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.destroyWeak(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_destroyWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-destroyweak-id-object>`_. '``llvm.objc.initWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.initWeak(ptr, ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_initWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-initweak>`_. '``llvm.objc.loadWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.loadWeak(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_loadWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-loadweak>`_. '``llvm.objc.loadWeakRetained``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.loadWeakRetained(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_loadWeakRetained <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-loadweakretained>`_. '``llvm.objc.moveWeak``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.moveWeak(ptr, ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_moveWeak <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-moveweak-id-dest-id-src>`_. '``llvm.objc.release``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.release(ptr). Lowering:; """"""""""""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:968615,load,loadWeak,968615,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loadWeak']
Performance,"ocs/lnt/tests.html#cross-compiling](https://llvm.org/docs/lnt/tests.html#cross-compiling). - [https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html](https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html). Cross compilation from macOS to iOS is possible with the; `test-suite/cmake/caches/target-target-*-iphoneos-internal.cmake` CMake cache; files; this requires an internal iOS SDK. ### Running. There are two ways to run the tests in a cross compilation setting:. - Via SSH connection to an external device: The `TEST_SUITE_REMOTE_HOST` option; should be set to the SSH hostname. The executables and data files need to be; transferred to the device after compilation. This is typically done via the; `rsync` make target. After this, the lit runner can be used on the host; machine. It will prefix the benchmark and verification command lines with an; `ssh` command. Example:. ```bash; % cmake -G Ninja -D CMAKE_C_COMPILER=path/to/clang \; -C ../test-suite/cmake/caches/target-arm64-iphoneos-internal.cmake \; -D CMAKE_BUILD_TYPE=Release \; -D TEST_SUITE_REMOTE_HOST=mydevice \; ../test-suite; % ninja; % ninja rsync; % llvm-lit -j1 -o result.json .; ```. - You can specify a simulator for the target machine with the; `TEST_SUITE_RUN_UNDER` setting. The lit runner will prefix all benchmark; invocations with it. Running the test-suite via LNT; ------------------------------. The LNT tool can run the test-suite. Use this when submitting test results to; an LNT instance. See; [https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite](https://llvm.org/docs/lnt/tests.html#llvm-cmake-test-suite); for details. Running the test-suite via Makefiles (deprecated); -------------------------------------------------. **Note**: The test-suite comes with a set of Makefiles that are considered; deprecated. They do not support newer testing modes like `Bitcode` or; `Microbenchmarks` and are harder to use. Old documentation is available in the; [test-suite Makefile Guide](Te",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:12091,cache,caches,12091,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,1,['cache'],['caches']
Performance,"ocument goes over how ``MemorySSA`` is structured, and some basic; intuition on how ``MemorySSA`` works. A paper on MemorySSA (with notes about how it's implemented in GCC) `can be; found here <http://www.airs.com/dnovillo/Papers/mem-ssa.pdf>`_. Though, it's; relatively out-of-date; the paper references multiple memory partitions, but GCC; eventually swapped to just using one, like we now have in LLVM. Like; GCC's, LLVM's MemorySSA is intraprocedural. MemorySSA Structure; ===================. MemorySSA is a virtual IR. After it's built, ``MemorySSA`` will contain a; structure that maps ``Instruction``\ s to ``MemoryAccess``\ es, which are; ``MemorySSA``'s parallel to LLVM ``Instruction``\ s. Each ``MemoryAccess`` can be one of three types:. - ``MemoryDef``; - ``MemoryPhi``; - ``MemoryUse``. ``MemoryDef``\ s are operations which may either modify memory, or which; introduce some kind of ordering constraints. Examples of ``MemoryDef``\ s; include ``store``\ s, function calls, ``load``\ s with ``acquire`` (or higher); ordering, volatile operations, memory fences, etc. A ``MemoryDef``; always introduces a new version of the entire memory and is linked with a single; ``MemoryDef/MemoryPhi`` which is the version of memory that the new; version is based on. This implies that there is a *single*; ``Def`` chain that connects all the ``Def``\ s, either directly; or indirectly. For example in:. .. code-block:: llvm. b = MemoryDef(a); c = MemoryDef(b); d = MemoryDef(c). ``d`` is connected directly with ``c`` and indirectly with ``b``.; This means that ``d`` potentially clobbers (see below) ``c`` *or*; ``b`` *or* both. This in turn implies that without the use of `The walker`_,; initially every ``MemoryDef`` clobbers every other ``MemoryDef``. ``MemoryPhi``\ s are ``PhiNode``\ s, but for memory operations. If at any; point we have two (or more) ``MemoryDef``\ s that could flow into a; ``BasicBlock``, the block's top ``MemoryAccess`` will be a; ``MemoryPhi``. As in LLVM IR, ``Memo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:2094,load,load,2094,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['load'],['load']
Performance,"ocumentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.incl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:1149,load,loaded,1149,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,3,['load'],['loaded']
Performance,"od can be used; and the errors retrieved from the fit are corrected following a procedure described in paragraph 8.5.2 of the book,; *F. James, Statistical Methods in Experimental Physics, 2nd Edition*. ### Fit Statistics. You can change the statistics box to display the fit parameters with the; `TStyle::SetOptFit(mode)` method. This parameter has four digits:; `mode = pcev` (`default = 0111`). - `p` = 1 print probability; - `c` = 1 print Chi-square/number of degrees of freedom; - `e` = 1 print errors (if `e=1`, `v` must be 1); - `v` = 1 print name/values of parameters. For example, to print the fit probability, parameter names/values, and; errors, use:. ``` {.cpp}; gStyle->SetOptFit(1011);; ```. ## The Fit Panel. ![The Fit Panel](pictures/03000061.png). To display the Fit Panel right click on a histogram to pop up the; context menu, and then select the menu entry Fit Panel. The new Fit Panel GUI is available in ROOT v5.14. Its goal is to; replace the old Fit Panel and to provide more user friendly way for; performing, exploring and comparing fits. By design, this user interface is planned to contain two tabs:; ""General"" and ""Minimization"". Currently, the ""General"" tab provides; user interface elements for setting the fit function, fit method and; different fit, draw, print options.; The ""Minimization tab"" provides the option to set the Minimizer to use in the fit and; its specific options. The new fit panel is a modeless dialog, i.e. when opened, it does not; prevent users from interacting with other windows. Its first prototype; is a singleton application. When the Fit Panel is activated, users can; select an object for fitting in the usual way, i.e. by left-mouse; click on it. If the selected object is suitable for fitting, the fit; panel is connected with this object and users can perform fits by; setting different parameters and options. ### Function Choice and Settings. *Predefined' combo box* - contains a list of predefined functions in; ROOT. You have a choi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:20278,perform,performing,20278,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['perform'],['performing']
Performance,"odInfo, TClingTypeInfo, TFunction) to allow for parallel workflows using RDataFrame in multiple C++ `std::thread`s. ## I/O Libraries. - Improve parsing of input argument to `TChain::Add`. Now it supports the case of globbing files while also using the `?#` token to specify the tree name. ## RDataFrame; - instead of returning nothing, `ROOT::RDF::RunGraphs` now returns the number of separate computation graphs that have been run. - Introduce [`ProgressBar`](https://root.cern/doc/master/classROOT_1_1RDataFrame.html#progressbar) feature that can be added to any RDataFrame program. - The `RDatasetSpec` class and its users now employ the concept of 'sample' rather than the original naming 'group' for groups of files with associated metadata. - `df106_HiggsToFourLeptons` tutorials (both python and C++) now showcase the `ProgressBar`. They now use `FromSpec` to define multiple samples and `Vary` for systematic variations. ### Distributed RDataFrame. - Vastly improve runtime performance when using an RDataFrame with simulated dataset, i.e. `RDataFrame(nentries)`, by removing usage of `Range` operation to define the per-task entry range. - Explicitly error out when trying to process a TTree with a TTreeIndex in distributed mode. The feature is currently not supported. - JITting the RDataFrame computation graph now only happens once per worker process, not once per task. This greatly reduces memory usage and runtime overhead at of each task. ## TTree Libraries. ## RNTuple; ROOT's experimental successor of TTree has seen a large number of updates during the last few months. Specifically, v6.30 includes the following changes:. - Support for custom ROOT I/O rules that target transient members of a user-defined class (see PR [#11944](https://github.com/root-project/root/pull/11944)). If a rule only targets transient members and it was working in TTree, it should work unmodified in RNTuple. - Improved support for user-defined classes that behave as a collection. Specifically, RNTup",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:5536,perform,performance,5536,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['perform'],['performance']
Performance,"ode as it is built. If you take a; slightly more complex example:. ::. ready> def test(x) (1+2+x)*(x+(1+2));; ready> Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double 3.000000e+00, %x; %addtmp1 = fadd double %x, 3.000000e+00; %multmp = fmul double %addtmp, %addtmp1; ret double %multmp; }. In this case, the LHS and RHS of the multiplication are the same value.; We'd really like to see this generate ""``tmp = x+3; result = tmp*tmp;``""; instead of computing ""``x+3``"" twice. Unfortunately, no amount of local analysis will be able to detect and; correct this. This requires two transformations: reassociation of; expressions (to make the add's lexically identical) and Common; Subexpression Elimination (CSE) to delete the redundant add instruction.; Fortunately, LLVM provides a broad range of optimizations that you can; use, in the form of ""passes"". LLVM Optimization Passes; ========================. LLVM provides many optimization passes, which do many different sorts of; things and have different tradeoffs. Unlike other systems, LLVM doesn't; hold to the mistaken notion that one set of optimizations is right for; all languages and for all situations. LLVM allows a compiler implementor; to make complete decisions about what optimizations to use, in which; order, and in what situation. As a concrete example, LLVM supports both ""whole module"" passes, which; look across as large of body of code as they can (often a whole file,; but if run at link time, this can be a substantial portion of the whole; program). It also supports and includes ""per-function"" passes which just; operate on a single function at a time, without looking at other; functions. For more information on passes and how they are run, see the; `How to Write a Pass <../../WritingAnLLVMPass.html>`_ document and the; `List of LLVM Passes <../../Passes.html>`_. For Kaleidoscope, we are currently generating functions on the fly, one; at a time, as the user types them in. We are",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:3355,optimiz,optimization,3355,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimization']
Performance,"ode never; exhibits undefined behavior. Note that this guarantee is cheap on common; platforms for loads of a native width, but can be expensive or unavailable for; wider loads, like a 64-bit store on ARM. (A frontend for Java or other ""safe""; languages would normally split a 64-bit store on ARM into two 32-bit unordered; stores.). Notes for optimizers; In terms of the optimizer, this prohibits any transformation that transforms a; single load into multiple loads, transforms a store into multiple stores,; narrows a store, or stores a value which would not be stored otherwise. Some; examples of unsafe optimizations are narrowing an assignment into a bitfield,; rematerializing a load, and turning loads and stores into a memcpy; call. Reordering unordered operations is safe, though, and optimizers should; take advantage of that because unordered operations are common in languages; that need them. Notes for code generation; These operations are required to be atomic in the sense that if you use; unordered loads and unordered stores, a load cannot see a value which was; never stored. A normal load or store instruction is usually sufficient, but; note that an unordered load or store cannot be split into multiple; instructions (or an instruction which does multiple memory operations, like; ``LDRD`` on ARM without LPAE, or not naturally-aligned ``LDRD`` on LPAE ARM). Monotonic; ---------. Monotonic is the weakest level of atomicity that can be used in synchronization; primitives, although it does not provide any general synchronization. It; essentially guarantees that if you take all the operations affecting a specific; address, a consistent ordering exists. Relevant standard; This corresponds to the C++/C ``memory_order_relaxed``; see those; standards for the exact definition. Notes for frontends; If you are writing a frontend which uses this directly, use with caution. The; guarantees in terms of synchronization are very weak, so make sure these are; only used in a pattern",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:9662,load,loads,9662,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,['load'],"['load', 'loads']"
Performance,"ode snippet for such a walk looks like this:. .. code-block:: c++. MemoryDef *Def; // find who's optimized or defining for this MemoryDef; for (auto& U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *DefUser = cast_of_null<MemoryDef>MA); if (DefUser->isOptimized() && DefUser->getOptimized() == Def) {; // User who is optimized to Def; } else {; // User who's defining access is Def; optimized to something else or not optimized.; }; }. When ``MemoryUse``\ s are optimized, for a given store, you can find all loads; clobbered by that store by walking the immediate and transitive uses of; the store. .. code-block:: c++. checkUses(MemoryAccess *Def) { // Def can be a MemoryDef or a MemoryPhi.; for (auto& U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *MU = cast_of_null<MemoryUse>MA) {; // Process MemoryUse as needed.; }; else {; // Process MemoryDef or MemoryPhi as needed. // As a user can come up twice, as an optimized access and defining; // access, keep a visited list. // Check transitive uses as needed; checkUses (MA); // use a worklist for an iterative algorithm; }; }; }. An example of similar traversals can be found in the DeadStoreElimination pass. Invalidation and updating; -------------------------. Because ``MemorySSA`` keeps track of LLVM IR, it needs to be updated whenever; the IR is updated. ""Update"", in this case, includes the addition, deletion, and; motion of ``Instructions``. The update API is being made on an as-needed basis.; If you'd like examples, ``GVNHoist`` and ``LICM`` are users of ``MemorySSA``\ s; update API.; Note that adding new ``MemoryDef``\ s (by calling ``insertDef``) can be a; time-consuming update, if the new access triggers many ``MemoryPhi`` insertions and; renaming (optimization invalidation) of many ``MemoryAccesses``\ es. Phi placement; ^^^^^^^^^^^^^. ``MemorySSA`` only places ``MemoryPhi``\ s where they're actually; needed. That is, it is a pruned SSA form, like ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:13804,optimiz,optimized,13804,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimized']
Performance,"ode, a decision must be made; as to whether or not analysis can continue along the current path. This decision; is based on whether the detected bug is one that would prevent the program under; analysis from continuing. For example, leaking of a resource should not stop; analysis, as the program can continue to run after the leak. Dereferencing a; null pointer, on the other hand, should stop analysis, as there is no way for; the program to meaningfully continue after such an error. If analysis can continue, then the most recent ExplodedNode; generated by the checker can be passed to the BugReport constructor; without additional modification. This ExplodedNode will be the one; returned by the most recent call to CheckerContext::addTransition.; If no transition has been performed during the current callback, the checker should call CheckerContext::addTransition(); and use the returned node for bug reporting. If analysis can not continue, then the current state should be transitioned; into a so-called sink node, a node from which no further analysis will be; performed. This is done by calling the ; CheckerContext::generateSink function; this function is the same as the; addTransition function, but marks the state as a sink node. Like; addTransition, this returns an ExplodedNode with the updated; state, which can then be passed to the BugReport constructor. After a BugReport is created, it should be passed to the analyzer core; by calling CheckerContext::emitReport. AST Visitors; Some checks might not require path-sensitivity to be effective. Simple AST walk; might be sufficient. If that is the case, consider implementing a Clang; compiler warning. On the other hand, a check might not be acceptable as a compiler; warning; for example, because of a relatively high false positive rate. In this; situation, AST callbacks checkASTDecl and; checkASTCodeBody are your best friends. Testing; Every patch should be well tested with Clang regression tests. The checker tests; live in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html:17717,perform,performed,17717,interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,2,['perform'],['performed']
Performance,"ode-index=<LLVM opcode index>. Specify the opcode to measure, by index. Specifying `-1` will result; in measuring every existing opcode. See example 1 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --opcode-name=<opcode name 1>,<opcode name 2>,... Specify the opcode to measure, by name. Several opcodes can be specified as; a comma-separated list. See example 1 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --snippets-file=<filename>. Specify the custom code snippet to measure. See example 2 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --mode=[latency|uops|inverse_throughput|analysis]. Specify the run mode. Note that some modes have additional requirements and options. `latency` mode can be make use of either RDTSC or LBR.; `latency[LBR]` is only available on X86 (at least `Skylake`).; To run in `latency` mode, a positive value must be specified; for `x86-lbr-sample-period` and `--repetition-mode=loop`. In `analysis` mode, you also need to specify at least one of the; `-analysis-clusters-output-file=` and `-analysis-inconsistencies-output-file=`. .. option:: --benchmark-phase=[prepare-snippet|prepare-and-assemble-snippet|assemble-measured-code|measure]. By default, when `-mode=` is specified, the generated snippet will be executed; and measured, and that requires that we are running on the hardware for which; the snippet was generated, and that supports performance measurements.; However, it is possible to stop at some stage before measuring. Choices are:; * ``prepare-snippet``: Only generate the minimal instruction sequence.; * ``prepare-and-assemble-snippet``: Same as ``prepare-snippet``, but also dumps an excerpt of the sequence (hex encoded).; * ``assemble-measured-code``: Same as ``prepare-and-assemble-snippet``. but also creates the full sequence that can be dumped to a file using ``--dump-object-to-disk``.; * ``measur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:10216,latency,latency,10216,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['latency'],['latency']
Performance,"ode. We should treat it as a two-address code and make sure the ADDri is; scheduled after any node that reads %reg1039. //===---------------------------------------------------------------------===//. Use local info (i.e. register scavenger) to assign it a free register to allow; reuse:; ldr r3, [sp, #+4]; add r3, r3, #3; ldr r2, [sp, #+8]; add r2, r2, #2; ldr r1, [sp, #+4] <==; add r1, r1, #1; ldr r0, [sp, #+4]; add r0, r0, #2. //===---------------------------------------------------------------------===//. LLVM aggressively lift CSE out of loop. Sometimes this can be negative side-; effects:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; load [i + R1]; ...; load [i + R2]; ...; load [i + R3]. Suppose there is high register pressure, R1, R2, R3, can be spilled. We need; to implement proper re-materialization to handle this:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; R1 = X + 4 @ re-materialized; load [i + R1]; ...; R2 = X + 7 @ re-materialized; load [i + R2]; ...; R3 = X + 15 @ re-materialized; load [i + R3]. Furthermore, with re-association, we can enable sharing:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; T = i + X; load [T + 4]; ...; load [T + 7]; ...; load [T + 15]; //===---------------------------------------------------------------------===//. It's not always a good idea to choose rematerialization over spilling. If all; the load / store instructions would be folded then spilling is cheaper because; it won't require new live intervals / registers. See 2003-05-31-LongShifts for; an example. //===---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0 x %obj] }** %array_addr; %nth_el = getelementptr { i32, [0 x %obj] }* %array, i32 0, i32 %n; %old = lo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:2112,load,load,2112,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['load'],['load']
Performance,"ode> = !{ i32 1 }; !<empty_node> = !{}. Overview:; """""""""""""""""". The '``store``' instruction is used to write to memory. Arguments:; """""""""""""""""""". There are two arguments to the ``store`` instruction: a value to store and an; address at which to store it. The type of the ``<pointer>`` operand must be a; pointer to the :ref:`first class <t_firstclass>` type of the ``<value>``; operand. If the ``store`` is marked as ``volatile``, then the optimizer is not; allowed to modify the number or order of execution of this ``store`` with other; :ref:`volatile operations <volatile>`. Only values of :ref:`first class; <t_firstclass>` types of known size (i.e. not containing an :ref:`opaque; structural type <t_opaque>`) can be stored. If the ``store`` is marked as ``atomic``, it takes an extra :ref:`ordering; <ordering>` and optional ``syncscope(""<target-scope>"")`` argument. The; ``acquire`` and ``acq_rel`` orderings aren't valid on ``store`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic stores. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemporal`` does not have any; defined semantics for atomic stores. The optional constant ``align`` argument specifies the alignment of the; operation (that is, the alignment of the memory address). It is the; responsibility of the code emitter to ensure that the alignment information is; correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value hig",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:420376,load,loads,420376,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loads']
Performance,"odel-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx942`; * :ref:`amdgpu-amdhsa-memory-model-gfx10-gfx11`. .. _amdgpu-amdhsa-memory-model-gfx6-gfx9:. Memory Model GFX6-GFX9; ++++++++++++++++++++++. For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence betw",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:206885,perform,performed,206885,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance,"odes are:. .. _icmp_md_cc:. #. ``eq``: equal; #. ``ne``: not equal; #. ``ugt``: unsigned greater than; #. ``uge``: unsigned greater or equal; #. ``ult``: unsigned less than; #. ``ule``: unsigned less or equal; #. ``sgt``: signed greater than; #. ``sge``: signed greater or equal; #. ``slt``: signed less than; #. ``sle``: signed less or equal. The remaining two arguments must be :ref:`integer <t_integer>` or; :ref:`pointer <t_pointer>` or integer :ref:`vector <t_vector>` typed. They; must also be identical types. Semantics:; """""""""""""""""""". The '``icmp``' compares ``op1`` and ``op2`` according to the condition; code given as ``cond``. The comparison performed always yields either an; :ref:`i1 <t_integer>` or vector of ``i1`` result, as follows:. .. _icmp_md_cc_sem:. #. ``eq``: yields ``true`` if the operands are equal, ``false``; otherwise. No sign interpretation is necessary or performed.; #. ``ne``: yields ``true`` if the operands are unequal, ``false``; otherwise. No sign interpretation is necessary or performed.; #. ``ugt``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is greater than ``op2``.; #. ``uge``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is greater than or equal to ``op2``.; #. ``ult``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is less than ``op2``.; #. ``ule``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is less than or equal to ``op2``.; #. ``sgt``: interprets the operands as signed values and yields ``true``; if ``op1`` is greater than ``op2``.; #. ``sge``: interprets the operands as signed values and yields ``true``; if ``op1`` is greater than or equal to ``op2``.; #. ``slt``: interprets the operands as signed values and yields ``true``; if ``op1`` is less than ``op2``.; #. ``sle``: interprets the operands as signed values and yields ``true``; if ``op1`` is less than or equal to ``op2``. If the operands are :ref:`pointer <t_point",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:461047,perform,performed,461047,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"odified the histogram's Z axis parameters. - Call automatically `Deflate` at drawing time of alphanumeric labels. It makes sense as; nobody wants to see extra blank labels. - The Confidence interval colors set by SetConfidenceIntervalColors (TRatioPlot) were inverted. - Add GetZaxis for THStack. - Fix Graph Errorbar Offsets for the new Marker Styles and thick markers. - When the palette width is bigger than the palette height, the palette; is automatically drawn horizontally. - THStack::GetXaxis->SetRange did not auto-zoom Yaxis range. - The Paint method of THStack always redrew the histograms in the sub-pads defined by the; THStack drawing option ""pads"". Like the ""pad dividing"" the ""histograms' drawing"" should be; done only the first time the THStack is painted otherwise any additional graphics objects; added in one of the pads (created by the ""pads"" option) will be removed. - Improve TRatioPlot axes drawing. ## Math Libraries. - `RVec` has been heavily re-engineered in order to add a small buffer optimization and to streamline its internals. The change should provide a small performance boost to; applications that make heavy use of `RVec`s and should otherwise be user-transparent. Please report any issues you should encounter.; - I/O support of `RVec` objects has been optimized. As a side-effect, `RVec`s can now be read back as `std::vector`s and vice-versa.; - Add `ROOT::VecOps::Drop`, an operation that removes `RVec` elements at the specified indices.; - handy aliases `ROOT::RVecI`, `ROOT::RVecD`, `ROOT::RVecF`, ..., have been introduced as short-hands for `RVec<int>`, `RVec<double>`, `RVec<float>`, ...; - Add `VecOps::StableArgsort` and `VecOps::StableSort` operations. ## RooFit Libraries. ### Experimental CUDA support for RooFit's `BatchMode`. RooFit's [`BatchMode`](https://root.cern/doc/master/classRooAbsPdf.html#a8f802a3a93467d5b7b089e3ccaec0fa8) has been around; [since ROOT 6.20](https://root.cern/doc/v620/release-notes.html#fast-function-evaluation-and-vect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:14059,optimiz,optimization,14059,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['optimiz'],['optimization']
Performance,"oduction to the LLVM remark diagnostics; ===========================================. LLVM is able to emit diagnostics from passes describing whether an optimization; has been performed or missed for a particular reason, which should give more; insight to users about what the compiler did during the compilation pipeline. There are three main remark types:. ``Passed``. Remarks that describe a successful optimization performed by the compiler. :Example:. ::. foo inlined into bar with (cost=always): always inline attribute. ``Missed``. Remarks that describe an attempt to an optimization by the compiler that; could not be performed. :Example:. ::. foo not inlined into bar because it should never be inlined; (cost=never): noinline function attribute. ``Analysis``. Remarks that describe the result of an analysis, that can bring more; information to the user regarding the generated code. :Example:. ::. 16 stack bytes in function. ::. 10 instructions in function. Enabling optimization remarks; =============================. There are two modes that are supported for enabling optimization remarks in; LLVM: through remark diagnostics, or through serialized remarks. Remark diagnostics; ------------------. Optimization remarks can be emitted as diagnostics. These diagnostics will be; propagated to front-ends if desired, or emitted by tools like :doc:`llc; <CommandGuide/llc>` or :doc:`opt <CommandGuide/opt>`. .. option:: -pass-remarks=<regex>. Enables optimization remarks from passes whose name match the given (POSIX); regular expression. .. option:: -pass-remarks-missed=<regex>. Enables missed optimization remarks from passes whose name match the given; (POSIX) regular expression. .. option:: -pass-remarks-analysis=<regex>. Enables optimization analysis remarks from passes whose name match the given; (POSIX) regular expression. Serialized remarks; ------------------. While diagnostics are useful during development, it is often more useful to; refer to optimization remarks post-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst:1034,optimiz,optimization,1034,interpreter/llvm-project/llvm/docs/Remarks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst,1,['optimiz'],['optimization']
Performance,"odule (before return from the function -- an; allocator function may return newly accessible memory while only; accessing inaccessible memory itself). Inaccessible memory is often used; to model control dependencies of intrinsics.; - The default access kind (specified without a location prefix) applies to; all locations that haven't been specified explicitly, including those that; don't currently have a dedicated location kind (e.g. accesses to globals; or captured pointers). If the ``memory`` attribute is not specified, then ``memory(readwrite)``; is implied (all memory effects are possible). The memory effects of a call can be computed as; ``CallSiteEffects & (FunctionEffects | OperandBundleEffects)``. Thus, the; call-site annotation takes precedence over the potential effects described; by either the function annotation or the operand bundles.; ``minsize``; This attribute suggests that optimization passes and code generator; passes make choices that keep the code size of this function as small; as possible and perform optimizations that may sacrifice runtime; performance in order to minimize the size of the generated code.; This attribute is incompatible with the ``optdebug`` and ``optnone``; attributes.; ``naked``; This attribute disables prologue / epilogue emission for the; function. This can have very system-specific consequences.; ``""no-inline-line-tables""``; When this attribute is set to true, the inliner discards source locations; when inlining code and instead uses the source location of the call site.; Breakpoints set on code that was inlined into the current function will; not fire during the execution of the inlined call sites. If the debugger; stops inside an inlined call site, it will appear to be stopped at the; outermost inlined call site.; ``no-jump-tables``; When this attribute is set to true, the jump tables and lookup tables that; can be generated from a switch case lowering are disabled.; ``nobuiltin``; This indicates that the callee function a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:86742,optimiz,optimization,86742,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,4,"['optimiz', 'perform']","['optimization', 'optimizations', 'perform', 'performance']"
Performance,"odule which contains the corresponding definition. Switching; back to preloading of all C++ modules is done by setting the `ROOT_USE_GMI`; environment variable to false.; ; ### Supported Platforms. We support all platforms with glibc++ versions: 5.2 onward. We support OSX from XCode 10 onward. ## Changes required by the users; * Self-contained header files -- every header file should be able to compile; on its own. For instance, `cat header.h header.h | gcc -fsyntax-only -xc++ -`.; This command concatenates `header.h` twice before compiling it to make sure; it has proper include protectors.; * Enable it in `rootcling` -- rootcling can produce a C++ Modules-aware; dictionary when it is invoked with `-cxxmodule` flag.; * Modularization of external dependencies -- if a header file is not explicitly; nominated as part of a module and it is transitively included in two modules,; both modules contain that header file content. In other words, the header is; duplicated. In turn, this leads to performance regressions. If a dictionary; depends on a header (directly or indirectly) from a external library (e.g.; libxml) it needs to be modularized. As part of our ongoing efforts to move; CMSSW to use C++ Modules [[6]] we have implemented a helper tool [[7]]. The; tool detects (based on the include paths of the compiler) dependencies and; tries to generate the relevant vfs file. ## State of the union. Preloading all modules at start up time turn our motivating example into:. ```cpp; // ROOT prompt; root [] S *s; // #1: does not require a definition.; root [] foo::bar *baz1; // #2: does not require a definition.; root [] foo::bar baz2; // #3: requires a definition.; root [] TCanvas* c = new TCanvas(); // #4 requires a definition. ```. becomes equivalent to. ```cpp; // ROOT prompt; root [] import ROOT.*;; root [] import Foo.*;; root [] S *s; // #1: does not require a definition.; root [] foo::bar *baz1; // #2: does not require a definition.; root [] foo::bar baz2; // #3: requires a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:15342,perform,performance,15342,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,1,['perform'],['performance']
Performance,"odule2 = TGeoVolume::Import(""file.root"", ""MOD2"");; top->AddNode(module1, 1, new TGeoTranslation(0,0,100));; top->AddNode(module2, 1, new TGeoTranslation(0,0,-100));; // One should close oneself the geometry; geom->CloseGeometry();; ~~~. \anchor GP06a; ### GDML. Few lines above word GDML was used. GDML stands for Geometry; Description Markup Language. It is an application-independent; geometry description format based on XML. It is mainly used for geometry; interchange between %ROOT and Geant4 framework. More details about this; project can be found http://gdml.web.cern.ch. This feature; (importing/exporting from/to gdml file format) is disabled by default in; %ROOT installation. To enable this feature add `--enable-gdml` option to; `./configure` script call. \anchor GP07; ## Navigation Algorithms. This section will describe the main methods and algorithms used for; implementing the navigation features within the geometrical modeller.; This includes navigation queries at shape level, global geometrical; queries and optimization mechanisms. \anchor GP07a; ### Finding the State Corresponding to a Location (x,y,z). For reminder, a geometry state is a touchable' object in the geometry; hierarchy. It is represented by a path like: `/TOP\_1/A\_1/B\_3/C\_1`,; where `B\_3` for instance is a copy of volume `B` positioned inside; volume `A`. A state is always associated to a transformation matrix; `M` of the touchable with respect to the global reference frame; (obtained by piling-up all local transformations of nodes in the branch; with respect to their containers). The current state and the; corresponding global matrix are updated whenever the geometry depth is; modified. The global transformations corresponding to all nodes in the; current branch are kept in an array: (`MTOP\_1, MA\_1, MB\_3, ...`). \image html geometry015.png ""Navigation in the geometry hierarchy"" width=600px. The elementary operations for changing the state are:. ~~~{.cpp}; TGeoManager::CdUp();; TGeoManag",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:115314,optimiz,optimization,115314,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['optimiz'],['optimization']
Performance,"odule`` and the FunctionPassManager,; we need to initialize other parts of the framework. The four AnalysisManagers; allow us to add analysis passes that run across the four levels of the IR; hierarchy. PassInstrumentationCallbacks and StandardInstrumentations are; required for the pass instrumentation framework, which allows developers to; customize what happens between passes. Once these managers are set up, we use a series of ""addPass"" calls to add a; bunch of LLVM transform passes:. .. code-block:: c++. // Add transform passes.; // Do simple ""peephole"" optimizations and bit-twiddling optzns.; TheFPM->addPass(InstCombinePass());; // Reassociate expressions.; TheFPM->addPass(ReassociatePass());; // Eliminate Common SubExpressions.; TheFPM->addPass(GVNPass());; // Simplify the control flow graph (deleting unreachable blocks, etc).; TheFPM->addPass(SimplifyCFGPass());. In this case, we choose to add four optimization passes.; The passes we choose here are a pretty standard set; of ""cleanup"" optimizations that are useful for a wide variety of code. I won't; delve into what they do but, believe me, they are a good starting place :). Next, we register the analysis passes used by the transform passes. .. code-block:: c++. // Register analysis passes used in these transform passes.; PassBuilder PB;; PB.registerModuleAnalyses(*TheMAM);; PB.registerFunctionAnalyses(*TheFAM);; PB.crossRegisterProxies(*TheLAM, *TheFAM, *TheCGAM, *TheMAM);; }. Once the PassManager is set up, we need to make use of it. We do this by; running it after our newly created function is constructed (in; ``FunctionAST::codegen()``), but before it is returned to the client:. .. code-block:: c++. if (Value *RetVal = Body->codegen()) {; // Finish off the function.; Builder.CreateRet(RetVal);. // Validate the generated code, checking for consistency.; verifyFunction(*TheFunction);. // Optimize the function.; TheFPM->run(*TheFunction, *TheFAM);. return TheFunction;; }. As you can see, this is pretty straigh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:7515,optimiz,optimizations,7515,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimizations']
Performance,"oes not have instrumentation. The original code and; the instrumented code are modified to have a branch to the trace; cache, where the optimized traces are kept. We copy the code from the original to the instrumentation version; by tracing the LLVM-to-Machine code basic block map and then copying; each machine code basic block we think is in the hot region into the; trace cache. Then we instrument that code. The process is similar for; generating the final optimized trace; we copy the same basic blocks; because we might need to put in fixup code for exit BBs. LLVM basic blocks are not typically used in the Reoptimizer except; for the mapping information. We are restricted to using single instructions to branch between the; original code, trace, and instrumented code. So we have to keep the; code copies in memory near the original code (they can't be far enough; away that a single pc-relative branch would not work.) Malloc() or; data region space is too far away. this impacts the design of the ; trace cache. We use a dummy function that is full of a bunch of for loops which we; overwrite with trace-cache code. The trace manager keeps track of; whether or not we have enough space in the trace cache, etc. The trace insertion routine takes an original start address, a vector; of machine instructions representing the trace, index of branches and; their corresponding absolute targets, and index of calls and their; corresponding absolute targets. The trace insertion routine is responsible for inserting branches from; the beginning of the original code to the beginning of the optimized; trace. This is because at some point the trace cache may run out of; space and it may have to evict a trace, at which point the branch to; the trace would also have to be removed. It uses a round-robin; replacement policy; we have found that this is almost as good as LRU; and better than random (especially because of problems fitting the new; trace in.). We cannot deal with discontiguous tr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt:4715,cache,cache,4715,interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,1,['cache'],['cache']
Performance,"oes not invalidate any of the analysis results though. OPTIONS; -------. .. option:: --help. Print a summary of command line options. .. option:: --opcode-index=<LLVM opcode index>. Specify the opcode to measure, by index. Specifying `-1` will result; in measuring every existing opcode. See example 1 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --opcode-name=<opcode name 1>,<opcode name 2>,... Specify the opcode to measure, by name. Several opcodes can be specified as; a comma-separated list. See example 1 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --snippets-file=<filename>. Specify the custom code snippet to measure. See example 2 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --mode=[latency|uops|inverse_throughput|analysis]. Specify the run mode. Note that some modes have additional requirements and options. `latency` mode can be make use of either RDTSC or LBR.; `latency[LBR]` is only available on X86 (at least `Skylake`).; To run in `latency` mode, a positive value must be specified; for `x86-lbr-sample-period` and `--repetition-mode=loop`. In `analysis` mode, you also need to specify at least one of the; `-analysis-clusters-output-file=` and `-analysis-inconsistencies-output-file=`. .. option:: --benchmark-phase=[prepare-snippet|prepare-and-assemble-snippet|assemble-measured-code|measure]. By default, when `-mode=` is specified, the generated snippet will be executed; and measured, and that requires that we are running on the hardware for which; the snippet was generated, and that supports performance measurements.; However, it is possible to stop at some stage before measuring. Choices are:; * ``prepare-snippet``: Only generate the minimal instruction sequence.; * ``prepare-and-assemble-snippet``: Same as ``prepare-snippet``, but also dumps an excerpt of the sequence (hex encoded).; * ``assemble-measured-code``:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:10087,latency,latency,10087,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['latency'],['latency']
Performance,"of Volumes. The first thing one would like to do after building some geometry is to; visualize the volume tree. This provides the fastest validation check; for most common coding or design mistakes. As soon as the geometry is; successfully closed, one should draw it starting from the top-level; volume:. ``` {.cpp}; //... code for geometry building; root[] gGeoManager->CloseGeometry();; root[] gGeoManager->GetMasterVolume()->Draw();; ```. Doing this ensures that the original top-level volume of the geometry is; drawn, even if another volume is currently the geometry `root`. OK, I; suppose you already did that with your simple geometry and immediately; noticed a new ROOT canvas popping-up and having some more or less; strange picture inside. Here are few questions that might come:. ***`Q:`*** ""The picture is strangely rotated; where are the coordinate axes?"". ***`A:`*** If drawn in a new canvas, any view has some default; viewpoint, center of view and size. One can then perform mouse/keyboard; actions to change them:. - Mouse left-click and drag will rotate the view;. - Some keys can be pressed when the view canvas is selected: J/K; zoom/un-zoom, U/I move up/down, L/H move left/right. The coordinate axes; display as well as changing top or side viewpoints can be activated from; the **`TView`** context menu: right-click on the picture when no object; is selected;. ***`Q:`*** ""Every line is black! I cannot figure out what is what..."". ***`A:`*** Volumes can have different colors (those known by ROOT of; course). Think at using them after each volume creation:; `myvolume->SetLineColor(Int_t color);` otherwise everything is by; default black. ***`Q:`*** ""The top volume of my geometry is a box but I see only its content."". ***`A:`*** By default the drawn volume is not displayed just because we; do not want to hide its content when changing the view to HLR or solid; mode. In order to see it in the default wire frame picture one has to; call **`TGeoManager::SetTopVisible()`.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:138352,perform,perform,138352,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['perform']
Performance,"of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13608,cache,cache,13608,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,2,['cache'],"['cache', 'caches']"
Performance,"of a; packet containing various information about the performance related to; that file only.; Added support also for performance monitoring when writing. RGLITE: A ROOT GRID interface. RGLite plug-in - a ROOT plug-in module, which implements the ROOT Grid; interface and offers to ROOT users possibilities to perform a number of; operations using gLite middleware from within ROOT. Supported features:. Workload Management System operations:; ; job submission  normal, DAG and parametric; jobs (gLite; WMProxy API), ; smart look-up algorithm for WMP-Endpoints, ; job status querying (gLite LB API), ; job output retrieving (Globus GridFTP). . File Catalog operations (gLite/LCG LFC API):; ; smart session manager, ; set/query the current working catalog directory, ; list files, directories and their stats, ; add/remove files in a catalog namespace, ; add/remove directories, ; add/remove replicas from a given file. . An executive logging. ; Support of an external XML configuration file with; according XML; schema. . Usage examples:. Job operations. // loading RGLite plug-in. TGrid::Connect(""glite"");; // submitting Grid job. TGridJob *job = gGrid->Submit(""JDLs/simple.jdl"");; // getting status object. TGridJobStatus *status = job->GetJobStatus();; // getting status of the job. TGridJobStatus::EGridJobStatus st( status->GetStatus() );; // when the st is; TGridJobStatus::kDONE you can; retrieve job's output. job->GetOutputSandbox(""/tmp"");. File Catalog operations. // loading RGLite plug-in. TGrid::Connect(""glite"");; // changing the current directory to; ""/grid/dech"". gGrid->Cd(""/grid/dech"");; // using Mkdir to create a new; directory. Bool_t b = gGrid->Mkdir(""root_test2"");; // listing the current directory. TGridResult* result = gGrid->Ls();; // full file information. result->Print(""all"");; // removing the directory . b = gGrid->Rmdir(""root_test2"");. Documentation: ; http://www-linux.gsi.de/%7Emanafov/D-Grid/docz/RGLite/html/. and; http://www-linux.gsi.de/~manafov/D-Grid/docz/; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html:3938,load,loading,3938,net/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html,4,['load'],['loading']
Performance,"of all entries with more than 600; tracks. To see the entry numbers use the `Print(""all"")` command. ``` {.cpp}; root[] myList->Print(""all"");; ```. When using the ""`>>`"" whatever was in the list is overwritten. The list; can be grown by using the ""`>>+`"" syntax. For example to add the; entries, with exactly 600 tracks:. ``` {.cpp}; root[] T->Draw("">>+ myList"",""fNtrack == 600"", ""entrylist"");; ```. If the `Draw` command generates duplicate entries, they are not added to; the list. ``` {.cpp}; root[] T->Draw("">>+ myList"","" fNtrack > 610"", ""entrylist"");; ```. This command does not add any new entries to the list because all; entries with more than 610 tracks have already been found by the; previous command for entries with more than 600 tracks. #### Main Differences between TEventList and TEntryList. The functionality is essentially the same: both are used to store entry; numbers. **`TEntryList`**, however, uses considerably less memory for; storage, and is optimized for both very high and very low selectivity of; cuts (see **`TEntryListBlock`** class description for the details of; internal storage). Unlike the **`TEventList`**, **`TEntryList`** makes a; distinction between indices from a **`TChain`** and from a **`TTree`**.; While a **`TEntryList`** for a **`TTree`** can be seen as just a list of; numbers, a **`TEntryList`** for a **`TChain`** is a collection of; **`TEntryList`**(s) for the **`TTree`**(s) that constitute this; **`TChain`**. Such ""sub-lists"" can be extracted by calling the function. ``` {.cpp}; TEntryList::GetEntryList(const char *treename, const char *filename); ```. and then be used to construct a new **`TEntryList`** for a new; **`TChain`**, or processed independently as normal **`TEntryList`**(s); for **`TTree`**(s). This modularity makes **`TEntryList`** much better; suited for PROOF processing than the **`TEventList`**. #### Using an Event List. A **`TEventList`** or a **`TEntryList`** can be used to limit the; **`TTree`** to the events in the list",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:109632,optimiz,optimized,109632,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['optimiz'],['optimized']
Performance,"of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variable ``!23`` should not flow ""down"" into the ``%exit`` block. .. _ccxx_frontend:. C/C++ front-end specific debug information; ==========================================. The C and C++ front-ends represent information about the program in a; format that is effectively identical to `DWARF <http://www.dwarfstd.org/>`_; in terms of information content. This allows code generators to; trivially support native debuggers by generating standard dwarf; information, and contains enough information for non-dwarf targets to; translate it as needed. This section describes the forms used to represent C and C++ programs. Other; languages could pattern themselves after this (which itself is tuned to; representing programs in the same way that DWARF does), or they could choose; to provide completely different forms if they don't fit into the DWARF model.; As support for debugging information gets added to the various LLVM; source-language front-ends, the information used should be documented here. The following sections provide examples of a few C/C++ constructs and; the debug information that would best describe those constructs. The; canonical references are the ``DINode`` classes defined in; ``include/llvm/IR/DebugInfoMetadata.h`` and the implementations of the; helper functions in ``lib/IR/DIBuilder.cpp``. C/C++ source file information; -----------------------------. ``llvm::Instruction`` provides easy access to metadata attached with an; instruction. One can extract line number information encoded in LLVM IR using; ``Instruction::getDebugLoc()`` and ``DILocation::getLine()``. .. code-block:: c++. if (DILocation *Loc = I->getDebugLoc()) { // Here I is an LLVM instruction; unsigned Line = Loc->getLine();; StringRef ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:40933,tune,tuned,40933,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['tune'],['tuned']
Performance,"of having Cling interpret your script there is a way to have your; scripts compiled, linked and dynamically loaded using the C++ compiler; and linker. The advantage of this is that your scripts will run with the; speed of compiled C++ and that you can use language constructs that are; not fully supported by Cling. On the other hand, you cannot use any Cling; shortcuts (see ""C++ Extensions To Ease Scripting"" above) and for small scripts, the; overhead of the compile/link cycle might be larger than just executing; the script in the interpreter. ACLiC will build a dictionary and a shared library from your C++; script, using the compiler and the compiler options that were used to; compile the ROOT executable. You do not have to write a Makefile; remembering the correct compiler options, and you do not have to exit; ROOT. ### Usage. Before you can compile your interpreted script you need to add include; statements for the classes used in the script. Once you did that, you; can build and load a shared library containing your script. To load it; use the command `.L` and append the file name with a `+`. ``` {.cpp}; root[] .L MyScript.C+; ```. The + option generates the shared library and names it by taking; the name of the file ""filename"" but replacing the dot before the; extension by an underscore and by adding the shared library extension; for the current platform. For example on most platforms, `hsimple.cxx`; will generate `hsimple_cxx.so`. The + command rebuild the library only if the script or any of the; files it includes are newer than the library. When checking the; timestamp, ACLiC generates a dependency file which name is the same as; the library name, just replacing the 'so' extension by the extension; 'd'. For example on most platforms, `hsimple.cxx` will generate; `hsimple_cxx.d`. To ensure that the shared library is rebuilt you can use the ++; syntax:. ``` {.cpp}; root[] .L MyScript.C++; ```. To build, load, and execute the function with the same name as the; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md:13593,load,load,13593,documentation/users-guide/Cling.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md,1,['load'],['load']
Performance,"of parentheses) and allow; it to be treated uniformly with valid CallExprs. However, jamming the data we; have into CallExpr forces us to weaken its invariants, e.g. arg count may be; wrong. This would introduce a huge burden on consumers of the AST to handle such; ""impossible"" cases. So when we're representing (rather than correcting) errors,; we use a distinct recovery node type with extremely weak invariants instead. ``RecoveryExpr`` is the only recovery node so far. In practice, broken decls; need more detailed semantics preserved (the current ``Invalid`` flag works; fairly well), and completely broken statements with interesting internal; structure are rare (so dropping the statements is OK). Types and dependence; ^^^^^^^^^^^^^^^^^^^^. ``RecoveryExpr`` is an ``Expr``, so it must have a type. In many cases the true; type can't really be known until the code is corrected (e.g. a call to a; function that doesn't exist). And it means that we can't properly perform type; checks on some containing constructs, such as ``return 42 + unknownFunction()``. To model this, we generalize the concept of dependence from C++ templates to; mean dependence on a template parameter or how an error is repaired. The; ``RecoveryExpr`` ``unknownFunction()`` has the totally unknown type; ``DependentTy``, and this suppresses type-based analysis in the same way it; would inside a template. In cases where we are confident about the concrete type (e.g. the return type; for a broken non-overloaded function call), the ``RecoveryExpr`` will have this; type. This allows more code to be typechecked, and produces a better AST and; more diagnostics. For example:. .. code-block:: C++. unknownFunction().size() // .size() is a CXXDependentScopeMemberExpr; std::string(42).size() // .size() is a resolved MemberExpr. Whether or not the ``RecoveryExpr`` has a dependent type, it is always; considered value-dependent, because its value isn't well-defined until the error; is resolved. Among other things, thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:87925,perform,perform,87925,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['perform'],['perform']
Performance,"of standard objective function like the Chi2 function, the Poisson likelihood function (for binned likelihood fits) and the loh likelihood function (for unbinned fits). These standard objective functions can be created with or without gradient functionality. In the first case the minimization will be performed using the gradient provided by the function. These functions can also be used in specialized fitting methods like Fumili or the GSL non-linear least square.; . MathCore. Fixed a bug in setting the VEGAS integration mode in the GSLMCIntegrator class.; . Fumili. Add implementation of Minimizer interface using TFumili.; ; Minuit. In TMinuitMinimizer: do not delete the contained TMinuit reference, but maintain it alive, and accessible outside as gMinuit. It can then be used after fitting, for example for drawing contour plots. Add also support for Scan and Contour plots.; ; TLinearMinimizer: add support for robust fitting; . Minuit2. Add support to perform parallel minimization using a thread for each gradient calculation with openMP. In the ROOT environment the Minuit2 library can be built using openMP ( -fopenmp compilation flag for gcc) if the environment variables USE_PARALLEL_MINUIT2 and USE_OPENMP are set.; In the Minuit2 standalone built libraries (using autoconf) support for openMP is automatically enabled, whenever the compiler supports it (for example for gcc version >= 4.2). Some small changes have been applied in Minuit2 to make it thread safe. For example, when transforming from internal to external values, the parameter values are not cached anymore in MnUserTransformation class.; DavidonErrorUpdator: add an additional check to avoid a division by zero.; In Minuit2Minimizer fill the status information according to the minimizer result; Add Scan and Contour methods in the Minuit2Minimizer class; ; GenVector. Change the way the exception are thrown in the package (class GenVector_exception). Now, the GenVector_exception class is created only when the th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html:3110,perform,perform,3110,math/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html,2,['perform'],['perform']
Performance,"of the existing registries; we; recommend ``llvm/CodeGen/RegAllocRegistry.h``. The key things to modify are; the class name and the ``FunctionPassCtor`` type. Then you need to declare the registry. Example: if your pass registry is; ``RegisterMyPasses`` then define:. .. code-block:: c++. MachinePassRegistry<RegisterMyPasses::FunctionPassCtor> RegisterMyPasses::Registry;. And finally, declare the command line option for your passes. Example:. .. code-block:: c++. cl::opt<RegisterMyPasses::FunctionPassCtor, false,; RegisterPassParser<RegisterMyPasses> >; MyPassOpt(""mypass"",; cl::init(&createDefaultMyPass),; cl::desc(""my pass option help""));. Here the command option is ""``mypass``"", with ``createDefaultMyPass`` as the; default creator. Using GDB with dynamically loaded passes; ----------------------------------------. Unfortunately, using GDB with dynamically loaded passes is not as easy as it; should be. First of all, you can't set a breakpoint in a shared object that; has not been loaded yet, and second of all there are problems with inlined; functions in shared objects. Here are some suggestions to debugging your pass; with GDB. For sake of discussion, I'm going to assume that you are debugging a; transformation invoked by :program:`opt`, although nothing described here; depends on that. Setting a breakpoint in your pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. First thing you do is start gdb on the opt process:. .. code-block:: console. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:52239,load,loaded,52239,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['load'],['loaded']
Performance,"of the most recent dynamic alloca. Although for most targets `llvm.get.dynamic.area.offset <int_get_dynamic_area_offset>`; returns just a zero, for others, such as PowerPC and PowerPC64, it returns a; compile-time-known constant value. The return value type of :ref:`llvm.get.dynamic.area.offset <int_get_dynamic_area_offset>`; must match the target's default address space's (address space 0) pointer type. '``llvm.prefetch``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.prefetch(ptr <address>, i32 <rw>, i32 <locality>, i32 <cache type>). Overview:; """""""""""""""""". The '``llvm.prefetch``' intrinsic is a hint to the code generator to; insert a prefetch instruction if supported; otherwise, it is a noop.; Prefetches have no effect on the behavior of the program but can change; its performance characteristics. Arguments:; """""""""""""""""""". ``address`` is the address to be prefetched, ``rw`` is the specifier; determining if the fetch should be for a read (0) or write (1), and; ``locality`` is a temporal locality specifier ranging from (0) - no; locality, to (3) - extremely local keep in cache. The ``cache type``; specifies whether the prefetch is performed on the data (1) or; instruction (0) cache. The ``rw``, ``locality`` and ``cache type``; arguments must be constant integers. Semantics:; """""""""""""""""""". This intrinsic does not modify the behavior of the program. In; particular, prefetches cannot trap and do not produce a value. On; targets that support this intrinsic, the prefetch can provide hints to; the processor cache for better performance. '``llvm.pcmarker``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.pcmarker(i32 <id>). Overview:; """""""""""""""""". The '``llvm.pcmarker``' intrinsic is a method to export a Program; Counter (PC) in a region of code to simulators and other tools. The; method is target specific, but it is expected that the marker will use; exported symbols to transmit the PC of the marker. The ma",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:523575,cache,cache,523575,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['cache'],['cache']
Performance,"of the most; recent dynamic alloca. For targets where stack grows upwards, the situation is a bit more; complicated, because subtracting this value from stack pointer would get the address; one past the end of the most recent dynamic alloca. Although for most targets `llvm.get.dynamic.area.offset <int_get_dynamic_area_offset>`; returns just a zero, for others, such as PowerPC and PowerPC64, it returns a; compile-time-known constant value. The return value type of :ref:`llvm.get.dynamic.area.offset <int_get_dynamic_area_offset>`; must match the target's default address space's (address space 0) pointer type. '``llvm.prefetch``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.prefetch(ptr <address>, i32 <rw>, i32 <locality>, i32 <cache type>). Overview:; """""""""""""""""". The '``llvm.prefetch``' intrinsic is a hint to the code generator to; insert a prefetch instruction if supported; otherwise, it is a noop.; Prefetches have no effect on the behavior of the program but can change; its performance characteristics. Arguments:; """""""""""""""""""". ``address`` is the address to be prefetched, ``rw`` is the specifier; determining if the fetch should be for a read (0) or write (1), and; ``locality`` is a temporal locality specifier ranging from (0) - no; locality, to (3) - extremely local keep in cache. The ``cache type``; specifies whether the prefetch is performed on the data (1) or; instruction (0) cache. The ``rw``, ``locality`` and ``cache type``; arguments must be constant integers. Semantics:; """""""""""""""""""". This intrinsic does not modify the behavior of the program. In; particular, prefetches cannot trap and do not produce a value. On; targets that support this intrinsic, the prefetch can provide hints to; the processor cache for better performance. '``llvm.pcmarker``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.pcmarker(i32 <id>). Overview:; """""""""""""""""". The '``llvm.pcmarker``' intrinsic is a method to export a P",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:523271,perform,performance,523271,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performance']
Performance,"of the progress; dialog. The improved log window allows to chose a different master; and/or session and displays human readable information about; the starting time of the session being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench,. Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; Thissolves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:5447,Load,Load,5447,proof/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html,1,['Load'],['Load']
Performance,"of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:37259,perform,performance,37259,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['perform'],['performance']
Performance,"of variables mapped in target regions. These have the; same format as the source location in the :ref:`identifier structure; <table-ident_t_structure>`, but the function name is replaced with the variable; name. .. _Device Compilation:. Offload Device Compilation; --------------------------. The input file is compiled for each active device toolchain. The device; compilation stage is performed differently from the host stage. Namely, we do; not generate any offloading entries. This is set by passing the; ``-fopenmp-is-target-device`` flag to the front-end. We use the host bitcode to; determine which symbols to export from the device. The bitcode file is passed in; from the previous stage using the ``-fopenmp-host-ir-file-path`` flag.; Compilation is otherwise performed as it would be for any other target triple. When compiling for the OpenMP device, we set the visibility of all device; symbols to be ``protected`` by default. This improves performance and prevents a; class of errors where a symbol in the target device could preempt a host; library. The OpenMP runtime library is linked in during compilation to provide the; implementations for standard OpenMP functionality. For GPU targets this is done; by linking in a special bitcode library during compilation, (e.g.; ``libomptarget-nvptx64-sm_70.bc``) using the ``-mlink-builtin-bitcode`` flag.; Other device libraries, such as CUDA's libdevice, are also linked this way. If; the target is a standard architecture with an existing ``libomp``; implementation, that will be linked instead. Finally, device tools are used to; create a relocatable device object file that can be embedded in the host. .. _Creating Fat Objects:. Creating Fat Objects; --------------------. A fat binary is a binary file that contains information intended for another; device. We create a fat object by embedding the output of the device compilation; stage into the host as a named section. The output from the device compilation; is passed to the host b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OffloadingDesign.rst:10840,perform,performance,10840,interpreter/llvm-project/clang/docs/OffloadingDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OffloadingDesign.rst,1,['perform'],['performance']
Performance,"of volume `B` does. After finding out the node containing; the particle, one can check if the geometry state is different compared; to the last located point:. ~~~{.cpp}; Bool_t *TGeoManager::IsSameLocation(); ~~~. The algorithm for finding where a point is located in geometry is; presented in the figure 17-36. It always starts by checking if the last computed modeller state is the; answer. This optimizes the search when continuously tracking a particle.; The main actions performed are:. - moving up and down in the logical node tree while updating the; current node and its global matrix; - converting the global position into the local frame of the current; node/volume; - checking whether the local position lies within the geometrical; shape of the current volume - if this is the case continue the; search downwards for the daughters of the current node, otherwise; search upwards its containers until the top level is reached.; - the number of candidate nodes to be checked at a given level is; minimized by an additional optimization structure: voxels. This is; effective even in case there is only one daughter of the current; volume.; - in case the current node is declared as possibly overlapping, the; method FindInCluster() is invoked. This method checks all different; possibilities within the cluster of overlapping candidates. One of; the candidates is prioritized if one of the following conditions id; fulfilled (in order):; - Is declared as non-overlapping (these are anyway searched first); - Has at least one daughter that contains the current point; - Was already declared as containing the point at a previous step. \image html geometry016.png ""Finding the location of a point in the geometry hierarchy"" width=600px. \anchor GP07b; ### Finding the Distance to Next Crossed Boundary. The most important feature provided by the modeller related to track; propagation is the computation of the distance to the next boundary; along a straight line. The relevant state parameters",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:118302,optimiz,optimization,118302,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['optimiz'],['optimization']
Performance,"of which is this:. _test1:; movl 4(%esp), %eax; cmpl $-1, %eax; leal 7(%eax), %ecx; cmovle %ecx, %eax; sarl $3, %eax; ret. which is probably slower, but it's interesting at least :). //===---------------------------------------------------------------------===//. We are currently lowering large (1MB+) memmove/memcpy to rep/stosl and rep/movsl; We should leave these as libcalls for everything over a much lower threshold,; since libc is hand tuned for medium and large mem ops (avoiding RFO for large; stores, TLB preheating, etc). //===---------------------------------------------------------------------===//. Optimize this into something reasonable:; x * copysign(1.0, y) * copysign(1.0, z). //===---------------------------------------------------------------------===//. Optimize copysign(x, *y) to use an integer load from y. //===---------------------------------------------------------------------===//. The following tests perform worse with LSR:. lambda, siod, optimizer-eval, ackermann, hash2, nestedloop, strcat, and Treesor. //===---------------------------------------------------------------------===//. Adding to the list of cmp / test poor codegen issues:. int test(__m128 *A, __m128 *B) {; if (_mm_comige_ss(*A, *B)); return 3;; else; return 4;; }. _test:; 	movl 8(%esp), %eax; 	movaps (%eax), %xmm0; 	movl 4(%esp), %eax; 	movaps (%eax), %xmm1; 	comiss %xmm0, %xmm1; 	setae %al; 	movzbl %al, %ecx; 	movl $3, %eax; 	movl $4, %edx; 	cmpl $0, %ecx; 	cmove %edx, %eax; 	ret. Note the setae, movzbl, cmpl, cmove can be replaced with a single cmovae. There; are a number of issues. 1) We are introducing a setcc between the result of the; intrisic call and select. 2) The intrinsic is expected to produce a i32 value; so a any extend (which becomes a zero extend) is added. We probably need some kind of target DAG combine hook to fix this. //===---------------------------------------------------------------------===//. We generate significantly worse code for this than GCC:; http:/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:5499,optimiz,optimizer-eval,5499,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,['optimiz'],['optimizer-eval']
Performance,"offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per pipeline.; 0x1000000D PerShaderPerfData 32-bit pointer to GPU memory containing the per-shader performance data buffer.; 0x1000000F VertexBufferTable 32-bit pointer to GPU memory containing the vertex buffer SRD table. This can; only appear for one shader stage per pipeline.; 0x10000010 UavExportTable 32-bit pointer to GPU memory containing the UAV export SRD table. This can; only appear for one shader stage per pipeline (PS). These replace color targets; and are completely separate from any UAVs used by the shader. This is optional,; and only used by the PS when UAV exports are used to replace color-target; exports to optimize specific shaders.; 0x10000011 NggCullingData 64-bit pointer to GPU memory containing the hardware register data needed by; some NGG pipelines to perform culling. This value contains the address of the; first of two consecutive registers which provide the full GPU address.; 0x10000015 FetchShaderPtr 64-bit pointer to GPU memory containing the fetch shader subroutine.; ========== ================= =============================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:417348,perform,performance,417348,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performance']
Performance,"ogram; (main.cpp), which allows looping, conditional execution, and all the; other possibilities of , but not interactivity, since it must be; compiled before execution. ## Design aspects of M in ##. What M is:. - platform independent. - written in an object-oriented way using standard. - independent of any external package. The maintainability should be guaranteed with the choice of a modern; computer language. Choosing object-oriented technology M should profit; from an increased flexibility and functionality and make it also; extendable (recursiveness, new algorithms, new functionality). What M does not:. - histogramming. - data handling. - graphics. M is kept as a low-level package with optimal performance. The main usages of M are. - from a user's program (such as int main()...). - from a graphical data analysis tool such as HippoDraw@bib-HippoDraw. The most important goals of M in are. - its numerical accuracy (equivalent to its Fortran version). - its computational performance (equivalent to its Fortran version). For the design of the application programming interface (API) of M a; two-way strategy was imposed:. - a minimal required interface with minimum interaction with M objects; and with appropriate usage of the standard library (STL): the user's; implementation of the FCNBase class, initial parameter values and; uncertainties are provided by the to M user via std::vectors. - a rich interface which provides the user with more functionality; such as interaction with parameters. The core of the minimization functionality and related tools (the kernel; of M ) should be clearly separated from the user, who is interfacing via; defined user interfaces (the API). ## Internal and external parameters ##. Each of the parameters to the $\mbox{FCN}$ is defined by the user as; belonging to one of the following types:. - Freely variable: allowed to take on any value. - Variable with double sided limits: allowed to vary only between two; limits specified by the user. - V",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:4280,perform,performance,4280,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['perform'],['performance']
Performance,"oherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:239228,cache,cache,239228,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance,"oherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX940, GFX941, GFX942; are defined in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx940-gfx941-gfx942-table`. .. table:: AMDHSA Memory Model Code Sequences GFX940, GFX941, GFX942; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx940-gfx941-gfx942-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX940, GFX941, GFX942; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; nt=1. - volatile. 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. GFX940, GFX941; - constant buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. - !volatile & nontemporal. 1. GFX940, GFX941; buffer/global/flat_store; nt=1 sc0=1 sc1=1; GFX942; buffer/global/flat_store; nt=1. - volatile. 1. buffer/global/flat_store; sc0=1 sc1=1; 2. s_wait",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:292600,load,load,292600,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance,"oid pointer type, can be used for round-trip casts. Represented as; the union of all pointers which can be cast to void.; Defined in ``""VoidPointer.h""``. * ``PT_ObjCBlockPtr``. Pointer type for ObjC blocks. Defined in ``""ObjCBlockPointer.h""``. Composite types; ---------------. The interpreter distinguishes two kinds of composite types: arrays and; records (structs and classes). Unions are represented as records, except; at most a single field can be marked as active. The contents of inactive; fields are kept until they are reactivated and overwritten.; Complex numbers (``_Complex``) and vectors; (``__attribute((vector_size(16)))``) are treated as arrays. Bytecode Execution; ==================. Bytecode is executed using a stack-based interpreter. The execution; context consists of an ``InterpStack``, along with a chain of; ``InterpFrame`` objects storing the call frames. Frames are built by; call instructions and destroyed by return instructions. They perform; one allocation to reserve space for all locals in a single block.; These objects store all the required information to emit stack traces; whenever evaluation fails. Memory Organisation; ===================. Memory management in the interpreter relies on 3 data structures: ``Block``; objects which store the data and associated inline metadata, ``Pointer``; objects which refer to or into blocks, and ``Descriptor`` structures which; describe blocks and subobjects nested inside blocks. Blocks; ------. Blocks contain data interleaved with metadata. They are allocated either; statically in the code generator (globals, static members, dummy parameter; values etc.) or dynamically in the interpreter, when creating the frame; containing the local variables of a function. Blocks are associated with a; descriptor that characterises the entire allocation, along with a few; additional attributes:. * ``IsStatic`` indicates whether the block has static duration in the; interpreter, i.e. it is not a local in a frame. * ``DeclI",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst:3778,perform,perform,3778,interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,1,['perform'],['perform']
Performance,"oint and direction coordinates to the local frame of this; object and computes the distance to its shape. The node returned is the; one pointed by the input path in case the shape is crossed; otherwise; the returned value is NULL. In case the distance to next crossed; boundary is required, the current point has to be physically INSIDE the; shape pointed by the current volume. This is only insured in case a call; to `TGeoManager::FindNode()` was performed for the current point.; Therefore, the first step is to convert the global current point and; direction in the local reference frame of the current volume and to; compute the distance to exit its shape from inside. The returned value; is again compared to the maximum allowed step (the proposed one) and in; case the distance is safe no other action is performed and the proposed; step is approved. In case the boundary is closer, the computed distance; is taken as maximum allowed step. For optimization purposed, for; particles starting very close to the current volume boundary (less than; 0.01 microns) and exiting the algorithm stops here. After computing the distance to exit the current node, the distance to; the daughter of the current volume which is crossed next is computed by; **`TGeoManager`**`::FindNextDaughterBoundary().` This computes the; distance to all daughter candidates that can be possibly crossed by; using volume voxelization. The algorithm is efficient in average only in; case the number of daughters is greater than 4. For fewer nodes, a; simple loop is performed and the minimum distance (from a point outside; each shape) is taken and compared to the maximum allowed step. The step; value is again updated if `step<stepmax` . A special case is when the current node is declared as possibly; overlapping with something else. If this is the case, the distance is; computed for all possibly overlapping candidates, taking into account; the overlapping priorities (see also: "" Overlapping volumes ""). The global m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:162940,optimiz,optimization,162940,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['optimiz'],['optimization']
Performance,"oint in trying to guarantee correctness in the; presence of race conditions. ARC does not have a stack-scanning; garbage collector, and guaranteeing the atomicity of every load and; store operation would be prohibitive and preclude a vast amount of; optimization. ARC may assume that non-ARC code engages in sensible balancing; behavior and does not rely on exact or minimum retain count values; except as guaranteed by ``__strong`` object invariants or +1 transfer; conventions. For example, if an object is provably double-retained; and double-released, ARC may eliminate the inner retain and release;; it does not need to guard against code which performs an unbalanced; release followed by a ""balancing"" retain. .. _arc.optimization.liveness:. Object liveness; ---------------. ARC may not allow a retainable object ``X`` to be deallocated at a; time ``T`` in a computation history if:. * ``X`` is the value stored in a ``__strong`` object ``S`` with; :ref:`precise lifetime semantics <arc.optimization.precise>`, or. * ``X`` is the value stored in a ``__strong`` object ``S`` with; imprecise lifetime semantics and, at some point after ``T`` but; before the next store to ``S``, the computation history features a; load from ``S`` and in some way depends on the value loaded, or. * ``X`` is a value described as being released at the end of the; current full-expression and, at some point after ``T`` but before; the end of the full-expression, the computation history depends; on that value. .. admonition:: Rationale. The intent of the second rule is to say that objects held in normal; ``__strong`` local variables may be released as soon as the value in; the variable is no longer being used: either the variable stops; being used completely or a new value is stored in the variable. The intent of the third rule is to say that return values may be; released after they've been used. A computation history depends on a pointer value ``P`` if it:. * performs a pointer comparison with ``P``,; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:78911,optimiz,optimization,78911,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimization']
Performance,"ointer type, the first index steps through that pointer. A; value of 0 means 0 elements offset from that pointer. #. The second index, ``i32 1`` selects the second field of the structure (the; ``i32``). What is dereferenced by GEP?; ----------------------------. Quick answer: nothing. The GetElementPtr instruction dereferences nothing. That is, it doesn't access; memory in any way. That's what the Load and Store instructions are for. GEP is; only involved in the computation of addresses. For example, consider this:. .. code-block:: text. @MyVar = external global { i32, ptr }; ...; %idx = getelementptr { i32, ptr }, ptr @MyVar, i64 0, i32 1; %arr = load ptr, ptr %idx; %idx = getelementptr [40 x i32], ptr %arr, i64 0, i64 17. In this example, we have a global variable, ``@MyVar``, which is a pointer to; a structure containing a pointer. Let's assume that this inner pointer points; to an array of type ``[40 x i32]``. The above IR will first compute the address; of the inner pointer, then load the pointer, and then compute the address of; the 18th array element. This cannot be expressed in a single GEP instruction, because it requires; a memory dereference in between. However, the following example would work; fine:. .. code-block:: text. @MyVar = external global { i32, [40 x i32 ] }; ...; %idx = getelementptr { i32, [40 x i32] }, ptr @MyVar, i64 0, i32 1, i64 17. In this case, the structure does not contain a pointer and the GEP instruction; can index through the global variable, into the second field of the structure; and access the 18th ``i32`` in the array there. Why don't GEP x,0,0,1 and GEP x,1 alias?; ----------------------------------------. Quick Answer: They compute different address locations. If you look at the first indices in these GEP instructions you find that they; are different (0 and 1), therefore the address computation diverges with that; index. Consider this example:. .. code-block:: llvm. @MyVar = external global { [10 x i32] }; %idx1 = getelementp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:7047,load,load,7047,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['load'],['load']
Performance,"ointeraliasing>`_. * Provide a consistent method for computing addresses so that address; computations don't need to be a part of load and store instructions in the IR. * Support non-C-like languages, to the extent that it doesn't interfere with; other goals. * Minimize target-specific information in the IR. Why do struct member indices always use ``i32``?; ------------------------------------------------. The specific type i32 is probably just a historical artifact, however it's wide; enough for all practical purposes, so there's been no need to change it. It; doesn't necessarily imply i32 address arithmetic; it's just an identifier which; identifies a field in a struct. Requiring that all struct indices be the same; reduces the range of possibilities for cases where two GEPs are effectively the; same but have distinct operand types. What's an uglygep?; ------------------. Some LLVM optimizers operate on GEPs by internally lowering them into more; primitive integer expressions, which allows them to be combined with other; integer expressions and/or split into multiple separate integer expressions. If; they've made non-trivial changes, translating back into LLVM IR can involve; reverse-engineering the structure of the addressing in order to fit it into the; static type of the original first operand. It isn't always possibly to fully; reconstruct this structure; sometimes the underlying addressing doesn't; correspond with the static type at all. In such cases the optimizer instead will; emit a GEP with the base pointer casted to a simple address-unit pointer, using; the name ""uglygep"". This isn't pretty, but it's just as valid, and it's; sufficient to preserve the pointer aliasing guarantees that GEP provides. Summary; =======. In summary, here's some things to always remember about the GetElementPtr; instruction:. #. The GEP instruction never accesses memory, it only provides pointer; computations. #. The second operand to the GEP instruction is always a pointer and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:20477,optimiz,optimizers,20477,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['optimiz'],['optimizers']
Performance,"ol Resolution; ---------------------------. In this stage, the linker resolves symbols using global symbol table. It may; report undefined symbol errors, read archive members, replace weak symbols, etc.; The linker is able to do this seamlessly even though it does not know the exact; content of input LLVM bitcode files. If dead code stripping is enabled then the; linker collects the list of live symbols. Phase 3 : Optimize Bitcode Files; --------------------------------. After symbol resolution, the linker tells the LTO shared object which symbols; are needed by native object files. In the example above, the linker reports; that only ``foo1()`` is used by native object files using; ``lto_codegen_add_must_preserve_symbol()``. Next the linker invokes the LLVM; optimizer and code generators using ``lto_codegen_compile()`` which returns a; native object file creating by merging the LLVM bitcode files and applying; various optimization passes. Phase 4 : Symbol Resolution after optimization; ----------------------------------------------. In this phase, the linker reads optimized a native object file and updates the; internal global symbol table to reflect any changes. The linker also collects; information about any changes in use of external symbols by LLVM bitcode; files. In the example above, the linker notes that ``foo4()`` is not used any; more. If dead code stripping is enabled then the linker refreshes the live; symbol information appropriately and performs dead code stripping. After this phase, the linker continues linking as if it never saw LLVM bitcode; files. .. _libLTO:. ``libLTO``; ==========. ``libLTO`` is a shared object that is part of the LLVM tools, and is intended; for use by a linker. ``libLTO`` provides an abstract C interface to use the LLVM; interprocedural optimizer without exposing details of LLVM's internals. The; intention is to keep the interface as stable as possible even when the LLVM; optimizer continues to evolve. It should even be possible",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:7390,optimiz,optimization,7390,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['optimiz'],['optimization']
Performance,"ol2""; .globl Symbol2; Symbol2:; .long 1. In addition to the types allowed with ``.linkonce``, ``.section`` also accepts; ``associative``. The meaning is that the section is linked if a certain other; COMDAT section is linked. This other section is indicated by the comdat symbol; in this directive. It can be any symbol defined in the associated section, but; is usually the associated section's comdat. The following restrictions apply to the associated section:. 1. It must be a COMDAT section.; 2. It cannot be another associative COMDAT section. In the following example the symbol ``sym`` is the comdat symbol of ``.foo``; and ``.bar`` is associated to ``.foo``. .. code-block:: gas. 	.section	.foo,""bw"",discard, ""sym""; 	.section	.bar,""rd"",associative, ""sym"". MC supports these flags in the COFF ``.section`` directive:. - ``b``: BSS section (``IMAGE_SCN_CNT_INITIALIZED_DATA``); - ``d``: Data section (``IMAGE_SCN_CNT_UNINITIALIZED_DATA``); - ``n``: Section is not loaded (``IMAGE_SCN_LNK_REMOVE``); - ``r``: Read-only; - ``s``: Shared section; - ``w``: Writable; - ``x``: Executable section; - ``y``: Not readable; - ``D``: Discardable (``IMAGE_SCN_MEM_DISCARDABLE``). These flags are all compatible with gas, with the exception of the ``D`` flag,; which gnu as does not support. For gas compatibility, sections with a name; starting with "".debug"" are implicitly discardable. ARM64/COFF-Dependent; --------------------. Relocations; ^^^^^^^^^^^. The following additional symbol variants are supported:. **:secrel_lo12:** generates a relocation that corresponds to the COFF relocation; types ``IMAGE_REL_ARM64_SECREL_LOW12A`` or ``IMAGE_REL_ARM64_SECREL_LOW12L``. **:secrel_hi12:** generates a relocation that corresponds to the COFF relocation; type ``IMAGE_REL_ARM64_SECREL_HIGH12A``. .. code-block:: gas. add x0, x0, :secrel_hi12:symbol; ldr x0, [x0, :secrel_lo12:symbol]. add x1, x1, :secrel_hi12:symbol; add x1, x1, :secrel_lo12:symbol; ... ELF-Dependent; -------------. ``.section`` Direc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst:4025,load,loaded,4025,interpreter/llvm-project/llvm/docs/Extensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Extensions.rst,1,['load'],['loaded']
Performance,"ol; ================================. .. program:: llvm-otool. SYNOPSIS; --------. :program:`llvm-otool` [*option...*] *[file...]*. DESCRIPTION; -----------. :program:`llvm-otool` is a tool for dumping Mach-O files. It attempts to be command-line-compatible and output-compatible with macOS's; :program:`otool`. OPTIONS; -------. .. option:: -arch <value>. Select slice of universal Mach-O file. .. option:: -chained_fixups. Print chained fixup information. .. option:: -C. Print linker optimization hints. .. option:: -dyld_info. Print bind and rebase information. .. option:: -D. Print shared library id. .. option:: -d. Print data section. .. option:: -f. Print universal headers. .. option:: -G. Print data-in-code table. .. option:: --help-hidden. Print help for hidden flags. .. option:: --help. Print help. .. option:: -h. Print mach header. .. option:: -I. Print indirect symbol table. .. option:: -j. Print opcode bytes. .. option:: -L. Print used shared libraries. .. option:: -l. Print load commands. .. option:: -mcpu=<value>. Select cpu for disassembly. .. option:: -o. Print Objective-C segment. .. option:: -P. Print __TEXT,__info_plist section as strings. .. option:: -p <function name>. Start disassembly at <function name>. .. option:: -r. Print relocation entries. .. option:: -s <segname> <sectname>. Print contents of section. .. option:: -t. Print text section. .. option:: --version. Print version. .. option:: -V. Symbolize disassembled operands (implies :option:`-v`). .. option:: -v. Verbose output / disassemble when printing text sections. .. option:: -X. Omit leading addresses or headers. .. option:: -x. Print all text sections. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. EXIT STATUS; -----------. :program:`llvm-otool` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-objdump/>. SEE ALSO",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst:1027,load,load,1027,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst,1,['load'],['load']
Performance,"olicy. Code review is one way to increase the quality of; software. Please see :doc:`CodeReview` for more information on LLVM's code-review; process. .. _breaking:. Making Potentially Breaking Changes; -----------------------------------. Please help notify users and vendors of potential disruptions when upgrading to; a newer version of a tool. For example, deprecating a feature that is expected; to be removed in the future, removing an already-deprecated feature, upgrading a; diagnostic from a warning to an error, switching important default behavior, or; any other potentially disruptive situation thought to be worth raising; awareness of. For such changes, the following should be done:. .. warning::. Phabricator is deprecated and will be switched to read-only mode in October; 2023, for new code contributions use :ref:`GitHub Pull Requests <github-reviews>`.; This section contains old information that needs to be updated. * When performing the code review for the change, please add any applicable; ""vendors"" group to the review for their awareness. The purpose of these; groups is to give vendors early notice that potentially disruptive changes; are being considered but have not yet been accepted. Vendors can give early; testing feedback on the changes to alert us to unacceptable breakages. The; current list of vendor groups is:. * `Clang vendors <https://reviews.llvm.org/project/members/113/>`_; * `libc++ vendors <https://reviews.llvm.org/project/members/109/>`_. People interested in joining the vendors group can do so by clicking the; ""Join Project"" link on the vendor's ""Members"" page in Phabricator. * When committing the change to the repository, add appropriate information; about the potentially breaking changes to the ``Potentially Breaking Changes``; section of the project's release notes. The release note should have; information about what the change is, what is potentially disruptive about; it, as well as any code examples, links, and motivation that is appr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:5731,perform,performing,5731,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['perform'],['performing']
Performance,"ollowing global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. load atomic acquire - agent - generic 1. flat_load sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:297342,load,loads,297342,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance,"ologue/epilogue inserter to force the position of; the ``AllocaInst`` stack slot to be before local variables on the stack. This is; to ensure that if a local variable on the stack is overwritten, it will destroy; the value of the guard. When the function exits, the guard on the stack is; checked against the original guard by ``llvm.stackprotectorcheck``. If they are; different, then ``llvm.stackprotectorcheck`` causes the program to abort by; calling the ``__stack_chk_fail()`` function. '``llvm.stackguard``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.stackguard(). Overview:; """""""""""""""""". The ``llvm.stackguard`` intrinsic returns the system stack guard value. It should not be generated by frontends, since it is only for internal usage.; The reason why we create this intrinsic is that we still support IR form Stack; Protector in FastISel. Arguments:; """""""""""""""""""". None. Semantics:; """""""""""""""""""". On some platforms, the value returned by this intrinsic remains unchanged; between loads in the same thread. On other platforms, it returns the same; global variable value, if any, e.g. ``@__stack_chk_guard``. Currently some platforms have IR-level customized stack guard loading (e.g.; X86 Linux) that is not handled by ``llvm.stackguard()``, while they should be; in the future. '``llvm.objectsize``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i32 @llvm.objectsize.i32(ptr <object>, i1 <min>, i1 <nullunknown>, i1 <dynamic>); declare i64 @llvm.objectsize.i64(ptr <object>, i1 <min>, i1 <nullunknown>, i1 <dynamic>). Overview:; """""""""""""""""". The ``llvm.objectsize`` intrinsic is designed to provide information to the; optimizer to determine whether a) an operation (like memcpy) will overflow a; buffer that corresponds to an object, or b) that a runtime check for overflow; isn't necessary. An object in this context means an allocation of a specific; class, structure, array, or other object. Arguments:; """""""""""""""""""". The `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:931288,load,loads,931288,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loads']
Performance,"ols that allow the user control over where clang-cl will; locate these headers. The default behaviour for the Windows SDK and UCRT is as; follows:. 1. Consult the command line. Anything the user specifies is always given precedence. The following; extensions are part of the clang-cl toolset:. - `/winsysroot:`. The `/winsysroot:` is used as an equivalent to `-sysroot` on Unix; environments. It allows the control of an alternate location to be treated; as a system root. When specified, it will be used as the root where the; `Windows Kits` is located. - `/winsdkversion:`; - `/winsdkdir:`. If `/winsysroot:` is not specified, the `/winsdkdir:` argument is consulted; as a location to identify where the Windows SDK is located. Contrary to; `/winsysroot:`, `/winsdkdir:` is expected to be the complete path rather; than a root to locate `Windows Kits`. The `/winsdkversion:` flag allows the user to specify a version identifier; for the SDK to prefer. When this is specified, no additional validation is; performed and this version is preferred. If the version is not specified,; the highest detected version number will be used. 2. Consult the environment. TODO: This is not yet implemented. This will consult the environment variables:. - `WindowsSdkDir`; - `UCRTVersion`. 3. Fallback to the registry. If no arguments are used to indicate where the SDK is present, and the; compiler is running on Windows, the registry is consulted to locate the; installation. The Visual C++ Toolset has a slightly more elaborate mechanism for detection. 1. Consult the command line. - `/winsysroot:`. The `/winsysroot:` is used as an equivalent to `-sysroot` on Unix; environments. It allows the control of an alternate location to be treated; as a system root. When specified, it will be used as the root where the; `VC` directory is located. - `/vctoolsdir:`; - `/vctoolsversion:`. If `/winsysroot:` is not specified, the `/vctoolsdir:` argument is consulted; as a location to identify where the Visual C++ To",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:194819,perform,performed,194819,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['perform'],['performed']
Performance,ols-extra/clang-tidy/objc/DeallocInCategoryCheck.h; clang-tools-extra/clang-tidy/objc/ForbiddenSubclassingCheck.h; clang-tools-extra/clang-tidy/objc/MissingHashCheck.cpp; clang-tools-extra/clang-tidy/objc/MissingHashCheck.h; clang-tools-extra/clang-tidy/objc/NSInvocationArgumentLifetimeCheck.cpp; clang-tools-extra/clang-tidy/objc/NSInvocationArgumentLifetimeCheck.h; clang-tools-extra/clang-tidy/objc/PropertyDeclarationCheck.h; clang-tools-extra/clang-tidy/objc/SuperSelfCheck.cpp; clang-tools-extra/clang-tidy/objc/SuperSelfCheck.h; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.cpp; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.h; clang-tools-extra/clang-tidy/openmp/OpenMPTidyModule.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.h; clang-tools-extra/clang-tidy/performance/FasterStringFindCheck.cpp; clang-tools-extra/clang-tidy/performance/ForRangeCopyCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.h; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.h; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.cpp; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.h; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.cpp; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.h; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.cpp; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.h; clang-tools-extra/clang-tidy/performance/PerformanceTidyMod,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:64837,perform,performance,64837,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['perform'],['performance']
Performance,"olution mechanisms, bloom filters -- standard ROOT relies; on information in ROOTMAP files to react when the llvm JIT issues an; unresolved symbol callback. C++ Modules-aware ROOT relies on a behavior much; closer to the standard linker behavior. In particular, we start searching on; the LD_LIBRARY_PATH descending to the system libraries. The algorithm is very; efficient because it uses bloom filters[[5]]. This in turn allows ROOT symbol; to be extended to system libraries. ### Module Registration Approaches. The C++ modules system supports /*preloading*/ of all modules at startup time.; The current implementation of loading of C++ modules in clang has an overhead; and is between 40-60 MB depending on the ROOT configuration while there might; be 2x slowdown depending on the workflow. These issues are very likely to be; addressed by the LLVM community in midterm. Preloading of all C++ modules is semantically the closest to C++ behavior.; However, in order to achieve performance ROOT loads them on demand using; a global module index file. It has sufficient information to map a looked up; identifier to the module which contains the corresponding definition. Switching; back to preloading of all C++ modules is done by setting the `ROOT_USE_GMI`; environment variable to false.; ; ### Supported Platforms. We support all platforms with glibc++ versions: 5.2 onward. We support OSX from XCode 10 onward. ## Changes required by the users; * Self-contained header files -- every header file should be able to compile; on its own. For instance, `cat header.h header.h | gcc -fsyntax-only -xc++ -`.; This command concatenates `header.h` twice before compiling it to make sure; it has proper include protectors.; * Enable it in `rootcling` -- rootcling can produce a C++ Modules-aware; dictionary when it is invoked with `-cxxmodule` flag.; * Modularization of external dependencies -- if a header file is not explicitly; nominated as part of a module and it is transitively included in two mo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:14200,perform,performance,14200,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,2,"['load', 'perform']","['loads', 'performance']"
Performance,"om positive bins.; ; In THistPainter::PaintH3 the palette is drawn in case of option; COLZ. This is useful when a TTree 4D plot is painted with that option.; ; This image has been prodiced with the command:; ntuple->Draw(""px:py:pz:px*px"","""",""COLZ"");. TGraph2D. The operator ""="" was not correct. TGraph. Protection added in PaintPolyLineHatches (division by zero in some; cases).; All the graphical code has been moved from the TGraph classes to; TGraphPainter. TGraphPolar. Protection added in case a GraphPolar is plotted with option; ""E"" but has no errors defined.; The markers clipping (in TGraphPainter) was wrong in case of TGraphPolar.; The constructor's parameters naming was wrong.; Documentation: better example (easier to understand).; In the constructors some data members were not initialized. TPie. Add the TPie::GetEntries() method that return the number slices.; (Guido Volpi).; Implement Editors for TPie and TPieSlice (Guido Volpi). TPaletteAxis. Attributes are now accessible in the context menu.; (requested by Mathieu de Naurois <denauroi@in2p3.fr>). TPolyLine. Implement the possibility to draw TPolyLine in NDC coordinates; (it was partially done but the code was not used). Documentation. Better comments in THelix.; Option ""FUNC"" was not documented in THistPainter..; Update the help for animated gif generation in TPad.; Update TAttMarker documentation about the non scalable markers.; Re-writting of the THistPainter documentation. TCutG. The graphical cuts applied on histograms did not work when the cut name; contained a mix of lower and upper case characters. This problem occured; because the option used to draw an histogram was always converted into; lower case before begin stored in a pad (in Draw and DrawCopy). Now in; Draw() and DrawCopy() the AppendPad() procedure is called with the option; string not converted in lower; case. QT; Version 3 of QT is not supported anymore. If you install ROOT with the QT option; you must have QT version 4 already installed. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v520/index.html:5785,scalab,scalable,5785,graf2d/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/graf2d/doc/v520/index.html,2,['scalab'],['scalable']
Performance,"om the module into their; own functions. ``instnamer``: Assign names to anonymous instructions; -----------------------------------------------------. This is a little utility pass that gives instructions names, this is mostly; useful when diffing the effect of an optimization because deleting an unnamed; instruction can change all other instruction numbering, making the diff very; noisy. .. _passes-verify:. ``verify``: Module Verifier; ---------------------------. Verifies an LLVM IR code. This is useful to run after an optimization which is; undergoing testing. Note that llvm-as verifies its input before emitting; bitcode, and also that malformed bitcode is likely to make LLVM crash. All; language front-ends are therefore encouraged to verify their output before; performing optimizing transformations. #. Both of a binary operator's parameters are of the same type.; #. Verify that the indices of mem access instructions match other operands.; #. Verify that arithmetic and other things are only performed on first-class; types. Verify that shifts and logicals only happen on integrals f.e.; #. All of the constants in a switch statement are of the correct type.; #. The code is in valid SSA form.; #. It is illegal to put a label into any other type (like a structure) or to; return one.; #. Only phi nodes can be self referential: ``%x = add i32 %x``, ``%x`` is; invalid.; #. PHI nodes must have an entry for each predecessor, with no extras.; #. PHI nodes must be the first thing in a basic block, all grouped together.; #. PHI nodes must have at least one entry.; #. All basic blocks should only end with terminator insts, not contain them.; #. The entry node to a function must not have predecessors.; #. All Instructions must be embedded into a basic block.; #. Functions cannot take a void-typed parameter.; #. Verify that a function's argument list agrees with its declared type.; #. It is illegal to specify a name for a void value.; #. It is illegal to have an internal global ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:41507,perform,performed,41507,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['perform'],['performed']
Performance,"om; operator delete[].; See tests cases in handle_constructors_with_new_array.cpp.; . Constructing an array requires invoking multiple (potentially unknown); amount of constructors with the same construct-expression.; Apart from the technical difficulties of juggling program points around; correctly to avoid accidentally merging paths together, we'll have to; be a judge on when to exit the loop and how to widen it.; Given that the constructor is going to be a default constructor,; a nice 95% solution might be to execute exactly one constructor and; then default-bind the resulting LazyCompoundVal to the whole array;; it'll work whenever the default constructor doesn't touch global state; but only initializes the object to various default values.; But if, say, we're making an array of strings,; depending on the implementation you might have to allocate a new buffer; for each string, and in this case default-binding won't cut it.; We might want to come up with an auxiliary analysis in order to perform; widening of these simple loops more precisely.; . Handle constructors that can be elided due to Named Return Value Optimization (NRVO); Local variables which are returned by values on all return statements; may be stored directly at the address for the return value,; eliding the copy or move constructor call.; Such variables can be identified using the AST call VarDecl::isNRVOVariable.; . Handle constructors of lambda captures; Variables which are captured by value into a lambda require a call to; a copy constructor.; This call is not currently modeled.; . Handle constructors for default arguments; Default arguments in C++ are recomputed at every call,; and are therefore local, and not static, variables.; See tests cases in handle_constructors_for_default_arguments.cpp.; . Default arguments are annoying because the initializer expression is; evaluated at the call site but doesn't syntactically belong to the; caller's AST; instead it belongs to the ParmVarDecl for the defa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html:3851,perform,perform,3851,interpreter/llvm-project/clang/www/analyzer/open_projects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html,2,['perform'],['perform']
Performance,"om; outside, the whole thing looks like a big pack that you can open finding; out other smaller packs nicely arranged waiting to be opened at their; turn. The biggest one containing all others defines the ""world"" of the; model. We will often call this ""master reference system (MARS)"". Going; on and opening our packs, we will obviously find out some empty ones,; otherwise, something is very wrong... We will call these leaves (by; analogy with a tree structure). On the other hand, any volume is a small world by itself - what we need; to do is to take it out and to ignore all the rest since it is a; self-contained object. In fact, the modeller can act like this,; considering a given volume as temporary MARS, but we will describe this; feature later on. Let us focus on the biggest pack - it is mandatory to; define one. Consider the simplest geometry that is made of a single box.; Here is an example on how to build it:. \anchor GP00a; ### Example 1: Creating the World. We first need to load the geometry library. This is not needed if one; does ""make map"" in root folder. ~~~{.cpp}; root[] gSystem->Load(""libGeom"");; ~~~. Second, we have to create an instance of the geometry manager class.; This takes care of all the modeller components, performing several tasks; to insure geometry validity and containing the user interface for; building and interacting with the geometry. After its creation, the; geometry manager class can be accessed with the global; `gGeoManager`:. ~~~{.cpp}; root[] new TGeoManager(""world"", ""the simplest geometry"");; ~~~. We want to create a single volume in our geometry, but since any volume; needs to have an associated medium, we will create a dummy one. You can; safely ignore the following lines for the time being, since materials; and media will be explained in detail later on. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""Vacuum"",0,0,0);; root[] TGeoMedium *med = new TGeoMedium(""Vacuum"",1,mat);; ~~~. We can finally make our volume having a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:4924,load,load,4924,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['load'],['load']
Performance,"omic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220569,load,load,220569,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"omic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx942`; * :ref:`amdgpu-amdhsa-memory-model-gfx10-gfx11`. .. _amdgpu-amdhsa-memory-model-gfx6-gfx9:. Memory Model GFX6-GFX9; ++++++++++++++++++++++. For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:206638,perform,performed,206638,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance,"omic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atom",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:258420,load,load,258420,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"omicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227853,perform,performing,227853,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"oming from: if control flow comes; from the cond\_false block, X.2 gets the value of X.1. Alternatively, if; control flow comes from cond\_true, it gets the value of X.0. The intent; of this chapter is not to explain the details of SSA form. For more; information, see one of the many `online; references <http://en.wikipedia.org/wiki/Static_single_assignment_form>`_. The question for this article is ""who places the phi nodes when lowering; assignments to mutable variables?"". The issue here is that LLVM; *requires* that its IR be in SSA form: there is no ""non-ssa"" mode for; it. However, SSA construction requires non-trivial algorithms and data; structures, so it is inconvenient and wasteful for every front-end to; have to reproduce this logic. Memory in LLVM; ==============. The 'trick' here is that while LLVM does require all register values to; be in SSA form, it does not require (or permit) memory objects to be in; SSA form. In the example above, note that the loads from G and H are; direct accesses to G and H: they are not renamed or versioned. This; differs from some other compiler systems, which do try to version memory; objects. In LLVM, instead of encoding dataflow analysis of memory into; the LLVM IR, it is handled with `Analysis; Passes <../../WritingAnLLVMPass.html>`_ which are computed on demand. With this in mind, the high-level idea is that we want to make a stack; variable (which lives in memory, because it is on the stack) for each; mutable object in a function. To take advantage of this trick, we need; to talk about how LLVM represents stack variables. In LLVM, all memory accesses are explicit with load/store instructions,; and it is carefully designed not to have (or need) an ""address-of""; operator. Notice how the type of the @G/@H global variables is actually; ""i32\*"" even though the variable is defined as ""i32"". What this means is; that @G defines *space* for an i32 in the global data area, but its; *name* actually refers to the address for that spa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:3709,load,loads,3709,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['loads']
Performance,"omit.; - If OpenCL, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If CU wavefront execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1 dlc=1. - If GFX11, omit dlc=1. 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_gl*_inv.; - Ensures the load; has completed; before invalidating; the caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1 dlc=1; - system; - If GFX11, omit dlc=1. 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_gl*_invl.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic; load",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:348070,load,load,348070,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"ommand; line.; * Use clang as usual, but prefix all arguments to the cc1 process with; `-Xclang`. For example, to run the ``print-function-names`` plugin over a source file in; clang, first build the plugin, and then call clang with the plugin from the; source tree:. .. code-block:: console. $ export BD=/path/to/build/directory; $ (cd $BD && make PrintFunctionNames ); $ clang++ -D_GNU_SOURCE -D_DEBUG -D__STDC_CONSTANT_MACROS \; -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS -D_GNU_SOURCE \; -I$BD/tools/clang/include -Itools/clang/include -I$BD/include -Iinclude \; tools/clang/tools/clang-check/ClangCheck.cpp -fsyntax-only \; -Xclang -load -Xclang $BD/lib/PrintFunctionNames.so -Xclang \; -plugin -Xclang print-fns. Also see the print-function-name plugin example's; `README <https://github.com/llvm/llvm-project/blob/main/clang/examples/PrintFunctionNames/README.txt>`_. Using the clang command line; ----------------------------. Using `-fplugin=plugin` on the clang command line passes the plugin; through as an argument to `-load` on the cc1 command line. If the plugin; class implements the ``getActionType`` method then the plugin is run; automatically. For example, to run the plugin automatically after the main AST; action (i.e. the same as using `-add-plugin`):. .. code-block:: c++. // Automatically run the plugin after the main AST action; PluginASTAction::ActionType getActionType() override {; return AddAfterMainAction;; }. Interaction with ``-clear-ast-before-backend``; ----------------------------------------------. To reduce peak memory usage of the compiler, plugins are recommended to run; *before* the main action, which is usually code generation. This is because; having any plugins that run after the codegen action automatically turns off; ``-clear-ast-before-backend``. ``-clear-ast-before-backend`` reduces peak; memory by clearing the Clang AST after generating IR and before running IR; optimizations. Use ``CmdlineBeforeMainAction`` or ``AddBeforeMainAction`` as",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst:6828,load,load,6828,interpreter/llvm-project/clang/docs/ClangPlugins.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst,1,['load'],['load']
Performance,"ompilation within LLVM IR. This; pass looks for calls to the ``@__nvvm_reflect`` function and replaces them; with constants based on the defined reflection parameters. Such conditional; code often follows a pattern:. .. code-block:: c++. float my_function(float a) {; if (__nvvm_reflect(""FASTMATH"")); return my_function_fast(a);; else; return my_function_precise(a);; }. The default value for all unspecified reflection parameters is zero. The ``NVVMReflect`` pass should be executed early in the optimization; pipeline, immediately after the link stage. The ``internalize`` pass is also; recommended to remove unused math functions from the resulting PTX. For an; input IR module ``module.bc``, the following compilation flow is recommended:. 1. Save list of external functions in ``module.bc``; 2. Link ``module.bc`` with ``libdevice.compute_XX.YY.bc``; 3. Internalize all functions not in list from (1); 4. Eliminate all unused internal functions; 5. Run ``NVVMReflect`` pass; 6. Run standard optimization pipeline. .. note::. ``linkonce`` and ``linkonce_odr`` linkage types are not suitable for the; libdevice functions. It is possible to link two IR modules that have been; linked against libdevice using different reflection variables. Since the ``NVVMReflect`` pass replaces conditionals with constants, it will; often leave behind dead code of the form:. .. code-block:: llvm. entry:; ..; br i1 true, label %foo, label %bar; foo:; ..; bar:; ; Dead code; .. Therefore, it is recommended that ``NVVMReflect`` is executed early in the; optimization pipeline before dead-code elimination. The NVPTX TargetMachine knows how to schedule ``NVVMReflect`` at the beginning; of your pass manager; just use the following code when setting up your pass; manager and the PassBuilder will use ``registerPassBuilderCallbacks`` to let; NVPTXTargetMachine::registerPassBuilderCallbacks add the pass to the; pass manager:. .. code-block:: c++. std::unique_ptr<TargetMachine> TM = ...;; PassBuilder PB(TM);; Mod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst:9293,optimiz,optimization,9293,interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,1,['optimiz'],['optimization']
Performance,"ompile and run, but has not been; updated**. Welcome to Chapter 1 of the ""Building an ORC-based JIT in LLVM"" tutorial. This; tutorial runs through the implementation of a JIT compiler using LLVM's; On-Request-Compilation (ORC) APIs. It begins with a simplified version of the; KaleidoscopeJIT class used in the; `Implementing a language with LLVM <LangImpl01.html>`_ tutorials and then; introduces new features like concurrent compilation, optimization, lazy; compilation and remote execution. The goal of this tutorial is to introduce you to LLVM's ORC JIT APIs, show how; these APIs interact with other parts of LLVM, and to teach you how to recombine; them to build a custom JIT that is suited to your use-case. The structure of the tutorial is:. - Chapter #1: Investigate the simple KaleidoscopeJIT class. This will; introduce some of the basic concepts of the ORC JIT APIs, including the; idea of an ORC *Layer*. - `Chapter #2 <BuildingAJIT2.html>`_: Extend the basic KaleidoscopeJIT by adding; a new layer that will optimize IR and generated code. - `Chapter #3 <BuildingAJIT3.html>`_: Further extend the JIT by adding a; Compile-On-Demand layer to lazily compile IR. - `Chapter #4 <BuildingAJIT4.html>`_: Improve the laziness of our JIT by; replacing the Compile-On-Demand layer with a custom layer that uses the ORC; Compile Callbacks API directly to defer IR-generation until functions are; called. - `Chapter #5 <BuildingAJIT5.html>`_: Add process isolation by JITing code into; a remote process with reduced privileges using the JIT Remote APIs. To provide input for our JIT we will use a lightly modified version of the; Kaleidoscope REPL from `Chapter 7 <LangImpl07.html>`_ of the ""Implementing a; language in LLVM tutorial"". Finally, a word on API generations: ORC is the 3rd generation of LLVM JIT API.; It was preceded by MCJIT, and before that by the (now deleted) legacy JIT.; These tutorials don't assume any experience with these earlier APIs, but; readers acquainted with them wi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst:1427,optimiz,optimize,1427,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT1.rst,1,['optimiz'],['optimize']
Performance,"ompiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:2321,load,load,2321,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,1,['load'],['load']
Performance,"ompiler needs to know which part of that line is taken more; frequently. This is what discriminators provide. In this case, the calls to; ``foo`` and ``bar`` will be at the same line, but will have; different discriminator values. This allows the compiler to correctly; set edge weights into ``foo`` and ``bar``. c. Number of samples. This is an integer quantity representing the; number of samples collected by the profiler at this source; location. d. [OPTIONAL] Potential call targets and samples. If present, this; line contains a call instruction. This models both direct and; number of samples. For example,. .. code-block:: console. 130: 7 foo:3 bar:2 baz:7. The above means that at relative line offset 130 there is a call; instruction that calls one of ``foo()``, ``bar()`` and ``baz()``,; with ``baz()`` being the relatively more frequently called target. As an example, consider a program with the call chain ``main -> foo -> bar``.; When built with optimizations enabled, the compiler may inline the; calls to ``bar`` and ``foo`` inside ``main``. The generated profile; could then be something like this:. .. code-block:: console. main:35504:0; 1: _Z3foov:35504; 2: _Z32bari:31977; 1.1: 31977; 2: 0. This profile indicates that there were a total of 35,504 samples; collected in main. All of those were at line 1 (the call to ``foo``).; Of those, 31,977 were spent inside the body of ``bar``. The last line; of the profile (``2: 0``) corresponds to line 2 inside ``main``. No; samples were collected there. .. _prof_instr:. Profiling with Instrumentation; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Clang also supports profiling via instrumentation. This requires building a; special instrumented version of the code and has some runtime; overhead during the profiling, but it provides more detailed results than a; sampling profiler. It also provides reproducible results, at least to the; extent that the code behaves consistently across runs. Clang supports two types of instrumentation: frontend-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:101525,optimiz,optimizations,101525,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,"ompiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:6543,perform,performed,6543,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['perform'],['performed']
Performance,"ompleted before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vm/vscnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:368908,perform,performing,368908,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance,"ompletely distinct: `WIRE_CO_1` and; `WIRE_CO_2`. We will want now to place symmetrically 1000 chambers on a; pad, following a pattern of 20 rows and 50 columns. One way to do this; will be to replicate our chamber by positioning it 1000 times in; different positions of the pad. Unfortunately, this is far from being; the optimal way of doing what we want. Imagine that we would like to; find out which of the 1000 chambers is containing a `(x,y,z)` point; defined in the pad reference. You will never have to do that, since the; modeller will take care of it for you, but let's guess what it has to; do. The most simple algorithm will just loop over all daughters, convert; the point from mother to local reference and check if the current; chamber contains the point or not. This might be efficient for pads with; few chambers, but definitely not for 1000. Fortunately the modeller is; smarter than that and creates for each volume some optimization; structures called `voxels` to minimize the penalty having too many; daughters, but if you have 100 pads like this in your geometry you will; anyway lose a lot in your tracking performance. The way out when; volumes can be arranged according to simple patterns is the usage of; divisions. We will describe them in detail later on. Let's think now at; a different situation: instead of 1000 chambers of the same type, we may; have several types of chambers. Let's say all chambers are cylindrical; and have a wire inside, but their dimensions are different. However, we; would like all to be represented by a single volume family, since they; have the same properties. #### Volume Families. A volume family is represented by the class **`TGeoVolumeMulti`**. It; represents a class of volumes having the same shape type and each member; will be identified by the same name and volume ID. Any operation applied; to a **`TGeoVolumeMulti`** equally affects all volumes in that family.; The creation of a family is generally not a user task, but can be f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:80414,optimiz,optimization,80414,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"ompletely distinct: `WIRE_CO_1` and; `WIRE_CO_2`. We will want now to place symmetrically 1000 chambers on a; pad, following a pattern of 20 rows and 50 columns. One way to do this; will be to replicate our chamber by positioning it 1000 times in; different positions of the pad. Unfortunately, this is far from being; the optimal way of doing what we want. Imagine that we would like to; find out which of the 1000 chambers is containing a `(x,y,z)` point; defined in the pad reference. You will never have to do that, since the; modeller will take care of it for you, but let's guess what it has to; do. The most simple algorithm will just loop over all daughters, convert; the point from mother to local reference and check if the current; chamber contains the point or not. This might be efficient for pads with; few chambers, but definitely not for 1000. Fortunately the modeller is; smarter than that and creates for each volume some optimization; structures called `voxels` to minimize the penalty having too many; daughters, but if you have 100 pads like this in your geometry you will; anyway lose a lot in your tracking performance. The way out when; volumes can be arranged according to simple patterns is the usage of; divisions. We will describe them in detail later on. Let's think now at; a different situation: instead of 1000 chambers of the same type, we may; have several types of chambers. Let's say all chambers are cylindrical; and have a wire inside, but their dimensions are different. However, we; would like all to be represented by a single volume family, since they; have the same properties. \anchor GP01bh; #### Volume Families. A volume family is represented by the class TGeoVolumeMulti. It; represents a class of volumes having the same shape type and each member; will be identified by the same name and volume ID. Any operation applied; to a TGeoVolumeMulti equally affects all volumes in that family.; The creation of a family is generally not a user task, but can ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:40857,optimiz,optimization,40857,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance,"ompression= 2.97 *; ```. ## Scan a Variable the Tree with TTree::Scan. The `TTree::Scan` method shows all values of the list of leaves; separated by a colon. ``` {.cpp}; root[] T->Scan(""Cost:Age:Children""); ************************************************; * Row * Cost * Age * Children *; ************************************************; * 0 * 11975 * 58 * 0 *; * 1 * 10228 * 63 * 0 *; * 2 * 10730 * 56 * 2 *; * 3 * 9311 * 61 * 0 *; * 4 * 9966 * 52 * 2 *; * 5 * 7599 * 60 * 0 *; * 6 * 9868 * 53 * 1 *; * 7 * 8012 * 60 * 1 *; ...; ```. ## The Tree Viewer. ![Activating the tree viewer](pictures/030000EF.png). The tree viewer is a quick and easy way to examine a tree. To start the; tree viewer, open a file and object browser. Right click on a; **`TTree`** and select `StartViewer`. You can also start the tree viewer; from the command line. First load the viewer library. ``` {.cpp}; root[] TFile f(""cernstaff.root""); root[] T->StartViewer(); ```. If you want to start a tree viewer without a tree, you need to load the; tree player library first:. ``` {.cpp}; root[] gSystem->Load(""libTreeViewer.so""); root[] new TTreeViewer(); ```. The figure above shows how the tree viewer looks like for the example file; `cernstaff.root`. The left panel contains the list of trees and their; branches; in this case there is only one tree. You can add more trees; with the File-Open command to open the file containing the new tree,; then use the context menu on the right panel, select `SetTreeName` and; enter the name of the tree to add. On the right are the leaves or; variables in the tree. You can double click on any leaf to a histogram; it. The toolbar in the upper part can be used for user commands, changing; the drawing option and the histogram name. The lower part contains three; picture buttons that draw a histogram, stop the current command, and; refresh the tree. The three check buttons toggle the following:. `Hist`- the histogram drawing mode;. `Scan`- enables redirecting of `TTree::Scan ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:6786,load,load,6786,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['load']
Performance,"on Pygments' horrible `llvm` lexer. It just totally gives up; on highlighting this due to the first line. ::. ready> ^D; ; ModuleID = 'my cool jit'. define double @0() {; entry:; %addtmp = fadd double 4.000000e+00, 5.000000e+00; ret double %addtmp; }. define double @foo(double %a, double %b) {; entry:; %multmp = fmul double %a, %a; %multmp1 = fmul double 2.000000e+00, %a; %multmp2 = fmul double %multmp1, %b; %addtmp = fadd double %multmp, %multmp2; %multmp3 = fmul double %b, %b; %addtmp4 = fadd double %addtmp, %multmp3; ret double %addtmp4; }. define double @bar(double %a) {; entry:; %calltmp = call double @foo(double %a, double 4.000000e+00); %calltmp1 = call double @bar(double 3.133700e+04); %addtmp = fadd double %calltmp, %calltmp1; ret double %addtmp; }. declare double @cos(double). define double @1() {; entry:; %calltmp = call double @cos(double 1.234000e+00); ret double %calltmp; }. When you quit the current demo (by sending an EOF via CTRL+D on Linux; or CTRL+Z and ENTER on Windows), it dumps out the IR for the entire; module generated. Here you can see the big picture with all the; functions referencing each other. This wraps up the third chapter of the Kaleidoscope tutorial. Up next,; we'll describe how to `add JIT codegen and optimizer; support <LangImpl04.html>`_ to this so we can actually start running; code!. Full Code Listing; =================. Here is the complete code listing for our running example, enhanced with; the LLVM code generator. Because this uses the LLVM libraries, we need; to link them in. To do this, we use the; `llvm-config <https://llvm.org/cmds/llvm-config.html>`_ tool to inform; our makefile/command line about which options to use:. .. code-block:: bash. # Compile; clang++ -g -O3 toy.cpp `llvm-config --cxxflags --ldflags --system-libs --libs core` -o toy; # Run; ./toy. Here is the code:. .. literalinclude:: ../../../examples/Kaleidoscope/Chapter3/toy.cpp; :language: c++. `Next: Adding JIT and Optimizer Support <LangImpl04.html>`_. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst:20965,optimiz,optimizer,20965,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.rst,1,['optimiz'],['optimizer']
Performance,"on ``Loc``, starting at ``MA``.; Because this API does not request the clobbering access of a specific memory; access, there are no results that can be cached. Locating clobbers yourself; ^^^^^^^^^^^^^^^^^^^^^^^^^^. If you choose to make your own walker, you can find the clobber for a; ``MemoryAccess`` by walking every ``MemoryDef`` that dominates said; ``MemoryAccess``. The structure of ``MemoryDef``\ s makes this relatively simple;; they ultimately form a linked list of every clobber that dominates the; ``MemoryAccess`` that you're trying to optimize. In other words, the; ``definingAccess`` of a ``MemoryDef`` is always the nearest dominating; ``MemoryDef`` or ``MemoryPhi`` of said ``MemoryDef``. Use and Def optimization; ------------------------. ``MemoryUse``\ s keep a single operand, which is their defining or optimized; access.; Traditionally ``MemorySSA`` optimized ``MemoryUse``\ s at build-time, up to a; given threshold.; Specifically, the operand of every ``MemoryUse`` was optimized to point to the; actual clobber of said ``MemoryUse``. This can be seen in the above example; the; second ``MemoryUse`` in ``if.end`` has an operand of ``1``, which is a; ``MemoryDef`` from the entry block. This is done to make walking,; value numbering, etc, faster and easier.; As of `this revision <https://reviews.llvm.org/D121381>`_, the default was; changed to not optimize uses at build time, in order to provide the option to; reduce compile-time if the walking is not necessary in a pass. Most users call; the new API ``ensureOptimizedUses()`` to keep the previous behavior and do a; one-time optimization of ``MemoryUse``\ s, if this was not done before.; New pass users are recommended to call ``ensureOptimizedUses()``. Initially it was not possible to optimize ``MemoryDef``\ s in the same way, as we; restricted ``MemorySSA`` to one operand per access.; This was changed and ``MemoryDef``\ s now keep two operands.; The first one, the defining access, is; always the previous ``Mem",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:11241,optimiz,optimized,11241,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimized']
Performance,"on a loop nest the default behavior; is to automatically extend the representation of the loop counter to; 64 bits for the cases where the sizes of the collapsed loops are not; known at compile time. To prevent this conservative choice and use; at most 32 bits, compile your program with the; `-fopenmp-optimistic-collapse`. GPU devices support; ===================. Data-sharing modes; ------------------. Clang supports two data-sharing models for Cuda devices: `Generic` and `Cuda`; modes. The default mode is `Generic`. `Cuda` mode can give an additional; performance and can be activated using the `-fopenmp-cuda-mode` flag. In; `Generic` mode all local variables that can be shared in the parallel regions; are stored in the global memory. In `Cuda` mode local variables are not shared; between the threads and it is user responsibility to share the required data; between the threads in the parallel regions. Often, the optimizer is able to; reduce the cost of `Generic` mode to the level of `Cuda` mode, but the flag,; as well as other assumption flags, can be used for tuning. Features not supported or with limited support for Cuda devices; ---------------------------------------------------------------. - Cancellation constructs are not supported. - Doacross loop nest is not supported. - User-defined reductions are supported only for trivial types. - Nested parallelism: inner parallel regions are executed sequentially. - Debug information for OpenMP target regions is supported, but sometimes it may; be required to manually specify the address class of the inspected variables.; In some cases the local variables are actually allocated in the global memory,; but the debug info may be not aware of it. .. _OpenMP implementation details:. OpenMP 5.0 Implementation Details; =================================. The following table provides a quick overview over various OpenMP 5.0 features; and their implementation status. Please post on the; `Discourse forums (Runtimes - OpenMP cate",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst:2045,optimiz,optimizer,2045,interpreter/llvm-project/clang/docs/OpenMPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/OpenMPSupport.rst,1,['optimiz'],['optimizer']
Performance,"on and its derivatives. - Input: `head` (starting mathematical expression).; - Output: code for evaluating the function. - **RooFuncWrapper::declareAndDiffFunction()**: Declare the function and create; its derivative. - Inputs: `funcName` (name of the function being differentiated), `funcBody`; (actual mathematical formula or equation).; - Output: Function declaration and its derivative. - **RooFuncWrapper::dumpCode()**: Prints the squashed code body to console; (useful for debugging). - Output: Print squashed code body to console. - **RooFuncWrapper::dumpGradient()**: Prints the derivative code body to; console (useful for debugging). - Output: Print derivative code body to console. - **RooFuncWrapper::gradient()**: Calculates the gradient of the function with; respect to its parameters. - Input: `out` (array where the computed gradient values will be stored).; - Output: Populates the `out` array with gradient values. - **RooFuncWrapper::loadParamsAndData()** Extracts parameters and observables; from the provided data and prepares them for evaluation. - Input: `funcName` (function name), `head` (structure of the function),; `paramSet` (input function's parameters), `data` (optional data points).; - Output: Parameters, observables and other related information (e.g., output; size of the provided function). [^1]: For more details, please see this paper on [Automatic Differentiation of; Binned Likelihoods with Roofit and Clad]. [Automatic Differentiation of Binned Likelihoods with Roofit and Clad]: https://arxiv.org/abs/2304.02650. [^2]: For more details, please see this paper on [GPU Accelerated Automatic Differentiation with Clad]. [GPU Accelerated Automatic Differentiation with Clad]: https://arxiv.org/abs/2203.06139. [RooFit]: https://root.cern/manual/roofit/. [Clad]: https://compiler-research.org/clad/. [MathFuncs]: https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooFit/Detail/MathFuncs.h. [MathFuncs]: https://github.com/root-project/root/b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:38478,load,loadParamsAndData,38478,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['load'],['loadParamsAndData']
Performance,"on and opening our packs, we will obviously find out some empty ones,; otherwise, something is very wrong... We will call these leaves (by; analogy with a tree structure). On the other hand, any volume is a small world by itself - what we need; to do is to take it out and to ignore all the rest since it is a; self-contained object. In fact, the modeller can act like this,; considering a given volume as temporary MARS, but we will describe this; feature later on. Let us focus on the biggest pack - it is mandatory to; define one. Consider the simplest geometry that is made of a single box.; Here is an example on how to build it:. \anchor GP00a; ### Example 1: Creating the World. We first need to load the geometry library. This is not needed if one; does ""make map"" in root folder. ~~~{.cpp}; root[] gSystem->Load(""libGeom"");; ~~~. Second, we have to create an instance of the geometry manager class.; This takes care of all the modeller components, performing several tasks; to insure geometry validity and containing the user interface for; building and interacting with the geometry. After its creation, the; geometry manager class can be accessed with the global; `gGeoManager`:. ~~~{.cpp}; root[] new TGeoManager(""world"", ""the simplest geometry"");; ~~~. We want to create a single volume in our geometry, but since any volume; needs to have an associated medium, we will create a dummy one. You can; safely ignore the following lines for the time being, since materials; and media will be explained in detail later on. ~~~{.cpp}; root[] TGeoMaterial *mat = new TGeoMaterial(""Vacuum"",0,0,0);; root[] TGeoMedium *med = new TGeoMedium(""Vacuum"",1,mat);; ~~~. We can finally make our volume having a box shape. Note that the world; volume does not need to be a box - it can be any other shape. Generally,; boxes and tubes are the most recommendable shapes for this purpose due; to their fast navigation algorithms. ~~~{.cpp}; root[] TGeoVolume *top=gGeoManager->MakeBox(""Top"",med,10.,10.,10.);",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:5178,perform,performing,5178,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performing']
Performance,"on call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any followin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:211270,cache,cache,211270,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['cache'],['cache']
Performance,"on case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations specific to basic extension modules (C function; pointer calls), gaining a performance boost of more than 30% over Python2.; Only since Python3.8 is there also better support for closure objects (vector; calls) as cppyy uses, to short-cut through the interpreter's own overhead. As a practical consideration, whether a binder performs well on code that you; care about, depends `entirely` on whether it has the relevant specializations; for your most performance-sensitive use cases.; The only way to know for sure is to write a test application and measure, but; a binder that provides more specializations, or makes it easy to add your; own, is more likely to deliver. `Manual v.s. automatic`; -----------------------. Python is, today, one of the most popular programming languages and has a; rich and mature eco-system around it.; But when the project that became cppyy started in the field of High Energy; Physics (HEP), Python usage was non-existent there.; As a Python user to work in this predominantly C++ environment, you had to; bring your own bindings, thus automatic was the only way to go.; Binders such as SWIG, SIP (or even boost.python with Pyste) all had the fatal; assumption that you were providing Python bindings to your `own` C++ code,; and that you were thus able to modify those (many) areas of the C++ codes; that their parsers could not handle.; The `CIN",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:4172,perform,performs,4172,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,2,['perform'],"['performance-sensitive', 'performs']"
Performance,"on comparison of its two integer, integer vector,; pointer, or pointer vector operands. Arguments:; """""""""""""""""""". The '``icmp``' instruction takes three operands. The first operand is; the condition code indicating the kind of comparison to perform. It is; not a value, just a keyword. The possible condition codes are:. .. _icmp_md_cc:. #. ``eq``: equal; #. ``ne``: not equal; #. ``ugt``: unsigned greater than; #. ``uge``: unsigned greater or equal; #. ``ult``: unsigned less than; #. ``ule``: unsigned less or equal; #. ``sgt``: signed greater than; #. ``sge``: signed greater or equal; #. ``slt``: signed less than; #. ``sle``: signed less or equal. The remaining two arguments must be :ref:`integer <t_integer>` or; :ref:`pointer <t_pointer>` or integer :ref:`vector <t_vector>` typed. They; must also be identical types. Semantics:; """""""""""""""""""". The '``icmp``' compares ``op1`` and ``op2`` according to the condition; code given as ``cond``. The comparison performed always yields either an; :ref:`i1 <t_integer>` or vector of ``i1`` result, as follows:. .. _icmp_md_cc_sem:. #. ``eq``: yields ``true`` if the operands are equal, ``false``; otherwise. No sign interpretation is necessary or performed.; #. ``ne``: yields ``true`` if the operands are unequal, ``false``; otherwise. No sign interpretation is necessary or performed.; #. ``ugt``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is greater than ``op2``.; #. ``uge``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is greater than or equal to ``op2``.; #. ``ult``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is less than ``op2``.; #. ``ule``: interprets the operands as unsigned values and yields; ``true`` if ``op1`` is less than or equal to ``op2``.; #. ``sgt``: interprets the operands as signed values and yields ``true``; if ``op1`` is greater than ``op2``.; #. ``sge``: interprets the operands as signed values and yields ``true``; if ``op1`` ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:460684,perform,performed,460684,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance,"on cost model is used to select the vector width. Interleaving multiple loop iterations allows modern processors to further; improve instruction-level parallelism (ILP) using advanced hardware features,; such as multiple execution units and out-of-order execution. The vectorizer uses; a cost model that depends on the register pressure and generated code size to; select the interleaving count. Vectorization is enabled by ``vectorize(enable)`` and interleaving is enabled; by ``interleave(enable)``. This is useful when compiling with ``-Os`` to; manually enable vectorization or interleaving. .. code-block:: c++. #pragma clang loop vectorize(enable); #pragma clang loop interleave(enable); for(...) {; ...; }. The vector width is specified by; ``vectorize_width(_value_[, fixed|scalable])``, where _value_ is a positive; integer and the type of vectorization can be specified with an optional; second parameter. The default for the second parameter is 'fixed' and; refers to fixed width vectorization, whereas 'scalable' indicates the; compiler should use scalable vectors instead. Another use of vectorize_width; is ``vectorize_width(fixed|scalable)`` where the user can hint at the type; of vectorization to use without specifying the exact width. In both variants; of the pragma the vectorizer may decide to fall back on fixed width; vectorization if the target does not support scalable vectors. The interleave count is specified by ``interleave_count(_value_)``, where; _value_ is a positive integer. This is useful for specifying the optimal; width/count of the set of target architectures supported by your application. .. code-block:: c++. #pragma clang loop vectorize_width(2); #pragma clang loop interleave_count(2); for(...) {; ...; }. Specifying a width/count of 1 disables the optimization, and is equivalent to; ``vectorize(disable)`` or ``interleave(disable)``. Vector predication is enabled by ``vectorize_predicate(enable)``, for example:. .. code-block:: c++. #pragma clang loop",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:164678,scalab,scalable,164678,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['scalab'],['scalable']
Performance,"on into a place,; and the stored bits can be safely read from the place by another thread via; synchronization. .. code-block:: llvm. @lock = global i1 true. define void @f(ptr %a) {; store ptr %a, ptr* @glb; store atomic i1 false, ptr @lock release ; %a is captured because another thread can safely read @glb; store ptr null, ptr @glb; ret void; }. 3. The call's behavior depends on any bit of the pointer carrying information. .. code-block:: llvm. @glb = global i8 0. define void @f(ptr %a) {; %c = icmp eq ptr %a, @glb; br i1 %c, label %BB_EXIT, label %BB_CONTINUE ; escapes %a; BB_EXIT:; call void @exit(); unreachable; BB_CONTINUE:; ret void; }. 4. The pointer is used in a volatile access as its address. .. _volatile:. Volatile Memory Accesses; ------------------------. Certain memory accesses, such as :ref:`load <i_load>`'s,; :ref:`store <i_store>`'s, and :ref:`llvm.memcpy <int_memcpy>`'s may be; marked ``volatile``. The optimizers must not change the number of; volatile operations or change their order of execution relative to other; volatile operations. The optimizers *may* change the order of volatile; operations relative to non-volatile operations. This is not Java's; ""volatile"" and has no cross-thread synchronization behavior. A volatile load or store may have additional target-specific semantics.; Any volatile operation can have side effects, and any volatile operation; can read and/or modify state which is not accessible via a regular load; or store in this module. Volatile operations may use addresses which do; not point to memory (like MMIO registers). This means the compiler may; not use a volatile operation to prove a non-volatile access to that; address has defined behavior. The allowed side-effects for volatile accesses are limited. If a; non-volatile store to a given address would be legal, a volatile; operation may modify the memory at that address. A volatile operation; may not modify any other memory accessible by the module being compiled.; A volati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:145985,optimiz,optimizers,145985,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizers']
Performance,"on is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vectorization for the compiler to generate code that; promotes portions of an array into vector registers. For example, if the; hardware has vector registers with 8 elements, and 8 wide SIMD instructions, the; compiler may vectorize a loop so that is executes 8 iterations concurrently for; each vectorized loop iteration. On the first iteration of the generated vectorized loop, iterations 0 to 7 of; the source language loop will be executed using SI",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:34394,concurren,concurrent,34394,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['concurren'],['concurrent']
Performance,"on may describe the same; physical location. e.g. A stack slot may appear as a deopt location,; a gc base pointer, and a gc derived pointer. The LiveOut section of the StkMapRecord will be empty for a statepoint; record. Safepoint Semantics & Verification; ==================================. The fundamental correctness property for the compiled code's; correctness w.r.t. the garbage collector is a dynamic one. It must be; the case that there is no dynamic trace such that an operation; involving a potentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intrinsics mentioned in their respective; documentation. The current implementation in LLVM does not check the; key relocation invariant, but this is ongoing wo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:24083,perform,performed,24083,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['perform'],['performed']
Performance,"on methods of the ``DeclContext``, so; the vast majority of clients can ignore them. Because the same entity can be defined multiple times in different modules,; it is also possible for there to be multiple definitions of (for instance); a ``CXXRecordDecl``, all of which describe a definition of the same class.; In such a case, only one of those ""definitions"" is considered by Clang to be; the definition of the class, and the others are treated as non-defining; declarations that happen to also contain member declarations. Corresponding; members in each definition of such multiply-defined classes are identified; either by redeclaration chains (if the members are ``Redeclarable``); or by simply a pointer to the canonical declaration (if the declarations; are not ``Redeclarable`` -- in that case, a ``Mergeable`` base class is used; instead). Error Handling; --------------. Clang produces an AST even when the code contains errors. Clang won't generate; and optimize code for it, but it's used as parsing continues to detect further; errors in the input. Clang-based tools also depend on such ASTs, and IDEs in; particular benefit from a high-quality AST for broken code. In presence of errors, clang uses a few error-recovery strategies to present the; broken code in the AST:. - correcting errors: in cases where clang is confident about the fix, it; provides a FixIt attaching to the error diagnostic and emits a corrected AST; (reflecting the written code with FixIts applied). The advantage of that is to; provide more accurate subsequent diagnostics. Typo correction is a typical; example.; - representing invalid node: the invalid node is preserved in the AST in some; form, e.g. when the ""declaration"" part of the declaration contains semantic; errors, the Decl node is marked as invalid.; - dropping invalid node: this often happens for errors that we dont have; graceful recovery. Prior to Recovery AST, a mismatched-argument function call; expression was dropped though a CallExpr ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:84415,optimiz,optimize,84415,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['optimiz'],['optimize']
Performance,"on of the '``llvm.experimental.vector.reverse.*``' intrinsic. Arguments:; """""""""""""""""""". The result and the first argument ``vec`` are vectors with the same type.; The second argument ``mask`` is a vector mask and has the same number of; elements as the result. The third argument is the explicit vector length of; the operation. Semantics:; """""""""""""""""""". This intrinsic reverses the order of the first ``evl`` elements in a vector.; The lanes in the result vector disabled by ``mask`` are ``poison``. The; elements past ``evl`` are poison. .. _int_vp_load:. '``llvm.vp.load``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x float> @llvm.vp.load.v4f32.p0(ptr %ptr, <4 x i1> %mask, i32 %evl); declare <vscale x 2 x i16> @llvm.vp.load.nxv2i16.p0(ptr %ptr, <vscale x 2 x i1> %mask, i32 %evl); declare <8 x float> @llvm.vp.load.v8f32.p1(ptr addrspace(1) %ptr, <8 x i1> %mask, i32 %evl); declare <vscale x 1 x i64> @llvm.vp.load.nxv1i64.p6(ptr addrspace(6) %ptr, <vscale x 1 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.vp.load.*``' intrinsic is the vector length predicated version of; the :ref:`llvm.masked.load <int_mload>` intrinsic. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is a; vector of boolean values with the same number of elements as the return type.; The third is the explicit vector length of the operation. The return type and; underlying type of the base pointer are the same vector types. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.vp.load``' intrinsic reads a vector from memory in the same way as; the '``llvm.masked.load``' intrinsic, where the mask is taken from the; combination of the '``mask``' and '``evl``' operands in the usual VP way.; Certain '``llvm.masked.load``' operands do not have corresponding operands in; '``llvm.vp.load``': the '``passthr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:783335,load,load,783335,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance,"on of the operands using ""``$``""; followed by a number, to indicate substitution of the given register/memory; location, as specified by the constraint string. ""``${NUM:MODIFIER}``"" may also; be used, where ``MODIFIER`` is a target-specific annotation for how to print the; operand (See :ref:`inline-asm-modifiers`). A literal ""``$``"" may be included by using ""``$$``"" in the template. To include; other special characters into the output, the usual ""``\XX``"" escapes may be; used, just as in other strings. Note that after template substitution, the; resulting assembly string is parsed by LLVM's integrated assembler unless it is; disabled -- even when emitting a ``.s`` file -- and thus must contain assembly; syntax known to LLVM. LLVM also supports a few more substitutions useful for writing inline assembly:. - ``${:uid}``: Expands to a decimal integer unique to this inline assembly blob.; This substitution is useful when declaring a local label. Many standard; compiler optimizations, such as inlining, may duplicate an inline asm blob.; Adding a blob-unique identifier ensures that the two labels will not conflict; during assembly. This is used to implement `GCC's %= special format; string <https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html>`_.; - ``${:comment}``: Expands to the comment character of the current target's; assembly dialect. This is usually ``#``, but many targets use other strings,; such as ``;``, ``//``, or ``!``.; - ``${:private}``: Expands to the assembler private label prefix. Labels with; this prefix will not appear in the symbol table of the assembled object.; Typically the prefix is ``L``, but targets may use other strings. ``.L`` is; relatively popular. LLVM's support for inline asm is modeled closely on the requirements of Clang's; GCC-compatible inline-asm support. Thus, the feature-set and the constraint and; modifier codes listed here are similar or identical to those in GCC's inline asm; support. However, to be clear, the syntax of the templat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:207170,optimiz,optimizations,207170,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance,"on of the pass is not skipped individual transformations within; that invocation may still be skipped. The order of the values assigned is guaranteed to remain stable and consistent; from one run to the next up to and including the value specified as the limit.; Above the limit value skipping of optimizations can cause a change in the; numbering, but because all optimizations above the limit are skipped this; is not a problem. When an opt-bisect index value refers to an entire invocation of the run; function for a pass, the pass will query whether or not it should be skipped; each time it is invoked and each invocation will be assigned a unique value.; For example, if a FunctionPass is used with a module containing three functions; a different index value will be assigned to the pass for each of the functions; as the pass is run. The pass may be run on two functions but skipped for the; third. If the pass internally performs operations on a smaller IR unit the pass must be; specifically instrumented to enable bisection at this finer level of granularity; (see below for details). Example Usage; =============. .. code-block:: console. $ opt -O2 -o test-opt.bc -opt-bisect-limit=16 test.ll. BISECT: running pass (1) Simplify the CFG on function (g); BISECT: running pass (2) SROA on function (g); BISECT: running pass (3) Early CSE on function (g); BISECT: running pass (4) Infer set function attributes on module (test.ll); BISECT: running pass (5) Interprocedural Sparse Conditional Constant Propagation on module (test.ll); BISECT: running pass (6) Global Variable Optimizer on module (test.ll); BISECT: running pass (7) Promote Memory to Register on function (g); BISECT: running pass (8) Dead Argument Elimination on module (test.ll); BISECT: running pass (9) Combine redundant instructions on function (g); BISECT: running pass (10) Simplify the CFG on function (g); BISECT: running pass (11) Remove unused exception handling info on SCC (<<null function>>); BISECT: running pass ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst:4924,perform,performs,4924,interpreter/llvm-project/llvm/docs/OptBisect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst,1,['perform'],['performs']
Performance,"on passes assume that the rounding mode is; round-to-nearest and that floating-point exceptions will not be monitored.; Constrained FP intrinsics are used to support non-default rounding modes and; accurately preserve exception behavior without compromising LLVM's ability to; optimize FP code when the default behavior is used. If any FP operation in a function is constrained then they all must be; constrained. This is required for correct LLVM IR. Optimizations that; move code around can create miscompiles if mixing of constrained and normal; operations is done. The correct way to mix constrained and less constrained; operations is to use the rounding mode and exception handling metadata to; mark constrained intrinsics as having LLVM's default behavior. Each of these intrinsics corresponds to a normal floating-point operation. The; data arguments and the return value are the same as the corresponding FP; operation. The rounding mode argument is a metadata string specifying what; assumptions, if any, the optimizer can make when transforming constant; values. Some constrained FP intrinsics omit this argument. If required; by the intrinsic, this argument must be one of the following strings:. ::. ""round.dynamic""; ""round.tonearest""; ""round.downward""; ""round.upward""; ""round.towardzero""; ""round.tonearestaway"". If this argument is ""round.dynamic"" optimization passes must assume that the; rounding mode is unknown and may change at runtime. No transformations that; depend on rounding mode may be performed in this case. The other possible values for the rounding mode argument correspond to the; similarly named IEEE rounding modes. If the argument is any of these values; optimization passes may perform transformations as long as they are consistent; with the specified rounding mode. For example, 'x-0'->'x' is not a valid transformation if the rounding mode is; ""round.downward"" or ""round.dynamic"" because if the value of 'x' is +0 then; 'x-0' should evaluate to '-0' when rounding",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:868373,optimiz,optimizer,868373,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance,"on than their type would; normally allow. This permits operation fusing, and Clang takes advantage; of this by default. This behavior can be controlled with the ``FP_CONTRACT``; and ``clang fp contract`` pragmas. Please refer to the pragma documentation; for a description of how the pragmas interact with this option. Valid values are:. * ``fast`` (fuse across statements disregarding pragmas, default for CUDA); * ``on`` (fuse in the same statement unless dictated by pragmas, default for languages other than CUDA/HIP); * ``off`` (never fuse); * ``fast-honor-pragmas`` (fuse across statements unless dictated by pragmas, default for HIP). .. option:: -f[no-]honor-infinities. Allow floating-point optimizations that assume arguments and results are; not +-Inf.; Defaults to ``-fhonor-infinities``. If both ``-fno-honor-infinities`` and ``-fno-honor-nans`` are used,; has the same effect as specifying ``-ffinite-math-only``. .. option:: -f[no-]honor-nans. Allow floating-point optimizations that assume arguments and results are; not NaNs.; Defaults to ``-fhonor-nans``. If both ``-fno-honor-infinities`` and ``-fno-honor-nans`` are used,; has the same effect as specifying ``-ffinite-math-only``. .. option:: -f[no-]approx-func. Allow certain math function calls (such as ``log``, ``sqrt``, ``pow``, etc); to be replaced with an approximately equivalent set of instructions; or alternative math function calls. For example, a ``pow(x, 0.25)``; may be replaced with ``sqrt(sqrt(x))``, despite being an inexact result; in cases where ``x`` is ``-0.0`` or ``-inf``.; Defaults to ``-fno-approx-func``. .. option:: -f[no-]signed-zeros. Allow optimizations that ignore the sign of floating point zeros.; Defaults to ``-fsigned-zeros``. .. option:: -f[no-]associative-math. Allow floating point operations to be reassociated.; Defaults to ``-fno-associative-math``. .. option:: -f[no-]reciprocal-math. Allow division operations to be transformed into multiplication by a; reciprocal. This can be signifi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:58050,optimiz,optimizations,58050,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance,"on the duplicated node. Because of these reasons,; we created a lookup class which has the sole purpose to register all; declarations, so later they can be looked up by subsequent import requests.; This is the ``ASTImporterLookupTable`` class. This lookup table should be; shared amongst the different ``ASTImporter`` instances if they happen to import; to the very same ""to"" context. This is why we can use the importer specific; lookup only via the ``ASTImporterSharedState`` class. ExternalASTSource; ~~~~~~~~~~~~~~~~~. The ``ExternalASTSource`` is an abstract interface associated with the; ``ASTContext`` class. It provides the ability to read the declarations stored; within a declaration context either for iteration or for name lookup. A; declaration context with an external AST source may load its declarations; on-demand. This means that the list of declarations (represented as a linked; list, the head is ``DeclContext::FirstDecl``) could be empty. However, member; functions like ``DeclContext::lookup()`` may initiate a load. Usually, external sources are associated with precompiled headers. For example,; when we load a class from a PCH then the members are loaded only if we do want; to look up something in the class' context. In case of LLDB, an implementation of the ``ExternalASTSource`` interface is; attached to the AST context which is related to the parsed expression. This; implementation of the ``ExternalASTSource`` interface is realized with the help; of the ``ASTImporter`` class. This way, LLDB can reuse Clang's parsing; machinery while synthesizing the underlying AST from the debug data (e.g. from; DWARF). From the view of the ``ASTImporter`` this means both the ""to"" and the; ""from"" context may have declaration contexts with external lexical storage. If; a ``DeclContext`` in the ""to"" AST context has external lexical storage then we; must take extra attention to work only with the already loaded declarations!; Otherwise, we would end up with an uncontrolled im",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:106925,load,load,106925,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['load'],['load']
Performance,"on the instruction tells the; optimizer that the value loaded is known to be aligned to a boundary specified; by the integer value in the metadata node. The alignment must be a power of 2.; This is analogous to the ''align'' attribute on parameters and return values.; This metadata can only be applied to loads of a pointer type. If the returned; value is not appropriately aligned at runtime, a poison value is returned; instead. The optional ``!noundef`` metadata must reference a single metadata name; ``<empty_node>`` corresponding to a node with no entries. The existence of; ``!noundef`` metadata on the instruction tells the optimizer that the value; loaded is known to be :ref:`well defined <welldefinedvalues>`.; If the value isn't well defined, the behavior is undefined. If the ``!noundef``; metadata is combined with poison-generating metadata like ``!nonnull``,; violation of that metadata constraint will also result in undefined behavior. Semantics:; """""""""""""""""""". The location of memory pointed to is loaded. If the value being loaded; is of scalar type then the number of bytes read does not exceed the; minimum number of bytes needed to hold all bits of the type. For; example, loading an ``i24`` reads at most three bytes. When loading a; value of a type like ``i20`` with a size that is not an integral number; of bytes, the result is undefined if the value was not originally; written using a store of the same type.; If the value being loaded is of aggregate type, the bytes that correspond to; padding may be accessed but are ignored, because it is impossible to observe; padding from the loaded aggregate value.; If ``<pointer>`` is not a well-defined value, the behavior is undefined. Examples:; """""""""""""""""". .. code-block:: llvm. %ptr = alloca i32 ; yields ptr; store i32 3, ptr %ptr ; yields void; %val = load i32, ptr %ptr ; yields i32:val = i32 3. .. _i_store:. '``store``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. store [volatile] <ty> <value>, ptr <point",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:418152,load,loaded,418152,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loaded']
Performance,"on's global; declaration to ``Passes.h`` and add a ""pseudo"" call line to; ``llvm/Codegen/LinkAllCodegenComponents.h``. Creating new registries; -----------------------. The easiest way to get started is to clone one of the existing registries; we; recommend ``llvm/CodeGen/RegAllocRegistry.h``. The key things to modify are; the class name and the ``FunctionPassCtor`` type. Then you need to declare the registry. Example: if your pass registry is; ``RegisterMyPasses`` then define:. .. code-block:: c++. MachinePassRegistry<RegisterMyPasses::FunctionPassCtor> RegisterMyPasses::Registry;. And finally, declare the command line option for your passes. Example:. .. code-block:: c++. cl::opt<RegisterMyPasses::FunctionPassCtor, false,; RegisterPassParser<RegisterMyPasses> >; MyPassOpt(""mypass"",; cl::init(&createDefaultMyPass),; cl::desc(""my pass option help""));. Here the command option is ""``mypass``"", with ``createDefaultMyPass`` as the; default creator. Using GDB with dynamically loaded passes; ----------------------------------------. Unfortunately, using GDB with dynamically loaded passes is not as easy as it; should be. First of all, you can't set a breakpoint in a shared object that; has not been loaded yet, and second of all there are problems with inlined; functions in shared objects. Here are some suggestions to debugging your pass; with GDB. For sake of discussion, I'm going to assume that you are debugging a; transformation invoked by :program:`opt`, although nothing described here; depends on that. Setting a breakpoint in your pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. First thing you do is start gdb on the opt process:. .. code-block:: console. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show wa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:52014,load,loaded,52014,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['load'],['loaded']
Performance,"on't; delve into what they do but, believe me, they are a good starting place :). Next, we register the analysis passes used by the transform passes. .. code-block:: c++. // Register analysis passes used in these transform passes.; PassBuilder PB;; PB.registerModuleAnalyses(*TheMAM);; PB.registerFunctionAnalyses(*TheFAM);; PB.crossRegisterProxies(*TheLAM, *TheFAM, *TheCGAM, *TheMAM);; }. Once the PassManager is set up, we need to make use of it. We do this by; running it after our newly created function is constructed (in; ``FunctionAST::codegen()``), but before it is returned to the client:. .. code-block:: c++. if (Value *RetVal = Body->codegen()) {; // Finish off the function.; Builder.CreateRet(RetVal);. // Validate the generated code, checking for consistency.; verifyFunction(*TheFunction);. // Optimize the function.; TheFPM->run(*TheFunction, *TheFAM);. return TheFunction;; }. As you can see, this is pretty straightforward. The; ``FunctionPassManager`` optimizes and updates the LLVM Function\* in; place, improving (hopefully) its body. With this in place, we can try; our test above again:. ::. ready> def test(x) (1+2+x)*(x+(1+2));; ready> Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double %x, 3.000000e+00; %multmp = fmul double %addtmp, %addtmp; ret double %multmp; }. As expected, we now get our nicely optimized code, saving a floating; point add instruction from every execution of this function. LLVM provides a wide variety of optimizations that can be used in; certain circumstances. Some `documentation about the various; passes <../../Passes.html>`_ is available, but it isn't very complete.; Another good source of ideas can come from looking at the passes that; ``Clang`` runs to get started. The ""``opt``"" tool allows you to; experiment with passes from the command line, so you can see if they do; anything. Now that we have reasonable code coming out of our front-end, let's talk; about executing it!. Adding a JIT Compil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:8549,optimiz,optimizes,8549,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimizes']
Performance,"on() {;}; virtual ~ATLFMuon() {;}; ClassDef(ATLFMuon,1) //; };; ClassImp(ATLFMuon); #endif; ```. ## Compression and Performance. ROOT uses a compression algorithm based on the well-known `gzip`; algorithm. It supports nine levels of compression. The default for ROOT; is one. The compression level can be set with the method; `TFile::SetCompressionLevel`. The experience with this algorithm shows; that a compression level of 1.3 for raw data files and around two on; most DST files is the optimum. The choice of one for the default is a; compromise between the time it takes to read and write the object vs.; the disk space savings. To specify no compression, set the level to zero. We recommend using compression when the time spent in I/O is small; compared to the total processing time. If the I/O operation is increased; by a factor of 5 it is still a small percentage of the total time and it; may compress the data by a factor of 10. On the other hand if the time; spend on I/O is large, compression may have a large impact on the; program's performance. The compression factor, i.e. the savings of disk space, varies with the; type of data. A buffer with a same value array is compressed so that the; value is only written once. For example, a track has the mass of a pion; that it is always the same, and the charge of the pion that is either; positive or negative. For 1000 pions, the mass will be written only; once, and the charge only twice (positive and negative). When the data; is sparse, i.e. when there are many zeros, the compression factor is; also high. +---------------------+------------------+-------------------+-------------------+; | Compression level | Bytes | Write Time (sec) | Read Time (sec.) |; +---------------------+------------------+-------------------+-------------------+; | 0 | 1,004,998 | 4.77 | 0.07 |; +---------------------+------------------+-------------------+-------------------+; | 1 | 438,366 | 6.67 | 0.05 |; +---------------------+------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:92391,perform,performance,92391,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['perform'],['performance']
Performance,"on-atomic operation. Some examples of how optimizations interact with various kinds of atomic; operations:. * ``memcpyopt``: An atomic operation cannot be optimized into part of a; memcpy/memset, including unordered loads/stores. It can pull operations; across some atomic operations. * LICM: Unordered loads/stores can be moved out of a loop. It just treats; monotonic operations like a read+write to a memory location, and anything; stricter than that like a nothrow call. * DSE: Unordered stores can be DSE'ed like normal stores. Monotonic stores can; be DSE'ed in some cases, but it's tricky to reason about, and not especially; important. It is possible in some case for DSE to operate across a stronger; atomic operation, but it is fairly tricky. DSE delegates this reasoning to; MemoryDependencyAnalysis (which is also used by other passes like GVN). * Folding a load: Any atomic load from a constant global can be constant-folded,; because it cannot be observed. Similar reasoning allows sroa with; atomic loads and stores. Atomics and Codegen; ===================. Atomic operations are represented in the SelectionDAG with ``ATOMIC_*`` opcodes.; On architectures which use barrier instructions for all atomic ordering (like; ARM), appropriate fences can be emitted by the AtomicExpand Codegen pass if; ``shouldInsertFencesForAtomic()`` returns true. The MachineMemOperand for all atomic operations is currently marked as volatile;; this is not correct in the IR sense of volatile, but CodeGen handles anything; marked volatile very conservatively. This should get fixed at some point. One very important property of the atomic operations is that if your backend; supports any inline lock-free atomic operations of a given size, you should; support *ALL* operations of that size in a lock-free manner. When the target implements atomic ``cmpxchg`` or LL/SC instructions (as most do); this is trivial: all the other operations can be implemented on top of those; primitives. However, on many o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:18080,load,loads,18080,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['load'],['loads']
Performance,"on-call path. for () {; *P += 1;; if (); call();; else; ...; ->; tmp = *P; for () {; tmp += 1;; if () {; *P = tmp;; call();; tmp = *P;; } else ...; }; *P = tmp;. We now hoist the reload after the call (Transforms/GVN/lpre-call-wrap.ll), but; we don't sink the store. We need partially dead store sinking. //===---------------------------------------------------------------------===//. [LOAD PRE CRIT EDGE SPLITTING]. GCC PR37166: Sinking of loads prevents SROA'ing the ""g"" struct on the stack; leading to excess stack traffic. This could be handled by GVN with some crazy; symbolic phi translation. The code we get looks like (g is on the stack):. bb2:		; preds = %bb1; ..; 	%9 = getelementptr %struct.f* %g, i32 0, i32 0		; 	store i32 %8, i32* %9, align bel %bb3. bb3:		; preds = %bb1, %bb2, %bb; 	%c_addr.0 = phi %struct.f* [ %g, %bb2 ], [ %c, %bb ], [ %c, %bb1 ]; 	%b_addr.0 = phi %struct.f* [ %b, %bb2 ], [ %g, %bb ], [ %b, %bb1 ]; 	%10 = getelementptr %struct.f* %c_addr.0, i32 0, i32 0; 	%11 = load i32* %10, align 4. %11 is partially redundant, an in BB2 it should have the value %8. GCC PR33344 and PR35287 are similar cases. //===---------------------------------------------------------------------===//. [LOAD PRE]. There are many load PRE testcases in testsuite/gcc.dg/tree-ssa/loadpre* in the; GCC testsuite, ones we don't get yet are (checked through loadpre25):. [CRIT EDGE BREAKING]; predcom-4.c. [PRE OF READONLY CALL]; loadpre5.c. [TURN SELECT INTO BRANCH]; loadpre14.c loadpre15.c . actually a conditional increment: loadpre18.c loadpre19.c. //===---------------------------------------------------------------------===//. [LOAD PRE / STORE SINKING / SPEC HACK]. This is a chunk of code from 456.hmmer:. int f(int M, int *mc, int *mpp, int *tpmm, int *ip, int *tpim, int *dpp,; int *tpdm, int xmb, int *bp, int *ms) {; int k, sc;; for (k = 1; k <= M; k++) {; mc[k] = mpp[k-1] + tpmm[k-1];; if ((sc = ip[k-1] + tpim[k-1]) > mc[k]) mc[k] = sc;; if ((sc = dpp[k-1] + tpdm[k-1]) > mc[k",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:33189,load,load,33189,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,2,['load'],['load']
Performance,"on. As a concrete example, LLVM supports both ""whole module"" passes, which; look across as large of body of code as they can (often a whole file,; but if run at link time, this can be a substantial portion of the whole; program). It also supports and includes ""per-function"" passes which just; operate on a single function at a time, without looking at other; functions. For more information on passes and how they are run, see the; `How to Write a Pass <../../WritingAnLLVMPass.html>`_ document and the; `List of LLVM Passes <../../Passes.html>`_. For Kaleidoscope, we are currently generating functions on the fly, one; at a time, as the user types them in. We aren't shooting for the; ultimate optimization experience in this setting, but we also want to; catch the easy and quick stuff where possible. As such, we will choose; to run a few per-function optimizations as the user types the function; in. If we wanted to make a ""static Kaleidoscope compiler"", we would use; exactly the code we have now, except that we would defer running the; optimizer until the entire file has been parsed. In addition to the distinction between function and module passes, passes can be; divided into transform and analysis passes. Transform passes mutate the IR, and; analysis passes compute information that other passes can use. In order to add; a transform pass, all analysis passes it depends upon must be registered in; advance. In order to get per-function optimizations going, we need to set up a; `FunctionPassManager <../../WritingAnLLVMPass.html#what-passmanager-doesr>`_ to hold; and organize the LLVM optimizations that we want to run. Once we have; that, we can add a set of optimizations to run. We'll need a new; FunctionPassManager for each module that we want to optimize, so we'll; add to a function created in the previous chapter (``InitializeModule()``):. .. code-block:: c++. void InitializeModuleAndManagers(void) {; // Open a new context and module.; TheContext = std::make_unique<LLVMC",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:4771,optimiz,optimizer,4771,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimizer']
Performance,"on:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it performs a retain; operation followed by the operation described in; :ref:`objc_autoreleaseReturnValue <arc.runtime.objc_autoreleaseReturnValue>`.; Equivalent to the following code:. .. code-block:: objc. id objc_retainAutoreleaseReturnValue(id value) {; return objc_autoreleaseReturnValue(objc_retain(value));; }. Always returns ``value``. .. _arc.runtime.objc_retainAutoreleasedReturnValue:. ``id objc_retainAutoreleasedReturnValue(id value);``; ----------------------------------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it attempts to; accept a hand off of a retain count from a call to; :ref:`objc_autoreleaseReturnValue <arc.runtime.objc_autoreleaseReturnValue>` on; ``value`` in a recently-called function or something it tail-calls. If that; fails, it performs a retain operation exactly like :ref:`objc_retain; <arc.runtime.objc_retain>`. Always returns ``value``. .. _arc.runtime.objc_retainBlock:. ``id objc_retainBlock(id value);``; ----------------------------------. *Precondition:* ``value`` is null or a pointer to a valid block object. If ``value`` is null, this call has no effect. Otherwise, if the block pointed; to by ``value`` is still on the stack, it is copied to the heap and the address; of the copy is returned. Otherwise a retain operation is performed on the; block exactly as if it had been sent the ``retain`` message. .. _arc.runtime.objc_storeStrong:. ``void objc_storeStrong(id *object, id value);``; ------------------------------------------------. *Precondition:* ``object`` is a valid pointer to a ``__strong`` object which is; adequately aligned for a pointer. ``value`` is null or a pointer to a valid; object. Performs the complete sequence for assigning to a ``__strong`` object of; non-block type [*]_. Equivalent to the following code:. ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:115370,perform,performs,115370,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['performs']
Performance,"on:. .. code:: cpp. extern ""C"" const char *__gwp_asan_default_options() {; return ""MaxSimultaneousAllocations=16:SampleRate=5000"";; }. The following options are available:. +----------------------------+---------+--------------------------------------------------------------------------------+; | Option | Default | Description |; +----------------------------+---------+--------------------------------------------------------------------------------+; | Enabled | true | Is GWP-ASan enabled? |; +----------------------------+---------+--------------------------------------------------------------------------------+; | PerfectlyRightAlign | false | When allocations are right-aligned, should we perfectly align them up to the |; | | | page boundary? By default (false), we round up allocation size to the nearest |; | | | power of two (2, 4, 8, 16) up to a maximum of 16-byte alignment for |; | | | performance reasons. Setting this to true can find single byte |; | | | buffer-overflows at the cost of performance, and may be incompatible with |; | | | some architectures. |; +----------------------------+---------+--------------------------------------------------------------------------------+; | MaxSimultaneousAllocations | 16 | Number of simultaneously-guarded allocations available in the pool. |; +----------------------------+---------+--------------------------------------------------------------------------------+; | SampleRate | 5000 | The probability (1 / SampleRate) that a page is selected for GWP-ASan |; | | | sampling. Sample rates up to (2^31 - 1) are supported. |; +----------------------------+---------+--------------------------------------------------------------------------------+; | InstallSignalHandlers | true | Install GWP-ASan signal handlers for SIGSEGV during dynamic loading. This |; | | | allows better error reports by providing stack traces for allocation and |; | | | deallocation when reporting a memory error. GWP-ASan's signal handler will |; | | | fo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:7684,perform,performance,7684,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['perform'],['performance']
Performance,"on:: -code-model=model. Choose the code model from:. .. code-block:: text. default: Target default code model; tiny: Tiny code model; small: Small code model; kernel: Kernel code model; medium: Medium code model; large: Large code model. .. option:: -disable-post-RA-scheduler. Disable scheduling after register allocation. .. option:: -disable-spill-fusing. Disable fusing of spill code into instructions. .. option:: -jit-enable-eh. Exception handling should be enabled in the just-in-time compiler. .. option:: -join-liveintervals. Coalesce copies (default=true). .. option:: -nozero-initialized-in-bss. Don't place zero-initialized symbols into the BSS section. .. option:: -pre-RA-sched=scheduler. Instruction schedulers available (before register allocation):. .. code-block:: text. =default: Best scheduler for the target; =none: No scheduling: breadth first sequencing; =simple: Simple two pass scheduling: minimize critical path and maximize processor utilization; =simple-noitin: Simple two pass scheduling: Same as simple except using generic latency; =list-burr: Bottom-up register reduction list scheduling; =list-tdrr: Top-down register reduction list scheduling; =list-td: Top-down list scheduler. .. option:: -regalloc=allocator. Register allocator to use (default=linearscan). .. code-block:: text. =bigblock: Big-block register allocator; =linearscan: linear scan register allocator; =local: local register allocator; =simple: simple register allocator. .. option:: -relocation-model=model. Choose relocation model from:. .. code-block:: text. =default: Target default relocation model; =static: Non-relocatable code; =pic: Fully relocatable, position independent code; =dynamic-no-pic: Relocatable external references, non-relocatable code. .. option:: -spiller. Spiller to use (default=local). .. code-block:: text. =simple: simple spiller; =local: local spiller. .. option:: -x86-asm-syntax=syntax. Choose style of code to emit from X86 backend:. .. code-block:: text. =att: Emit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:4618,latency,latency,4618,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,1,['latency'],['latency']
Performance,"on; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246481,load,load,246481,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance,"onAST::codegen() {; ...; Builder->SetInsertPoint(BB);. // Record the function arguments in the NamedValues map.; NamedValues.clear();; for (auto &Arg : TheFunction->args()) {; // Create an alloca for this variable.; AllocaInst *Alloca = CreateEntryBlockAlloca(TheFunction, Arg.getName());. // Store the initial value into the alloca.; Builder->CreateStore(&Arg, Alloca);. // Add arguments to variable symbol table.; NamedValues[std::string(Arg.getName())] = Alloca;; }. if (Value *RetVal = Body->codegen()) {; ... For each argument, we make an alloca, store the input value to the; function into the alloca, and register the alloca as the memory location; for the argument. This method gets invoked by ``FunctionAST::codegen()``; right after it sets up the entry block for the function. The final missing piece is adding the mem2reg pass, which allows us to; get good codegen once again:. .. code-block:: c++. // Promote allocas to registers.; TheFPM->add(createPromoteMemoryToRegisterPass());; // Do simple ""peephole"" optimizations and bit-twiddling optzns.; TheFPM->add(createInstructionCombiningPass());; // Reassociate expressions.; TheFPM->add(createReassociatePass());; ... It is interesting to see what the code looks like before and after the; mem2reg optimization runs. For example, this is the before/after code; for our recursive fib function. Before the optimization:. .. code-block:: llvm. define double @fib(double %x) {; entry:; %x1 = alloca double; store double %x, double* %x1; %x2 = load double, double* %x1; %cmptmp = fcmp ult double %x2, 3.000000e+00; %booltmp = uitofp i1 %cmptmp to double; %ifcond = fcmp one double %booltmp, 0.000000e+00; br i1 %ifcond, label %then, label %else. then: ; preds = %entry; br label %ifcont. else: ; preds = %entry; %x3 = load double, double* %x1; %subtmp = fsub double %x3, 1.000000e+00; %calltmp = call double @fib(double %subtmp); %x4 = load double, double* %x1; %subtmp5 = fsub double %x4, 2.000000e+00; %calltmp6 = call double @fib(double %su",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:16680,optimiz,optimizations,16680,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['optimiz'],['optimizations']
Performance,"onDAG framework will; natively support the new node. In this case, you must also add code in your; node's case statement in ``LegalizeOp`` to Expand your node into simpler,; legal operations. The case for ``ISD::UREM`` for expanding a remainder into; a divide, multiply, and a subtract is a good example. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. If targets may support the new node being added only at certain sizes, you; will also need to add code to your node's case statement in ``LegalizeOp``; to Promote your node's operands to a larger size, and perform the correct; operation. You will also need to add code to ``PromoteOp`` to do this as; well. For a good example, see ``ISD::BSWAP``, which promotes its operand to; a wider size, performs the byteswap, and then shifts the correct bytes right; to emulate the narrower byteswap in the wider type. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add a case for your node in ``ExpandOp`` to teach the legalizer how to; perform the action represented by the new node on a value that has been split; into high and low halves. This case will be used to support your node with a; 64 bit operand on a 32 bit target. #. ``lib/CodeGen/SelectionDAG/DAGCombiner.cpp``:. If your node can be combined with itself, or other existing nodes in a; peephole-like fashion, add a visit function for it, and call that function; from. There are several good examples for simple combines you can do;; ``visitFABS`` and ``visitSRL`` are good starting places. #. ``lib/Target/PowerPC/PPCISelLowering.cpp``:. Each target has an implementation of the ``TargetLowering`` class, usually in; its own file (although some targets include it in the same file as the; DAGToDAGISel). The default behavior for a target is to assume that your new; node is legal for all types that are legal for that target. If this target; does not natively support your node, then tell the target to either Promote; it (if it is supported at a larger type) or Expand it. This will caus",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:5913,perform,perform,5913,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,1,['perform'],['perform']
Performance,"onal image.; dim:SQ_RSRC_IMG_2D Two-dimensional image.; dim:SQ_RSRC_IMG_3D Three-dimensional image.; dim:SQ_RSRC_IMG_CUBE Cubemap array.; dim:SQ_RSRC_IMG_1D_ARRAY One-dimensional image array.; dim:SQ_RSRC_IMG_2D_ARRAY Two-dimensional image array.; dim:SQ_RSRC_IMG_2D_MSAA Two-dimensional multi-sample auto-aliasing image.; dim:SQ_RSRC_IMG_2D_MSAA_ARRAY Two-dimensional multi-sample auto-aliasing image array.; =============================== =========================================================. dlc; ~~~. See a description :ref:`here<amdgpu_synid_dlc>`. Miscellaneous Modifiers; -----------------------. .. _amdgpu_synid_dlc:. dlc; ~~~. Controls device level cache policy for memory operations. Used for synchronization.; When specified, forces operation to bypass device level cache, making the operation device; level coherent. By default, instructions use device level cache. ======================================== ================================================; Syntax Description; ======================================== ================================================; dlc Bypass device level cache.; ======================================== ================================================. .. _amdgpu_synid_glc:. glc; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`slc<amdgpu_synid_slc>`; to specify cache policy. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; glc Set glc bit to 1.; ======================================== ================================================. .. _amdgpu_synid_lds:. lds; ~~~. Specifies where to store the result: VGPRs or LDS (VGPRs by default). ======================================== ===========================; Syntax Description; ==",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:17503,cache,cache,17503,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,1,['cache'],['cache']
