quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Testability,"@scott7z Well, my feeling is that would be too much work, which could be fostered elsewhere. Unless there is a defined criteria for working off a specific revision, it is usually less of a benefit to be tied to a specific release. It'll also make the cost of supporting it too much of a headache, as the other dependencies will continue to evolve. I always prefer to simplify and feel it's more practical to push compliance of dependencies to their maintainers, while expanding on the fun part of adding community-driven features. For example, there over 1000 commits between the two SHAs, and it would be hard to keep track of so many contributions:. ```Bash; $ git log | grep commit | cat -n | grep '97a4c226e8a9e7c5c36fc38e2b9f8459c77abd5a\|ab0fcaceda001825654424bf18e8a8e0f8d39df2'; 1 commit 97a4c226e8a9e7c5c36fc38e2b9f8459c77abd5a; 1244 commit ab0fcaceda001825654424bf18e8a8e0f8d39df2; $; ```. Usually more contributions to a dependency might provide us with more opportunities :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/19#issuecomment-353510712:667,log,log,667,,https://github.com/google/deepvariant/issues/19#issuecomment-353510712,1,['log'],['log']
Testability,"@sophienguyen01 , I can run a chr20 test on our end try to replicate. Looking at the code, the filtering logics are implemented [here](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/make_examples_core.py#L123). ```python; def _select_biallelic_snps(v):; return variant_utils.is_snp(v) and variant_utils.is_biallelic(v). def _select_biallelic_indels(v):; return variant_utils.is_indel(v) and variant_utils.is_biallelic(v). def _select_biallelic_insertions(v):; return variant_utils.has_insertion(v) and variant_utils.is_biallelic(v). def _select_biallelic_deletions(v):; return variant_utils.has_deletion(v) and variant_utils.is_biallelic(v). VARIANT_TYPE_SELECTORS = {; 'snps': _select_biallelic_snps,; 'indels': _select_biallelic_indels,; 'insertions': _select_biallelic_insertions,; 'deletions': _select_biallelic_deletions,; 'multi-allelics': variant_utils.is_multiallelic,; 'all': lambda v: True,; }; ```. And the filtering logic is implemented [here](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/make_examples_core.py#L905). . It looks like `--select_variant_types='indels multi-allelics'` will give you all multi-allelic indels too. I am unsure if it will solve the issue because the VCF you provided before also misses bi-allelic indels. I will need to debug it further to see if there's something missing. Meanwhile, you can use `--select_variant_types='indels multi-allelics'` to see if it fixes your issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/813#issuecomment-2091037482:36,test,test,36,,https://github.com/google/deepvariant/issues/813#issuecomment-2091037482,3,"['log', 'test']","['logic', 'logics', 'test']"
Testability,"@sophienguyen01 - from the log file it looks like everything worked. Here are all the tune/categorical accuracies from your training data. ```; tune/categorical_accuracy=0.9944317936897278; tune/categorical_accuracy=0.9909400343894958; tune/categorical_accuracy=0.9915463924407959; tune/categorical_accuracy=0.9925118088722229; tune/categorical_accuracy=0.9921825528144836; tune/categorical_accuracy=0.9924613237380981; tune/categorical_accuracy=0.9926846623420715; tune/categorical_accuracy=0.9929667711257935; tune/categorical_accuracy=0.9925829172134399; tune/categorical_accuracy=0.9926416277885437; tune/categorical_accuracy=0.9923893213272095; tune/categorical_accuracy=0.9925225377082825; ```. The first number represents accuracy direct from the pretrained model. Since none of the subsequent tuning evaluations outperformed the original, no checkpoints were created. One thing you could try: reduce the learning rate, and see if that helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2042819603:27,log,log,27,,https://github.com/google/deepvariant/issues/802#issuecomment-2042819603,1,['log'],['log']
Testability,"@sophienguyen01 For DeepVariant production models we generally train on chr1-19, tune on chr21-22, and save chr20 for final ""test"" or ""inference"" evaluations. When we have enough samples we'll leave out a whole sample; for most (maybe all) of our production models this is currently HG003 that is never seen during training (or tune), only kept for inference. It's important to do this train/tune/test split at the sample level and/or chromosome level so DeepVariant can't overfit to the specific variants it sees, which it could if you for example left out one of two bam files that came from the same sample.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/698#issuecomment-1681392580:125,test,test,125,,https://github.com/google/deepvariant/issues/698#issuecomment-1681392580,2,['test'],['test']
Testability,"@sophienguyen01 the logs indicate checkpoints are output:. ```; I0423 18:41:59.026870 139913113728832 train.py:456] Saved checkpoint tune/f1_weighted=0.9114237 step=3352 epoch=1 path=model_train/checkpoints/ckpt-3352; I0423 18:44:53.215049 139913113728832 train.py:456] Saved checkpoint tune/f1_weighted=0.91949123 step=6704 epoch=2 path=model_train/checkpoints/ckpt-6704; I0423 18:47:47.292658 139913113728832 train.py:456] Saved checkpoint tune/f1_weighted=0.92320794 step=10056 epoch=3 path=model_train/checkpoints/ckpt-10056; ```. But as @kishwarshafin suggests, the warnings at the end are normal and can be ignored.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2073372104:20,log,logs,20,,https://github.com/google/deepvariant/issues/802#issuecomment-2073372104,1,['log'],['logs']
Testability,@splaisan if the quickstart runs and the timing is acceptable to you then you can use the Docker image as is. Otherwise you can [build from source](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-build-test.md),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/452#issuecomment-1496617163:219,test,test,219,,https://github.com/google/deepvariant/issues/452#issuecomment-1496617163,1,['test'],['test']
Testability,"@vinisalazar Can you create a gist or attach a complete log of what you see when you run `./build-prereq.sh`? Also if you type `which bazel` what does show up? It might not be in your path. Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/98#issuecomment-424863854:56,log,log,56,,https://github.com/google/deepvariant/issues/98#issuecomment-424863854,1,['log'],['log']
Testability,"@zyxue Two small questions:. 1) Do you have a NVidia GPU on the machine you are running DeepVariant on?. 2) If you type `find / -name ""*libcublas*"" -print 2>/dev/null` on the command prompt, do you see something similar to this:. ```; $ find / -name ""*libcublas*"" -print 2>/dev/null; /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.7; /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.so.7; /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_static.a; /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so; /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_device.a; /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5; /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5.18; /opt/apps/cuda75/sdk/7.5.18/lib64/stubs/libcublas.so; $; ```. Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/102#issuecomment-429139266:692,stub,stubs,692,,https://github.com/google/deepvariant/issues/102#issuecomment-429139266,1,['stub'],['stubs']
Testability,Actually the answer is right in front of you - you don't need the logs. The prize goes to the first one who sees it :),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437081677:66,log,logs,66,,https://github.com/google/deepvariant/issues/116#issuecomment-437081677,1,['log'],['logs']
Testability,"Actually those messages might not be a warning, ""The above is not a warning and is just a point of information.""; https://discuss.tensorflow.org/t/tensorflow-with-proper-compiler-flag-error-message/12393/3. Now I will try with the test quickstart run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575652409:231,test,test,231,,https://github.com/google/deepvariant/issues/657#issuecomment-1575652409,1,['test'],['test']
Testability,"Actually, when I took a closer look at the logs, it says:. ```; 2023-03-16 05:35:30.141288: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; 2023-03-16 05:35:30.141355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: pichuan-gpu2; 2023-03-16 05:35:30.141366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: pichuan-gpu2; 2023-03-16 05:35:30.141423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; 2023-03-16 05:35:30.141471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 530.30.2; ```. So it seems like I'm able to reproduce this issue. . Let me take a closer look. I'll also want to test this on Ubuntu. I tested before release, but I'll want to test it again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471376570:43,log,logs,43,,https://github.com/google/deepvariant/issues/619#issuecomment-1471376570,4,"['log', 'test']","['logs', 'test', 'tested']"
Testability,"After updating to v0.9.0 we have different results:. <details>; <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```; ##fileformat=VCFv4.2; ##FILTER=<ID=PASS,Description=""All filters passed"">; ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">; ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">; ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">; ##contig=<ID=chr20,length=63025520>; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878; chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0; chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37; chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51; chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0; chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0; chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47; chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0; chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34; chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0; chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0; chr20	100014",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/239#issuecomment-558061938:77,test,test,77,,https://github.com/google/deepvariant/issues/239#issuecomment-558061938,1,['test'],['test']
Testability,"Again, please share workers log so we can help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437187170:28,log,log,28,,https://github.com/google/deepvariant/issues/116#issuecomment-437187170,1,['log'],['log']
Testability,"Also, if I try to follow your instructions for an EC2 instance, I can't actually create a _t1.micro_ EC2 instance, but I can create a **t2.micro** EC2 instance (with 1 vCPU and 1 GB of RAM). I remember spending some effort to try and install Docker on the EC2 instance. That installation is quite quick, and I almost wondered if I hadn't somehow didn't test `sudo yum install docker`. However, there was slow-down after pulling the docker image (possibly due to the type of instance?). If I sign into another terminal and try to run `docker images` (to confirm that everything worked OK), I get the following error message:. `Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.38/images/json: dial unix /var/run/docker.sock: connect: permission denied`. Strictly speaking, I was running the script rather than just the pull command. So, when the 1st terminal stopped running (in approximately 5-10 minutes), I still got the same error message that I started with:. ```; sudo sh run_deepvariant.sh; Unable to find image 'gcr.io/deepvariant-docker/deepvariant:latest' locally; latest: Pulling from deepvariant-docker/deepvariant; 18d680d61657: Pull complete; 0addb6fece63: Pull complete; 78e58219b215: Pull complete; eb6959a66df2: Pull complete; 54de1d38bbd7: Pull complete; d17c3563217d: Pull complete; ba1bdbdefce9: Pull complete; 94eba53c4ad9: Pull complete; 413f494b0501: Pull complete; 4d89363e7fb4: Pull complete; e9213d1ccf36: Pull complete; fb6121657d6b: Pull complete; Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f; Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:latest; docker images; terminate called after throwing an instance of 'std::bad_alloc'; what(): std::bad_alloc; ```. _[I entered ""docker images"" when I didn't see anything, so that is input, not output]_. However, I then get that ""docker.sock"" error message if I try to run `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480642492:353,test,test,353,,https://github.com/google/deepvariant/issues/167#issuecomment-480642492,1,['test'],['test']
Testability,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-479522653:235,test,testing,235,,https://github.com/google/deepvariant/issues/167#issuecomment-479522653,2,['test'],"['test', 'testing']"
Testability,"Also, when we tried to run `call_varaints.zip` with a training checkpoint we just found earlier, it failed with this exception below. We are not entirely sure what we did wrong. We just used your command to train and the command in the case study to run the model to produce variants; ```; root@qiuz-deepvariant-quickstart:~/case-study/output/logs# cat call_variants.log; WARNING: Logging before flag parsing goes to stderr.; I0209 02:46:47.705486 139970286499584 htslib_gcp_oauth.py:82] GCP credentials found; will be able to access non-public gs:// URIs from htslib; 2018-02-09 02:46:50.318843: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA; I0209 02:46:51.237144 139970286499584 call_variants.py:325] Initializing model from /root/case-study/output/model.ckpt; 2018-02-09 02:46:51.248949: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /root/case-study/output/model.ckpt: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_lnD8hJ/runfiles/genomics/deepvariant/call_variants.py"", line 387, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run; _sys.exit(main(_sys.argv[:1] + flags_passthrough)); File ""/tmp/Bazel.runfiles_lnD8hJ/runfiles/genomics/deepvariant/call_variants.py"", line 378, in main; batch_size=FLAGS.batch_size); File ""/tmp/Bazel.runfiles_lnD8hJ/runfiles/genomics/deepvariant/call_variants.py"", line 326, in call_variants; model.initialize_from_checkpoint(checkpoint_path, 3, False)(sess); File ""/tmp/Bazel.runfiles_lnD8hJ/runfiles/genomics/deepvariant/modeling.py"", line 298, in initialize_from_checkpoint; [self.n_classes_model_variable]); File ""/tmp/Bazel.runfiles_lnD8hJ/runfiles/genomics/deepvariant/tf_utils.py"", line 264, in model_sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/46#issuecomment-364502198:343,log,logs,343,,https://github.com/google/deepvariant/issues/46#issuecomment-364502198,3,"['Log', 'log']","['Logging', 'log', 'logs']"
Testability,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```; terminate called after throwing an instance of 'std::system_error'; what(): Resource temporarily unavailable; ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-482393946:40,test,testing,40,,https://github.com/google/deepvariant/issues/167#issuecomment-482393946,1,['test'],['testing']
Testability,"And, follow up on @akolesnikov 's point, if you have gotten to this point, it would seem like these files should be complete?. ```; /output/HG002.g.vcf.gz \; /output/HG003.g.vcf.gz \; /output/HG004.g.vcf.gz \; ```. If you can examine those files and confirm, that will be great. (Or look at the log like I mentioned before. But given you have the files, checking the files directly might be easier :))",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/815#issuecomment-2096635722:295,log,log,295,,https://github.com/google/deepvariant/issues/815#issuecomment-2096635722,1,['log'],['log']
Testability,"Another test-; I've ran the WES exactly like it is with your test files (fasta bam and bed) and again I get this same error: ; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --regions /input/idt_capture_novogene.grch38.bed --task 3. In this example it also not working for a specific region ""chr20:10000000-10010000"" (some intermediate files are created but not the vcf file). The Error:; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --regions chr20:10000000-10010000 --task 0; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --regions chr20:10000000-10010000 --task 1; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --regions chr20:10000000-10010000 --task 2; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --gvcf /output/intermediate_res",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/483#issuecomment-917342943:8,test,test,8,,https://github.com/google/deepvariant/issues/483#issuecomment-917342943,2,['test'],['test']
Testability,"As @AndrewCarroll said, we need workers log to investigate the failure. Please share workers log (you should be able to find them under `gs://canis/CNR-data/deep_variant_files/logs`).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437076116:40,log,log,40,,https://github.com/google/deepvariant/issues/116#issuecomment-437076116,3,['log'],"['log', 'logs']"
Testability,"As these are sorted reads, by just looking at the BAM file, it starts with position 60001, as shown here - which why you are getting 0 candidates:. ```; 55ad4f97_28026_0 0 chr20 60001 50 618S27M1D8M1I6M1D7M1D5M1I9M1I5M1D20M1D8M1I24M1I35M1I9M1I2M1I1M1I52M1D3M1D15M2D4M2D12M1I21M1I5M1; D11M1D7M1I18M1I15M1D1M1D43M1I16M1D8M1I21M1D2M1D7M1I10M1I2M1D8M1D5M1D3M1D2M1I13M1D28M1I20M1I4M1I37M1I19M1I21M1D18M1I5M1D16M1I1M1I3M1I29M1I12M1D6M1I2M1I7; M1D1M1D2M1I4M1D22M1D18M1I4M1D12M1D4M1I1M1I3M2I17M1I1M1I44M1D3M1D2M1D10M1I11M2D1M1D9M1I19M1D2M1I32M1D2M1D8M1D20M1I14M1D6M1D15M1I7M1D3M1D25M1I6M1I8M1D11M; 1I7M1I11M1I12M1D2M1D3M1I70M1I23M1D3M1I48M1I21M1I46M1D14M1I3M1D10M1I6M1D34M2I8M1I11M1I5M1I10M1D8M1I8M1I14M1D19M1I26M1I6M1I13M1D4M1I2M1I33M1I8M1I7M1I12M1I1M1I4M1I8M1I3M1I1M1I3M2I4M1I14M1I1M1I5M1I1M1I1M1I2M2I2M1I3M1I1M4I3M1I1M1I1M2I3M4I5M1I3M1I1M1I3M3I5M1I6M1I2M1I1M2I1M1I7M1I3M2I3M1I5M2I1M2I4M1I1M1I2M1D4M1I6M1I3M1I2M1I1M4I1M1I1M2I5M1I3M1I3M1I2M1D1M1I2M2I1M1I1M1I4M3I1M2I2M1I6M1I4M3I1M3I1M3I8M2I47M1I11M1I8M1D3M1I1M1I30M1I15M1I6M1I17M1D18M1D4M1I19M1I28M1D37M1I23M1D7M1D21M1D79M1I12M1D1M1D9M1I21M1D44M1D30M1D3M1I13M1I9M1I34M1D10M1I; ```; Since no PHRED value is stored with a `*`, as shown here:. ```; AGTCTGCTTCATGCCTTTAACT * AS:i:-15583 ; ```; This is why the read triggers the assertion failure [here](https://github.com/google/deepvariant/blob/master/deepvariant/allelecounter.cc#L103):. ```C++; CHECK_LE(offset + len, read.aligned_quality_size());; ```. The preferred response that would be nice, is if the code could just identify which read (QNAME) it is referring to in order to verify this, or just have a flag to ignore reads that one has no QUAL score for. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-457426984:1267,assert,assertion,1267,,https://github.com/google/deepvariant/issues/138#issuecomment-457426984,1,['assert'],['assertion']
Testability,"Before you proceed, if you can't use Docker because of root permission, I recommend that you try Singularity: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity. If you don't have root permission, you won't be able to install necessary things before running the binaries either. ---. Here is what I did:. Get a machine. (Not required to run on GCP. I just use this to get a machine to test). `gcloud compute instances create ""${USER}-cpu"" --scopes ""compute-rw,storage-full,cloud-platform"" --image-family ""ubuntu-2004-lts"" --image-project ""ubuntu-os-cloud"" --machine-type ""custom-64-131072"" --boot-disk-size ""300"" --zone ""us-west2-b"" --min-cpu-platform ""Intel Skylake""`. ssh into the machine:. ```; gcloud compute ssh pichuan-cpu --zone us-west2-b; ```. Get the binaries and models:. ```; BUCKET=""gs://deepvariant""; BIN_VERSION=""1.4.0""; MODEL_VERSION=""1.4.0"". BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}""; MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". mkdir -p bin; # Download the DeepVariant binaries.; gsutil -m cp ""${BIN_BUCKET}/*"" bin/; chmod a+x bin/*; ```. Then, I ran:; ```; cd bin; bash run-prereq.sh; cd -; ```. The `run-prereq.sh` tends to be the most tricky one - it will require root permission, and it'll install a bunch of stuff on your machine. If you can't use Docker because of root permissions, you likely won't be able to run this as well. Download test data:. ```; INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/590#issuecomment-1322695241:435,test,test,435,,https://github.com/google/deepvariant/issues/590#issuecomment-1322695241,1,['test'],['test']
Testability,"Building a deepvariant Singularity image is indeed really quite simple and portable. I did it and test it on CentOS7 and MacOS X and it run in both case with deepvariant quick-test data. I will post the complete ""how-to"" when I'll have a couple of minutes.; Thank's ink1 for the idea.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/6#issuecomment-372953552:98,test,test,98,,https://github.com/google/deepvariant/issues/6#issuecomment-372953552,2,['test'],['test']
Testability,"By the way, I'll add a pointer from deepvariant-build-test.md to https://github.com/google/deepvariant/issues/756#issuecomment-1865388872. The change will come out in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/756#issuecomment-1865519973:54,test,test,54,,https://github.com/google/deepvariant/issues/756#issuecomment-1865519973,1,['test'],['test']
Testability,"Can you verify TF examples (test.gvcf.tfrecord-*) are in ${BASE} path?. If you use DeepVariant's cloud runner, you won't need to do all these steps manually. It takes care of everything and runs the pipeline on GCP. See instruction here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant. Is there any reason why you don't use cloud runner?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461288578:28,test,test,28,,https://github.com/google/deepvariant/issues/151#issuecomment-461288578,1,['test'],['test']
Testability,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you?. ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/574#issuecomment-1277509481:800,log,log,800,,https://github.com/google/deepvariant/issues/574#issuecomment-1277509481,1,['log'],['log']
Testability,D in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log; //deepvariant/labeler:haplotype_labeler_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log; //deepvariant/labeler:labeled_examples_to_vcf_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log; //deepvariant/labeler:positional_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log; //deepvariant/labeler:variant_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/p,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:120104,test,testlogs,120104,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,D in 0.5s; //deepvariant:variant_calling_test (cached) PASSED in 0.6s; //deepvariant/environment_tests:env_smoke_test (cached) PASSED in 0.7s; //deepvariant/environment_tests:protobuf_implementation_test (cached) PASSED in 1.2s; //deepvariant/realigner:fast_pass_aligner_test (cached) PASSED in 0.6s; //deepvariant/realigner:ssw_test (cached) PASSED in 0.5s; //deepvariant/realigner/python:ssw_misc_test (cached) PASSED in 0.9s; //deepvariant/realigner/python:ssw_wrap_test (cached) PASSED in 1.2s; //deepvariant/vendor:timer_test (cached) PASSED in 0.7s; //deepvariant:call_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log; //deepvariant:data_providers_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log; //deepvariant:haplotypes_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvaria,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:118411,log,log,118411,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"Dear Andrew,. Thank you for your quick reply. I agree with you that most sequencing and; resequencing projects will move towards HiFi reads rather than CLR reads.; However, there is a lot of CLR sequencing data that has been generated in; the past couple of years and continues to be produced currently and could; still be useful for groups without the means to resequence using the novel; HiFi reads. So, I definitely see a niche in a large part of the; bioinformatics community that do a lot of data reusing (nowadays data; parasites). So, if there is anything we can do to help you n development,; please feel free to let me know how we can collaborate. Kind regards,. Juan D. Montenegro. El mar., 15 sept. 2020 a las 18:37, Andrew Carroll (<; notifications@github.com>) escribió:. > Hi @jdmontenegro <https://github.com/jdmontenegro>; >; > For the question about multi-allelic heterozygous calls - yes, DeepVariant; > is able to all 1/2 events, and will represent these in one line as a GT 1/2; > call in the VCF.; >; > For CLR calling in DeepVariant. It is theoretically possible for us to; > make a model for DeepVariant that can call CLR data. However, this requires; > us to write a special candidate generation logic to deal with the higher; > error rate. Based on what we perceive for the direction of future use in; > the genomics community, we think that data generated will be increasingly; > HiFi, so we have not been able to highly prioritize CLR models. Feedback; > from users like yourself will be useful to us in evaluating if that; > prioritization makes sense. For now, I can't commit to a timeframe under; > which we would support a PacBio CLR model.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/347#issuecomment-693053180>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ACHSLOV5RPVLTVGDW2A44X3SF73E7ANCNFSM4RNQJZYQ>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/347#issuecomment-693080237:1220,log,logic,1220,,https://github.com/google/deepvariant/issues/347#issuecomment-693080237,1,['log'],['logic']
Testability,"Dear Paul,. Thank you for you suggestions about STR analysis! . Please do not apologize, as you have indeed helped me a lot and saved me a lot of time. Thank you for providing very professional guidance on Deepvariant. I am still unable to reach a conclusion on whether deepvariant can be used in some way on logically paired samples, so I will take a look at the HipSTR and deep repeat you provided, which may be helpful for my research. Thank you very much!. Wich you have a nice day!. Ji",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/697#issuecomment-1683275474:309,log,logically,309,,https://github.com/google/deepvariant/issues/697#issuecomment-1683275474,1,['log'],['logically']
Testability,"Dear Paul:; Thank you so much for the speedy reply.; I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:; /share/app/singularity/3.8.1/bin/singularity exec \; --containall \; --bind /usr/lib/locale/:/usr/lib/locale/ \; --bind $ccsbam:$ccsbam \; --bind $ccsbam.bai:$ccsbam.bai \; --bind $fasta:$fasta \; --bind $fasta.fai:$fasta.fai \; --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \; /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****; time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main; return _run_code(code, main_globals, None,; File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300:55,test,tested,55,,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300,1,['test'],['tested']
Testability,"Dear Pi-Chuan,. Thanks for pointing out the worker log files since I didn't realize the files are log files. ; It is really helpful!. The error comes from the inappropriate bam index file name I used (*.bai instead of *.bam.bai) as the log file describes: ; CommandException: No URLs matched: gs://input_bam/IO_045.sam_sorted_dedup.bam.bai. After changing the bam index file name, the pipeline works now! ; Thank you so much for your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/120#issuecomment-439734780:51,log,log,51,,https://github.com/google/deepvariant/issues/120#issuecomment-439734780,3,['log'],['log']
Testability,"DeepVariant v1.0 includes two additional channels which align reads to the ALT sequences (with the channels being different when more than one ALT allele is present). . Even if the model shapes between versions are compatible, it is not a good idea to apply the model from one version with the machinery of another. This is because the training process for each model uses the machinery of that same version. I am not sure I understand the reason to use a model trained on only the v3.3.2 examples? The v4.2 truth set is more comprehensive and correct. It would be better to use chromsome20, which is always fully withheld from all training as a benchmark. Starting from the next release, we will fully withhold HG003 from all PacBio training.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/381#issuecomment-727742145:646,benchmark,benchmark,646,,https://github.com/google/deepvariant/issues/381#issuecomment-727742145,1,['benchmark'],['benchmark']
Testability,"Did openvino make it into deeptrio-1.2.0? From some quick tests, it doesn't look like it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/416#issuecomment-889450969:58,test,tests,58,,https://github.com/google/deepvariant/issues/416#issuecomment-889450969,1,['test'],['tests']
Testability,Did you run `tensorflow.test.is_gpu_available()` from the DeepVariant docker?. Could you try the suggestion from this [thread](https://stackoverflow.com/questions/48658204/tensorflow-failed-call-to-cuinit-cuda-error-no-device),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/820#issuecomment-2125953311:24,test,test,24,,https://github.com/google/deepvariant/issues/820#issuecomment-2125953311,1,['test'],['test']
Testability,"Do you see any other error messages higher up in the logs? The CalledProcessError is just the wrapper, so it doesn't tell us what went wrong inside make_examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/419#issuecomment-774270943:53,log,logs,53,,https://github.com/google/deepvariant/issues/419#issuecomment-774270943,1,['log'],['logs']
Testability,"ER}-centos8"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""centos-8"" \; --image-project ""centos-cloud"" \; --machine-type ""e2-standard-16"" \; --boot-disk-size ""200G"" \; --zone ""us-west1-b""; ```. ssh into the machine:; ```; gcloud compute ssh ${USER}-centos8; ```. Check OS version:; ```; [pichuan@pichuan-centos8 ~]$ cat /etc/os-release; NAME=""CentOS Linux""; VERSION=""8""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""8""; PLATFORM_ID=""platform:el8""; PRETTY_NAME=""CentOS Linux 8""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:8""; HOME_URL=""https://centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/""; CENTOS_MANTISBT_PROJECT=""CentOS-8""; CENTOS_MANTISBT_PROJECT_VERSION=""8""; ```. I installed singularity on the machine following instructions on https://sylabs.io/guides/3.7/admin-guide/installation.html#installation-on-linux. Confirmed the version:; ```; [pichuan@pichuan-centos8 ~]$ singularity --version; singularity version 3.7.0-1.el8; ```. I'm using the data in Quick Start to test. I downloaded data in the Quick Start: https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md. Then, I ran:; ```; BIN_VERSION=1.1.0. singularity build deepvariant.sif docker://google/deepvariant:${BIN_VERSION}. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1; ```. After this, examine the content in ""${OUTPUT_DIR}/intermediate_results_dir"". ```; [pichuan@pichuan-centos8 ~]$ ls -1 ""${OUTPUT_DIR}/intermediate_results_dir""; call_variants_output.tfrecord.gz; gvcf.tfrecord-00000-of-00001.gz; make_examples.tfrecord-00000-of-00001.gz",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/296#issuecomment-767294612:1833,test,test,1833,,https://github.com/google/deepvariant/issues/296#issuecomment-767294612,1,['test'],['test']
Testability,"E_DIR.: stat /run/user/3019658: no such fil e or directory: Trying to pull image in the event that it is a public image.; I0327 13:31:58.252949 47794500922048 run_deepvariant.py:241] Re-using the directory fo r intermediate results in /tmp/tmp63xxmwmi. ***** Intermediate results will be written to /tmp/tmp63xxmwmi in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mo de calling --ref ""/scratch/moldach/bin/quickstart-testdata/ucsc.hg19.chr20.unittest.fa sta"" --reads ""/scratch/moldach/bin/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmp63xxmwmi/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmp63xxmwmi/gv cf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I0327 13:32:07.160181 47175299967680 make_examples.py:386] ReadRequirements are: min_m apping_quality: 10; min_base_quality: 10; min_base_quality_mode: ENFORCED_BY_CLIENT. I0327 13:32:07.206463 47175299967680 genomics_reader.py:223] Reading /scratch/moldach/ bin/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0327 13:32:07.218669 47175299967680 make_examples.py:535] Preparing inputs; I0327 13:32:07.293092 47175299967680 genomics_reader.py:223] Reading /scratch/moldach/ bin/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0327 13:32:07.294783 47175299967680 make_examples.py:535] Common contigs are ['chr20' ]; I0327 13:32:07.296233 47175299967680 make_examples.py:535] Writing ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-605306987:2115,log,login,2115,,https://github.com/google/deepvariant/issues/287#issuecomment-605306987,1,['log'],['login']
Testability,"Error as before (from `make_examples.log` file):. ```; 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs; 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'; [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi; [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi; I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run; _sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main; make_examples_runner(options); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner; regions = processing_regions_from_options(options); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-448201709:2367,test,testdata,2367,,https://github.com/google/deepvariant/issues/128#issuecomment-448201709,1,['test'],['testdata']
Testability,"FILE_NAME=WGS_Provided.vcf. ## Model for calling whole genome sequencing data.; MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2; DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}""; COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \; --project ${PROJECT_ID} \; --zones us-west2-* \; --sample_name VeritasProvided \; --docker_image ${DOCKER_IMAGE} \; --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \; --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \; --model ${MODEL} \; --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \; --ref gs://cdw-genome/Ref/hg19.gatk.fasta \; --gcsfuse""; ; # Run the pipeline.; # run after 'gcloud config set compute/region """"'; gcloud alpha genomics pipelines run \; --project ""${PROJECT_ID}"" \; --regions us-west2 \; --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \; --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \; 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \; --command-line ""${COMMAND}""; ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483490946:1492,log,logging,1492,,https://github.com/google/deepvariant/issues/171#issuecomment-483490946,1,['log'],['logging']
Testability,"FYI, I'm not sure if this is the best solution, but I noticed that running in my home directory avoids the need to use _sudo_. While I am still encountering the same result (and I thought I encountered some issue with running Docker interactively at another step), I do have the ability to launch Docker in my home directory in interactive mode:. `docker run -it -v /mnt/efs-genome:/mnt/efs-genome gcr.io/deepvariant-docker/deepvariant`. and then run the commands for :. ```; OUTPUT_DIR=/mnt/efs-genome/Charles_Human/Genos_Exome/Genos_Alignment/DeepVariant; REF=/mnt/efs-genome/Ref/hg19.gatk.fasta; CALL_VARIANTS_OUTPUT=""${OUTPUT_DIR}/call_variants_output.tfrecord.gz""; FINAL_OUTPUT_VCF=""${OUTPUT_DIR}/output.vcf.gz"". /opt/deepvariant/bin/postprocess_variants \; --ref ""${REF}"" \; --infile ""${CALL_VARIANTS_OUTPUT}"" \; --outfile ""${FINAL_OUTPUT_VCF}""; ```. Again, I am neither seeing an error message nor a result file (and the command stops running within seconds). However, if this provides a useful option for troubleshooting, I thought I should mention it. Also, I am starting the Google Cloud testing, but I am currently only at the file upload stage (I want to make sure I can run the 1st two steps, before checking that as a solution for the 3rd step). Thank you very much for your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480628311:1098,test,testing,1098,,https://github.com/google/deepvariant/issues/167#issuecomment-480628311,1,['test'],['testing']
Testability,"First of all, I assume that you have access to `gs://canis/CNR-data/exomes.bed` file?; If you do:; `gsutil cat gs://canis/CNR-data/exomes.bed` from the project that has the same permission, you can first double check that you have access to it. And, I don't fully understand how gcsfuse is implemented in the Google Cloud runner, so I'll defer this to our collaborator at Cloud @nmousavi -- Nima, in the command in the previous log, particularly this one:; `mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs canis /input-gcsfused-0 && /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/canis/CNR-data/deep_variant_files/examples/0/examples_output.tfrecord@8.gz --reads /input-gcsfused-0/CNR-data/TLE_a_001.reheader.bam --ref /mnt/google/.google/input/deepvariant/performance-testdata/hs37d5.fa.gz --task 0 --regions gs://canis/CNR-data/exomes.bed`. It seems weird to me that everything else has been changed to under `/input-gcsfused-0` or `/mnt`, but the BED file still has a `gs://` prefix. This seems to me like something might be wrong in how the runner is using gcsfuse on the BED file. Can you take a look?. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437712479:428,log,log,428,,https://github.com/google/deepvariant/issues/116#issuecomment-437712479,2,"['log', 'test']","['log', 'testdata']"
Testability,Flow `r1.12` installed duing the deepvariant build is looking for CUDA 9:. ```; FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; (05:40:51) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:1236,log,log,1236,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"Follow up: I looked my older work log -- I actually did test the Singularity+OpenVINO combination. I didn't see any issues at the time. I repeated my steps, and still found that **I wasn't able to reproduce your issue, if I'm running in a directory where I have write access.** But, I'm able to see the same issue, if I start my command in a directory where I can't write to. I have two questions for you:; (1) When you run the command, do you have write permission to the directory you're in? (Based on the current code, that's where the converted model files are written to.); (2) What is your Singularity version?. I listed all my steps below in case it's useful. ---. # Worklog. ## Get a Ubuntu16.04 machine; I used the [command here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-details.md#command-for-a-cpu-only-machine-on-google-cloud-platform) to get a Ubuntu16.04 machine. ## Set up on the machine; After ssh into the machine, before start running the [PacBio tutorial](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md), I'll install things first:. ```; curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; bash Miniconda3-latest-Linux-x86_64.sh; ```; After installing conda, I logged out and re-logged in. I install Singularity:; ```; curl -O https://raw.githubusercontent.com/google/deepvariant/r1.1/scripts/install_singularity.sh; bash install_singularity.sh; ```. Here is my Singularity version:; ```; (base) pichuan@pichuan-cpu:~$ singularity --version; singularity version 3.3.0-1; ```. ## Run through PacBio tutorial; I follow the steps here:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md; and ran through all commands set up conda, and download all files. When I get to this step:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md#run-deepvariant-on-chromosome-20-alignments. I added `--call_variants_extr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-761309014:34,log,log,34,,https://github.com/google/deepvariant/issues/404#issuecomment-761309014,2,"['log', 'test']","['log', 'test']"
Testability,"Following up on my previous comment,; I confirmed that hap.py results in `happy.output.summary.csv` are the same. @dkurt One thing similar to what I observed before: call_variants with openvino seems to block at the beginning for quite a bit before it starts printing each of the logs:. ```. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp0gfwv278/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp0gfwv278/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino. I1128 03:33:00.717135 139674856871680 call_variants.py:338] Shape of input examples: [100, 221, 6]; 2020-11-28 03:33:00.726560: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 AVX512F FMA; To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.; 2020-11-28 03:33:00.742278: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000175000 Hz; 2020-11-28 03:33:00.748254: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x419c1f0 executing computations on platform Host. Devices:; 2020-11-28 03:33:00.748310: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version; 2020-11-28 03:33:00.752221: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; W1128 03:33:02.766410 139674856871680 deprecation.py:323] From /tmp/Bazel.runfiles_rud4ovxa/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.; Instructions for updating:; Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735276922:280,log,logs,280,,https://github.com/google/deepvariant/pull/363#issuecomment-735276922,1,['log'],['logs']
Testability,"For the v1.5.0 release we did not train a new RNA-seq model and therefore did not release a new model. You can stick with v1.4.0 model+codebase to run the RNA-seq model or you can use this v1.4.0 model with the v1.5.0 codebase (we have not tested directly, but it should work). Please let me know if you run into any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/624#issuecomment-1485499295:240,test,tested,240,,https://github.com/google/deepvariant/issues/624#issuecomment-1485499295,1,['test'],['tested']
Testability,"From the log it seems like there's something to do with your authentication to the Google Cloud Platform. But usually this shouldn't fail even if you didn't set that up. Can you give us a bit more description about your machine? (OS version, if you're running on cloud, where and what type of machine, etc)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/7#issuecomment-350520174:9,log,log,9,,https://github.com/google/deepvariant/issues/7#issuecomment-350520174,1,['log'],['log']
Testability,"From the log, it seems like the issue is that `bazel` was not installed.; After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits?; And, if install bazel failed for you, can you paste the part of log of how the installation failed for you?. By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/89#issuecomment-415797913:9,log,log,9,,https://github.com/google/deepvariant/issues/89#issuecomment-415797913,2,['log'],['log']
Testability,"From your log, I suspect that the postprocess_variants step failed.; Your log only shows this:. ```; ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878; 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz; ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step?. ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: ; https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/868#issuecomment-2286801983:10,log,log,10,,https://github.com/google/deepvariant/issues/868#issuecomment-2286801983,2,['log'],['log']
Testability,"G002, 1 HG002, 1 HG004 | 99,675,190<sup>[(5)](#vfootnote5)</sup> |; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/HG002_ONT_deeptrio.denovo.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/customized_classes.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_gvcf_output.g.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.vcf_candidate_importer.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00001-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_single_site_output.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/HG002_ONT_deeptrio.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/golden.vcf_candidate_importer.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040:2895,test,testdata,2895,,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040,1,['test'],['testdata']
Testability,"G004, 1 HG005, 1 HG006, 1 HG007 | 838,515,085<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 1 HG002, 1 HG002, 1 HG004 | 50,249,704<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 1 HG002, 1 HG002, 1 HG004 | 99,675,190<sup>[(5)](#vfootnote5)</sup> |; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/HG002_ONT_deeptrio.denovo.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/customized_classes.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_gvcf_output.g.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.vcf_candidate_importer.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00001-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_single_site_output.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/HG002_ONT_deeptrio.examples.tfrecord.gz.example_info.json:{""ve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040:2641,test,testdata,2641,,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040,1,['test'],['testdata']
Testability,"Glad it helped Sophie! Currently yes, though DeepVariant can easily be ported to multiple GPUs with many other optimizations, that would probably be at a later time. Even if you think about the called variants, those are locus-specific and multiple regions can run across multiple GPUs. For counting alleles in the `make_examples` stage, that would be the same thing that can be taken advantage of [as illustrated by the benchmark of its sub-stages](https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md) -- and there are GPU-based Smith-Waterman aligners that are 8x-20x faster than CPU. Distributing for speedup the collecting/transforming/sorting in the last stage of post-processing the variants is only natural, and that can subsequently also provide logarithmic combines -- including other optimizations, which would be aided by utilizing changes in the previous stage. So the future is very bright, but again that would be something for a later time :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/696#issuecomment-1679436458:421,benchmark,benchmark,421,,https://github.com/google/deepvariant/issues/696#issuecomment-1679436458,2,"['benchmark', 'log']","['benchmark', 'logarithmic']"
Testability,Got it. My first test run did finish successfully and the hap.py numbers are the same as before.; I'm now running a few bigger runs to take a look at the runtime.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/523#issuecomment-1069288915:17,test,test,17,,https://github.com/google/deepvariant/pull/523#issuecomment-1069288915,1,['test'],['test']
Testability,"Great! The logs you posted confirmed that the checkpoints were not being written, but it's not clear _why_ that was the case. I will close this issue for now, but please don't hesitate to reopen if you encounter it again!. To your second question, that's correct! In 1.6, we migrated our training and inference platform from Slim to Keras, and as part of this effort we combined `model_train` and `model_eval` with a single executable `train` to make training easier.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2033038202:11,log,logs,11,,https://github.com/google/deepvariant/issues/797#issuecomment-2033038202,1,['log'],['logs']
Testability,"Great, glad you found the report useful!. If you need the numbers from the visual report, you can extract them by clicking the button on the top right of the report and in the dropdown selecting ""View Source"". This gives the JSON that in vega-lite produces those plots, and it has the summarized data inside it. These are all summarized data though, since the raw data is the VCF itself. . Also note that you can run our DeepVariant visual report with VCFs from other callers if you want to compare. Other VCFs may be missing some of the information used to make a few of the plots, but otherwise it should work fine -- I stress tested the visual report a lot to make sure of that. Let me know if you try it whether that works for you. And good luck with your research!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/257#issuecomment-569150582:629,test,tested,629,,https://github.com/google/deepvariant/issues/257#issuecomment-569150582,1,['test'],['tested']
Testability,"HI @pichuan, . I trained on a new dataset and run into similar issue. This time there are files created in checkpoint but I still get the same error. Only the first epoch has low tune/categorical_accuracy and the next remaining epoch the accuracy higher than 0.9. I attached the log file here ; [train_041924.log](https://github.com/google/deepvariant/files/15082130/train_041924.log). Here is the parameter I used to train: ; ```-config.num_epochs=10 \; --config.learning_rate=0.0001 \; --config.num_validation_examples=0 \; --experiment_dir=""model_train"" \; --strategy=mirrored \; --config.batch_size=32 \; ```. Would you take a look and let me know what's going wrong? Thank you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2073289661:279,log,log,279,,https://github.com/google/deepvariant/issues/802#issuecomment-2073289661,3,['log'],['log']
Testability,"HI,. Seven million realigned BAMs seems to be a right number. For your purposes you may use --regions parameter that would restrict make_examples to a specific region. For example --regions chr20:1000-1500 would generate BAM files for 500 bases. In addition, if you use --regions flag you may want to remove a shardining from output examples files name: make_examples.tfrecord.gz instead of make_examples.tfrecord@60.gz. And you don't need to run it with parallel, you just need to run one instance. --task parameter is also not needed when the output is not sharded.; Something like this:; ```; /opt/deepvariant/bin/make_examples \; --mode calling --emit_realigned_reads --realigner_diagnostics=results/sample/deepvariant/realigned \; --ref data/genome/reference.fasta --reads results/sample/aligned/sample.bam \; --examples results/sample/deepvariant/tmp/make_examples/make_examples.tfrecord.gz \; --sample_name sample --regions chr20:1000-1500 2> results/sample/deepvariant/tmp/make_examples.log; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/370#issuecomment-716678135:995,log,log,995,,https://github.com/google/deepvariant/issues/370#issuecomment-716678135,1,['log'],['log']
Testability,"Hello @ayeshbond!. Could you please add a log statement with the exact error that you're seeing? . Additionally, you can always disable the creation of the `vcf_stats_repot` in case it's blocking you from running DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/839#issuecomment-2302920900:42,log,log,42,,https://github.com/google/deepvariant/issues/839#issuecomment-2302920900,1,['log'],['log']
Testability,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far!. I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:; ```; python bin/make_examples.zip \; --mode training \; --ref ""data/chr5.fa"" \; --reads ""data/sorted_final_merged.bam"" \; --examples ""training-examples/training_set.with_label.tfrecord.gz"" \; --confident_regions ""data/NA12878.sorted.bed"" \; --truth_variants ""data/NA12878.sorted.vcf.gz"" \; --regions ""chr5"" \; --norealign_reads; ```; and this is the output:; ```; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader; I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader; I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-455862468:683,log,log,683,,https://github.com/google/deepvariant/issues/138#issuecomment-455862468,1,['log'],['log']
Testability,"Hello @lucasbrambrink,. Thank you very much for the response. I am attaching the log file herewith. THe command I used was: . singularity run -B /usr/lib/locale/:/usr/lib/locale/ deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""{rest_path}/tools/DeepVariant/ref_genomes/GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta"" --reads=""{rest_path}/MiniMap_SAM_BAM/11741-KA-0004.sorted.bam"" --output_vcf=""{rest_path}/deepvar_calls/11741-KA-0004_output.vcf.gz"" --output_gvcf=""{rest_path}/deepvar_calls/11741-KA-0004_output.g.vcf.gz"" --intermediate_results_dir ""{rest_path}/deepvar_calls/intermediate_results_dir/0004"" --num_shards=32 &> deepvar_0004.log. [deepvar_0004.log](https://github.com/user-attachments/files/16730424/deepvar_0004.log). Also, could you let me know how I can disable it the `vcf_stat_report`?` I tried to look for it but to no luck. It doesn't necessarily affect the variant calling through. Just gives an error/failure due to this last step. Thank you very much once again, and please let me know if I can get you any more information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/839#issuecomment-2307275017:81,log,log,81,,https://github.com/google/deepvariant/issues/839#issuecomment-2307275017,4,['log'],['log']
Testability,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:; `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/849#issuecomment-2232682994:1150,log,logs,1150,,https://github.com/google/deepvariant/issues/849#issuecomment-2232682994,2,['log'],"['log', 'logs']"
Testability,"Hello @sidharthgoel . Thank you for your help with this issue - I was able to build deepvariant! Tests failed, below, and I am happy to open a separate issue for this or take it somewhere else this is TensorFlow-specific. It seems that TensorFlow `r1.12` installed duing the deepvariant build is looking for CUDA 9:. ```; FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:97,Test,Tests,97,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,12,"['Test', 'log', 'test']","['Tests', 'log', 'test', 'testlogs']"
Testability,"Hello Amy,. We haven't tested DeepVariant with HaloPlex data. WES model would be the best fit for this kind of data but there is no guaranty. Please let us know if you have any further questions. . Thanks; Alex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/583#issuecomment-1309166060:23,test,tested,23,,https://github.com/google/deepvariant/issues/583#issuecomment-1309166060,1,['test'],['tested']
Testability,"Hello Ryan,. I built on an Ubuntu 16 system with CUDA-9.0, CUDNN version 7, tensorflow-gpu installed via tf-nightly-GPU using the last build available of 1.5 (it depends on CUDA-9.0). As I mentioned, build_and_test.sh showed success, running all tests successfully. I can install CUDA 8, CUDNN 6 and try again. Brad Thomas. From: Ryan Poplin [mailto:notifications@github.com]; Sent: Monday, February 5, 2018 3:08 PM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [External]Re: [google/deepvariant] Build and test works, binaries do not (#47). I wonder if there is an issue somehow with how you are building with tensorflow-gpu. What commands did you use to build it? We think this should work with tensorflow-gpu==1.4. Here is what I did to try it out:. git clone https://github.com/google/deepvariant.git. #edit settings.sh so that DV_GPU_BUILD=1 and DV_INSTALL_GPU_DRIVERS=1. ./build-prereq.sh; ./build_release_binaries.sh. then ran a test command with the quickstart testdata:. python deepvariant/bazel-bin/deepvariant/make_examples.zip; --mode calling; --ref ""${REF}""; --reads ""${BAM}""; --regions ""chr20:10,000,000-10,010,000""; --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". which executes as expected. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/47#issuecomment-363221616>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqV3UwUysMDiEktsAe-3kindiR3myks5tR22hgaJpZM4R5yAT>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/47#issuecomment-363230217:246,test,tests,246,,https://github.com/google/deepvariant/issues/47#issuecomment-363230217,2,['test'],"['test', 'tests']"
Testability,"Hello Ryan,. I was able to build successfully using CUDA 8.0, cudnn 6, and tensorflow-gpu 1.4. I ran the WES example. That went fine. Questions: what is the minimum allele frequency deepvariant will call? Is there a version contemplated that will do matched tumor/normal pairs? Unmatched pairs (as with a “pooled” normal)?. Thanks,; Brad Thomas. From: Ryan Poplin [mailto:notifications@github.com]; Sent: Monday, February 5, 2018 5:10 PM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [External]Re: [google/deepvariant] Build and test works, binaries do not (#47). Unfortunately DeepVariant isn't yet compatible with TensorFlow version 1.5 so I think you'll need to install tensorflow-gpu version 1.4 for this to work. In our build script we do this with; sudo -H pip install --upgrade 'tensorflow-gpu==1.4'. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/47#issuecomment-363252951>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqcP3vxIqOIV_Q6VUU-5cueBwPpQiks5tR4plgaJpZM4R5yAT>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/47#issuecomment-364172639:633,test,test,633,,https://github.com/google/deepvariant/issues/47#issuecomment-364172639,1,['test'],['test']
Testability,"Hello Ryan,. Thanks for the information. We have about 500 curated vcf on a gene panel we use here. I will try to create a model for that panel. We want variants as low as 1%. Have you tried something similar?. Best,. Brad Thomas. ________________________________; From: Ryan Poplin <notifications@github.com>; Sent: Friday, February 9, 2018 12:54 PM; To: google/deepvariant; Cc: Brad Thomas; Author; Subject: [External]Re: [google/deepvariant] Build and test works, binaries do not (#47). Great to hear. There are minimum allele fractions that are used to generate candidate variants here (https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L165), you'll likely want to lower those thresholds for your use case. For the model itself, there is no explicit allele fraction, but keep in mind that the model was trained to predict the diploid genotype states of {hom ref, het, and hom var} so things that are lower allele fraction will likely be classified as 0/0 by the model. We don't currently have a version that does somatic variant calling. -; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/47#issuecomment-364524990>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqVYdivUTLfEIl26QitFq5k-svzBeks5tTJSBgaJpZM4R5yAT>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/47#issuecomment-364650047:455,test,test,455,,https://github.com/google/deepvariant/issues/47#issuecomment-364650047,1,['test'],['test']
Testability,"Hello Salik,. I am sorry you are encountering issues with the Cloud Runner. I can't definitively tell you what has gone wrong, but I can spot a few things that will be issues (there could also be others). First, I think the log snippet here comes from the main log of the cloud runner. The underlying program error can often be found in another folder of the same run. You should see a ""logs"" folder and this should contain a program-specific log (like make_examples.log). This can be more informative. From your run, I can see that you provide your FASTA as an uncompressed .FA file. I believe that the cloud runner requires a BGZIP compressed reference, a samtools FAIDX, and a GZI index all in the same place. You will need to do the following operations on the FASTA file in a bucket that you control:. bgzip -i GRCh38_Verily_v1.genome.fa; samtools faidx GRCh38_Verily_v1.genome.fa. afterward, you will need to put the resulting:. GRCh38_Verily_v1.genome.fa.gz; GRCh38_Verily_v1.genome.fa.gz.gzi; GRCh38_Verily_v1.genome.fa.gz.fai. in the same bucket that the cloud runner can access. . Hopefully these instructions seem reasonable and this unblocks you from this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-436856528:224,log,log,224,,https://github.com/google/deepvariant/issues/116#issuecomment-436856528,5,['log'],"['log', 'logs']"
Testability,"Hello,. Did you follow the instructions here: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md?. It seems like you are missing distutils, please follow the instruction in the readme to see if the error persists.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/730#issuecomment-1813395301:117,test,test,117,,https://github.com/google/deepvariant/issues/730#issuecomment-1813395301,1,['test'],['test']
Testability,"Hello,. I did make 64 examples from the GIAB exome data mentioned on the github site. I encountered the same problem I mentioned. I’ve attached an archive, bundle.zip that has important files. The file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,; Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]; Sent: Friday, April 13, 2018 10:14 AM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,; originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that.; How about at least posting the commands you used?. From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty.; (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —; You are receiving this beca",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381247700:339,test,testModeExamples,339,,https://github.com/google/deepvariant/issues/62#issuecomment-381247700,1,['test'],['testModeExamples']
Testability,"Hello,. I have the exact same issue. In my case, I have my VCFs, gVCFs and the index files created but it fails at creating the ""vcf_stats_repot"". I have given the absolute paths as well. . When I ran the test data, I had the same issue. Tried runnig the VCF run report separate as documented here: https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-vcf-stats-report.md and that also didn't work. Any assistance would be greatly appreciated. Thank you so much.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/839#issuecomment-2302567837:205,test,test,205,,https://github.com/google/deepvariant/issues/839#issuecomment-2302567837,1,['test'],['test']
Testability,"Here is an attempt to deliberately mess up the BAM file in the case study, so I can get the make_examples step to fail, and observe the logs.; However, in my test runs below, I'm seeing useful error messages. @Asppagh if you have suggestions on how I can reproduce an error type like yours. It'll be really helpful! Otherwise I'm currently stuck on how to help you debug this. I'll share my test runs below so you can take a look:. ---. I followed steps in:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md; to get data. ## I deliberately messed up the BAM, and ran `run_deepvariant`; ```; ls -l quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam; -rw-rw-r-- 1 pichuan pichuan 3925783 Nov 27 2017 quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam; ```; ```; head -c 3000000 quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam > quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam; cp quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam.bai quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; ```. I ran:; ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.truncated.bam \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=1; ```. for the sake of completeness, I'll paste the log below up to the stack trace in make_examples:. ```; I0629 23:08:46.468520 139667868600064 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpj5fx0phm. ***** Intermediate results will be written to /tmp/tmpj5fx0phm in docker. ****. ***** Running the command:*****; ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.truncated.bam"" ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:136,log,logs,136,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,9,"['log', 'test']","['logs', 'test', 'testdata']"
Testability,"Here's the full command --. ```; /opt/deepvariant/bin/run_deepvariant --model_type=WGS \; --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \; --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz \; --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz \; --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir \; --num_shards=1 --verbosity=2; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/901#issuecomment-2455512850:124,test,testdata,124,,https://github.com/google/deepvariant/issues/901#issuecomment-2455512850,2,['test'],['testdata']
Testability,"Here's the output of those two commands:; ```; singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.0.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/home/sk2847/scratch60/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions chr20:10,000,000-10,010,000 --output_vcf=/home/sk2847/scratch60/quickstart-output/output.vcf.gz --output_gvcf=/home/sk2847/scratch60/quickstart-output/output.g.vcf.gz --intermediate_results_dir /home/sk2847/scratch60/quickstart-output/intermediate_results_dir --num_shards=1. singularity -s exec --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.0.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/sk2847/scratch60/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/home/sk2847/scratch60/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions chr20:10,000,000-10,010,000 --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz; ```. The output of `ls -l ${INPUT_DIR}` is:; ```; -rw-r--r-- 1 sk2847 kahle 3925783 Nov 27 2017 NA12878_S1.chr20.10_10p1mb.bam; -rw-r--r-- 1 sk2847 kahle 5472 Nov 27 2017 NA12878_S1.chr20.10_10p1mb.bam.bai; -rw-r--r-- 1 sk2847 kahle 264 Nov 27 2017 test_nist.b37_chr20_100kbp_at_10mb.bed; -rw-r--r-- 1 sk2847 kahle 5728 Nov 27 2017 test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; -rw-r--r-- 1 sk2847 kahle 197 Nov 27 2017 test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; -rw-r--r-- 1 sk2847 kahle 64286038 Nov 27 2017 ucsc.hg19.chr20.unittest.fasta; -rw-r--r-- 1 sk2847 kahle 23 Nov 27 2017 ucsc.hg19.chr20.unittest.fasta.fai; -rw-r--r-- 1 sk2847 kahle 606944 Nov 27 2017 ucsc.hg19.chr20.unittest.fasta.gz; -rw-r--r-- 1 sk2847 kahle 23 Nov 27 2017 ucsc.hg19.chr20.unittest.fasta.gz.fai; -rw-r--r-- 1 sk2847 kahle 15704 Nov 27 2017 ucsc.hg19.chr20.unittest.fasta.gz.gzi; ```. Which is what I would expect.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/402#issuecomment-761662095:239,test,testdata,239,,https://github.com/google/deepvariant/issues/402#issuecomment-761662095,4,['test'],['testdata']
Testability,"Hey @pichuan, @pgrosu ; thx for the quick reply's :) i tested your first idea paul still had the same issue sadly, but the solution from issue 559 seems to be working (i dont understand why so but thats another problem) since the workflow is still running so i cant say for sure but it makes the tfrecords what didnt happend the last few time; ![image](https://github.com/google/deepvariant/assets/138118818/14c3b254-ec78-468c-9a2f-301443bc3a5b). I will update when the Workflow is done . Best regards ; Sami",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/677#issuecomment-1635666898:55,test,tested,55,,https://github.com/google/deepvariant/issues/677#issuecomment-1635666898,1,['test'],['tested']
Testability,"Hey! I managed to do this using the batch. This was my script that worked (it takes a file which has a list of the ID files and picks them out to insert into the file and then runs each one as a batch! - you can adapt this to be more efficient obviously!) - I just left my last used file names in for ease with copy and paste. ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p htc; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=12:00:00; #SBATCH --mem-per-cpu=128GB; #SBATCH --qos=maxjobs100. module purge; module load parallel; module load singularity. EXOME_IDs_FILE=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/RAW_input/NG0921_sampleIDs; HG38_REFERENCE=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/bwa/index/GCA_000001405.15_GRCh38_no_alt_analysis_set_refandindex/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna; PICARDMARKDUPLICATES_SORTEDBAM=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/picard/markduplicates/markedduplicates/{}PE_markedduplicates_GCA_000001405.15_GRCh38_no_alt_analysis_set.bam; BED_REGIONS=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/deepvariant/bed/Agilent-SureSelect-XT-Reagent-Kit-Human-AllExon-V6-hg38.bed; OUTPUT_VCF=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/deepvariant/vcf/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set.vcf.gz; OUTPUT_GVCF=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/deepvariant/gvcf/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set.g.vcf.gz; INTERMEDIATE_RESULTS=/scratch/c.c21087028/Polyposis_Exome_Analysis_NG0921/deepvariant/intermediateresults/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/717#issuecomment-1770571154:346,log,login,346,,https://github.com/google/deepvariant/issues/717#issuecomment-1770571154,1,['log'],['login']
Testability,"Hi @0820LL ; There is no docker for ARM64, however you may try to build binaries yourself. Please check [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-build-test.md) page for instructions how to build from source. It will not work out of the box for ARM platform. The main obstacle would be the Bazel build (there might be other obstacles as well). I found [this](https://groups.google.com/g/bazel-discuss/c/BQCVxaNd5f8?pli=1) link that can be a starting point to make the Bazel work for ARM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/834#issuecomment-2183583252:184,test,test,184,,https://github.com/google/deepvariant/issues/834#issuecomment-2183583252,1,['test'],['test']
Testability,"Hi @A-Tsai ,; I think our setup on GitHub might be a bit confusing right now.; Because the way our repo is set up, the main DeepVariant repo can't directly merge from external pull requests. . We will need to internally test your pull request, and will have to internally make a code change which will be exported to GitHub later. When we make the code change internally, we will point to your PR in the commit log.; Please let us know if you're ok with that. If so, we'll proceed with that. Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/159#issuecomment-469111350:220,test,test,220,,https://github.com/google/deepvariant/pull/159#issuecomment-469111350,2,"['log', 'test']","['log', 'test']"
Testability,"Hi @ASLeonard , thanks for the report.; Now I think about it, I might not have tested the combination of Singularity and our use of OpenVINO together.; I'll run this through the [PacBio example](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md) and confirm that I can reproduce this issue. There are a few fixes I can think of, which you also suggested:; 1. We can provide a flag that allows users to provide a pointer to the OpenVINO model file. This will require the user to run the freeze_graph code to convert the model themselves.; 2. At this line:; https://github.com/google/deepvariant/blob/2dbebb4d97e15d0d5fcf303a4466314b1f313208/deepvariant/openvino_estimator.py#L80; We can provide the intermediate directory to write the model.pb file in. And users can specify a directory that Singularity won't be unhappy with. I'll first try to reproduce the issue, and then I'll likely try with option 2 above. ; Thanks for reporting this issue. I'll update again when I look into it more. Also tagging @dkurt here as an FYI.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-761285739:79,test,tested,79,,https://github.com/google/deepvariant/issues/404#issuecomment-761285739,1,['test'],['tested']
Testability,"Hi @ASLeonard ,. Is it possible to provide the input data so we can reproduce the error on our end? On our side, we didn’t update nucleus between versions so unsure why you are seeing this behavior. Would be very helpful if you can provide a small data to reproduce as all the tests involving cram files still passes on v1.6z",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/741#issuecomment-1831176447:277,test,tests,277,,https://github.com/google/deepvariant/issues/741#issuecomment-1831176447,1,['test'],['tests']
Testability,"Hi @ASLeonard ,. Thanks for reporting this issue. We actually made a deliberate decision to not include OpenVINO this time, because in our test setting we were not able to get faster runtime. We did talk to @dkurt about this and tried https://github.com/google/deepvariant/pull/523. We will still plan to try OpenVINO again in the next release. But given that we didn't see faster runtime, we decided to leave it out of the default. If you would like to use it, please use our Dockerfile and build with the option on. I'm curious - were you seeing a speedup by using OpenVINO in DeepVariant v1.3.0? If so, what is the type of machine you're using?. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/541#issuecomment-1152836865:139,test,test,139,,https://github.com/google/deepvariant/issues/541#issuecomment-1152836865,1,['test'],['test']
Testability,"Hi @ASLeonard . For the hybrid model, we do not use haplotagged BAMs in the training process. In our initial benchmarks of the hybrid model, we observed a similar accuracy when training with haplotag as compared to training without it. Since haplotagging is an additional step, we decided not to include haplotag in the hybrid model. If you provide a haplotagged BAM to the hybrid model, it will still be able to read the BAM and should result in the same accuracy as when providing an untagged BAM, since the parsing of the haplotags is an additional step which is enabled by a flag.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/410#issuecomment-766309585:109,benchmark,benchmarks,109,,https://github.com/google/deepvariant/issues/410#issuecomment-766309585,1,['benchmark'],['benchmarks']
Testability,"Hi @AndrewCarroll , . Thanks for the detailed reply. This is still kind of in early days. Our team is mostly from the National Museum of Natural History so we all work on a variety of taxa from snakes to plants. At this point we were trying to figure out the best non-model group(s) to start with because if we could start with a taxon with genome trios sequenced (or I suppose WES) then we could try the technique from the mosquito paper. But, in most cases with non-model groups we don't have any trios, and often we just have one representative genome that at times is not that well resolved. In terms of choosing test groups we could try one with genome characteristics more like humans, and then test of something more different. ; I certainly like the second suggestion of sampling the GIAB data, and if the genome in question is not too different then it could be a good approach. One thing we are thinking about is how far out evolutionarily you can extend the model we train. In a lot of pop gen and phylogenetic studies sampling is interspecific, and so we are also thinking about trying to evaluate how well a model would work across a clade or genus. The fact that DV worked well on mice is encouraging in this respect. I will keep you posted if we come up with any breakthroughs!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/459#issuecomment-858159795:617,test,test,617,,https://github.com/google/deepvariant/issues/459#issuecomment-858159795,2,['test'],['test']
Testability,"Hi @AndrewCarroll ,. I followed the instructions to merge gvcf file into a final vcf via GLnexus with the default parameters like this:. `singularity exec glnexus.sif glnexus_cli --config DeepVariantWGS $gvcf_path/*.gvcf.gz > ${output_bcf}`. But it only output 62409 SNPs in the final vcf file (pepper.merged.glnexus.vcf.gz 6.8M), there are 5 input gvcf files (each of one is about 11GB, the sample is from the whole genome of pig). . the below is the log from GLnexus. > INFO: Convert SIF file to sandbox...; > WARNING: underlay of /etc/localtime required more than 50 (77) bind mounts; > [71420] [2024-04-03 09:10:42.182] [GLnexus] [info] glnexus_cli release v1.4.1-0-g68e25e5 Aug 13 2021; > [71420] [2024-04-03 09:10:42.182] [GLnexus] [info] detected jemalloc 5.2.1-0-gea6b3e973b477b8061e0076bb257dbd7f3faa756; > [71420] [2024-04-03 09:10:42.183] [GLnexus] [info] Loading config preset DeepVariantWGS; > [71420] [2024-04-03 09:10:42.190] [GLnexus] [info] config:; > unifier_config:; > drop_filtered: false; > min_allele_copy_number: 1; > min_AQ1: 10; > min_AQ2: 10; > min_GQ: 0; > max_alleles_per_site: 32; > monoallelic_sites_for_lost_alleles: true; > preference: common; > genotyper_config:; > revise_genotypes: true; > min_assumed_allele_frequency: 9.99999975e-05; > snv_prior_calibration: 0.600000024; > indel_prior_calibration: 0.449999988; > required_dp: 0; > allow_partial_data: true; > allele_dp_format: AD; > ref_dp_format: MIN_DP; > output_residuals: false; > more_PL: true; > squeeze: false; > trim_uncalled_alleles: true; > top_two_half_calls: false; > output_format: BCF; > liftover_fields:; > - {orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}; > - {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Al",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/778#issuecomment-2033814378:452,log,log,452,,https://github.com/google/deepvariant/issues/778#issuecomment-2033814378,2,"['log', 'sandbox']","['log', 'sandbox']"
Testability,"Hi @AndrewCarroll ,; thanks for your reply and the additional info. I'd love to conduct some deeper investigations but unfortunately, I don't have the time. So if you could provide some more bacteria related test results, this would be highly appreciated.; Thanks a lot and best regards!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/183#issuecomment-493038730:208,test,test,208,,https://github.com/google/deepvariant/issues/183#issuecomment-493038730,1,['test'],['test']
Testability,"Hi @Asppagh ,. It can be many different reasons. ; Your machine setup definitely could be one of the factors.; And, not all inputs will take the same amount of time to run. For example, some regions in some BAMs might take longer to realign, etc. In DeepVariant, we tried to empirically set some thresholds so we hope that even the slowest cases are not too slow. But it's always useful to learn from our users what edge cases might still cause the DeepVariant to be slow. If your input BAM file is publicly sharable, you can also point us to it, and I'm happy to give it try and see if I can identify any reasons why it might be particularly slow. But it's also possible that your data is not publicly available. If that's the case, to diagnose your machine setup, you can start by running on some of our publicly shared data used in https://github.com/google/deepvariant/blob/r1.1/docs/metrics.md. Specifically under:; https://github.com/google/deepvariant/blob/r1.1/docs/metrics.md#how-to-reproduce-the-metrics-on-this-page. For example, you can run on our WGS BAM file: gs://deepvariant/case-study-testdata/HG003.novaseq.pcr-free.35x.dedup.grch38_no_alt.bam on your cluster using singularity , and see what runtime you're getting. And, one more question that will help us provide better support:; Do you know if make_examples finish running on your machine? If so, how long it took on how many cores? If make_examples finished, then what's the runtime on call_variants and postprocess_variants?; (One possible issue we've seen before is that the call_variants stage is slow if users run on CPUs without acceleration)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-864304812:1102,test,testdata,1102,,https://github.com/google/deepvariant/issues/463#issuecomment-864304812,1,['test'],['testdata']
Testability,"Hi @Asppagh ; From the error above it wasn't very informative. This seems like it failed on the make_examples step already. We should have just stopped there, instead of proceeding into call_variants and next steps. --> This is now fixed in internal code, and will be fixed in the next release. Another question is -- why did the failed make_examples not produce any useful logs?. This one is a bit less clear to me. . With the same setting, instead of using /opt/deepvariant/bin/run_deepvariant (which is a convenient script that combines 3 steps), can you try directly running with . `/opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord.gz""`. This should allow you to just run 1 make_examples, without using GNU parallel as well. Hopefully whatever error messages will be more clear here.; Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870041849:374,log,logs,374,,https://github.com/google/deepvariant/issues/465#issuecomment-870041849,2,['log'],['logs']
Testability,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```; bcftools norm -m - multi_allelic.vcf > biallelic.vcf; ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```; bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv; ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1648597119:791,test,test,791,,https://github.com/google/deepvariant/issues/682#issuecomment-1648597119,1,['test'],['test']
Testability,"Hi @DLPerf , I have some results to update:. I followed you suggestions and swapped the `map` and `batch` in data_providers. And then, I changed these lines:; https://github.com/google/deepvariant/blob/r1.2/deepvariant/data_providers.py#L189-L194; to:; ```; parsed = tf.io.parse_example(serialized=tf_example,; features=self.feature_extraction_spec); image = parsed['image/encoded']; if self.tensor_shape:; image = tf.io.decode_raw(image, tf.uint8); image = tf.reshape(image, [-1]+self.tensor_shape); ```. to make it work. This doesn't fully work when `use_tpu` is True. But given that we can [measure runtime](https://github.com/google/deepvariant/blob/r1.2/docs/metrics.md) on CPU machines, I was able to test on CPU machines with that change. After the change above, I re-ran the 4 test in [r1.2 metrics.md](https://github.com/google/deepvariant/blob/r1.2/docs/metrics.md). I observed that:; (1) Accuracy is the same for 4 models - this is expected.; (2) Looking at the `call_variants` runtime, I do not see an improvement. Here are the runtime from all 4 runs:. ## WGS (Illumina); ```; real 114m10.723s; real 193m19.324s; real 74m39.826s; ```; ## WES (Illumina); ```; real 7m26.571s; real 1m24.083s; real 1m3.679s; ```. ## PacBio (HiFi); ```; real 126m28.198s; real 175m40.960s; real 67m49.753s; ```; ## Hybrid (Illumina + PacBio HiFi); ```; real 161m32.681s; real 200m26.225s; real 63m20.731s; ```. Comparing these to [r1.2 metrics.md](https://github.com/google/deepvariant/blob/r1.2/docs/metrics.md), surprisingly it does not look to me that the `call_variants` step has significant improvement. . A few possibilities:; (a) All these runtime have some variance. For example, when I made the metrics.md, I ran a few times and average the runtime (and try to round them up). So it's possible it's mostly variance. But, if this is an improvement, I'd still expect a bit better numbers.; (b) It is possible that the new code is more efficient, but might need some tuning (e.g., batch size? other par",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/479#issuecomment-905684335:707,test,test,707,,https://github.com/google/deepvariant/issues/479#issuecomment-905684335,2,['test'],['test']
Testability,"Hi @DLPerf , thanks for looking into this.; I can look into your suggestions above, test out the changes, and report back.; If you want to just create a PR with your fixes suggested above, that will certainly make my job easier and avoid miscommunication. Note that our repo isn't quite setup to directly take external pull requests, but if you create one, I can create a corresponding internal commit and point to your PR when we commit it. Let me know if you want to create a PR, or just for me to try to follow your suggestion above. Either way works. If you'll create a PR, I'll wait for that first.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/479#issuecomment-903356421:84,test,test,84,,https://github.com/google/deepvariant/issues/479#issuecomment-903356421,1,['test'],['test']
Testability,"Hi @ErinKinghorn , if I understand your latest comment, you meant that you were able to get them to work now?; If so, I'll close this. (But if I misunderstood, please reopen with more questions!). @kishwarshafin will plan to do a 1.6.1 release to fix the issue above (and will officially publish a Docker). Thanks for helping us test!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/776#issuecomment-1990519945:329,test,test,329,,https://github.com/google/deepvariant/issues/776#issuecomment-1990519945,1,['test'],['test']
Testability,"Hi @GaianX39 . I wanted to add just a few things. . First, in our next release we're planning to improve the de novo detection aspects of DeepTrio, so if that's of interest to you, please stay tuned for this. . Using GIAB to validate performance is only something that you can do when sequencing the known samples (e.g. HG002-HG003-HG004). If you have those, then please follow the ""Running Hap.py"" steps at the end of most quick starts (e.g. [Hap.py section of WGS case study](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md#perform-analysis-with-happy-against-421-truth-set). To do this with a joint called VCF, we use BCFtools to subset the VCF to individual samples (e.g. `bcftools -s ${SAMPLE_ID}`). For runtime, we have benchmarks in the Figure 6 of the [DeepTrio paper](https://www.biorxiv.org/content/10.1101/2021.04.05.438434v1). Here, we see DeepTrio takes about 1.5x the time that running DeepVariant on all 3 samples does. The cost should be a similar multiple as this is run on the same hardware. What this translates to in cost depends on how you run it (local, which cloud provider and with which deals, etc...)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/704#issuecomment-1719944491:758,benchmark,benchmarks,758,,https://github.com/google/deepvariant/issues/704#issuecomment-1719944491,1,['benchmark'],['benchmarks']
Testability,"Hi @GuillaumeHolley . This is a complicated issue, and though I've looked into it, I'm not 100% sure the following is correct, but I am reasonably confident:. DeepVariant is consists of some human-written heuristics which are used to identify positions that are candidate to be variant. Identified candidates are given to the neural network for classification. After this classification, another set of human-written heuristics converts the output probabilities of the network to VCF and gVCF entries. . As part of this process, there are positions that were never proposed as candidates because they do not have enough support to reach the candidate generation threshold (for the PacBio defaults, this is at least 2 reads which support an alternate event with a minimum ALT fraction of 0.12, and where the reads used for the calculation have MAPQ>=5). When this threshold is not met, the site is always considered either a reference or a no-call, and human-written heuristics are used to make a determine the genotype quality of the position for binning in the gVCF. This logic is fairly simple, and can sometimes result in a calculation of HET being the most likely, even if DeepVariant's neural network never made a call. The GQ should be set to 0 in these cases. This occurs because we value the neural network's output much more highly, and would like only it to make calls. . Hopefully this helps clarify what is going on here. The situation and explanation is complicated, so please feel free to ask further questions. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/403#issuecomment-759187363:1073,log,logic,1073,,https://github.com/google/deepvariant/issues/403#issuecomment-759187363,1,['log'],['logic']
Testability,"Hi @GuillaumeHolley, thanks for raising the issue. Could you try to run this with 1.0.0 image and let me know whether the issue persists? We haven't officially released 1.0.0 just yet, but we can use it to test this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/341#issuecomment-686052590:206,test,test,206,,https://github.com/google/deepvariant/issues/341#issuecomment-686052590,1,['test'],['test']
Testability,"Hi @Han-Cao ,. from your log, I'm surprised that your make_examples step was making that many examples.; Before it crashed, one shard already made 20480581 examples. And it seems like you have 40 shards.; So, that would mean 20480581*40 = 819,223,240 examples has already been made. That is a surprising amount of examples! Is there anything unusual about your sample?. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/847#issuecomment-2221036030:25,log,log,25,,https://github.com/google/deepvariant/issues/847#issuecomment-2221036030,1,['log'],['log']
Testability,"Hi @JakeHagen . Although we do have access to some dbGaP datasets, I don't believe that this is one of them. Let me conduct some experiments from our benchmark data and see if I can replicate the effect.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/586#issuecomment-1331125414:150,benchmark,benchmark,150,,https://github.com/google/deepvariant/issues/586#issuecomment-1331125414,1,['benchmark'],['benchmark']
Testability,"Hi @JakeHagen ; Currently there isn't a very clean way to do this. You can modify the code and build DeepVariant from source: https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-build-test.md. I'm personally interested in learning more about what you're trying to do - what is the expected input and output. If there's general enough use cases, maybe in the future we can make things easier to import, even though we don't currently have plans for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/344#issuecomment-689698461:197,test,test,197,,https://github.com/google/deepvariant/issues/344#issuecomment-689698461,1,['test'],['test']
Testability,"Hi @JoelDaon , were you able to run this?; What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver.; I documented it for myself here:; https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```; ( time sudo nvidia-docker run \; -v /home/${USER}:/home/${USER} \; gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \; /opt/deepvariant/bin/call_variants \; --outfile ""${CALL_VARIANTS_OUTPUT}"" \; --examples ""${EXAMPLES}"" \; --checkpoint ""${MODEL}""; ) >""${LOG_DIR}/call_variants.log"" 2>&1; ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/81#issuecomment-415637165:598,log,log,598,,https://github.com/google/deepvariant/issues/81#issuecomment-415637165,1,['log'],['log']
Testability,"Hi @JosephLalli . At the time we were putting together the vg-giraffe paper, we noticed that Indel errors would occur because the positioning of read indel events in the CIGAR string were not always left-normalized. ABRA both fixed that issue and also seems to give some additional advantage by standardizing the representation before running the candidate generation in DeepVariant. Subsequent to that finding, both ourselves and the vg team built methods which left-normalize Indel CIGAR events during processing. We found that this reduced almost all, but not quite all, of the Indel performance difference with ABRA processed reads. Because we have built the DeepVariant vg pipeline to include read normalization with the --normalize_reads=true tag, we don't routinely benchmark the two methods against each other. Our last head-to-head benchmark on ABRA on and off on 35x HG003 was no_ABRA Indel F1=0.9953, with ABRA Indel F1=0.9958. @pichuan Has made [this linked gist](https://gist.github.com/pichuan/eedab4cf2e06fa7ceb2fad0f9b3f8066) that we use for efficient, single machine processing of vg giraffe+DeepVariant. We opted not to include the use of ABRA realignment in that pipeline. With the benchmark numbers available here, I hope this is sufficient information for you to decide whether you would like to include it or not. We continue to look at improvements in the Indel realignment/reassembly process to see if we can further improve in some of the manners that ABRA helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/629#issuecomment-1503848466:773,benchmark,benchmark,773,,https://github.com/google/deepvariant/issues/629#issuecomment-1503848466,3,['benchmark'],['benchmark']
Testability,"Hi @Lenbok . Thank you for the note, with the links from @aderzelle, I was able to pull in the file and visualize this event. . I think what is happening is that there are variants that can be represented in an internally consistent way at two different sets of positions. I think that DeepVariant reassembly is generating these two sets of candidates. The neural net always sees positions reassembled in the context of that particular position, so there looks to be evidence for support for each when inspected relative to the reference. We've had some internal discussions about how to improve candidate haplotype assignment for reads, but it will likely take some time to implement, test, and release. Thank you for highlighting this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/209#issuecomment-531590836:686,test,test,686,,https://github.com/google/deepvariant/issues/209#issuecomment-531590836,1,['test'],['test']
Testability,"Hi @MariaNattestad , thanks so much for your reply!; Yes, I'm testing for germline variation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/535#issuecomment-1104708449:62,test,testing,62,,https://github.com/google/deepvariant/issues/535#issuecomment-1104708449,1,['test'],['testing']
Testability,"Hi @MariaNattestad ,. Thank you for the reply,; 1) NextFlow pipeline is written by me. 3) I ran with Chr20, below is the log, 4) in NextFlow Input out we can give any name for the files as input/out.; ```; Jun-08 12:02:05.261 [main] INFO nextflow.cli.CmdRun - Launching `dv.nf` [spontaneous_wright] DSL2 - revision: fbe7d83e44; Jun-08 12:02:05.261 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins default=[]; Jun-08 12:02:05.261 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins resolved requirement=[]; Jun-08 12:02:05.268 [main] DEBUG nextflow.secret.LocalSecretsProvider - Secrets store: /home/kiran.patil/.nextflow/secrets/store.json; Jun-08 12:02:05.271 [main] DEBUG nextflow.secret.SecretsLoader - Discovered secrets providers: [nextflow.secret.LocalSecretsProvider@58472096] - activable => nextflow.secret.LocalSecretsProvider@58472096; Jun-08 12:02:05.320 [main] DEBUG nextflow.Session - Session UUID: 1e83b778-2b0d-4f02-9875-bf3b18b4a30a; Jun-08 12:02:05.320 [main] DEBUG nextflow.Session - Run name: spontaneous_wright; Jun-08 12:02:05.320 [main] DEBUG nextflow.Session - Executor pool size: 96; Jun-08 12:02:05.330 [main] DEBUG nextflow.util.ThreadPoolBuilder - Creating thread pool 'FileTransfer' minSize=10; maxSize=288; workQueue=LinkedBlockingQueue[10000]; allowCoreThreadTimeout=false; Jun-08 12:02:05.348 [main] DEBUG nextflow.cli.CmdRun -; Version: 22.10.7 build 5853; Created: 18-02-2023 20:32 UTC (19-02-2023 02:02 IDT); System: Linux 5.4.0-146-generic; Runtime: Groovy 3.0.13 on OpenJDK 64-Bit Server VM 14.0.2+12-Ubuntu-120.04; Encoding: UTF-8 (UTF-8); Process: 683315@victor [127.0.1.1]; CPUs: 96 - Mem: 503.5 GB (137.9 GB) - Swap: 108 GB (107.9 GB); Jun-08 12:02:05.365 [main] DEBUG nextflow.Session - Work-dir: /data/shared/clinical/LongRead/Pipeline/work [ext2/ext3]; Jun-08 12:02:05.365 [main] DEBUG nextflow.Session - Script base path does not exist or is not a directory: /data/shared/clinical/LongRead/Pipeline/bin; Jun-08 12:02:05.372 [main] DEBUG nextflow.execut",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308:121,log,log,121,,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308,1,['log'],['log']
Testability,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here.; ```; 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609; 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990; ```; Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,; Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/517#issuecomment-1055258649:255,test,tests,255,,https://github.com/google/deepvariant/issues/517#issuecomment-1055258649,1,['test'],['tests']
Testability,"Hi @MorganHow ,; What is the command you used? I assume you're using the latest `0.10.0` version?. The latest v0.10.0 is built with Python 3.6. ; From the log, it seems like make_examples finish running, but not that many examples were made. However, I don't expect call_variants to fail. Are there more logs that you can share?. Or, can you share the OS version, and command that you're using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/304#issuecomment-620382628:155,log,log,155,,https://github.com/google/deepvariant/issues/304#issuecomment-620382628,2,['log'],"['log', 'logs']"
Testability,"Hi @Npaffen . Yes, in phase variants, the reads are assigned a haplotag value. Briefly, in this process, a set of potential variants are scored with heuristics (no neural network) on the likelihood that they are heterozygous variants. A cluster of such variants forms a candidate seed for a haplotype. The evidence from multiple reads across multiple positions are used to identify the putative variants on that haplotype, and then reads are scored based on whether they fall into one of the haplotypes, the other, or cannot be phased. Because this haplotagging uses information from much longer stretches and more candidate variants than the individual process of variant calling, it has the advantage of a broader set of information. This haplotagging is used to populate the information in the ""haplotype channel"" which is one of the inputs for DeepVariant long read data. We [wrote a blog](https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/) describing this channel and its impact. Note that this process is only used to provide the information to the neural network for consider, the neural network will be able to learn when this channel is or is not reliable based on genome context, coverage, etc... the network's call on the genotype is what finally goes into a variant. As a result, haplotag is not used as input to generate the non-ref blocks of the gVCF, and as the final variants called are still from the neural network, the definition of a variant remains the same - a position with an ALT allele that receives a non-reference (0/0 or ./.) call. We are currently working on a deeper description of the phasing logic used in DeepVariant, which may help understand or reproduce the haplotag method more easily. Please let me know if anything in the explanation is unclear or can be elaborated further.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1602118672:1651,log,logic,1651,,https://github.com/google/deepvariant/issues/666#issuecomment-1602118672,1,['log'],['logic']
Testability,"Hi @Phillip-a-richmond ,; I want to give an update on this issue:. As part of working on v1.4.0, we did some experiments on this, which is still work in progress. If you can reach out to me and @AndrewCarroll (you can email me at pichuan@google.com), we can follow up on an experimental model for you to test, if you're still interested.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/518#issuecomment-1145399411:304,test,test,304,,https://github.com/google/deepvariant/issues/518#issuecomment-1145399411,1,['test'],['test']
Testability,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/518#issuecomment-1050404831:431,test,test,431,,https://github.com/google/deepvariant/issues/518#issuecomment-1050404831,1,['test'],['test']
Testability,"Hi @Phillip-a-richmond . Thank you for the report. You are correct, that the behavior out-of-the box for DeepTrio can currently be sub-optimal for the sex chromosomes in male samples. We've benchmarked some strategies for dealing with this. In the short term, our recommendation is to run separate calling on the non-PAR regions of ChrX and ChrY, where only the mother sample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a; > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we; > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on; > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and; > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous; > variant calls in the non-PAR regions of chromosomeX.; > ; > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are; > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference; > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic.; > Since chromosomeX in males is inherited from the mother, we performed calling on; > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/518#issuecomment-1045294025:190,benchmark,benchmarked,190,,https://github.com/google/deepvariant/issues/518#issuecomment-1045294025,2,['benchmark'],"['benchmarked', 'benchmarks']"
Testability,"Hi @SHuang-Broad , thanks for bringing up the issue about the logging file size. ; I've made two changes internally (which will come out in the next release):; 1. make_examples: I changed this line https://github.com/google/deepvariant/blob/r1.2/deepvariant/make_examples_options.py#L221 to 2000 instead.; 2. call_variants: I changed this line https://github.com/google/deepvariant/blob/r1.2/deepvariant/call_variants.py#L70 to 50000 instead. In a quick test on a WGS BAM, both will roughly be 1-2min intervals, which hopefully is more reasonable. Before release, I'll check the size of the log files as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/491#issuecomment-966527557:62,log,logging,62,,https://github.com/google/deepvariant/issues/491#issuecomment-966527557,3,"['log', 'test']","['log', 'logging', 'test']"
Testability,"Hi @SHuang-Broad , thanks for your question. This line in the log indicates that you are running with our internal phasing:; ```; I0514 02:29:01.686342 140121429608256 make_examples_core.py:257] Skip phasing: len(candidates[main_sample]) is 5953.; ```; (In this case, the phasing algorithm skips some windows based on some threshold). Given that you're using run_deepvariant, you can see that in r1.5, our run_deepvariant.py enables `phase_reads` for the PacBio mode.; https://github.com/google/deepvariant/blob/r1.5/scripts/run_deepvariant.py#L247-L260; (Other than `phase_reads`, a few other flags are also necessary. For example: `track_ref_reads`, `sort_by_haplotypes`, `parse_sam_aux_fields`, And `partition_size` to cover enough candidates.); If you're running make_examples separately, please make sure to add these flags. You can use the `--dry_run` flag of run_deepvariant to figure out which flags to add. Note that our phasing is intended for use in DeepVariant accuracy only (so that our users don't need to add an extra step like before). We don't intend for our phasing results to be used like a standalone phasing tool. That is why we didn't explicitly expose the phased results. If you're not seeing the accuracy we reported, or the accuracy you see on other samples look unexpected, please let us know!. By the way, if you really want to double check the phasing results, you can save the make_examples results using the --intermediate_results_dir flag. And then use our https://github.com/google/deepvariant/blob/r1.5/docs/show-examples.md tools to visualize the images. You should able to see a channel with the sorted HP values. Note that not all windows would be phased, but if you look through a few of them you should be able to check. If you're curious about the phasing algorithm itself, @akolesnikov and @kishwarshafin are working on writing up a bit more of the details. That might take a while to finish, but we can let you know when we have some more details to share.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/649#issuecomment-1547069475:62,log,log,62,,https://github.com/google/deepvariant/issues/649#issuecomment-1547069475,1,['log'],['log']
Testability,"Hi @SHuang-Broad . This is a good question. There have been a number of changes to DeepVariant over releases. However, I don't think we've deeply revisited the timing advantages between CPU and GPU. I think that in our investigations, we see that in the GCP machines we use CPU instances still have some degree of cost advantage relative to GPU. I agree that it's likely we're not optimally using the GPU, and I don't think we've specifically optimized for higher utilization of it. Although that's something we could look more into over time, right now we're prioritizing other feature improvements. . For GPUs, how do you consider Parabricks as an option? I believe that with their most recent release, they will be able to run v1.5. For the optimization of GPU performance, I expect they are much better in using the GPU than our out-of-the-box code. By the way, $100/sample seems high to me relative to our current experience. I hope that might be a function of the older method being Call-Phase-Call. If you have new benchmarks for this I would be curious to know. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/650#issuecomment-1548690112:1022,benchmark,benchmarks,1022,,https://github.com/google/deepvariant/issues/650#issuecomment-1548690112,1,['benchmark'],['benchmarks']
Testability,"Hi @SHuang-Broad,. Thank you both for the detailed statistics background information. For PEPPER - we're now not using the code from that approach and instead are using the make_examples logic in DeepVariant. However, you conclusion will still be correct. Within make_examples and even call_variants we're still not using the GPU to its fullest capability. Improving GPU utilization is an area we could make progress on. However, the skill profile of the team will allow us to do the work, but not as quickly as for groups that have more experience optimizing GPU performance. As a result, we don't feel that our team's leverage is as high for that work as opposed to other projects. We may get to it eventually, but it will probably remain lower priority. @pgrosu Thank you for the I/O profile. We have also flagged I/O as a bottleneck and area for improvement in DeepVariant in general. At this time, for speed improvements, we are looking into optimizations which reduce the amount of data being passed back and forth for various function calls. This seems to us to be the most engineer-time efficient way to speed up DeepVariant currently. I am hopeful that this will result in runtime improvements in the next 1 or 2 releases. This should benefit both CPU and GPU ways of running. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/650#issuecomment-1551809050:187,log,logic,187,,https://github.com/google/deepvariant/issues/650#issuecomment-1551809050,1,['log'],['logic']
Testability,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```; docker run \; -v ""/input_files/input"":""/input"" \; -v ""/output_files/output"":""/output"" \; google/deepvariant:1.5.0 \; /opt/deepvariant/bin/make_examples \; ...; ```. This would be a first step to test before generalizing the file. Does this also work for you?. Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/677#issuecomment-1634515397:507,test,test,507,,https://github.com/google/deepvariant/issues/677#issuecomment-1634515397,1,['test'],['test']
Testability,"Hi @Suke-fudan , ; to answer your question about `./.`, please refer to https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md , specifically this section and the first sentence:; ""Missing variants where a candidate is generated:"". As explained there, DeepVariant makes a prediction which is probabilistic, based on the evidence it has, it might not always be as confident about its prediction. Our postprocessing logic can change a less confident call to a `./.` call. See this flag here:; https://github.com/google/deepvariant/blob/r1.3/deepvariant/postprocess_variants.py#L86-L89. As for ""RNC"" , I don't think that comes from DeepVariant. I wonder if it comes from GLnexus? But I'm not sure actually.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/494#issuecomment-1018054666:419,log,logic,419,,https://github.com/google/deepvariant/issues/494#issuecomment-1018054666,1,['log'],['logic']
Testability,"Hi @WenyuLiang ,. We have used the standard ONT mapping command to map Duplex reads to fastq:; ```; minimap2 -k 17 -ax map-ont -t <CPUS> <REF> <FASTQ>; ```; We have not tested other mapping modes for R10.4 to see if it improves overall mapping. If that is something you explore on your end and find improvements, please let us know by opening a github issue or reaching out over an email as we have not explored this extensively.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/617#issuecomment-1450589919:169,test,tested,169,,https://github.com/google/deepvariant/issues/617#issuecomment-1450589919,1,['test'],['tested']
Testability,"Hi @X1angyang . The model is InceptionV3. You can see the layers of one of the DeepVariant models like this:; ```; import tensorflow as tf. !gsutil cp gs://deepvariant/models/DeepVariant/0.10.0/DeepVariant-inception_v3-0.10.0+data-wgs_standard/model* /tmp/; checkpoint_path = '/tmp/model.ckpt'. reader = tf.compat.v1.train.NewCheckpointReader(checkpoint_path); shape_map_for_layers = reader.get_variable_to_shape_map(); print(shape_map_for_layers); ```; I just tested that in Colab (https://colab.research.google.com/). However, reimplementing all of DeepVariant from bam to output VCF would be a huge project. If you are interested in something smaller to get started, I'd like to bring this blog post to your attention: https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction/.; It has an associated Colab notebook that walks through some smaller but still challenging examples of how to use genomic data in machine learning using TensorFlow and Nucleus. I hope that helps!; Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/328#issuecomment-663252998:461,test,tested,461,,https://github.com/google/deepvariant/issues/328#issuecomment-663252998,1,['test'],['tested']
Testability,"Hi @Zjianglin , I took a quick look of the script and I'm not sure I fully understand what you're testing here. I tried a simplified version on my side. (The following steps has nothing to do with DeepVariant anymore. I'm mostly just testing `ls` and `singularity` right now). First I got these files in my /tmp; ```; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; wget -P /tmp ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P /tmp ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; ```. Then I made my deepvariant.sif. ```; singularity build deepvariant.sif docker://google/deepvariant:1.5.0; ```. First, I check that I have the files; ```; REF=/tmp/ucsc.hg19.chr20.unittest.fasta; ls -al ${REF}*; ```; This worked.; (Note, you were doing something like `ls -al ""${ref_idx}*""`. Don't add the double quotes around the *. That didn't work for me. ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant.sif \; ls -al ${REF}*; ```. This also worked fine for me. I can see the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1573188242:98,test,testing,98,,https://github.com/google/deepvariant/issues/653#issuecomment-1573188242,3,['test'],"['testdata', 'testing']"
Testability,"Hi @Zjianglin , the log above is a bit difficult for me to read. Can you confirm whether you have the fai file in your path `/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai`?. If not, can you index your FASTA file? You can use `samtools faidx hs37d5.fa` to create the index file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1559913831:20,log,log,20,,https://github.com/google/deepvariant/issues/653#issuecomment-1559913831,1,['log'],['log']
Testability,"Hi @ZuyaoLiu . When I tested calling and training, I also saw that message. But in both of my calling and training, the GPU was utialized. We added an entry in FAQ: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-am-i-seeing-cuda_error_not_initialized-initialization-error-while-running-on-gpu. and I mentioned that message in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-training-case-study.md#test-the-model as well. @ZuyaoLiu , can you help check whether the results of calling is reasonable on your side, and whether GPU is utilized or not?. And, similarly in the training case, some of the warning messages you have might not affect the results. Can you also check whether you can run through the steps (and whether GPU is utilized or not)?. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/722#issuecomment-1787602575:22,test,tested,22,,https://github.com/google/deepvariant/issues/722#issuecomment-1787602575,2,['test'],"['test-the-model', 'tested']"
Testability,"Hi @abrozzi, a quick check: where is the `quickstart-testdata` directory located? The Docker command you are using expects it to be under `/root`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/325#issuecomment-658938973:53,test,testdata,53,,https://github.com/google/deepvariant/issues/325#issuecomment-658938973,1,['test'],['testdata']
Testability,"Hi @aderzelle ,. Since you're using `zsh` as a shell just include single-quotes like this when you use wildcards:. `gsutil -m cp 'gs://deepvariant/quickstart-testdata/*' input/`. Or you could try `bash` as a shell :). Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/61#issuecomment-375468423:158,test,testdata,158,,https://github.com/google/deepvariant/issues/61#issuecomment-375468423,1,['test'],['testdata']
Testability,"Hi @aderzelle ; First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```; 90123; TGGGT; T--GTTC <-- Sample 1; TGTTC <-- Sample 2; ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/202#issuecomment-517123277:698,log,logic,698,,https://github.com/google/deepvariant/issues/202#issuecomment-517123277,1,['log'],['logic']
Testability,"Hi @aedavids, the below messages are expected when running DeepVariant. You will see these and many other logging outputs when you run the software. ```; I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10; min_base_quality: 10; min_base_quality_mode: ENFORCED_BY_CLIENT; ```. I do notice a possible issue with your Docker command, pasted below. ```; sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4; ```. Since you are mounting your local `/data/input` and `/data/output` directories to `/input` and `/output` in the container, you will want to change the file paths used in the command to reference the container directories. For example, in the below command, you can use: ; `--ref=/input/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/254#issuecomment-567577141:106,log,logging,106,,https://github.com/google/deepvariant/issues/254#issuecomment-567577141,1,['log'],['logging']
Testability,"Hi @ajsa-nukovic , thanks for reporting the issue. First, I tried to reproduce your issue. I haven't been able to reproduce it yet. I wrote down my commands below:. Get a Ubuntu18.04 machine ; ```; gcloud compute instances create ""${USER}-test"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-1804-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""e2-medium"" \; --zone ""us-west1-b""; ```. After ssh into the machine, I ran:. ```; sudo apt -y update && sudo apt -y install docker.io; ```. And then followed the steps here:. https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md. For the main DeepVariant command, I ran:. ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --intermediate_results_dir /output/intermediate_results_dir \; --num_shards=1 \; --call_variants_extra_args=""use_openvino=true"" \; 2>&1 | tee /tmp/deepvariant.log; ```. With this run above, all steps (including call_variants) completed without errors. After that run, I repeated the call_variants step:; ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/call_variants \; --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" \; --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" \; --checkpoint ""/opt/models/wgs/model.ckpt"" \; --use_openvino; ```; which worked fine too. You mentioned you used DeepVariant1.1.0 version via Docker, but you also mentioned your command was:; `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz -",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/432#issuecomment-806341687:239,test,test,239,,https://github.com/google/deepvariant/issues/432#issuecomment-806341687,1,['test'],['test']
Testability,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running.; please see below code and log file. ###### code #############; #!/usr/bin/env nextflow. nextflow.enable.dsl=2; params.outdir = '/home/deepak/integration/resu1'; params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'; params.refhg38 = '/home/deepak/integration/hg381_22XYM'; params.bed = '/home/deepak/integration'. workflow {; // Define channels for input data; Channel; .fromPath(""${params.data_dir}/*_sorted_md.bam""); .map { file -> ; def sample_id = file.baseName.replace('_sorted_md', ''); return [sample_id, file]; }; .set { read_pairs }; /// Step 1. DeepVariant; DeepVariant(read_pairs, params.refhg38, params.bed); }. process DeepVariant {; tag ""deepavar on ${sample_id}""; publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'; cpus 4; //BIN_VERSION 1.6.1. input:; tuple val(sample_id), path(read_files); val(params.refhg38); val(params.bed); ; output:; //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs; tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:; """"""; docker run \; -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \; google/deepvariant:latest \; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \; --reads /opt/bam/${read_files} \; --regions /opt/bed/hg38_exomeY.bed \; --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \; --num_shards ${task.cpus}; """"""; }. ######## code ################. terminal:; (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1); [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/883#issuecomment-2352056013:88,log,log,88,,https://github.com/google/deepvariant/issues/883#issuecomment-2352056013,2,['log'],['log']
Testability,"Hi @akolesnikov ,; Please find log files; [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log); [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/883#issuecomment-2360482009:31,log,log,31,,https://github.com/google/deepvariant/issues/883#issuecomment-2360482009,5,['log'],['log']
Testability,"Hi @alanlamsiu ,. If I understand correctly, your .sif file was previously built from our Docker version?. I'm going to walk through what I've tested so far. Maybe you can check which step is different from your experience. ---. Just to make sure I try it myself, here is what I did:. Get a GPU machine to test with:. ```bash; gcloud compute instances create ""${USER}-gpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --maintenance-policy ""TERMINATE"" \; --accelerator=type=nvidia-tesla-p100,count=1 \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-16"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. I ssh to the machine `gcloud compute ssh pichuan-gpu --zone us-west1-b`. Because my machine doesn't have Nvidia driver installed, I used:. ```bash; wget https://raw.githubusercontent.com/google/deepvariant/r1.6/scripts/install_nvidia_docker.sh; sudo bash -x install_nvidia_docker.sh ; ```; (the docker part is probably not necessary. I just need the driver). And then because I want to test Singularity, I install that with:. ```bash; wget https://raw.githubusercontent.com/google/deepvariant/r1.6/scripts/install_singularity.sh; sudo bash -x install_singularity.sh ; ```. Now, my machine has Singularity. I'll start following https://github.com/google/deepvariant/blob/r1.6/docs/deeptrio-quick-start.md#notes-on-singularity. I ran:. ```bash; BIN_VERSION=1.6.0; singularity pull docker://google/deepvariant:deeptrio-""${BIN_VERSION}-gpu""; ```. This created the file `deepvariant_deeptrio-1.6.0-gpu.sif` on my machine. I checked its size:. ```bash; pichuan@pichuan-gpu:~$ ls -lh deepvariant_deeptrio-1.6.0-gpu.sif ; -rwxrwxr-x 1 pichuan pichuan 12G Dec 5 07:38 deepvariant_deeptrio-1.6.0-gpu.sif; ```. ( @alanlamsiu , This is one thing I'd like you to double check. If you're converting from the 1.6.0 version, I don't think you should see `1.6.0rc2` in your .sif filename. Which is why I ask",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389:143,test,tested,143,,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389,2,['test'],"['test', 'tested']"
Testability,"Hi @anands-repo ,; to your original question about how the multiple images are combined, you can find the logic in https://github.com/google/deepvariant/blob/r0.8/deepvariant/postprocess_variants.py; Specifically, the function `merge_predictions` is the one that takes multiple images for multi-allelic cases and merge them.; As you can see, the comment in that function also refers to: ""See the logic described in the class PileupImageCreator pileup_image.py"", which is probably the logic you found. For your last question, I'll have to read and reply later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/197#issuecomment-512061556:106,log,logic,106,,https://github.com/google/deepvariant/issues/197#issuecomment-512061556,3,['log'],['logic']
Testability,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/224#issuecomment-540821357:138,test,test,138,,https://github.com/google/deepvariant/issues/224#issuecomment-540821357,3,['test'],['test']
Testability,"Hi @andremrsantos. I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend Best practices for multi-sample variant calling with DeepVariant. We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. In our benchmarks, we found this merging approach more accurate than merging with GATK GenotypeGVCFs (and we found merging DeepVariant gVCFs using GATK GenotypeGVCFs substantially less accurate than the single-sample DeepVariant VCFs themselves). Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/83#issuecomment-553660314:353,benchmark,benchmarks,353,,https://github.com/google/deepvariant/issues/83#issuecomment-553660314,1,['benchmark'],['benchmarks']
Testability,"Hi @annabeldekker . I'll paste some similar information from my answer in the other issue: https://github.com/google/deepvariant/issues/458#issuecomment-844317545. Hopefully my answer below will help you as well:. Starting from v1.1.0, we added an additional channel to our PacBio model, and tried to simplify the flags in the one-step `run_deepvariant` by adding just one flag `--use_hp_information`, which you can set to false if you're BAM is not phased, and set to true if your BAM is phased. Example:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md#run-deepvariant-on-haplotagged-chromosome-20-alignments. This `--use_hp_information` flag in the one-step `run_deepvariant` command actually controls both `sort_by_haplotypes` and `parse_sam_aux_fields` in the make_examples stage. If you set `--use_hp_information` to true in the one-step `run_deepvariant` command, that means `sort_by_haplotypes` and `parse_sam_aux_fields` are both set to true in make_examples stage. And if you set `--use_hp_information` to false, that means `sort_by_haplotypes` and `parse_sam_aux_fields` are both set to false in make_examples stage. In both cases, if you're running for PacBio, you always have to set `--add_hp_channel` to true in make_examples stage make sure the last channel is added. (If you're using the one-step `run_deepvariant` command, `--add_hp_channel` is automatically added). We tried our best to encaspulate these 3 flags into just one `--use_hp_information` in our one-step `run_deepvariant` command. However, I understand this might have caused further confusion when people tried to use the make_examples binary on its own.; You can find the logic here: ; https://github.com/google/deepvariant/blob/r1.1/scripts/run_deepvariant.py#L240-L242. I will try to update our deepvariant-pacbio-model-case-study.md file to document this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/457#issuecomment-845522247:1698,log,logic,1698,,https://github.com/google/deepvariant/issues/457#issuecomment-845522247,1,['log'],['logic']
Testability,"Hi @bopohdr ; Thank you, the log is helpful.; From the error, specifically this line:; ```; ValueError: Failed precondition: Cannot query without an index; ```; It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:; `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/232#issuecomment-549225504:29,log,log,29,,https://github.com/google/deepvariant/issues/232#issuecomment-549225504,1,['log'],['log']
Testability,"Hi @bopohdr, if it's possible, can you send me to full log?. In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:; ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/232#issuecomment-548948642:55,log,log,55,,https://github.com/google/deepvariant/issues/232#issuecomment-548948642,1,['log'],['log']
Testability,"Hi @chrisfleisch , sorry it took me a while to find some time to try this. I just got an AMD machine on Google Cloud to test. But, I'm unable to reproduce your issue in the `make_examples` step.; I'll post what I did below (which didn't reproduce your error).; But, maybe this Stackoverflow issue could be related?; https://stackoverflow.com/questions/52026652/openblas-blas-thread-init-pthread-create-resource-temporarily-unavailable; Specifically, can you try the suggestion in https://stackoverflow.com/a/54746150 and let me know if that worked for you?. ---. For completeness, here is what I tried:. I got a AMD machine:. ```; gcloud compute instances create ""${USER}-amd"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-1604-lts"" --image-project ""ubuntu-os-cloud"" \; --machine-type ""n2d-standard-16"" --boot-disk-size ""100"" \; --zone ""europe-west4-b""; ```. On that machine, I ran:; ```; $ lscpu; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 16; On-line CPU(s) list: 0-15; Thread(s) per core: 2; Core(s) per socket: 8; Socket(s): 1; NUMA node(s): 1; Vendor ID: AuthenticAMD; CPU family: 23; Model: 49; Model name: AMD EPYC 7B12; Stepping: 0; CPU MHz: 2249.998; BogoMIPS: 4499.99; Hypervisor vendor: KVM; Virtualization type: full; L1d cache: 32K; L1i cache: 32K; L2 cache: 512K; L3 cache: 16384K; NUMA node0 CPU(s): 0-15; Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid; ```. Then, I ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/274#issuecomment-599870096:120,test,test,120,,https://github.com/google/deepvariant/issues/274#issuecomment-599870096,1,['test'],['test']
Testability,"Hi @chrisfleisch ; I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:; https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-480945659:457,test,tested,457,,https://github.com/google/deepvariant/issues/132#issuecomment-480945659,1,['test'],['tested']
Testability,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/672#issuecomment-1613645470:34,log,log,34,,https://github.com/google/deepvariant/issues/672#issuecomment-1613645470,1,['log'],['log']
Testability,"Hi @crazysummerW ,. DeepTrio will ignore the existing HP value from the BAM, and will use our internal read phasing.; Specifically, this block of logic deals with that:; https://github.com/google/deepvariant/blob/r1.6/deepvariant/make_examples_core.py#L2133-L2135. I agree that the way our case study is written is confusing. We should at least mentioned that the HP information from the BAM would be discarded, or use an unphased BAM as an example. I will file an internal issue to track this, so we can update it in the future. Thanks for noticing this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/720#issuecomment-1782229530:146,log,logic,146,,https://github.com/google/deepvariant/issues/720#issuecomment-1782229530,1,['log'],['logic']
Testability,"Hi @crazysummerW ,. Looking at your error, it seems like this might be relevant:. ```; File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 241, in make_fid; fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5f.pyx"", line 122, in h5py.h5f.create; OSError: [Errno 5] Unable to synchronously create file (unable to lock file, errno = 5, error message = 'Input/output error'); ```. This is because this logic in our code writes a temp file:; https://github.com/google/deepvariant/blob/r1.6/deepvariant/keras_modeling.py#L97-L99. ```; tmp_weights_dir = tempfile.gettempdir(); tmp_weights_path = os.path.join(tmp_weights_dir, 'tmp_weights.h5'); model.save_weights(tmp_weights_path); ```. Can you check your setting, and see if somehow your run wasn't able to create a temp file?. I reran our set up in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md (using a GCP machine as an example) and wasn't able to reproduce that error. So, it'll be very helpful for me to understand your machine setup, and try to make our code more robust in the future. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/725#issuecomment-1799132190:582,log,logic,582,,https://github.com/google/deepvariant/issues/725#issuecomment-1799132190,1,['log'],['logic']
Testability,"Hi @crazysummerW ,. One more thought:; You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here.; That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:; When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:; ```; deepconsensus run \; --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \; --ccs_bam=${shard_id}.ccs.bam \; --checkpoint=model/checkpoint \; --output=${shard_id}.output.fastq; ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/672#issuecomment-1615974070:61,test,tested,61,,https://github.com/google/deepvariant/issues/672#issuecomment-1615974070,1,['test'],['tested']
Testability,"Hi @crazysummerW . The message here is most consistent with reads that do not have quality values. Inspection of the GIAB file indicates that this is the case here - the reads have bases and not quality values. These GIAB files appear to be deposited in 2018. It seems likely to me that they are PacBio continuous long read (CLR) sequencing instead of Circular Consensus Sequencing (CCS). PacBio CLR sequencing has a higher base error rate and DeepVariant is not designed to process this older type of sequence data. . Mechanically, the reason this input file fails is that it lacks quality values, which DeepVariant expects. CLR sequencing does not generate quality values. For test data, I recommend using a more recent set of sequencing which use the CCS prep, e.g. the contents of: . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_CCS_15kb_20kb_chemistry2/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/631#issuecomment-1507742336:679,test,test,679,,https://github.com/google/deepvariant/issues/631#issuecomment-1507742336,1,['test'],['test']
Testability,"Hi @danielecook , I was trying various things that would require least amount of effort. I ended up just skipping and using the `google/deepvariant` docker image as-is.; I'm no expert in docker, just trying to get things running. ; Then I also have the issue that singularity can't use/convert the deepvariant docker image:; ```; $ singularity build --sandbox deepvariant_1_1_0 docker://gcr.io/deepvariant-docker/deepvariant:1.1.0; WARNING: Building sandbox as non-root may result in wrong file permissions; Docker image path: gcr.io/deepvariant-docker/deepvariant:1.1.0; ERROR MANIFEST_UNKNOWN: Manifest with tag '1.1.0' has media type 'application/vnd.docker.distribution.manifest.v2+json', but client accepts 'application/json'.; Cleaning up...; ```; This may be my inexperience in these things, but I'm simply having trouble getting them running.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/445#issuecomment-822613451:352,sandbox,sandbox,352,,https://github.com/google/deepvariant/issues/445#issuecomment-822613451,2,['sandbox'],['sandbox']
Testability,"Hi @danielecook ,; I tried without ```--debug=false``` and set ```--config.num_epochs=10``` but I still get the same error that ```--config.num_epochs=10```. I attached my log file here . [train_040324.log](https://github.com/google/deepvariant/files/14873081/train_040324.log). THis is the command I used:; ```; BIN_VERSION=""1.6.1""; DOCKER_IMAGE=""google/deepvariant:${BIN_VERSION}"". time sudo docker run --gpus 1 \; -v /home/${USER}:/home/${USER} \; -w /home/${USER} \; ${DOCKER_IMAGE}-gpu \; train \; --config=s3-mount/deepvariant_training/script/dv_config.py:base \; --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \; --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \; --config.init_checkpoint=""${GCS_PRETRAINED_WGS_MODEL}"" \; --config.num_epochs=10 \; --config.learning_rate=0.02 \; --config.num_validation_examples=0 \; --experiment_dir=""model_train"" \; --strategy=mirrored \; --config.batch_size=512; ```. Did I miss anything?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2037432899:172,log,log,172,,https://github.com/google/deepvariant/issues/802#issuecomment-2037432899,3,['log'],['log']
Testability,"Hi @dbhayal9 , from your log, it seems like DeepVariant finished running, and generated an output VCF here: /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz. Can you try looking for the file? Something like. `ls /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz`. and if it exist, you can `zcat` it to see if it has the expected content?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/883#issuecomment-2392384965:25,log,log,25,,https://github.com/google/deepvariant/issues/883#issuecomment-2392384965,1,['log'],['log']
Testability,"Hi @dkurt , an update and a question for you:. I was curious about the runtime myself, so over the weekend, I tried building and running the version with OpenVINO to observe the behavior of call_variants. Specifically, I did something similar to https://github.com/google/deepvariant/blob/r1.0/scripts/run_wgs_runtime_test_docker.sh - but I incorporate your changes, and build the docker with OpenVINO, and made sure I ran call_variants with OpenVINO. Here is a strange thing I found in my log:. ```; ...; W1019 04:32:52.604453 140673783289600 deprecation.py:323] From /tmp/Bazel.runfiles_mdh0lz62/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave >; Instructions for updating:; Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Opti>; 2020-10-19 04:32:52.727391: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_thread>; W1019 04:32:52.748747 140673783289600 deprecation.py:323] From /tmp/Bazel.runfiles_mdh0lz62/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from >; Instructions for updating:; Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the f>; I1019 09:14:02.799481 140673783289600 call_variants.py:520] Writing calls to /tmp/tmpll7hkhwu/call_variants_output.tfrecord.gz; I1019 09:14:02.804919 140673783289600 call_variants.py:538] Processed 1 examples in 1 batches [0.284 sec per 100]; I1019 09:14:04.482554 140673783289600 call_variants.py:538] Processed 15001 examples in 30 batches [0.011 sec per 100]; I1019 09:14:06.172387 140673783289600 call_variants.py:538] Processed 30001 examples in 59 batches [0.011 sec per 100]; I1019 09:14:07.867975 140673783289600 call_var",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-712402658:490,log,log,490,,https://github.com/google/deepvariant/pull/363#issuecomment-712402658,1,['log'],['log']
Testability,"Hi @dkurt ,. I've tested your change, and compare to without using OpenVINO (we internally are now using `intel-tensorflow==2.5.0`). Here are the call_variants runtime comparison on our latest code:; * WGS:; * Without OpenVINO: ~166m (this was an average from 3 runs); * With OpenVINO: 151m26.692s (this was from one run. I can do 2 more runs to reduce the variance for comparison). My PacBio and Hybrid runs are still going. I can report them when they're done. I want to check whether this is roughly inline with your expectation, or if there are things I need to tweak further. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/472#issuecomment-878550413:18,test,tested,18,,https://github.com/google/deepvariant/pull/472#issuecomment-878550413,1,['test'],['tested']
Testability,"Hi @dkurt ,; thank you for sending this PR. . From the discussion between you and Andrew above, here is my current summary:. 1. You are planning to do more benchmarking on this change, and will let us know when you have some numbers on runtime improvement.; 2. You want to know whether we're interested in enabling GitHub Actions. For 2., I am not familiar with GitHub Actions, but it seems interesting! I'll file an internal issue to look into this. This will likely fall under a lower priority, but I want to let you know that we'll track it and give you update if any. If there are more details that you wish to contact directly, please feel free to email me at pichuan@google.com. We can also continue to communicate here to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-710709303:156,benchmark,benchmarking,156,,https://github.com/google/deepvariant/pull/363#issuecomment-710709303,1,['benchmark'],['benchmarking']
Testability,"Hi @dkurt . First, thank you for your interest in DeepVariant, and for the substantial work that you have put into these modifications. I have some questions for you, and I suspect @pichuan may add some questions and comments as well. 1. We do not directly accept external PRs, but this is not because we do not accept community additions. The ""source of truth"" for the DeepVariant GitHub repo resides in internal systems, which are then copied onto GitHub. As a result, to incorporate your changes, we will need to change the internal code and copy that back out. We have done this in the past with community additions, and have attributed the authors for contributions in release notes and other forums. 2. Can you help me understand the expected benefit of the changes? It looks like this should improve runtime for call_variants. Do you have any high-level information from benchmark runs for us to understand the percentage improvement to expect. 3. If we are to incorporate these changes, we would want to make sure this would perform well across various hardware. For example, we would want our Docker images to gracefully fallback to working code if it is on a machine with incompatible hardware. Do you expect OpenVINO to have this property (for example, if someone is running on an AMD machine). 4. We will also have to think about how these changes interact with any updates we would make to our use of TensorFlow. We're not directly planning anything in the near future, but it's good for us to consider. . I suspect that we will try to run with these changes and see how the performance changes. If you are able to answer some of these questions, it could be helpful for us to understand how to prioritize their assessment. Thank you again for the work you have put into this. It's quite impressive, and we appreciate your effort. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-709920659:878,benchmark,benchmark,878,,https://github.com/google/deepvariant/pull/363#issuecomment-709920659,1,['benchmark'],['benchmark']
Testability,"Hi @duceppemo , can you clarify what error message you were seeing when you try with a BAM file with `.csi` indices?. I just tested with data from https://github.com/google/deepvariant/blob/r1.2/docs/deepvariant-quick-start.md. And I deliberately deleted the `.bai` index file and created a `.csi` instead:. ```; $ rm -f quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam.bai; $ samtools index -c quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam; $ ls quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam*; quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam; quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam.csi; ```. After that, it seems like I was still able to go through the Quick Start steps without any issues. DeepVariant is using htslib to read BAM files, and it seems like `.csi` is already supported there. Can you give me an reproducible example, if you're seeing any issues?. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/481#issuecomment-919633316:125,test,tested,125,,https://github.com/google/deepvariant/issues/481#issuecomment-919633316,6,['test'],"['testdata', 'tested']"
Testability,"Hi @ed5152 - adding an additional class may require a substantial amount of work. You will likely need to update the make_examples step, the training/inference step, and the postprocessing step. Can you provide additional context for what you are trying to do?. [make_examples_core.py](https://github.com/google/deepvariant/blob/r1.2/deepvariant/make_examples_core.py#L1504-L1519) contains the logic for generating examples. You would modify the code to allow for an additional class here. Then you would need to subclass the DeepVariant model to modify the final layer and add an extra output. https://github.com/google/deepvariant/blob/b6a91d5f8514cc09a4f059b9980ac80043a899c3/deepvariant/modeling.py#L420-L426. Finally, you would need to update [postprocess_variants.py](https://github.com/google/deepvariant/blob/r1.2/deepvariant/postprocess_variants.py) to handle an additional class output.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/495#issuecomment-981766539:394,log,logic,394,,https://github.com/google/deepvariant/issues/495#issuecomment-981766539,1,['log'],['logic']
Testability,"Hi @ekofman , ; thanks for reporting this!. It seems like you're using the example from the WGS case study. From my experience, suppose you on a 4-core machine, if you specify a $numShards bigger than 4 (say, 64), `parallel` will actually still just run 4 at a time. Therefore, it might run 0-3 first. And when they finished, `parallel` will proceed with the range of 4-7, etc. Because of that, if you run 64 shards on 4-core machine, you won't see all 64 jobs started at the same time. Can you first confirm whether that's the case for you? ; In your case, if somehow all 64 `make_examples` started on the same machine that 4 cores, it is possible that the machine starts becoming resource constrained and swapping a lot, therefore nothing will finish. But the first thing will be to check whether `parallel` handles this for you (which is my experience in the past).; @ekofman , please let me know what you observe. And, it'll also be useful to know how many cores are on your machine, and how much RAM. If you can check your system resources while you're running to see what resource might be exhausted, that will also be useful to know. If your BAM file is sharable / public, I'm also happy to run a few test runs myself. I expect changing $numShards should work, so I'd really like to know what went wrong here and fix it. Thanks!. The GCP runner code that @pgrosu mentioned is actually a separate example. The GCP runner config is evolving over time as well, so it's by no means the best (or only) config that we recommend. But it's a useful example to see how to orchestrate these jobs on multiple machines on Google Cloud. For example, the amount of RAM it requests for its workers can be a good example of how much you might need.; I'm adding @nmousavi, our collaborator on the Cloud team, as a FYI since Paul's comment mentioned the GCP runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/150#issuecomment-460861609:1208,test,test,1208,,https://github.com/google/deepvariant/issues/150#issuecomment-460861609,1,['test'],['test']
Testability,"Hi @ekofman ,. a few things:. (1) The `@64` format correspond to `000??-of-00064`. So, in your case, it is expected that `--examples ""${sample_id}.examples.tfrecord@${numShards}.gz""` in the `make_examples` step generated ; `test.examples.tfrecord-000??-of-00064.gz` (shards from 00 to 63). (2) From the command you pasted, it seems like you're directly running inside docker.; If that is the case, you don't need the [-v flags](https://docs.docker.com/storage/volumes/), but you still need to make sure that the files are actually visible when/where you run call_variants.; If you're still running call_variants inside docker (like you did for your make_examples step), please make sure when you can see `test.examples.tfrecord-000??-of-00064.gz` from where you run the command. So, `ls test.examples.tfrecord-000??-of-00064.gz` should see the files. The command you pasted from our run_wgs_case_study_docker.sh example is actually different from the make_examples command you posted first. If you're using that, you need to make sure you're using the [-v flags](https://docs.docker.com/storage/volumes/) correctly and make sure the files are visible to it. (3) I tested with `sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.2` first and directly running the commands inside. I modified from the WES example because it's faster, but WGS should be the same. I can confirm that I was able to run the following steps without any issues:. 1. Start interactive mode so I can use command similar to yours. I'm not considering how I'm getting the data out.; ```; sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.2; ```. 2. Inside the interactive mode, run the following:; ```; MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wes_standard""; DATA_HTTP_DIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata; N_SHARDS=""64"". ## Download extra packages; sudo apt-get -y update; sudo apt-get -y in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:224,test,test,224,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,3,['test'],['test']
Testability,"Hi @elcortegano . Interesting, that is a lot larger than I expected. But I ran a test and got a similar result with a PacBio BAM. . Can you attach just that single read here as a BAM file (using the grep command). I can likely run a test from that. If that fails, the best way might be to upload to a Google Drive object and share permissions with me for the 300MB file. Thank you for your patience,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/434#issuecomment-814530426:81,test,test,81,,https://github.com/google/deepvariant/issues/434#issuecomment-814530426,2,['test'],['test']
Testability,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/200#issuecomment-513411694:716,benchmark,benchmarks,716,,https://github.com/google/deepvariant/issues/200#issuecomment-513411694,1,['benchmark'],['benchmarks']
Testability,"Hi @fo40225, thank you so much for this pull request. At the moment we cannot accept external contributions (see https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md) as we don't yet have a mechanism setup to resync changes from GitHub back into our codebase within Google. We will look into these changes and are happy to submit a patch after internal testing and benchmarking. Are you ok with that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/152#issuecomment-462244723:366,test,testing,366,,https://github.com/google/deepvariant/pull/152#issuecomment-462244723,2,"['benchmark', 'test']","['benchmarking', 'testing']"
Testability,"Hi @forumsan, thanks for reporting this issue! Others users have reported seeing this message as well. When we looked into this issue internally, we found out that this was actually a problem with logging in TensorFlow, and AVX-512 instructions are being used correctly. If you try running DeepVariant on a CPU-only machine that does not support AVX-512, you should see a clear increase in the overall runtime. The logging issue has since been fixed in TensorFlow, but won't show up in our current Docker images. This is because we are installing a version of the intel-tensorflow package that does not contain the fix. I'll close this issue for now, but feel free to reopen if you still have other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/301#issuecomment-617907163:197,log,logging,197,,https://github.com/google/deepvariant/issues/301#issuecomment-617907163,2,['log'],['logging']
Testability,"Hi @forumsan, you are already getting the speedup from AVX2/AVX-512 if you are using Intel Skylake or later! :) The message you are seeing is an issue with logging in TensorFlow. Feel free to ignore that message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/301#issuecomment-618511477:156,log,logging,156,,https://github.com/google/deepvariant/issues/301#issuecomment-618511477,1,['log'],['logging']
Testability,"Hi @gambalab . The data for our hybrid model is described here: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-hybrid-case-study.md . It's merged from PacBio and Illumina data. We have a page that describes the amount of training data we used for the models for each release, you can find them in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-details-training-data.md. If you need some BAM files to train on, you can also see our [An Extensive Sequence Dataset of Gold-Standard Samples for Benchmarking and Development](https://doi.org/10.1101/2020.12.11.422022) manuscript. (Data can be found in `gs://brain-genomics-public/research/sequencing` ) For Hybrid, you'll need to make the hybrid BAM files yourself following the instructions in the first documentation. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/721#issuecomment-1777228301:527,Benchmark,Benchmarking,527,,https://github.com/google/deepvariant/issues/721#issuecomment-1777228301,1,['Benchmark'],['Benchmarking']
Testability,"Hi @gevro,. Early in building the PacBio models, we benchmarked on both NGMLR and Minimap2/pbmm2 and found that they gave similar quality of variant calls. We train with data from Minimap2/pbmm2, and I would recommend using pbmm2 for the mapper.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/295#issuecomment-608975822:52,benchmark,benchmarked,52,,https://github.com/google/deepvariant/issues/295#issuecomment-608975822,1,['benchmark'],['benchmarked']
Testability,"Hi @githubtefo ,; When you run the command, you should have logs in the terminal.; Can you provide those logs?. And, can you try something simple like https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-pacbio-model-case-study.md first? That should certainly have logs when you run it. If not, there's something else wrong in your environment that we need to understand first.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/810#issuecomment-2068119641:60,log,logs,60,,https://github.com/google/deepvariant/issues/810#issuecomment-2068119641,3,['log'],['logs']
Testability,"Hi @gunjanbaid , I am a novice when it comes to beam. So I will defer to you on https://github.com/google/deepvariant/pull/365#discussion_r512315819. My setup works with Spark/Flink so I can test it out. I am looking at another part of the code that is potentially fatal for execution at the moment:; ``` ; return (input_examples; | 'Randomize' >> beam.Map(lambda x: (sha1(x), x)); | 'Groupby' >> beam.GroupByKey(); | 'DropKey' >> beam.FlatMap(lambda x: x[1])); ```. I notice that GroupByKey is loading all of the data into the memory of the worker. Is this not a problem for DataflowRunner?. I am trying to run shuffle on tfrecords produced from 6 BAM files. The gzipped tfrecords are approximately 120GB in total, and GroupByKey quickly runs out of memory when the machine has over 600GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/365#issuecomment-717368605:191,test,test,191,,https://github.com/google/deepvariant/pull/365#issuecomment-717368605,1,['test'],['test']
Testability,"Hi @gunjanbaid . Unfortunately I am not compiling for x86, but for IBM power, so most of the installation scripts need to be discarded, and packages need to be manually compiled from source using IBM's Advance Toolchain gcc compilers. I have finally gotten all bazel tests to complete as well as the build to complete. I was wondering whether you could explain one piece of the build files though - this is just out of curiosity. In build_release_binaries, there is a function that starts as follows - which seems to be performing a hack to fix something:; ```; # Bazel's --build_python_zip replaces our carefully engineered symbolic links; # with copies. This function puts the symbolic links back.; function fix_zip_file {; orig_zip_file=$1. # Step 1: Copy the zip file to a temporary place.; TMPDIR=$(mktemp -d -t tmp.XXXXXXXXXXX); # The .zip version of the binary doesn't have the header that makes it; # self-executable. We use that version because otherwise unzip would; # complain and raise an error code.; cp ""${orig_zip_file}.zip"" ""${TMPDIR}""; ```. Would you be able to give a quick explanation of what the problem is? I understand what it does, but I do not understand why it is needed, or whether it is just for convenience. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/356#issuecomment-699007209:267,test,tests,267,,https://github.com/google/deepvariant/issues/356#issuecomment-699007209,1,['test'],['tests']
Testability,"Hi @gunjanbaid I do not see the same issue now. I switched to openjdk-11. However, I still need to pass the --host_javabase option, which is not present by default in the build scripts. I do see another issue. The trace is as follows; ```; (02:26:24) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:413:1: ClifProtoLibraryGeneration third_party/nucleus/protos/bedgraph_pyclif.h failed (Exit 1): proto failed: error executing command; (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \; exec env - \; bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/bin/third_party/nucleus/protos/bedgraph_pyclif.cc -h bazel-out/ppc-opt/bin/third_party/nucleus/protos/bedgraph_pyclif.h '--strip_dir=bazel-out/ppc-opt/bin' '--source_dir='\''.'\''' third_party/nucleus/protos/bedgraph.proto). Execution platform: @bazel_tools//platforms:host_platform ; Traceback (most recent call last): ; File ""bazel-out/host/bin/external/clif/proto"", line 5, in <module>; from clif.python.proto import start ; File ""/root/opt/clif/lib64/python3.6/site-packages/clif/python/proto.py"", line 29, in <module>; from clif.python.utils import proto_util ; ImportError: libprotobuf.so.24: cannot open shared object file: No such file or directory. ```. This is for the following command from build_and_test.sh:; ```; bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \; deepvariant/...; ```. Why is bazel running ```exec env -``` here? This is invalidating library paths (LD_LIBRARY_PATH variable) where it would find ```libprotobuf.so```. As expected, when I run the failing command from the trace without ```exec env -```, it is fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/355#issuecomment-697093712:1357,test,test,1357,,https://github.com/google/deepvariant/issues/355#issuecomment-697093712,1,['test'],['test']
Testability,"Hi @gunjanbaid,; I'm starting pipeline with a GCP runner like this:; ```; MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard; IMAGE_VERSION=0.6.1; DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}""; DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \; --project ""${PROJECT_ID}"" \; --zones ""${ZONES}"" \; --docker_image ""${DOCKER_IMAGE}"" \; --docker_image_gpu ""${DOCKER_IMAGE_GPU}"" \; --gpu \; --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \; --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \; --model ""${MODEL}"" \; --ref ""${INPUT_REF}"" \; --bam ""${INPUT_BAM}"" \; --shards 512 \; --make_examples_workers 16 \; --make_examples_cores_per_worker 10 \; --make_examples_ram_per_worker_gb 60 \; --make_examples_disk_per_worker_gb 200 \; --call_variants_workers 16 \; --call_variants_cores_per_worker 8 \; --call_variants_ram_per_worker_gb 30 \; --call_variants_disk_per_worker_gb 50; ```; I've checked logs - a bunch of tasks failed (8, 32, 67, 105, 192, 231, 261, 293, 358).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/207#issuecomment-523380440:1064,log,logs,1064,,https://github.com/google/deepvariant/issues/207#issuecomment-523380440,1,['log'],['logs']
Testability,"Hi @gyuhee0928 ,. By default, `make_examples` only creates pileup images for candidates that are created by our default candidate generation logic. After the examples are created, you can then visualize these examples by using `show_examples`: https://github.com/google/deepvariant/blob/r1.1/docs/show-examples.md. We do have a more advanced optional flag you can specify to use `vcf_candidate_importer` instead. It is a more advanced / experimental implementation , where we allow the users to provide a list of candidates that they want DeepVariant to call. You can see an example use case here: https://gist.github.com/pichuan/baba6ee9bd9890be2a45076a4934dd38. Another important use case for `vcf_candidate_importer` is [PEPPER-DeepVariant](https://github.com/kishwarshafin/pepper) which works on Oxford Nanopore long-read data. We haven't written an official documentation for this, because there are many subtle details when providing the VCF file for --proposed_variants, otherwise it might confuse DeepVariant. You're welcome to give it a try, and feel free to ask questions here. Our team might be a bit slower to answer specific questions on vcf_candidate_importer, but we can try our best to support. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/438#issuecomment-819098517:141,log,logic,141,,https://github.com/google/deepvariant/issues/438#issuecomment-819098517,1,['log'],['logic']
Testability,"Hi @helizabeth1103 , the logic is in; https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`?. If you have that file, then this should be true:. ```; use_saved_model = tf.io.gfile.exists(; _CUSTOMIZED_MODEL.value; ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'); ```. And then:; ```; if use_saved_model:; logging.info('Using saved model: %s', str(use_saved_model)); ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/866#issuecomment-2285478515:25,log,logic,25,,https://github.com/google/deepvariant/issues/866#issuecomment-2285478515,3,['log'],"['logging', 'logic']"
Testability,"Hi @husamia ,; I see that you're running DeepTrio.; For both DeepVariant or DeepTrio, it will generate intermediate files for each step (make_examples, call_variants). . For DeepTrio, the size of these intermediate files might even be bigger, which might fill up your disk in the process. I guess it is possible that Docker setting has some limit. I'm not familiar enough Docker to help with that. A few suggestions here:. 1. Can you tell us how big your 3 BAM files are? For comparison, what we used in WGS in https://github.com/google/deepvariant/blob/r1.1/docs/metrics-deeptrio.md is:; ```; $ gsutil ls -lh gs://deepvariant/case-study-testdata/HG00?.novaseq.pcr-free.35x.dedup.grch38_no_alt.bam; 42.87 GiB 2020-07-16T22:57:42Z gs://deepvariant/case-study-testdata/HG002.novaseq.pcr-free.35x.dedup.grch38_no_alt.bam; 43.59 GiB 2020-08-19T20:40:44Z gs://deepvariant/case-study-testdata/HG003.novaseq.pcr-free.35x.dedup.grch38_no_alt.bam; 42.88 GiB 2020-08-19T20:40:34Z gs://deepvariant/case-study-testdata/HG004.novaseq.pcr-free.35x.dedup.grch38_no_alt.bam; TOTAL: 3 objects, 138872581896 bytes (129.34 GiB); ```; 2. You can try one run with just one chromosome first, e.g., just chr20 (using the `--regions` flag) to see if I can get that run to finish. . I'm going to close this issue first. But if there are anything else we can help with, feel free to reopen or file a new issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/400#issuecomment-750715758:638,test,testdata,638,,https://github.com/google/deepvariant/issues/400#issuecomment-750715758,4,['test'],['testdata']
Testability,"Hi @jaydevshelat . DeepVariant's checkpoints are based on InceptionV3 and use slim, see https://github.com/google-research/tf-slim. I can share with you some code that @pichuan has written to read the checkpoints, but if you have any further questions on that, please consult the documentation for tensorflow or tf-slim.; ```; ! pip install tf-slim. import tensorflow.compat.v1 as tf; import os; import tf_slim as slim; from tf_slim.nets import inception_v3. !gsutil cp gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard/model* /tmp/; ckpt_file = '/tmp/model.ckpt'. graph = tf.Graph(). with graph.as_default():; images = tf.placeholder(tf.float32, shape=(None, 100, 221, 6)). with slim.arg_scope(inception_v3.inception_v3_arg_scope()):; _, end_points = inception_v3.inception_v3(images, is_training=False, ; num_classes=3,; create_aux_logits=False); ; print(""end_points:""); print(end_points.keys()); # Restore the checkpoint; sess = tf.Session(graph=graph); saver = tf.train.Saver(); saver.restore(sess, ckpt_file); ```. For training, you would need a lot more training data than the quickstart-testdata, as in multiple samples of WGS worth of sequencing data. For more information on training, see the documentation: https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/339#issuecomment-682069726:1135,test,testdata,1135,,https://github.com/google/deepvariant/issues/339#issuecomment-682069726,1,['test'],['testdata']
Testability,"Hi @jaydevshelat, this [doc](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-build-test.md) shows you how to build from source. Note that it mentions support for Ubuntu 14 and 16, so you may need to make some changes in order for it to work on your OS. Feel free to followup if you hit any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/340#issuecomment-685893807:101,test,test,101,,https://github.com/google/deepvariant/issues/340#issuecomment-685893807,1,['test'],['test']
Testability,"Hi @jdmontenegro . For the question about multi-allelic heterozygous calls - yes, DeepVariant is able to all 1/2 events, and will represent these in one line as a GT 1/2 call in the VCF. For CLR calling in DeepVariant. It is theoretically possible for us to make a model for DeepVariant that can call CLR data. However, this requires us to write a special candidate generation logic to deal with the higher error rate. Based on what we perceive for the direction of future use in the genomics community, we think that data generated will be increasingly HiFi, so we have not been able to highly prioritize CLR models. Feedback from users like yourself will be useful to us in evaluating if that prioritization makes sense. For now, I can't commit to a timeframe under which we would support a PacBio CLR model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/347#issuecomment-693053180:377,log,logic,377,,https://github.com/google/deepvariant/issues/347#issuecomment-693053180,1,['log'],['logic']
Testability,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision?. You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors?. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334644453:347,log,log,347,,https://github.com/google/deepvariant/issues/879#issuecomment-2334644453,1,['log'],['log']
Testability,"Hi @jguhlin ,; thanks for the feedback, and for letting us know that our users are still interested in Singularity images.; I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. ; But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:; https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```; gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg; gs://deepvariant/singularity_images/deepvariant-0.9.0.simg; ```; Or you can find them in the browser here:; https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you?. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:; https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```; VERSION=0.9.0; sudo apt -y update && sudo apt-get install -y docker.io; sudo docker pull google/deepvariant:${VERSION}; sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest; sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2; sudo docker push localhost:5000/deepvariant:latest; SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest; ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant-${VERSI",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/243#issuecomment-561996442:855,test,test,855,,https://github.com/google/deepvariant/issues/243#issuecomment-561996442,1,['test'],['test']
Testability,"Hi @jumpyknight . **tl;dr - VCF_caller represents experimental functionality not ready for production use**. DeepVariant has three stages **make_examples** identifies candidate positions that may be variants using relatively simple human-written heuristics. **call_variants** applies the trained neural net model to identify which of these candidates are real variants and at what probability. **postprocess_variants** converts these probability to a VCF output. From the first versions of DeepVariant, very_sensitive_caller has been the logic used to generate candidates for make_examples. VCF_caller is an experimental feature we have been developing that would allow the generation of candidates directly from an input VCF, so that different (or third-party) logic could be applied to generate candidates. However, this feature is not ready for production use. Its inclusion here occurs because this code is in our main branch at the release time and reflects our internal use and experiments with it. DeepVariant v0.9 still uses very_sensitive_caller to generate candidates and VCF_caller is not used for any released model. We attempt to fully document and mention in release notes features that are ready for use. Your eyes to the released code are astute, I was not expecting to field questions for VCF_caller.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/256#issuecomment-568660419:538,log,logic,538,,https://github.com/google/deepvariant/issues/256#issuecomment-568660419,2,['log'],['logic']
Testability,"Hi @kalexiou ,; if the file is not public, unfortunately I cannot download it or test it. Thanks for offering though. If you can share a bit more about what type of file this is (sequencing instrument, coverage, PCR-free or PCR-plus, etc) that might make this file unique, maybe I can try to see if I can reproduce the issue on another public file. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/427#issuecomment-789122414:81,test,test,81,,https://github.com/google/deepvariant/issues/427#issuecomment-789122414,1,['test'],['test']
Testability,"Hi @karoliinas ,; From your log, it seems like the DeepVariant model has made a prediction with unexpected numerical value. From your log, I'm unable to tell why this has occurred. In this command:. `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz""`. If you can share the `sample1.intermediate/call_variants_output.tfrecord.gz` (and optionally`sample1.intermediate/gvcf.tfrecord@19.gz` files) with me, I can able to look into the records and see which example has this issue. (Or, if you can narrow this down to a small BAM file, and if you can share that BAM file, that works too). Please email to pichuan@google.com if you can share. If you can't share the files, we can think about what we can do here to help identify which example caused the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/849#issuecomment-2221028135:28,log,log,28,,https://github.com/google/deepvariant/issues/849#issuecomment-2221028135,2,['log'],['log']
Testability,"Hi @karoliinas . As Pi-Chuan mentioned, it is (in theory) possible to train a quartet model, but it would take work. If you want to always have consistent calls between parents and child, the best thing is probably to either use parent calling from only 1 DeepTrio run, or to run DeepVariant instead on the full quartet. In the event that you do want to use DeepTrio on both trios as opposed to DeepVariant on the four, there are some things you can look at to increase sensitivity for de novos. From our benchmarks, DeepTrio has a higher overall accuracy for de novos, but is more conservative (lower sensitivity, higher specificity). You could potentially use the GQ/PL values for no-call sites that are potential de novos sites and rank these by confidence, setting your own threshold. I mention the above possibility as an option. It sounds like for your use case of having a quartet and wanting higher sensitivity, the most straightfoward approach is to just use DeepVariant for joint genotyping. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/609#issuecomment-1423013212:505,benchmark,benchmarks,505,,https://github.com/google/deepvariant/issues/609#issuecomment-1423013212,1,['benchmark'],['benchmarks']
Testability,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:; 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you); 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/849#issuecomment-2233667709:487,test,test,487,,https://github.com/google/deepvariant/issues/849#issuecomment-2233667709,1,['test'],['test']
Testability,"Hi @karthick1087. DeepVariant will be able to run on a BAM file for one microbial species relative to its reference genome and should be able to produce a VCF file with variants. However, DeepVariant is designed with diploid variant calling in mind, so it will call HET variants, and it also not trained with subclonal variant fractions in mind. In addition, the training data for DeepVariant is diploid human data. So it hasn't really been designed to address the problem of calling on haploid microorganisms. External groups have benchmarked DeepVariant for bacterial variant calling alongside many other callers designed for this purpose (https://academic.oup.com/gigascience/article/9/2/giaa007/5728470). Given the limitations to DeepVariant mentioned above, it performs surprisingly well, but is not the most accurate pipeline. . It does, however, seem to have a high precision (DeepVariant with NextGenMap had the highest precision of any of the methods), but with lower recall. So I would not recommend DeepVariant as the only method used to analyze microbial data. However, given its high precision and given that it is a very different approach to other methods you might run, it could be of use to use DeepVariant as a secondary caller. In this use case, you would have a high degree of confidence in variants called by both DeepVariant and the alternative method. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/343#issuecomment-688064227:532,benchmark,benchmarked,532,,https://github.com/google/deepvariant/issues/343#issuecomment-688064227,1,['benchmark'],['benchmarked']
Testability,"Hi @kishwarshafin ,. No worries, thanks for finding the time to get back to me! And thanks for the explanation - I had read that line in the log file ""Not including more"", as it is including some. . So the truth data is generated from the offspring of 5 trios. Variants for the parents and offspring were called (using GATK4) against a reference, mendelian expectations were checked for each locus, and the loci that passed that check, as well as some hard filters (e.g. depth, GQ etc), were kept for the truth set. . The variants in the truth set are the combination of all the variants that passed these filters in all 5 trios, which amounts to around 450,000 variants (split into ~350k training, and ~100k for tuning). The reference is from a different population which which will probably result in more hom_alt SNPs against the ref, but other than that, I don't think this number of SNPs is particularly high for a 400Mb genome of a wild fish with relatively large pop sizes. The 0.5x downsampling of course doubles this number, resulting in ~900,000 truth vars in total. . So, could a solution be to increase the maximum for genotype_options_product? Or would you suggest subsampling the truth variants? . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/876#issuecomment-2336577721:141,log,log,141,,https://github.com/google/deepvariant/issues/876#issuecomment-2336577721,1,['log'],['log']
Testability,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/876#issuecomment-2358819920:146,test,tests,146,,https://github.com/google/deepvariant/issues/876#issuecomment-2358819920,2,"['log', 'test']","['log', 'tests']"
Testability,"Hi @kishwarshafin, thanks for your reply.; I am providing sorted and aligned inputs to DeepVariant, generated by pbmm2.; I am not seeing any logs in the output dir, it is completely empty :(",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/810#issuecomment-2068082015:141,log,logs,141,,https://github.com/google/deepvariant/issues/810#issuecomment-2068082015,1,['log'],['logs']
Testability,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success.; Could you please suggest some ideas on how to resolve this issue?; Thank you for your assistance.; ```; /opt/deepvariant/bin/run_deepvariant \; --ref=GRCh38_no_alt_analysis_set.fasta \; --reads=sample1-lane_1.converted.cram \; --output_vcf=sample1-lane_1.deepvariant.vcf.gz \; --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \; --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ ; --model_type PACBIO \; --regions=chrX_10001-44821.bed \; --intermediate_results_dir=tmp \; --num_shards=12; ```; [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz); [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/853#issuecomment-2243024446:194,test,test,194,,https://github.com/google/deepvariant/issues/853#issuecomment-2243024446,1,['test'],['test']
Testability,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:; [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:; [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/876#issuecomment-2345422270:348,log,log,348,,https://github.com/google/deepvariant/issues/876#issuecomment-2345422270,2,"['log', 'test']","['log', 'tested']"
Testability,"Hi @kishwarshafin,. The training process starts as expected with GPU activity visible, but it abruptly stops without any error message while processing the first epoch and determining the best checkpoint metric (code snippet). This step completes as expected when using the CPU image with the same dataset and parameters. Initially, I thought TensorRT issues might be causing this stop, but I'll share the logs with you to get your perspective and an extra set of eyes on the problem. **Command:** ; ```; ( time sudo docker run --runtime=nvidia --gpus 1\; -v ${HOME}:${HOME} \; -w ${HOME} \; google/deepvariant:1.6.1-gpu \; train \; --config=""${BASE}/dv_config.py"":base \; --config.train_dataset_pbtxt=""${BASE}/training_set.pbtxt"" \; --config.tune_dataset_pbtxt=""${BASE}/validation_set.pbtxt"" \; --config.init_checkpoint=""${BASE}/checkpoint/deepvariant.wgs.ckpt"" \; --config.num_epochs=10 \; --config.learning_rate=0.0001 \; --config.num_validation_examples=0 \; --experiment_dir=${TRAINING_DIR} \; --strategy=mirrored \; --config.batch_size=512 \; ) > ""${LOG_DIR}/train.log"" 2>&1 &; ```; ```; I0508 17:53:46.544947 140534986602304 train.py:384] Starting epoch 0; I0508 17:53:46.545100 140534986602304 train.py:391] Performing initial evaluation of warmstart model.; I0508 17:53:46.545171 140534986602304 train.py:361] Running tune at step=0 epoch=0; I0508 17:53:46.545287 140534986602304 train.py:366] Tune step 0 / 15 (0.0%); I0508 17:54:10.069682 140512707213056 logging_writer.py:48] [0] tune/categorical_accuracy=0.22617188096046448, tune/categorical_crossentropy=1.3209192752838135, tune/f1_het=0.02283571846783161, tune/f1_homalt=0.09889934211969376, tune/f1_homref=0.843934178352356, tune/f1_macro=0.3218897581100464, tune/f1_micro=0.22617188096046448, tune/f1_weighted=0.21346084773540497, tune/false_negatives_1=6123.0, tune/false_positives_1=5727.0, tune/loss=1.3209190368652344, tune/precision_1=0.21375617384910583, tune/precision_het=0.19323670864105225, tune/precision_homalt=0.05127762",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/819#issuecomment-2101161904:406,log,logs,406,,https://github.com/google/deepvariant/issues/819#issuecomment-2101161904,1,['log'],['logs']
Testability,"Hi @koido ,; sorry that it took me a while to get back to this again.; Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:; https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227; And the location where the checkpoints are saved was specified earlier:; https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/127#issuecomment-449040624:574,test,test,574,,https://github.com/google/deepvariant/issues/127#issuecomment-449040624,2,['test'],"['test', 'tests']"
Testability,"Hi @kokyriakidis. Thank you for your question. There are a few possibilities for this. First, chrX and chrY do share regions of homology, the pseudo autosomal regions (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2435358/), which allows them to pair and segregate appropriately during meiosis. Because the reference sequence for both chrX and chrY contains these sequences, even in a female individual, reads will map to either and this can manifest as HET calls. It could be good to look at whether these calls occur in PAR regions. This will depend on which reference you are using, as some references mask this region. Can you tell us the reference build that you are using?. Second, reads may end up mismapped onto chrY from autosomes. When mismapping occurs, there is signal that will look like variation. The variant callers are not told whether a sample is male or female, and have to judge whether the signal is consistent with a variant or if the sample is female. Errors in this process can occur. How many variants are you seeing as PASS, it could be illustrative to compare this number to other benchmark human samples. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/196#issuecomment-511731809:1107,benchmark,benchmark,1107,,https://github.com/google/deepvariant/issues/196#issuecomment-511731809,1,['benchmark'],['benchmark']
Testability,"Hi @kostasgalexiou , from the log, does it look like all 16 make_examples have finished? (At the end it should have something like:; ```; Task 1/16: Created ... examples; ```; If that's hard to see, can you check how many of the make_examples are still running?. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/427#issuecomment-789047987:30,log,log,30,,https://github.com/google/deepvariant/issues/427#issuecomment-789047987,1,['log'],['log']
Testability,"Hi @kostasgalexiou ,; Looking at the file size, they look reasonable, but I can't tell exactly whether they're complete or not.; You can certainly try directly to run call_variants. If some of the records are not complete or corrupted, call_variants or postprocess_variants might give you an error later on. I'm still curious on why it didn't finish though. If you have more new observations or logs that might be informative, please let me know. I suppose your input BAM file is not public? If it is public, I would love to try to reproduce your issue on a n1-standard-16 machine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/427#issuecomment-789115542:395,log,logs,395,,https://github.com/google/deepvariant/issues/427#issuecomment-789115542,1,['log'],['logs']
Testability,"Hi @kunmonster ,; if I understand correctly, we haven't been able to reproduce the issue on our side, therefore it has been difficult for us to help. I know you've already run `tensorflow.test.is_gpu_available()`. can you also try this and see what you see?. ```; sudo docker run --gpus all google/deepvariant:1.6.1-gpu python3 -c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))""; ```. When I run this on my machine, I see:. ```; [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]; ```. Given that your is_gpu_available is True, I think it'll also list something. Just want to double check here. If there's any other information that you can provide, in order for us to reproduce on our side, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/820#issuecomment-2164273245:188,test,test,188,,https://github.com/google/deepvariant/issues/820#issuecomment-2164273245,1,['test'],['test']
Testability,"Hi @leorippel . If you are referring specifically to the process of VQSR, we do not recommend this step. In our benchmarks for VQSR, at both the cohort and individual level, recall and overall accuracy are substantially worse (see Figure3 of https://www.biorxiv.org/content/10.1101/2020.02.10.942086v1.full.pdf or Table 1 of https://www.nature.com/articles/nbt.4235). If you would like to further filter variant calls to increase precision, we recommend instead filtering based on genotype quality instead, with something like a cutoff of GQ>10 being reasonable (this implies the lowest retained variant has at least a 90% chance of being correctly called). The model specified in the command line here is the model used for the calling process itself. It is, in theory, possible to retrain this model, but you would need to have a set of confident sites generated through a process with better accuracy, for example deep PacBio HiFi data and using those sites to train an Illumina model. This process is technically involved as well, so my recommendation is that if you would like higher precision, you can apply a filter on the GQ value for calls. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/324#issuecomment-659250952:112,benchmark,benchmarks,112,,https://github.com/google/deepvariant/issues/324#issuecomment-659250952,1,['benchmark'],['benchmarks']
Testability,"Hi @leorippel . In your log, the error says:; ```; 2021-01-26 17:29:22.919993: E third_party/nucleus/io/tfrecord_reader.cc:48] /input/gvcf.tfrecord-00000-of-00030.gz; No such file or directory; ```; Can you confirm that you actually have this file? From what you described earlier, you're trying to rename files into this format, but I'm not sure what you actually rename them to.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/413#issuecomment-767954630:24,log,log,24,,https://github.com/google/deepvariant/issues/413#issuecomment-767954630,1,['log'],['log']
Testability,"Hi @lpryszcz . With respect to your aligner question, we have evaluated DeepVariant with BWA-MEM/BWA-MEM2, minimap2, DRAGEN, and the graph mapper Giraffe. For mapping to a linear reference, we would recommend BWA-MEM/BWA-MEM2 or DRAGEN. DeepVariant is trained on BWA MEM data. Minimap2 will work, but has slightly lower accuracy. . We have not evaluated HISAT2. If I had to guess, I would suspect that there might be split read mapping which is creating more candidates. The difference in speed that you encounter suggests that this has something to do with our candidate generation logic, as opposed to something about the neural network. This would probably require us to look at what in HISAT2 is causing an edge case with our candidate generation logic. It's possible there is a flag in HISAT2 that could be altered, but failing that it would probably take us some time to prioritize supporting HISAT2. . We typically find that marking duplicates is not necessary, but it does not have a negative effect on accuracy to do so for typical coverages (25x-50x). Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/460#issuecomment-854263305:583,log,logic,583,,https://github.com/google/deepvariant/issues/460#issuecomment-854263305,2,['log'],['logic']
Testability,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334737190:1324,test,tests,1324,,https://github.com/google/deepvariant/issues/879#issuecomment-2334737190,1,['test'],['tests']
Testability,"Hi @lucasbrambrink,. I actually tried with different batch_size (32 and 512) but the batch_size takes longer so I switched to 512. I also tried with epoch=10 but still have encountered the same error. I just updated my error log file with the error ```No checkpoint found.```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2033267320:225,log,log,225,,https://github.com/google/deepvariant/issues/802#issuecomment-2033267320,1,['log'],['log']
Testability,"Hi @luciamayorf , can you share your command?. And, can you quickly test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md and see if that worked for you?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/492#issuecomment-1821236290:68,test,test,68,,https://github.com/google/deepvariant/issues/492#issuecomment-1821236290,1,['test'],['test']
Testability,"Hi @mallikag9 . I don't see a BED file for the exome regions in your command. For exome, we typically restrict to the capture regions of the exome (sometimes with a 100bp pad region). . You can download the capture regions with this command:. ```; HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/idt_capture_novogene.grch38.bed > input/idt_capture_novogene.grch38.bed; ```. and add `--regions /input/idt_capture_novogene.grch38.bed` to the command.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/735#issuecomment-1817582712:316,test,testdata,316,,https://github.com/google/deepvariant/issues/735#issuecomment-1817582712,1,['test'],['testdata']
Testability,"Hi @mano2991 , Two questions:; (1) Can you tell me what environment (e.g., OS, version) you're running this on? ; There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run.; (2); Can you try rerunning with:; `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/231#issuecomment-548147127:232,test,test,232,,https://github.com/google/deepvariant/issues/231#issuecomment-548147127,1,['test'],['test']
Testability,"Hi @marchoeppner . We are currently working on some approaches to better call MNPs and locations with complex variants. Those are in an intermediate stage of investigation, and I can't estimate at present when they will complete (nor give with certainty a guarantee that it will improve accuracy). For now, I will generate some benchmarks for MNP calls which might ground discussions in some quantifiable numbers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/520#issuecomment-1542578964:328,benchmark,benchmarks,328,,https://github.com/google/deepvariant/issues/520#issuecomment-1542578964,1,['benchmark'],['benchmarks']
Testability,"Hi @maricatovictor . 1. Accessing the pre-logit layer (and other layers) is demonstrated in the code here: https://github.com/google/deepvariant/blob/r1.0/deepvariant/modeling.py#L1161. This is probably the best place to start experimenting if you would like to take information from within the layers for other purposes. 2. There is a new (and somewhat experimental) method to force-call on positions in a VCF. I am attaching a PDF with those instructions. Note that this feature is new, and we may not have enough bandwidth to provide full support for issues that arise in development. This might be what you mean when asking about VCF input. If you are asking whether it is possible to read in other data from FORMAT or INFO field values of a VCF, this is not yet possible, and definite plans for it are not currently on the roadmap. [(2020-09-28) Tutorial_ Force calling with DeepVariant.pdf](https://github.com/google/deepvariant/files/5440613/2020-09-28.Tutorial_.Force.calling.with.DeepVariant.pdf)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/371#issuecomment-716733704:42,log,logit,42,,https://github.com/google/deepvariant/issues/371#issuecomment-716733704,1,['log'],['logit']
Testability,"Hi @maricatovictor . At this time, we have not put effort into abstracting these components into a module. We'll take your request into account for future development. It is definitely something that we would like to do, but we likely have a few more pressing issues to address. Yes, right now you would need to fork the code to be able to work with the pre-logits. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/371#issuecomment-717581087:358,log,logits,358,,https://github.com/google/deepvariant/issues/371#issuecomment-717581087,1,['log'],['logits']
Testability,"Hi @meghanasp21 ; If you're running with Singularity, I suspect a temp directory has been created directly under your /tmp/. The line of code that created the tempdir is this line:. https://github.com/google/deepvariant/blob/r0.10/scripts/run_deepvariant.py#L234. In the logs as you run, it should give you the name of the corresponding directory under `/tmp/`. You can manually remove the directory after your run is finished.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/296#issuecomment-609217252:271,log,logs,271,,https://github.com/google/deepvariant/issues/296#issuecomment-609217252,1,['log'],['logs']
Testability,"Hi @melkerdawy ,; currently our code doesn't support training with multiple GPUs. I haven't really tried training with CPUs, so I don't know whether model_train automatically utilize multiple CPUs or not. (We know that `call_variants` does. But I've never used CPU for training.); If you want, you can try running it and see how many CPUs it utilizes. However, I don't recommend training with CPUs becaues I think it'll be really slow. And, using GPU parallel with training also won't work. In the case if training, it's not easily parallelizable like inference. The most practical path forward is probably to get a really powerful GPU and see how well that works for you. I've been hoping to benchmark for training on GPU as well, but haven't got time to do so. If you have some results you want to share, that will be great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/192#issuecomment-507880713:693,benchmark,benchmark,693,,https://github.com/google/deepvariant/issues/192#issuecomment-507880713,1,['benchmark'],['benchmark']
Testability,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 ; ./. calls - 150,238; 0/1 calls - 2,793,521; 1/1 calls - 1,851,566; 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/241#issuecomment-559228691:146,benchmark,benchmarks,146,,https://github.com/google/deepvariant/issues/241#issuecomment-559228691,2,['benchmark'],['benchmarks']
Testability,"Hi @mkazanov ; Internally we've updated to Ubuntu18.04 and made a bunch of updates accordingly too. It will come out in the next release. Given that there's another similar question in https://github.com/google/deepvariant/issues/441 , I can try to see if it's easy for me to share some of the updated files (I'll need to test it with the v1.1 repo first).; Otherwise, I can try to push a bit more on the timeline for the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/443#issuecomment-821522061:322,test,test,322,,https://github.com/google/deepvariant/issues/443#issuecomment-821522061,1,['test'],['test']
Testability,"Hi @moldach ; somehow your logs above have a lot of spaces in the middle, making it hard to read. It seems like the last step was looking for `/scratch/moldach/bin/quickstart-output/output.vcf.gz` but couldn't find it. . I'll walk through the steps again to see if I can reproduce your error, but meanwhile, can you try:. ```; singularity run -B $PWD,/usr/lib/locale/ \; ```. instead of . ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; ```. And see if it works for you? Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-606340201:27,log,logs,27,,https://github.com/google/deepvariant/issues/287#issuecomment-606340201,1,['log'],['logs']
Testability,"Hi @mpinese ,; I'm commenting here for your question 4. Internally for warmstarting, we use the same flag (`--start_from_checkpoint`) in https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md to train our WES and PacBio release models. You refer to: https://github.com/google/deepvariant/issues/185 . The advice in my comment https://github.com/google/deepvariant/issues/185#issuecomment-494919509 has a code change that you could try out, only if you want to experiment with different warmstarting logic on your own. . What we currently use is what you can find in our r0.10 codebase:; https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/modeling.py#L560. When warmstarting and training with a small(er) amount of data, it's always possible that the curve might look a bit weird at the beginning. Here is a rule of thumb I use: a stable training setup should be mostly reproducible. Meaning, if you run the same training multiple times, the curves should eventually converge to about the same place, and shouldn't behave drastically different. They won't look the exactly same because of randomness in training process. But if half of the runs don't converge, or behave very differently from the other half, then something needs to be improved. You might also have a question on whether you need to warmstart. That is an empirical question. Here is an example from my experience:; For our PacBio training, at this point I actually feel like we have enough data to not have to warmstart from the WGS model. But we're still warmstarting (at least for now) because I find that it converges faster and the resulting accuracy is about the same. We make these decisions based on empirical evidence and our intuition on ML and the data. These decisions can also evolve over time. ( Btw, one thing that we might not have documented - if you want to try with *not* warmstarting from anything, and want to just randomly init, you ca",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/312#issuecomment-638521636:533,log,logic,533,,https://github.com/google/deepvariant/issues/312#issuecomment-638521636,1,['log'],['logic']
Testability,"Hi @one-matrix ,. Are you trying to build deepvariant locally? If that's the case, then please follow the steps here: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1856359741:189,test,test,189,,https://github.com/google/deepvariant/issues/753#issuecomment-1856359741,1,['test'],['test']
Testability,"Hi @one-matrix ,. From your original post, you mentioned you ran `python deepvariant/call_variants.py`. That won't work in DeepVariant setup. For DeepVariant, all binaries needs to be built with bazel. Unlike other pure Python setup, simply `python` a .py file won't execute it correctly. This is documented in the https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md page that @danielecook mentioned before. But, for extra clarity, let me run through it again, and write it down below for your reference. Here is an example of how I build and execute DeepVariant binaries:. # First, get a machine to run. In my example, I used a machine from GCP, using a command like this: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-details.md#command-for-a-cpu-only-machine-on-google-cloud-platform. ```bash; gcloud compute instances create ""${USER}-cpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-64"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. # ssh into the machine, and get the latest DeepVariant repo. Then, I ssh into the machine:. ```bash; gcloud compute ssh ${USER}-cpu --zone us-west1-b; ```. Then I get the repo:. ```bash; git clone https://github.com/google/deepvariant.git; cd deepvariant; ```. Following in the instructions in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md. I first run:. ```bash; sudo su; ```. and then:. ```bash; ./build-prereq.sh; ```. This step does a lot of stuff, including checking out other repos such as clif and tensorflow, and using that as part of the build environment. On my machine that I tested with just now, it took me 10m56.021s. and then run:. ```bash; ./build_and_test.sh; ```. This step took about 7min on my machine. . The [build_and_test.sh](https://github.com/google/deepvariant/blob/r1.6/build_and_test.sh) script is",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872:386,test,test,386,,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872,1,['test'],['test']
Testability,"Hi @pamelameza . The contents of the INFO field are generally used by other calling methods to describe statistics about the variant position that are used in the process of variant calling (for example ""##INFO=<ID=ClippingRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases"">""). . In DeepVariant, instead of directly calculating many of these values to use in a statistical model, the more raw read-level data is directly presented to a neural network and the neural network itself determines what properties in the raw data are useful for variant calling. So we don't populate the INFO field as we don't calculate many of those derived features. One thing that people often use the INFO field for is to filter variant calls by different properties. We've looked into the most effective ways to filter calls, and it is consistently the case that the sample level GQ field is well-calibrated to the probability of a call being correct. If you want to see some data for this, you can look at the calibration in Figure 2 of the DeepVariant paper (https://www.nature.com/articles/nbt.4235) or at the general work in our cohort calling paper (https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). Are there fields in particular you generally use within INFO? It's unlikely we could easily add them, but it might be useful for us to know. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/620#issuecomment-1470895246:295,test,test,295,,https://github.com/google/deepvariant/issues/620#issuecomment-1470895246,1,['test'],['test']
Testability,"Hi @pichuan , Thanks for your reply. As your suggestion, after removing the double quote around the *, the `ls` run normally in `bash` script. However, the `ls` in `deepvariant` image of `singularity` still failed. Notably, If I add a `which ls;` before a `ls -al $ref_idx*`, it runs normally so that I can see the detailed information for the files..; Here is the script:; ```bash; #!/bin/bash. nthreads=32; dvsif=""/lustre/Data/toolsDB/deepvariant.sif""; ref_idx=""/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa"". wkdir=""/lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP""; bamdir=""${wkdir}/mappinged_bams""; logdir=""${wkdir}/logs""; vcfoutdir=""${wkdir}/DeepVariant_outputs"". source activate ~/.conda/envs/zjlEnv. echo -e ""ref_idx is $ref_idx\n""; if [ -f ""$ref_idx"" ];; then; echo -e ""ref_idx $ref_idx exists!\n""; which ls; echo -e ""ls -al --block=M ${ref_idx}*\n""; ls -al --block=M ${ref_idx}*; echo -e ""ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*\n""; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*; else; echo -e ""Warning!! ref_idx [$ref_idx] not exist!\n""; fi. echo -e ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif ls -al ${ref_idx}*""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif ls -al ${ref_idx}*; echo -e ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif which ls; ls -al ${ref_idx}*""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ $dvsif which ls; ls -al ${ref_idx}*. ```. Here is the running output:; ```shell; /usr/bin/ls; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. -rw-rw-r-- 1 zhoujianglin zhoujianglin 3042M Apr 26 14:53 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; -rw-rw-r-- 1 zhoujianglin zhoujianglin 5985M Apr 26 15:23 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M Apr 26 15:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1575922269:613,log,logdir,613,,https://github.com/google/deepvariant/issues/653#issuecomment-1575922269,2,['log'],"['logdir', 'logs']"
Testability,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks!. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/904#issuecomment-2458942715:115,test,test,115,,https://github.com/google/deepvariant/issues/904#issuecomment-2458942715,1,['test'],['test']
Testability,"Hi @pichuan . Here is a helper shell script for that: https://raw.githubusercontent.com/anands-repo/deepvariant/r1.0/tools/post_eval.sh. Steps to use:; 1. Create a target empty working directory: `$WORKDIR`; 2. Launch model_eval with `--checkpoint_dir=$WORKDIR`, and direct output logs to `$WORKDIR/eval.log`; 3. Launch post_eval.sh as: `post_eval.sh $TRAINING_DIRECTORY $WORKDIR` where (`$TRAINING_DIRECTORY` is the original directory where checkpoints were dumped by model_train). The post_eval script copies one checkpoint after another to $WORKDIR from $TRAINING_DIRECTORY and modifies the ""checkpoint"" file in that directory, in coordination with model_eval, so that model_eval runs on one checkpoint after another just like when it is launched concurrently with training.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/378#issuecomment-721485772:281,log,logs,281,,https://github.com/google/deepvariant/issues/378#issuecomment-721485772,2,['log'],"['log', 'logs']"
Testability,"Hi @pichuan . Unfortunately, I do not have the log file. None of the make_examples is running. The last update occurred on March,1 at 18:44. Can we say whether the make_example / gvcf process has finished? If yes, can I launch deevariant again and go directly to call_variants?. -rw-r--r-- 1 root root 354156544 Mar 1 18:44 gvcf.tfrecord-00000-of-00016.gz; -rw-r--r-- 1 root root 353894400 Mar 1 18:44 gvcf.tfrecord-00001-of-00016.gz; -rw-r--r-- 1 root root 353632256 Mar 1 18:44 gvcf.tfrecord-00002-of-00016.gz; -rw-r--r-- 1 root root 353107968 Mar 1 18:44 gvcf.tfrecord-00003-of-00016.gz; -rw-r--r-- 1 root root 353894400 Mar 1 18:44 gvcf.tfrecord-00004-of-00016.gz; -rw-r--r-- 1 root root 354156544 Mar 1 18:44 gvcf.tfrecord-00005-of-00016.gz; -rw-r--r-- 1 root root 353894400 Mar 1 18:44 gvcf.tfrecord-00006-of-00016.gz; -rw-r--r-- 1 root root 353370112 Mar 1 18:44 gvcf.tfrecord-00007-of-00016.gz; -rw-r--r-- 1 root root 353894400 Mar 1 18:44 gvcf.tfrecord-00008-of-00016.gz; -rw-r--r-- 1 root root 354156544 Mar 1 18:44 gvcf.tfrecord-00009-of-00016.gz; -rw-r--r-- 1 root root 354942976 Mar 1 18:44 gvcf.tfrecord-00010-of-00016.gz; -rw-r--r-- 1 root root 354942976 Mar 1 18:44 gvcf.tfrecord-00011-of-00016.gz; -rw-r--r-- 1 root root 354418688 Mar 1 18:44 gvcf.tfrecord-00012-of-00016.gz; -rw-r--r-- 1 root root 354680832 Mar 1 18:44 gvcf.tfrecord-00013-of-00016.gz; -rw-r--r-- 1 root root 354680832 Mar 1 18:44 gvcf.tfrecord-00014-of-00016.gz; -rw-r--r-- 1 root root 354156544 Mar 1 18:44 gvcf.tfrecord-00015-of-00016.gz; -rw-r--r-- 1 root root 10704650240 Mar 1 18:44 make_examples.tfrecord-00000-of-00016.gz; -rw-r--r-- 1 root root 10710417408 Mar 1 18:44 make_examples.tfrecord-00001-of-00016.gz; -rw-r--r-- 1 root root 10699931648 Mar 1 18:44 make_examples.tfrecord-00002-of-00016.gz; -rw-r--r-- 1 root root 10677649408 Mar 1 18:44 make_examples.tfrecord-00003-of-00016.gz; -rw-r--r-- 1 root root 10692329472 Mar 1 18:44 make_examples.tfrecord-00004-of-00016.gz; -rw-r--r-- 1 root root 107253",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/427#issuecomment-789089400:47,log,log,47,,https://github.com/google/deepvariant/issues/427#issuecomment-789089400,1,['log'],['log']
Testability,"Hi @pichuan ; I just used the command you suggested but I am not getting any log.; could you please let me know how to set /opt/deepvariant/bin/make_examples parameter to get the errors?; Thanks,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870744502:77,log,log,77,,https://github.com/google/deepvariant/issues/465#issuecomment-870744502,1,['log'],['log']
Testability,Hi @pichuan ; I will test that option. But sounds exactly like what I'm looking for.; Thanks; Stefan,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/723#issuecomment-1785004783:21,test,test,21,,https://github.com/google/deepvariant/issues/723#issuecomment-1785004783,1,['test'],['test']
Testability,"Hi @pichuan ; Thank you for your response. . I have completed the testing of NGS-WES data and Pacbio-WGS data on deeptrio1.6, and performed single sample analysis using deepvariant1.6. I have some questions that I would like to confirm with you. . 1. If I want to test 3 Pacbio WGS datasets using deeptrio1.6, how much memory should I allocate at least? . 2. Regarding NGS-deeptrio1.6 analysis, I only saw the benchmark comparison results for WGS-chr20. Do you have any results (Recall, Precision, F1_Score) to share for WES data? . 3. For Pacbio-deeptrio1.6 analysis, I tested the official WGS HiFi data (HG002, HG003, HG004). The reference genome used for alignment was hs37d5.fa. The bam was hifi_reads_aligned.haplotagged.bam (pbmm2+whatshap haplotag). The region is chr20. However, the benchmark comparison results were worse than the data you published. Does the choice of reference genome affect the precision of the results? . 4. Whether it is NGS-WES or Pacbio-WGS, the results from using deeptrio1.6 for analysis are slightly less precision than using deepvariant1.6. Is this normal? In theory, should the results from deeptrio1.6 be better than those from deepvariant1.6?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/720#issuecomment-1780570310:66,test,testing,66,,https://github.com/google/deepvariant/issues/720#issuecomment-1780570310,5,"['benchmark', 'test']","['benchmark', 'test', 'tested', 'testing']"
Testability,"Hi @pichuan @gunjanbaid . I apologize for overcomplicating this PR. I should have taken the rest of the discussion elsewhere. Thanks for your patient responses and advise so far. Even though I made many commits here, the only PR here is for `shuffle_tfrecords_beam.py`, and the changes are trivial as @gunjanbaid has reviewed already. The purpose of the PR is to enable `shuffle_tfrecords_beam.py` to work with DirectRunner with multiple workers (`--direct_num_workers=2, --direct_running_mode=""multi_processing""` for example), as well as with SparkRunner, FlinkRunner etc. To answer @gunjanbaid 's question on using beam.DoFn instead of a callable, my personal opinion is that that may not be necessary. The issue I saw is that `lambda` functions cannot be invoked through ParDo for these runners/modes. I attribute it to the same issue that we see with python multiprocessing which uses pickle to dispatch functions across processes and lambda functions are not picklable. So in this context, I think a callable meets the minimum requirements to enable this. I have tested on my end that the original deepvariant script and the modified script give the same output for a testcase. I am not trying to push you into accepting this PR, but just trying to clear any confusions that may have been caused by my multiple commits to the same branch, so that if and when you do revisit this matter, there is a summary about what's going on. I understand that the changes may still be far outside the priority of the team, so please take this at the appropriate pace. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/365#issuecomment-723468092:1068,test,tested,1068,,https://github.com/google/deepvariant/pull/365#issuecomment-723468092,2,['test'],"['testcase', 'tested']"
Testability,"Hi @pichuan and @tedyun ~. I run the command which @pichuan provided but it still print nothing on terminal. ; And the docker version of this machine is `Docker version 19.03.3, build a872fc2`. So I switch to another machine which supported AVX instruction and run the test again by @tedyun 's advice.; Then it run normally and output the files as same as the tutorial. Here is the environment & the command:. - Host CPU info; ```text; processor : 0; vendor_id : GenuineIntel; cpu family : 6; model : 63; model name : Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz; stepping : 2; microcode : 0x43; cpu MHz : 1199.975; cache size : 25600 KB; physical id : 0; siblings : 20; core id : 0; cpu cores : 10; apicid : 0; initial apicid : 0; fpu : yes; fpu_exception : yes; cpuid level : 15; wp : yes; flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts md_clear spec_ctrl intel_stibp flush_l1d; bogomips : 4595.05; clflush size : 64; cache_alignment : 64; address sizes : 46 bits physical, 48 bits virtual; power management:; ```; - OS ,kernel & docker version; ```sh; # uname -a; Linux CoreS 3.10.0-1062.12.1.el7.x86_64 #1 SMP Tue Feb 4 23:02:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. # cat /etc/centos-release; CentOS Linux release 7.7.1908 (Core). # docker -v; Docker version 19.03.12, build 48a66213fe; ```. - Test run command; ```sh; # BIN_VERSION=""1.0.0""; # ls -1 ${INPUT_DIR}; NA12878_S1.chr20.10_10p1mb.bam; NA12878_S1.chr20.10_10p1mb.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-690842263:269,test,test,269,,https://github.com/google/deepvariant/issues/345#issuecomment-690842263,1,['test'],['test']
Testability,"Hi @pichuan ~. I tried the code you provided but it print nothing error.; There is also nothing output file in the output folder. Here is the code:. ```sh; $ sudo docker run \; > -v ""${INPUT_DIR}"":""/input"" \; > -v ""${OUTPUT_DIR}"":""/output"" \; > google/deepvariant:""${BIN_VERSION}"" \; > /opt/deepvariant/bin/make_examples \; > --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta \; > --reads /input/NA12878_S1.chr20.10_10p1mb.bam \; > --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz \; > --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz \; > --regions chr20:10,000,000-10,010,000 \; > --task 0. $ ls; quickstart-output quickstart-testdata. $ ls quickstart-output/; intermediate_results_dir. ```. Best,; Jerry",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-689958395:670,test,testdata,670,,https://github.com/google/deepvariant/issues/345#issuecomment-689958395,1,['test'],['testdata']
Testability,"Hi @pichuan ~. Thank you for this quickly reply~. I tried to add `--user root` into docker command like the solved issue #325 ; But it still didn't show any additional error message like the issue ; I also check the disk and it is still have about 9 Gb free space. Here is the code and message output. ```sh; $ BIN_VERSION=""1.0.0""; $ sudo docker pull google/deepvariant:""${BIN_VERSION}""; Digest: sha256:6ef8f3b4c4465e41ee7597cd2351a7c44dd8b62a849a47766316507a6234f5f8; Status: Downloaded newer image for google/deepvariant:1.0.0; docker.io/google/deepvariant:1.0.0. $ INPUT_DIR=""${PWD}/quickstart-testdata""; $ ls -1 ${INPUT_DIR}; NA12878_S1.chr20.10_10p1mb.bam; NA12878_S1.chr20.10_10p1mb.bam.bai; test_nist.b37_chr20_100kbp_at_10mb.bed; test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; ucsc.hg19.chr20.unittest.fasta; ucsc.hg19.chr20.unittest.fasta.fai; ucsc.hg19.chr20.unittest.fasta.gz; ucsc.hg19.chr20.unittest.fasta.gz.fai; ucsc.hg19.chr20.unittest.fasta.gz.gzi. $ OUTPUT_DIR=""${PWD}/quickstart-output""; $ ls ${OUTPUT_DIR}; intermediate_results_dir. $ df -h; 檔案系統 容量 已用 可用 已用% 掛載點; udev 7.8G 0 7.8G 0% /dev; tmpfs 1.6G 11M 1.6G 1% /run; /dev/sda1 109G 95G 8.9G 92% /; tmpfs 7.9G 200K 7.9G 1% /dev/shm; tmpfs 5.0M 4.0K 5.0M 1% /run/lock; tmpfs 7.9G 0 7.9G 0% /sys/fs/cgroup; /dev/loop1 56M 56M 0 100% /snap/core18/1885; /dev/loop3 55M 55M 0 100% /snap/gtk-common-themes/1502; /dev/loop2 162M 162M 0 100% /snap/gnome-3-28-1804/128; /dev/loop4 161M 161M 0 100% /snap/gnome-3-28-1804/116; /dev/loop0 30M 30M 0 100% /snap/snapd/8790; /dev/loop5 63M 63M 0 100% /snap/gtk-common-themes/1506; /dev/loop6 55M 55M 0 100% /snap/core18/1880; /dev/loop7 30M 30M 0 100% /snap/snapd/8542; /dev/loop8 39M 39M 0 100% /snap/remmina/4309; /dev/loop9 40M 40M 0 100% /snap/remmina/4324; tmpfs 1.6G 40K 1.6G 1% /run/user/108; tmpfs 1.6G 12K 1.6G 1% /run/user/1000. $ sudo docker run \; > --user root \; > -v ""${INPUT_DIR}"":""/input"" \; > -v ""${OUTPUT_DIR}"":""/output"" \; > google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-689932270:597,test,testdata,597,,https://github.com/google/deepvariant/issues/345#issuecomment-689932270,1,['test'],['testdata']
Testability,"Hi @pichuan, @akolesnikov,. I'm new to DeepTrio and couldn't locate the log files, but I have intermediate results showing that DeepTrio ran successfully without errors. Additionally, I successfully benchmarked the .vcf files generated by DeepTrio. I've attached screenshots for reference. Your assistance is greatly appreciated.; Thank you. finished log; ![Screenshot from 2024-05-07 09-52-02](https://github.com/google/deepvariant/assets/45700858/1f9f1b6d-bdd5-4d5d-87fd-a1416e8b4f22); ![Screenshot from 2024-05-07 09-52-32](https://github.com/google/deepvariant/assets/45700858/1c40eb86-018e-4df7-a290-963dccb767b8). Benchmark; ![Screenshot from 2024-05-07 09-52-59](https://github.com/google/deepvariant/assets/45700858/e98c8307-12ba-4c15-a26a-2323948e8f05)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/815#issuecomment-2097677205:72,log,log,72,,https://github.com/google/deepvariant/issues/815#issuecomment-2097677205,4,"['Benchmark', 'benchmark', 'log']","['Benchmark', 'benchmarked', 'log']"
Testability,"Hi @pichuan,. VM instance: n1-standard-16 (16 vCPUs, 60 GB memory). I don't get any error messages. The instance is still on and not giving any errors....or at least I haven't found any logs myself... Below is the structure of the contents in the VM instance:. ├── [drwxrwxr-x 4.0K] input; │ └── [drwxrwxr-x 4.0K] data; │ ├── [-rw-rw-r-- 2.9G] Annuum.v1.6.Total.fa; │ ├── [-rw-rw-r-- 1.6M] Annuum.v1.6.Total.fa.fai; │ ├── [-rw-rw-r-- 17G] FC85.sort.pcr_rem.RG.kept.bam; │ └── [-rw-rw-r-- 9.2M] FC85.sort.pcr_rem.RG.kept.bam.bai; └── [drwxrwxr-x 4.0K] output; └── [drwxr-xr-x 4.0K] intermediate_results_dir; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00000-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00001-of-00016.gz; ├── [-rw-r--r-- 337M] gvcf.tfrecord-00002-of-00016.gz; ├── [-rw-r--r-- 337M] gvcf.tfrecord-00003-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00004-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00005-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00006-of-00016.gz; ├── [-rw-r--r-- 337M] gvcf.tfrecord-00007-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00008-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00009-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00010-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00011-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00012-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00013-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00014-of-00016.gz; ├── [-rw-r--r-- 338M] gvcf.tfrecord-00015-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00000-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00001-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00002-of-00016.gz; ├── [-rw-r--r-- 9.9G] make_examples.tfrecord-00003-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00004-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00005-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00006-of-00016.gz; ├── [-rw-r--r-- 10.0G] make_examples.tfrecord-00007-of-00016",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/427#issuecomment-788690917:186,log,logs,186,,https://github.com/google/deepvariant/issues/427#issuecomment-788690917,1,['log'],['logs']
Testability,"Hi @pichuan,. sorry I was on vacation. Mhm strange I've checked your test command on my Debian 10 machine and it's showing the container nvidia-smi output without any problems. . I've checked your script. Did you install any NVIDIA drivers before CUDA? If I remember right, I did something like ""nivida-detect"" and installed the proposed package. What is your version of nvidia-container-toolkit (mine is 1.1.2-1) ? I saw in your mentioned issue that people there are using a newer one. So maybe it is worth a try to downgrade. You can also try something like ""sudo modprobe nvidia-uvm"". I have had this issue with another tool that wanted to use the GPU. Somehow the card was not ready and this fixed my problem. I hope this helps. I'm quite new in the GPU world. Best regards,. Sebastian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/321#issuecomment-674744222:69,test,test,69,,https://github.com/google/deepvariant/issues/321#issuecomment-674744222,1,['test'],['test']
Testability,"Hi @pichuan,; Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! ; Best,; ```. ***** Running the command:*****; time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s; user	0m0.699s; sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/243#issuecomment-579406829:64,test,tested,64,,https://github.com/google/deepvariant/issues/243#issuecomment-579406829,7,"['log', 'test']","['login', 'test', 'testdata', 'tested']"
Testability,"Hi @pichuan,; Thanks for getting back to me! Any suggestions would be great. . 1. Your OS version.; NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31"". 2. Your Singularity version.; singularity version 3.4.1-1.2.el7; 3. Your numpy version (I'm not sure whether this affects singularity); 1.17.5; 4. Just to confirm, which *simg file are you using? The command you run? Was this with or without GPU?. I tried using the deepvariant-0.9.0.simg image from here with and without GPU: `https://storage.googleapis.com/deepvariant/singularity_images`; # Pull Singularity images; INPUT_DIR='singularity'; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/singularity_images""; # Non-gpu image; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/deepvariant-0.9.0.simg; # GPU image; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/deepvariant-0.9.0-gpu.simg. # Test Singularity DeepVariant0.9.0 image on test data; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; ${INPUT_DIR}/deepvariant-${BIN_VERSION}.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz . # Errors:. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2020-01-31 01:37:29.333483: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . # Test Singularity DeepVariant0.9.0 GPU image on test data; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; ${INPUT_DIR}/deepvariant-${BIN_VERSION}-gpu.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/265#issuecomment-580549772:936,Test,Test,936,,https://github.com/google/deepvariant/issues/265#issuecomment-580549772,1,['Test'],['Test']
Testability,"Hi @pichuan,; Thanks for the response. ; As our data is not publicly available, soI tried to use the benchmark data in the following link to get the better comparison.; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-exome-case-study.md; In the link below, you mentioned about ""sec per 100"" on the log file is .67 sec for your hardware configuration. That should be proportionally adjustable on my machine's configuration (I use an 8 core machine and 64GB memory). ; https://github.com/google/deepvariant/issues/74. But unfortunately It is not the case on my machine. I got way higher time for different runs. from 20 second to some times 1 minutes per 100.; Surprisingly singularity does not use the full memory, 64 GB made available to it.; I am confused that if I set num_shards to the number of cores for example in my case 8, it makes the process even slower than when I set it to one.; May I kindly ask how much memory normally singularity uses?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-864505178:101,benchmark,benchmark,101,,https://github.com/google/deepvariant/issues/463#issuecomment-864505178,2,"['benchmark', 'log']","['benchmark', 'log']"
Testability,"Hi @pioneer-pi , . Here is my attempt to reproduce the issue. To build from source, the documentation to use is this: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md. Given that you want to build 1.5, let me use the r1.5 one (the doc is mostly the same , but I'll remember to use the 1.5 code): https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-build-test.md. To get a machine, I used a command here: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-details.md#command-for-a-cpu-only-machine-on-google-cloud-platform. ```bash; gcloud compute instances create ""${USER}-cpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-64"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. I sshed into the machine. ```bash; gcloud compute ssh pichuan-cpu --zone us-west1-b; ```. Then, on the machine, I get DeepVariant r1.5 source first:. ```bash; git clone https://github.com/google/deepvariant.git; cd deepvariant/; git checkout r1.5; ```. And I confirmed the version:. ```; pichuan@pichuan-cpu:~/deepvariant$ git log | head; commit ab068c4588a02e2167051bd9e74c0c9579462b51; Author: pichuan <pichuan@google.com>; Date: Mon Feb 27 23:03:48 2023 -0800. Update README.md; ; PiperOrigin-RevId: 512838102. ```. From there, I followed the instructions on https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-build-test.md; So I ran:. ```bash; sudo su; ./build-prereq.sh; ```. My run succeeded. I looked at my log to see the section close to where your error occurred. And I see:. ```; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- wor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785:189,test,test,189,,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785,2,['test'],['test']
Testability,"Hi @pioneer-pi ,. Can you please put some more details? Please follow the suggestions in this doc: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md, which suggests you to run `sudo su` before running `./build-prereq.sh`. One thing you can do is run:. ```bash; ./build-prereq.sh 2>&1 | tee /tmp/dv_build.log; ```; Then upload the `dv_build.log` here so a detailed log is available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/737#issuecomment-1818039062:170,test,test,170,,https://github.com/google/deepvariant/issues/737#issuecomment-1818039062,4,"['log', 'test']","['log', 'test']"
Testability,"Hi @pioneer-pi ,; I'll try to reproduce on my side and paste my log.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/739#issuecomment-1823193514:64,log,log,64,,https://github.com/google/deepvariant/issues/739#issuecomment-1823193514,1,['log'],['log']
Testability,"Hi @poddarharsh15 . Actually, can you go back in your log and confirm that DeepTrio runs actually finish correctly?. If I remember correctly, our run_deeptrio one-step script might continue to run the following steps even when previous steps failed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/815#issuecomment-2096596686:54,log,log,54,,https://github.com/google/deepvariant/issues/815#issuecomment-2096596686,1,['log'],['log']
Testability,"Hi @qili93 ,. This is a bug that the mock ref_reader does not have its 'contig' function return value populated. This has been fixed internally and will be part of the next release. In the meantime, if you want to modify your own version of the code you need to do the following:. In deepvariant/labeler/BUILD, in the ""haplotype_labeler_test"", add the following dependency:; ""//third_party/nucleus/protos:reference_py_pb2"",. In deepvariant/labeler/haplotype_labeler_test.py, include the following import and mock call:. ### Insert at line 42; from third_party.nucleus.protos import reference_pb2. ### Insert at line 346; labeler._ref_reader.contig.return_value = reference_pb2.ContigInfo(name='20', n_bases=50)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/154#issuecomment-465775663:37,mock,mock,37,,https://github.com/google/deepvariant/issues/154#issuecomment-465775663,2,['mock'],['mock']
Testability,"Hi @qili93 ; I wasn't able to reproduce your error. Here is what I did (on a Ubuntu 16 machine); ```; git clone https://github.com/google/deepvariant.git; cd deepvariant; ./build-prereq.sh && pip install --user 'intervaltree==2.1.0'; bazel test -c opt //deepvariant/labeler:haplotype_labeler_test; ```. And this passed for me. Currently your setting might be outside our actively supported platform. If you can suggest a patch (that wouldn't break other settings), we're happy to make a fix internally as well. But we don't currently have extra bandwidth to look into this issue. One more question for you (it'll really help us understand your need and why you need to build) -- Were you able to run with our prebuilt docker container image? If so, what was the reason that you decided to build on your own? . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/154#issuecomment-464843333:240,test,test,240,,https://github.com/google/deepvariant/issues/154#issuecomment-464843333,1,['test'],['test']
Testability,"Hi @qili93 ; can you paste your error messages here?. Many of the recent test errors reported by users are related to the fact that we didn't pin our intervaltree version in our last release, and intervaltree v3 came out and had some API changes... So, the first thing to try is to change this line:; https://github.com/google/deepvariant/blob/r0.7/run-prereq.sh#L86; to:; ```; pip install --user 'intervaltree==2.1.0'; ```; and see if the tests will pass? Please let me know. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/154#issuecomment-464599230:73,test,test,73,,https://github.com/google/deepvariant/issues/154#issuecomment-464599230,2,['test'],"['test', 'tests']"
Testability,"Hi @raphaelbetschart,. Just wondering on a few things:. 1) What are your QUAL and GQ scores for that call site?; 2) Is that SNP at an exon boundary?; 3) What tissue is this from? (Different tissue types can have an impact with DeepVariant RNA-Seq.); 4) Is this site in the [REDIportal](http://srv00.recas.ba.infn.it/atlas/search.html)? . Based on this curve, at 5x coverage you should still get a good majority of the CDS label variants that you saw at 3x coverage (this figure is from the Supplementary data available in [the paper](https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031?login=false) listed in the Reference section):. ![image](https://github.com/google/deepvariant/assets/6555937/2f6f8745-89ee-455e-8d20-950ef983875b). Thanks,; Paul. #### References; [1] [A deep-learning-based RNA-seq germline variant caller](https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031?login=false)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/701#issuecomment-1695811605:610,log,login,610,,https://github.com/google/deepvariant/issues/701#issuecomment-1695811605,2,['log'],['login']
Testability,"Hi @sclan ; to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur.; The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: ; ```; def main(_):; check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir); check_flags(). commands = create_all_commands(); for command in commands:; print('\n***** Running the command:*****\n{}\n'.format(command)); try:; subprocess.check_call(command, shell=True, executable='/bin/bash'); except subprocess.CalledProcessError as e:; logging.info(e.output); raise; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/232#issuecomment-596040813:692,log,logging,692,,https://github.com/google/deepvariant/issues/232#issuecomment-596040813,1,['log'],['logging']
Testability,"Hi @segoerge ; Sorry that it took a while for me to get to this again. I'm now trying to get a Debian 10 to reproduce your issue. But I'm actually stuck at getting nvidia-smi to work on Debian 10. Here is what I've done so far:. ## Get a Debian 10 machine; ```; gcloud compute instances create ""${USER}-debian-10-gpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --maintenance-policy ""TERMINATE"" \; --accelerator=type=nvidia-tesla-p100,count=1 \; --image=debian-10-buster-v20200618 \; --image-project=debian-cloud \; --machine-type n1-standard-16 \; --zone ""us-west1-b""; ```. ## On the machine, install driver and docker; I did:; ```; curl https://gist.githubusercontent.com/pichuan/c538f04f08cd367c6ea2ad2df7be4de0/raw/a3c8dd11b5365dfa39351265dd53d7d986b84d8b/debian10_install_nvidia_docker.sh | bash -x; ```; to install. You can take a look at https://gist.githubusercontent.com/pichuan/c538f04f08cd367c6ea2ad2df7be4de0/raw/a3c8dd11b5365dfa39351265dd53d7d986b84d8b/debian10_install_nvidia_docker.sh to see what I did. At the end, this command failed:; ```; pichuan@pichuan-debian-10-gpu:~$ sudo docker run --gpus 1 nvidia/cuda:10.0-base nvidia-smi; docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused ""process_linux.go:449: container init caused \""process_linux.go:432: running prestart hook 0 caused \\\""error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: initialization error: driver error: failed to process request\\\\n\\\""\"""": unknown.; ERRO[0000] error waiting for container: context canceled ; ```; I saw this being reported here as well: https://github.com/NVIDIA/nvidia-container-toolkit/issues/183 . I'll need to figure this out because I can actually test DeepVariant behavior on this. If you have suggestions on how to get this work, let me know and I can proceed. Otherwise I'll take a look again later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/321#issuecomment-671016803:1767,test,test,1767,,https://github.com/google/deepvariant/issues/321#issuecomment-671016803,1,['test'],['test']
Testability,"Hi @serge2016 ,; If you have a setup that works for Ubuntu20.04 as well as Ubuntu18.04, I'd be happy to use it as our default.; You can send a pull request with your changes that works for both Ubuntu20.04 and Ubuntu18.04. Even though we can't directly merge pull requests, I can make corresponding internal changes and mention your contribution in the commit log.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/476#issuecomment-902118100:360,log,log,360,,https://github.com/google/deepvariant/issues/476#issuecomment-902118100,1,['log'],['log']
Testability,"Hi @simoncchu ,; I tried to run a small Quick Start using the same Singularity and OS version as you. ; With the small tests, I'm not able to see the issue that you observed. And, when I ran with `--intermediate_results_dir tmp/`, I actually do see a ""tmp"" directory created at my current working directory. Given that I'm not able to reproduce your issue, I'm not sure what's the best next step for me. If you're able to share more detailed setting for me so I can reproduce your issue, that'll be helpful. I'm not super familiar with Singularity, so I wonder if there are some other setting (other than the version) that could affect this. I'll share my steps below so you can take a look. . ----. Here are my steps trying to test Singularity on CentOS 8. Get a machine:; ```; gcloud compute instances create ""${USER}-centos8"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""centos-8"" \; --image-project ""centos-cloud"" \; --machine-type ""e2-standard-16"" \; --boot-disk-size ""200G"" \; --zone ""us-west1-b""; ```. ssh into the machine:; ```; gcloud compute ssh ${USER}-centos8; ```. Check OS version:; ```; [pichuan@pichuan-centos8 ~]$ cat /etc/os-release; NAME=""CentOS Linux""; VERSION=""8""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""8""; PLATFORM_ID=""platform:el8""; PRETTY_NAME=""CentOS Linux 8""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:8""; HOME_URL=""https://centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/""; CENTOS_MANTISBT_PROJECT=""CentOS-8""; CENTOS_MANTISBT_PROJECT_VERSION=""8""; ```. I installed singularity on the machine following instructions on https://sylabs.io/guides/3.7/admin-guide/installation.html#installation-on-linux. Confirmed the version:; ```; [pichuan@pichuan-centos8 ~]$ singularity --version; singularity version 3.7.0-1.el8; ```. I'm using the data in Quick Start to test. I downloaded data in the Quick Start: https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md. Then, I ran:; ```; BIN_VERSION=1.1.0. singu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/296#issuecomment-767294612:119,test,tests,119,,https://github.com/google/deepvariant/issues/296#issuecomment-767294612,2,['test'],"['test', 'tests']"
Testability,"Hi @sophienguyen01 , can you specifically point out the line of the error? All the lines in the logs are API warnings, you can safely ignore those.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2073368951:96,log,logs,96,,https://github.com/google/deepvariant/issues/802#issuecomment-2073368951,1,['log'],['logs']
Testability,"Hi @tgelafr-btx , thanks for waiting. It took me a while to get back to this. Before I share my work log, one observation from your error earlier:; It seems like you're using Python 3.10. Note that DeepVariant 1.5.0 is bulit with Python 3.8. So, can you try with Python 3.8?. ---. Here is what I tried. On a GCE instance, I ran:. ```bash; wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; bash Miniconda3-latest-Linux-x86_64.sh -b -u -p $HOME/miniconda; eval ""$(${HOME}/miniconda/bin/conda shell.bash hook)""; ```. Then, I ran:. ```bash; conda config --add channels defaults && \; conda config --add channels bioconda && \; conda config --add channels conda-forge; conda create -y -n dv-env deepvariant; conda activate dv-env; ```. Which seems to work (without error). I don't actually know how to use conda (or deepvariant in conda). But I did see the files here: . ```; (dv-env) pichuan@pichuan-cpu:~$ ls /home/pichuan/miniconda/envs/dv-env/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/; call_variants.zip licenses.zip model_train.zip runtime_by_region_vis.zip; call_variants_keras.zip make_examples.zip multisample_make_examples.zip settings.sh; deeptrio make_examples_somatic.zip postprocess_variants.zip show_examples.zip; freeze_graph.zip model_eval.zip run-prereq.sh vcf_stats_report.zip; ```. These are probably the files that were packaged with the last release: https://github.com/google/deepvariant/releases/tag/v1.5.0. @tgelafr-btx Question for you: Have you consider using Docker or Singularity, which are better supported by our team? Like the example in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md or https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-pacbio-model-case-study.md . Anyway, hopefully my test with conda install was somewhat informative. If you figure out how to install+use it, please update here. I don't think I would be able to provide further support on conda here t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/736#issuecomment-1829204521:101,log,log,101,,https://github.com/google/deepvariant/issues/736#issuecomment-1829204521,1,['log'],['log']
Testability,"Hi @tinyfallen . @pgrosu is correct, the most efficient way is to run DeepVariant individually and then merge with GLnexus. One point to make, GLnexus runs quite quickly relative to the variant calling step. The joint calling operation won't add much cost relative to DeepVariant (scaling benchmarks for GLnexus can be found in Figure 7C of [the DeepVariant-GLnexus paper](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So the main resource use can be estimated from the single sample runtime multiplied by sample number. If you are curious for a comparison, it might make sense to run a single sample and compare the calls for that sample with the extracted set of calls from the GATK joint calls.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/651#issuecomment-1576131534:289,benchmark,benchmarks,289,,https://github.com/google/deepvariant/issues/651#issuecomment-1576131534,1,['benchmark'],['benchmarks']
Testability,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/683#issuecomment-1644260839:1671,test,test,1671,,https://github.com/google/deepvariant/issues/683#issuecomment-1644260839,1,['test'],['test']
Testability,"Hi @woodoo46 ; Can you give me more information like:; Which OS you're using, what singularity version, etc. And, are there more logs before the first line?; ```; I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None; ```. It'll help if I can try reproducing the error first.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/444#issuecomment-821754409:129,log,logs,129,,https://github.com/google/deepvariant/issues/444#issuecomment-821754409,1,['log'],['logs']
Testability,"Hi @yangyxt ,; In your log, I saw this line which is a bit strange:. ```; Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error; ```. I tried to search for that function in our r1.4 codebase (which is the version you mentioned you're using):. ```; git clone https://github.com/google/deepvariant.git; cd deepvariant/; git checkout r1.4; find . -type f -exec grep -H call_deeptrio_per_pair {} \;; ```. And I can't find that function in our codebase. Can you confirm that you're running our version, or maybe you're running a modified version from somewhere else?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/646#issuecomment-1547115920:23,log,log,23,,https://github.com/google/deepvariant/issues/646#issuecomment-1547115920,1,['log'],['log']
Testability,"Hi @yassineS . Thank you for the question. In short, DeepVariant tends to call fewer variants as coverage drops (this is similar to other callers). We have benchmarks for down to 15x of Illumina WGS [at our ""20 is the new 30 blog post](https://google.github.io/deepvariant/posts/2019-09-10-twenty-is-the-new-thirty-comparing-current-and-historical-wgs-accuracy-across-coverage/). This also breaks down the types of errors by class as coverage falls. I am not sure what the lower bound of coverage for using DeepVariant. At some point, imputation approaches will be required instead of variant calling ones. I would guess this is somewhere around 5x-8x. . I am curious how low you consider low coverage, so I understand your use case.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/279#issuecomment-591172632:156,benchmark,benchmarks,156,,https://github.com/google/deepvariant/issues/279#issuecomment-591172632,1,['benchmark'],['benchmarks']
Testability,"Hi @yonatansc97 . In the default WGS and exome models, DeepVariant does not expand the content of insertion sequences. Instead, it represents them with a character marker that indicates that an insertion is present at the position. To a human, this visually looks like a SNP in the pileup, but the machine learning model can easily distinguish this from a SNP event. This representation is necessary in order to keep the pileup at a consistent width. The information of the content of the insertion is also implicitly present in the 5th channel (supports variant) which only gets a value of 255 with the read when the insertion sequence matches the event to be called. The representation is in some ways sub-optimal, because in some cases information is lost in the presentation to the network. We have developed an additional process, which aligns reads to the ALT allele as well, which expands insertion sequences and makes the full sequence of ALT insertion events visible. This improves accuracy for calling variants in PacBio HiFi data and Oxford Nanopore data, and is defaulted to on in those models. . The flag for this option is: --alt_aligned_pileup, which can have the values: --alt_aligned_pileup=diff_channels and --alt_aligned_pileup=rows. . From our benchmarks, the --alt_aligned_pileup flag did increase accuracy in Illumina WGS and exome models, but only marginally. Since this also somewhat increases the compute cost, we do not use this option in Illumina WGS and exome models. We discuss this feature in more detail in our [blog on DeepVariant v1.0](https://ai.googleblog.com/2020/09/improving-accuracy-of-genomic-analysis.html)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/379#issuecomment-724880533:1264,benchmark,benchmarks,1264,,https://github.com/google/deepvariant/issues/379#issuecomment-724880533,1,['benchmark'],['benchmarks']
Testability,"Hi @yonatansc97 . Those imports you listed have something in common: they are in C++ (or protos) and therefore need to be compiled first.; Inside the docker container, we have these already compiled into the binaries like `/opt/deepvariant/bin/make_examples`, while `make_examples.py` is the source, but it won't work without compiling its C++ dependencies. I don't know how to make this work with your special setup, but perhaps the documentation on building from source will help get you started: https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-build-test.md. I hope that helps at least point you in the right direction!; Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/359#issuecomment-701664438:570,test,test,570,,https://github.com/google/deepvariant/issues/359#issuecomment-701664438,1,['test'],['test']
Testability,"Hi Again,. I’ve had a chance to do some testing with my own samples, so I thought I should report back:. Going back to _point 4_, I noticed that you could choose to output a gVCF file in DeepVariant. However, that is not what is done by default (and it’s not what I did), and I can also tell that’s probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldn’t expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out “complex variants” (with more than one variant at a position), but .vcf files containing those variants weren’t flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:; ```; 68759 / 72556 (94.8%) full SNP recovery; 71276 / 72556 (98.2%) partial SNP recovery; 3027 / 3648 (83.0%) full insertion recovery; 3413 / 3648 (93.6%) partial insertion recovery; 3119 / 3911 (79.7%) full deletion recovery; 3596 / 3911 (91.9%) partial deletion recovery; ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:; ```; 51417 / 54229 (94.8%) full SNP recovery; 53116 / 54229 (97.9%) pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:40,test,testing,40,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,1,['test'],['testing']
Testability,"Hi Alexey,. sure, the exact command was:. ``` sudo docker run --gpus all --cpus=25.0 -v /home/docker_input:/input -v /home/docker_output:/output google/deepvariant@sha256:fcecf5e3032245dd0b6da2c28ec0d9a9d099537af7d6df054df0e25fe4a29006 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/grch37.75.fa --reads=/input/input.bam --output_vcf=/output/output.vcf --num_shards=25 --make_examples_extra_args logging_every_n_candidates=10000 ```. I think there is nothing special regarding the used parameters. One difference to your quick start guide is the usage of ""docker run --gpus all"" instead of the deprecated nvidia-docker (see https://github.com/NVIDIA/nvidia-docker#quickstart) . I did some additional checks with ""nvidia-smi"" command, when calling is runing. It seems like it's definitly not using the GPU. Is it maybe possible that this is some driver incompatibility with our installed nvidia drivers and the one inside the docker container? I'm wondering where this 410.129.0 version in the logs is comming from. Best regards,. Sebastian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/321#issuecomment-656000987:1013,log,logs,1013,,https://github.com/google/deepvariant/issues/321#issuecomment-656000987,1,['log'],['logs']
Testability,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/870#issuecomment-2307643608:41,log,logs,41,,https://github.com/google/deepvariant/issues/870#issuecomment-2307643608,1,['log'],['logs']
Testability,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-476428247:462,benchmark,benchmarks,462,,https://github.com/google/deepvariant/issues/165#issuecomment-476428247,2,"['benchmark', 'test']","['benchmarks', 'tested']"
Testability,"Hi Andy, thank you for your response. I am working with ancient DNA which in the vast majority of the cases comes; at coverages between 0.1-1X. So data missingness is a reality we know how; to deal with, I just want to make sure that the calls we are making are; accurate. The second family of data I am working with are indigenous groups that are; at least diverged from the reference over 2000 generations ago. We observe; a strong bias towards the reference allele using GATK, but it'll be very; interesting to see how DeepVariant behave in such cases. On Wed, 26 Feb 2020 at 11:17, Andrew Carroll <notifications@github.com>; wrote:. > Hi @yassineS <https://github.com/yassineS>; >; > Thank you for the question. In short, DeepVariant tends to call fewer; > variants as coverage drops (this is similar to other callers). We have; > benchmarks for down to 15x of Illumina WGS at our ""20 is the new 30 blog; > post; > <https://google.github.io/deepvariant/posts/2019-09-10-twenty-is-the-new-thirty-comparing-current-and-historical-wgs-accuracy-across-coverage/>.; > This also breaks down the types of errors by class as coverage falls.; >; > I am not sure what the lower bound of coverage for using DeepVariant. At; > some point, imputation approaches will be required instead of variant; > calling ones. I would guess this is somewhere around 5x-8x.; >; > I am curious how low you consider low coverage, so I understand your use; > case.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/279?email_source=notifications&email_token=AANPQIK47CJ7LXIEDGA365DREW3YTA5CNFSM4K2FW2S2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEM6JIGA#issuecomment-591172632>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AANPQIIDTK3D5ON7PYU7BE3REW3YTANCNFSM4K2FW2SQ>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/279#issuecomment-591260702:835,benchmark,benchmarks,835,,https://github.com/google/deepvariant/issues/279#issuecomment-591260702,1,['benchmark'],['benchmarks']
Testability,"Hi Charles,. Great! So if you run the following steps, what do you see (I know some are obvious, but it's just a sanity check):. $`1)`$ The following will test that your file is at the correct location:. ```; ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs . ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs | grep NC_045426.1_A_filt_fixed_markdup_csort.bam; ```. $`2)`$ The following will test that your `INPUT_DIR` environment variable works properly:. ``` ; INPUT_DIR=""${PWD}/inputs"" . echo ${PWD}. ls -l ${INPUT_DIR}. ls -l ${INPUT_DIR} | grep NC_045426.1_A_filt_fixed_markdup_csort.bam; ```. $`3)`$ The following will test that your `INPUT_DIR` environment variable works properly inside Docker:. ```; INPUT_DIR=""${PWD}/inputs"" ; BIN_VERSION=""1.5.0"". echo ${PWD}. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input. sudo docker run -v ""${INPUT_DIR}"":""/input"" google/deepvariant:""${BIN_VERSION}"" ls -l /input | grep NC_045426.1_A_filt_fixed_markdup_csort.bam; ```. You should see the file `NC_045426.1_A_filt_fixed_markdup_csort.bam` for all 3 steps. Please list for which step you don't see that file, and what you actually see for that step (in terms of the complete output of the step). Of course the other way to explicitly name the input and output variables, by changing them to the following (and not relying on `${PWD}` - the present working directory - which could change):. ```; INPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"". OUTPUT_DIR=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/outputs"". ```; Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1699969751:155,test,test,155,,https://github.com/google/deepvariant/issues/184#issuecomment-1699969751,3,['test'],['test']
Testability,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow.; It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-479584377:424,log,logs,424,,https://github.com/google/deepvariant/issues/167#issuecomment-479584377,1,['log'],['logs']
Testability,"Hi Charles,. Usually `mount` (`-v`) require specialized access that the administrator can provide. ; Maybe you can show them our tests that worked for you previously. In any case, here are a few more tests:. $`1)`$ The first is to use the `mount` command explicitly:. ```; docker run \; --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" \; google/deepvariant:""1.5.0"" ls -l /input; ```. $`2)`$ This is using volumes, which is a different approach:. ```; docker volume create --name dv-vol. docker run \; --mount source=dv-vol,target=""/input"" \; google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run \; --mount source=dv-vol,target=""/input"" \; google/deepvariant:""1.5.0"" ls -l /input. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. touch input-path-cont/file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run \; --mount source=dv-vol,target=""/input"" \; google/deepvariant:""1.5.0"" ls -l /input. docker rmi --force hello-world:latest. docker volume rm dv-vol; ```. If the volume removal gives you an error like this:. ```; Error response from daemon: remove dv-vol: volume is in use - [ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2]; ```; Just perform `docker container rm` on each individual of the listed container ids in the brackets, like this (before trying `docker volume rm dv-vol` again):. ```; docker container rm ba544db0a11b27dfdc6eb578c65e4a6eb09c31854a039bce010b37e2bf40f3f2; ```. Let me know the results of both steps. Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1701584604:129,test,tests,129,,https://github.com/google/deepvariant/issues/184#issuecomment-1701584604,2,['test'],['tests']
Testability,"Hi Hagen,. Could you please attach worker logs located at gs://ms_bam/deep_output/stage/logs/call_variants/0?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/129#issuecomment-447057319:42,log,logs,42,,https://github.com/google/deepvariant/issues/129#issuecomment-447057319,2,['log'],['logs']
Testability,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/217#issuecomment-530580878:454,test,test,454,,https://github.com/google/deepvariant/issues/217#issuecomment-530580878,1,['test'],['test']
Testability,"Hi Maria,. Thanks for the response. My Intent is to generate frozen graph from the available checkpoints. The code snippet is my own. Do you think it needs any fixing / addition? . Is there anyone who can provide steps/methods/guidance? I tried from inside as well as outside the Docker. I even tried Google Colab with different Hardware configurations -- i.e. combination of CPU, GPU, TPU. And also with different TF versions. I am never able to import the meta graph and restore the checkpoint. I always get ""No Op Kernel was registered"" with different Op names. Additional question: for training:. - Can I train on the ""quickstart-testdata"" provided in deepvariant? ; - And how do I produce a frozen graph during a training run?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/339#issuecomment-681204545:634,test,testdata,634,,https://github.com/google/deepvariant/issues/339#issuecomment-681204545,1,['test'],['testdata']
Testability,"Hi Maria,; Thanks a lot for your help!; [problematic logs with training.docx](https://github.com/google/deepvariant/files/4641018/problematic.logs.with.training.docx). Now I am setting Google Cloud SDK in our Linux system, but whenever I run the following command, there is an error.; ( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \; sudo nvidia-docker run \; -v ${HOME}:${HOME} \; google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/make_examples \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM_CHR1}"" \; --examples ""${OUTPUT_DIR}/training_set.with_label.tfrecord@${N_SHARDS}.gz"" \; --truth_variants ""${TRUTH_VCF}"" \; --confident_regions ""${TRUTH_BED}"" \; --task {} \; --regions ""'chr1'"" \; ) >""${LOG_DIR}/training_set.with_label.make_examples.log"" 2>&1; Since there are no GPUs in our server, I changed the ""nvidia-docker"" to ""docker"", and the ""${BIN_VERSION}-gpu"" to ""${BIN_VERSION}"", but it still didn't work with an error that 'The index file is older than the data file'.; The log is attached here and I wonder whether the training mode could work without a GPU machine. Thanks a lot!; Best regards,; Weiwei",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/308#issuecomment-629860393:53,log,logs,53,,https://github.com/google/deepvariant/issues/308#issuecomment-629860393,5,['log'],"['log', 'logs']"
Testability,"Hi Mark and Asha,; here's what I believe the current status is:; (1) If there is just an empty shard (a shard file that exist, but just contains 0 record) out of many, what happens is the code will move on to the next shard to attempt to read image/format. -- this is what Mark meant by the previously fixed empty shards bug.; (2) However, if all the shard files exist but all of them contains 0 records, the current code can fail with that error message above. In this case, if the actual error message observed is:; The TF examples in /mnt/data/input/gs/wgs-test-shan/test_samples/UDN689484temp/examples/examples_output.tfrecord-00000-of-00064.gz has image/format 'None' (expected 'raw'). It seems like this call_variant run is specifically being done on on that one file. And if that file has 0 record, unfortunately it will currently fail with that error. :-(. So, I think this is a real bug that we should fix. Because we do expect the use case where users run 64 separate call_variants, and some of them might have complete empty single input file. Is that correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/27#issuecomment-355805026:560,test,test-shan,560,,https://github.com/google/deepvariant/issues/27#issuecomment-355805026,1,['test'],['test-shan']
Testability,"Hi Nils,. This is possibly because most of the decoy contigs are excluded by default through the following file (because of possible large incorrect mappings):. https://github.com/google/deepvariant/blob/r1.5/deepvariant/exclude_contigs.py. More of this is discussed in [issue 37](https://github.com/google/deepvariant/issues/37). In this situation, besides trying with GRCh38 -- which could be a good check -- some of your reads probably have better alignment to the decoy contigs with suboptimal alignment to chromosome Y (or vice-versa). One thing you could try is to indirectly determine the sex of the sample via a threshold that compares differences between allele depth (AD) and depth of coverage (DP) across variants in the sample. If that is not enough (in case they are equal), then a comparison between GQ and QUAL might provide better granularity. The idea is that suboptimal vs optimal read alignments for chrY might work as an inference of sex. For this to work, you would need to create a test and validation set of samples where the sex is known to extract what the threshold would be. I'm assuming these are not in the pseudo-autosomal (PAR) regions, as both chrX and chrY are identical in the PAR regions of the genome assembly. As a last resort you can rename the decoys in your BAM and reference with something different than the ones in the excluded file, so that they would be included in the VCF. What's interesting is that you see the decoy-aligned reads on chrY. As I think a bit about the realignment and how things are excluded, can you confirm that the reads that were aligned to the decoy contigs actually realign to chrY? Basically does your DP increase for regions of chrY more than the number of reads you expect there, and would account for reads from the decoy contigs? I'm only asking based on how I see the code processing the regions. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/695#issuecomment-1677027250:1004,test,test,1004,,https://github.com/google/deepvariant/issues/695#issuecomment-1677027250,1,['test'],['test']
Testability,"Hi Nima, ; I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. ; ```; call-varia--root--180510-193828-03: SUCCESS; Traceback (most recent call last):; File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>; run(); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run; _run_call_variants(pipeline_args); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants; result.get(); File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get; raise self._value; RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]].; (exit status 1); ```. Here are the full runner log. You can find out the yam file in the same repo.; [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log); [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log); [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/70#issuecomment-388183666:912,log,log,912,,https://github.com/google/deepvariant/issues/70#issuecomment-388183666,7,['log'],['log']
Testability,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/87#issuecomment-414549806:704,test,testing,704,,https://github.com/google/deepvariant/issues/87#issuecomment-414549806,1,['test'],['testing']
Testability,"Hi Paul, thanks for mentioning this issue.; I looked at our documentation and noticed that an update was made to our README a few days ago with this extra description:. Pre-built binaries are available at [gs://deepvariant/](https://console.cloud.google.com/storage/browser/deepvariant).; These are compiled to use SSE4 and AVX instructions, so you'll need a CPU (such as Intel Sandy Bridge) that supports them. (The file /proc/cpuinfo lists these features under ""flags"".). But it seems like this new information to the doc hasn't be synced to the external GitHub yet. This should come out in the new year at the latest. I suspect we'd like to keep the pre-built binary having optimization. But we will at least add that line of disclaimer so that it's clear what the binaries are built for.; Would it be ok for you to build DeepVariant for your CPU by following [Building and testing; DeepVariant](docs/deepvariant-build-test.md), or do you need pre-built binaries without AVX from us?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/21#issuecomment-353701703:877,test,testing,877,,https://github.com/google/deepvariant/issues/21#issuecomment-353701703,2,['test'],"['test', 'testing']"
Testability,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue.; [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/94#issuecomment-422863842:127,test,tests,127,,https://github.com/google/deepvariant/issues/94#issuecomment-422863842,2,"['log', 'test']","['log', 'tests']"
Testability,"Hi Peter,; We used multiple HG002 samples generated with PacBio (CCS mode). We didn't test this model for CLR reads.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/174#issuecomment-483406535:86,test,test,86,,https://github.com/google/deepvariant/issues/174#issuecomment-483406535,1,['test'],['test']
Testability,"Hi Phil,; as you can see from the log you posted, the error actually came from:; ```; File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq; ""can't find current frequency file""); ```; If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how.; And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/191#issuecomment-504481029:34,log,log,34,,https://github.com/google/deepvariant/issues/191#issuecomment-504481029,1,['log'],['log']
Testability,"Hi Pi-Chuan, ; I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```; call-varia--root--180508-211940-52: FAILURE; [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]; [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-te",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/70#issuecomment-387564029:844,log,logging,844,,https://github.com/google/deepvariant/issues/70#issuecomment-387564029,2,['log'],"['logging', 'logs']"
Testability,"Hi Pi-Chuan,. I'm still not back home yet (so, I apologize that I'm not 100% answering your question). However, I can say this:. Even thought I would expect the direct command-line analysis (in AWS or Google Cloud) should cost less, I did briefly look into DNAnexus and Seven Bridges. However, DNAnexus requires that you create an account with an institutional e-mail, and I was checking about what were options for people who want to re-analyze that that is directly provided to them (who may not be scientists). I also didn't see a way to create a Seven Bridges account with a G-mail address, but both companies gave me an initial reply about my account creation question within 24 hours. That said, I am also currently working on uploading my data to PrecisionFDA (which uses DNAnexus, but I can't use my PrecisionFDA account to sign into DNAnexus). For the user, I think this would be free, and it provides a way to test results provided by companies (**and** I could create an account with a Gmail address). However, PrecisionFDA doesn't currently have a DeepVariant App. I passed along an earlier version of this thread to them, but I will also now ask if it might be helpful that DNAnexus already has a DeepVariant app (to see how easily that can be applied within PrecisionFDA). I'll upload the call_variants file when I get home. Unless there is something obvious that you can see, I think it would probably be more fair for your time to start a Google Cloud test (although that means you may have to wait a little while before I get to the same step on another platform). Thank you again for all of your prompt replies!. Sincerely,; Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-479700070:920,test,test,920,,https://github.com/google/deepvariant/issues/167#issuecomment-479700070,2,['test'],['test']
Testability,"Hi Pi-Chuan,. Yes, that is correct - you should see it in the generated output files (VCF and GVCF). The control-flow logic for finding these candidates is as follows for [r1.1 of make_examples.py](https://github.com/google/deepvariant/blob/r1.1/deepvariant/make_examples.py):. $`1)`$ On [line 613](https://github.com/google/deepvariant/blob/r1.1/deepvariant/make_examples.py#L613), `options.calling_regions` is extended with the values from the user-defined `--regions` flag:. ```Python; options.calling_regions.extend(parse_regions_flag(flags_obj.regions)); ```. $`2)`$ On [line 2082](https://github.com/google/deepvariant/blob/r1.1/deepvariant/make_examples.py#L2082), in function `make_examples_runner()` a request is made to provide these regions for processing:. ```Python; regions = processing_regions_from_options(options); ```. $`3)`$ On [lines 1960-1961](https://github.com/google/deepvariant/blob/r1.1/deepvariant/make_examples.py#L1960-L1961), in function `processing_regions_from_options()`, the variable `calling_regions` is initialized based on the contents of `options.calling_regions` and `options.exclude_calling_regions`:. ```Python; calling_regions = build_calling_regions(ref_contigs, options.calling_regions,; options.exclude_calling_regions); ```. Which is then used to construct the `regions` and `region_list` on [lines 1968-1975](https://github.com/google/deepvariant/blob/r1.1/deepvariant/make_examples.py#L1968-L1975):. ```; regions = regions_to_process(; contigs=contigs,; partition_size=options.allele_counter_options.partition_size,; calling_regions=calling_regions,; task_id=options.task_id,; num_shards=options.num_shards). region_list = list(regions); ```. $`4)`$ Continuing with function `make_examples_runner()`, on [lines 2105-2106](https://github.com/google/deepvariant/blob/r1.1/deepvariant/make_examples.py#L2105-L2106) it finds candidates based on these regions, creating also the corresponding example files:. ```Python; for region in regions:; candidates, ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/708#issuecomment-1719933271:118,log,logic,118,,https://github.com/google/deepvariant/issues/708#issuecomment-1719933271,1,['log'],['logic']
Testability,"Hi Pi-Chuan,; Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well.; ```; make-examp--root--180505-205721-02: FAILURE; [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']; [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']; Traceback (most recent call last):; File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>; run(); File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/70#issuecomment-386838731:837,log,logging,837,,https://github.com/google/deepvariant/issues/70#issuecomment-386838731,2,['log'],"['logging', 'logs']"
Testability,"Hi Pichuan,. That's a great idea to add it to the README, as it's probably the first thing users see. For those who might miss noticing its importance in the README, it probably would not hurt adding an assert statement to the GCS zip-specific `make_examples.py`, for the appropriate flags in `/proc/cpuinfo` with a gentle commented termination. I also just noticed it with a search here as well:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-release-notes.md#040. Thank you for the offer regarding the customized binaries, but it was just a few minor changes and I got working now. I was just mentioning it in case others might run into that issue, and would wonder why it exited. Thanks,; `p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/21#issuecomment-353712933:203,assert,assert,203,,https://github.com/google/deepvariant/issues/21#issuecomment-353712933,1,['assert'],['assert']
Testability,"Hi Pichuan. > Can you give us a bit more information on your BAM? Is it WGS or WES? Which Illumina sequencing machine is it from?. The am using WES. We assumed this would run faster. We used UC Berkeley HiSeq 4000 illumina machine . > If you are okay with sharing the BAM header, it'll help too. If it's easier to share via email, you can email [pichuan@google.com](mailto:pichuan@google.com); > . I sent the headers to you in email. > > I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good!; > . The run that worked well used WGS. The library was created by a different Lab. Not sure if this is relevant or not. We are running on RNA. We got really good F-scores on our ""gold standard"" data set. > > p.s. I am running in AWS . not sure if that makes a difference or not; > ; > I don't expect it to make a difference. But if you do observe any issues, feel free to let us know what kind of AWS instances you're running on, and what's the unexpected behavior, so we can reproduce the issue.; > . region: oregen; m5dn.8xlarge; 32 CPU; 2 x 600GB SSD; Deep Learning AMI (Ubuntu 16.04) Version 26.0 (ami-07728e9e2742b0662)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/260#issuecomment-573841969:595,log,log,595,,https://github.com/google/deepvariant/issues/260#issuecomment-573841969,1,['log'],['log']
Testability,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam""; Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/219#issuecomment-531389119:63,test,test,63,,https://github.com/google/deepvariant/issues/219#issuecomment-531389119,1,['test'],['test']
Testability,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version?. Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/94#issuecomment-422241830:105,log,log,105,,https://github.com/google/deepvariant/issues/94#issuecomment-422241830,1,['log'],['log']
Testability,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```; wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl; ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python; DESCRIPTOR = _descriptor.FileDescriptor(; name='tensorflow/core/framework/resource_handle.proto',; package='tensorflow',; syntax='proto3',; serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/94#issuecomment-423037408:74,test,tests,74,,https://github.com/google/deepvariant/issues/94#issuecomment-423037408,2,"['log', 'test']","['log', 'tests']"
Testability,"Hi Shalabh,. We have performed internal benchmarks on merging of gVCFs with GATK and do not recommend this approach. I think it will be better to wait for recommendations on merging with GLnexus, or to collaborate directly.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/142#issuecomment-460945051:40,benchmark,benchmarks,40,,https://github.com/google/deepvariant/issues/142#issuecomment-460945051,1,['benchmark'],['benchmarks']
Testability,"Hi Sophie,. So it is best to train across all the samples. The reason is that the model will need to be representative of all those samples, and you don't want to overfit for one sample over another. Today there is more data than computing power and memory, so training happens by batching the data, training on a batch, and then tweaking the model in the follow-up batches. Here's a visual example of what could happen:. ![image](https://github.com/google/deepvariant/assets/6555937/3ff13990-c2cc-4863-a904-bb0219791b06). In the first batch, the coefficients will be biased in a monotonically increasing function. Then when the second batch is used to tweak the model's parameters, it will shift towards a monotonically decreasing function shifting it towards an opposite direction. Then when the third batch comes in it will shift the parameters in the other direction. Sure, the independent variable (x-axis) here is a simple one-dimensional type, but this can become complex with multiple channels (`read base`, `base quality`, `mapping quality`, etc). And of course if the training data is shuffled, then the validation data and tuning data should also be shuffled in order to have the same data representation - with the exception of the test data, which will be used for benchmarking the model as a real scenario (though there is additional read shuffling when downsampling with too many reads for a pileup image). As @akolesnikov mentioned, the `input_pattern_list` parameter of the shuffle script takes a list of files, so you can do it all at once. Let me know if I should expand on anything. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/698#issuecomment-1711046219:1244,test,test,1244,,https://github.com/google/deepvariant/issues/698#issuecomment-1711046219,2,"['benchmark', 'test']","['benchmarking', 'test']"
Testability,"Hi all,. sorry about the late reply I was testing the UKBiobank WES Protocol provided by Andrew but unfortunately it does not seem fix our problem.; The general issue is that to identify runs of homozygosity(ROH) with plink you can also just provide a vcf file but this vcf file needs a base resolution e.g. an entry for each position, whether it is variable or not:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT PacBio_CCS; SUPER_1 1 . C . . . DP=49 GT:AD:DP:RGQ 0/0:49:49:99; SUPER_1 2 . C . . . DP=50 GT:AD:DP:RGQ 0/0:50:50:99; SUPER_1 3 . T . . . DP=54 GT:AD:DP:RGQ 0/0:54:54:99; SUPER_1 4 . A . . . DP=61 GT:AD:DP:RGQ 0/0:61:61:99; ... And we were just wondering if there is a possibility to generate such a vcf file using DeepVariant. Thanks again for all the replies and help. best regards,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/571#issuecomment-1283869277:42,test,testing,42,,https://github.com/google/deepvariant/issues/571#issuecomment-1283869277,1,['test'],['testing']
Testability,"Hi all,; it has recently be reported again that the crashing issue on empty shard for `call_variants` wasn't fully resolved last time. I just released v0.6.1 that should really resolve this issue now:; https://github.com/google/deepvariant/releases/tag/v0.6.1. The issue was that I didn't properly return in the if branch where an empty shard was detected:; https://github.com/google/deepvariant/commit/12f9e67f9a246dcf2209c98f7792a4c728469bc9; (And the unit test I had for it was flawed. We'll fix the unit test in a later release.). This time I've tested it manually on an empty shard, and confirmed that call_variants works when there is zero record. . Please feel free to report if you see any issues again. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/27#issuecomment-385593624:459,test,test,459,,https://github.com/google/deepvariant/issues/27#issuecomment-385593624,3,['test'],"['test', 'tested']"
Testability,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2; I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : ; - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc.; The make command ran well (no error of what I can see) but when I do make check it crashes with ; test-math-isinff.cc: Command not found; If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ?; Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-480128599:835,test,test-math-isinff,835,,https://github.com/google/deepvariant/issues/137#issuecomment-480128599,1,['test'],['test-math-isinff']
Testability,"Hi kmarianski,. This line is suspicious. ; ```; Re-using the directory for intermediate results in /tmp/kmarians_4189323/tmpxrz5rqbp; ```. Each DeepVariant job needs a separate `intermediate_directory`. Could you verify that each job uses different temp directory?. The error in the log comes from TensorFlow library. Unfortunately, we are unable to help with TensorFlow (which is a third party tool).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/602#issuecomment-1381120099:283,log,log,283,,https://github.com/google/deepvariant/issues/602#issuecomment-1381120099,1,['log'],['log']
Testability,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage.; In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. ; Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/249#issuecomment-563510580:132,log,logs,132,,https://github.com/google/deepvariant/issues/249#issuecomment-563510580,1,['log'],['logs']
Testability,"Hi there!. I tried to combine the deepvariant's gvcf files using GATK and it returned a error because of the ""NON_REF"".; Do you have any other recommendation? Or did you tested your gvcf in GATK?. This is the error that I got using GATK:; A USER ERROR has occurred: The list of input alleles must contain <NON_REF> as an allele but that is not the case at position 10325413; please use the Haplotype Caller with gVCF output to generate appropriate records. The DeepVariant ""<NON_REF>"" allele is ""<*>""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/45#issuecomment-481414559:170,test,tested,170,,https://github.com/google/deepvariant/issues/45#issuecomment-481414559,1,['test'],['tested']
Testability,"Hi! Thanks for the question. Since you got DeepVariant working on the command line, this might just be a Nextflow issue, but we can certainly take a look and see if we can help on our end. A few questions and suggestions:; 1. Did you get this Nextflow pipeline from somewhere online or write it yourself?; 2. Can you include more of the log messages? The message you included looks to be from Nextflow, not from DeepVariant, so we need more context to help you debug this.; 3. Can you try running this with a small region, e.g. `--regions chr20:100,000-110,000` in the `run_deepvariant` command? This should make it faster to debug so you don't need to wait multiple hours. You can get that tiny run working before starting a full run.; 4. I'm not an expert on Nextflow, but do you need to set the `output:` in `process pbc_varicall` to see the outputs?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/659#issuecomment-1581314748:337,log,log,337,,https://github.com/google/deepvariant/issues/659#issuecomment-1581314748,1,['log'],['log']
Testability,"Hi!. Made some optimizations and tested on chr20 from https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-case-study.md. Can you please tell me if it's a representative launch?. | [Intel® Xeon® Gold 6258R](https://devcloud.intel.com/edge/devices/intel-xeon-gold-6258r-cpu/) | make_examples | call_variants	| postprocess_variants |; |---|---|---|---|; | TensorFlow MKL-DNN | 3m7.950s | 5m59.221s | 1m5.724s |; | OpenVINO | 3m6.239s | 3m46.756s (x1.58) | 1m7.640s |. (""real"" times are in the table). ```bash; python3 ./bazel-deepvariant/scripts/run_deepvariant.py \; --model_type=WGS \; --ref=./reference/GRCh38_no_alt_analysis_set.fasta \; --reads=./input/HG002.novaseq.pcr-free.35x.dedup.grch38_no_alt.chr20.bam \; --output_vcf=${OUTPUT_DIR}/HG002.output.vcf.gz \; --output_gvcf=${OUTPUT_DIR}/HG002.output.g.vcf.gz \; --num_shards=16 \; --regions ""chr20"" \; --call_variants_extra_args=""use_openvino=True""; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-724316304:33,test,tested,33,,https://github.com/google/deepvariant/pull/363#issuecomment-724316304,1,['test'],['tested']
Testability,"Hi, . I'm sure I'm doing something wrong, but couldn't figure out where that is: the variants I get are not directly phased. I followed the PacBio case study, using the 1.5.0 docker. ; Here's the command. ```bash; $ ./run_deepvariant \; --model_type PACBIO \; --ref /shuang_data/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \; --reads /shuang_data/HG003.GRCh38.chr20.pFDA_truthv2.bam \; --output_vcf /tmp/only_vcf.vcf.gz \; --regions chr20; ```. What's strange in the log are the following lines. ```; ...; I0514 01:48:09.263085 140121429608256 make_examples_core.py:257] 62017 candidates (71070 examples) [121.51s elapsed]; I0514 01:48:23.145400 140121429608256 make_examples_core.py:257] Skip phasing: len(candidates[main_sample]) is 7088.; I0514 01:52:54.732045 140121429608256 make_examples_core.py:257] 67303 candidates (76952 examples) [285.47s elapsed]; ...; I0514 02:28:55.286200 140121429608256 make_examples_core.py:257] 166834 candidates (181516 examples) [142.03s elapsed]; I0514 02:29:01.686342 140121429608256 make_examples_core.py:257] Skip phasing: len(candidates[main_sample]) is 5953.; I0514 02:31:24.326849 140121429608256 make_examples_core.py:257] 172413 candidates (187997 examples) [149.04s elapsed]; I0514 02:31:26.924692 140121429608256 make_examples_core.py:257] Skip phasing: len(candidates[main_sample]) is 7496.; I0514 02:35:53.029588 140121429608256 make_examples_core.py:257] 178012 candidates (194646 examples) [268.70s elapsed]; ....; ```. And there's also the relevant command information from the log below (formatted for human consumption). ```; time seq 0 0 | parallel -q --halt 2 \; --line-buffer /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""/shuang_data/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa"" \; --reads ""/shuang_data/HG003.GRCh38.chr20.pFDA_truthv2.bam"" \; --examples ""/tmp/tmpouwynlb0/make_examples.tfrecord@1.gz"" \; --add_hp_channel \; --alt_aligned_pileup ""diff_channels"" \; --max_reads_per_partition ""600"" \; --min_mapping_quali",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/649#issuecomment-1546990230:470,log,log,470,,https://github.com/google/deepvariant/issues/649#issuecomment-1546990230,1,['log'],['log']
Testability,"Hi, ; I am now testing the quickstart with the test data (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) inside of docker and I get the error ValueError: Not found: Could not open quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam. I followed the instructions and ; ```; OUTPUT_DIR=quickstart-testdata/; REF=quickstart-testdata/ucsc.hg19.chr20.unittest.fasta; BAM=quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam. ## test deepvariant; docker run \; -v /home/${USER}:/home/${USER} \; gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""${REF}"" \; --reads ""${BAM}"" \; --regions ""chr20:10,000,000-10,010,000"" \; --examples ""${OUTPUT_DIR}/examples.tfrecord.gz""; ```. The BAM file is there, when I try ls $BAM, I get: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam. Any suggestions would be great, thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/104#issuecomment-439540680:15,test,testing,15,,https://github.com/google/deepvariant/issues/104#issuecomment-439540680,8,['test'],"['test', 'testdata', 'testing']"
Testability,"Hi, ; thank you both for the answers and suggestions. > The error comes from the line `output_queue = multiprocessing.Queue()` Could you try a simple test? Run docker in CLI model: `docker run -it <DeepVariant image> bash` Inside docker start Python3 and execute:; > ; > ```; > import multiprocessing; > q = multiprocessing.Queue(); > ```; > ; > Please let us know if that works. No, it doesn't work. I get the following error that parallels the one above (full disclosure: I run it again with udocker, not docker):; ```; Python 3.8.10 (default, May 26 2023, 14:05:08); [GCC 9.4.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import multiprocessing; >>> q = multiprocessing.Queue(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory; ```. Also the approach suggested by @kishwarshafin unfortunately didn't work for me. I thought that udocker could be a viable option considering what said in #669. Maybe I'll try to downgrade to 1.5.0 since it's the version that was mentioned in the orginal post. . I'm not really familiar with multiprocessing but I will have a look. If you have any additional pointers, I would be really grateful for them :) . Thank you! ; Federico . EDIT: I tried running DeepVariant v1.5.0 and indeed it works! So I guess it is an issue of the newer release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/733#issuecomment-1818694916:150,test,test,150,,https://github.com/google/deepvariant/issues/733#issuecomment-1818694916,1,['test'],['test']
Testability,"Hi, @pichuan, thanks for your quick replay.; I ran the command `/opt/deepvariant/bin/run_deepvariant --version` using GPU version in singularity image . It return the `CUDA_ERROR_UNKNOWN` error as above I mentioned. Now I am trying to use the 1.5.0 version. I use the same test command and it return the same error as followings:; ```; Singularity> /opt/deepvariant/bin/run_deepvariant --version; 2023-03-16 09:39:40.831726: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-03-16 09:39:40.953050: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.; 2023-03-16 09:39:42.599918: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; 2023-03-16 09:39:42.599962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: yy01.local; 2023-03-16 09:39:42.599972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: yy01.local; 2023-03-16 09:39:42.600020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; 2023-03-16 09:39:42.600049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5; DeepVariant version 1.5.0; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471145851:273,test,test,273,,https://github.com/google/deepvariant/issues/619#issuecomment-1471145851,1,['test'],['test']
Testability,"Hi, I am experiencing similar issue - VM, 32 threads, 64GB RAM. Could you provide the experimental container? ; Btw, thank you for outstanding work while making this software available for us. This tool has great value is reliable and important for us. Regards, ; Tomasz Stokowy, Leader Scientific Computing, University of Bergen, Norway. Running via docker 1.6.1, earlier steps work smoothly. cat /proc/version; Linux version 6.1.0-22-amd64 (debian-kernel@lists.debian.org) (gcc-12 (Debian 12.2.0-14) 12.2.0, GNU ld (GNU Binutils for Debian) 2.40) #1 SMP PREEMPT_DYNAMIC Debian 6.1.94-1 (2024-06-21). Error log:. ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""/Reference/core_ref_GRCh38_hla_decoy_ebv/genome.fa"" --infile ""/Output/call_variants_output.tfrecord.gz"" --outfile ""/Output/CoriellIndex.vcf"" --cpus ""32"" --gvcf_outfile ""/Output/CoriellIndex.gvcf"" --nonvariant_site_tfrecord_path ""/Output/gvcf.tfrecord@32.gz"". I0823 15:16:56.752997 139658307389248 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: CoriellIndex; 2024-08-23 15:16:56.766309: I deepvariant/postprocess_variants.cc:94] Read from: /Output/call_variants_output-00000-of-00001.tfrecord.gz; 2024-08-23 15:18:01.806248: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 10880665; I0823 15:20:45.074391 139658307389248 postprocess_variants.py:1313] CVO sorting took 3.805263650417328 minutes; I0823 15:20:45.077561 139658307389248 postprocess_variants.py:1316] Transforming call_variants_output to variants.; I0823 15:20:45.077694 139658307389248 postprocess_variants.py:1318] Using 32 CPUs for parallelization of variant transformation.; I0823 15:20:51.014987 139658307389248 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: CoriellIndex. real	8m32.455s; user	7m11.835s; sys	1m25.577s; Process ForkPoolWorker-2:; Traceback (most recent call last):; File ""/usr/lib/python3.8/multiproces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/804#issuecomment-2308162449:608,log,log,608,,https://github.com/google/deepvariant/issues/804#issuecomment-2308162449,1,['log'],['log']
Testability,"Hi, I am interested in benchmarking DV on exome data from a group of snakes. I have a single reference genome from a closely related species, but I would not have the trio data as was done with the Drosophila data. Do you know if anyone has been able to retrain DV using one or two genomes without pedigree info? . Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/459#issuecomment-849788653:23,benchmark,benchmarking,23,,https://github.com/google/deepvariant/issues/459#issuecomment-849788653,1,['benchmark'],['benchmarking']
Testability,"Hi, This does not work for me. I still get ; ValueError: Not found: Could not open quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam. Any suggestions?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/104#issuecomment-443661136:94,test,testdata,94,,https://github.com/google/deepvariant/issues/104#issuecomment-443661136,1,['test'],['testdata']
Testability,"Hi, can you provide the worker log as well?; (See this example : https://github.com/google/deepvariant/issues/118#issuecomment-437114999 )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/120#issuecomment-439711961:31,log,log,31,,https://github.com/google/deepvariant/issues/120#issuecomment-439711961,1,['log'],['log']
Testability,"Hi, can you share the commands you ran and the associated logs so we can take a look?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/194#issuecomment-508186152:58,log,logs,58,,https://github.com/google/deepvariant/issues/194#issuecomment-508186152,1,['log'],['logs']
Testability,"Hi, so I noticed in the Deepvariant manuscript supplementary text that the 44x NA12878 CLR data (sorted_final_merged.bam) from GIAB was used for benchmarking Deepvariant with PacBio CLR reads (specifically, that chroms 1-19 were used for training and testing was performed on chroms 20-22). Would it be possible for me to access the result VCF for chroms 20-22 (and ideally also the trained model used in the manuscript)? The reason I'm interested in this is that we have developed our own CLR variant calling method and I would like to fairly compare it with Deepvariant. If I have the VCF, then I can be sure that our precision/recall calculations on chr20-22 are done in exactly the same way, and if I have the trained model then I also have the option to run Deepvariant myself on other CLR data. Unfortunately, the training procedure for Deepvariant seems to be complicated at this time and requires significant compute resources. I would be very grateful if it would be possible to meet this request -- you can reach me by email at pedge AT eng.ucsd.edu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/174#issuecomment-487190949:145,benchmark,benchmarking,145,,https://github.com/google/deepvariant/issues/174#issuecomment-487190949,2,"['benchmark', 'test']","['benchmarking', 'testing']"
Testability,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:; ```; I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]; I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]; ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/74#issuecomment-391092118:180,log,log,180,,https://github.com/google/deepvariant/issues/74#issuecomment-391092118,1,['log'],['log']
Testability,"Hi, thanks for responding. This is very helpful. Definitely will be interested in collaborating on this. I will get back to you with more information on that.; Also, apart from GLnexus, have you performed any testing using GATK4 to merge gVCFs (from Deepvariant) into final VCF? . Shalabh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/142#issuecomment-460720523:209,test,testing,209,,https://github.com/google/deepvariant/issues/142#issuecomment-460720523,1,['test'],['testing']
Testability,"Hi, up to the latest version (1.6), we've been excluding HG003 and chr20-22 from the training data. Building on that assumption, if you train a model (warmstarting our model) that also exclude those data from training, you can be sure that the model would never have seen those data. And you're correct that it's still good to be aware that HG002 is the son of HG003. So it depends on what hypothesis you're testing, you'll want to think about that factor too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/788#issuecomment-1992359932:408,test,testing,408,,https://github.com/google/deepvariant/issues/788#issuecomment-1992359932,1,['test'],['testing']
Testability,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334875005:290,test,tests,290,,https://github.com/google/deepvariant/issues/879#issuecomment-2334875005,1,['test'],['tests']
Testability,"Hi,. We have not tested DeepVariant's accuracy in paralogous regions outside of the GIAB high-confidence regions. Both of your solution can potentially improve the accuracy. The only suggestion we can give you is to look at the pangenome mapping + DeepVariant case-study here: https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-vg-case-study.md where dropping mapq=0 might give you better resolution in the paralogous regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/900#issuecomment-2436210393:17,test,tested,17,,https://github.com/google/deepvariant/issues/900#issuecomment-2436210393,1,['test'],['tested']
Testability,"Hi,; As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself.; This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally.; The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend.; Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/91#issuecomment-418172888:727,log,log,727,,https://github.com/google/deepvariant/issues/91#issuecomment-418172888,1,['log'],['log']
Testability,"Hi,; From a quick look of your error, it doesn't look like anything I've ever; encountered before. If you could potentially set up a reproducible setting; that I can very quickly run, I can see if I can try it out and tell you; what might could have gone wrong. We don't currently have a tutorial for; training, unfortunately. And to be honest, even if we do, it probably; wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is; > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for; > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:; > [64,27,1,3]; >; >; > I hate to keep bothering people about this. Is there documentation on all; > of this that I can refer to?; >; >; > Thanks,; > Brad Thomas; >; >; > From: Pi-Chuan Chang [mailto:notifications@github.com]; > Sent: Tuesday, April 10, 2018 1:04 PM; > To: google/deepvariant <deepvariant@noreply.github.com>; > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <; > author@noreply.github.com>; > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62); >; > CAUTION: This email originated from outside the organization. DO NOT click; > links or open attachments unless you recognize the sender and know the; > content is safe.; >; > I think you'll want:; > tfrecord_path:; > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064""; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub<; > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,; > or mute the thread<; > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>.; >; >; > This message contains confidential information and is intended only for; > the individual named. If you are not the named addressee you should not; > disseminate, distr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-380935943:657,Log,Logits,657,,https://github.com/google/deepvariant/issues/62#issuecomment-380935943,1,['Log'],['Logits']
Testability,"Hi,; I found a bug in the visualizing ipynb and fixed it internally already. It will come out in the next release (which I'm hoping will be soon). For now, please update the `channels_to_rgb` function to this:. ```; def channels_to_rgb(channels):; # Reconstruct the original channels; base = channels[0]; qual = np.minimum(channels[1], channels[2]); strand = channels[3]; alpha = np.multiply(; channels[4] / 254.0,; channels[5] / 254.0); return np.multiply(; np.stack([base, qual, strand]),; alpha).astype(np.uint8).transpose([1, 2, 0]); ```. It was actually a pretty obvious mistake. I wish I unit tested my notebook.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/110#issuecomment-432092110:599,test,tested,599,,https://github.com/google/deepvariant/issues/110#issuecomment-432092110,1,['test'],['tested']
Testability,"Hi,; can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```; gcloud beta compute instances create ""${USER}-centos-test"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image ""centos-7-v20181011"" \; --image-project centos-cloud \; --machine-type ""custom-64-131072"" \; --boot-disk-size ""300"" \; --boot-disk-type ""pd-ssd"" \; --zone ""us-west1-b""; ```. I sshed into the machine, and checked the OS version:. ```; [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release; CentOS Linux release 7.5.1804 (Core) ; ```. Then:. ```; [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker; [pichuan@pichuan-centos-test ~]$ sudo service docker start; Redirecting to /bin/systemctl start docker.service; [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1; ```. Then, I use a modified script to run WES case study:. ```; root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash; ```. You can see:; https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh; for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/104#issuecomment-437647446:166,test,testing,166,,https://github.com/google/deepvariant/issues/104#issuecomment-437647446,6,['test'],"['test', 'testing']"
Testability,"Hi,; from your log, it seems like this call failed `read.aligned_quality[read_pos]`, which might indicate that read doesn't have a quality score?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/75#issuecomment-403638598:15,log,log,15,,https://github.com/google/deepvariant/issues/75#issuecomment-403638598,1,['log'],['log']
Testability,"Hi,; looking at your log closely, specifically this:; ```; File ""/tmp/Bazel.runfiles_1j54j0yh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 549, in build_calling_regions; regions = ranges.RangeSet.from_contigs(contigs); ```. and ; ```; ValueError: IntervalTree: Null Interval objects not allowed in IntervalTree: Interval(0, 0); ```. It seems like you might have contigs in your reference files that are empty. Is that expected?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/77#issuecomment-394751639:21,log,log,21,,https://github.com/google/deepvariant/issues/77#issuecomment-394751639,1,['log'],['log']
Testability,"Hi,; originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data.; How about at least posting the commands you used?. From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty.; (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381167653:596,log,logic,596,,https://github.com/google/deepvariant/issues/62#issuecomment-381167653,1,['log'],['logic']
Testability,"Hi,; we don't currently have a good tutorial for training mode yet. But a quick answer here - your understanding for the ""labels"" isn't quite correct.; 0/0, 0/1, or 1/1 you're referring to is the representation in VCFs, which is HOM-REF, HET, and HOM-ALT.; However, that's not how the ""labels"" are represented in the training examples. If you want to see examples of how each of the ""training examples"" that go into training, please look at this:; https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb; Specifically, this data here was generated with `make_examples` in training mode:; ```; # This tfrecord comes from HG002 PFDA data. I ran make_examples in training mode so we also have the labels.; src = 'gs://deepvariant/datalab-testdata/make_examples_datalab.tfrecord.gz'; ```. The ""label"" that represent the 3 classes are actually 0, 1, or 2, which represents HOM-REF, HET, and HOM-ALT. You can see the `get_label` function in the notebook. The representation (0/0, 0/1, 1/1) you're seeing in the final VCF is after `postprocess_variants` step, where we properly write out the common VCF format from the intermediate representation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/67#issuecomment-383258475:759,test,testdata,759,,https://github.com/google/deepvariant/issues/67#issuecomment-383258475,1,['test'],['testdata']
Testability,"Hi,; we have seen regions that run for longer. Up to 14 or 22 hours still sound like longer than what I personally have seen before. ; If you look into the log files of the `make_examples` shard (under `$HOME/case-study/output/logs/1/`), you can see log like this:. ```; I0815 16:59:22.392369 139972404860672 make_examples.py:825] Found 0 candidates in 1:2392001-2393000 [1000 bp] [0.08s elapsed]; I0815 16:59:22.490614 139972404860672 make_examples.py:825] Found 1 candidates in 1:2456001-2457000 [1000 bp] [0.10s elapsed]; I0815 16:59:22.616637 139972404860672 make_examples.py:825] Found 4 candidates in 1:2520001-2521000 [1000 bp] [0.12s elapsed]; ```. If you find where it stopped, you can usually use the pattern of regions to find out which one it got stuck on. Let me know if that helps. I'll also discuss with the team to see if we can print out more incremental logs in cases like this to help understand what the code is doing.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/105#issuecomment-429911563:156,log,log,156,,https://github.com/google/deepvariant/issues/105#issuecomment-429911563,4,['log'],"['log', 'logs']"
Testability,"Hi. After your comment I've repeated the test using the same input BAM (18X WGS sequenced with 150bp paired reads), running deepvar 0.9.0 and 1.0.0 with singularity v.3.5.2-1.1.el7 and exactly the same command (`--num_shards=10`). The running time is now almost the same, much longer than my old test with deepvar 0.9.0 on a 30X WGS. . Below I've reported running time in min for make_example+call_variants+post_process:; - **v0.9.0**: 290+1494+281 = 2065min (~34h); - **v1.0.0**: 335+1487+300 = 2122min (~35h); - **v0.9.0 OLD TEST ON 30X WGS**: 198+456+82 = 736min (~12h). The number of variants for the 3 runs are:; - **v0.9.0**: 531371190 g.vcf.gz; 10784757 vcf.gz (4552313 PASS, 6232444 RefCall); - **v1.0.0**: 547491396 g.vcf.gz; 11892262 vcf.gz (4619350 PASS, 7272912 RefCall); - **v0.9.0 OLD TEST ON 30X WGS**: 213244705 g.vcf.gz; 9096927 vcf.gz (4661618 PASS, 4435309 RefCall). So, the first question is: are these running times expected? The running times you reported are much shorter it seems. Can it be that the running time increased from 12 to 34h just because of the lower coverage? . The exact command I've used is below (it is the same for v1.0.0 but using the corresponding singularity image):; ```; singularity exec \; --bind /data/ref/genomes/GRCh38:/genomes \; --bind /data/projects/HICF2_project/BAM:/bam_files \; /well/gel/HICF2/software/singularity/deepvariant-0.9.0.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS --ref=""/genomes/GCA_000001405.15_GRCh38_full_plus_hs38d1_analysis_set.fna"" \; --reads=""/bam_files/${bamfile}"" \; --output_vcf=""VCF/${sampleID}.vcf.gz"" \; --output_gvcf=""VCF/${sampleID}.g.vcf.gz"" \; --intermediate_results_dir=""tmp_data"" \; --num_shards=10; ```. I've uploaded the log files from the 3 runs if you want to take a look:; [deepvar_0.9.0_oldrun.log](https://github.com/google/deepvariant/files/5281370/deepvar_0.9.0_oldrun.log); [deepvar_1.0.0.log](https://github.com/google/deepvariant/files/5281371/deepvar_1.0.0.log); [deepvar_0.9.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/346#issuecomment-698786904:41,test,test,41,,https://github.com/google/deepvariant/issues/346#issuecomment-698786904,4,"['TEST', 'test']","['TEST', 'test']"
Testability,"Hi. This is actually happening in the Docker image provided with DeepVariant. (It's been converted to a Singularity image, but it's difficult to imagine that affecting this behavior.). Doing a little testing, the ""%m"" seems to crash Python 2 but not Python 3. Perhaps that's somehow the difference? And this is (I think) coming via TensorFlow, which might also matter. ```; Python 2.7.10 (default, Jul 14 2015, 19:46:27); [GCC 4.8.2] on linux; 'asdf %0.001mean' % (3,); Traceback (most recent call last):; File ""python"", line 1, in <module>; ValueError: unsupported format character 'm' (0x6d) at index 11; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/78#issuecomment-398511601:200,test,testing,200,,https://github.com/google/deepvariant/issues/78#issuecomment-398511601,1,['test'],['testing']
Testability,"Hmm interesting. ; @williamrowell FYI - I tried out your image you shared, and I'm having the same issue as well. @drtamermansour Thanks for testing it out. Let me rebuild with the steps I shared in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 and see if you can try mine as well. I'll follow up soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/178#issuecomment-503758185:141,test,testing,141,,https://github.com/google/deepvariant/issues/178#issuecomment-503758185,1,['test'],['testing']
Testability,"I agree this issue is probably system specific. ; This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR.; Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:; `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/524#issuecomment-1067597987:447,log,login,447,,https://github.com/google/deepvariant/issues/524#issuecomment-1067597987,1,['log'],['login']
Testability,"I also tested running _make_examples_ without _parallel_ (so, without the 4 threads), and the run-time was similar on the same instance (I believe a few hours). However, I am still getting the same error message that the **call_variant** step (with or without the threads / shards). Thank you again for your help! :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/166#issuecomment-478394293:7,test,tested,7,,https://github.com/google/deepvariant/issues/166#issuecomment-478394293,1,['test'],['tested']
Testability,"I am just benchmarking TPU usage on DeepVariant to see if there is a significant speedup as compared to GPU. There were supporting flags in the call_variants step, so I wanted to test with TPU. If TPU is not recommended for inference, then I will switch over to training and try from there, thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1148060981:10,benchmark,benchmarking,10,,https://github.com/google/deepvariant/issues/537#issuecomment-1148060981,2,"['benchmark', 'test']","['benchmarking', 'test']"
Testability,"I am working with singularity on HPC and it is so slow compared with DeepVariant docker image. It took 3 days to reach model.ckpt-4854. Do you have any recommendations to change some parameters (like the batch size, keep_checkpoint_every_n_hours, or save_interval_secs) in order to speed up model_train? ; ; The parameters I am using is here: . `INPUT_DIR=""${PWD}/input""; OUTPUT_DIR=""${PWD}/output""; LOG_DIR=""${OUTPUT_DIR}/logs""; OUTPUT_DIR_TRAINING = ""${OUTPUT_DIR}/training_output""; mkdir -p ""{OUTPUT_DIR_TRAINING}""; WES_PRETRAINED_MODEL = ""${PWD}/models/wes/model.ckpt"". singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ --bind; input:${OUTPUT_DIR}/ \; deepvariant.simg \; /opt/deepvariant/bin//model_train \; --dataset_config_pbtxt = ""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \; --train_dir = ""${OUTPUT_DIR_TRAINING}"" \; --keep_checkpoint_every_n_hours = 0.05 \; --model_name=""inception_v3"" \; --number_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=512 \; --learning_rate=0.01 \; --start_from_checkpoint = ""${WES_PRETRAINED_MODEL}"" >; ""${LOG_DIR}/train.log"" 2>&1 &`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/192#issuecomment-507247544:423,log,logs,423,,https://github.com/google/deepvariant/issues/192#issuecomment-507247544,2,['log'],"['log', 'logs']"
Testability,"I attached two files. One is shuffled validation set, the other one is without shuffled. These data sets are from google quick-start test dataset. Region is chr20:10,005,000-10,008,000. ; [validation_set_with_shuffled.tar.gz](https://github.com/google/deepvariant/files/3082816/validation_set_with_shuffled.tar.gz); [validation_set_without_shuffled.tar.gz](https://github.com/google/deepvariant/files/3082817/validation_set_without_shuffled.tar.gz); @akolesnikov Thanks very much.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/172#issuecomment-483490813:133,test,test,133,,https://github.com/google/deepvariant/issues/172#issuecomment-483490813,1,['test'],['test']
Testability,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:; `; I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default; 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz; 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602; I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes; I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants.; I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default; I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes; I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s; user 220m0.378s; sys 13m54.784s. `. Samples with problems:; `; I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default; 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz; 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573; I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/868#issuecomment-2290172397:188,log,log,188,,https://github.com/google/deepvariant/issues/868#issuecomment-2290172397,1,['log'],['log']
Testability,"I changed the ""num_examples"" form 1 to 2 only,not add any tfrecord.gz file, then it start run, but it is really slow, it have run two hours stilly. So is this situation normal? The tfrecord.gz file is about 2.4M size. ![image](https://user-images.githubusercontent.com/15261087/33869274-d250d54c-df42-11e7-9d37-a6cb401e4cdc.png). Here my config.txt:; ```; name: ""test-training-dataset""; tfrecord_path: ""/leostore/analysis/development/liteng/deepvariant_test/train_set/test_train.tfrecord.gz""; num_examples: 2; ```; This is my command; ```; python /leostore/software/deepvariant/bazel-bin/deepvariant/model_train.zip --dataset_config_pbtxt /leostore/analysis/development/liteng/deepvariant_test/test_train.config.txt --start_from_checkpoint inception_v3.ckpt; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/10#issuecomment-350952138:363,test,test-training-dataset,363,,https://github.com/google/deepvariant/issues/10#issuecomment-350952138,1,['test'],['test-training-dataset']
Testability,I confirmed again that `cd bin; sudo ./run-prereq.sh` exits with `$?` set to 0. Then I did another attempt with `make-examples.zip` and the test data but the result is still the same ImportError.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/41#issuecomment-360832980:140,test,test,140,,https://github.com/google/deepvariant/issues/41#issuecomment-360832980,1,['test'],['test']
Testability,"I get a 8 VCPUs, 52 GB RAM [n1-highmem-8](https://cloud.google.com/compute/docs/machine-types#n1_high-memory_machine_types) machine to test:. ```; gcloud compute instances create ""${USER}-test-speed"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-1804-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-highmem-8"" \; --zone ""us-west2-b"" \; --boot-disk-size 100G \; --min-cpu-platform ""Intel Skylake""; ```. On the machine, I installed Singularity:; ```; curl https://gist.githubusercontent.com/pichuan/7840c8ba80ad31fee9d6f8bea20edb6a/raw/cbf62eb2ea2f141351801db76781d99d04704b4e/install_singularity_3.7.0.sh | \; sed -e s'|github.com/sylabs|github.com/hpcng|' | \; bash -x; ```. Here's the version:; ```; pichuan@pichuan-test-speed:~$ singularity --version; singularity version 3.7.0; ```. I followed:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-exome-case-study.md; to download the data. And then:. ```; mkdir -p output; mkdir -p output/intermediate_results_dir. # Pull the image.; BIN_VERSION=1.1.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref reference/GRCh38_no_alt_analysis_set.fasta \; --reads input/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions input/idt_capture_novogene.grch38.bed \; --output_vcf output/HG003.output.vcf.gz \; --output_gvcf output/HG003.output.g.vcf.gz \; --num_shards $(nproc) \; --intermediate_results_dir output/intermediate_results_dir 2>&1 | tee /tmp/all.log; ```. I'll paste part of the log of each step so that you can compare. ## make_examples; make_examples speed is roughly:; ```; I0622 21:19:25.373434 140610510067456 make_examples.py:648] Task 7/8: 4900 candidates (5187 examples) [27.99s elapsed]; I0622 21:19:35.260825 139809239041792 make_examples.py:648] Task 1/8: 4809 candidate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866352316:135,test,test,135,,https://github.com/google/deepvariant/issues/463#issuecomment-866352316,3,['test'],"['test', 'test-speed']"
Testability,"I get the same error. There appears to be Cuda 12 modules being used even though Cuda 11 is installed? Adding '--env LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/lib/python3.8/dist-packages/nvidia/cublas/lib:/usr/local/lib/python3.8/dist-packages/nvidia/cuda_nvrtc/lib:/usr/local/lib/python3.8/dist-packages/nvidia/cuda_runtime/lib:/usr/local/lib/python3.8/dist-packages/nvidia/cudnn/lib' lets the image see all these libraries and stops the ""Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file"" error. . But now during the call_variants step, I get a new error --> ""2024-03-11 23:23:22.756430: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED; 2024-03-11 23:23:22.756490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Possibly insufficient driver version: 470.57.2"". Just doing '--env LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/lib/python3.8/dist-packages/nvidia/cublas/lib' also seems to get past the ""Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12:"" error, but now I get ""could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error"" during the call_variants step. The 1.6.0-gpu image appears to have some mixed cuda 11 & cuda 12 module library conflict issues. Some of these issues may be suppressed if you have a sufficient nvidia driver for both cuda 11 and cuda 12 (I'm still waiting to test that though).; Note that 1.5.0 has no issues running for me.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/761#issuecomment-1990592785:1564,test,test,1564,,https://github.com/google/deepvariant/issues/761#issuecomment-1990592785,1,['test'],['test']
Testability,"I got a machine to test:. ```; gcloud compute instances create ""${USER}-gpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --maintenance-policy ""TERMINATE"" \; --accelerator=type=nvidia-tesla-p100,count=1 \; --image-family ""centos-7"" \; --image-project ""centos-cloud"" \; --machine-type ""n1-standard-16"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. On the machine, I install nvidia driver first:. ```; sudo yum update -y && sudo yum install -y python3; curl https://raw.githubusercontent.com/GoogleCloudPlatform/compute-gpu-installation/main/linux/install_gpu_driver.py --output install_gpu_driver.py; sudo python3 install_gpu_driver.py; ```. After that, I can confirm that nvidia-smi exists:; ```; [pichuan@pichuan-gpu2 ~]$ nvidia-smi; Thu Mar 16 04:47:54 2023 ; +-----------------------------------------------------------------------------+; | NVIDIA-SMI 525.85.12 Driver Version: 525.85.12 CUDA Version: 12.0 |; |-------------------------------+----------------------+----------------------+; | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |; | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |; | | | MIG M. |; |===============================+======================+======================|; | 0 Tesla P100-PCIE... Off | 00000000:00:04.0 Off | 0 |; | N/A 34C P0 29W / 250W | 0MiB / 16384MiB | 1% Default |; | | | N/A |; +-------------------------------+----------------------+----------------------+; ; +-----------------------------------------------------------------------------+; | Processes: |; | GPU GI CI PID Type Process name GPU Memory |; | ID ID Usage |; |=============================================================================|; | No running processes found |; +-----------------------------------------------------------------------------+; ```. Then I install cuda. This was from: https://developer.nvidia.com/cuda-downloads; ```; curl -O https://developer.download.nvidia.com/compute/cuda",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471348553:19,test,test,19,,https://github.com/google/deepvariant/issues/619#issuecomment-1471348553,1,['test'],['test']
Testability,"I got the following to work (I haven't tested to the end, but successfully reached calling variants). I'm going to keep iterating and seeing how much of these commands I can remove. Opening singularity through a shell; `singularity shell --no-home --cleanenv --containall -B tmp:/tmp,input:/input,output:/output deepvariant_1.1.0.sif`. Changing directory to something I've bound (e.g. ouptut), and then running call_variants; ```; cd ouput; ../opt/deepvariant/bin/call_variants \; --examples ""/output/intermediate_results_dir/make_examples.tfrecord@24.gz"" \; --outfile ""/output/intermediate_results_dir/call_variants_out.tfrecord.gz"" \; --checkpoint ""/opt/models/pacbio/model.ckpt"" \; --use_openvino; ```; At this point, we made progress with the following; ```; Model Optimizer version: 	. [ SUCCESS ] Generated IR version 10 model.; [ SUCCESS ] XML file: /output/./model.xml; [ SUCCESS ] BIN file: /output/./model.bin; [ SUCCESS ] Total execution time: 30.04 seconds. ; [ SUCCESS ] Memory consumed: 699 MB; ```; With persistent model.bin/mapping/xml files in my output folder. I tried unsuccessfully with different binds to be able to write files to the `/` directory in the container, which is where the openvino graph is being written. It may be related to the directory structure on our cluster not meshing well with the container.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-763490283:39,test,tested,39,,https://github.com/google/deepvariant/issues/404#issuecomment-763490283,1,['test'],['tested']
Testability,"I had set the environment variables just didn't include them in the above message. That error was certainly caused by the `**Replace this string with exactly one of the following [WGS,WES,PACBIO]**` string. However, I'm still getting an _unrelated_ error:; ## Set the environment; ```; [moldach@cdr767 bin]$ BIN_VERSION=""0.10.0""; [moldach@cdr767 bin]$ INPUT_DIR=""${PWD}/quickstart-testdata""; [moldach@cdr767 bin]$ OUTPUT_DIR=""${PWD}/quickstart-output""; [moldach@cdr767 bin]$ salloc --time=0:30:0 --mem=8000; [moldach@cdr767 bin]$ singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; > docker://google/deepvariant:""${BIN_VERSION}"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; > --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; > --regions ""chr20:10,000,000-10,010,000"" \; > --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; > --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; > --num_shards=1; WARN[0000] ""/run/user/3019658"" directory set by $XDG_RUNTIME_DIR does not exist. Eithe r create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such fil e or directory: Trying to pull image in the event that it is a public image.; I0327 13:31:58.252949 47794500922048 run_deepvariant.py:241] Re-using the directory fo r intermediate results in /tmp/tmp63xxmwmi. ***** Intermediate results will be written to /tmp/tmp63xxmwmi in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mo de calling --ref ""/scratch/moldach/bin/quickstart-testdata/ucsc.hg19.chr20.unittest.fa sta"" --reads ""/scratch/moldach/bin/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmp63xxmwmi/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmp63xxmwmi/gv cf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Paral",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-605306987:381,test,testdata,381,,https://github.com/google/deepvariant/issues/287#issuecomment-605306987,1,['test'],['testdata']
Testability,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`; 1. what does `--task {}` mean?. Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/99#issuecomment-428692945:472,log,log,472,,https://github.com/google/deepvariant/issues/99#issuecomment-428692945,1,['log'],['log']
Testability,"I have generated those files and added those using the '--ref_fai' and '--ref_gzi' flags respectively and let you know the results. Here is my new configuration:; ```; #!/bin/bash; set -euo pipefail; # Set common settings.; PROJECT_ID=valis-194104; OUTPUT_BUCKET=gs://canis/CNR-data; STAGING_FOLDER_NAME=deep_variant_files; OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf; # Model for calling whole exome sequencing data.; MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard; IMAGE_VERSION=0.7.0; DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}""; COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \; --project ${PROJECT_ID} \; --zones us-west1-b \; --docker_image ${DOCKER_IMAGE} \; --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \; --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \; --model ${MODEL} \; --regions gs://canis/CNR-data/CDS-canonical.bed \; --bam gs://canis/CNR-data/TLE_a_001.bam \; --bai gs://canis/CNR-data/TLE_a_001.bam.bai \; --ref gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz \; --ref_fai gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz.fai \; --ref_gzi gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz.gzi \; --gcsfuse""; # Run the pipeline.; gcloud alpha genomics pipelines run \; --project ""${PROJECT_ID}"" \; --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \; --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \; --zones us-west1-b \; --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \; --command-line ""${COMMAND}""; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437006790:1392,log,logging,1392,,https://github.com/google/deepvariant/issues/116#issuecomment-437006790,2,['log'],"['log', 'logging']"
Testability,"I have no problem in making my .bam file public, but please help me where; to drop / upload it, to make it public, so you can test it. On Thu, Sep 23, 2021 at 4:25 AM Kirti B ***@***.***> wrote:. > I think RAM is not an issue, my machine has 2TB RAM.; >; > Coverage is 46x; >; > On Thu, Sep 23, 2021 at 4:19 AM Pi-Chuan Chang ***@***.***>; > wrote:; >; >> Hmm, empirically we've been able to handle larger input BAM than 20GB; >> with less RAM you had.; >>; >> Another known issue (which we will fix in the next release) is that if; >> auxiliary fields are being read in, and if the BAM has many of them, it; >> could unnecessarily increase the RAM usage. However, in this case given; >> that you're using WGS model (which by default isn't parsing aux fields),; >> that shouldn't be an issue...; >>; >> @kirti141 <https://github.com/kirti141> Another question for you - is; >> there a BAM file that you can make public (with no sensitive information,; >> of course) that we can attempt to reproduce this issue? Thanks again for; >> reporting this.; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/google/deepvariant/issues/482#issuecomment-925383292>,; >> or unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/ANQXTK5JEYIGIH5HDIV742LUDJMPBANCNFSM5DR4DILA>; >> .; >> Triage notifications on the go with GitHub Mobile for iOS; >> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; >> or Android; >> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.; >>; >>; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/482#issuecomment-925387861:126,test,test,126,,https://github.com/google/deepvariant/issues/482#issuecomment-925387861,1,['test'],['test']
Testability,"I ran the above command as such, but the terminal didn't return any errors except `sudo: unable to resolve host smd` where `smd` is the OpenStack instance name. `sudo: unable to resolve host smd` message didn't cause any problems in another OpenStack instance where I have been successful with running deepvariant. . ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""/input/ilAriAges1.fasta.bgz"" \; --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" \; --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" \; --norealign_reads \; --vsc_min_fraction_indels ""0.12"" \; --task 54 --logtostderr; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/315#issuecomment-638428497:793,log,logtostderr,793,,https://github.com/google/deepvariant/issues/315#issuecomment-638428497,1,['log'],['logtostderr']
Testability,"I ran:. ```; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}-gpu"" python -c 'import tensorflow as tf;print(tf.test.is_gpu_available())'; ```; This printed False, which confirmed that this setup was indeed not seeing GPU. :(. Let me test on Ubuntu to get another data point.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471378680:164,test,test,164,,https://github.com/google/deepvariant/issues/619#issuecomment-1471378680,2,['test'],['test']
Testability,"I see. @pgrosu are you saying that if we just grep the output `HG003.output.vcf.gz` file (like I did with the input), we'll see it?; I ended up not having time to test it last night. So I haven't gone through a run to check. @genieusbio if you can confirm that, that will be great! I can also check later. I still need to work on a few other things before I get to this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/708#issuecomment-1719699043:163,test,test,163,,https://github.com/google/deepvariant/issues/708#issuecomment-1719699043,1,['test'],['test']
Testability,I see. Right you mentioned that before.; It could be that the versions are different. Let me see if it's possible for me to get a CentOS7 set up with CUDA version V11.8.89 and then test with that.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471281516:181,test,test,181,,https://github.com/google/deepvariant/issues/619#issuecomment-1471281516,1,['test'],['test']
Testability,"I tested with chr1 of [the WGS script](https://github.com/google/deepvariant/blob/r1.0/scripts/run_wgs_case_study_docker.sh). See below for details.; With `use_openvino=true`, call_variants runs for ~15m on chr1. Without, it takes about ~21m. See commands and machine details below:; ----. # Commands. Tested on the same machine:. All below were done with command like:; ```; scripts/run_wgs_case_study_docker.sh 2>&1 | tee /tmp/openvino.log; ```; with some code diffs below:. 1. Use your Docker image, use_openvino=true; The code diff:; ```; $ git diff; diff --git a/scripts/run_wgs_case_study_docker.sh b/scripts/run_wgs_case_study_docker.sh; index 3dc9712..78712d8 100755; --- a/scripts/run_wgs_case_study_docker.sh; +++ b/scripts/run_wgs_case_study_docker.sh; @@ -65,14 +65,14 @@ aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testda; aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testdata/${REF}.fai"" -d ""${INPUT_DIR}""; ; ## Pull the docker image.; -sudo docker pull google/deepvariant:""${BIN_VERSION}""; +sudo docker pull dkurtaev/deepvariant:latest; ; echo ""Run DeepVariant...""; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; - google/deepvariant:""${BIN_VERSION}"" \; - /opt/deepvariant/bin/run_deepvariant \; + dkurtaev/deepvariant:latest \; + /opt/deepvariant/bin/run_deepvariant --call_variants_extra_args=use_openvino=true --make_examples_extra_args=regions=chr1 \; --model_type=WGS \; --ref=""/input/${REF}.gz"" \; --reads=""/input/${BAM}"" \; @@ -100,6 +100,6 @@ pkrusche/hap.py /opt/hap.py/bin/hap.py \; -f ""${INPUT_DIR}/${TRUTH_BED}"" \; -r ""${UNCOMPRESSED_REF}"" \; -o ""${OUTPUT_DIR}/happy.output"" \; - --engine=vcfeval; + --engine=vcfeval -l chr1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done."". ```. Runtime:; ```; $ grep '^real' /tmp/open; real 7m38.326s; real 15m12.564s; real 7m15.173s; ```. 2. Use your Docker image, use_openvino=false; The code diff:; ```; $ git diff; diff --git a/scripts/run_wg",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735276044:2,test,tested,2,,https://github.com/google/deepvariant/pull/363#issuecomment-735276044,5,"['Test', 'log', 'test']","['Tested', 'log', 'testda', 'testdata', 'tested']"
Testability,"I want to give you an update on the situation. Following your suggestions, I've discussed with the system administrators and I found out that some older nodes on the cluster do not have AVX2 or AVX512 instructions. I've now completed a test running on nodes supporting those and the running time on the same BAM file is ~14h (290+326+134). So I've discussed with them and found a way to allocate all deepvar jobs to the new nodes supporting the AVX instruction. . Thanks for your support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/346#issuecomment-704106130:236,test,test,236,,https://github.com/google/deepvariant/issues/346#issuecomment-704106130,1,['test'],['test']
Testability,I was able to run a test pipeline successfully with BED file you provided (`gs://public-debug/exomes.bed`). Could you please run your pipeline with `gs://public-debug/exomes.bed` (not `gs://canis/CNR-data/exomes.bed`) and see if it succeeds. This is what I got in the log. ```; I1112 17:29:38.624562 140623242430208 genomics_reader.py:213] Reading gs://public-debug/exomes.bed with NativeBedReader; I1112 17:30:18.942625 140623242430208 make_examples.py:1086] Writing examples to /mnt/google/.google/output/nmousavi-test/dv-test/2018-11-10/staging/examples/0/examples_output.tfrecord-00000-of-00008.gz. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437974705:20,test,test,20,,https://github.com/google/deepvariant/issues/116#issuecomment-437974705,4,"['log', 'test']","['log', 'test']"
Testability,"I was suspicious something else might be the issue. So I did a simple test to see if there is an issue with Luisa's BAM file, and noticed that I cannot even create an index - which would naturally make even the prerequisite `make_examples` not complete properly:. ```; paul@gubuntu:~/data/luisa$ wget http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; --2018-03-07 16:20:42-- http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; Resolving dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)... 52.218.52.113; Connecting to dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)|52.218.52.113|:80... connected.; HTTP request sent, awaiting response... 200 OK; Length: 357342653 (341M) [binary/octet-stream]; Saving to: âENCFF528VXT.bamâ. ENCFF528VXT.bam 100%[=========================================================>] 340.79M 1.26MB/s in 5m 17s. 2018-03-07 16:25:59 (1.08 MB/s) - âENCFF528VXT.bamâ saved [357342653/357342653]. paul@gubuntu:~/data/luisa$ samtools index ENCFF528VXT.bam; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [E::bgzf_read] Read block operation failed with error -1 after 143 of 246 bytes; samtools index: failed to create index for ""ENCFF528VXT.bam""; paul@gubuntu:~/data/luisa$; paul@gubuntu:~/data/luisa$; paul@gubuntu:~/data/luisa$ cd ~/deepvariant/bazel-bin; paul@gubuntu:~/deepvariant/bazel-bin$ PYTHONPATH=. /usr/bin/python deepvariant/make_examples --mode calling --ref /home/paul/data/luisa/hg19.fa --reads /home/paul/data/luisa/ENCFF528VXT.bam --examples /home/paul/data/luisa/shardedExamples/examples.tfrecord@2.gz --regions chr20:10,000,000-10,010,000 --task 0; WARNING: Logging before flag parsing goes to stderr.; I0307 16:27:52.052795 140569100494592 client.py:1004] Timeout attempting to reach GCE metadata service.; W0307 16:27:52.112967 140569100494592 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib; [W::bam_hdr_read] EOF marker is absent",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371293506:70,test,test,70,,https://github.com/google/deepvariant/issues/52#issuecomment-371293506,7,['test'],"['test', 'testfiles']"
Testability,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/541#issuecomment-1153777690:164,benchmark,benchmark,164,,https://github.com/google/deepvariant/issues/541#issuecomment-1153777690,1,['benchmark'],['benchmark']
Testability,"I wonder if there is an issue somehow with how you are building with tensorflow-gpu. What commands did you use to build it? We think this should work with tensorflow-gpu==1.4. Here is what I did to try it out:. git clone https://github.com/google/deepvariant.git. #edit settings.sh so that DV_GPU_BUILD=1 and DV_INSTALL_GPU_DRIVERS=1. ./build-prereq.sh; ./build_release_binaries.sh. then ran a test command with the quickstart testdata:. python deepvariant/bazel-bin/deepvariant/make_examples.zip \; --mode calling \; --ref ""${REF}"" \; --reads ""${BAM}"" \; --regions ""chr20:10,000,000-10,010,000"" \; --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". which executes as expected.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/47#issuecomment-363221616:394,test,test,394,,https://github.com/google/deepvariant/issues/47#issuecomment-363221616,2,['test'],"['test', 'testdata']"
Testability,"I' m using Ubuntu Virtual-Machine mount on Windows 11.; Running ""cat ${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta"" it displays the fasta file, but after running:; sudo docker run...., it reports -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. Why?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/675#issuecomment-1631967811:236,test,testdata,236,,https://github.com/google/deepvariant/issues/675#issuecomment-1631967811,1,['test'],['testdata']
Testability,"I'm currently testing on a low-pass WGS bam (~2GB, from blood biopsy) for quicker debugging turnaround time, and am successfully getting 16 shards and cores to run when GCP has the appropriate machine type available, here is output of lscpu:. ```; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 16; On-line CPU(s) list: 0-15; Thread(s) per core: 2; Core(s) per socket: 8; Socket(s): 1; NUMA node(s): 1; Vendor ID: GenuineIntel; CPU family: 6; Model: 63; Model name: Intel(R) Xeon(R) CPU @ 2.30GHz; Stepping: 0; CPU MHz: 2300.000; BogoMIPS: 4600.00; Hypervisor vendor: KVM; Virtualization type: full; L1d cache: 32K; L1i cache: 32K; L2 cache: 256K; L3 cache: 46080K; NUMA node0 CPU(s): 0-15; ```. I then get 16 messages like this:; `; Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']`. Then the candidate site lines begin printing out. . How much memory per shard/core/worker (assuming one worker per shard and core if I'm not mistaken) is recommended?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/150#issuecomment-461090328:14,test,testing,14,,https://github.com/google/deepvariant/issues/150#issuecomment-461090328,1,['test'],['testing']
Testability,"I'm going to try installing CUDA 11.3 on the CentOS7 machine first, to confirm whether that will address the issue. I followed: https://developer.nvidia.com/cuda-11.3.0-download-archive?target_os=Linux. ```; wget https://developer.download.nvidia.com/compute/cuda/11.3.0/local_installers/cuda_11.3.0_465.19.01_linux.run; sudo sh cuda_11.3.0_465.19.01_linux.run; ```. ```; export PATH=/usr/local/cuda-11.3/bin:$PATH; export LD_LIBRARY_PATH=/usr/local/cuda-11.3/lib64:$LD_LIBRARY_PATH; sudo ldconfig; ```. ```; [pichuan@pichuan-gpu2 ~]$ nvcc --version; nvcc: NVIDIA (R) Cuda compiler driver; Copyright (c) 2005-2021 NVIDIA Corporation; Built on Sun_Mar_21_19:15:46_PDT_2021; Cuda compilation tools, release 11.3, V11.3.58; Build cuda_11.3.r11.3/compiler.29745058_0; ```. Now, with this, I tried:. ```; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}-gpu"" python -c 'import tensorflow as tf;print(tf.test.is_gpu_available())'; ```. which still gave me False! Hmm. I'll search the error on the internet to see if I can find something useful",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471410648:951,test,test,951,,https://github.com/google/deepvariant/issues/619#issuecomment-1471410648,1,['test'],['test']
Testability,"I'm seeing an OOM in the logs:; ```; OP_REQUIRES failed at conv_ops.cc:698 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[16384,32,37,110]; ```; It also shows your training params:; ```; Training Examples: 8264746; Batch Size: 16384; Epochs: 1; Steps per epoch: 504; Steps per tune: 1500000; Num train steps: 504; ```. It seems that the `--config.batch_size=512` is not being picked up. It could be related to setting `num_epochs=0`, try changing that to the original 10. If that doesn't work, you could edit the batch_size in `dv_config.py` directly. . Let me know if that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2033253696:25,log,logs,25,,https://github.com/google/deepvariant/issues/802#issuecomment-2033253696,1,['log'],['logs']
Testability,"I've also tried on Ubuntu 18.04 and getting similar problems. Have you tried these test on systems other than 16.04, or should I really try to downgrade to that exact version? Thanks!. `Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-54-generic x86_64)`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/199#issuecomment-514398912:83,test,test,83,,https://github.com/google/deepvariant/issues/199#issuecomment-514398912,1,['test'],['test']
Testability,"I've attached the output from the _call_variants_ step. **I'm not sure how much may have to do with having a total of ~2 weeks AWS experience**, but the current situation may be kind of interesting:. **1)** I believe I started running **postprocess_variants** this morning; **2)** After an 1-2 hours I would have expected to see that error message with the previous runs.; **3)** Using _r4.8xlarge_ EC2 instance launched from the ECS cluster (listed as having have 32 cores and 244 GB of RAM), **postprocess_variants** step is still running. I was admittedly surprised with I had problems with 64 GB of RAM (and initiated this issue). So, **using 244 GB of RAM seems to have gotten around the memory issue (_at least after having been running for ~12 hours_)**, but the run-time seems extraordinarily long (if I correctly understand that this step is supposed to be just file reformatting, for an Exome dataset). I kind of want to see if the job is capable of finishing running (and giving the expected result). However, I think I need to either figure out what is going on or test other options (since I want to test an alternative .bam alignment for that Exome file, as well as testing 2 alignments for my WGS data). In other words, if the job completes and produces a .vcf file, I will close this issue. If not, I will keep looking into things, but I think it may be a little while before I follow-up and get to the point where I would close the issue. [call_variants_output.tfrecord.gz](https://github.com/google/deepvariant/files/3041631/call_variants_output.tfrecord.gz)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-479738587:1077,test,test,1077,,https://github.com/google/deepvariant/issues/167#issuecomment-479738587,3,['test'],"['test', 'testing']"
Testability,I've got 1.1-gpu working so I don't think it's an issue with my CUDA. Testing 1.2 now.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/514#issuecomment-1035492077:70,Test,Testing,70,,https://github.com/google/deepvariant/issues/514#issuecomment-1035492077,1,['Test'],['Testing']
Testability,I've tested your solution - it works on Ubuntu 20.04 but doesn't work on Ubuntu 18.04. Still looking for solution,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/489#issuecomment-942094050:5,test,tested,5,,https://github.com/google/deepvariant/issues/489#issuecomment-942094050,1,['test'],['tested']
Testability,"ID:4 LB:lib1 PL:illumina SM:20 PU:unit1; @PG ID:bwa PN:bwa VN:0.7.10-r789 CL:/usr/local/bin/bwa0.7.10 sampe -P reference_files/male.hg19.fa.gz ENCFF182MTO.sai ENCFF949NMY.sai ENCFF182MTO.fastq.gz ENCFF949NMY.fastq.gz; @PG ID:MarkDuplicates PN:MarkDuplicates VN:1.92() CL:net.sf.picard.sam.MarkDuplicates INPUT=[ENCFF182MTOENCFF949NMY.raw.srt.filt.srt.bam] OUTPUT=ENCFF182MTOENCFF949NMY.raw.srt.dupmark.bam METRICS_FILE=ENCFF182MTOENCFF949NMY.raw.srt.dup.qc REMOVE_DUPLICATES=false ASSUME_SORTED=true VALIDATION_STRINGENCY=LENIENT PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 READ_NAME_REGEX=[a-zA-Z0-9]+:[0-9]:([0-9]+):([0-9]+):([0-9]+).* OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 VERBOSITY=INFO QUIET=false COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false; ```. I uploaded the modified file on this public s3 bucket so you can have a look on it directly from here : ; s3://dv-testfiles/hg19.fa; s3://dv-testfiles/ENCFF528VXT.bam. There you can find the genome I used for running too. Before i created the needed files ( done in the following docker container https://hub.docker.com/r/luisas/samtools/ ) :; ```; samtools index ENCFF528VXT.bam; samtools faidx hg19.fa; bgzip -c -i hg19.fa > hg19.fa.gz; samtools faidx ""hg19.fa.gz""; ```. Then I ran in the docker container you provide :; ```; mkdir shardedExamples. time seq 0 1 | parallel --eta --halt 2 python /opt/deepvariant/bin/make_examples.zip --mode calling --ref hg19.fa --regions chr20:10,000,000-10,010,000 --reads ENCFF528VXT.bam --examples shardedExamples/examples.tfrecord@2.gz --task {}. ```. ```; /opt/deepvariant/bin/call_variants --outfile call_variants_output.tfrecord --examples shardedExamples/examples.tfrecord@2.gz --checkpoint dv2/models/model.ckpt; ```. and here the error output:; ```; WARNING: Logging before flag parsing goes to stderr.; W0307 09:54:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371096675:2175,test,testfiles,2175,,https://github.com/google/deepvariant/issues/52#issuecomment-371096675,1,['test'],['testfiles']
Testability,"If it helps, this is what the model folder looks like:. ```; total 401316; -rw-rw-r-- 1 ec2-user ec2-user 348681272 Dec 11 23:41 model.ckpt.data-00000-of-00001; -rw-rw-r-- 1 ec2-user ec2-user 18473 Dec 11 23:42 model.ckpt.index; -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta; -rw-rw-r-- 1 ec2-user ec2-user 31118992 Dec 11 23:41 model.ckpt.meta.1; ```; (I think there are two meta files because I had to change the HTTPS permissions and re-download the files). and these were the commands to download those files:. ```; MODEL_VERSION=""0.7.2""; MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard""; MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME}"". mkdir -p ${MODEL_NAME}; wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.data-00000-of-00001; wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.index; wget -P ${MODEL_NAME} ${MODEL_HTTP_DIR}/model.ckpt.meta; ```. I also tested deleting those files and re-downloading them (but I got the same error message).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/166#issuecomment-478393809:974,test,tested,974,,https://github.com/google/deepvariant/issues/166#issuecomment-478393809,1,['test'],['tested']
Testability,"If you are okay with sharing the BAM header, it'll help too. If it's easier to share via email, you can email pichuan@google.com. > 2. Any idea of how I do a better job sizing compute resources?. On the GCP DeepVariant tutorial page:; https://cloud.google.com/life-sciences/docs/tutorials/deepvariant; You can see some numbers of runtime and cost estimates on GCP. This might help give you some sense of what type of machine you can choose. Since you're running on AWS, the cost might change based on pricing. > 3. How do I know if docker is making progress or not?. Currently, our one-step script should be outputting some logs as it goes. If make_examples is still running, you should see lines of logs coming out, showing there's progress. There's likely room for improvement on how we show this progress. If you have suggestions or bug reports, please let us know. > I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good!. Sorry to hear that the logs are not coming out promptly. If it's possible, can you tell us where did the log get stuck?. > 4. I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. I haven't tried using nohub. I'll have to try and respond to this later.; > ; > thanks; > ; > Andy; > ; > p.s. I am running in AWS . not sure if that makes a difference or not. I don't expect it to make a difference. But if you do observe any issues, feel free to let us know what kind of AWS instances you're running on, and what's the unexpected behavior, so we can reproduce the issue.; > ; > p.p.s. Is",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/260#issuecomment-573487475:1591,log,log,1591,,https://github.com/google/deepvariant/issues/260#issuecomment-573487475,1,['log'],['log']
Testability,"In the current release, training occurs on chr1-19 using the v3.3.2 benchmark set for HG001, HG005-HG006 using BAM files mapped to GRCh37 (it's important to use GRCh37 when benchmarking with v3.3.2 as there are liftover artifacts on GRCh38 since v3.3.2 was not constructed on this truth set. v4.2 regions are used in training with HG002-HG004 in the current version with GRCh38. With the next version, we plan to fully withhold HG003 from training for all data types. chr20 is never used for training or model selection or anything that would influence model performance. It is a fully held-out test set. chr21 and chr22 are not used for training, but the performance on chr21 and chr22 are used in a tune set that identifies at what checkpoint to select the model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/381#issuecomment-728683346:68,benchmark,benchmark,68,,https://github.com/google/deepvariant/issues/381#issuecomment-728683346,3,"['benchmark', 'test']","['benchmark', 'benchmarking', 'test']"
Testability,"Including my `$BIN_VERSION` `INPUT_DIR` and `OUTPUT_DIR` in a run script fixed this and I was able to run the test data on a t2.medium. Thanks! . ```; BIN_VERSION=""1.1.0""; INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". time sudo docker run \; 	-v ""${INPUT_DIR}"":""/input"" \; 	-v ""${OUTPUT_DIR}"":""/output"" \; 	google/deepvariant:""${BIN_VERSION}"" \; 	/opt/deepvariant/bin/run_deepvariant \; 	--model_type=WGS \; 	--ref=/input/ucsc.hg19.chr20.unittest.fasta \; 	--reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; 	--regions ""chr20:10,000,000-10,010,000"" \; 	--output_vcf=/output/output.vcf.gz \; 	--output_gvcf=/output/output.g.vcf.gz \; 	--intermediate_results_dir /output/intermediate_results_dir \; 	--num_shards=1; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/462#issuecomment-867736803:110,test,test,110,,https://github.com/google/deepvariant/issues/462#issuecomment-867736803,2,['test'],"['test', 'testdata']"
Testability,"Indeed the file was truncated, sorry about that. I am still testing locally; with other even smaller files ( like : wget; http://dv-testfiles.s3.amazonaws.com/wgEncodeUwRepliSeqGm12878G1bAlnRep1.bam; which is public and smaller and not truncated ) and I get the same exact; error again. 2018-03-07 22:36 GMT+01:00 Paul Grosu <notifications@github.com>:. > I was suspicious something else might be the issue. So I did a simple test; > to see if there is an issue with Luisa's BAM file, and noticed that I; > cannot even create an index - which would naturally make even the; > prerequisite make_examples not complete properly:; >; > paul@gubuntu:~/data/luisa$ wget http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > --2018-03-07 <http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam--2018-03-07> 16:20:42-- http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > Resolving dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)... 52.218.52.113; > Connecting to dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)|52.218.52.113|:80... connected.; > HTTP request sent, awaiting response... 200 OK; > Length: 357342653 (341M) [binary/octet-stream]; > Saving to: âENCFF528VXT.bamâ; >; > ENCFF528VXT.bam 100%[=========================================================>] 340.79M 1.26MB/s in 5m 17s; >; > 2018-03-07 16:25:59 (1.08 MB/s) - âENCFF528VXT.bamâ saved [357342653/357342653]; >; > paul@gubuntu:~/data/luisa$ samtools index ENCFF528VXT.bam; > [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; > [E::bgzf_read] Read block operation failed with error -1 after 143 of 246 bytes; > samtools index: failed to create index for ""ENCFF528VXT.bam""; > paul@gubuntu:~/data/luisa$; > paul@gubuntu:~/data/luisa$; > paul@gubuntu:~/data/luisa$ cd ~/deepvariant/bazel-bin; > paul@gubuntu:~/deepvariant/bazel-bin$ PYTHONPATH=. /usr/bin/python deepvariant/make_examples --mode calling --ref /home/paul/data/luisa/hg19.fa --reads /home/paul/data/luisa/ENCFF528VXT.bam --exam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371306075:60,test,testing,60,,https://github.com/google/deepvariant/issues/52#issuecomment-371306075,9,['test'],"['test', 'testfiles', 'testing']"
Testability,"It depends on what you want. In the simplest case, people take the genome (fasta) + callset (vcf) as a representation of this individual's genome sequence. This is a bit simplistic, though, as it doesn't differentiate between regions where we are confidently the sample is the same as the reference vs. those where we are uncertain. That information is captured in the ""genome VCF"" or ""gVCF"" which DeepVariant can generate (see `--gvcf` in `make_examples`) but currently isn't so usable as the records come out in TFRecord of Variant proto format. We are working on adding support for creating a normally-formatted gVCF by extending postprocess_variants to merge those gVCF records and the callset together, which we hope to release soon. But in the meantime the best representation you can get from DeepVariant (without coding up merging logic for the gVCF yourself, which you are more than welcome to do) is VCF + genome. . I can't comment on the suitability of FastaAlternateReferenceMaker for your specific needs (despite being the original author of that tool) as I don't believe it was widely used or whether it is maintained now. I would post to biostars or other equivalent forum to ask for recommendations on what people typically do to combine a genome FASTA + VCF to make a diploid (or haploid) reference genome sequence. There are many options (e.g., FASTG, particularly important if you have diploid organisms) but I don't know what's widely used in the community. Hope that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/13#issuecomment-351172185:839,log,logic,839,,https://github.com/google/deepvariant/issues/13#issuecomment-351172185,1,['log'],['logic']
Testability,"It has nothing to do with docker image. The problem is with input file (with err `Unrecognized SAM header type`). Pasting make_example worker log:. ```; Unrecognized SAM header type, ignoring:; I1108 21:36:46.455516 140363989006080 genomics_reader.py:213] Reading /input-gcsfused-2/CNR-data/TLE_a_001.bam with NativeSamReader; Traceback (most recent call last):; File ""/mnt/google/.google/tmp/Bazel.runfiles_pV6vDu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run; _sys.exit(main(argv)); File ""/mnt/google/.google/tmp/Bazel.runfiles_pV6vDu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main; make_examples_runner(options); File ""/mnt/google/.google/tmp/Bazel.runfiles_pV6vDu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner; regions = processing_regions_from_options(options); File ""/mnt/google/.google/tmp/Bazel.runfiles_pV6vDu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options; options.min_shared_contigs_basepairs); File ""/mnt/google/.google/tmp/Bazel.runfiles_pV6vDu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs; min_coverage_fraction); File ""/mnt/google/.google/tmp/Bazel.runfiles_pV6vDu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage; ref_bp, common_bp, coverage, format_contig_matches())); ValueError: Reference contigs span 3088269832 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""chr1"" is 248956422 bp and IS MISSING, ""chr2"" is 242193529 bp and IS MISSING, ""chr3"" is 198295559 bp and IS MISSING, ""chr4"" is 190214555 bp and IS MISSING, ""chr5"" is 181538259 bp a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437191865:142,log,log,142,,https://github.com/google/deepvariant/issues/116#issuecomment-437191865,1,['log'],['log']
Testability,"It is at the beginning of the log. I copied it from your first post. `; Running evaluations on DeepVariantInput(name=HG001, input_file_spec=/data/output/training_data/customized_training/validation_set_with_label_shuffled/validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz, num_examples=8, mode=eval with model DeepVariantModel(name=inception_v3); I0415 07:34:19.585236 140713377441536 model_eval.py:198] Dataset has 8 samples, doing eval over 0; max_examples is 1000000, num_batches is 0; `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/172#issuecomment-484975077:30,log,log,30,,https://github.com/google/deepvariant/issues/172#issuecomment-484975077,1,['log'],['log']
Testability,"It is not a requirement to use Google Cloud or its SDK. You should be able to still use DeepVariant without having to install anything related to Google Cloud.; One issue here is that we put our data (including pre-built binaries) on Google Cloud storage. So you might not have access to them. You can try the browser version to see if you can view or download the data: https://console.cloud.google.com/storage/browser/deepvariant. But even if that doesn't work, you should still be able to build the binary from scratch:; https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. The example input data (such as FASTA, BAM files) can be found on their original sites. For example, in the Case Study we listed where we got the files: https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-case-study.md#test-data",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/17#issuecomment-352085708:595,test,test,595,,https://github.com/google/deepvariant/issues/17#issuecomment-352085708,2,['test'],"['test', 'test-data']"
Testability,"It looks like examples were created for all the samples but call_variants did not run for the child. ; Could you please check the sizes of all files with extension ```tfrecord``` for all samples? To make sure that parents' files are not empty.; Is there a chance you could share your BAM files or may be just a chr20? It would be easier to investigate the issue if we could reproduce it locally.; Also, could you try to run the test on Ubuntu OS?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/431#issuecomment-804422288:428,test,test,428,,https://github.com/google/deepvariant/issues/431#issuecomment-804422288,1,['test'],['test']
Testability,"It might work on your test data, but not working on all my samples...I; tried on many samples. Will think of any solution for sharing my .bam file. On Thu, Sep 23, 2021 at 6:06 AM Pi-Chuan Chang ***@***.***>; wrote:. > @kirti141 <https://github.com/kirti141> hm, this question (data sharing); > turns out to be more complicated than I thought. I'll have to think about; > what's a best way for this.; >; > For now, I can try to run DV 1.2 on this large BAM file:; >; > $ gsutil ls -lh gs://deepvariant/case-study-testdata/HG002_NIST_150bp_50x.bam; > 110.3 GiB 2019-02-26T18:04:41Z gs://deepvariant/case-study-testdata/HG002_NIST_150bp_50x.bam; >; > on a 64 cores CentOS machine, to see if I can reproduce the issue.; >; > I'll report back after I have a chance to run it.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/482#issuecomment-925428637>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ANQXTK3FDM6LAWCEQH7A2MTUDJZCNANCNFSM5DR4DILA>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.; >; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/482#issuecomment-925432605:22,test,test,22,,https://github.com/google/deepvariant/issues/482#issuecomment-925432605,3,['test'],"['test', 'testdata']"
Testability,"Just to ""update"" this one more time (haven't seen any commits referencing this issue):. The problem seems a bit more pervasive than initially thought. I have now completed two benchmarking runs (NA12878) with hap.py - one using Deepvariant (1.1), and one with Strelka (2.9), input BAM file being the same for both:. Strelka - SNP Recall: 0.995 SNP Precision: 0.997 - FN: 88 FP: 56; Deepvariant - SNP Recall: 0.951 SNP Precision: 0.953 - FN: 936 FP: 904. I checked a bunch of these FN/FP calls and found that they are mostly the above described incorrect heterozygous calls. The read length for this data set is 100bp, which is shorter than our own in-house produced data (150bp) where we do not see this issue. Maybe that explains it (more uniq mappings). . Anyway, hopefully this can be fixed soonish.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/470#issuecomment-891869362:176,benchmark,benchmarking,176,,https://github.com/google/deepvariant/issues/470#issuecomment-891869362,1,['benchmark'],['benchmarking']
Testability,"K-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```; Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele; ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/680#issuecomment-1640133876:1783,assert,assertion,1783,,https://github.com/google/deepvariant/issues/680#issuecomment-1640133876,1,['assert'],['assertion']
Testability,"Looking at @amy-houseman 's latest IGV in https://github.com/google/deepvariant/issues/691#issuecomment-1669163372 , it seems like the realigned BAM would see 1 read containing the alt allele C. If this is the case, I don't expect it to even trigger our candidate generation logic. (From this post, it didn't seem like @amy-houseman has specified different vsc_ thresholds). One possibility is that the realignment BAM was generated with different region compared with when the variant calling was run, like @pgrosu mentioned above.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/691#issuecomment-1670038776:275,log,logic,275,,https://github.com/google/deepvariant/issues/691#issuecomment-1670038776,1,['log'],['logic']
Testability,"Looks like the problem is in make_examples. In order to debug the problem we need make_examples logs. You can run the command below. Flag ""logtostderr"" redirect logs to the console. You need to run it inside docker the same way as you ran your original command.; ``` ; /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task 54 --logtostderr; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/315#issuecomment-638394420:96,log,logs,96,,https://github.com/google/deepvariant/issues/315#issuecomment-638394420,4,['log'],"['logs', 'logtostderr']"
Testability,"Looks like this is the GLnexus question. Could you please post the question at GLNexus [page ](https://github.com/dnanexus-rnd/GLnexus); Also, from the log output it looks like GLnexus was completed successfully.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/815#issuecomment-2096502613:152,log,log,152,,https://github.com/google/deepvariant/issues/815#issuecomment-2096502613,1,['log'],['log']
Testability,"Machine has 64 cores, 2TB RAM, Centos is OS. Deep variant docker code works well when input bam file size is less than; 20 Gb file size, but when I increase the file size / coverage, I get the; error. On Wed, Sep 22, 2021 at 9:08 PM Pi-Chuan Chang ***@***.***>; wrote:. > @kirti141 <https://github.com/kirti141> from the log, I agree that it; > isn't quite clear.; > Can you tell us about your machine? How many CPU cores, RAM, what OS, etc.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/482#issuecomment-925047566>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ANQXTKYZH6MM2EGS7CBSZPTUDHZ7FANCNFSM5DR4DILA>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.; >; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/482#issuecomment-925379521:321,log,log,321,,https://github.com/google/deepvariant/issues/482#issuecomment-925379521,1,['log'],['log']
Testability,"Most likely what happens is that your BAM file (or truth file) has contig names that do not match contig names of the reference. Could you list all the arguments you used for running make_examples? Also, could you print the header of 'project-retraining/testdata/aligned_reads.bam'?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-445914153:254,test,testdata,254,,https://github.com/google/deepvariant/issues/128#issuecomment-445914153,1,['test'],['testdata']
Testability,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/522#issuecomment-1059260579:365,log,login,365,,https://github.com/google/deepvariant/issues/522#issuecomment-1059260579,1,['log'],['login']
Testability,My apologies. Thank you for the comment. I have not yet tested but it's looking like what I was after. I very much appreciate it.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/731#issuecomment-1834714799:56,test,tested,56,,https://github.com/google/deepvariant/issues/731#issuecomment-1834714799,1,['test'],['tested']
Testability,"N=1.21.0 OS=linux ARCH=amd64 && \; wget https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz && \; sudo tar -C /usr/local -xzvf go$VERSION.$OS-$ARCH.tar.gz && \; rm go$VERSION.$OS-$ARCH.tar.gz; ```. ```bash; echo 'export PATH=/usr/local/go/bin:$PATH' >> ~/.bashrc && \; source ~/.bashrc; ```. ```bash; export VERSION=4.1.0 && \; wget https://github.com/sylabs/singularity/releases/download/v${VERSION}/singularity-ce-${VERSION}.tar.gz && \; tar -xzf singularity-ce-${VERSION}.tar.gz && \; cd singularity-ce-${VERSION}; ```. ```bash; ./mconfig && \; make -C builddir && \; sudo make -C builddir install; ```. At this point, I have singularity installed. ```bash; $ singularity --version; singularity-ce version 4.1.0; ```. ## Get data and run DeepVariant. Now, let me try to follow similar steps:. ```bash; singularity build DeepVariant_1.6.1.sif docker://google/deepvariant:1.6.1; ```. From here, I used https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-pacbio-model-case-study.md to test. Download data:. ```bash; mkdir -p reference. FTPDIR=ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids. curl ${FTPDIR}/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | gunzip > reference/GRCh38_no_alt_analysis_set.fasta; curl ${FTPDIR}/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.fai > reference/GRCh38_no_alt_analysis_set.fasta.fai; ```. ```bash; mkdir -p input; HTTPDIR=https://downloads.pacbcloud.com/public/dataset/HG003/deepvariant-case-study. curl ${HTTPDIR}/HG003.GRCh38.chr20.pFDA_truthv2.bam > input/HG003.GRCh38.chr20.pFDA_truthv2.bam; curl ${HTTPDIR}/HG003.GRCh38.chr20.pFDA_truthv2.bam.bai > input/HG003.GRCh38.chr20.pFDA_truthv2.bam.bai; ```. ```bash; ulimit -u 10000; BIN_VERSION=""1.6.1""; mkdir -p deepvariant_output; ```. @Carl-labhub mentioned ""When I run it, I’m doing so from an interactive session with singularity exec"". I'm a bit confused by this. Maybe you mean `singularity shell`? So I tried:. ``",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/812#issuecomment-2076206716:3112,test,test,3112,,https://github.com/google/deepvariant/issues/812#issuecomment-2076206716,1,['test'],['test']
Testability,"NOTE: I've checked the `alignments20_sorted.bam` file to see if the QUAL field is still set to * as @pgrosu pointed out here:. > As these are sorted reads, by just looking at the BAM file, it starts with position 60001, as shown here - which why you are getting 0 candidates:; > ; > ```; > 55ad4f97_28026_0 0 chr20 60001 50 618S27M1D8M1I6M1D7M1D5M1I9M1I5M1D20M1D8M1I24M1I35M1I9M1I2M1I1M1I52M1D3M1D15M2D4M2D12M1I21M1I5M1; > D11M1D7M1I18M1I15M1D1M1D43M1I16M1D8M1I21M1D2M1D7M1I10M1I2M1D8M1D5M1D3M1D2M1I13M1D28M1I20M1I4M1I37M1I19M1I21M1D18M1I5M1D16M1I1M1I3M1I29M1I12M1D6M1I2M1I7; > M1D1M1D2M1I4M1D22M1D18M1I4M1D12M1D4M1I1M1I3M2I17M1I1M1I44M1D3M1D2M1D10M1I11M2D1M1D9M1I19M1D2M1I32M1D2M1D8M1D20M1I14M1D6M1D15M1I7M1D3M1D25M1I6M1I8M1D11M; > 1I7M1I11M1I12M1D2M1D3M1I70M1I23M1D3M1I48M1I21M1I46M1D14M1I3M1D10M1I6M1D34M2I8M1I11M1I5M1I10M1D8M1I8M1I14M1D19M1I26M1I6M1I13M1D4M1I2M1I33M1I8M1I7M1I12M1I1M1I4M1I8M1I3M1I1M1I3M2I4M1I14M1I1M1I5M1I1M1I1M1I2M2I2M1I3M1I1M4I3M1I1M1I1M2I3M4I5M1I3M1I1M1I3M3I5M1I6M1I2M1I1M2I1M1I7M1I3M2I3M1I5M2I1M2I4M1I1M1I2M1D4M1I6M1I3M1I2M1I1M4I1M1I1M2I5M1I3M1I3M1I2M1D1M1I2M2I1M1I1M1I4M3I1M2I2M1I6M1I4M3I1M3I1M3I8M2I47M1I11M1I8M1D3M1I1M1I30M1I15M1I6M1I17M1D18M1D4M1I19M1I28M1D37M1I23M1D7M1D21M1D79M1I12M1D1M1D9M1I21M1D44M1D30M1D3M1I13M1I9M1I34M1D10M1I; > ```; > Since no PHRED value is stored with a `*`, as shown here:; > ; > ```; > AGTCTGCTTCATGCCTTTAACT * AS:i:-15583 ; > ```; > This is why the read triggers the assertion failure [here](https://github.com/google/deepvariant/blob/master/deepvariant/allelecounter.cc#L103):; > ; > ```c++; > CHECK_LE(offset + len, read.aligned_quality_size());; > ```; > ; > The preferred response that would be nice, is if the code could just identify which read (QNAME) it is referring to in order to verify this, or just have a flag to ignore reads that one has no QUAL score for.; > ; > Hope it helps,; > ~p. Viewing the file with samtools (and quickly killing the command) showed me that it is indeed still set to *, as you can see below:; ```; user@",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-458488164:1426,assert,assertion,1426,,https://github.com/google/deepvariant/issues/138#issuecomment-458488164,1,['assert'],['assertion']
Testability,"NP, please share workers log so we can help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/118#issuecomment-437467869:25,log,log,25,,https://github.com/google/deepvariant/issues/118#issuecomment-437467869,1,['log'],['log']
Testability,"NPATH --test_env=PYTHONPATH=$PYTHONPATH; echo 'Expect a usage message:'; (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; ```. ## Fix DV Error. ```bash; ################################################################################; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test; # use lscpu to show the actual CPU number; ################################################################################; python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160; python -c ""import psutil;print(p/sutil.cpu_count; ())"" #160. vim deepvariant/resources.py; --------------------------------; def _get_cpu_count():; """"""Gets the number of physical cores in this machine.; Returns:; int >= 1 if the call to get the cpu_count succeeded, or 0 if not.; """"""; # return psutil.cpu_count(logical=False) or 0 ==> comment; return 20; --------------------------------. vim deepvariant/resources_test.py; --------------------------------; def test_metrics_is_ok_when_cpu_count_returns_none(self):; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):; with resources.ResourceMonitor() as monitor:; #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment; self.assertEqual(monitor.metrics().physical_core_count, 20); --------------------------------. ##########################################################################; # //deepvariant/realigner/allele_count_linear:generate_trained_model_test; # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8; ##########################################################################; # reinstall numpy, scipy, Cpython, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:20533,log,logical,20533,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,1,['log'],['logical']
Testability,"No YAML file is needed for running DeepVariant as we migrated to using Genomics Pipeline API v2 since DeepVariant v0.7 . Please see DeepVariant's cloud page for sample scripts. https://cloud.google.com/genomics/docs/tutorials/deepvariant. Note that we keep the cloud page updated with every release, and it is the place to look into in case of major changes to DeepVariant runner. For debugging, we found workers log more helpful in general. In your case, they are under `gs://gbsc-gcp-project-udn-dev-deep-variant/UDN668131_test/deepvariant_staging_folder/logs`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/118#issuecomment-437114999:413,log,log,413,,https://github.com/google/deepvariant/issues/118#issuecomment-437114999,2,['log'],"['log', 'logs']"
Testability,"No problem. I will still want to make sure there isn't a problem on AWS though. Our team develop DeepVariant to run everywhere (with a compatible OS). We mostly test on Ubuntu 16.04 so far because we haven't had much resource to test much more broadly. But a Ubuntu either on GCP or AWS shouldn't be an issue. And if it is, I think our team needs to know why.; Once I have a chance to test and confirm, I'll report back here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480324512:161,test,test,161,,https://github.com/google/deepvariant/issues/167#issuecomment-480324512,3,['test'],['test']
Testability,"Not at this time. Are there specific dependencies in Ubuntu 20.04 that are required? Or an older version of DV that has been tested on 18.04?. Would also like some clarification on this statement to help me figure out what is going on, . `Build clif binary from scratch. Might not be ideal because it installs a bunch of dependencies, but this works fine when we used this in a Dockerfile because we don't do build-prereq.sh in the final image.`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/476#issuecomment-896286964:125,test,tested,125,,https://github.com/google/deepvariant/issues/476#issuecomment-896286964,1,['test'],['tested']
Testability,"OK – that proceeded further, I think. Now the error is; ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes: [64,27,1,3]. I hate to keep bothering people about this. Is there documentation on all of this that I can refer to?. Thanks,; Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]; Sent: Tuesday, April 10, 2018 1:04 PM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. I think you'll want:; tfrecord_path: ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380193942>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth D",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-380197853:143,Log,Logits,143,,https://github.com/google/deepvariant/issues/62#issuecomment-380197853,1,['Log'],['Logits']
Testability,"OK. I noticed that my `pyclif_proto` is in /usr/local/bin/, not /usr/local/clif/bin. Not knowing if that really is an issue, I did the following:; ```; sudo ln -sf /usr/local/bin/pyclif_proto /usr/local/clif/bin/pyclif_proto; ```. And added that to my [experimental build-prereq.sh](https://gist.github.com/pichuan/7928d101a730c03167b6d80c9c3c58ac). Now I'm seeing a different error:; ```; (06:15:00) INFO: Found 80 targets and 33 test targets...; (06:15:00) ERROR: /home/pichuan/.cache/bazel/_bazel_pichuan/01047f0bd74be1f8c2eae71c8557726c/external/nsync/BUILD:441:1: C++ compilation of rule '@nsync//:nsync_cpp' failed (Exit 1): gcc failed: error executing command; (cd /home/pichuan/.cache/bazel/_bazel_pichuan/01047f0bd74be1f8c2eae71c8557726c/execroot/com_google_deepvariant && \; exec env - \; PATH=/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/pichuan/bin \; PWD=/proc/self/cwd \; PYTHON_BIN_PATH=/usr/local/bin/python2.7 \; PYTHON_LIB_PATH=/usr/local/lib/python2.7/site-packages \; TF_NEED_CUDA=0 \; TF_NEED_OPENCL_SYCL=0 \; /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 -MD -MF bazel-out/k8-opt/bin/external/nsync/_objs/nsync_cpp/external/nsync/internal/common.pic.d -fPIC -iquote external/nsync -iquote bazel-out/k8-opt/genfiles/external/nsync -iquote external/bazel_tools -iquote bazel-out/k8-opt/genfiles/external/bazel_tools -isystem external/nsync/public -isystem bazel-out/k8-opt/genfiles/external/nsync/public -isystem external/bazel_tools/tools/cpp/gcc3 -x c++ '-std=c++11' -DNSYNC_ATOMIC_CPP11 -DNSYNC_USE_CPP11_TIMEPOINT -I./external/nsync//platform/c++11 -I./external/nsync//platform/gcc -I./external/nsync//platform/x86_64 -I./external/nsync//public -I./external/nsy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386513685:431,test,test,431,,https://github.com/google/deepvariant/issues/29#issuecomment-386513685,1,['test'],['test']
Testability,"Oh I thought I was using a consistent model and codebase — thanks for the links. *Edit*: I was using the correct model, it was simply that it was not localized in the correct folder apparently. > On Feb 6, 2019, at 11:57 PM, Nima Mousavi <notifications@github.com> wrote:; > ; > Can you verify TF examples (test.gvcf.tfrecord-*) are in ${BASE} path?; > ; > If you use DeepVariant's cloud runner, you won't need to do all these steps manually. It takes care of everything and runs the pipeline on GCP. See instruction here:; > ; > https://cloud.google.com/genomics/docs/tutorials/deepvariant; > ; > Is there any reason why you don't use cloud runner?; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461399048:307,test,test,307,,https://github.com/google/deepvariant/issues/151#issuecomment-461399048,1,['test'],['test']
Testability,"Oh, sorry I couldn't see that you already had one `--regions` in there.; I believe this one below (taken from your attached logs) should have worked, and it works for me locally, so I'll leave this here and ask my colleagues to weigh in.; ```; ***** Running the command:*****; time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/Homo_sapiens_assembly19.fasta"" --reads ""/input/proper.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""3:178936057-178936106 3:178952054-178952106"" --vsc_min_fraction_snps ""0.004"" --task {}. E0416 22:39:09.366390 140299630700288 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_WCb7xE/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"".; ``",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/305#issuecomment-620732836:124,log,logs,124,,https://github.com/google/deepvariant/issues/305#issuecomment-620732836,1,['log'],['logs']
Testability,"Okay, I will try this with my exomes.bed file. I was already able to successfully run the pipeline with the following params; ```; --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \; --bam gs://canis/CNR-data/TLE_a_001.reheader.bam \; --bai gs://canis/CNR-data/TLE_a_001.reheader.bam.bai \; --ref gs://deepvariant/performance-testdata/hs37d5.fa.gz \; ```. It is odd that the bed file needs to lie in a public bucket, while the genomic data does not.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-438034821:175,test,testdata,175,,https://github.com/google/deepvariant/issues/116#issuecomment-438034821,2,['test'],['testdata']
Testability,"Oo likely my fault! If I am adding the particular region around that variant such as ""chr15:41,132,484-42,007,831"". Do I still have to provide a WES bed file? I have this as my current script and last time it seemed like the bed file was the problem.. ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p htc; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-2; #SBATCH --mem-per-cpu=68GB; #SBATCH --qos=maxjobs500. module purge; module load parallel; module load singularity. EXOME_IDs_FILE=/scratch/c.c21087028/checking_variant_deepvariant/exome_ID_file; HG38_REFERENCE=/scratch/c.c21087028/coverage_graph_and_clincnv_files/ClinCNV/hg38/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna; PICARDMARKDUPLICATES_SORTEDBAM=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_markedduplicates_GCA_000001405.15_GRCh38_no_alt_analysis_set.bam; REGIONS=""chr15:41,132,484-42,007,831""; OUTPUT_VCF=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set_checkingvariantregion.vcf.gz; OUTPUT_GVCF=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_GCA_000001405.15_GRCh38_no_alt_analysis_set_checkvariantregion.g.vcf.gz; INTERMEDIATE_RESULTS=/scratch/c.c21087028/checking_variant_deepvariant/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$REGIONS \; --make_examples_extra_args=""emit_realigned_reads=true,realigner_diagnostics=/output/realig",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/691#issuecomment-1667692113:271,log,login,271,,https://github.com/google/deepvariant/issues/691#issuecomment-1667692113,1,['log'],['login']
Testability,Our build and test was tested on Ubuntu 16.4. I can do a quick test run on Ubuntu 14.4.; Can you remind us what version of `bazel` you're using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/199#issuecomment-514360900:14,test,test,14,,https://github.com/google/deepvariant/issues/199#issuecomment-514360900,3,['test'],"['test', 'tested']"
Testability,Our experience is the model works well across a variety of species. But we have not tested it on bacteria or other haploid organisms so we'd love to hear about any results you get there.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/3#issuecomment-350808977:84,test,tested,84,,https://github.com/google/deepvariant/issues/3#issuecomment-350808977,1,['test'],['tested']
Testability,"PATH=gs://deepvariant/packages/tensorflow; ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow; ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow; ++ export DV_INSTALL_GPU_DRIVERS=0; ++ DV_INSTALL_GPU_DRIVERS=0; +++ which python; ++ export PYTHON_BIN_PATH=/usr/bin/python; ++ PYTHON_BIN_PATH=/usr/bin/python; ++ export USE_DEFAULT_PYTHON_LIB_PATH=1; ++ USE_DEFAULT_PYTHON_LIB_PATH=1; ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'; ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'; + bazel; [bazel release 0.15.0]; Usage: bazel <command> <options> ... Available commands:; analyze-profile Analyzes build profile data.; build Builds the specified targets.; canonicalize-flags Canonicalizes a list of bazel options.; clean Removes output files and optionally stops the server.; coverage Generates code coverage report for specified test targets.; cquery Loads, analyzes, and queries the specified targets w/ configurations.; dump Dumps the internal state of the bazel server process.; fetch Fetches external repositories that are prerequisites to the targets.; help Prints help for commands, or the index.; info Displays runtime info about the bazel server.; license Prints the license of this software.; mobile-install Installs targets to mobile devices.; print_action Prints the command line args for compiling a file.; query Executes a dependency graph query.; run Runs the specified target.; shutdown Stops the bazel server.; test Builds and runs the specified test targets.; version Prints version information for bazel. Getting more help:; bazel help <command>; Prints help and options for <command>.; bazel help startup_options; Options for the JVM hosting bazel.; bazel help target-syntax; Explains the syntax for specifying targets.; bazel help info-keys; Displays a list of keys used by the info comma",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:9775,test,test,9775,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['test'],['test']
Testability,"Peter;; Thanks for testing, it sounds like there is a problem with the recent google-cloud-sdk packages. I'll take a look to see if I can figure out what is going wrong but an immediate thing you could try is to restrict that dependency version to try and avoid the issue:; ```; conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'; ```; Hope this helps get it installed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/177#issuecomment-486163437:19,test,testing,19,,https://github.com/google/deepvariant/issues/177#issuecomment-486163437,1,['test'],['testing']
Testability,"Phil and Pi-Chuan;; That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:; ```; dv_make_examples.py; --ref chr20.fa.gz \; --reads test.bam \; --examples shardedExamples/examples.tfrecord@2.gz \; --regions regions.bed \; --sample test \; --logdir location/to/place/logfiles; --cores 1; ```; Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/101#issuecomment-430171385:536,test,test,536,,https://github.com/google/deepvariant/issues/101#issuecomment-430171385,4,"['log', 'test']","['logdir', 'logfiles', 'test']"
Testability,"Pi-Chuan -- thanks for this. We'd ideally build with CLIF directly in bioconda to avoid you needing to have these custom builds, but will hold off on that until there is an easier to build/install CLIF dependency. Happy to test the new version with reduced glibc requirements when it's ready. Björn -- We do pin to 1.14 now in DeepVariant, with the downside that it's not compatible in a shared environment with other looks that pin to the bioconda 1.12 default. I can work around this for now by having DeepVariant in a separate environment, but would love to synchronize bioconda to 1.14 at some point. Thanks again for all this work and help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-385485505:223,test,test,223,,https://github.com/google/deepvariant/issues/29#issuecomment-385485505,1,['test'],['test']
Testability,"Pi-Chuan and Mike;; Thanks for all this background and help. I'm trying to fit this into the conda recipe bazel build for DeepVariant but am not sure how to take advantage of using the local anaconda python in that context. The error I'm seeing is that bazel can't find pyclif_proto:; ```; (17:56:01) INFO: Found 1 target...; (17:56:01) [0 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt; (17:56:01) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'; (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1: //third_party/nucleus/protos:variants_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'; Target //deepvariant:binaries failed to build; (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1 1 input file(s) do not exist; ```; which I thought was triggered by the difficulty running pyclif without having the local python installed. It could also be due to not installing is in `/usr/local/bin` since I have to remain sandboxed in the work directory, but I did adjust the PATH to include the download location. Sorry I'm stuck here due to me limited knowledge of bazel tweaking. Either understanding how to handle a root install of the pre-build pyclif or tweaking to use the local python would be helpful. Alternatively, if you can already build DeepVariant on a CentOS6 system yourself I could use the pre-build binaries the way we're doing now, just with the build against an older glibc. Thanks again for the help with this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386250002:1105,sandbox,sandboxed,1105,,https://github.com/google/deepvariant/issues/29#issuecomment-386250002,1,['sandbox'],['sandboxed']
Testability,"Pichuan, to increase the ease use and expand adoption within the Bioinformatics community it might not hurt to have a collection of customized build-and-test environments at Google that match a variety of environment configurations that users have in place, or that common packages recommend out here. Sometimes folks will be curious to try out some new Bioinformatics software package, and the faster they get it to a running state on their own machines, the happier the experience enabling the community for that package to grow faster. Basically most people just want to use stuff - and want a turn-key solution - though some of us like tinkering with puzzles :) If their experience is good on something local - or even a cluster - then they'll see the obvious need to try it out on a Cloud environment. I sort of did it from the other side. Many times when I tested most of the GoogleGenomics tools, I would try them out in some real-world scenarios, I usually ran them against a variety of configurations. That helped with having better error messages, control flow decisions, documentation or additional features. Basically you have developed a great software - which is evolving - and now comes the service component of supporting it, which is just as important. Just a friendly recommendation,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-385874525:153,test,test,153,,https://github.com/google/deepvariant/issues/29#issuecomment-385874525,2,['test'],"['test', 'tested']"
Testability,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/81#issuecomment-409913088:169,log,log,169,,https://github.com/google/deepvariant/issues/81#issuecomment-409913088,1,['log'],['log']
Testability,"Please share the full runner log, as well as config (YAML) file used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/70#issuecomment-387572014:29,log,log,29,,https://github.com/google/deepvariant/issues/70#issuecomment-387572014,1,['log'],['log']
Testability,"Processes: |; | GPU GI CI PID Type Process name GPU Memory |; | ID ID Usage |; |=============================================================================|; | No running processes found |; +-----------------------------------------------------------------------------+; ```. Then I install cuda. This was from: https://developer.nvidia.com/cuda-downloads; ```; curl -O https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run ; export TERM=xterm; sudo sh cuda_12.1.0_530.30.02_linux.run; ```. ```; export PATH=/usr/local/cuda-12.1/bin:$PATH; export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH; sudo ldconfig; ```. ```; [pichuan@pichuan-gpu2 ~]$ nvcc --version; nvcc: NVIDIA (R) Cuda compiler driver; Copyright (c) 2005-2023 NVIDIA Corporation; Built on Tue_Feb__7_19:32:13_PST_2023; Cuda compilation tools, release 12.1, V12.1.66; Build cuda_12.1.r12.1/compiler.32415258_0; ```. This is not 11.8, but is a newer version. So let's test with it. Install Singularity:. ```; curl -O https://raw.githubusercontent.com/google/deepvariant/r1.5/scripts/install_singularity.sh; sed -i -e 's/apt-get/yum/g' install_singularity.sh; bash -x install_singularity.sh; ```. Check version:; ```; [pichuan@pichuan-gpu2 ~]$ singularity --version; singularity version 3.7.0; ```. The rest is similar to https://github.com/google/deepvariant/issues/514#issuecomment-1035630725 , but with v1.5.0. ```; # Pull the image.; BIN_VERSION=1.5.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run DeepVariant.; # Using ""--nv"" and ""${BIN_VERSION}-gpu"" is important.; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471348553:2578,test,test,2578,,https://github.com/google/deepvariant/issues/619#issuecomment-1471348553,1,['test'],['test']
Testability,"Quartet.LCL5.GRCh38.HiFi.minimap2.bam"",; bai=""/data/DATA/ChineseQuartet/ref_based_analysis/aligned_reads/ChineseQuartet/LCL5/ChineseQuartet.LCL5.GRCh38.HiFi.minimap2.bam"",; output:; bam=dir_work + ""bams/ChineseQuartet.{region}.bam"",; bed=dir_work + ""bams/ChineseQuartet.{region}.bed"",; run:; chrom, start, end = f""{wildcards.region}"".split(""_""); start = int(start) - 1000; end = int(end) + 1000; shell(""{samtools} view -h -O BAM {input.bam} {chrom}:{start}-{end} > {output.bam}""); shell(""echo '{chrom}\t{start}\t{end}' > {output.bed}""). rule deepvariant:; input:; bam=dir_work + ""bams/ChineseQuartet.{region}.bam"",; bai=dir_work + ""bams/ChineseQuartet.{region}.bam.bai"",; bed=dir_work + ""bams/ChineseQuartet.{region}.bed"",; ref=path_ref; output:; vcf_gz=dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.vcf.gz"",; gvcf_gz=dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.g.vcf.gz""; # gvcf_gz=config[""dir_variants""] + ""dv/dv_details/{sample}/{sample}.{prefix}.dv.raw.g.vcf.gz""; log:; dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.log""; benchmark:; dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.log""; threads: 48; run:; dir_tmp = str(output.vcf_gz).rstrip("".vcf.gz"") + ""_tmp""; file_tmp = dir_tmp.split(""/"")[-1]; shell(""mkdir -p "" + dir_tmp); bam_dir = ""/"".join(str(input.bam).split(""/"")[:-1]); bam_file = str(input.bam).split(""/"")[-1]; bed_file = str(input.bed).split(""/"")[-1]; ref_dir = ""/"".join(str(input.ref).split(""/"")[:-1]); ref_file = str(input.ref).split(""/"")[-1]; output_dir = ""/"".join(str(output.vcf_gz).split(""/"")[:-1]); output_file = str(output.vcf_gz).split(""/"")[-1].rstrip("".vcf.gz""). shell('docker run '; '-v ""{bam_dir}"":""/input"" '; '-v ""{ref_dir}"":""/ref"" '; '-v ""{output_dir}"":""/output"" '; 'google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant '; '--model_type=PACBIO '; '--ref=/ref/{ref_file} '; '--reads=/input/{bam_file} '; '--regions /input/{bed_file} '; '--output_vcf=/output/{output_file}.vcf '; '--output_gvcf=/output/{output_file}.g.vcf '; '--num_sha",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/660#issuecomment-1589724792:2272,log,log,2272,,https://github.com/google/deepvariant/issues/660#issuecomment-1589724792,1,['log'],['log']
Testability,"Quick answer: Can you try `./build_release_binaries.sh` instead of `./build_and_test.sh` in your steps above?; Then it should work.; The issue you're encountering has nothing to do with Ubuntu 18. ----. More details:. Earlier today, @akolesnikov and I were just wondering why our internal tests didn't capture this.; We have daily tests that run scripts like this:; https://github.com/google/deepvariant/blob/r0.8/scripts/run_wes_case_study_binaries.sh. After checking what that script was doing, I found out that if you run `scripts/run_wes_case_study_binaries.sh`, it'll work on both Ubuntu 16 and 18. We'll fix build_and_test.sh in the next release. Thanks for reporting! ; If using `build_release_binaries.sh` still doesn't work for you, feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/199#issuecomment-514472365:289,test,tests,289,,https://github.com/google/deepvariant/issues/199#issuecomment-514472365,2,['test'],['tests']
Testability,"Ran it again, and still hitting failures:; ```; done: true; error:; code: 9; message: 'Execution failed: action 1: unexpected exit status 1 was not ignored'; metadata:; '@type': type.googleapis.com/google.genomics.v2alpha1.Metadata; createTime: '2018-11-08T14:27:06.016940Z'; endTime: '2018-11-08T14:30:59.324697Z'; events:; - description: Worker released; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.WorkerReleasedEvent; instance: google-pipelines-worker-4b16fd95b691baddc54b0c5ec50dc6c7; zone: us-west1-b; timestamp: '2018-11-08T14:30:59.324697Z'; - description: 'Execution failed: action 1: unexpected exit status 1 was not ignored'; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.FailedEvent; cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored'; code: FAILED_PRECONDITION; timestamp: '2018-11-08T14:30:58.518326Z'; - description: Stopped running ""/bin/sh -c gsutil -q cp /google/logs/output gs://canis/CNR-data/deep_variant_files/runner_logs_20181108_082705.log""; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.ContainerStoppedEvent; actionId: 2; exitStatus: 0; stderr: ''; timestamp: '2018-11-08T14:30:58.416239Z'; - description: Started running ""/bin/sh -c gsutil -q cp /google/logs/output gs://canis/CNR-data/deep_variant_files/runner_logs_20181108_082705.log""; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.ContainerStartedEvent; actionId: 2; ipAddress: ''; portMappings: {}; timestamp: '2018-11-08T14:30:55.929647Z'; - description: Unexpected exit status 1 while running ""-c /opt/deepvariant_runner/bin/gcp_deepvariant_runner --project; valis-194104 --zones us-west1-b --docker_image gcr.io/deepvariant-docker/deepvariant:0.7.0 --outfile; gs://canis/CNR-data/TLE_a_001_deep_variant.vcf --staging gs://canis/CNR-data/deep_variant_files --model; gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard --regions; gs://canis/CNR-data/CDS-canonical.bed --bam gs:/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437055644:946,log,logs,946,,https://github.com/google/deepvariant/issues/116#issuecomment-437055644,1,['log'],['logs']
Testability,"Regarding loading the checkpoint, it worked for me. I wonder if the issue is because of the gotcha of the filenames. The --checkpoint argument to call_variants is actually supposed to be the model prefix name, not an actual file name. For example I just tried . `( time python bin/call_variants.zip --outfile ""${CALL_VARIANTS_OUTPUT}"" --examples ~/case-study/output/HG002.examples.tfrecord-00004-of-00008.gz --checkpoint /tmp/deepvariant/model.ckpt-726 --batch_size 32; ) >""${LOG_DIR}/call_variants.log"" 2>&1`. and it ran as expected. Let me know if that works for you. Another thing to keep in mind is that if you run model_train again without specifying the 'train_dir' arg then it will attempt to pick up where it left off.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/46#issuecomment-364545868:499,log,log,499,,https://github.com/google/deepvariant/issues/46#issuecomment-364545868,1,['log'],['log']
Testability,"Right, but which version of the Cuda Toolkit do you have? You can easily install the 9.0 from the link below, but I would do it as a local (non-sudo) user so you sandbox the changes to your environment in order to easily remove them later, if necessary:. https://developer.nvidia.com/cuda-90-download-archive. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/102#issuecomment-429154858:162,sandbox,sandbox,162,,https://github.com/google/deepvariant/issues/102#issuecomment-429154858,1,['sandbox'],['sandbox']
Testability,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/; https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-453800484:594,test,test,594,,https://github.com/google/deepvariant/issues/137#issuecomment-453800484,1,['test'],['test']
Testability,"Running with -v, everything looks normal except 2 error messages:. 1st error message:; ==============; ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===; prefix=/mnt/home/mansourt/miniconda3/envs/deepVar; source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully; python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7; py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py; pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc; compile rc: 1; compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ...; File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102; def keyworded(*arg1, arg2=1):; ^; SyntaxError: invalid syntax. compile stderr:. 2nd error message:; ==============; $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh; ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==; ==> exit code: 1 <==; ==> stdout <==; b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'; ==> stderr <==; b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-451711664:499,test,tests,499,,https://github.com/google/deepvariant/issues/137#issuecomment-451711664,4,['test'],['tests']
Testability,"R}""; ```. ```; gsutil -m cp ${DATA_BUCKET}/BGISEQ_PE100_NA12878.sorted.chr*.bam* ""${DATA_DIR}""; gsutil -m cp -r ""${DATA_BUCKET}/ucsc_hg19.fa*"" ""${DATA_DIR}""; gsutil -m cp -r ""${DATA_BUCKET}/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_*"" ""${DATA_DIR}"". gunzip ""${DATA_DIR}/ucsc_hg19.fa.gz""; ```. ```; sudo apt -y update; sudo apt -y install parallel; sudo apt -y install docker.io; ```. ```; sudo docker pull google/deepvariant:""${BIN_VERSION}""; ```. ```; ( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --line-buffer \; sudo docker run \; -v ${HOME}:${HOME} \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM_CHR1}"" \; --examples ""${OUTPUT_DIR}/training_set.with_label.tfrecord@${N_SHARDS}.gz"" \; --truth_variants ""${TRUTH_VCF}"" \; --confident_regions ""${TRUTH_BED}"" \; --task {} \; --regions ""'chr1'"" \; ) 2>&1 | tee ""${LOG_DIR}/training_set.with_label.make_examples.log""; ```. ```; gsutil -m cp ${OUTPUT_DIR}/training_set.with_label.tfrecord-?????-of-000??.gz \; ${OUTPUT_BUCKET}; ```. ```; ( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --line-buffer \; sudo docker run \; -v /home/${USER}:/home/${USER} \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM_CHR21}"" \; --examples ""${OUTPUT_DIR}/validation_set.with_label.tfrecord@${N_SHARDS}.gz"" \; --truth_variants ""${TRUTH_VCF}"" \; --confident_regions ""${TRUTH_BED}"" \; --task {} \; --regions ""'chr21'"" \; ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log""; ```. ```; gsutil -m cp ${OUTPUT_DIR}/validation_set.with_label.tfrecord-?????-of-000??.gz \; ${OUTPUT_BUCKET}; ```. ```; mkdir -p ${SHUFFLE_SCRIPT_DIR}; wget https://gist.githubusercontent.com/pichuan/75aa5aebc961dd2c2472bcbcdd9ecaa9/raw/3c313815050f1b517a660604b222ecc7528b37e0/shuffle_tfrecords_beam.py -O ${SHUFFLE_SCRIPT_DIR}/shuffle_tfrecords_beam.py; `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/469#issuecomment-871936544:3244,log,log,3244,,https://github.com/google/deepvariant/issues/469#issuecomment-871936544,1,['log'],['log']
Testability,"S1.chr20.10_10p1mb.bam with NativeSamReader; I0327 13:32:07.294783 47175299967680 make_examples.py:535] Common contigs are ['chr20' ]; I0327 13:32:07.296233 47175299967680 make_examples.py:535] Writing examples to /tmp/tm p63xxmwmi/make_examples.tfrecord-00000-of-00001.gz; I0327 13:32:07.296404 47175299967680 make_examples.py:535] Writing gvcf records to /tm p/tmp63xxmwmi/gvcf.tfrecord-00000-of-00001.gz; I0327 13:32:07.298243 47175299967680 make_examples.py:535] Starting from v0.9.0, --use _ref_for_cram is default to true. If you are using CRAM input, note that we will decod e CRAM using the reference you passed in with --ref; 2020-03-27 13:32:07.298857: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OP T_BLOCK_SIZE to 134217728; I0327 13:32:07.388042 47175299967680 genomics_reader.py:223] Reading /scratch/moldach/ bin/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0327 13:32:07.389374 47175299967680 genomics_reader.py:223] Reading /scratch/moldach/ bin/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0327 13:32:07.863366 47175299967680 make_examples.py:535] 6 candidates (6 examples) [ 0.57s elapsed]; I0327 13:32:09.857359 47175299967680 make_examples.py:535] Found 78 candidate variants; I0327 13:32:09.857484 47175299967680 make_examples.py:535] Created 86 examples. real 0m11.980s; user 0m5.478s; sys 0m3.350s. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp63xxmwmi/call_variants_outp ut.tfrecord.gz"" --examples ""/tmp/tmp63xxmwmi/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0327 13:32:13.471893 47138345245376 call_variants.py:316] Set KMP_BLOCKTIME to 0; 2020-03-27 13:32:13.524960: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instruct ions in performance critical operations: AVX2 FMA; To enable them in non-MKL-DNN operations, rebuild TensorFlow wit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-605306987:3920,test,testdata,3920,,https://github.com/google/deepvariant/issues/287#issuecomment-605306987,1,['test'],['testdata']
Testability,Solving the first error (libcublas.so.12) by creating a sandbox with singularity and adding the location of libcublas.so.12 to the env. I guess creating a soft link with ln -s would also work.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/722#issuecomment-1780922055:56,sandbox,sandbox,56,,https://github.com/google/deepvariant/issues/722#issuecomment-1780922055,1,['sandbox'],['sandbox']
Testability,"Some other things to look in to:. * Is what you have pasted above the full stack trace? If there's any other output, it would be helpful to see that as well.; * Could you try running `make_examples` directly using the below command? This is only using one shard. If this command fails, we may see a more informative error message. ```; sudo docker run \; -v ""/root/quickstart-testdata"":""/input"" \; -v ""/root/quickstart-output"":""/output"" \; google/deepvariant:latest \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" \; --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" \; --examples ""/output/make_examples.tfrecord@1.gz"" \; --gvcf ""/output/gvcf.tfrecord@1.gz"" \; --regions ""chr20:10,000,000-10,010,000""; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/325#issuecomment-659076993:376,test,testdata,376,,https://github.com/google/deepvariant/issues/325#issuecomment-659076993,1,['test'],['testdata']
Testability,"Sorry about the the confusion of <sample_name>, I edited out the actual name. The name was appeared correctly and It was being generated at the right path too (files were deleted by snakemake due to incomplete workflow). . It seems like both VCF and gVCF were generated successfully from the log but if failed to run vcf_stats_report.py: . ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""/project/pi_robertmills_umass_edu/databases/bacteroides_genome/<ref_genome>"" --infile ""../../results/deepVariant/KO_PV/<sample_name>/intermediate/call_variants_output.tfrecord.gz"" --outfile ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --cpus ""6"" --gvcf_outfile ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --nonvariant_site_tfrecord_path ""../../results/deepVariant/KO_PV/<sample_name>/intermediate/gvcf.tfrecord@6.gz"". I0626 19:01:26.925776 139684790912832 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default; 2024-06-26 19:01:26.928061: I deepvariant/postprocess_variants.cc:94] Read from: ../../results/deepVariant/KO_PV/<sample_name>/intermediate/call_variants_output-00000-of-00001.tfrecord.gz; 2024-06-26 19:01:26.930065: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 407; I0626 19:01:26.930917 139684790912832 postprocess_variants.py:1313] CVO sorting took 6.503661473592123e-05 minutes; I0626 19:01:26.931080 139684790912832 postprocess_variants.py:1316] Transforming call_variants_output to variants.; I0626 19:01:26.931126 139684790912832 postprocess_variants.py:1318] Using 6 CPUs for parallelization of variant transformation.; I0626 19:01:26.954008 139684790912832 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default; I0626 19:01:26.991115 139684790912832 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 0.00046567519505818686",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/839#issuecomment-2195634219:292,log,log,292,,https://github.com/google/deepvariant/issues/839#issuecomment-2195634219,1,['log'],['log']
Testability,"Sorry for my late reply! To be honest, I believe I went with the [quick start](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md) and replaced the test data with my own. Then I started to debug on that ValueError, believing that was a potential bug (because of the error saying I was using `--make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`, while I was actually not; I put that first argument to false, not true).; I don't believe there is something wrong with your user flow! Your github is really nice and the docker and dependencies were very easily installed. I wouldn't want to comment more on that without extensively trying your tool, so maybe I can provide with proper feedback later :) I will definitely let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/457#issuecomment-844185505:177,test,test,177,,https://github.com/google/deepvariant/issues/457#issuecomment-844185505,1,['test'],['test']
Testability,"Sorry, I've been traveling the past week without a solid network connection. I've uploaded my simg to google drive at the address below. This will likely not be a permanent link, but you can use it for testing now. https://drive.google.com/open?id=12NZKJwRTroKofGB6KrZ4JVyN36DRbPuF",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/178#issuecomment-488824724:202,test,testing,202,,https://github.com/google/deepvariant/issues/178#issuecomment-488824724,1,['test'],['testing']
Testability,"Sorry, i used model_train.zip really, just pasted the incorrect command to issue. ; This is my correct command:; ```; python /leostore/software/deepvariant/bazel-bin/deepvariant/model_train.zip --dataset_config_pbtxt ""/leostore/analysis/development/liteng/deepvariant_test/test_train.config.txt"" --start_from_checkpoint inception_v3.ckpt; ```; The inception_v3.ckpt is downloaded from https://github.com/tensorflow/models/tree/master/research/slim#Data ; This is my config file:; ```; name: ""test-training-dataset""; tfrecord_path: ""/leostore/analysis/development/liteng/deepvariant_test/train_set/test_train.tfrecord.gz""; num_examples: 1; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/10#issuecomment-350909874:492,test,test-training-dataset,492,,https://github.com/google/deepvariant/issues/10#issuecomment-350909874,1,['test'],['test-training-dataset']
Testability,"Sort of a follow-up question, on a related application: can DeepVariant take an RNA-seq bam file obtained via GATK's best practices (link [here](https://software.broadinstitute.org/gatk/documentation/article.php?id=3891)), and get a trustworthy output? . A quick check on a specific locus indicates that DeepVariant's WGS applied to RNA-seq retrieves a few more variants than GATK's ""HaplotypeCaller"". Can we trust it? Has anybody done more comprehensive testing of this?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/115#issuecomment-457703903:455,test,testing,455,,https://github.com/google/deepvariant/issues/115#issuecomment-457703903,1,['test'],['testing']
Testability,Still yields a core dump with no error message. Going to test this on docker.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/419#issuecomment-774282552:57,test,test,57,,https://github.com/google/deepvariant/issues/419#issuecomment-774282552,1,['test'],['test']
Testability,"Sure! please find attached the logs in the terminal.; In the meantime, I will run the simple case study.; Thank you!; [output.log](https://github.com/google/deepvariant/files/15052710/output.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/810#issuecomment-2068128270:31,log,logs,31,,https://github.com/google/deepvariant/issues/810#issuecomment-2068128270,3,['log'],"['log', 'logs']"
Testability,TEST 2,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/1#issuecomment-348330972:0,TEST,TEST,0,,https://github.com/google/deepvariant/issues/1#issuecomment-348330972,1,['TEST'],['TEST']
Testability,"TP_DIR=""https://storage.googleapis.com/deepvariant/singularity_images""; # Non-gpu image; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/deepvariant-0.9.0.simg; # GPU image; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/deepvariant-0.9.0-gpu.simg. # Test Singularity DeepVariant0.9.0 image on test data; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; ${INPUT_DIR}/deepvariant-${BIN_VERSION}.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz . # Errors:. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2020-01-31 01:37:29.333483: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . # Test Singularity DeepVariant0.9.0 GPU image on test data; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; ${INPUT_DIR}/deepvariant-${BIN_VERSION}-gpu.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz . # Errors: ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_0Ul6DZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 43, in <module>; import tensorflow as tf; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/265#issuecomment-580549772:1687,Test,Test,1687,,https://github.com/google/deepvariant/issues/265#issuecomment-580549772,1,['Test'],['Test']
Testability,"TTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; >; > Run make_examples:; >; > OUTPUT_DIR=""${PWD}/quickstart-output""; > mkdir -p ""${OUTPUT_DIR}""; >; > python bin/make_examples.zip \; > --mode calling \; > --ref ""${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta"" \; > --reads ""${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam"" \; > --regions ""chr20:10,000,000-10,010,000"" \; > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"" \; > --channels ""insert_size""; >; > (To figure out which flags you need to add for each model, you can read; > https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L253; > . Sorry that we don't have better documentation than that right now); >; > For how to run this with multiple shards, and how to run the rest of the; > commands, please read; > https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md; >; > I just tested the steps above and confirmed that it worked for me on; > v1.4.0, at least for the make_examples step.; > If you encounter more issues with other steps, please feel free to ask; > again. I'd be happy to help.; >; > Note that I don't plan to put this into an official documentation page; > now, because that adds to our maintenance burden to keep it up to date.; > Given that we have the Docker/Singularity solution that works generally; > well for our users, I don't expect many of our users to need to use; > pre-built binaries. @zivlang <https://github.com/zivlang> thank you for; > your question so I have a chance to test it again and document it here.; > Hopefully this is helpful for you. Happy to answer more questions if you; > encounter more problems.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/590#issuecomment-1322695241>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALBF75YWC2I4SZFXBKRL4KTWJPVBNANCNFSM6AAAAAASFZYTTI>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566:4111,test,test,4111,,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566,1,['test'],['test']
Testability,"T_2021; Cuda compilation tools, release 11.3, V11.3.58; Build cuda_11.3.r11.3/compiler.29745058_0; ```. Try this again:; ```; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}-gpu"" python -c 'import tensorflow as tf;print(tf.test.is_gpu_available())'; ```; Still false -- didn't seem to help:. ```; 2023-03-16 07:01:52.583106: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; 2023-03-16 07:01:52.583190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: pichuan-gpu2; 2023-03-16 07:01:52.583209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: pichuan-gpu2; 2023-03-16 07:01:52.583304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; 2023-03-16 07:01:52.583352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1; False; ```. I tried one more thing, which is rebooting after installing nvidia-modprobe. I did:; ```; gcloud compute instances reset --zone us-west1-b pichuan-gpu2; ```. and then ssh back to the machine. ```; BIN_VERSION=1.5.0; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}-gpu"" python -c 'import tensorflow as tf;print(tf.test.is_gpu_available())'; ```. Oh wow, that actually worked. --> it returns True. Although, now I'm seeing @pgrosu 's comment above, and started wondering if it could be that restarting means I reset $LD_LIBRARY_PATH (because now it's empty , and the command above still worked). So, my new hypothesis that ""nvidia-modprobe helped"" might not be true. Need to test with clean setup again :). But at least something works now! I just don't exactly know what helped yet :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471426355:2367,test,test,2367,,https://github.com/google/deepvariant/issues/619#issuecomment-1471426355,2,['test'],['test']
Testability,Test,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/426#issuecomment-782440933:0,Test,Test,0,,https://github.com/google/deepvariant/issues/426#issuecomment-782440933,1,['Test'],['Test']
Testability,"Thank a lot for your answer. Now the are public for real!. Luisa. 2018-03-07 16:53 GMT+01:00 Mark DePristo <notifications@github.com>:. > Thanks Luisa! It seems those s3 files aren't public:; >; > wget http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > --2018-03-07 07:28:01-- http://dv-testfiles.s3.; > amazonaws.com/ENCFF528VXT.bam; > Resolving dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)...; > 52.218.52.113; > Connecting to dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)|52.218.52.113|:80...; > connected.; > HTTP request sent, awaiting response... 403 Forbidden; > 2018-03-07 07:28:01 ERROR 403: Forbidden.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/52#issuecomment-371184018>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AWD1QUPeGVGaxtvJH4LH2Ygb1cSQEtjlks5tcAKUgaJpZM4SejU_>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371186430:212,test,testfiles,212,,https://github.com/google/deepvariant/issues/52#issuecomment-371186430,6,['test'],['testfiles']
Testability,Thank you - I think these commands will be helpful as I learn about using Google Cloud. Please don't rush the AWS test - I am guessing I will have to wait until at least Sunday to be able to set up an account and confirm that using Google Cloud can resolve this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480271688:114,test,test,114,,https://github.com/google/deepvariant/issues/167#issuecomment-480271688,1,['test'],['test']
Testability,"Thank you @ASLeonard for sharing your current solution. On my end I'll continue to try to reproduce the issue. If I'm unable to, I might need to ask you to help test out my updated code after I have it. I might reach out again later on this thread. For now, I'll close this issue. Please feel free to update with more information, or submit another issue if you have other questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-763821009:161,test,test,161,,https://github.com/google/deepvariant/issues/404#issuecomment-763821009,1,['test'],['test']
Testability,"Thank you @AndrewCarroll and @pichuan for the clarification. The calibration makes sense, and could be intriguing for inspecting DNN-resiliency. Having the same underlying Inception V3 network architecture for both PacBio and WGS, a point of natural comparability would be the logits kernel across all three genotypes:. ![image](https://github.com/pgrosu/test/assets/6555937/e8ebb437-0132-474e-9ada-c64256aeb791). ![image](https://github.com/pgrosu/test/assets/6555937/f1f478fa-8ffc-4a9a-b5de-4f123658750d). ![image](https://github.com/pgrosu/test/assets/6555937/eb14b3e0-3424-4dc5-82b3-c77091c871a2). Given visual similarity, these were confirmed via Euclidean distance (0.9931127, 0.8543731 and 1.052052, respectively). This indicates the feature set might exhibit strong similarity for interpretation. . Looking at one network (PacBio), it might be possible to confirm calibration by testing for network-resiliency. Via perturbation analysis it should be possible to get insight into a channel's response under perturbation, and their binary interactions under such conditions. Keeping the variant unchanged within a window on each side for preserving the call, the inspection each channel vulnerability response to perturbation can be tested. This resulted in the following perturbation response ($`c\_*`$ denotes a channel, and $`i\_*\_*`$ represents a binary interaction between two channels):. ![image](https://github.com/pgrosu/test/assets/6555937/97c6b13e-e80b-48ae-939d-2367e7ab65c1). The above can be mapped into a network of interactions among the channels:. ![image](https://github.com/pgrosu/test/assets/6555937/cc0e1e2a-278f-4178-a124-67b0321bba3e). Based on the above mapping, by testing well-interacting channels through a probabilistically value-update -- within DeepVariant-acceptable values -- it might be possible to check for shifts in genotype mimicking Mendelian violation. Selecting `base_quality` and staying within DeepVariant's minimum acceptable value, random sampling wit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1619352040:277,log,logits,277,,https://github.com/google/deepvariant/issues/666#issuecomment-1619352040,5,"['log', 'test']","['logits', 'test', 'testing']"
Testability,"Thank you @Zer0day-0 . I went back and looked at my notes on the last time I tried to install with Conda: https://github.com/google/deepvariant/issues/736#issuecomment-1829204521. I noticed that you're using CentOS. I think I might be testing with CentOS at the time. So let me try that. # Get a CentOS machine to test. I used:. ```bash; gcloud compute instances create ""${USER}-centos7"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""centos-7"" \; --image-project ""centos-cloud"" \; --machine-type ""e2-standard-16"" \; --zone ""us-west1-b"". gcloud compute ssh pichuan-centos7 --zone ""us-west1-b""; ```. Version:. ```; $ uname -a; Linux pichuan-centos7 3.10.0-1160.114.2.el7.x86_64 #1 SMP Wed Mar 20 15:54:52 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux; ```. Install conda:. ```bash; curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh > Miniconda3-latest-Linux-x86_64.sh; bash Miniconda3-latest-Linux-x86_64.sh -b -u -p $HOME/miniconda; eval ""$(${HOME}/miniconda/bin/conda shell.bash hook)""; ```. To repeat what I did in, I tried: https://github.com/google/deepvariant/issues/736#issuecomment-1829204521. ```bash; conda config --add channels defaults && \; conda config --add channels bioconda && \; conda config --add channels conda-forge; conda create -y -n dv-env deepvariant; conda activate dv-env; ```. It completed without any error messages. I see:. ```; (dv-env) [pichuan@pichuan-centos7 ~]$ ls /home/pichuan/miniconda/envs/dv-env/share/; bash-completion deepvariant-1.5.0-0 doc et examples google-cloud-sdk-359.0.0-0 icu info keyutils licenses locale man tabset terminfo zsh; (dv-env) [pichuan@pichuan-centos7 ~]$ ls /home/pichuan/miniconda/envs/dv-env/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0; call_variants_keras.zip freeze_graph.zip make_examples.zip multisample_make_examples.zip runtime_by_region_vis.zip vcf_stats_report.zip; call_variants.zip licenses.zip model_eval.zip postprocess_variants.zip settings.sh; deeptr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/806#issuecomment-2067274405:235,test,testing,235,,https://github.com/google/deepvariant/issues/806#issuecomment-2067274405,2,['test'],"['test', 'testing']"
Testability,Thank you @carsonhh ! I'll test this and make a change accordingly.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/789#issuecomment-1992745319:27,test,test,27,,https://github.com/google/deepvariant/issues/789#issuecomment-1992745319,1,['test'],['test']
Testability,"Thank you @githubtefo for the log. The last step certainly looks strange to me:. ```; ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""/reference/Homo_sapiens.GRCh37.dna.primary_assembly.fa"" --infile ""/tmp/tmpba2iuryg/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --cpus ""16"" --gvcf_outfile ""/output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmpba2iuryg/gvcf.tfrecord@16.gz"". I0418 11:23:10.756783 140607260936000 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: 15337_Control; 2024-04-18 11:23:10.761841: I deepvariant/postprocess_variants.cc:94] Read from: /tmp/tmpba2iuryg/call_variants_output-00000-of-00001.tfrecord.gz; 2024-04-18 11:23:39.285004: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 8753635; I0418 11:24:21.877126 140607260936000 postprocess_variants.py:1313] CVO sorting took 1.1852648933728536 minutes; I0418 11:24:21.877437 140607260936000 postprocess_variants.py:1316] Transforming call_variants_output to variants.; I0418 11:24:21.877472 140607260936000 postprocess_variants.py:1318] Using 16 CPUs for parallelization of variant transformation.; I0418 11:24:35.259627 140607260936000 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: 15337_Control. real	2m10.376s; user	1m41.800s; sys	0m24.640s; ```. I would expect `postprocess_variants` to be doing more. I believe @lucasbrambrink is looking into another issue in `postprocess_variants` related to multiprocessing (https://github.com/google/deepvariant/issues/804), but I'm not sure if this relevant. For now, can you try disable multiprocessing in the `postprocess_variants` step by setting `--cpus 0`. If you're using the run_deepvariant one-step script, you can add:. ```bash; --postprocess_variants_extra_args=""cpus=0""; ```. and see if that works for you. Please let us know. We'll try to make this more robust in the future!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/810#issuecomment-2068144877:30,log,log,30,,https://github.com/google/deepvariant/issues/810#issuecomment-2068144877,1,['log'],['log']
Testability,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```; paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta; -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory; paul$; ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/675#issuecomment-1632163617:811,test,testdata,811,,https://github.com/google/deepvariant/issues/675#issuecomment-1632163617,2,['test'],['testdata']
Testability,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480616982:163,test,test,163,,https://github.com/google/deepvariant/issues/167#issuecomment-480616982,2,['test'],"['test', 'tested']"
Testability,"Thank you for help, with your tweak build and tests passed.; But I get different results on test data - described [here](https://github.com/google/deepvariant/issues/239#issuecomment-558061938).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/236#issuecomment-558062729:46,test,tests,46,,https://github.com/google/deepvariant/issues/236#issuecomment-558062729,2,['test'],"['test', 'tests']"
Testability,"Thank you for looking into this. I'm running DeepVariant on a docker image. Below is my command line. My reference genome, reads, and truth VCF are 300Mb, so I will send via email if that is okay.; ```; ref=H37Rv.fa; BAM=GCA_000193185.1_1_1.bowtie2.rmdup.bam; TRUTH_VCF=test.vcf.gz; base=${BAM%.rmdup.bam}. /opt/deepvariant/bin/make_examples --mode training --ref ${ref} --reads ${BAM} --examples ${base}.tfrecord --truth_variants ${TRUTH_VCF} --confident_regions confidence.bed . ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/71#issuecomment-387870861:270,test,test,270,,https://github.com/google/deepvariant/issues/71#issuecomment-387870861,1,['test'],['test']
Testability,Thank you for providing the run-prereq.sh information. I found a 2.1.0 version of intervaltree in ${HOME}/.local/lib/python2.7/site-packages that was overriding the site-packages directory within the container. The test ran successfully once I eliminated the conflict.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/255#issuecomment-570610250:215,test,test,215,,https://github.com/google/deepvariant/issues/255#issuecomment-570610250,1,['test'],['test']
Testability,"Thank you for the acknowledgement, but more importantly as scientists we require that the experiment be complete by reflecting equivalence in the results. Let's dig a little deeper:. 1. In the article you are right with AVX-512 would give you the ability to ""operate on more information at once"", so have you tried a test where you compiled DeepVariant with just `-mavx512*` without MKL? Let's look at the following article:. https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture. The increased throughput (though significant) via vectorized functions is _*only one*_ aspect of the optimizations. I would suspect you picked MKL for multiple optimization reasons, one of which performs auto-queries for code path dispatches to save space on multiple binaries for users (among many other reasons):. https://software.intel.com/en-us/mkl-linux-developer-guide-instruction-set-specific-dispatching-on-intel-architectures. 2. Yes Mark's proposal is accurate with AVX, but try running with just AVX512 optimizations - which not everyone might have access to such CPUs - and _*without MKL*_ and I think you might surmise the results. To drive the point home, look at the code references in Tensoflow for AVX512 vs MKL:. * 143 for MKL => https://github.com/tensorflow/tensorflow/search?q=mkl&unscoped_q=mkl; * 19 for AVX512 => https://github.com/tensorflow/tensorflow/search?q=avx512&unscoped_q=avx512. Now having said that, what do you think could be done to make DeepVariant even faster besides AVX/MKL/CUDA/TPU optimizations?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/21#issuecomment-489377484:317,test,test,317,,https://github.com/google/deepvariant/issues/21#issuecomment-489377484,1,['test'],['test']
Testability,"Thank you for the feedback! @danielecook I can confirm that the files in the tmp directory do look to be normal as you described above. @kishwarshafin, I tested the docker that you suggested and now it seems that Deepvariant did not run at all (vcfs and gvcfs are empty); [deepvarrun_b37_MND_G33.1kei.log](https://github.com/google/deepvariant/files/14458499/deepvarrun_b37_MND_G33.1kei.log); ; I have attached a log file for one of the samples, so you can see what happened.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/776#issuecomment-1972749674:154,test,tested,154,,https://github.com/google/deepvariant/issues/776#issuecomment-1972749674,4,"['log', 'test']","['log', 'tested']"
Testability,"Thank you for the quick response!; I'd be glad to provide more information (the information listed below is from the original datasets / metrics provided from the genetic testing company that performed the tests utilizing their own tooling.); What type of sequencing data? Diagnostic Testing / XomeDx / Clinical Exome Sequence Analysis (provided in cram format with md5 hg19 as reference and the accompanying vcfs from said company) ; what depths - 152x mean depth of coverage with a quality threshold of 98.6; what organism - Humans using hg19 as reference (family of 4 two affected female probands two unaffected parents); Anything noticeably different from the data we used in case studies - nothing that i'm aware of at this time. It'll be great if you can also report: how many number of calls in your VCFs, how many GTs are in each calls (e.g., how many calls are ./.)? -I'm not completely sure where this is located but I believe I can find it. And, if your data is public, you can point to us and we can take a look. - The data is not available publicly yet but I would be glad to share it with you and your team. It has been submitted for public sharing with mygene2 (at least I'm pretty sure they are not online yet). I do, however, plan on sharing them online with Genome Connect and the rest of genetic community in the near future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/311#issuecomment-636996628:171,test,testing,171,,https://github.com/google/deepvariant/issues/311#issuecomment-636996628,3,"['Test', 'test']","['Testing', 'testing', 'tests']"
Testability,"Thank you for the reply. I have included the "" "" in the code however it appears missing at runtime.It worked when I replace that with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e.; ``` ; I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]; I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants ; ``` . However, for region 20:10,002,000-10,003,000, I get; ``` ; I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]; I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants ; ``` ; which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, ; ``` ; I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]; I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants ; ```; ; which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case?. I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/72#issuecomment-413179094:471,log,log,471,,https://github.com/google/deepvariant/issues/72#issuecomment-413179094,1,['log'],['log']
Testability,"Thank you for the response ; I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```; conda create -n deepvariant python=2.7; source activate deepvariant; conda install -c conda-forge google-cloud-sdk; conda install -v -y deepvariant &> deepvariant_insatll.log; ```. I got a successful installation inspite of the first error message just like you; However, running the code is producing another error:. ```; python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \; --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \; --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \; --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>; import tensorflow as tf; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_intern",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-453685106:367,log,log,367,,https://github.com/google/deepvariant/issues/137#issuecomment-453685106,1,['log'],['log']
Testability,"Thank you for trying. I'm not able to reproduce on any cloud instance so it must be a local issue. I did run into a different performance issue with AMD during the call_variants.py step in my testing. I setup an Intel 48 core instance and an AMD 48 core instance. Both in AWS. > intel:~$ lscpu; > Architecture: x86_64; > CPU op-mode(s): 32-bit, 64-bit; > Byte Order: Little Endian; > CPU(s): 48; > On-line CPU(s) list: 0-47; > Thread(s) per core: 2; > Core(s) per socket: 24; > Socket(s): 1; > NUMA node(s): 1; > Vendor ID: GenuineIntel; > CPU family: 6; > Model: 85; > Model name: Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz; > Stepping: 4; > CPU MHz: 1520.299; > BogoMIPS: 4999.99; > Hypervisor vendor: KVM; > Virtualization type: full; > L1d cache: 32K; > L1i cache: 32K; > L2 cache: 1024K; > L3 cache: 33792K; > NUMA node0 CPU(s): 0-47; > Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves ida arat pku ospke. > amd:~$ lscpu; > Architecture: x86_64; > CPU op-mode(s): 32-bit, 64-bit; > Byte Order: Little Endian; > CPU(s): 48; > On-line CPU(s) list: 0-47; > Thread(s) per core: 2; > Core(s) per socket: 24; > Socket(s): 1; > NUMA node(s): 3; > Vendor ID: AuthenticAMD; > CPU family: 23; > Model: 1; > Model name: AMD EPYC 7571; > Stepping: 2; > CPU MHz: 2524.374; > BogoMIPS: 4399.90; > Hypervisor vendor: KVM; > Virtualization type: full; > L1d cache: 32K; > L1i cache: 64K; > L2 cache: 512K; > L3 cache: 8192K; > NUMA node0 CPU(s): 0-7,24-31; > NUMA node1 CPU(s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/274#issuecomment-603439134:192,test,testing,192,,https://github.com/google/deepvariant/issues/274#issuecomment-603439134,1,['test'],['testing']
Testability,"Thank you for your reply!; 1、My machine doesn't have `/usr/bin/python3`.I don't have permission to change `/usr/bin/`.I tried to modify the source code, but I couldn't locate the code.; 2、I tried to install Singularity. I use the parameter `--without -- seccomp --without -- conmon` because of the following error; `./mconfig --without-suid --without-seccomp --without-conmon --prefix=/path/singularity && make -C ./builddir &&make -C ./builddir install`; ```; seccomp headers are required to build Singularity with seccomp support.; To disable seccomp support run mconfig using '--without-seccomp'. Cannot build conmon for OCI support without libseccomp headers.; Use --without-conmon to disable build and use conmon on PATH if present.; ```; Then I try to run it; ```; singularity run -B /path/locale/:/path/locale/ \; > docker://google/deepvariant:""1.4.0"" \; > /path/dpv_singu \; > --model_type=PACBIO \; > --ref=/path/ref_fasta/QJref.fa \; > --reads=/path/bam_files/F1N_sorted.merged.addg.uniq.rmdup.bam \; > --output_vcf=/path/output.vcf.gz \; > --output_gvcf=/path/output.g.vcf.gz \; > --intermediate_results_dir /path/intermediate_results_dir; ```; The error information is as follows; ```; INFO: Using cached SIF image; INFO: Converting SIF file to temporary sandbox...; FATAL: while handling /home/my_user_name/.singularity/cache/oci-tmp/sha256.83ce0d6bbe3695bcbaa348b73c48737bdbfaeaea2272b0105dd4bdfa7a804f18: while extracting image: root filesystem extraction failed: extract command failed: ERROR : Failed to create user namespace: user namespace disabled; : exit status 1; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/598#issuecomment-1359523260:1267,sandbox,sandbox,1267,,https://github.com/google/deepvariant/issues/598#issuecomment-1359523260,1,['sandbox'],['sandbox']
Testability,"Thank you so much.; In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required.; Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation.; For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:; https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/127#issuecomment-446044386:510,test,testing,510,,https://github.com/google/deepvariant/issues/127#issuecomment-446044386,1,['test'],['testing']
Testability,Thank you very much for your quick replay.; I changed the version of the singularity to > 3 the problem was solved. however when I try to run the image using the following command ; singularity run -B /usr/lib/locale/:/usr/lib/locale/ /home/my_username/deepvariant_1.3.0.sif --model_type=WES --ref=input/Homo_sapiens_assembly38.fasta --reads=/oldHome/my_username/exome_data/EX2015.sorted.bam \ --output_vcf=output/output.vcf.gz --intermediate_results_dir=outout --num_shards=10; it returns the following error and stop; INFO: Convert SIF file to sandbox...; ERROR : Failed to create user namespace: user namespace not supported by your system; Thanks,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/513#issuecomment-1027691620:546,sandbox,sandbox,546,,https://github.com/google/deepvariant/issues/513#issuecomment-1027691620,1,['sandbox'],['sandbox']
Testability,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), I’m getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didn’t achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/869#issuecomment-2315052827:126,test,test,126,,https://github.com/google/deepvariant/issues/869#issuecomment-2315052827,1,['test'],['test']
Testability,"Thank you! Although while testing I will continue to use Docker, changing the code might become important to me 👍",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/42#issuecomment-360789056:26,test,testing,26,,https://github.com/google/deepvariant/issues/42#issuecomment-360789056,1,['test'],['testing']
Testability,"Thank you! I re-ran the training and validation sets with that flag, and re-shuffled them. Now, however, when I go to train the model (using the same parameters as the example case study--I just want to test out the process) I'm not getting any checkpoints in the output training directory, just the event log and the json file. What does this mean? Is the training step failing, or do I simply need to adjust my parameters? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2029425877:203,test,test,203,,https://github.com/google/deepvariant/issues/797#issuecomment-2029425877,2,"['log', 'test']","['log', 'test']"
Testability,Thank you! I'll test that out.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/71#issuecomment-387952593:16,test,test,16,,https://github.com/google/deepvariant/issues/71#issuecomment-387952593,1,['test'],['test']
Testability,"Thank you, I agree with you about v4.2 being more comprehensive and correct. However, the reason why I am interested in a model trained on v3.3.2 is because I wanted to test DeepVariant's performance on v4.2 benchmark variants, for which it would be better to use a model that was not already trained on v4.2 benchmark variants. Just to get final clarification, PacBio model in the current v.1.0.0 release is trained on chr1-22 (except chr20 which is withheld) of all three Ashkenazim trio genomes, or just HG002 and HG004?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/381#issuecomment-728645413:169,test,test,169,,https://github.com/google/deepvariant/issues/381#issuecomment-728645413,3,"['benchmark', 'test']","['benchmark', 'test']"
Testability,Thank you. Do you have a timeline on when the benchmarks on GLnexus to combine gVCFs would be completed ?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/142#issuecomment-461139788:46,benchmark,benchmarks,46,,https://github.com/google/deepvariant/issues/142#issuecomment-461139788,1,['benchmark'],['benchmarks']
Testability,"Thank you. I want to use a PacBio model trained on v3.3.2 benchmark variants. I assumed that the following model: deepvariant/models/DeepVariant/0.9.0/DeepVariant-inception_v3-0.9.0+data-pacbio_standard from DeepVariant bucket released in 2019 is trained on v3.3.2. However, when I run this model in call_variants using examples created by make_examples from DeepVariant v1.0.0, I get the following error:. `ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 8.`. Does this mean this model is not compatible with DeepVariant v1.0.0? If I recreate examples with 6 channels using DeepVariant v0.9, will that have a significant drop in accuracy? Also, is there a trained model on v3.3.2 of benchmark variants that is compatible with 8 channels?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/381#issuecomment-727285166:58,benchmark,benchmark,58,,https://github.com/google/deepvariant/issues/381#issuecomment-727285166,2,['benchmark'],['benchmark']
Testability,Thanks @AndrewCarroll! Happy to test beta version when you produce them.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/518#issuecomment-1086175908:32,test,test,32,,https://github.com/google/deepvariant/issues/518#issuecomment-1086175908,1,['test'],['test']
Testability,"Thanks @Asppagh . Sorry it took me a while to get back to this. From your response above, you're talking about the `call_variants` step.; The issue (https://github.com/google/deepvariant/issues/74) you cited above was from a while ago, so the numbers might have changed. But I think it's still a good reference point. Even with 8 cores, going from < 1sec to 20-60 sec does seem extreme. Let me try to get a 8-core, 64 GB machine and test it with Singularity and report back, so we can have a better comparison. Other thing that come into mind is that `call_variants` step uses TensorFlow, which relies on CPU optimization to be faster. See: https://google.github.io/deepvariant/posts/2019-04-30-the-power-of-building-on-an-accelerating-platform-how-deepVariant-uses-intels-avx-512-optimizations/; Can you check what type of CPU you have? (What's in your ` /proc/cpuinfo`?). One more note on num_shards:; num_shards affects the way that `make_examples` step is parallelized. On the high level it shouldn't affect call_variants step. But, setting `num_shards` to 8 means the output from `make_examples` will be in 8 shards (8 files), so it's possible that the input into call_variants become slower, but I don't expect a big difference. And, I would expect setting `num_shards=1` would make `make_examples` step much slower.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866205653:433,test,test,433,,https://github.com/google/deepvariant/issues/463#issuecomment-866205653,1,['test'],['test']
Testability,"Thanks @Suke-fudan for your update.; And thanks for reporting the confusing warning message.; In the next release, we plan to store the input shape for how each model is trained on, and we'll update our logging message to be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/488#issuecomment-964833815:203,log,logging,203,,https://github.com/google/deepvariant/issues/488#issuecomment-964833815,1,['log'],['logging']
Testability,"Thanks @akolesnikov and @pichuan . Please find the details and the error-log below. Please note that I have upgraded the following dependencies according to Tensorflow - 2.11. . DV_BAZEL_VERSION=""5.3.0""; DV_GCP_OPTIMIZED_TF_WHL_VERSION=""2.11.0""; ABSL_VERSION=20210324.2; PROTOBUF_VERSION=3.19.6. **Error log:** ; (03:11:57) ERROR: /opt/deepvariant/third_party/nucleus/io/BUILD:1051:11: Compiling third_party/nucleus/io/gfile.cc failed: (Exit 1): gcc failed: error executing command; (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \; exec env - \; PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \; PWD=/proc/self/cwd \; PYTHON_BIN_PATH=/usr/local/bin/python3 \; PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \; TF2_BEHAVIOR=1 \; /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-. Also, at an earlier point in the build, there is one more issue - . Download from https://mirror.bazel.build/github.com/bazelbuild/rules_cc/archive/081771d4a0e9d7d3aa0eed2ef389fa4700dfb23e.tar.gz failed: class java.io.FileNotFoundException GET returned **404 Not Found**",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/607#issuecomment-1418449705:73,log,log,73,,https://github.com/google/deepvariant/issues/607#issuecomment-1418449705,2,['log'],['log']
Testability,"Thanks @akolesnikov for responding! . I'm running Python `Python 2.7.15+`. This was on a fresh Ubuntu 14.4 install, using your default settings in DeepVariant v0.8/master and running `./build-prereq.sh` followed by `./build_and_test.sh`. What I'm confused by is that `bazel-bin/deepvariant/make_examples_test` runs and everything passes... ```; $ bazel-bin/deepvariant/make_examples_test; Running tests under Python 2.7.15: /usr/bin/python; ...; .; ----------------------------------------------------------------------; Ran 101 tests in 6.501s. OK; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/199#issuecomment-514034399:397,test,tests,397,,https://github.com/google/deepvariant/issues/199#issuecomment-514034399,2,['test'],['tests']
Testability,"Thanks @chrisfleisch for following up on this issue.; If I understand correctly, you're also talking specifically about the `call_variants` step, not the `make_examples` step, right?. I can try to see if I can get a AMD machine to test it out. I actually have not made any progress on this issue yet.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/274#issuecomment-597978325:231,test,test,231,,https://github.com/google/deepvariant/issues/274#issuecomment-597978325,1,['test'],['test']
Testability,"Thanks @dkurt ! ; I'll take a look next week and make sure I can incorporate the changes internally.; Can you confirm again that you're ok with us doing that? (I'll add a pointer to this PR when I make the internal change, so that the commit log will have the information. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/442#issuecomment-821760836:242,log,log,242,,https://github.com/google/deepvariant/pull/442#issuecomment-821760836,1,['log'],['log']
Testability,"Thanks @edg1983 ; Looking at your numbers. Comparing **v0.9.0** (slower) and **v0.9.0 OLD TEST ON 30X WGS**; 1. make_examples runtime: 290/198 = about 1.5 times; 2. #entries in VCF: 10784757/9096927 = about 1.2 times entries; 3. #entries in gVCF: 531371190/213244705 = about 2.5 times; 4. call_variants runtime: 1494/456 = about 3.3 times; 5. postprocess_variants runtime: 281/82 = about 3.4 times. My observations:; (1) gVCF entries is higher, which is not unexpected on lower coverage BAMs.; (2) The increase on call_variants runtime should be linear to the number of examples presented to the classifier, which should be roughly similar to the #entries in VCF. One reason this could change significantly is: if you end up having too many multi-allelic entries. I guess it is possible with lower coverage files, but I'm still surprised by this. I'll see if I can find some internal benchmarking runs to see if we observe this. This one is currently a surprise to me.; (3) The increase on postprocess_variants runtime - We know that lower coverage will increase gVCF entries and postprocess_variants runtime. Given that the #entries in gVCF has increased to 2.5 times, this number might not be unexpected here.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/346#issuecomment-700190764:90,TEST,TEST,90,,https://github.com/google/deepvariant/issues/346#issuecomment-700190764,2,"['TEST', 'benchmark']","['TEST', 'benchmarking']"
Testability,"Thanks @machomachopadre for your report. Just so I'm 100% clear, you've got python 2.7 and 3.5 on the machine, and our build-prereqs.sh script is installing some packages into python 3.5 and some into 2.7? I don't think we've been clear before about this, but DeepVariant is intended for python 2.7 only, as we've never tested it using python3. . Can you confirm that you can install DeepVariant on a clean Ubuntu 16 instance in the cloud?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/30#issuecomment-355031587:320,test,tested,320,,https://github.com/google/deepvariant/issues/30#issuecomment-355031587,1,['test'],['tested']
Testability,"Thanks @pgrosu !. Follow up with you @ruolin , ; I started a machine with:; `gcloud compute instances create --project OUR_PROJECT --zone us-west1-b --image-project ubuntu-os-cloud --image-family ubuntu-1804-lts --machine-type custom-64-131072 --min-cpu-platform ""Intel Skylake"" --boot-disk-size 300G pichuan-test-20210425`. which is a 64 core, 128 GB RAM machine, and the command finished running without any issue.; The command I ran was:. ```; sudo docker run \; -v /home/pichuan/pacbio-case-study/input/data:/input \; -v /home/pichuan/pacbio-case-study/output:/output \; google/deepvariant:1.1.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=/input/Homo_sapiens_assembly19.fasta \; --reads=/input/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam \; --output_vcf=/output/deepvariant.output.vcf.gz \; --output_gvcf=/output/deepvariant.output.g.vcf.gz \; --num_shards=64 \; --logging_dir=/output/logs \; --runtime_report --use_hp_information=true; ```. I can try another run with 20 cores, and I can also try with smaller disks to see if that would produce a similar issue. @ruolin let us know if you have any other ideas for us to reproduce this issue. I haven't tried Terra, but there's someone I can contact there for DeepVariant setup, feel free to let me know too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/446#issuecomment-826959857:309,test,test-,309,,https://github.com/google/deepvariant/issues/446#issuecomment-826959857,2,"['log', 'test']","['logs', 'test-']"
Testability,"Thanks @pgrosu for helping out!. One thing to note is that DeepVariant isn't tested on Mac, and it's not currently something that we officially support. But good to know that there seems to be workarounds. I'll keep this open for a bit longer in case @heznanda wants to follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1622159614:77,test,tested,77,,https://github.com/google/deepvariant/issues/657#issuecomment-1622159614,1,['test'],['tested']
Testability,"Thanks @pichuan :). Finally I got the root cause of this issue, it seem the return number of min on Ubuntu and RHEL are different. I tried to run the following commands on both python2:. The output of **Ubuntu** (on X86) is:; ```; >>> import mock; >>>; >>> expected_start=9; >>> expected_end=21; >>> bufsize=0; >>> expected_bases = 'A' * (expected_end - expected_start); >>>; >>> start=10; >>> end=21; >>> contig='20'; >>> ref_reader = mock.MagicMock(); >>> ref_reader.query.return_value = expected_bases; >>> contig_nbp = ref_reader.contig(contig).n_bases; >>> res = min(end + bufsize, contig_nbp); >>> res; 21; ```. And then I tried the same code on **RHEL 7.5 (both on X86 and Power**, the output is:. ```; >>> import mock; >>>; >>> expected_start=9; >>> expected_end=21; >>> bufsize=0; >>> expected_bases = 'A' * (expected_end - expected_start); >>>; >>> start=10; >>> end=21; >>> contig='20'; >>> ref_reader = mock.MagicMock(); >>> ref_reader.query.return_value = expected_bases; >>> contig_nbp = ref_reader.contig(contig).n_bases; >>> res = min(end + bufsize, contig_nbp); >>> res; <MagicMock name='mock.contig().n_bases' id='140373647899088'>; >>> int(res); 1; ```. And I accidentally run the above command with Python3, and it throw the following error:. ```; >>> res = min(end + bufsize, contig_nbp); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: '<' not supported between instances of 'MagicMock' and 'int'; ``` . So propose to fix the above type conversion if you have plan to support RHEL or upgrade to Python 3 in the future :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/154#issuecomment-464961152:242,mock,mock,242,,https://github.com/google/deepvariant/issues/154#issuecomment-464961152,5,['mock'],['mock']
Testability,"Thanks Luisa! It seems those s3 files aren't public:. wget http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; --2018-03-07 07:28:01-- http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; Resolving dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)... 52.218.52.113; Connecting to dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)|52.218.52.113|:80... connected.; HTTP request sent, awaiting response... 403 Forbidden; 2018-03-07 07:28:01 ERROR 403: Forbidden.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371184018:69,test,testfiles,69,,https://github.com/google/deepvariant/issues/52#issuecomment-371184018,6,['test'],['testfiles']
Testability,"Thanks Nima. I ran it again. Looks like the error is because it is unable to open the bed file I have provided. However, the bed file exists on gcp and my v0.6.1 code was able to access it. I am not sure what I am doing wrong. I was able to run the same code successfully if I provide the bed file in the example documentation (gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed). . Error file: gbsc-gcp-project-udn-dev-deep-variant/UDN668131_deepVariant_test4/deepvariant_staging_folder/logs/make_examples/0:. W::hts_idx_load2] The index file is older than the data file: /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bai; 2018-11-09 19:48:51.497793: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring: ; I1109 19:48:51.498179 140612532332288 genomics_reader.py:213] Reading /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bam with NativeSamReader; I1109 19:48:51.518172 140612532332288 make_examples.py:1075] Preparing inputs; [W::hts_idx_load2] The index file is older than the data file: /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bai; 2018-11-09 19:48:52.291229: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring: ; I1109 19:48:52.291625 140612532332288 genomics_reader.py:213] Reading /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bam with NativeSamReader; I1109 19:48:52.335163 140612532332288 make_examples.py:991] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']; [E::hts_open_format] **Failed to open file gs://gbsc-gcp-project-udn-dev-test/VCRome_2_1_hg19_capture_targets_chrStripped.bed**; Traceback (most recent call last):; File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/di",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/118#issuecomment-437503051:362,test,testdata,362,,https://github.com/google/deepvariant/issues/118#issuecomment-437503051,2,"['log', 'test']","['logs', 'testdata']"
Testability,"Thanks Paul for pointing this out,. The reason why I used Parabricks is to add optional parameters and run DeepVariant in one command. However based on what you said, I will run 3 steps (make_examples, call_variants and post_process_variants) separately so I can add optional parameters in `make_examples` step. While doing `call_variants` step, it generates a lot of errors. One of the error points out that `input depth must be evenly divisible by filter depth: 6 vs 7`. What does it mean?. I also attached the error log [error.log](https://github.com/google/deepvariant/files/12731863/error.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1736300897:519,log,log,519,,https://github.com/google/deepvariant/issues/706#issuecomment-1736300897,3,['log'],['log']
Testability,Thanks for bringing this to our attention!; I'm running our tests with `nvidia/cuda:12.1.1-cudnn8-devel-ubuntu20.04` now and will update here when I have confirmed whether it's working.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/676#issuecomment-1631277506:60,test,tests,60,,https://github.com/google/deepvariant/issues/676#issuecomment-1631277506,1,['test'],['tests']
Testability,"Thanks for clearing that up! I appreciate it. I did use hap.py to compare the customized model to the WGS model and it appears to have performed slightly worse, so I'll keep this in mind for future tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2038129909:198,test,tests,198,,https://github.com/google/deepvariant/issues/797#issuecomment-2038129909,1,['test'],['tests']
Testability,"Thanks for confirmation. I have done additional testings, and the conclusion is that the underlying htslib used in DeepVariant is the culprit. I have created a issue for my self to fix it (#119). Meanwhile, if it's possible please put your BED file into a public bucket and rerun DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-438403390:48,test,testings,48,,https://github.com/google/deepvariant/issues/116#issuecomment-438403390,1,['test'],['testings']
Testability,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/228#issuecomment-549166457:51,log,log,51,,https://github.com/google/deepvariant/issues/228#issuecomment-549166457,1,['log'],['log']
Testability,Thanks for the feedback and the good news about the model. I plan to get some WES data from Element for testing.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/703#issuecomment-1708558330:104,test,testing,104,,https://github.com/google/deepvariant/issues/703#issuecomment-1708558330,1,['test'],['testing']
Testability,"Thanks for the feedback. I went back to my files and just realized that my previous comment was inaccurate: the locus I analyzed on RNASeq was ""chr20:10,000,000-10,040,000""; the same exonic variant (chr20:10019093) was detected by both GATK and DeepVariant (WGS model) in my sample. As mentioned, I didn't do extensive tests at all (it was just that one locus) -- I'm happy to do further analysis if relevant,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/115#issuecomment-462075143:319,test,tests,319,,https://github.com/google/deepvariant/issues/115#issuecomment-462075143,1,['test'],['tests']
Testability,"Thanks for the help. So call variants only needs to be called once on all the shards at once, running on one GPU? Not individually once per shard? And under the hood it’s designed to recognize the tfrecord naming and numbering scheme as is described in the example wgs sh script? Given that the format is 000*-of-00064 do I have to specify this or does call variants assume that format and know how to find the 64 shards if they’re in the working directory? There’s a lot of regex going on I’d love to see documented (I guess maybe it’s in the codebase but if it could be explicitly written on the documentation that’d be awesome) — I understand that there is this cloud runner but considering these other components are exposed I feel like I don’t have a good sense of the way they should be appropriately called individually. . I’m hoping to set up a version of this in FireCloud using WDL as all of our workflows are currently set up in this way. It seems like I’m almost there — if I can’t figure it out then yes I will perhaps have to use the cloud runner. . > On Feb 6, 2019, at 11:57 PM, Nima Mousavi <notifications@github.com> wrote:; > ; > Can you verify TF examples (test.gvcf.tfrecord-*) are in ${BASE} path?; > ; > If you use DeepVariant's cloud runner, you won't need to do all these steps manually. It takes care of everything and runs the pipeline on GCP. See instruction here:; > ; > https://cloud.google.com/genomics/docs/tutorials/deepvariant; > ; > Is there any reason why you don't use cloud runner?; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461398822:1177,test,test,1177,,https://github.com/google/deepvariant/issues/151#issuecomment-461398822,1,['test'],['test']
Testability,Thanks for the pull request. I've updated this in our codebase and will point to this PR in the commit log.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/472#issuecomment-879985843:103,log,log,103,,https://github.com/google/deepvariant/pull/472#issuecomment-879985843,1,['log'],['log']
Testability,"Thanks for the quick reply, @pichuan . First of all, I followed the instructions in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md, but it gives the same error. 1. I got the image from ""docker://google/deepvariant:1.6.0"" I tried both: locally download the image and use the image without downloading. But they gave the same error.; 2. Follow the instructions in the link above to run the program. Here is the script that I used ; ```; #!/bin/bash. BIN_VERSION=""1.6.0"". INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}"". # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/746#issuecomment-1846470975:531,test,testdata,531,,https://github.com/google/deepvariant/issues/746#issuecomment-1846470975,2,['test'],['testdata']
Testability,"Thanks for the quick reply:; For me, make_examples.tfrecord@8.gz file is not generated and the following is the `make_examples.log` . ```{bash}; I0330 15:47:21.754682 140654028756736 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.756700 140654028756736 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.755398 140432560695040 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757477 140432560695040 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.770883 139863230490368 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.773075 139863230490368 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.754880 139747089467136 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.756903 139747089467136 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.754880 139944273491712 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757000 139944273491712 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.759158 140716713432832 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.761278 140716713432832 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.755259 140202003052288 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757451 140202003052288 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.765991 139705794897664 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.768276 139705794897664 errors.py:61] sample_name must be specified in calling mode.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/ref.fa --reads /input/sample.bam --examples /output/intermediate_results_dir/make_exa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/435#issuecomment-810383024:127,log,log,127,,https://github.com/google/deepvariant/issues/435#issuecomment-810383024,1,['log'],['log']
Testability,"Thanks for the quick response. This is the command and log file.; [stderr.log](https://github.com/google/deepvariant/files/14670380/stderr.log); ```; /opt/deepvariant/bin/run_deepvariant \; --model_type=~{model} \ ; --ref= ~{ref_fasta} \; --reads= ~{align_bam} \; --make_examples_extra_args=~{MAKE_EXAMPLE_ARGS} \; --output_vcf= ~{sampleID}.vcf.gz \; --output_gvcf= ~{output_file_name} \; --num_shards= ~{cpu_per_task} \; --haploid_contigs=""chrX,chrY"" \ ; --par_regions_bed= ~{par_bed} \ ; --postprocess_variants_extra_args=~{POSTPROCESS_VARIANTS_ARGS} \; --regions= ~{regions}```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/783#issuecomment-2010160828:55,log,log,55,,https://github.com/google/deepvariant/issues/783#issuecomment-2010160828,3,['log'],['log']
Testability,"Thanks for the update, @Stikus . In the code I'm working on, I currently changed that block to:; ```; # Because of an issue with pypi's numpy on Ubuntu 14.04. we need to compile from; # source.; # See https://github.com/tensorflow/tensorflow/issues/6968#issuecomment-279061085; if [[ ""$(lsb_release -d)"" == *Ubuntu*14.04.* ]]; then; echo ""Installing numpy with -no-binary=:all:. This will take a bit longer.""; pip3 install ""${PIP_ARGS[@]}"" --no-binary=:all: ""numpy==${DV_TF_NUMPY_VERSION}""; else; pip3 install ""${PIP_ARGS[@]}"" ""numpy==${DV_TF_NUMPY_VERSION}""; fi; ```. But I'm also wondering if I should just remove if/else statement for different Ubuntu versions if we're not internally testing it to make sure everything still runs. So I might end up simplifying this further in the next release. Glad to hear that the fix you mentioned above worked for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/394#issuecomment-742700347:688,test,testing,688,,https://github.com/google/deepvariant/issues/394#issuecomment-742700347,1,['test'],['testing']
Testability,"Thanks for the updates @fo40225 . We've also been communicating through emails. To give a quick update here: after a few internal testing, it seems like the current implementation of the async writer is missing records. We're still looking through this with @fo40225 . Hopefully it'll get resolved eventually. When we can confirm the results are consistent as before, we will be able to add this to our codebase.; Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/152#issuecomment-477842467:130,test,testing,130,,https://github.com/google/deepvariant/pull/152#issuecomment-477842467,1,['test'],['testing']
Testability,Thanks for your reminder @scott7z ; I ignored what you mentioned.; But for now I do not plan to make any further changes.; I've converted to a platform that supports AVX2 and completed a 'quick-start' test.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/16#issuecomment-352945209:201,test,test,201,,https://github.com/google/deepvariant/issues/16#issuecomment-352945209,1,['test'],['test']
Testability,Thanks for your reply and i will try DeepVariant v1.5.0 to benchmark the HG002 Revio data.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/641#issuecomment-1535591093:59,benchmark,benchmark,59,,https://github.com/google/deepvariant/issues/641#issuecomment-1535591093,1,['benchmark'],['benchmark']
Testability,"Thanks for your reply, but it didn't work. If I type --regions ""3:178936057-178936106"" --regions ""3:178952054-178952106"", then the deepvariant only accepts the second region as an input. I have also tried several ways, such as --regions=""3:178936057-178936106"" ""3:178952054-178952106"" , --regions=""3:178936057-178936106 3:178952054-178952106"", --regions=3:178936057-178936106 3:178952054-178952106, --regions=3:178936057-178936106 178952054-178952106, --regions ""3:178936057-178936106 178952054-178952106"", --regions ""3:178936057-178936106,178952054-178952106"", and none of them works. The log is attached here. Thanks a lot!; [problemetic logs with 'regions'.txt](https://github.com/google/deepvariant/files/4546376/problemetic.logs.with.regions.txt)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/305#issuecomment-620645675:590,log,log,590,,https://github.com/google/deepvariant/issues/305#issuecomment-620645675,3,['log'],"['log', 'logs']"
Testability,"Thanks nmousavi. I have the yaml file only for v0.6.1 and not for v_0.7.0. However, thanks for pointing toward workers log folder. This gives a better idea in debugging. Thanks,; Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/118#issuecomment-437461639:119,log,log,119,,https://github.com/google/deepvariant/issues/118#issuecomment-437461639,1,['log'],['log']
Testability,"Thanks paul for the detailed analysis and explanation of how you went about it. To confirm this analysis I tried out by changing TF_WHL_VERSION and other related symbols to 1.10.1 in settings.sh so that build-prereq.sh installs the matching tensorflow. Now, the build and test passes and I am able to run variant calling. I presume this is a good workaround to address this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/94#issuecomment-423268455:272,test,test,272,,https://github.com/google/deepvariant/issues/94#issuecomment-423268455,1,['test'],['test']
Testability,"Thanks!. בתאריך יום ב׳, 21 בנוב׳ 2022, 23:50, מאת Pi-Chuan Chang ‏<; ***@***.***>:. > Before you proceed, if you can't use Docker because of root permission, I; > recommend that you try Singularity:; > https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity; >; > If you don't have root permission, you won't be able to install necessary; > things before running the binaries either.; > ------------------------------; >; > Here is what I did:; >; > Get a machine. (Not required to run on GCP. I just use this to get a; > machine to test); >; > gcloud compute instances create ""${USER}-cpu"" --scopes; > ""compute-rw,storage-full,cloud-platform"" --image-family ""ubuntu-2004-lts""; > --image-project ""ubuntu-os-cloud"" --machine-type ""custom-64-131072""; > --boot-disk-size ""300"" --zone ""us-west2-b"" --min-cpu-platform ""Intel; > Skylake""; >; > ssh into the machine:; >; > gcloud compute ssh pichuan-cpu --zone us-west2-b; >; > Get the binaries and models:; >; > BUCKET=""gs://deepvariant""; > BIN_VERSION=""1.4.0""; > MODEL_VERSION=""1.4.0""; >; > BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}""; > MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard""; >; > mkdir -p bin; > # Download the DeepVariant binaries.; > gsutil -m cp ""${BIN_BUCKET}/*"" bin/; > chmod a+x bin/*; >; > Then, I ran:; >; > cd bin; bash run-prereq.sh; cd -; >; > The run-prereq.sh tends to be the most tricky one - it will require root; > permission, and it'll install a bunch of stuff on your machine. If you; > can't use Docker because of root permissions, you likely won't be able to; > run this as well.; >; > Download test data:; >; > INPUT_DIR=""${PWD}/quickstart-testdata""; > DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; >; > mkdir -p ${INPUT_DIR}; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566:578,test,test,578,,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566,1,['test'],['test']
Testability,"Thanks, @pichuan. Always happy to contribute to the open source community.; I ran twice the command with the new argument and in bot cases it failed :( the external hard drive where I have allocated the bam file got ejected and a; [output2.log](https://github.com/google/deepvariant/files/15167067/output2.log); lso I noticed that the syslog and kern.log became insanely big (~200GB), leaving me with no extra disk space.; Any ideas what might be going on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/810#issuecomment-2085656965:240,log,log,240,,https://github.com/google/deepvariant/issues/810#issuecomment-2085656965,3,['log'],['log']
Testability,"Thanks, just to followup: my `call_variants` step eventually finished after 1d2h31m. The last lines in my call_variants.log file read:. <pre>; 2018-10-17T14:30:33.396510159Z statfs 424901734400 available 4378992640 used 429280727040 total -- interval 10.0000 seconds 0 used; 2018-10-17T14:30:33.786897949Z I1017 14:30:33.786412 140161207068416 call_variants.py:359] Processed 10551585 examples in 329738 batches [0.904 sec per 100]; 2018-10-17T14:30:34.069377504Z I1017 14:30:34.068934 140161207068416 call_variants.py:359] Processed 10551617 examples in 329739 batches [0.904 sec per 100]; 2018-10-17T14:30:34.164880374Z I1017 14:30:34.164383 140161207068416 call_variants.py:359] Processed 10551649 examples in 329740 batches [0.904 sec per 100]; 2018-10-17T14:30:34.166325693Z I1017 14:30:34.166042 140161207068416 call_variants.py:361] Done evaluating variants; </pre>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/105#issuecomment-430723173:120,log,log,120,,https://github.com/google/deepvariant/issues/105#issuecomment-430723173,1,['log'],['log']
Testability,"That's good, but let's go a bit slower just to be sure each individual component is working properly. I'm not sure Bazel is working properly, so let's try the following steps:. 1) Complete these last steps of `clif`:. ```; sudo mkdir -p /usr/clang/bin/; sudo ln -sf /usr/local/bin/clif-matcher /usr/clang/bin/clif-matcher; sudo mkdir -p /usr/local/clif/bin; sudo ln -sf /usr/local/bin/pyclif* /usr/local/clif/bin/; DIST_PACKAGES_DIR=$(python3 -c ""import site; print(site.getsitepackages()[0])""); sudo ln -sf ""${DIST_PACKAGES_DIR}""/clif/python /usr/local/clif/; ```. 2) Let's troubleshoot `bazel`, as `bazel` is also a bit tricky to install. First do the following:. ``sudo mv /root/.bazel /root/.bazel-orig``; ``sudo mv /root/bin/bazel /root/bin/bazel-orig``. Could you try the following steps and let me know what you see -- it would be nice to run as sudo and not as root directly:. ```; rm .bazelrc; curl -L -O https://github.com/bazelbuild/bazel/releases/download/5.3.0/bazel-5.3.0-installer-linux-x86_64.sh; chmod +x bazel-*.sh; ./bazel-5.3.0-installer-linux-x86_64.sh --user > /dev/null; ```. When you run it and launch it, it should look something like this:. ```; $ ./bazel-5.3.0-installer-linux-x86_64.sh --user > /dev/null; Extracting Bazel installation...; Starting local Bazel server and connecting to it...; $ bazel; [bazel release 5.3.0]; Usage: bazel <command> <options> ... Available commands:; analyze-profile Analyzes build profile data.; aquery Analyzes the given targets and queries the action graph.; build Builds the specified targets.; canonicalize-flags Canonicalizes a list of bazel options.; clean Removes output files and optionally stops the server.; coverage Generates code coverage report for specified test targets.; cquery Loads, analyzes, and queries the specified targets w/ configurations.; ...; ```. Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577183377:1733,test,test,1733,,https://github.com/google/deepvariant/issues/657#issuecomment-1577183377,1,['test'],['test']
Testability,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/94#issuecomment-423408772:63,log,logs,63,,https://github.com/google/deepvariant/issues/94#issuecomment-423408772,1,['log'],['logs']
Testability,"The 12.1.1 base image did NOT work. I tested `nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04` instead, which did work correctly. . # Please use `nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/676#issuecomment-1634645510:38,test,tested,38,,https://github.com/google/deepvariant/issues/676#issuecomment-1634645510,1,['test'],['tested']
Testability,"The Bam file was downloaded from. ```; https://www.encodeproject.org/files/ENCFF528VXT/@@download/ENCFF528VXT.bam; ```. Then, since it was missing the @RG line, I added it manually just to test using picard:; ```; java -jar /picard.jar AddOrReplaceReadGroups I=ENCFF528VXT.bam O=ENCFF528VXT.bam RGID=4 RGLB=lib1 RGPL=illumina RGPU=unit1 RGSM=20; ```; The output of runninng; ```; samtools view -H ENCFF528VXT.bam; ```; is the following :; ```; @HD VN:1.5 SO:coordinate; @SQ SN:chr1 LN:249250621; @SQ SN:chr2 LN:243199373; @SQ SN:chr3 LN:198022430; @SQ SN:chr4 LN:191154276; @SQ SN:chr5 LN:180915260; @SQ SN:chr6 LN:171115067; @SQ SN:chr7 LN:159138663; @SQ SN:chr8 LN:146364022; @SQ SN:chr9 LN:141213431; @SQ SN:chr10 LN:135534747; @SQ SN:chr11 LN:135006516; @SQ SN:chr12 LN:133851895; @SQ SN:chr13 LN:115169878; @SQ SN:chr14 LN:107349540; @SQ SN:chr15 LN:102531392; @SQ SN:chr16 LN:90354753; @SQ SN:chr17 LN:81195210; @SQ SN:chr18 LN:78077248; @SQ SN:chr19 LN:59128983; @SQ SN:chr20 LN:63025520; @SQ SN:chr21 LN:48129895; @SQ SN:chr22 LN:51304566; @SQ SN:chrX LN:155270560; @SQ SN:chrY LN:59373566; @SQ SN:chrM LN:16571; @RG ID:4 LB:lib1 PL:illumina SM:20 PU:unit1; @PG ID:bwa PN:bwa VN:0.7.10-r789 CL:/usr/local/bin/bwa0.7.10 sampe -P reference_files/male.hg19.fa.gz ENCFF182MTO.sai ENCFF949NMY.sai ENCFF182MTO.fastq.gz ENCFF949NMY.fastq.gz; @PG ID:MarkDuplicates PN:MarkDuplicates VN:1.92() CL:net.sf.picard.sam.MarkDuplicates INPUT=[ENCFF182MTOENCFF949NMY.raw.srt.filt.srt.bam] OUTPUT=ENCFF182MTOENCFF949NMY.raw.srt.dupmark.bam METRICS_FILE=ENCFF182MTOENCFF949NMY.raw.srt.dup.qc REMOVE_DUPLICATES=false ASSUME_SORTED=true VALIDATION_STRINGENCY=LENIENT PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 READ_NAME_REGEX=[a-zA-Z0-9]+:[0-9]:([0-9]+):([0-9]+):([0-9]+).* OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 VERBOSITY=INFO QUIET=false COMPRESSION_LEVEL=5 MAX_RECORDS_I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371096675:189,test,test,189,,https://github.com/google/deepvariant/issues/52#issuecomment-371096675,1,['test'],['test']
Testability,"The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"") ; -- Checking for module 'protobuf'; -- Found protobuf, version 3.13.0; -- Checking for module 'libglog'; -- Found libglog, version 0.4.0; -- Looking for pthread.h; -- Looking for pthread.h - found; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed; -- Looking for pthread_create in pthreads; -- Looking for pthread_create in pthreads - not found; -- Looking for pthread_create in pthread; -- Looking for pthread_create in pthread - found; -- Found Threads: TRUE ; -- Found GTest: /usr/local/lib/cmake/GTest/GTestConfig.cmake (found version ""1.10.0"") ; -- Found PythonInterp: /usr/local/bin/python3 (found version ""3.8.10"") ; -- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.8.so (found version ""3.8.10"") ; -- Configuring done; -- Generating done; -- Build files have been written to: /root/clif/build; ```; which succeeded (and then proceed to the next step). @pioneer-pi , given that I can't reproduce this error, I'll need more information from you to understand why it failed. This is the step where your setup failed , but mine worked:. ```bash; root@pichuan-cpu:/home/pichuan/deepvariant# cd /root/clif/build; root@pichuan-cpu:~/clif/build# cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; ```. It'll be good to understand how/why it failed on your side. If you can provide more information there, I'm ha",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785:2694,Test,Test,2694,,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785,2,['Test'],['Test']
Testability,"The TF/Cuda/cuDNN versions being used may be incompatible with your GPU. A few questions for you:. * Does the quickstart without GPU run without errors? Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; * What OS are you running on?; * Command to reproduce your issue?; * Are you able to run TF + GPU separately from DeepVariant?; * Do older versions of DeepVariant run without errors? I recommend trying 1.0.0 or 0.10.0. We recommend using the latest version for best results, but this is just for debugging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/452#issuecomment-833796921:160,test,test,160,,https://github.com/google/deepvariant/issues/452#issuecomment-833796921,1,['test'],['test']
Testability,"The actual error is ""The TF examples in /mnt/data/input/gs/wgs-test-shan/test_samples/UDN689484temp/examples/examples_output.tfrecord-00000-of-00064.gz has image/format \'None\' (expected \'raw\') which means you might need to rerun make_examples to genenerate the examples again."". @pichuan @depristo this is odd since the pipeline ran as a single workflow. The model and docker binary paths also seem correct. One issue I can think of is most of the shards being empty (the output has 64 shards, but it's only 1.3KB in total). Do you know if empty shards could cause such an error?. P.S. the 'gsutil not found' error is actually harmless. I think we should provide a 'parser' for these errors based on the logs that provides a meaningful error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/27#issuecomment-355032456:63,test,test-shan,63,,https://github.com/google/deepvariant/issues/27#issuecomment-355032456,2,"['log', 'test']","['logs', 'test-shan']"
Testability,"The command I ran was on version 0.10.0; `sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/input/GRCh38_latest_genomic.fna --reads=/input/SOL235_sorted.bam --regions ""NC_000007.14"" --output_vcf=/output/SOL235output.vcf.gz --output_gvcf=/output/SOL235output.g.vcf.gz --num_shards=1 \ `. I am running deep variant on MacOS Catalina Version 10.15.4 (19E287); Attached you'll find the full dump of the terminal from running the above command all the way until it errors out. Thanks for your help!; [DeepVariantDump.log](https://github.com/google/deepvariant/files/4545525/DeepVariantDump.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/304#issuecomment-620560432:629,log,log,629,,https://github.com/google/deepvariant/issues/304#issuecomment-620560432,2,['log'],['log']
Testability,"The command for installing DeepVariant? . `singularity build DeepVariant_1.6.1.sif docker://google/deepvariant:1.6.1`. Or the full command that is written to stdout when DeepVariant runs? For this latter case, after installing nucleus the full command for deepvariant is not written to output. The last line of output is `KeyError: 'SerializedDType'`. I dont have the output saved from the test data run to retrieve the full command output with the error prior to installing nucleus as user, and will re-run that and update this comment with it in a few hours. I did, however, get the same error attempting to run deepvariant with my own data (prior to installing nucleus as user), and the output and command from that are below:. ```; for bam in $READS; do; 	echo ""running deepvariant on $bam""; 	run_deepvariant --model_type=PACBIO --ref=$REF --reads=$bam --output_vcf=$OUTDIR/$bam.vcf.gz --output_gvcf=$OUTDIR/$bam.g.vcf.gz --logging_dir=$LOGDIR --num_shards=$CORES; 	echo ""finished with $bam""; done. #output in block comment below. # running deepvariant on /work/cjm124/SWFst/VarCalling/reads/bc2001_aligned_sorted.bam; # 2024-04-23 11:42:51.281492: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; # To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; # I0423 11:42:57.943745 140073410221888 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmpkmab_2kw. # ***** Intermediate results will be written to /tmp/tmpkmab_2kw in docker. ****. # ***** Running the command:*****; # time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/work/cjm124/SWFst/lvar3ref/Lvar_scaffolds.fasta"" --reads ""/work/cjm124/SWFst/VarCalling/reads/bc2001_aligned_sorted.bam"" --examples ""/tmp/tmpkmab_2kw/make_example",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/812#issuecomment-2075116946:390,test,test,390,,https://github.com/google/deepvariant/issues/812#issuecomment-2075116946,2,"['LOG', 'test']","['LOGDIR', 'test']"
Testability,The error comes from the line `output_queue = multiprocessing.Queue()`; Could you try a simple test? ; Run docker in CLI model: `docker run -it <DeepVariant image> bash`; Inside docker start Python3 and execute:; ```; import multiprocessing; q = multiprocessing.Queue(); ```; Please let us know if that works.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/733#issuecomment-1816864777:95,test,test,95,,https://github.com/google/deepvariant/issues/733#issuecomment-1816864777,1,['test'],['test']
Testability,The following are full runner log. ; [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log); [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log); [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/70#issuecomment-387605005:30,log,log,30,,https://github.com/google/deepvariant/issues/70#issuecomment-387605005,7,['log'],['log']
Testability,"The full logs are attached for exit status 16 and 20: ; [Logs_deepvariant.txt](https://github.com/google/deepvariant/files/3801760/Logs_deepvariant.txt). I have found, that the Deepvariant works fine for the same .bam file, but with another target region .bed file (both are attached). Again, the target file that does not work for some samples, works fine for other samples. [Works_fine_Twist_Exome_Target.txt](https://github.com/google/deepvariant/files/3801765/Works_fine_Twist_Exome_Target.txt); [does_not_work_Trusight_one_bed.txt](https://github.com/google/deepvariant/files/3801766/does_not_work_Trusight_one_bed.txt)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/232#issuecomment-549153164:9,log,logs,9,,https://github.com/google/deepvariant/issues/232#issuecomment-549153164,1,['log'],['logs']
Testability,"The issue stems from a mismatch between the set of channels the model was trained on and the channels in the examples generated during `run_deepvariant`. The important bit in the logs you posted is:; ```; From /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_output/training_dir_test2/checkpoints/ckpt-58/example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6].; I0327 22:12:15.248034 139725850806080 dv_utils.py:365] From /local/scratch/haley.arnold/14698718/tmpg5h0cte0/make_examples.tfrecord-00000-of-00001.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; W0327 22:12:15.248203 139725850806080 call_variants.py:541] Input shape [100, 221, 7] and model shape [100, 221, 6] does not match.; W0327 22:12:15.248327 139725850806080 call_variants.py:549] Input channels [1, 2, 3, 4, 5, 6, 19] and model channels [1, 2, 3, 4, 5, 6] do not match.; ```. Your customized model was trained on `[1, 2, 3, 4, 5, 6]` (the `BASE_CHANNELS`) but the examples in `make_examples.tfrecord-00000-of-00001.gz` have an extra channel, 19 (`insert_size`), which gets [added to the WGS model preset](https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L369). . You can either:; a) include `--channels ""insert_size""` when [generating the training data](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#training-set); b) don't set `--model_type WGS` when you call `run_deepvariant` (which you may not need to do regardless if you provide a `customized_model`). . The choice comes down to if you want to include the channel or not. Experiments have shown it provides a slight accuracy boost for WGS, but its not strictly necessary.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2027543371:179,log,logs,179,,https://github.com/google/deepvariant/issues/797#issuecomment-2027543371,1,['log'],['logs']
Testability,"The parameter (see the flags at the top of make_examples.py) is ""realign_reads"", and the way to set it to false is to pass `--norealign_reads`. As stated in the usage you quoted above, reads longer than 500 bp are never realigned (this was added in v1.0). We still add `--norealign_reads` to PacBio runs, but if you forget to add it, there's likely not a big difference since very few pacbio reads will be below 500 bp. If you want to try a shorter run before the full one to test your setup, you can always run DeepVariant all the way through with a small region, like `--regions ""chr20:10,000,000-10,010,000""`, which should only take a few minutes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/437#issuecomment-816788129:476,test,test,476,,https://github.com/google/deepvariant/issues/437#issuecomment-816788129,1,['test'],['test']
Testability,"These mostly run on nodes with Intel Xeon Gold 6140, occasionally on Intel Xeon E5-2697v4, but these are much slower anyway. . I had noticed the same speed improvement in v1.1.0 with openvino as your metrics, but I haven't tested the new version extensively with and without. However, when rerunning identical samples (both with openvino flags), I've noticed that v1.2.0 takes longer wall clock time compared to v1.1.0, but less CPU time. Maybe it is just node variation or other jobs bottlenecking IO, so hopefully will see a clearer result after more samples run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/416#issuecomment-889821634:223,test,tested,223,,https://github.com/google/deepvariant/issues/416#issuecomment-889821634,1,['test'],['tested']
Testability,"This directory here contains `dockerfile` and other files that need to be `ADD` to the image; ![image](https://user-images.githubusercontent.com/25972546/33970607-df14b3b2-e0ae-11e7-8aea-0509ae0c9c61.png); `docker build -f dockerfile -t deepvariant_1214 .`; `Successfully built b829b45a9401`. This directory contains the deepvariant `models` and `quickstart-testdata` files downloaded from [https://console.cloud.google.com/storage/browser/deepvariant](url); ![image](https://user-images.githubusercontent.com/25972546/33970996-1a4e378a-e0b1-11e7-8852-9b63cb477f47.png); `docker run --name deepvariant_test_1214 -v /***/bioinfo/wangwd/workflow/deepvariant/data:/data -it b829b45a9401 /bin/bash`; Then I `cd /opt/deepvariant/bin/`; ![image](https://user-images.githubusercontent.com/25972546/33971209-4789bc8c-e0b2-11e7-833c-95f440712240.png); `./make_examples \; --mode calling \; --ref /data/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \; --reads /data/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --examples /data/quickstart-output/examples.tfrecord.gz`; When I finished executing this command, I did not get any result.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/16#issuecomment-351583972:358,test,testdata,358,,https://github.com/google/deepvariant/issues/16#issuecomment-351583972,3,['test'],['testdata']
Testability,"This seems to run fine when using the following script:; ```; #!/bin/sh. BIN_VERSION=""1.0.0""; INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". singularity -s exec --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \; --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/402#issuecomment-756252754:123,test,testdata,123,,https://github.com/google/deepvariant/issues/402#issuecomment-756252754,1,['test'],['testdata']
Testability,"To make it clearer, I put the path structure here.; ```; /deepvariant/core/; cloud_utils_test.py; math.py; ...; ```; And in `cloud_utils_test.py`:; ```; """"""Tests for deepvariant .core.cloud_utils."""""". from __future__ import absolute_import; from __future__ import division; from __future__ import print_function. import httplib; ...; ```; Through `httplib`, it imports `mimetools`, which imports `tempfile`, which imports `ramdom`, which imports `math`. ; But since there is a `math.py` in the same path, it shadows the `math` module in python's standard library, causing an error. To test the hypothesis, simply importing `httplib` in the same path caused the following error:; ```; >>> import httplib; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""xx/anaconda/envs/Python27/lib/python2.7/httplib.py"", line 80, in <module>; import mimetools; File ""xx/anaconda/envs/Python27/lib/python2.7/mimetools.py"", line 6, in <module>; import tempfile; File ""xx/anaconda/envs/Python27/lib/python2.7/tempfile.py"", line 35, in <module>; from random import Random as _Random; File ""xx/anaconda/envs/Python27/lib/python2.7/random.py"", line 45, in <module>; from math import log as _log, exp as _exp, pi as _pi, e as _e, ceil as _ceil; ***File ""math.py"", line 79, in <module>***; import numpy as np; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>; from . import add_newdocs; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/add_newdocs.py"", line 13, in <module>; from numpy.lib import add_newdoc; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/lib/__init__.py"", line 8, in <module>; from .type_check import *; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/lib/type_check.py"", line 11, in <module>; import numpy.core.numeric as _nx; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/core/__init__.py"", line 74, in <module>; from numpy.testing.nosetester impo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/32#issuecomment-355522771:156,Test,Tests,156,,https://github.com/google/deepvariant/issues/32#issuecomment-355522771,2,"['Test', 'test']","['Tests', 'test']"
Testability,"Update: I've done some investigation, and I think we need to change the logic in make_examples, specifically somewhere around here:. https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/variant_caller.py#L207-L230. I've done a prototype but the behavior isn't quite what I expected yet. I'll continue to work on this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/811#issuecomment-2297681816:72,log,logic,72,,https://github.com/google/deepvariant/issues/811#issuecomment-2297681816,1,['log'],['logic']
Testability,"Updating my previous response a bit. Could you share the output of the two echo commands below? I want to make sure there aren't any subtle differences with how quoting is done between both sets of commands. I don't immediately see what else could be causing this issue. Thanks!. ```; BIN_VERSION=""1.0.0""; INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". echo ""singularity run --cleanenv -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1"". echo ""singularity -s exec --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \; --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz""; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/402#issuecomment-757012167:335,test,testdata,335,,https://github.com/google/deepvariant/issues/402#issuecomment-757012167,1,['test'],['testdata']
Testability,"V_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled; # fix ""ImportError: No module named google.protobuf"" by install protobuf from source; bazel clean; bazel shutdown; bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \; --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \; --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \; --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \; --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \; --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &; bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only; bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary; bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; echo 'Expect a usage message:'; (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; ```. ## Fix DV Error. ```bash; ################################################################################; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test; # use lscpu to show the actual CPU number; ################################################################################; python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160; python -c ""import psutil;print(p/sutil.cpu_count; ())"" #160. vim deepvariant/resources.py; --------------------------------; def _get_cpu_count():; """"""Gets the number of physical ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:19389,test,test,19389,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,1,['test'],['test']
Testability,"Versions; - singularity version 3.6.4-1.el7; - CentOS Linux release 7.9.2009; - Kernel: Linux 3.10.0-1160.6.1.el7.x86_64. The command I was running has some differences in the singularity setup, as I had to explicitly bind the scratch directory etc on the compute nodes. When running the command that **did** work for you, I get the following error immediately `OSError: [Errno 30] Read-only file system: '/output'`, due to the binding issue.; ; ```; singularity run -B ${INPUT}:/input,${OUTPUT}:/output,${OUTPUT}/intermediate_results_dir:/output/intermediate_results_dir,$TMPDIR:$TMPDIR \; deepvariant_1.1.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type ""PACBIO"" \; --ref /input/asm.fasta \; --reads /input/hifi.bam \; --output_vcf /output/asm.output.vcf.gz \; --output_gvcf /output/asm.output.g.vcf.gz \; --num_shards ""${THREADS}"" \; --call_variants_extra_args ""use_openvino=true"" \; --intermediate_results_dir /output/intermediate_results_dir; ```. This correctly makes the examples and saves the results to the *intermediate_results_dir*, the error happens at the start of call_variants, when the openvino model wants to write to the read-only container. I tried making a `models/pacbio` file and dowloaded the ckpt files, and then made a bind to `opt/models/pacbio/`, but also same error on the read only system. I've also tried running the `bin/call_variants` command from the login nodes and ran into the same error, which was surprising as I have write permissions to more locations on those nodes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-762181198:1397,log,login,1397,,https://github.com/google/deepvariant/issues/404#issuecomment-762181198,1,['log'],['login']
Testability,We added a note about needing the `gsutil` from Google Cloud SDK to our [Build and Test guide](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md). Let us know if you are still having issues.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/5#issuecomment-350478903:83,Test,Test,83,,https://github.com/google/deepvariant/issues/5#issuecomment-350478903,2,"['Test', 'test']","['Test', 'test']"
Testability,"We are using singularity 3.5.2 and the image was obtained with this command:. singularity pull docker://gcr.io/deepvariant-docker/deepvariant:0.9.0. We have a wrapper script that we use with deepvariant-0.8.0 to submit to the CentOS 7 based compute cluster without issue and it is used with v0.9.0 with the only change being the version of deepvariant. Also I opened a shell on the 0.9.0 image and ran 'pip freeze | grep intervaltree' and got this version:; ; intervaltree==2.1.0. This is the submit script without the SLURM commands:; ```; export BIN_VERSION=""0.9.0""; export BASE=""${PWD}/deepvariant-run""; export INPUT_DIR=""${BASE}/input""; export REF=""hs37d5.fa.gz""; export BAM=""HG002_NIST_150bp_chr20_downsampled_30x.bam""; export OUTPUT_DIR=""${BASE}/output""; export DATA_DIR=""${INPUT_DIR}/data""; export OUTPUT_VCF=""HG002.output.vcf.gz""; export OUTPUT_GVCF=""HG002.output.g.vcf.gz"". mkdir -p ""${OUTPUT_DIR}""; mkdir -p ""${INPUT_DIR}""; mkdir -p ""${DATA_DIR}"". gsutil cp gs://deepvariant/performance-testdata/""${BAM}"" ""${DATA_DIR}""; gsutil cp gs://deepvariant/performance-testdata/""${BAM}"".bai ""${DATA_DIR}"". cd /scratch/rsmith/DeepvariantTests/case-study/; module load deepvariant/0.9.0-gpu-phoenix. run_deepvariant --model_type=WGS --ref=""/input/data/${REF}"" \; --reads=""${DATA}/input/data/${BAM}"" \; 	 --output_vcf=/output/${OUTPUT_VCF} \; --output_gvcf=/output/${OUTPUT_GVCF} \; --regions 20 --num_shards=$(nproc). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/255#issuecomment-568131537:997,test,testdata,997,,https://github.com/google/deepvariant/issues/255#issuecomment-568131537,2,['test'],['testdata']
Testability,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****; time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s; user 0m0.767s; sys 0m0.949s; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-482956117:737,test,testdata,737,,https://github.com/google/deepvariant/issues/132#issuecomment-482956117,2,['test'],['testdata']
Testability,"We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors. If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)? If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.; In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed. <!-- need_author_cla -->",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/125#issuecomment-445377405:278,log,login,278,,https://github.com/google/deepvariant/pull/125#issuecomment-445377405,1,['log'],['login']
Testability,"We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s). If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)? If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.; In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed. <!-- need_author_cla -->",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/55#issuecomment-371302921:260,log,login,260,,https://github.com/google/deepvariant/pull/55#issuecomment-371302921,2,['log'],['login']
Testability,"We use the testdata from DeepVariant source (https://github.com/google/deepvariant/tree/r0.6/deepvariant/testdata) .The test_nist.b37_chr20_100kbp_at_10mb.bed is really small, so we just can set one example in that examples.tfrecord.gz. . **test_nist.b37_chr20_100kbp_at_10mb.bed file:**; > chr20	10000846	10002407; chr20	10002520	10004171; chr20	10004273	10004964; chr20	10004994	10006386; chr20	10006409	10007800; chr20	10007824	10008018; chr20	10008043	10008079; chr20	10008100	10008707; chr20	10008808	10008897; chr20	10009002	10009791; chr20	10009933	10010531. We will try to train model with our realistic WES data, and set with at least 10,000 examples. Thanks",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/69#issuecomment-386202451:11,test,testdata,11,,https://github.com/google/deepvariant/issues/69#issuecomment-386202451,2,['test'],['testdata']
Testability,"We've started testing DeepVariant on a machine with 128 cores from AMD. Setting --num_shards=$(nproc) results in this error:. > OpenBLAS blas_thread_init: RLIMIT_NPROC 4096 current, 8254915 max; > OpenBLAS blas_thread_init: pthread_create failed for thread 63 of 64: Resource temporarily unavailable. It seems to create way more threads than the machine can handle. Setting num_shards=40 will work on the AMD machine, but the number of shards it creates is variable and much more than 40. I've seen 81, 116, and 101 intermediate shards created. From what I remember, in all our previous usage on machines with 40 cores or less the number of shards always matched the number of cores when using num_shards=$(nproc). The AMD machine with num_shards=40 also runs much slower compared to our Skylake machines with 40 cores and num_shards=$(nproc). The AMD machine takes over 7 hours per WGS file compared to less then 5 hours with the Skylake machine. It looks like when we try to run on the AMD machine it creates 2x as many tasks than available processors which might explain the slowdown.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/274#issuecomment-597715853:14,test,testing,14,,https://github.com/google/deepvariant/issues/274#issuecomment-597715853,1,['test'],['testing']
Testability,"Yeah, but @pichuan folks will then ask the obvious question of what would be the right number of shards to get the correct variant calls. Probably some validation tests might be required with comparative benchmarks that show consistent predictability. I'm sure you guys have done some of this already, which would be nice if it could be shared for optimally configuration of the settings. Ideally it's something that users can then replicate themselves, in order to run verification tests at different granular stages of the DeepVariant workflow - and would be compared to validated metrics for proper evaluation - just to convince the users all is working properly.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/112#issuecomment-433250645:163,test,tests,163,,https://github.com/google/deepvariant/issues/112#issuecomment-433250645,3,"['benchmark', 'test']","['benchmarks', 'tests']"
Testability,"Yes, I definitely got each pbtxt file. Attached below are the log files from the model train step. When I ran this step before (when I had not used the --channels flag, and could not test the model), the .err file for the model training step looked as though it reached a stopping point, whereas in this run it looks like it simply stopped and did not reach that same point. It's definitely not a timeout issue, but I'm not sure what's causing it. . The pbtxt file for the validation set (training set looks similar) looks like this:; ```; # Generated by shuffle_tfrecords_beam.py; #; # --input_pattern_list=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_output/validation_set.with_label_channlesize.tfrecord.gz; # --output_pattern_prefix=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_output/validation_set.with_label_channelsize.shuffled; #. name: ""Chromosome3""; tfrecord_path: ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_output/validation_set.with_label_channelsize.shuffled-?????-of-?????.tfrecord.gz""; num_examples: 35759; # class1: 27257; # class0: 1777; # class2: 6725; ```; And here are the log files from the attempted model training: ; [deepvariant_modeltrain-14705863-Atlas-0031.err.txt](https://github.com/google/deepvariant/files/14828238/deepvariant_modeltrain-14705863-Atlas-0031.err.txt); [deepvariant_modeltrain-14705863-Atlas-0031.out.txt](https://github.com/google/deepvariant/files/14828239/deepvariant_modeltrain-14705863-Atlas-0031.out.txt). Thank you for your help!. Best, ; Haley",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2030499725:62,log,log,62,,https://github.com/google/deepvariant/issues/797#issuecomment-2030499725,3,"['log', 'test']","['log', 'test']"
Testability,"Yes, I was having the same issue using the old version 0.4.1, when I change to 0.5.1:; ```; gcr.io/deepvariant-docker/deepvariant:0.5.1; ```. I get this error instead:; ```; WARNING: Logging before flag parsing goes to stderr.; W0307 21:19:10.482634 140039107020544 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib; W0307 21:19:10.488955 140039107020544 call_variants.py:299] Unable to read any records from shardedExamples/examples.tfrecord@64.gz. Output will contain zero records.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/call_variants.py"", line 391, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run; _sys.exit(main(_sys.argv[:1] + flags_passthrough)); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/call_variants.py"", line 382, in main; batch_size=FLAGS.batch_size); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/call_variants.py"", line 317, in call_variants; predictions = model.create(images, 3, is_training=False)['Predictions']; File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/genomics/deepvariant/modeling.py"", line 360, in create; images, num_classes, create_aux_logits=False, is_training=is_training); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/org_tensorflow_slim/nets/inception_v3.py"", line 483, in inception_v3; depth_multiplier=depth_multiplier); File ""/tmp/Bazel.runfiles_i7Wypy/runfiles/org_tensorflow_slim/nets/inception_v3.py"", line 104, in inception_v3_base; net = slim.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 181, in func_with_args; return func(*args, **current_args); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1011, in convolution; input_rank); ValueError: ('Co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371288942:183,Log,Logging,183,,https://github.com/google/deepvariant/issues/52#issuecomment-371288942,1,['Log'],['Logging']
Testability,"Yes, sorry about the blunt message. I ran deepvariant with a subset of my data to test. All right with the outputs, but I cannot visualize the visual_report.html. I have the file, but when I open with chrome or firefox nothing is show. I changed the permissions of the files, didn't help. I even tried to generate again usin the just the VCF stats report alone using as input the vcf file generated by DV. This is how I set the commands:. BIN_VERSION=""1.0.0""; BASE=""${PWD}/deepvariant-run""; INPUT_DIR=""${BASE}/input""; REF=""10consensus.fasta""; BAM=""268_041_m10.sorted.bam""; OUTPUT_DIR=""${BASE}/output""; DATA_DIR=""${INPUT_DIR}/data""; OUTPUT_VCF=""M10.output.vcf.gz""; OUTPUT_GVCF=""M10.output.g.vcf.gz""; mkdir -p ""${OUTPUT_DIR}""; mkdir -p ""${INPUT_DIR}""; mkdir -p ""${DATA_DIR}"". sudo docker run --gpus 1 \; -v ""${DATA_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""/input/${REF}"" \; --reads=""/input/${BAM}"" \; --output_vcf=/output/${OUTPUT_VCF} \; --output_gvcf=/output/${OUTPUT_GVCF} \; --intermediate_results_dir /output/intermediate_results_dir \; --num_shards=32. [output.visual_report.zip](https://github.com/google/deepvariant/files/5265027/output.visual_report.zip). Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/290#issuecomment-697073304:82,test,test,82,,https://github.com/google/deepvariant/issues/290#issuecomment-697073304,1,['test'],['test']
Testability,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from ; using the local libraries? . ```; INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>; from tensorflow.core.framework import function_pb2; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>; from google.protobuf import descriptor as _descriptor; File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>; from google.protobuf.internal import api_implementation; File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>; from google.protobuf.pyext import _message; TypeError: bases must be types; INFO: Cleaning up image...; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/580#issuecomment-1304645106:15,log,log,15,,https://github.com/google/deepvariant/issues/580#issuecomment-1304645106,2,"['log', 'sandbox']","['log', 'sandbox']"
Testability,"Yes, you can't do that with bazel - it doesn't allow you to do absolute path operations like that in general due to their approach to sandboxing / hermetic builds. I suspect moving CLIF to the expected location may fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/12#issuecomment-351271748:134,sandbox,sandboxing,134,,https://github.com/google/deepvariant/issues/12#issuecomment-351271748,1,['sandbox'],['sandboxing']
Testability,"You are right, there is no motivation to move this into a separate thread due current logging is already optimal! Benchmarked master and proposed branches and there is no time difference between them. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/393#issuecomment-743129654:86,log,logging,86,,https://github.com/google/deepvariant/pull/393#issuecomment-743129654,2,"['Benchmark', 'log']","['Benchmarked', 'logging']"
Testability,"You are totally right! I should have tested it before creating an issue... I also tested DeepVariant using `cram` and `crai` index files and it worked also. Maybe that information could be explicitly added to the documentation to prevent other (lazy) users to report same ""issues"". Thanks a million!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/481#issuecomment-920082344:37,test,tested,37,,https://github.com/google/deepvariant/issues/481#issuecomment-920082344,2,['test'],['tested']
Testability,"You need to specify all the variable in the same script. For example:. ```; #!/usr/bin/zsh; BIN_VERSION=""0.8.0""; INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=1; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/195#issuecomment-509390976:142,test,testdata,142,,https://github.com/google/deepvariant/issues/195#issuecomment-509390976,2,['test'],['testdata']
Testability,"[300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_gvcf_output.g.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.vcf_candidate_importer.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00001-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_single_site_output.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/HG002_ONT_deeptrio.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/golden.vcf_candidate_importer.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/alt_aligned_pileup.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 199, 8], ""channels"": [1, 2, 3, 4, 5, 6, 9, 10]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00001-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./Dockerfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040:3573,test,testdata,3573,,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040,1,['test'],['testdata']
Testability,"[log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt); Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:; 1. gcc version 4.8.5; 2. centos 7; 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly.; 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you; Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/94#issuecomment-422487671:100,log,log,100,,https://github.com/google/deepvariant/issues/94#issuecomment-422487671,1,['log'],['log']
Testability,"\; bash -x; ```. Here's the version:; ```; pichuan@pichuan-test-speed:~$ singularity --version; singularity version 3.7.0; ```. I followed:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-exome-case-study.md; to download the data. And then:. ```; mkdir -p output; mkdir -p output/intermediate_results_dir. # Pull the image.; BIN_VERSION=1.1.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref reference/GRCh38_no_alt_analysis_set.fasta \; --reads input/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions input/idt_capture_novogene.grch38.bed \; --output_vcf output/HG003.output.vcf.gz \; --output_gvcf output/HG003.output.g.vcf.gz \; --num_shards $(nproc) \; --intermediate_results_dir output/intermediate_results_dir 2>&1 | tee /tmp/all.log; ```. I'll paste part of the log of each step so that you can compare. ## make_examples; make_examples speed is roughly:; ```; I0622 21:19:25.373434 140610510067456 make_examples.py:648] Task 7/8: 4900 candidates (5187 examples) [27.99s elapsed]; I0622 21:19:35.260825 139809239041792 make_examples.py:648] Task 1/8: 4809 candidates (5065 examples) [32.79s elapsed]; I0622 21:19:37.868103 139727062120192 make_examples.py:648] Task 2/8: 4900 candidates (5208 examples) [37.92s elapsed]; I0622 21:19:37.739557 139786800707328 make_examples.py:648] Task 6/8: 5100 candidates (5441 examples) [29.08s elapsed]; I0622 21:19:44.484720 140667007305472 make_examples.py:648] Task 5/8: 4902 candidates (5241 examples) [37.78s elapsed]; ```. Here are the last few lines from the log:; ```; I0622 21:24:34.005878 140667007305472 make_examples.py:648] Task 5/8: Created 6240 examples; I0622 21:24:38.061186 139897026688768 make_examples.py:648] Task 4/8: 5906 candidates (6318 examples) [17.72s elapsed]; I0622 21:24:43.683619 140528910345984 make_ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866352316:1699,log,log,1699,,https://github.com/google/deepvariant/issues/463#issuecomment-866352316,1,['log'],['log']
Testability,"](#vfootnote6)</sup>9 HG001, 7 HG002, 7 HG003, 7 HG004, 8 HG005, 8 HG006, 8 HG007, 9 NA12891, 9 NA12892 | 27,783,324 |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | <sup>[(6)](#vfootnote6)</sup>6 HG002, 6 HG003, 6 HG004, 8 HG005, 8 HG006, 8 HG007 | 13,039,595 |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 9 HG002, 5 HG003, 5 HG004, 1 HG005, 1 HG006, 1 HG007 | 890,016,014<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 9 HG002, 5 HG003, 5 HG004, 1 HG005, 1 HG006, 1 HG007 | 838,515,085<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 1 HG002, 1 HG002, 1 HG004 | 50,249,704<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 1 HG002, 1 HG002, 1 HG004 | 99,675,190<sup>[(5)](#vfootnote5)</sup> |; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/HG002_ONT_deeptrio.denovo.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/customized_classes.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_gvcf_output.g.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.vcf_candidate_importer.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00000-of-00003.example_info.json:{""ver",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040:2144,test,testdata,2144,,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040,1,['test'],['testdata']
Testability,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,; ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3); 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false); 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154); 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1659358917:3963,log,login,3963,,https://github.com/google/deepvariant/issues/682#issuecomment-1659358917,1,['log'],['login']
Testability,"_DIR}/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/agilent_sureselect_human_all_exon_v5_b37_targets.bed; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz.fai; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz.gzi; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gzi; ```. Then, I ran `make_examples` similar to the way you did in your original post:; ```; ## Run `make_examples`; ( time seq 0 $((N_SHARDS-1)) | \; parallel -k --line-buffer \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""hs37d5.fa.gz"" \; --reads ""151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam"" \; --examples ""HG002.examples.tfrecord@${N_SHARDS}.gz"" \; --regions ""agilent_sureselect_human_all_exon_v5_b37_targets.bed"" \; --gvcf ""HG002.gvcf.tfrecord@${N_SHARDS}.gz"" \; --task {} \; ) 2>&1 | tee ""make_examples.log""; ```; This took on 13m33.192s a 64-core, 128GB RAM machine. Before I proceeded with call_variants, I first checked that the output files from make_examples exist:; ```; ls HG002.examples.tfrecord*.gz | wc -l; ```; I see 64 of them here.; A common issue is that if the make_examples step failed but you didn't notice, then the next step will fail.; Common failure modes I've seen before:; - if you were running make_examples, but abort in the middle by ctrl-c. Sometimes not all the make_examples in the background were killed. If you just re-run make_examples without killing all background make_examples first, the output might be corrupted.; - if make_examples failed completely without outputting HG002.examples.tfrecord*.gz at all, it'll also cause a failure. Our hope is that you'll notice this in the errors that make_examples displayed. If you're creating some kind of workflow yourself, you will need to make sure you check the error code of the runs. If make_examples died, you shouldn't proceed with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:3482,log,log,3482,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,1,['log'],['log']
Testability,"_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}"". # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1; ```. And I did same things as you to check the versions. ```; singularity --version; singularity version 3.8.5-2.el7. uname -a; Linux sumner098 3.10.0-1062.1.2.el7.x86_64 #1 SMP Mon Sep 30 14:19:46 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. singularity exec deepvariant_1.6.0.sif pip freeze | grep numpy; numpy==1.22.1. singularity shell -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.0; Singularity> python -c ""import numpy; print(numpy.__version__)""; 1.22.1; Singularity> python3 -c ""import numpy; print(numpy.__version__)""; 1.22.1. singularity exec --bind ${PWD}/quickstart-testdata/,${PWD}/quickstart-output/,/usr/lib/locale/:/usr/lib/locale/ deepvariant_1.6.0.sif python -c ""import numpy; print(numpy.__version__)""; 1.22.1; ```. Thanks a lot!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/746#issuecomment-1846470975:2689,test,testdata,2689,,https://github.com/google/deepvariant/issues/746#issuecomment-1846470975,1,['test'],['testdata']
Testability,"_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions; ranges.RangeSet.from_regions(regions_to_include, contig_dict)); File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions; return cls(ranges=from_regions(regions, contig_map=contig_map)); File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__; for i, range_ in enumerate(ranges):; File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions; for elt in reader(region):; File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser; with bed.BedReader(filename) as fin:; File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader; return NativeBedReader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__; self._reader = bed_reader.BedReader.from_file(bed_path, options); ValueError: OUT_OF_RANGE: EOF; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. real	0m9.092s; user	0m3.463s; sys	0m0.757s. I use the case study with all test files(https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md) put in it and now I remove the space that you tell me about this , what is the problem ?; @danielecook",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1303761079:3361,test,test,3361,,https://github.com/google/deepvariant/issues/581#issuecomment-1303761079,1,['test'],['test']
Testability,"_docker.sh example is actually different from the make_examples command you posted first. If you're using that, you need to make sure you're using the [-v flags](https://docs.docker.com/storage/volumes/) correctly and make sure the files are visible to it. (3) I tested with `sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.2` first and directly running the commands inside. I modified from the WES example because it's faster, but WGS should be the same. I can confirm that I was able to run the following steps without any issues:. 1. Start interactive mode so I can use command similar to yours. I'm not considering how I'm getting the data out.; ```; sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.2; ```. 2. Inside the interactive mode, run the following:; ```; MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wes_standard""; DATA_HTTP_DIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata; N_SHARDS=""64"". ## Download extra packages; sudo apt-get -y update; sudo apt-get -y install parallel; sudo apt-get -y install aria2; ## Download models, and test data; # Copy the model files to your local disk.; aria2c -c -x10 -s10 ""${MODEL_HTTP_DIR}""/model.ckpt.data-00000-of-00001; aria2c -c -x10 -s10 ""${MODEL_HTTP_DIR}""/model.ckpt.index; aria2c -c -x10 -s10 ""${MODEL_HTTP_DIR}""/model.ckpt.meta. # Copy the data; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/agilent_sureselect_human_all_exon_v5_b37_targets.bed; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz.fai; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz.gzi; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:1906,test,testdata,1906,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,1,['test'],['testdata']
Testability,_examples_to_vcf_test/test.log; //deepvariant/labeler:positional_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log; //deepvariant/labeler:variant_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log; //deepvariant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_ev,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:121355,log,log,121355,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"_future__ import absolute_import; from __future__ import division; from __future__ import print_function. import httplib; ...; ```; Through `httplib`, it imports `mimetools`, which imports `tempfile`, which imports `ramdom`, which imports `math`. ; But since there is a `math.py` in the same path, it shadows the `math` module in python's standard library, causing an error. To test the hypothesis, simply importing `httplib` in the same path caused the following error:; ```; >>> import httplib; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""xx/anaconda/envs/Python27/lib/python2.7/httplib.py"", line 80, in <module>; import mimetools; File ""xx/anaconda/envs/Python27/lib/python2.7/mimetools.py"", line 6, in <module>; import tempfile; File ""xx/anaconda/envs/Python27/lib/python2.7/tempfile.py"", line 35, in <module>; from random import Random as _Random; File ""xx/anaconda/envs/Python27/lib/python2.7/random.py"", line 45, in <module>; from math import log as _log, exp as _exp, pi as _pi, e as _e, ceil as _ceil; ***File ""math.py"", line 79, in <module>***; import numpy as np; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>; from . import add_newdocs; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/add_newdocs.py"", line 13, in <module>; from numpy.lib import add_newdoc; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/lib/__init__.py"", line 8, in <module>; from .type_check import *; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/lib/type_check.py"", line 11, in <module>; import numpy.core.numeric as _nx; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/core/__init__.py"", line 74, in <module>; from numpy.testing.nosetester import _numpy_tester; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/testing/__init__.py"", line 12, in <module>; from . import decorators as dec; File ""xx/anaconda/envs/Python27/lib/python2.7/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/32#issuecomment-355522771:1192,log,log,1192,,https://github.com/google/deepvariant/issues/32#issuecomment-355522771,1,['log'],['log']
Testability,_hs37d5/hs37d5.fa*. -rw-rw-r-- 1 zhoujianglin zhoujianglin 3042M Apr 26 14:53 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; -rw-rw-r-- 1 zhoujianglin zhoujianglin 5985M Apr 26 15:23 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann; -rw-rw-r-- 1 zhoujianglin zhoujianglin 9725M Apr 26 15:42 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai; -rw-rw-r-- 1 zhoujianglin zhoujianglin 749M Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.pac; singularity run -B /usr/lib/locale/:/usr/lib/locale/ /lustre/Data/toolsDB/deepvariant.sif ls -al /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*; INFO: Converting SIF file to temporary sandbox...; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.pac': No such file or directory; INFO: Cleaning up image... singularity run -B /usr/lib/locale/:/usr/lib/locale/ /lustre/Data/toolsDB/deepvariant.sif which ls; ls -al /lustre/Data/toolsDB/HostRefs/Hum,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1575922269:3484,sandbox,sandbox,3484,,https://github.com/google/deepvariant/issues/653#issuecomment-1575922269,1,['sandbox'],['sandbox']
Testability,"_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Opti>; 2020-10-19 04:32:52.727391: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_thread>; W1019 04:32:52.748747 140673783289600 deprecation.py:323] From /tmp/Bazel.runfiles_mdh0lz62/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from >; Instructions for updating:; Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the f>; I1019 09:14:02.799481 140673783289600 call_variants.py:520] Writing calls to /tmp/tmpll7hkhwu/call_variants_output.tfrecord.gz; I1019 09:14:02.804919 140673783289600 call_variants.py:538] Processed 1 examples in 1 batches [0.284 sec per 100]; I1019 09:14:04.482554 140673783289600 call_variants.py:538] Processed 15001 examples in 30 batches [0.011 sec per 100]; I1019 09:14:06.172387 140673783289600 call_variants.py:538] Processed 30001 examples in 59 batches [0.011 sec per 100]; I1019 09:14:07.867975 140673783289600 call_variants.py:538] Processed 45001 examples in 88 batches [0.011 sec per 100]; I1019 09:14:09.554191 140673783289600 call_variants.py:538] Processed 60001 examples in 118 batches [0.011 sec per 100]; I1019 09:14:11.247823 140673783289600 call_variants.py:538] Processed 75001 examples in 147 batches [0.011 sec per 100]; I1019 09:14:12.950735 140673783289600 call_variants.py:538] Processed 90001 examples in 176 batches [0.011 sec per 100]; ...; ```. The strange thing is: ; There seems to be a long lag from the timestamp 04:32 to 09:14, it blocked for almost 5 hours? ; But after that , the ""sec per 100"" log seems MUCH faster than a regular run without OpenVINO. However, because of that strange long lag, the over time runtime seems worse with OpenVINO. Any idea on what's happening here?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-712402658:2604,log,log,2604,,https://github.com/google/deepvariant/pull/363#issuecomment-712402658,1,['log'],['log']
Testability,"_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs; 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'; [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi; [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi; I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run; _sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main; make_examples_runner(options); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner; regions = processing_regions_from_options(options); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options; options.min_shared_contigs_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-448201709:2479,test,testdata,2479,,https://github.com/google/deepvariant/issues/128#issuecomment-448201709,1,['test'],['testdata']
Testability,_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log; //deepvariant:haplotypes_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log; //deepvariant/labeler:haplotype_labeler_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log; //deepvariant/labeler:labeled_examples_to_vcf_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:119255,log,log,119255,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log; (06:29:16) FAIL: //deepvariant:model_train_test (shard 10 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log); (06:29:16) INFO: From Testing //deepvariant:model_train_test (shard 10 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 10 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:72587,test,testlogs,72587,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log; //deepvariant/labeler:haplotype_labeler_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log; //deepvariant/labeler:labeled_examples_to_vcf_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log; //deepvariant/labeler:positional_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log; //deepvariant/labeler:variant_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log; //deepvariant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_ro,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:120409,log,log,120409,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:123647,log,log,123647,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"`[bazel release 0.21.0]` -- should I try a more recent version?. I believe this was prescribed by default `settings.sh`.; https://github.com/google/deepvariant/blob/r0.8/settings.sh. Is there a good review stable release from which to try? Sorry. Really at a loss here, as tests pass.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/199#issuecomment-514397821:273,test,tests,273,,https://github.com/google/deepvariant/issues/199#issuecomment-514397821,1,['test'],['tests']
Testability,"```; I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2024-08-15 14:02:47.618984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64; 2024-08-15 14:02:47.619048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; 2024-08-15 14:02:50.434353: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NOT_FOUND: named symbol not found; []; ```I am encountering errors while testing deepvariants calling with gpu. It seems that some libraries for cuda are missing causing it to only work with cpu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/820#issuecomment-2291334900:1103,test,testing,1103,,https://github.com/google/deepvariant/issues/820#issuecomment-2291334900,1,['test'],['testing']
Testability,"```; INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output""; ```. `echo $INPUT_DIR`; returns /ybod2/cavery/deepvariant_run/quickstart-testdata. I am executing commands from the ""deepvariant_run"" directory. I made the change you suggested and received a new error:; `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/output"": invalid volume specification: ':/output'.`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/262#issuecomment-574900293:34,test,testdata,34,,https://github.com/google/deepvariant/issues/262#issuecomment-574900293,2,['test'],['testdata']
Testability,"`types_to_alt_align` refers to the type of variants in which we perform alignments against the alternative variant, when you have also set the `alt_aligned_pileup` flag. . You might be able to accomplish something like this by making use of the vcf candidate importer. See `--truth_variants` + `--variant_caller=vcf_candidate_importer`. I would expect that if you perform filtering similarly on your training and test data, that this could be a way to develop a model specific to certain size INDEL variants, but we have never tried to do something like this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/813#issuecomment-2087375034:413,test,test,413,,https://github.com/google/deepvariant/issues/813#issuecomment-2087375034,1,['test'],['test']
Testability,"a dependency graph query.; run Runs the specified target.; shutdown Stops the bazel server.; sync Syncs all repositories specified in the workspace file; test Builds and runs the specified test targets.; version Prints version information for bazel. Getting more help:; bazel help <command>; Prints help and options for <command>.; bazel help startup_options; Options for the JVM hosting bazel.; bazel help target-syntax; Explains the syntax for specifying targets.; bazel help info-keys; Displays a list of keys used by the info command.; + [[ 1 = \1 ]]; + bazel test -c opt --local_test_jobs=1 --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11 deepvariant/...; (05:40:22) INFO: Options provided by the client:; Inherited 'common' options: --isatty=1 --terminal_columns=166; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.bazelrc:; Inherited 'common' options: --experimental_repo_remote_exec; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.bazelrc:; Inherited 'build' options: --define framework_shared_object=true --define tsl_protobuf_header_only=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,ten",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:5352,test,test,5352,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,1,['test'],['test']
Testability,a-forge; htslib: 1.9-h244ad75_9 bioconda ; httplib2: 0.14.0-py27_0 conda-forge; icu: 64.2-he1b5a44_1 conda-forge; idna: 2.8-py27_1000 conda-forge; intervaltree: 3.0.2-py_0 conda-forge; ipaddress: 1.0.23-py_0 conda-forge; keras-applications: 1.0.8-py_1 conda-forge; keras-preprocessing: 1.1.0-py_0 conda-forge; krb5: 1.16.4-h2fd8d38_0 conda-forge; libblas: 3.8.0-14_openblas conda-forge; libcblas: 3.8.0-14_openblas conda-forge; libcurl: 7.65.3-hda55be3_0 conda-forge; libdeflate: 1.3-h516909a_0 conda-forge; libedit: 3.1.20170329-hf8c457e_1001 conda-forge; libffi: 3.2.1-he1b5a44_1006 conda-forge; libgcc-ng: 9.2.0-hdf63c60_0 conda-forge; libgfortran-ng: 7.3.0-hdf63c60_2 conda-forge; liblapack: 3.8.0-14_openblas conda-forge; libopenblas: 0.3.7-h5ec1e0e_5 conda-forge; libpng: 1.6.37-hed695b0_0 conda-forge; libprotobuf: 3.11.1-h8b12597_0 conda-forge; libssh2: 1.8.2-h22169c7_2 conda-forge; libstdcxx-ng: 9.2.0-hdf63c60_0 conda-forge; linecache2: 1.0.0-py_1 conda-forge; markdown: 3.1.1-py_0 conda-forge; mock: 3.0.5-py27_0 conda-forge; ncurses: 6.1-hf484d3e_1002 conda-forge; numpy: 1.14.6-py27h95a1406_1201 conda-forge; oauth2client: 1.5.2-py27_0 bioconda ; openjdk: 8.0.192-h14c3975_1003 conda-forge; openssl: 1.1.1d-h516909a_0 conda-forge; parallel: 20160622-1 bioconda ; pbr: 5.4.2-py_0 conda-forge; perl: 5.26.2-h516909a_1006 conda-forge; perl-threaded: 5.26.0-0 bioconda ; pip: 19.3.1-py27_0 conda-forge; prettytable: 0.7.2-py_3 conda-forge; protobuf: 3.11.1-py27he1b5a44_0 conda-forge; psutil: 5.6.7-py27h516909a_0 conda-forge; pyasn1: 0.4.8-py_0 conda-forge; pyasn1-modules: 0.2.7-py_0 conda-forge; pycparser: 2.19-py27_1 conda-forge; pyopenssl: 19.1.0-py27_0 conda-forge; pyparsing: 2.4.5-py_0 conda-forge; pyperclip: 1.7.0-py_0 conda-forge; pysocks: 1.7.0-py27_0 conda-forge; python: 2.7.15-h5a48372_1009 conda-forge; pyyaml: 5.2-py27h516909a_0 conda-forge; readline: 8.0-hf8c457e_0 conda-forge; requests: 2.22.0-py27_1 conda-forge; rsa: 3.1.4-py27_0 bioconda ; scipy: 1.2.1-py27h921218d_,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/252#issuecomment-566427577:2402,mock,mock,2402,,https://github.com/google/deepvariant/issues/252#issuecomment-566427577,1,['mock'],['mock']
Testability,a024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log; //deepvariant/labeler:positional_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log; //deepvariant/labeler:variant_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log; //deepvariant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/a,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:121296,test,testlogs,121296,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,ache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log; //deepvariant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:121978,test,testlogs,121978,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"aded the modified file on this public s3 bucket so you can have a look on it directly from here : ; s3://dv-testfiles/hg19.fa; s3://dv-testfiles/ENCFF528VXT.bam. There you can find the genome I used for running too. Before i created the needed files ( done in the following docker container https://hub.docker.com/r/luisas/samtools/ ) :; ```; samtools index ENCFF528VXT.bam; samtools faidx hg19.fa; bgzip -c -i hg19.fa > hg19.fa.gz; samtools faidx ""hg19.fa.gz""; ```. Then I ran in the docker container you provide :; ```; mkdir shardedExamples. time seq 0 1 | parallel --eta --halt 2 python /opt/deepvariant/bin/make_examples.zip --mode calling --ref hg19.fa --regions chr20:10,000,000-10,010,000 --reads ENCFF528VXT.bam --examples shardedExamples/examples.tfrecord@2.gz --task {}. ```. ```; /opt/deepvariant/bin/call_variants --outfile call_variants_output.tfrecord --examples shardedExamples/examples.tfrecord@2.gz --checkpoint dv2/models/model.ckpt; ```. and here the error output:; ```; WARNING: Logging before flag parsing goes to stderr.; W0307 09:54:53.415692 140603705038592 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_vZjmn7/runfiles/genomics/deepvariant/call_variants.py"", line 410, in module; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run; _sys.exit(main(_sys.argv[:1] + flags_passthrough)); File ""/tmp/Bazel.runfiles_vZjmn7/runfiles/genomics/deepvariant/call_variants.py"", line 401, in main; batch_size=FLAGS.batch_size); File ""/tmp/Bazel.runfiles_vZjmn7/runfiles/genomics/deepvariant/call_variants.py"", line 324, in call_variants; examples_filename, example_format)); ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again.; ```. Thanks a lot,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371096675:3067,Log,Logging,3067,,https://github.com/google/deepvariant/issues/52#issuecomment-371096675,1,['Log'],['Logging']
Testability,"age when asking for help.; ================================================================================; (06:29:20) [2,519 / 2,523] 34 / 38 tests, 20 failed; Testing //deepvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:106990,log,log,106990,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"age; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/deepvariant-0.9.0.simg; # GPU image; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/deepvariant-0.9.0-gpu.simg. # Test Singularity DeepVariant0.9.0 image on test data; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; ${INPUT_DIR}/deepvariant-${BIN_VERSION}.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz . # Errors:. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2020-01-31 01:37:29.333483: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . # Test Singularity DeepVariant0.9.0 GPU image on test data; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; ${INPUT_DIR}/deepvariant-${BIN_VERSION}-gpu.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz . # Errors: ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_0Ul6DZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 43, in <module>; import tensorflow as tf; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/265#issuecomment-580549772:1734,test,test,1734,,https://github.com/google/deepvariant/issues/265#issuecomment-580549772,1,['test'],['test']
Testability,"ah, forgot to mention, I filtered chimeric reads because I had around 60% of them in every tested sample, was curious how much it affects my results (using samplix enrichment + pacbio hifi)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/863#issuecomment-2277597820:91,test,tested,91,,https://github.com/google/deepvariant/issues/863#issuecomment-2277597820,1,['test'],['tested']
Testability,"ake/modules/CLIFUtils.cmake ; ./INSTALL.sh; ```; After these changes, I am stuck again at building clif because of the following error:; ```; [100%] Linking CXX executable clif-matcher; /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':; matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'; /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':; matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'; collect2: error: ld returned 1 exit status; make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1; make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2; make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2; make: *** [Makefile:617: clif-matcher] Error 2; ```; I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217:6168,Log,LogMessage,6168,,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217,2,['Log'],['LogMessage']
Testability,"al = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/realigner/python:debruijn_graph_wrap_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner/python:debruijn_graph_wrap_test:; ==================== Test output for //deepvariant/realigner/python:debruijn_graph_wrap_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/python/debruijn_graph_wrap_test.runfiles/com_google_deepvariant/deepvariant/realigner/python/debruijn_graph_wrap_test.py"", line 38, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/python/debruijn_graph_wrap_test.runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 60, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:85322,log,log,85322,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,another test by not-Pi-Chuan,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/426#issuecomment-782471153:8,test,test,8,,https://github.com/google/deepvariant/issues/426#issuecomment-782471153,1,['test'],['test']
Testability,"ant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:124113,test,testlogs,124113,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:125988,test,testlogs,125988,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,ant:exclude_contigs_test (cached) PASSED in 0.9s; //deepvariant:postprocess_variants_lib_test (cached) PASSED in 0.1s; //deepvariant:resources_test (cached) PASSED in 1.7s; //deepvariant:utils_test (cached) PASSED in 0.5s; //deepvariant:variant_calling_test (cached) PASSED in 0.6s; //deepvariant/environment_tests:env_smoke_test (cached) PASSED in 0.7s; //deepvariant/environment_tests:protobuf_implementation_test (cached) PASSED in 1.2s; //deepvariant/realigner:fast_pass_aligner_test (cached) PASSED in 0.6s; //deepvariant/realigner:ssw_test (cached) PASSED in 0.5s; //deepvariant/realigner/python:ssw_misc_test (cached) PASSED in 0.9s; //deepvariant/realigner/python:ssw_wrap_test (cached) PASSED in 1.2s; //deepvariant/vendor:timer_test (cached) PASSED in 0.7s; //deepvariant:call_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log; //deepvariant:data_providers_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log; //deepvariant:haplotypes_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:118197,log,log,118197,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"ap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) FAIL: //deepvariant:haplotypes_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log); (06:29:12) INFO: From Testing //deepvariant:haplotypes_test:; ==================== Test output for //deepvariant:haplotypes_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/haplotypes_test.runfiles/com_google_deepvariant/deepvariant/haplotypes_test.py"", line 43, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/haplotypes_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:42233,test,testlogs,42233,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================. FAILED: //deepvariant:make_examples_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; (06:29:20) FAIL: //deepvariant:make_examples_test (shard 1 of 2) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log); (06:29:20) INFO: From Testing //deepvariant:make_examples_test (shard 1 of 2):; ==================== Test output for //deepvariant:make_examples_test (shard 1 of 2):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/deepvariant/make_examples_test.py"", line 48, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 69, in <module>; from third_party.nucleus.io import genomics_reader; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:100662,test,testlogs,100662,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testda; aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testdata/${REF}.fai"" -d ""${INPUT_DIR}""; ; ## Pull the docker image.; -sudo docker pull google/deepvariant:""${BIN_VERSION}""; +sudo docker pull dkurtaev/deepvariant:latest; ; echo ""Run DeepVariant...""; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; - google/deepvariant:""${BIN_VERSION}"" \; - /opt/deepvariant/bin/run_deepvariant \; + dkurtaev/deepvariant:latest \; + /opt/deepvariant/bin/run_deepvariant --call_variants_extra_args=use_openvino=false --make_examples_extra_args=regions=chr1 \; --model_type=WGS \; --ref=""/input/${REF}.gz"" \; --reads=""/input/${BAM}"" \; @@ -100,6 +100,6 @@ pkrusche/hap.py /opt/hap.py/bin/hap.py \; -f ""${INPUT_DIR}/${TRUTH_BED}"" \; -r ""${UNCOMPRESSED_REF}"" \; -o ""${OUTPUT_DIR}/happy.output"" \; - --engine=vcfeval; + --engine=vcfeval -l chr1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done.""; ```. Runtime:; ```; $ grep '^real' /tmp/open; real 7m20.986s; real 21m24.429s; real 6m32.705s; ```. 3. Use v1.0.0 image.; The code diff:; ```; $ git diff; diff --git a/scripts/run_wgs_case_study_docker.sh b/scripts/run_wgs_case_study_docker.sh; index 3dc9712..88fb0c1 100755; --- a/scripts/run_wgs_case_study_docker.sh; +++ b/scripts/run_wgs_case_study_docker.sh; @@ -72,7 +72,7 @@ sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; google/deepvariant:""${BIN_VERSION}"" \; - /opt/deepvariant/bin/run_deepvariant \; + /opt/deepvariant/bin/run_deepvariant --make_examples_extra_args=regions=chr1 \; --model_type=WGS \; --ref=""/input/${REF}.gz"" \; --reads=""/input/${BAM}"" \; @@ -100,6 +100,6 @@ pkrusche/hap.py /opt/hap.py/bin/hap.py \; -f ""${INPUT_DIR}/${TRUTH_BED}"" \; -r ""${UNCOMPRESSED_REF}"" \; -o ""${OUTPUT_DIR}/happy.output"" \; - --engine=vcfeval; + --engine=vcfeval -l chr1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done.""; ```. Runtime; ```; $ grep '^real",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735276044:3195,log,log,3195,,https://github.com/google/deepvariant/pull/363#issuecomment-735276044,1,['log'],['log']
Testability,"ariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****; time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s; user 0m0.767s; sys 0m0.949s; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>; app.run(main); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run; _run_main(main, args); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-482956117:1288,log,login,1288,,https://github.com/google/deepvariant/issues/132#issuecomment-482956117,1,['log'],['login']
Testability,"ariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:125463,test,testlogs,125463,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,ariant/labeler/positional_labeler_test/test.log; //deepvariant/labeler:variant_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log; //deepvariant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:121575,log,log,121575,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"ariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log. Executed 24 out of 38 tests: 14 tests pass and 24 fail locally.; There were tests whose specified size is too big. Use the --",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:126220,log,log,126220,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,azel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log; //deepvariant/labeler:variant_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log; //deepvariant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_de,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:121526,test,testlogs,121526,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"b/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/realigner/allele_count_linear:generate_trained_model_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner/allele_count_linear:generate_trained_model_test:; ==================== Test output for //deepvariant/realigner/allele_count_linear:generate_trained_model_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/generate_trained_model_test.runfiles/com_google_deepvariant/deepvariant/realigner/allele_count_linear/generate_trained_model_test.py"", line 39, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:80521,log,log,80521,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,b0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; (06:29:20) FAIL: //deepvariant:model_eval_test (shard 9 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log); (06:29:20) INFO: From Testing //deepvariant:model_eval_test (s,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:107339,log,log,107339,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"b0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:124518,log,log,124518,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"b0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; (05:40:51) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (05:40:51) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:1759,log,log,1759,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"b0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; (06:29:20) FAIL: //deepvariant:model_eval_test (shard 9 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log); (06:29:20) INFO: From Testing //deepvariant:model_eval_test (shard 9 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 9 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:107687,log,log,107687,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"b0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:124866,log,log,124866,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"b0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; (06:29:20) FAIL: //deepvariant:model_eval_test (shard 9 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log); (06:29:20) INFO: From Testing //deepvariant:model_eval_test (shard 9 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 9 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python impor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:107861,log,log,107861,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"b0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:125040,log,log,125040,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"b0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; (06:29:20) FAIL: //deepvariant:model_eval_test (shard 9 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log); (06:29:20) INFO: From Testing //deepvariant:model_eval_test (shard 9 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 9 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:107513,log,log,107513,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"b0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:124692,log,log,124692,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"b0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; (05:40:51) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (05:40:51) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python impor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:1933,log,log,1933,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; (05:40:51) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (05:40:51) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:2349,log,log,2349,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log; //deepvariant/labeler:haplotype_labeler_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log; //deepvariant/labeler:labeled_examples_to_vcf_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log; //deepvariant/labeler:positional_labeler_test FAILED in 0.2s; /root/.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:119457,log,log,119457,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log; //deepvariant/labeler:haplotype_labeler_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log; //deepvariant/labeler:labeled_examples_to_vcf_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log; //deepvariant/labeler:positional_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log; //deepvariant/labeler:variant_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/v,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:120346,test,testlogs,120346,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"bdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam""; REF=""/home/suanfa/Documents/source/ref/hg19.fasta""; var=${BAM##*/}; var=${var%.*}; path=""/home/suanfa/Documents/shishiming/training_WES_model""; OUTPUT_DIR=""$path/output""; EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz""; CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed""; TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz""; LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'; ( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \; python ""${BIN_DIR}""/make_examples.zip \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM}"" \; --examples ""${EXAMPLES}"" \; --confident_regions ${CONFIDENT_REGIONS} \; --truth_variants ${TRUTH_VARIANTS} \; --task {}; ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**; > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz; PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz; PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz; PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz; PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz; PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz PE150",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/69#issuecomment-386515701:1579,log,log,1579,,https://github.com/google/deepvariant/issues/69#issuecomment-386515701,1,['log'],['log']
Testability,"bedded ref instead of a ref file), this error could be because of inability to find the embedded ref file.; (2) Your BAM/CRAM file could be corrupted. Please check its md5.; If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues; ```. It seems like for this particular failure mode (BAM file is truncated), the default stackt race was already clear.; But given that I mentioned different level of verbosity. I tried that next. ## Use `-v` to increase verbosity level. if you run `/opt/deepvariant/bin/make_examples --helpfull` you'll see this flag:. ```; -v,--verbosity: Logging verbosity level. Messages logged at this level or; lower will be included. Set to 1 for debug logging. If the flag was not set; or supplied, the value will be changed from the default of -1 (warning) to 0; (info) after flags are parsed.; (default: '-1'); (an integer); ```; You can try to add `-v 1`. But in this case above, my run already had useful logging and didn't seem to produce more useful logs. ## What if we run with Singularity?. I think you were running with Singularity, so I tried that too. I repeated the steps in https://github.com/google/deepvariant/issues/463#issuecomment-866352316 to install Singularity. And then with the same data, I ran:. ```; # Pull the image.; BIN_VERSION=1.1.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" \; --reads ""quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam"" \; --examples ""quickstart-output/sing.make_examples.tfrecord.gz"" \; --gvcf ""quickstart-output/sing.gvcf.tfrecord.gz""; ```. Here is the log I got from my Singularity run:; ```; INFO: Using cached SIF image; [W::bam_hdr_read] EOF marker is absent. The input is probably tru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:14363,log,logging,14363,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,2,['log'],"['logging', 'logs']"
Testability,"bin/run_deepvariant.py"", line 317, in <module>; app.run(main); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run; _run_main(main, args); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1; ```; However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```; #!/usr/bin/zsh; OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model""; mkdir -p ""${OUTPUT_DIR}""; INPUT_DIR=""${PWD}""; BIN_VERSION=""0.9.0""; N_SHARDS=20; LOG_DIR=""${OUTPUT_DIR}/logs"" ; mkdir -p ""${LOG_DIR}"" ; #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3); #for SAMPLE in ""${decade[@]}""; #do; # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz; #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log""; #done; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/268#issuecomment-586584341:3736,log,logs,3736,,https://github.com/google/deepvariant/issues/268#issuecomment-586584341,2,['log'],"['log', 'logs']"
Testability,"blob/r1.1/docs/deepvariant-quick-start.md; to get data. ## I deliberately messed up the BAM, and ran `run_deepvariant`; ```; ls -l quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam; -rw-rw-r-- 1 pichuan pichuan 3925783 Nov 27 2017 quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam; ```; ```; head -c 3000000 quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam > quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam; cp quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam.bai quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; ```. I ran:; ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.truncated.bam \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=1; ```. for the sake of completeness, I'll paste the log below up to the stack trace in make_examples:. ```; I0629 23:08:46.468520 139667868600064 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpj5fx0phm. ***** Intermediate results will be written to /tmp/tmpj5fx0phm in docker. ****. ***** Running the command:*****; ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.truncated.bam"" --examples ""/tmp/tmpj5fx0phm/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpj5fx0phm/gvcf.tfrecord@1.gz"" --task {} ). [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: /input/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:08:49.655763 139654431344384 genomics_reader.py:223] Reading /input/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:08:49.663154 139654431344384 make_examples",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:1495,log,log,1495,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,1,['log'],['log']
Testability,"build DeepVariant so it can be portable to benchmark on remote target machine. These are initial numbers for [Intel DevCloud](https://devcloud.intel.com/edge/) machines and [quickstart-testdata](https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md):. | [Intel® Xeon® Gold 5120](https://devcloud.intel.com/edge/devices/intel-xeon-gold-5120-cpu/) | make_examples | call_variants | postprocess_variants |; |---|---|---|---|; | TensorFlow MKL-DNN | real 0m13.111s<br>user 0m8.496s<br>sys 0m4.869s | real 0m19.154s<br>user 0m23.705s<br>sys 0m8.424s | real 0m6.662s<br>user 0m7.946s<br>sys 0m4.841s |; | OpenVINO | real 0m13.083s<br>user 0m8.216s<br>sys 0m4.510s | real 0m9.687s (x1.97)<br>user 0m18.741s (x1.26)<br>sys 0m6.289s (x1.33) | real 0m6.709s<br>user 0m8.165s<br>sys 0m4.676s |. So, probably, my main question is how to interpret real, user and sys time? Maybe it will help us to understand how to improve the pipeline. ---. Here are my steps:. 1. Build locally (see [deepvariant-build-test.md](https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-build-test.md)). After build,; ```bash; ./build_release_binaries.sh; tar -cvzf bazel-deepvariant.tar.gz bazel-deepvariant/*; tar -cvzf bazel-genfiles.tar.gz bazel-genfiles/*; ```; 2. Go to another machine (i.e. Intel DevCloud) and clone repository. Unpack the binaries; ```bash; git clone -b master_openvino https://github.com/dkurt/deepvariant --depth 1; cd deepvariant; tar -xf bazel-deepvariant.tar.gz; tar -xf bazel-genfiles.tar.gz; ```; 3. Apply some patches to resolve local paths:; ```bash; sed -i -E 's|/opt/deepvariant/bin|./bazel-genfiles/deepvariant|' scripts/run_deepvariant.py; sed -i -E 's|/opt/models/wgs/model.ckpt|model.ckpt|' scripts/run_deepvariant.py; ln -s -f $HOME/deepvariant/scripts/ bazel-deepvariant/scripts; ```; 4. Download [GNU parallel](https://launchpad.net/ubuntu/bionic/amd64/parallel/20161222-1) (if you have no root permissions); ```bash; wget http://launchpadlibrarian.net/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-723242914:1069,test,test,1069,,https://github.com/google/deepvariant/pull/363#issuecomment-723242914,1,['test'],['test']
Testability,"but the docker install commands failed:. sudo apt-get -qq -y update; E: The repository 'https://download.docker.com/linux/ubuntu buster Release' does not have a Release file. sudo apt-get -qq -y install docker-ce; E: Package 'docker-ce' has no installation candidate. So instead I ran an alternate docker installation, which succeeded (sudo apt install docker.io). I don't know if this is the ultimate problem. The first command within the docker seems to complete with no errors:. ***** Running the command:*****; time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hs37d5.fa.gz"" --reads ""/input/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --regions ""20"" --task {}. ...omitting much output... It does take 40 minutes as opposed to the advertised 8, though. I was using pre-emptible instances so perhaps this caused delay, but I did test it 3 times, and it is reliably ~40 mins each time. The second command within the docker dies, this is all the output:. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --; checkpoint ""/opt/models/wgs/model.ckpt""; I1217 09:08:41.108182 139680301201152 call_variants.py:313] Set KMP_BLOCKTIME to 0; 2020-12-17 09:08:41.511115: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA; 2020-12-17 09:08:42.039849: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz; 2020-12-17 09:08:42.070759: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5abc760 executing computations on platform Host. Devices:; 2020-12-17 09:08:42.070838: I tensorflow/compiler/xla/service/service.cc:158] St",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/399#issuecomment-749313156:1100,test,test,1100,,https://github.com/google/deepvariant/issues/399#issuecomment-749313156,1,['test'],['test']
Testability,cached) PASSED in 1.2s; //deepvariant/realigner:fast_pass_aligner_test (cached) PASSED in 0.6s; //deepvariant/realigner:ssw_test (cached) PASSED in 0.5s; //deepvariant/realigner/python:ssw_misc_test (cached) PASSED in 0.9s; //deepvariant/realigner/python:ssw_wrap_test (cached) PASSED in 1.2s; //deepvariant/vendor:timer_test (cached) PASSED in 0.7s; //deepvariant:call_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log; //deepvariant:data_providers_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log; //deepvariant:haplotypes_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepva,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:118617,log,log,118617,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai': No such file or directory; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.pac': No such file or directory; INFO: Cleaning up image... singularity run -B /usr/lib/locale/:/usr/lib/locale/ /lustre/Data/toolsDB/deepvariant.sif which ls; ls -al /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*; INFO: Converting SIF file to temporary sandbox...; /usr/bin/ls; INFO: Cleaning up image...; -rw-rw-r-- 1 zhoujianglin zhoujianglin 3189750467 Apr 26 14:53 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; -rw-rw-r-- 1 zhoujianglin zhoujianglin 6274909010 Apr 26 15:23 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123; -rw-rw-r-- 1 zhoujianglin zhoujianglin 106669 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb; -rw-rw-r-- 1 zhoujianglin zhoujianglin 6924 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann; -rw-rw-r-- 1 zhoujianglin zhoujianglin 10196727247 Apr 26 15:42 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64; -rw-rw-r-- 1 zhoujianglin zhoujianglin 2813 May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai; -rw-rw-r-- 1 zhoujianglin zhoujianglin 784363628 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.pac. ```. The real case command `singularity run -B /usr/lib/locale/:/usr/lib/locale/ /lustre/Data,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1575922269:4527,sandbox,sandbox,4527,,https://github.com/google/deepvariant/issues/653#issuecomment-1575922269,1,['sandbox'],['sandbox']
Testability,"cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; (05:40:51) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (05:40:51) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:1584,log,log,1584,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; (05:40:51) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (05:40:51) INFO: From Testing //deepvariant:model_eval_test (,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:1410,log,log,1410,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:123167,log,log,123167,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,che/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log; //deepvariant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca0,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:121748,test,testlogs,121748,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ckages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) [2,488 / 2,523] 19 / 38 tests, 5 failed; Testing //deepvariant:data_providers_test; 0s local ... (35 actions, 2 running); (06:29:10) FAIL: //deepvariant:data_providers_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log); (06:29:10) INFO: From Testing //deepvariant:data_providers_test:; ==================== Test output for //deepvariant:data_providers_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/data_providers_test.runfiles/com_google_deepvariant/deepvariant/data_providers_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:30696,log,log,30696,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"constraining google-cloud-sdk version worked! thank you. On Wed, Apr 24, 2019 at 3:17 AM Brad Chapman <notifications@github.com>; wrote:. > Peter;; > Thanks for testing, it sounds like there is a problem with the recent; > google-cloud-sdk packages. I'll take a look to see if I can figure out what; > is going wrong but an immediate thing you could try is to restrict that; > dependency version to try and avoid the issue:; >; > conda create -n deepvariant python=2.7 deepvariant 'google-cloud-sdk<243.0.0'; >; > Hope this helps get it installed.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/177#issuecomment-486163437>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABUBV2DKBMPCNW6H6H2OGKLPSAXVJANCNFSM4HH7EBWQ>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/177#issuecomment-486821218:161,test,testing,161,,https://github.com/google/deepvariant/issues/177#issuecomment-486821218,1,['test'],['testing']
Testability,"cord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s; user 0m0.767s; sys 0m0.949s; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>; app.run(main); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run; _run_main(main, args); File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-482956117:2684,test,testdata,2684,,https://github.com/google/deepvariant/issues/132#issuecomment-482956117,2,['test'],['testdata']
Testability,"count=1 \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-16"" \; --boot-disk-size ""300"" \; --zone ""${zone}"" \; --min-cpu-platform ""Intel Skylake""; ```. I sshed into my machine:. ```bash; gcloud compute ssh pichuan-deepvariant-vm --zone us-west1-b; ```. I ran this with my own `YOUR_PROJECT` and `OUTPUT_GCS_BUCKET` setting.; Then the following is basically just copy/paste from the doc:. ```; BUCKET=""gs://deepvariant""; VERSION=""1.6.1""; DOCKER_IMAGE=""google/deepvariant:${VERSION}"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${VERSION}/DeepVariant-inception_v3-${VERSION}+data-wgs_standard""; GCS_PRETRAINED_WGS_MODEL=""${MODEL_BUCKET}/model.ckpt"". OUTPUT_BUCKET=""${OUTPUT_GCS_BUCKET}/customized_training""; TRAINING_DIR=""${OUTPUT_BUCKET}/training_dir"". BASE=""${HOME}/training-case-study""; DATA_BUCKET=gs://deepvariant/training-case-study/BGISEQ-HG001. INPUT_DIR=""${BASE}/input""; BIN_DIR=""${INPUT_DIR}/bin""; DATA_DIR=""${INPUT_DIR}/data""; OUTPUT_DIR=""${BASE}/output""; LOG_DIR=""${OUTPUT_DIR}/logs""; SHUFFLE_SCRIPT_DIR=""${HOME}/deepvariant/tools"". REF=""${DATA_DIR}/ucsc_hg19.fa""; BAM_CHR1=""${DATA_DIR}/BGISEQ_PE100_NA12878.sorted.chr1.bam""; BAM_CHR20=""${DATA_DIR}/BGISEQ_PE100_NA12878.sorted.chr20.bam""; BAM_CHR21=""${DATA_DIR}/BGISEQ_PE100_NA12878.sorted.chr21.bam""; TRUTH_VCF=""${DATA_DIR}/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf.gz""; TRUTH_BED=""${DATA_DIR}/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_nosomaticdel_chr.bed"". N_SHARDS=16; ```. ```bash; mkdir -p ""${OUTPUT_DIR}""; mkdir -p ""${BIN_DIR}""; mkdir -p ""${DATA_DIR}""; mkdir -p ""${LOG_DIR}""; ```. ```bash; gsutil -m cp ${DATA_BUCKET}/BGISEQ_PE100_NA12878.sorted.chr*.bam* ""${DATA_DIR}""; gsutil -m cp -r ""${DATA_BUCKET}/ucsc_hg19.fa*"" ""${DATA_DIR}""; gsutil -m cp -r ""${DATA_BUCKET}/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_*"" ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/793#issuecomment-2008639269:1388,log,logs,1388,,https://github.com/google/deepvariant/issues/793#issuecomment-2008639269,1,['log'],['logs']
Testability,"cs/deepvariant-training-case-study.md. ---. I got a CPU machine:; ```; gcloud compute instances create ""${USER}-cpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-1804-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""custom-64-131072"" \; --boot-disk-size ""300"" \; --zone ""us-west2-b"" \; --min-cpu-platform ""Intel Skylake""; ```. Set variables; ```; YOUR_PROJECT=REPLACE_WITH_YOUR_PROJECT; OUTPUT_GCS_BUCKET=REPLACE_WITH_YOUR_GCS_BUCKET. BUCKET=""gs://deepvariant""; BIN_VERSION=""1.1.0"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${BIN_VERSION}/DeepVariant-inception_v3-${BIN_VERSION}+data-wgs_standard""; GCS_PRETRAINED_WGS_MODEL=""${MODEL_BUCKET}/model.ckpt"". OUTPUT_BUCKET=""${OUTPUT_GCS_BUCKET}/customized_training""; TRAINING_DIR=""${OUTPUT_BUCKET}/training_dir"". BASE=""${HOME}/training-case-study""; DATA_BUCKET=gs://deepvariant/training-case-study/BGISEQ-HG001. INPUT_DIR=""${BASE}/input""; BIN_DIR=""${INPUT_DIR}/bin""; DATA_DIR=""${INPUT_DIR}/data""; OUTPUT_DIR=""${BASE}/output""; LOG_DIR=""${OUTPUT_DIR}/logs""; SHUFFLE_SCRIPT_DIR=""${HOME}/deepvariant/tools"". REF=""${DATA_DIR}/ucsc_hg19.fa""; BAM_CHR1=""${DATA_DIR}/BGISEQ_PE100_NA12878.sorted.chr1.bam""; BAM_CHR20=""${DATA_DIR}/BGISEQ_PE100_NA12878.sorted.chr20.bam""; BAM_CHR21=""${DATA_DIR}/BGISEQ_PE100_NA12878.sorted.chr21.bam""; TRUTH_VCF=""${DATA_DIR}/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf.gz""; TRUTH_BED=""${DATA_DIR}/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_nosomaticdel_chr.bed"". N_SHARDS=64; ```. ```; mkdir -p ""${OUTPUT_DIR}""; mkdir -p ""${BIN_DIR}""; mkdir -p ""${DATA_DIR}""; mkdir -p ""${LOG_DIR}""; ```. ```; gsutil -m cp ${DATA_BUCKET}/BGISEQ_PE100_NA12878.sorted.chr*.bam* ""${DATA_DIR}""; gsutil -m cp -r ""${DATA_BUCKET}/ucsc_hg19.fa*"" ""${DATA_DIR}""; gsutil -m cp -r ""${DATA_BUCKET}/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_*"" ""${DATA_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/469#issuecomment-871936544:1578,log,logs,1578,,https://github.com/google/deepvariant/issues/469#issuecomment-871936544,1,['log'],['logs']
Testability,"ctory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```; $ build status. Checking DeepVariant build prerequisites... OK; Checking DeepVariant test environment compatibility [GPU]... OK; Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]?. ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```; $ ./build help; ...; cloudbuild Builds Docker images of DeepVariant, and ; pushes them on the Google Container Registry (gcr.io) ; ... $ ./build cloudbuild help; CPU Builds a DeepVariant Docker image for CPU usage.; GPU Builds a DeepVariant Docker image for GPU usage.; Runner Builds a DeepVariant Docker image for large-scale analysis run; using the Genomics Pipelines API. $; ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnaly",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/87#issuecomment-413745335:1518,test,test,1518,,https://github.com/google/deepvariant/issues/87#issuecomment-413745335,1,['test'],['test']
Testability,"d of the multisample glnexus VCF. Yes, exactly!. > 2. How have you determined the TP sites? Are these Genome in a Bottle, or do they come from some other source. These are PCGC data, TPs were determined by combination of methods and manually curated. We expect an accuracy of the; found TPs to be > 95% (based on PCR for a similar dataset), although we might still miss some TP calls. > Are these true variants de novos? DeepTrio's quality distribution for de novo variants is very different from its general quality distribution. This occurs because DeepTrio has learned that de novo events are quite rare, and so requires a higher standard of evidence to make a call which is a de novo. In these cases, DeepTrio is not extremely confident in the call, which results in a lower quality value. I am sorry, I did not mention it. Yes, we are looking for denovos in trios. We are comparing efficiency of a few methods to create a pipeline for a big dataset. I thought we might use the QUAL score from DeepTrio to filter calls found by GATK4 pipeline.; If we use GQ fields for further filtering what values do you recommend for parents and proband?. Now, I use the following filters to retrieve denovo calls from the multisample glnexus VCF:; - Heterozygous ratio of proband = 0.2-0.8; - Homozygous ratio of parents <= 0.1; - ALT allele depth of proband >= 7; - Genotype quality of proband >= 60; - Read depth >= 7; - Allele count = 1; - Some regional filters were applied to remove noisy regions; - Common variants were removed based on 1000genome and gnomad population frequencies; Also, I had to split multiallelic calls and recalculate genotypes based on AD fields as I had a lot of ./. and 0/1 for Homozygous reference calls in parents. As results, I obtained 909 SNPs and 1,236 indels for my 10 test trios. My list of TPs contains 698 SNPs and 61 indels. So, I still have a lot of false-positives calls. Is there a way to filter my variants from DeepTrio further?. Thank you!. Best regards,; Maria.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/440#issuecomment-820564569:1894,test,test,1894,,https://github.com/google/deepvariant/issues/440#issuecomment-820564569,1,['test'],['test']
Testability,"d"" --machine-type ""custom-64-131072"" --boot-disk-size ""300"" --zone ""us-west2-b"" --min-cpu-platform ""Intel Skylake""`. ssh into the machine:. ```; gcloud compute ssh pichuan-cpu --zone us-west2-b; ```. Get the binaries and models:. ```; BUCKET=""gs://deepvariant""; BIN_VERSION=""1.4.0""; MODEL_VERSION=""1.4.0"". BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}""; MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". mkdir -p bin; # Download the DeepVariant binaries.; gsutil -m cp ""${BIN_BUCKET}/*"" bin/; chmod a+x bin/*; ```. Then, I ran:; ```; cd bin; bash run-prereq.sh; cd -; ```. The `run-prereq.sh` tends to be the most tricky one - it will require root permission, and it'll install a bunch of stuff on your machine. If you can't use Docker because of root permissions, you likely won't be able to run this as well. Download test data:. ```; INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ```. Run make_examples:. ```; OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}""; ```. ```; python bin/make_examples.zip \; --mode calling \; --ref ""${INPUT_DIR}/ucsc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/590#issuecomment-1322695241:1612,test,testdata,1612,,https://github.com/google/deepvariant/issues/590#issuecomment-1322695241,1,['test'],['testdata']
Testability,"d-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bai; 2018-11-09 19:48:51.497793: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring: ; I1109 19:48:51.498179 140612532332288 genomics_reader.py:213] Reading /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bam with NativeSamReader; I1109 19:48:51.518172 140612532332288 make_examples.py:1075] Preparing inputs; [W::hts_idx_load2] The index file is older than the data file: /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bai; 2018-11-09 19:48:52.291229: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring: ; I1109 19:48:52.291625 140612532332288 genomics_reader.py:213] Reading /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bam with NativeSamReader; I1109 19:48:52.335163 140612532332288 make_examples.py:991] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']; [E::hts_open_format] **Failed to open file gs://gbsc-gcp-project-udn-dev-test/VCRome_2_1_hg19_capture_targets_chrStripped.bed**; Traceback (most recent call last):; File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run; _sys.exit(main(argv)); File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main; make_examples_runner(options); File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner; regions = processing_regions_from_options(options); File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 993, in processing_regions_from_options",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/118#issuecomment-437503051:1723,test,test,1723,,https://github.com/google/deepvariant/issues/118#issuecomment-437503051,1,['test'],['test']
Testability,"d_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) [2,506 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test (shard 10 of 10); 0s local ... (17 actions, 2 running). FAILED: //deepvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:71244,log,log,71244,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log; //deepvariant/labeler:haplotype_labeler_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log; //deepvariant/labeler:labeled_examples_to_vcf_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log; //deepvariant/labeler:positional_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log; //deepvariant/labeler:variant_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cach,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:119925,log,log,119925,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:124344,log,log,124344,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"derlying Inception V3 network architecture for both PacBio and WGS, a point of natural comparability would be the logits kernel across all three genotypes:. ![image](https://github.com/pgrosu/test/assets/6555937/e8ebb437-0132-474e-9ada-c64256aeb791). ![image](https://github.com/pgrosu/test/assets/6555937/f1f478fa-8ffc-4a9a-b5de-4f123658750d). ![image](https://github.com/pgrosu/test/assets/6555937/eb14b3e0-3424-4dc5-82b3-c77091c871a2). Given visual similarity, these were confirmed via Euclidean distance (0.9931127, 0.8543731 and 1.052052, respectively). This indicates the feature set might exhibit strong similarity for interpretation. . Looking at one network (PacBio), it might be possible to confirm calibration by testing for network-resiliency. Via perturbation analysis it should be possible to get insight into a channel's response under perturbation, and their binary interactions under such conditions. Keeping the variant unchanged within a window on each side for preserving the call, the inspection each channel vulnerability response to perturbation can be tested. This resulted in the following perturbation response ($`c\_*`$ denotes a channel, and $`i\_*\_*`$ represents a binary interaction between two channels):. ![image](https://github.com/pgrosu/test/assets/6555937/97c6b13e-e80b-48ae-939d-2367e7ab65c1). The above can be mapped into a network of interactions among the channels:. ![image](https://github.com/pgrosu/test/assets/6555937/cc0e1e2a-278f-4178-a124-67b0321bba3e). Based on the above mapping, by testing well-interacting channels through a probabilistically value-update -- within DeepVariant-acceptable values -- it might be possible to check for shifts in genotype mimicking Mendelian violation. Selecting `base_quality` and staying within DeepVariant's minimum acceptable value, random sampling with replacement was performed in the window outside the variant region. A shift in genotype was achieved giving a measure of network resiliency. Other channels bein",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1619352040:1239,test,tested,1239,,https://github.com/google/deepvariant/issues/666#issuecomment-1619352040,1,['test'],['tested']
Testability,"details.md#command-for-a-cpu-only-machine-on-google-cloud-platform. ```bash; gcloud compute instances create ""${USER}-cpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-64"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. I sshed into the machine. ```bash; gcloud compute ssh pichuan-cpu --zone us-west1-b; ```. Then, on the machine, I get DeepVariant r1.5 source first:. ```bash; git clone https://github.com/google/deepvariant.git; cd deepvariant/; git checkout r1.5; ```. And I confirmed the version:. ```; pichuan@pichuan-cpu:~/deepvariant$ git log | head; commit ab068c4588a02e2167051bd9e74c0c9579462b51; Author: pichuan <pichuan@google.com>; Date: Mon Feb 27 23:03:48 2023 -0800. Update README.md; ; PiperOrigin-RevId: 512838102. ```. From there, I followed the instructions on https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-build-test.md; So I ran:. ```bash; sudo su; ./build-prereq.sh; ```. My run succeeded. I looked at my log to see the section close to where your error occurred. And I see:. ```; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"") ; -- Checking for module 'proto",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785:1522,test,test,1522,,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785,1,['test'],['test']
Testability,"dir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"") ; -- Checking for module 'protobuf'; -- Found protobuf, version 3.13.0; -- Checking for module 'libglog'; -- Found libglog, version 0.4.0; -- Looking for pthread.h; -- Looking for pthread.h - found; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed; -- Looking for pthread_create in pthreads; -- Looking for pthread_create in pthreads - not found; -- Looking for pthread_create in pthread; -- Looking for pthread_create in pthread - found; -- Found Threads: TRUE ; CMake Error at clif/cmake/modules/CLIFUtils.cmake:37 (find_package):; Could not find a configuration file for package ""LLVM"" that is compatible; with requested version ""11.1.0"". The following configuration files were considered but not accepted:. /usr/lib/llvm-11/lib/cmake/llvm/LLVMConfig.cmake, version: 11.0.0; /usr/lib/llvm-11/cmake/LLVMConfig.cmake, version: 11.0.0; /lib/llvm-11/cmake/LLVMConfig.cmake, version: 11.0.0. Call Stack (most recent call first):; clif/CMakeLists.txt:22 (include). -- Configuring incomplete, errors occurred!; See also ""/root/clif/build/CMakeFiles/CMakeOutput.log"".; See also ""/root/clif/build/CMakeFiles/CMakeError.log"". real	2m44.183s; user	0m18.337s; sys	0m18.865s; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276:5753,Test,Test,5753,,https://github.com/google/deepvariant/issues/657#issuecomment-1575779276,4,"['Test', 'log']","['Test', 'log']"
Testability,"doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file.; I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file.; And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```; python bin/make_examples.zip \; --mode training \; --ref ""project-retraining/testdata/sequence.fasta"" \; --reads ""project-retraining/testdata/aligned_reads.bam"" \; --examples ""project-retraining/training_examples"" \; --confident_regions ""project-retraining/testdata/variants.bed"" \; --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1; ```. and I get the same ValueError as before (from `make_examples.log` file):. ```; 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs; 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'; [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi; [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi; I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading projec",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-448201709:1591,test,testdata,1591,,https://github.com/google/deepvariant/issues/128#issuecomment-448201709,1,['test'],['testdata']
Testability,"dule>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) FAIL: //deepvariant:model_eval_test (shard 8 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log); (06:29:12) INFO: From Testing //deepvariant:model_eval_test (shard 8 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 8 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:44714,log,log,44714,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"dule>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:13) FAIL: //deepvariant:model_eval_test (shard 7 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log); (06:29:13) INFO: From Testing //deepvariant:model_eval_test (shard 7 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 7 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:49148,log,log,49148,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"dule>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:14) FAIL: //deepvariant:model_eval_test (shard 3 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log); (06:29:14) INFO: From Testing //deepvariant:model_eval_test (shard 3 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 3 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:57884,log,log,57884,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"dule>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:14) FAIL: //deepvariant:model_eval_test (shard 4 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log); (06:29:14) INFO: From Testing //deepvariant:model_eval_test (shard 4 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 4 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:55735,log,log,55735,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"dule>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:15) FAIL: //deepvariant:model_eval_test (shard 2 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log); (06:29:15) INFO: From Testing //deepvariant:model_eval_test (shard 2 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 2 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:60033,log,log,60033,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"e ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:17) FAIL: //deepvariant/realigner/allele_count_linear:model_evaluation_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log); (06:29:17) INFO: From Testing //deepvariant/realigner/allele_count_linear:model_evaluation_test:; ==================== Test output for //deepvariant/realigner/allele_count_linear:model_evaluation_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/realigner/allele_count_linear/model_evaluation_test.py"", line 41, in <module>; from deepvariant import testdata; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/testdata.py"", line 39, in <module>; from third_party.nucleus.testing import test_utils as nucleus_test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:77525,log,log,77525,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"e 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/python:allelecounter_wrap_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log); (06:29:18) INFO: From Testing //deepvariant/python:allelecounter_wrap_test:; ==================== Test output for //deepvariant/python:allelecounter_wrap_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/python/allelecounter_wrap_test.runfiles/com_google_deepvariant/deepvariant/python/allelecounter_wrap_test.py"", line 38, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/python/allelecounter_wrap_test.runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 60, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:82749,test,testlogs,82749,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"e 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/realigner:window_selector_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner:window_selector_test:; ==================== Test output for //deepvariant/realigner:window_selector_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/window_selector_test.runfiles/com_google_deepvariant/deepvariant/realigner/window_selector_test.py"", line 40, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/window_selector_test.runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 60, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:90094,test,testlogs,90094,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"e 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:19) FAIL: //deepvariant/labeler:haplotype_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log); (06:29:19) INFO: From Testing //deepvariant/labeler:haplotype_labeler_test:; ==================== Test output for //deepvariant/labeler:haplotype_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/haplotype_labeler_test.py"", line 40, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 60, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:94991,test,testlogs,94991,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"e initial numbers for [Intel DevCloud](https://devcloud.intel.com/edge/) machines and [quickstart-testdata](https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md):. | [Intel® Xeon® Gold 5120](https://devcloud.intel.com/edge/devices/intel-xeon-gold-5120-cpu/) | make_examples | call_variants | postprocess_variants |; |---|---|---|---|; | TensorFlow MKL-DNN | real 0m13.111s<br>user 0m8.496s<br>sys 0m4.869s | real 0m19.154s<br>user 0m23.705s<br>sys 0m8.424s | real 0m6.662s<br>user 0m7.946s<br>sys 0m4.841s |; | OpenVINO | real 0m13.083s<br>user 0m8.216s<br>sys 0m4.510s | real 0m9.687s (x1.97)<br>user 0m18.741s (x1.26)<br>sys 0m6.289s (x1.33) | real 0m6.709s<br>user 0m8.165s<br>sys 0m4.676s |. So, probably, my main question is how to interpret real, user and sys time? Maybe it will help us to understand how to improve the pipeline. ---. Here are my steps:. 1. Build locally (see [deepvariant-build-test.md](https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-build-test.md)). After build,; ```bash; ./build_release_binaries.sh; tar -cvzf bazel-deepvariant.tar.gz bazel-deepvariant/*; tar -cvzf bazel-genfiles.tar.gz bazel-genfiles/*; ```; 2. Go to another machine (i.e. Intel DevCloud) and clone repository. Unpack the binaries; ```bash; git clone -b master_openvino https://github.com/dkurt/deepvariant --depth 1; cd deepvariant; tar -xf bazel-deepvariant.tar.gz; tar -xf bazel-genfiles.tar.gz; ```; 3. Apply some patches to resolve local paths:; ```bash; sed -i -E 's|/opt/deepvariant/bin|./bazel-genfiles/deepvariant|' scripts/run_deepvariant.py; sed -i -E 's|/opt/models/wgs/model.ckpt|model.ckpt|' scripts/run_deepvariant.py; ln -s -f $HOME/deepvariant/scripts/ bazel-deepvariant/scripts; ```; 4. Download [GNU parallel](https://launchpad.net/ubuntu/bionic/amd64/parallel/20161222-1) (if you have no root permissions); ```bash; wget http://launchpadlibrarian.net/300780258/parallel_20161222-1_all.deb ; dpkg -x parallel_20161222-1_all.deb parallel; e",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-723242914:1149,test,test,1149,,https://github.com/google/deepvariant/pull/363#issuecomment-723242914,1,['test'],['test']
Testability,"e native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) [2,506 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test (shard 10 of 10); 0s local ... (17 actions, 2 running). FAILED: //deepvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:71419,log,log,71419,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"e specified targets w/ configurations.; dump Dumps the internal state of the bazel server process.; fetch Fetches external repositories that are prerequisites to the targets.; help Prints help for commands, or the index.; info Displays runtime info about the bazel server.; license Prints the license of this software.; mobile-install Installs targets to mobile devices.; print_action Prints the command line args for compiling a file.; query Executes a dependency graph query.; run Runs the specified target.; shutdown Stops the bazel server.; test Builds and runs the specified test targets.; version Prints version information for bazel. Getting more help:; bazel help <command>; Prints help and options for <command>.; bazel help startup_options; Options for the JVM hosting bazel.; bazel help target-syntax; Explains the syntax for specifying targets.; bazel help info-keys; Displays a list of keys used by the info command.; + [[ 1 = \1 ]]; + bazel test -c opt --local_test_jobs=1 --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/...; (06:29:06) WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.; (06:29:06) INFO: Current date is 2019-02-14; (06:29:06) Loading: ; (06:29:06) Loading: 0 packages loaded; (06:29:07) INFO: Analysed 168 targets (0 packages loaded).; (06:29:07) INFO: Found 130 targets and 38 test targets...; (06:29:07) [1 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt; (06:29:08) FAIL: //deepvariant/labeler:variant_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log); (06:29:08) INFO: From Testing //deepvariant/labeler:variant_labeler_test:; ==================== Test output for //deepvariant/labeler:variant_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_baz",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:10783,test,test,10783,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['test'],['test']
Testability,"e the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:17) FAIL: //deepvariant/realigner/allele_count_linear:model_evaluation_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log); (06:29:17) INFO: From Testing //deepvariant/realigner/allele_count_linear:model_evaluation_test:; ==================== Test output for //deepvariant/realigner/allele_count_linear:model_evaluation_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/realigner/allele_count_linear/model_evaluation_test.py"", line 41, in <module>; from deepvariant import testdata; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/testdata.py"", line 39, in <module>; from third_party.nucleus.testing import test_utils as nucleus_test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python impor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:78104,test,testdata,78104,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['test'],['testdata']
Testability,"e-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:08) [2,482 / 2,523] 16 / 38 tests, 2 failed; Testing //deepvariant:call_variants_test; 0s local ... (41 actions, 1 running); (06:29:09) FAIL: //deepvariant:call_variants_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log); (06:29:09) INFO: From Testing //deepvariant:call_variants_test:; ==================== Test output for //deepvariant:call_variants_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_test.runfiles/com_google_deepvariant/deepvariant/call_variants_test.py"", line 48, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:16963,log,log,16963,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"e4_2 movbe popcnt aes xsave avx hypervisor lahf_lm 3dnowprefetch arat; bogomips	: 4190.15; clflush size	: 64; cache_alignment	: 64; address sizes	: 40 bits physical, 48 bits virtual; power management:. What I compared was not only call_variant it was make example step too. To make it clear I enclose a part of the log here, however it uses slightly different setting and different example but it shows what I said in my previous comment.; In this case I did not specify any number of core for the cpu and the result are slightly better than if I specify the cpu cores equal to 8. stdout of the process:; input file S-001701867.markdup.bam; I0622 13:05:17.760246 47710258629632 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir; I0622 13:05:17.867540 47710258629632 run_deepvariant.py:405] Creating a directory for logs in /output/logs; I0622 13:05:17.933148 47710258629632 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****; ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001701867.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output. I0622 13:06:39.176360 47468847029248 genomics_reader.py:223] Reading /input/S-001701867.markdup.bam with NativeSamReader; I0622 13:06:39.193307 47468847029248 make_examples.py:648] Preparing inputs; I0622 13:06:39.256251 47468847029248 genomics_reader.py:223] Reading /input/S-001701867.markdup.bam with NativeSamReader; I0622 13:06:40.155634 47468847029248 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4',",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866226252:1820,log,logs,1820,,https://github.com/google/deepvariant/issues/463#issuecomment-866226252,1,['log'],['logs']
Testability,"e>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:09) FAIL: //deepvariant:model_train_test (shard 3 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log); (06:29:09) INFO: From Testing //deepvariant:model_train_test (shard 3 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 3 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:19094,log,log,19094,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"e>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant:model_train_test (shard 1 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log); (06:29:10) INFO: From Testing //deepvariant:model_train_test (shard 1 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 1 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:28432,log,log,28432,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"e>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:11) FAIL: //deepvariant:model_train_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log); (06:29:11) INFO: From Testing //deepvariant:model_train_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:35711,log,log,35711,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"e>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:11) FAIL: //deepvariant:model_train_test (shard 7 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log); (06:29:11) INFO: From Testing //deepvariant:model_train_test (shard 7 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 7 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:37866,log,log,37866,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"e>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:13) FAIL: //deepvariant:model_eval_test (shard 10 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log); (06:29:13) INFO: From Testing //deepvariant:model_eval_test (shard 10 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 10 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:51299,log,log,51299,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"e>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:15) FAIL: //deepvariant:model_train_test (shard 4 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log); (06:29:15) INFO: From Testing //deepvariant:model_train_test (shard 4 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 4 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:64476,log,log,64476,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"e>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) FAIL: //deepvariant:model_train_test (shard 5 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log); (06:29:16) INFO: From Testing //deepvariant:model_train_test (shard 5 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 5 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:66631,log,log,66631,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"e>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) FAIL: //deepvariant:model_train_test (shard 8 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log); (06:29:16) INFO: From Testing //deepvariant:model_train_test (shard 8 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 8 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:68786,log,log,68786,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"e_examples.zip/__main__.py"", line 326, in Main; AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found.; warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated; /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) ; warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated; Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main; AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found.; Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main; AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found.; parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full?; parallel: Error: Change $TMPDIR with --tmpdir or use --compress.; Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s; user 0m1.215s; sys 0m0.687s. ## command-line plan B:; /share/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300:3183,Assert,AssertionError,3183,,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300,1,['Assert'],['AssertionError']
Testability,"eading state information... Done; The following packages will be REMOVED:; docker-ce-rootless-extras slirp4netns; 0 upgraded, 0 newly installed, 2 to remove and 0 not upgraded.; After this operation, 19.2 MB disk space will be freed.; Do you want to continue? [Y/n] Y; (Reading database ... 177786 files and directories currently installed.); Removing docker-ce-rootless-extras (5:24.0.2-1~ubuntu.20.04~focal) ...; Removing slirp4netns (0.4.3-1) ...; Processing triggers for man-db (2.9.1-1) ...; ```. Extra commands output:; ```; > llvm-config-11 --version; 11.0.0; > cat /usr/lib/llvm-11/lib/cmake/llvm/LLVMConfig.cmake | grep PACKAGE_VERSION; set(LLVM_PACKAGE_VERSION 11.0.0); > cat /usr/lib/llvm-11/cmake/LLVMConfig.cmake | grep PACKAGE_VERSION; set(LLVM_PACKAGE_VERSION 11.0.0); > cat /lib/llvm-11/cmake/LLVMConfig.cmake | grep PACKAGE_VERSION; set(LLVM_PACKAGE_VERSION 11.0.0); ```. Finally the output from `sudo tools/build_clif.sh` installation of CLIF (still the same error I guess):; ```; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD; -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed; -- Looking for pthread_create in pthreads; -- Looking for pthread_create in pthreads - not found; -- Looking for pthread_create in pthread; -- Looking for pthread_create in pthread - found; -- Found Threads: TRUE ; CMake Error at clif/cmake/modules/CLIFUtils.cmake:37 (find_package):; Could not find a configuration file for package ""LLVM"" that is compatible; with requested version ""11.1.0"". The following configuration files were considered but not accepted:. /usr/lib/llvm-11/lib/cmake/llvm/LLVMConfig.cmake, version: 11.0.0; /usr/lib/llvm-11/cmake/LLVMConfig.cmake, version: 11.0.0; /lib/llvm-11/cmake/LLVMConfig.cmake, version: 11.0.0. Call Stack (most recent call first):; clif/CMakeLists.txt:22 (include). -- Configuring incomplete, errors occurred!; See also ""/root/clif/build/CMakeFiles/CMakeOutput.log"".; See also ""/root/clif/build/CMakeFiles/CMakeError.log"".; ```. Do you have any suggestions?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:13153,Test,Test,13153,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,4,"['Test', 'log']","['Test', 'log']"
Testability,"ed object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) FAIL: //deepvariant:haplotypes_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log); (06:29:12) INFO: From Testing //deepvariant:haplotypes_test:; ==================== Test output for //deepvariant:haplotypes_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/haplotypes_test.runfiles/com_google_deepvariant/deepvariant/haplotypes_test.py"", line 43, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/haplotypes_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:42711,test,testing,42711,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['test'],['testing']
Testability,ed) PASSED in 0.9s; //deepvariant/realigner/python:ssw_wrap_test (cached) PASSED in 1.2s; //deepvariant/vendor:timer_test (cached) PASSED in 0.7s; //deepvariant:call_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log; //deepvariant:data_providers_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log; //deepvariant:haplotypes_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/ba,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:118819,log,log,118819,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"eeptrio-details-training-data.md:| 1.6.0 | 1 HG002, 1 HG002, 1 HG004 | 50,249,704<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 1 HG002, 1 HG002, 1 HG004 | 99,675,190<sup>[(5)](#vfootnote5)</sup> |; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/HG002_ONT_deeptrio.denovo.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/customized_classes.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_gvcf_output.g.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.vcf_candidate_importer.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00001-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_single_site_output.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/HG002_ONT_deeptrio.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040:2727,test,testdata,2727,,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040,1,['test'],['testdata']
Testability,"egions ""${TRUTH_BED}"" \; --task {} \; --regions ""'chr1'"" \; --channels ""insert_size"" \; ) 2>&1 | tee ""${LOG_DIR}/training_set.with_label.make_examples.log""; ```. This took `20m0.146s`. ```; $ cat ""${OUTPUT_DIR}/training_set.with_label.tfrecord-00000-of-00016.gz.example_info.json""; {""version"": ""1.6.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}; ```. ```bash; gsutil -m cp ${OUTPUT_DIR}/training_set.with_label.tfrecord-?????-of-00016.gz* \; ${OUTPUT_BUCKET}; ```. ```bash; ( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --line-buffer \; sudo docker run \; -v /home/${USER}:/home/${USER} \; ${DOCKER_IMAGE} \; make_examples \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM_CHR21}"" \; --examples ""${OUTPUT_DIR}/validation_set.with_label.tfrecord@${N_SHARDS}.gz"" \; --truth_variants ""${TRUTH_VCF}"" \; --confident_regions ""${TRUTH_BED}"" \; --task {} \; --regions ""'chr21'"" \; --channels ""insert_size"" \; ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log""; ```. This took `5m25.905s`. ```bash; gsutil -m cp ${OUTPUT_DIR}/validation_set.with_label.tfrecord-?????-of-00016.gz* \; ${OUTPUT_BUCKET}; ```. # This parts starts shuffling... ```bash; sudo apt install -y python3.8-venv; # Create a virtualenv; python3 -m venv beam. # Activate the virtualenv; . beam/bin/activate; ```. ```bash; mkdir -p ${SHUFFLE_SCRIPT_DIR}; wget https://raw.githubusercontent.com/google/deepvariant/r1.6.1/tools/shuffle_tfrecords_beam.py -O ${SHUFFLE_SCRIPT_DIR}/shuffle_tfrecords_beam.py; ```. ```bash; sudo apt -y update && sudo apt -y install python3-pip; pip3 install --upgrade pip; pip3 install setuptools --upgrade; pip3 install apache_beam[gcp]==2.50.0 # 2.51.0 didn't work in my run.; pip3 install tensorflow # For parsing tf.Example in shuffle_tfrecords_beam.py.; ```. ```bash; time python3 ${SHUFFLE_SCRIPT_DIR}/shuffle_tfrecords_beam.py \; --project=""${YOUR_PROJECT}"" \; --input_pattern_list=""${OUTPUT_BUCKET}""/training_set.with_label.tfrecord-?????-of-00016.gz \; --o",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/793#issuecomment-2008639269:4047,log,log,4047,,https://github.com/google/deepvariant/issues/793#issuecomment-2008639269,1,['log'],['log']
Testability,eler_test/test.log; //deepvariant/labeler:haplotype_labeler_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log; //deepvariant/labeler:labeled_examples_to_vcf_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log; //deepvariant/labeler:positional_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log; //deepvariant/labeler:variant_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log; //deepvariant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:120879,log,log,120879,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"eloper.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2023-12-05 07:43:20.303963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-12-05 07:43:24.030774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-12-05 07:43:24.033082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; --model_type is required.; Pass --helpshort or --helpfull to see help on flags.; ```. Which is expected because I didn't pass in more flags for run_deeptrio. The most relevant message is the ones at the bottom:. ```; --model_type is required.; Pass --helpshort or --helpfull to see help on flags.; ```. From here, I should be able to pass in the arguments from Quick Start and have it working. (If you want, I can continue the test). ---. @alanlamsiu ,; Now I got here, please check these two things on your side:. 1. Can you confirm that your .sif is indeed made from `1.6.0`? (Which is our latest version. Please don't use the rc2 one).; 2. Can you try `/opt/deepvariant/bin/deeptrio/run_deeptrio`? You seem to be using a different path. I'm also not sure where that came from -- if we have any GitHub documentation that's inconsistent, please let me know and I can update.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389:4348,test,test,4348,,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389,1,['test'],['test']
Testability,"elow cpu info:. cat /proc/cpuinfo; processor	: 0; vendor_id	: GenuineIntel; cpu family	: 6; model		: 85; model name	: Intel(R) Xeon(R) Silver 4116 CPU @ 2.10GHz; stepping	: 4; microcode	: 0x200004d; cpu MHz		: 2095.078; cache size	: 16896 KB; physical id	: 0; siblings	: 1; core id		: 0; cpu cores	: 1; apicid		: 0; initial apicid	: 0; fpu		: yes; fpu_exception	: yes; cpuid level	: 13; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl tsc_reliable nonstop_tsc eagerfpu pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx hypervisor lahf_lm 3dnowprefetch arat; bogomips	: 4190.15; clflush size	: 64; cache_alignment	: 64; address sizes	: 40 bits physical, 48 bits virtual; power management:. What I compared was not only call_variant it was make example step too. To make it clear I enclose a part of the log here, however it uses slightly different setting and different example but it shows what I said in my previous comment.; In this case I did not specify any number of core for the cpu and the result are slightly better than if I specify the cpu cores equal to 8. stdout of the process:; input file S-001701867.markdup.bam; I0622 13:05:17.760246 47710258629632 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir; I0622 13:05:17.867540 47710258629632 run_deepvariant.py:405] Creating a directory for logs in /output/logs; I0622 13:05:17.933148 47710258629632 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****; ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/inp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866226252:1117,log,log,1117,,https://github.com/google/deepvariant/issues/463#issuecomment-866226252,1,['log'],['log']
Testability,"endor_id : GenuineIntel; cpu family : 6; model : 94; model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz; stepping : 3; microcode : 0xc2; cpu MHz : 1013.093; cache size : 8192 KB; physical id : 0; siblings : 8; core id : 0; cpu cores : 4; apicid : 0; initial apicid : 0; fpu : yes; fpu_exception : yes; cpuid level : 22; wp : yes; flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp; bugs : cpu_meltdown spectre_v1 spectre_v2; bogomips : 6816.62; clflush size : 64; cache_alignment : 64; address sizes : 39 bits physical, 48 bits virtual; power management:. I have used the preliminaries set in the exome case study, namely. ```; BASE=""/HD_disk/exome-case-study""; BUCKET=""gs://deepvariant""; BIN_VERSION=""0.6.1""; MODEL_VERSION=""0.6.0""; MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version.; BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*""; MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard""; DATA_BUCKET=""${BUCKET}/exome-case-study-testdata""; ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/74#issuecomment-391801518:1866,test,testdata,1866,,https://github.com/google/deepvariant/issues/74#issuecomment-391801518,1,['test'],['testdata']
Testability,"enerate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:123109,test,testlogs,123109,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) [2,519 / 2,523] 34 / 38 tests, 20 failed; Testing //deepvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:106412,test,testlogs,106412,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"er); ```; You can try to add `-v 1`. But in this case above, my run already had useful logging and didn't seem to produce more useful logs. ## What if we run with Singularity?. I think you were running with Singularity, so I tried that too. I repeated the steps in https://github.com/google/deepvariant/issues/463#issuecomment-866352316 to install Singularity. And then with the same data, I ran:. ```; # Pull the image.; BIN_VERSION=1.1.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" \; --reads ""quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam"" \; --examples ""quickstart-output/sing.make_examples.tfrecord.gz"" \; --gvcf ""quickstart-output/sing.gvcf.tfrecord.gz""; ```. Here is the log I got from my Singularity run:; ```; INFO: Using cached SIF image; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.562350 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:43:41.568112 139796154570496 make_examples.py:648] Preparing inputs; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.568638 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:43:41.569230 139796154570496 make_examples.py:648] Common contigs are ['chr20']; I0629 23:43:41.686007 139796154570496 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:15228,log,log,15228,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,1,['log'],['log']
Testability,"er@deepvariant:~/data$ samtools sort -f alignments20.bam alignments20_sorted.bam`; This command produced a sorted file with size of 7.75GB. 3. I tried running the `make_examples` script again with the new `alignments20_sorted.bam` file.; The command:; ```; python bin/make_examples.zip \; --mode training \; --ref ""data/chr20.fa"" \; --reads ""data/alignments20_sorted.bam"" \; --examples ""training-examples/training_set.with_label.tfrecord.gz"" \; --confident_regions ""data/NA12878.sorted.bed"" \; --truth_variants ""data/NA12878.sorted.vcf.gz"" \; --regions ""chr20"" \; --norealign_reads; ```; And The output: (receiving the same QUAL field missing error); ```; 2019-01-29 11:46:16.329383: W third_party/nucleus/io/sam_reader.cc:125] Unknown tag pb: in header line, ignoring: @HD VN:1.5 SO:coordinate pb:3.0.1; 2019-01-29 11:46:16.333216: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0129 11:46:16.334961 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/alignments20_sorted.bam with NativeSamReader; I0129 11:46:16.337215 140471159555840 make_examples.py:1024] Preparing inputs; 2019-01-29 11:46:16.340804: W third_party/nucleus/io/sam_reader.cc:125] Unknown tag pb: in header line, ignoring: @HD VN:1.5 SO:coordinate pb:3.0.1; 2019-01-29 11:46:16.344462: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0129 11:46:16.346041 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/alignments20_sorted.bam with NativeSamReader; I0129 11:46:16.360527 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/NA12878.sorted.vcf.gz with NativeVcfReader; I0129 11:46:16.361952 140471159555840 make_examples.py:946] Common contigs are [u'chr20']; I0129 11:46:16.501434 140471159555840 make_examples.py:1030] Writing examples to prj-NA12878/training-examples/training_set.with_label.tfrecord.gz; 2019-01-29 11:46:16.502209: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-458487916:1542,test,testdata,1542,,https://github.com/google/deepvariant/issues/138#issuecomment-458487916,1,['test'],['testdata']
Testability,"ere are my steps:. 1. Build locally (see [deepvariant-build-test.md](https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-build-test.md)). After build,; ```bash; ./build_release_binaries.sh; tar -cvzf bazel-deepvariant.tar.gz bazel-deepvariant/*; tar -cvzf bazel-genfiles.tar.gz bazel-genfiles/*; ```; 2. Go to another machine (i.e. Intel DevCloud) and clone repository. Unpack the binaries; ```bash; git clone -b master_openvino https://github.com/dkurt/deepvariant --depth 1; cd deepvariant; tar -xf bazel-deepvariant.tar.gz; tar -xf bazel-genfiles.tar.gz; ```; 3. Apply some patches to resolve local paths:; ```bash; sed -i -E 's|/opt/deepvariant/bin|./bazel-genfiles/deepvariant|' scripts/run_deepvariant.py; sed -i -E 's|/opt/models/wgs/model.ckpt|model.ckpt|' scripts/run_deepvariant.py; ln -s -f $HOME/deepvariant/scripts/ bazel-deepvariant/scripts; ```; 4. Download [GNU parallel](https://launchpad.net/ubuntu/bionic/amd64/parallel/20161222-1) (if you have no root permissions); ```bash; wget http://launchpadlibrarian.net/300780258/parallel_20161222-1_all.deb ; dpkg -x parallel_20161222-1_all.deb parallel; export PATH=$HOME/parallel/usr/bin:$PATH; ```. 5. Install TensorFlow MKL-DNN; ```bash; WHEEL_NAME=tensorflow-2.0.0-cp36-cp36m-linux_x86_64.whl; wget ""https://storage.googleapis.com/penporn-kokoro/tf-mkl-2.0-py36/${WHEEL_NAME}"" -O ""/tmp/${WHEEL_NAME}""; pip3 install --upgrade ""/tmp/${WHEEL_NAME}""; ```. 6. Run; ```bash; export INPUT_DIR=""${PWD}/quickstart-testdata""; export OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p $OUTPUT_DIR. export PYTHONPATH=./bazel-genfiles:$PYTHONPATH; python3 ./bazel-deepvariant/scripts/run_deepvariant.py \; --model_type=WGS \; --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \; --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=${OUTPUT_DIR}/output.vcf.gz \; --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \; --call_variants_extra_args=""use_openvino=True"" \; --num_shards=1; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-723242914:2493,test,testdata,2493,,https://github.com/google/deepvariant/pull/363#issuecomment-723242914,1,['test'],['testdata']
Testability,"esented to future samples. Thus you want as many good representative samples to train that model. That is why you want to shuffle across all your samples. The `make_examples` script only takes one BAM file via the `--reads` parameter, and you don't need to merge multiple BAM files into one, as the shuffling happens afterwards on the generated TFRecords. So the process is roughly as follows: ; 1) Run `make_examples` on training set BAMs, and run `make_examples` on validation set BAMs -- both of which will generate TFRecords.; 2) Shuffle TFRecords for training set, then shuffle the ones for validation set separately.; 3) Run `model_train` on shuffled training set shuffled data.; 4) Run `model_eval` on shuffled validation set data to evaluate generated checkpoints, which will generate `best_checkpoint.txt` and `best_checkpoint.metrics` files.; 5) Pick best model listed in the `best_checkpoint.txt` file.; 6) Test the best model with `run_deepvariant` by providing it to the `--customized_model` parameter, and for the `--reads` parameter setting it with the test data BAM file. ; 7) Benchmark by comparing your VCF with your Truth set VCF via [`hap.py`](https://github.com/Illumina/hap.py), and check the metrics against a baseline appropriate to your study.; 8) Then if you want, you could train/retrain a (new or previous) model by tuning the [modeling parameters](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md#parameters-to-tune) and/or updating the training data - i.e. if you want to make it more flexible to capture more variety in the input data - both of which might improve the model under different conditions. As Maria [mentioned previously](https://github.com/google/deepvariant/issues/698#issuecomment-1681392580), training is done on chromosome 1-19, then evaluation on 21-22, with a test on 20. Usually all training is done on some data, then evaluated on another for picking the best model, and finally the best model would be teste",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1711096081:1380,Test,Test,1380,,https://github.com/google/deepvariant/issues/706#issuecomment-1711096081,2,"['Test', 'test']","['Test', 'test']"
Testability,"et.LCL5.GRCh38.HiFi.minimap2.bam"",; output:; bam=dir_work + ""bams/ChineseQuartet.{region}.bam"",; bed=dir_work + ""bams/ChineseQuartet.{region}.bed"",; run:; chrom, start, end = f""{wildcards.region}"".split(""_""); start = int(start) - 1000; end = int(end) + 1000; shell(""{samtools} view -h -O BAM {input.bam} {chrom}:{start}-{end} > {output.bam}""); shell(""echo '{chrom}\t{start}\t{end}' > {output.bed}""). rule deepvariant:; input:; bam=dir_work + ""bams/ChineseQuartet.{region}.bam"",; bai=dir_work + ""bams/ChineseQuartet.{region}.bam.bai"",; bed=dir_work + ""bams/ChineseQuartet.{region}.bed"",; ref=path_ref; output:; vcf_gz=dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.vcf.gz"",; gvcf_gz=dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.g.vcf.gz""; # gvcf_gz=config[""dir_variants""] + ""dv/dv_details/{sample}/{sample}.{prefix}.dv.raw.g.vcf.gz""; log:; dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.log""; benchmark:; dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.log""; threads: 48; run:; dir_tmp = str(output.vcf_gz).rstrip("".vcf.gz"") + ""_tmp""; file_tmp = dir_tmp.split(""/"")[-1]; shell(""mkdir -p "" + dir_tmp); bam_dir = ""/"".join(str(input.bam).split(""/"")[:-1]); bam_file = str(input.bam).split(""/"")[-1]; bed_file = str(input.bed).split(""/"")[-1]; ref_dir = ""/"".join(str(input.ref).split(""/"")[:-1]); ref_file = str(input.ref).split(""/"")[-1]; output_dir = ""/"".join(str(output.vcf_gz).split(""/"")[:-1]); output_file = str(output.vcf_gz).split(""/"")[-1].rstrip("".vcf.gz""). shell('docker run '; '-v ""{bam_dir}"":""/input"" '; '-v ""{ref_dir}"":""/ref"" '; '-v ""{output_dir}"":""/output"" '; 'google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant '; '--model_type=PACBIO '; '--ref=/ref/{ref_file} '; '--reads=/input/{bam_file} '; '--regions /input/{bed_file} '; '--output_vcf=/output/{output_file}.vcf '; '--output_gvcf=/output/{output_file}.g.vcf '; '--num_shards={threads} '; '--make_examples_extra_args min_mapping_quality=1,keep_supplementary_alignments=true '; '--intermediate_results_dir /ou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/660#issuecomment-1589724792:2402,log,log,2402,,https://github.com/google/deepvariant/issues/660#issuecomment-1589724792,1,['log'],['log']
Testability,"etails:; '@type': type.googleapis.com/google.genomics.v2alpha1.WorkerReleasedEvent; instance: google-pipelines-worker-4b16fd95b691baddc54b0c5ec50dc6c7; zone: us-west1-b; timestamp: '2018-11-08T14:30:59.324697Z'; - description: 'Execution failed: action 1: unexpected exit status 1 was not ignored'; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.FailedEvent; cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored'; code: FAILED_PRECONDITION; timestamp: '2018-11-08T14:30:58.518326Z'; - description: Stopped running ""/bin/sh -c gsutil -q cp /google/logs/output gs://canis/CNR-data/deep_variant_files/runner_logs_20181108_082705.log""; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.ContainerStoppedEvent; actionId: 2; exitStatus: 0; stderr: ''; timestamp: '2018-11-08T14:30:58.416239Z'; - description: Started running ""/bin/sh -c gsutil -q cp /google/logs/output gs://canis/CNR-data/deep_variant_files/runner_logs_20181108_082705.log""; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.ContainerStartedEvent; actionId: 2; ipAddress: ''; portMappings: {}; timestamp: '2018-11-08T14:30:55.929647Z'; - description: Unexpected exit status 1 while running ""-c /opt/deepvariant_runner/bin/gcp_deepvariant_runner --project; valis-194104 --zones us-west1-b --docker_image gcr.io/deepvariant-docker/deepvariant:0.7.0 --outfile; gs://canis/CNR-data/TLE_a_001_deep_variant.vcf --staging gs://canis/CNR-data/deep_variant_files --model; gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard --regions; gs://canis/CNR-data/CDS-canonical.bed --bam gs://canis/CNR-data/TLE_a_001.bam --bai; gs://canis/CNR-data/TLE_a_001.bam.bai --ref gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz --ref_fai; gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz.fai --ref_gzi gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz.gzi --gcsfuse""; details:; '@type': type.googleapis.com/google.genomics.v2alpha1.UnexpectedExitStatusE",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437055644:1343,log,log,1343,,https://github.com/google/deepvariant/issues/116#issuecomment-437055644,1,['log'],['log']
Testability,"etch --all --tags --prune; # check out tag 3.4.5.20; git checkout tags/20; # load submoduel; git submodule update --init --recursive. # Dependency; pip install pyparsing; yum install qt-devel; # Build; python setup.py bdist_wheel. # Insatll; pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session; python -c ""import cv2""; ```. ## DV Prerequisite. ```bash; ####################################################################; # misc setup; ####################################################################. # development packages; yum install python2-pkgconfig zip zlib-devel unzip curl -y; # python packages; yum install python-devel python-pip python-wheel -y. ####################################################################; # python packages; ####################################################################. # python 2 required; echo ""$(python --version)""; echo ""$(pip --version)"". # Install python packages; pip install contextlib2; pip install enum34; pip install intervaltree; pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'; # pip install 'scipy==1.0' => skip as installed in TF; pip install 'oauth2client>=4.0.0'; pip install 'crcmod>=1.7'; pip install six; pip install sklearn; pip install pandas; pip install psutil; pip install --upgrade google-api-python-client. ####################################################################; # depend on opencv-python wheel - build from source; ####################################################################; pip install 'tensor2tensor>=1.9.0'. ####################################################################; # depend on - TensorFlow - 1.12 build from source; ####################################################################; pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################; # Misc dependencies; #################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:16414,mock,mock,16414,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,1,['mock'],['mock']
Testability,"evel. if you run `/opt/deepvariant/bin/make_examples --helpfull` you'll see this flag:. ```; -v,--verbosity: Logging verbosity level. Messages logged at this level or; lower will be included. Set to 1 for debug logging. If the flag was not set; or supplied, the value will be changed from the default of -1 (warning) to 0; (info) after flags are parsed.; (default: '-1'); (an integer); ```; You can try to add `-v 1`. But in this case above, my run already had useful logging and didn't seem to produce more useful logs. ## What if we run with Singularity?. I think you were running with Singularity, so I tried that too. I repeated the steps in https://github.com/google/deepvariant/issues/463#issuecomment-866352316 to install Singularity. And then with the same data, I ran:. ```; # Pull the image.; BIN_VERSION=1.1.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" \; --reads ""quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam"" \; --examples ""quickstart-output/sing.make_examples.tfrecord.gz"" \; --gvcf ""quickstart-output/sing.gvcf.tfrecord.gz""; ```. Here is the log I got from my Singularity run:; ```; INFO: Using cached SIF image; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.562350 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:43:41.568112 139796154570496 make_examples.py:648] Preparing inputs; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:14978,test,testdata,14978,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,1,['test'],['testdata']
Testability,"examples.py"", line 1616, in region_reads; error_message + '\nFailed to parse BAM/CRAM file. '; ValueError: Data loss: Failed to parse SAM record; Failed to parse BAM/CRAM file. This is often caused by:; (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file.; (2) Your BAM/CRAM file could be corrupted. Please check its md5.; If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues; ```. It seems like for this particular failure mode (BAM file is truncated), the default stackt race was already clear.; But given that I mentioned different level of verbosity. I tried that next. ## Use `-v` to increase verbosity level. if you run `/opt/deepvariant/bin/make_examples --helpfull` you'll see this flag:. ```; -v,--verbosity: Logging verbosity level. Messages logged at this level or; lower will be included. Set to 1 for debug logging. If the flag was not set; or supplied, the value will be changed from the default of -1 (warning) to 0; (info) after flags are parsed.; (default: '-1'); (an integer); ```; You can try to add `-v 1`. But in this case above, my run already had useful logging and didn't seem to produce more useful logs. ## What if we run with Singularity?. I think you were running with Singularity, so I tried that too. I repeated the steps in https://github.com/google/deepvariant/issues/463#issuecomment-866352316 to install Singularity. And then with the same data, I ran:. ```; # Pull the image.; BIN_VERSION=1.1.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" \; --reads ""quickstart-testdata/NA1287",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:14038,log,logged,14038,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,1,['log'],['logged']
Testability,"f the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```; sh deepvariant_run_Exome_BWA_MEM_by-step.sh; Reading package lists... Done; Building dependency tree; Reading state information... Done; time is already the newest version (1.7-25.1+b1).; 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.; Reading package lists... Done; Building dependency tree; Reading state information... Done; parallel is already the newest version (20161222-1).; 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.; mkdir: cannot create directory ‘logs’: Permission denied; 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k; 0inputs+0outputs (0major+73minor)pagefaults 0swaps; Academic tradition requires you to cite works you base your a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483490946:2956,test,tested,2956,,https://github.com/google/deepvariant/issues/171#issuecomment-483490946,1,['test'],['tested']
Testability,"f_idx ]` return `true`.; here is the script:; ```shell; #!/bin/bash. dvsif=""/lustre/Data/toolsDB//deepvariant.sif""; ref_idx=""/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa"". wkdir=""/lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP""; bamdir=""${wkdir}/mappinged_bams""; logdir=""${wkdir}/logs""; vcfoutdir=""${wkdir}/DeepVariant_outputs"". source activate ~/.conda/envs/zjlEnv. echo -e ""ref_idx is $ref_idx\n""; if [ -f ""$ref_idx"" ];; then; echo -e ""ref_idx $ref_idx exists!\n""; which ls; echo -e ""ls -al --block=M ${ref_idx}*\n""; ls -al --block=M ""${ref_idx}*""; echo -e ""ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*\n""; ls -al --block=M ""/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*""; echo -e ""/bin/ls -al --block=M ${ref_idx}*\n""; /bin/ls -al --block=M ""${ref_idx}*"". else; echo -e ""Warning!! ref_idx [$ref_idx] not exist!\n""; fi. ls -al ""${ref_idx}*""; singularity run $dvsif ls $ref_idx. ```. Here is the running output:; ```shell; $ bash scripts/02_run_deepvariant.sh ; ref_idx is /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa. ref_idx /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa exists!. /usr/bin/ls; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. ls: cannot access /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*: No such file or directory; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. ls: cannot access /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*: No such file or directory; /bin/ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. /bin/ls: cannot access /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*: No such file or directory; ls: cannot access /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*: No such file or directory; INFO: Converting SIF file to temporary sandbox...; /usr/bin/ls: cannot access '/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa': No such file or directory; INFO: Cleaning up image... ```. Could you please help me?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1568200761:3313,sandbox,sandbox,3313,,https://github.com/google/deepvariant/issues/653#issuecomment-1568200761,1,['sandbox'],['sandbox']
Testability,"fda.gov/challenges/truth/results-explore)"", and select “**func_cds**” (which is where I would expect most of the clinically actionable variants to be) DeepVariant is **not** top ranked for either F-score, Recall, or Precision (although the values are high, like the other variant calling results). I also created a [discussion group](https://precision.fda.gov/discussions/55-hg002-truth-dataset) on precisionFDA asking about how the “truth” set was defined. They mentioned that they **focused on regions where variants could be made most confidently** (genome-wide), and I’m assuming that is why most of the numbers are so high. Otherwise, they are more in the range of using [my same WGS sample and variant caller (DeepVariant) while only changing the alignment](https://precision.fda.gov/comparisons/3437), which isn’t really an independent verification (matching my original concern that the percentages being reported seemed unrealistically high). **In other words, I would say DeepVariant performed well, *along with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to creat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:6589,test,tested,6589,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,1,['test'],['tested']
Testability,"ference_bases: ""A""; alternate_bases: ""C""; end: 11; reference_name: ""20""; start: 10; , reference_bases: ""A""; alternate_bases: ""C""; end: 21; reference_name: ""20""; start: 20; ]) (__main__.HaplotypeLabelerClassUnitTest); test_make_labeler_ref(truths=[], expected_end=21, expected_start=9, bufsize=0, candidates=[reference_bases: ""A""; alternate_bases: ""C""; end: 11; reference_name: ""20""; start: 10; , reference_bases: ""A""; alternate_bases: ""C""; end: 21; reference_name: ""20""; start: 20; ]) (__main__.HaplotypeLabelerClassUnitTest); test_make_labeler_ref(truths=[], expected_end=21, expected_start=9, bufsize=0, candidates=[reference_bases: ""A""; ----------------------------------------------------------------------; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/dc155a991b1776fcc65387121539d20a/execroot/com_google_deepvariant/bazel-out/ppc-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/absl_py/absl/third_party/unittest3_backport/case.py"", line 37, in testPartExecutor; yield; File ""/root/.cache/bazel/_bazel_root/dc155a991b1776fcc65387121539d20a/execroot/com_google_deepvariant/bazel-out/ppc-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/absl_py/absl/third_party/unittest3_backport/case.py"", line 162, in run; testMethod(); File ""/root/.cache/bazel/_bazel_root/dc155a991b1776fcc65387121539d20a/execroot/com_google_deepvariant/bazel-out/ppc-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/absl_py/absl/testing/parameterized.py"", line 256, in bound_param_test; test_method(self, **testcase_params); File ""/root/.cache/bazel/_bazel_root/dc155a991b1776fcc65387121539d20a/execroot/com_google_deepvariant/bazel-out/ppc-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/haplotype_labeler_test.py"", line 371, in test_make_labeler_ref; ranges.make_range('20', expected_start, expected_end)); File ""/home/qilibj/inst/lib/python2.7/site-packages/mock/mock.py"", line 948, in assert_called_once_w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/154#issuecomment-464683367:1324,test,testPartExecutor,1324,,https://github.com/google/deepvariant/issues/154#issuecomment-464683367,1,['test'],['testPartExecutor']
Testability,"file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:17) FAIL: //deepvariant:variant_caller_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log); (06:29:17) INFO: From Testing //deepvariant:variant_caller_test:; ==================== Test output for //deepvariant:variant_caller_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/variant_caller_test.runfiles/com_google_deepvariant/deepvariant/variant_caller_test.py"", line 43, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/variant_caller_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.loc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:75476,test,testing,75476,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['test'],['testing']
Testability,"flow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) [2,492 / 2,523] 21 / 38 tests, 7 failed; Testing //deepvariant:model_eval_test [0s (10 actions)] ... (31 actions, 2 running); (06:29:12) FAIL: //deepvariant:model_eval_test (shard 1 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log); (06:29:12) INFO: From Testing //deepvariant:model_eval_test (shard 1 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 1 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:40156,log,log,40156,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"flow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:17) FAIL: //deepvariant:variant_caller_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log); (06:29:17) INFO: From Testing //deepvariant:variant_caller_test:; ==================== Test output for //deepvariant:variant_caller_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/variant_caller_test.runfiles/com_google_deepvariant/deepvariant/variant_caller_test.py"", line 43, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/variant_caller_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:75024,log,log,75024,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"g data.; MODEL=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard. IMAGE_VERSION=0.7.2; DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}""; COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \; --project ${PROJECT_ID} \; --zones us-west2-* \; --sample_name VeritasProvided \; --docker_image ${DOCKER_IMAGE} \; --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \; --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \; --model ${MODEL} \; --bam gs://cdw-genome/Charles_Human/Veritas_WGS/Combined_Veritas_Alignment/veritas_wgs.filter.bam \; --ref gs://cdw-genome/Ref/hg19.gatk.fasta \; --gcsfuse""; ; # Run the pipeline.; # run after 'gcloud config set compute/region """"'; gcloud alpha genomics pipelines run \; --project ""${PROJECT_ID}"" \; --regions us-west2 \; --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \; --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \; 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \; --command-line ""${COMMAND}""; ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483490946:1576,log,log,1576,,https://github.com/google/deepvariant/issues/171#issuecomment-483490946,1,['log'],['log']
Testability,"g for help.; ================================================================================; (06:29:08) FAIL: //deepvariant/realigner:aligner_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log); (06:29:08) INFO: From Testing //deepvariant/realigner:aligner_test:; ==================== Test output for //deepvariant/realigner:aligner_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/aligner_test.runfiles/com_google_deepvariant/deepvariant/realigner/aligner_test.py"", line 40, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/aligner_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:15082,test,testing,15082,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['test'],['testing']
Testability,"g/testdata/aligned_reads.bam with NativeSamReader; I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs; 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'; [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi; [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi; I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run; _sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main; make_examples_runner(options); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner; regions = processing_regions_from_options(options); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options; options.min_shared_contigs_basepairs); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_con",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-448201709:2598,test,testdata,2598,,https://github.com/google/deepvariant/issues/128#issuecomment-448201709,1,['test'],['testdata']
Testability,"gle_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; (06:29:20) FAIL: //deepvariant:model_eval_test (shard 9 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log); (06:29:20) INFO: From Testing //deepvariant:model_eval_test (shard 9 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 9 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:108035,log,log,108035,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"gle_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; (05:40:51) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (05:40:51) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:2107,log,log,2107,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"gner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:122793,test,testlogs,122793,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"golden.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_gvcf_output.g.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.vcf_candidate_importer.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00001-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_single_site_output.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/HG002_ONT_deeptrio.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/golden.vcf_candidate_importer.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/alt_aligned_pileup.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 199, 8], ""channels"": [1, 2, 3, 4, 5, 6, 9, 10]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00001-of-00003.example_info.json:{""ve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040:3495,test,testdata,3495,,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040,1,['test'],['testdata']
Testability,gs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log; //deepvariant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:121799,log,log,121799,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"h test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```; sh deepvariant_run_Exome_BWA_MEM_by-step.sh; Reading package lists... Done; Building dependency tree; Reading state information... Done; time is already the newest version (1.7-25.1+b1).; 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.; Reading package lists... Done; Building dependency tree; Reading state information... Done; parallel is already the newest version (20161222-1).; 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.; mkdir: cannot create directory ‘logs’: Permission denied; 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k; 0inputs+0outputs (0major+73minor)pagefaults 0swaps; Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists.; time=""2019-04-16T02:45:46Z"" level=error msg=""error waiting for container: context canceled""; parallel: This job failed:; sudo docker run -v /home/cwarden/cdw-genome:/mnt/cdw-genome gcr.io/deepvariant-docker/deepvariant /opt/deepvariant/bin/make_examples --mode calling --ref /mnt/cdw-genome/Ref/hg19.gatk.fasta --reads /mnt/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/BWA-MEM_realign_TARG",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483490946:4218,log,login,4218,,https://github.com/google/deepvariant/issues/171#issuecomment-483490946,1,['log'],['login']
Testability,"ha genomics pipelines run \; --project ""${PROJECT_ID}"" \; --regions us-west2 \; --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \; --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \; 	--docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \; --command-line ""${COMMAND}""; ```. I admittedly didn't know what were the default settings, and I saw larger numbers in the later commands. While that gives me other options to test to decrease run-time, it sounds like I should point out that these are two cloud comparisons (*not* being run on my local machine - that was only GATK). It also looks like I used an earlier version of one of the tutorials (not exactly what is provided in the Exome case study). So, I apologize for the confusion. **1b)** I think my answer is in *1a)* above. After I finish running testing with computations on Google Cloud, I'll keep an eye on the credits to see what the storage cost is now (although it should be higher now than before, because I have started to do other stuff with my Google Cloud account now). **2)** I wonder if there is an issue with how I have the bucket mounted and/or I am running Docker (although that is probably beyond the scope of this post, and I'll close the issue if I start focusing on stuff not related to DeepVariant). Nevertheless, I have my bucket (cdw-genome) mounted in my home directory (/home/cwarden), because it didn't work if I tried to mount it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483490946:2229,test,testing,2229,,https://github.com/google/deepvariant/issues/171#issuecomment-483490946,1,['test'],['testing']
Testability,"he file was truncated, sorry about that. I am still testing locally; with other even smaller files ( like : wget; http://dv-testfiles.s3.amazonaws.com/wgEncodeUwRepliSeqGm12878G1bAlnRep1.bam; which is public and smaller and not truncated ) and I get the same exact; error again. 2018-03-07 22:36 GMT+01:00 Paul Grosu <notifications@github.com>:. > I was suspicious something else might be the issue. So I did a simple test; > to see if there is an issue with Luisa's BAM file, and noticed that I; > cannot even create an index - which would naturally make even the; > prerequisite make_examples not complete properly:; >; > paul@gubuntu:~/data/luisa$ wget http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > --2018-03-07 <http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam--2018-03-07> 16:20:42-- http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > Resolving dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)... 52.218.52.113; > Connecting to dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)|52.218.52.113|:80... connected.; > HTTP request sent, awaiting response... 200 OK; > Length: 357342653 (341M) [binary/octet-stream]; > Saving to: âENCFF528VXT.bamâ; >; > ENCFF528VXT.bam 100%[=========================================================>] 340.79M 1.26MB/s in 5m 17s; >; > 2018-03-07 16:25:59 (1.08 MB/s) - âENCFF528VXT.bamâ saved [357342653/357342653]; >; > paul@gubuntu:~/data/luisa$ samtools index ENCFF528VXT.bam; > [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; > [E::bgzf_read] Read block operation failed with error -1 after 143 of 246 bytes; > samtools index: failed to create index for ""ENCFF528VXT.bam""; > paul@gubuntu:~/data/luisa$; > paul@gubuntu:~/data/luisa$; > paul@gubuntu:~/data/luisa$ cd ~/deepvariant/bazel-bin; > paul@gubuntu:~/deepvariant/bazel-bin$ PYTHONPATH=. /usr/bin/python deepvariant/make_examples --mode calling --ref /home/paul/data/luisa/hg19.fa --reads /home/paul/data/luisa/ENCFF528VXT.bam --examples /h",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371306075:1007,test,testfiles,1007,,https://github.com/google/deepvariant/issues/52#issuecomment-371306075,1,['test'],['testfiles']
Testability,"hi @pichuan , this log line is generated from my bash function wrapper running singularity version of DeepTrio. I confirm that I am using the official docker image (converted to SIF image with Singularity)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/646#issuecomment-1547132456:19,log,log,19,,https://github.com/google/deepvariant/issues/646#issuecomment-1547132456,1,['log'],['log']
Testability,"hi @sounkou-bioinfo,. Thank you for bringing up this issue. We have not worked on this specifically but I will try to give this a shot in our next release. It's a reasonable request and we may have the right logics to fix this in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/875#issuecomment-2322170478:208,log,logics,208,,https://github.com/google/deepvariant/issues/875#issuecomment-2322170478,1,['log'],['logics']
Testability,"hink Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help!; I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file.; I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file.; And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```; python bin/make_examples.zip \; --mode training \; --ref ""project-retraining/testdata/sequence.fasta"" \; --reads ""project-retraining/testdata/aligned_reads.bam"" \; --examples ""project-retraining/training_examples"" \; --confident_regions ""project-retraining/testdata/variants.bed"" \; --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1; ```. and I get the same ValueError as before (from `make_examples.log` file):. ```; 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs; 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-448201709:1274,log,logs,1274,,https://github.com/google/deepvariant/issues/128#issuecomment-448201709,1,['log'],['logs']
Testability,"his TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2021-06-22 21:25:07.731210: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000170000 Hz; 2021-06-22 21:25:07.731675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e87820 initialized for platform Host (this does not guarantee that XLA will be used). Devices:; 2021-06-22 21:25:07.731713: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version; 2021-06-22 21:25:07.734891: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; ```; which confirms that I'm using AVX optimization. The log for call_variants is pretty short, because WES has fewer examples to run on. My `call_variants` log look like this:; ```; I0622 21:25:17.009006 140301916206848 saver.py:1293] Restoring parameters from /opt/models/wes/model.ckpt; I0622 21:25:24.567713 140301916206848 call_variants.py:454] Processed 1 examples in 1 batches [1678.300 sec per 100]; I0622 21:26:59.442872 140301916206848 call_variants.py:454] Processed 15001 examples in 30 batches [0.744 sec per 100]; I0622 21:28:34.156948 140301916206848 call_variants.py:454] Processed 30001 examples in 59 batches [0.688 sec per 100]; I0622 21:30:08.158901 140301916206848 call_variants.py:454] Processed 45001 examples in 88 batches [0.667 sec per 100]; I0622 21:30:37.846297 140301916206848 call_variants.py:458] Processed 49760 examples in 98 batches [0.663 sec per 100]; I0622 21:30:37.846524 140301916206848 call_variants.py:461] Done calling variants from a total of 49760 examples. real 5m34.074s; user 32m1.122s; sys 0m32.211s; ```. Note that the CPU usage for `call_variant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866352316:5396,log,log,5396,,https://github.com/google/deepvariant/issues/463#issuecomment-866352316,1,['log'],['log']
Testability,hi，; Thanks for your reply. I mean BQSR. I tested on WES data. The result : ; 1. deal with deduplication and BQSR：; ![1682582003166](https://user-images.githubusercontent.com/70870741/234796615-a5ce10c7-da7b-4542-8717-b2cde03fc478.jpg); 2. only deal with deduplication:; ![1682582061403](https://user-images.githubusercontent.com/70870741/234796818-f7bb9a58-dc50-4a96-8848-6bd785b0b136.jpg). Can I think BQSR processed results are better?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/638#issuecomment-1525033039:43,test,tested,43,,https://github.com/google/deepvariant/issues/638#issuecomment-1525033039,1,['test'],['tested']
Testability,"ho ""Installing GPU-enabled TensorFlow ${DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION} wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade ""tensorflow-gpu==${DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION}""; # elif [[ ""${DV_USE_GCP_OPTIMIZED_TF_WHL}"" = ""1"" ]]; then; # echo ""Installing Intel's CPU-only MKL TensorFlow ${DV_GCP_OPTIMIZED_TF_WHL_VERSION} wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade ""intel-tensorflow==${DV_GCP_OPTIMIZED_TF_WHL_VERSION}""; # else; echo ""Installing standard CPU-only TensorFlow ${DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION} wheel""; pip3 install ""${PIP_ARGS[@]}"" --upgrade ""tensorflow==${DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION}""; # fi; # fi; # fi. # # A temporary fix.; # # Context: intel-tensorflow 2.7.0 will end up updating markupsafe to 2.1.1,; # # which caused the issue here: https://github.com/pallets/markupsafe/issues/286.; # # Specifically:; # # ImportError: cannot import name 'soft_unicode' from 'markupsafe'.; # # So, forcing a downgrade. This isn't the best solution, but we need it to get; # # our tests pass.; pip3 install ""${PIP_ARGS[@]}"" --upgrade 'markupsafe==2.0.1'. # ################################################################################; # # CUDA; # ################################################################################. # note_build_stage ""Install CUDA"". # # See https://www.tensorflow.org/install/source#gpu for versions required.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # if [[ ""${DV_INSTALL_GPU_DRIVERS}"" = ""1"" ]]; then; # # This script is only maintained for Ubuntu 20.04.; # UBUNTU_VERSION=""2004""; # # https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_local; # echo ""Checking for CUDA...""; # if ! dpkg-query -W cuda-11-3; then; # echo ""Installing CUDA...""; # UBUNTU_VERSION=""2004""; # curl -O https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin; # sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-rep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:2238,test,tests,2238,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,1,['test'],['tests']
Testability,"homas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,; From a quick look of your error, it doesn't look like anything I've ever; encountered before. If you could potentially set up a reproducible setting; that I can very quickly run, I can see if I can try it out and tell you; what might could have gone wrong. We don't currently have a tutorial for; training, unfortunately. And to be honest, even if we do, it probably; wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is; > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for; > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:; > [64,27,1,3]; >; >; > I hate to keep bothering people about this. Is there documentation on all; > of this that I can refer to?; >; >; > Thanks,; > Brad Thomas; >; >; > From: Pi-Chuan Chang [mailto:notifications@github.com]; > Sent: Tuesday, April 10, 2018 1:04 PM; > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>; > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <; > author@noreply.github.com<mailto:author@noreply.github.com>>; > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62); >; > CAUTION: This email originated from outside the organization. DO NOT click; > links or open attachments unless you recognize the sender and know the; > content is safe.; >; > I think you'll want:; > tfrecord_path:; > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064""; >; > —; > You are receiving this because you authored th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-381164890:1352,Log,Logits,1352,,https://github.com/google/deepvariant/issues/62#issuecomment-381164890,1,['Log'],['Logits']
Testability,"hon/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:123821,log,log,123821,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"hon/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) [2,512 / 2,523] 28 / 38 tests, 14 failed; Testing //deepvariant/realigner:realigner_test; 0s local ... (11 actions, 2 running); (06:29:18) FAIL: //deepvariant/realigner:realigner_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner:realigner_test:; ==================== Test output for //deepvariant/realigner:realigner_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/realigner_test.runfiles/com_google_deepvariant/deepvariant/realigner/realigner_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:87998,log,log,87998,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"hot.gpg.key | apt-key add - && \; add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main""; @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \; libllvm11 \; llvm-11 \; llvm-11-dev \; - llvm-11-linker-tools \; python3-dev \; zlib1g-dev; ; @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then; git checkout ""${CLIF_PIN}""; fi; ; +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake ; ./INSTALL.sh; ```; After these changes, I am stuck again at building clif because of the following error:; ```; [100%] Linking CXX executable clif-matcher; /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':; matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'; /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':; matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'; collect2: error: ld returned 1 exit status; make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1; make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2; make[1]: *** [CMak",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217:5599,Log,LogMessage,5599,,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217,2,['Log'],['LogMessage']
Testability,"hs37d5/hs37d5.fa.0123; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann; -rw-rw-r-- 1 zhoujianglin zhoujianglin 9725M Apr 26 15:42 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64; -rw-rw-r-- 1 zhoujianglin zhoujianglin 1M May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai; -rw-rw-r-- 1 zhoujianglin zhoujianglin 749M Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.pac; ```. However, If I run the follow bash script, it can not find `ref_idx` through `ls` command, whereas shell condition expression ` [ -f $ref_idx ]` return `true`.; here is the script:; ```shell; #!/bin/bash. dvsif=""/lustre/Data/toolsDB//deepvariant.sif""; ref_idx=""/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa"". wkdir=""/lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP""; bamdir=""${wkdir}/mappinged_bams""; logdir=""${wkdir}/logs""; vcfoutdir=""${wkdir}/DeepVariant_outputs"". source activate ~/.conda/envs/zjlEnv. echo -e ""ref_idx is $ref_idx\n""; if [ -f ""$ref_idx"" ];; then; echo -e ""ref_idx $ref_idx exists!\n""; which ls; echo -e ""ls -al --block=M ${ref_idx}*\n""; ls -al --block=M ""${ref_idx}*""; echo -e ""ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*\n""; ls -al --block=M ""/lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*""; echo -e ""/bin/ls -al --block=M ${ref_idx}*\n""; /bin/ls -al --block=M ""${ref_idx}*"". else; echo -e ""Warning!! ref_idx [$ref_idx] not exist!\n""; fi. ls -al ""${ref_idx}*""; singularity run $dvsif ls $ref_idx. ```. Here is the running output:; ```shell; $ bash scripts/02_run_deepvariant.sh ; ref_idx is /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa. ref_idx /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa exists!. /usr/bin/ls; ls -al --block=M /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*. ls: cannot access /lustre/Data/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1568200761:1766,log,logdir,1766,,https://github.com/google/deepvariant/issues/653#issuecomment-1568200761,2,['log'],"['logdir', 'logs']"
Testability,"https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================. FAILED: //deepvariant:make_examples_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; (06:29:20) FAIL: //deepvariant:make_examples_test (shard 1 of 2) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log); (06:29:20) INFO: From Testing //deepvariant:make_examples_test (shard 1 of 2):; ==================== Test output for //deepvariant:make_examples_test (shard 1 of 2):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/deepvariant/make_examples_test.py"", line 48, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 69, in <module>; from third_party.nucleus.io import genomics_reader; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 82, in <module>; from tensorflow.python.lib.io import python_io; File ""/root/.local/lib/pyt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:100720,log,log,100720,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"iables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option.; ```; Because in our code, we use a regular expression like this:; https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start.; This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:; ```; vars_to_warm_start=['|'.join(vars_to_include)]); ```; which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model.; So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/185#issuecomment-494919509:2064,log,log,2064,,https://github.com/google/deepvariant/issues/185#issuecomment-494919509,2,"['benchmark', 'log']","['benchmark', 'log']"
Testability,"iant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:125813,test,testlogs,125813,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ibcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) [2,519 / 2,523] 34 / 38 tests, 20 failed; Testing //deepvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:106760,test,testlogs,106760,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"icense of this software.; mobile-install Installs targets to mobile devices.; print_action Prints the command line args for compiling a file.; query Executes a dependency graph query.; run Runs the specified target.; shutdown Stops the bazel server.; sync Syncs all repositories specified in the workspace file; test Builds and runs the specified test targets.; version Prints version information for bazel. Getting more help:; bazel help <command>; Prints help and options for <command>.; bazel help startup_options; Options for the JVM hosting bazel.; bazel help target-syntax; Explains the syntax for specifying targets.; bazel help info-keys; Displays a list of keys used by the info command.; + [[ 1 = \1 ]]; + bazel test -c opt --local_test_jobs=1 --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11 deepvariant/...; (05:40:22) INFO: Options provided by the client:; Inherited 'common' options: --isatty=1 --terminal_columns=166; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.bazelrc:; Inherited 'common' options: --experimental_repo_remote_exec; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.bazelrc:; Inherited 'build' options: --define framework_shared_object=true --define tsl_protobuf_header_only=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tenso",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:5216,test,test,5216,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,1,['test'],['test']
Testability,"ike;; > Thanks for all this background and help. I'm trying to fit this into the; > conda recipe bazel build for DeepVariant but am not sure how to take; > advantage of using the local anaconda python in that context. The error I'm; > seeing is that bazel can't find pyclif_proto:; >; > (17:56:01) INFO: Found 1 target...; > (17:56:01) [0 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt; > (17:56:01) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'; > (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1: //third_party/nucleus/protos:variants_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'; > Target //deepvariant:binaries failed to build; > (17:56:01) ERROR: /opt/conda/conda-bld/deepvariant_1525283132666/work/deepvariant-0.6.1/third_party/nucleus/protos/BUILD:165:1 1 input file(s) do not exist; >; > which I thought was triggered by the difficulty running pyclif without; > having the local python installed. It could also be due to not installing; > is in /usr/local/bin since I have to remain sandboxed in the work; > directory, but I did adjust the PATH to include the download location.; >; > Sorry I'm stuck here due to me limited knowledge of bazel tweaking. Either; > understanding how to handle a root install of the pre-build pyclif or; > tweaking to use the local python would be helpful. Alternatively, if you; > can already build DeepVariant on a CentOS6 system yourself I could use the; > pre-build binaries the way we're doing now, just with the build against an; > older glibc. Thanks again for the help with this.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/29#issuecomment-386250002>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABQZ2kaD2Oo0vlzfw55tL9A65ZhknIu-ks5tutlEgaJpZM4RQhCy>; > .; >. -- ; Thanks,; --Mike",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-386327937:1726,sandbox,sandboxed,1726,,https://github.com/google/deepvariant/issues/29#issuecomment-386327937,1,['sandbox'],['sandboxed']
Testability,"iles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 429, in bed_parser; with bed.BedReader(filename) as fin:; File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 211, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader; return NativeBedReader(input_path, **kwargs); File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__; self._reader = bed_reader.BedReader.from_file(bed_path, options); ValueError: Not found: Could not open gs://gbsc-gcp-project-udn-dev-test/VCRome_2_1_hg19_capture_targets_chrStripped.bed; parallel: This job failed:; Using mount point: /input-gcsfused-48; Opening GCS connection...; Opening bucket...; Mounting file system...; File system has been successfully mounted.; mkdir -p ./input-gcsfused-48 && gcsfuse --implicit-dirs gbsc-gcp-project-udn-dev-deep-variant /input-gcsfused-48 && /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/gbsc-gcp-project-udn-dev-deep-variant/UDN668131_deepVariant_test4/deepvariant_staging_folder/examples/examples_output.tfrecord@64.gz --reads /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bam --ref /mnt/google/.google/input/gbsc-gcp-project-udn-dev-test/hs37d5_ref/hs37d5.fa --task 48 --regions gs://gbsc-gcp-project-udn-dev-test/VCRome_2_1_hg19_capture_targets_chrStripped.bed. operation id: 3776708258517585322. $ gsutil ls gs://gbsc-gcp-project-udn-dev-test/VCRome_2_1_hg19_capture_targets_chrStripped.bed; gs://gbsc-gcp-project-udn-dev-test/VCRome_2_1_hg19_capture_targets_chrStripped.bed. [deepvariant_v0.7.0_UDN668131_test.sh.txt](https://github.com/google/deepvariant/files/2567583/deepvariant_v0.7.0_UDN668131_test.sh.txt). Thanks,; Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/118#issuecomment-437503051:4997,test,test,4997,,https://github.com/google/deepvariant/issues/118#issuecomment-437503051,4,['test'],['test']
Testability,ileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log; //deepvariant/labeler:haplotype_labeler_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log; //deepvariant/labeler:labeled_examples_to_vcf_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log; //deepvariant/labeler:positional_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log; //deepvariant/labeler:variant_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepva,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:119859,test,testlogs,119859,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,impl_linux-64 2.40 h41732ed_0 conda-forge; libblas 3.9.0 17_linux64_openblas conda-forge; libcblas 3.9.0 17_linux64_openblas conda-forge; libcurl 7.87.0 h6312ad2_0 conda-forge; libdeflate 1.18 h0b41bf4_0 conda-forge; libedit 3.1.20191231 he28a2e2_2 conda-forge; libev 4.33 h516909a_1 conda-forge; libffi 3.4.2 h7f98852_5 conda-forge; libgcc-ng 13.1.0 he5830b7_0 conda-forge; libgfortran-ng 13.1.0 h69a702a_0 conda-forge; libgfortran5 13.1.0 h15d22d2_0 conda-forge; libgomp 13.1.0 he5830b7_0 conda-forge; liblapack 3.9.0 17_linux64_openblas conda-forge; libnghttp2 1.51.0 hdcd2b5c_0 conda-forge; libnsl 2.0.0 h7f98852_0 conda-forge; libopenblas 0.3.23 pthreads_h80387f5_0 conda-forge; libprotobuf 3.18.0 h780b84a_1 conda-forge; libsqlite 3.42.0 h2797004_0 conda-forge; libssh2 1.10.0 haa6b8db_3 conda-forge; libstdcxx-ng 13.1.0 hfd8a6a1_0 conda-forge; libzlib 1.2.13 hd590300_5 conda-forge; lz4-c 1.9.3 h9c3ff4c_1 conda-forge; markdown 3.4.3 pyhd8ed1ab_0 conda-forge; markupsafe 2.0.1 py36h8f6f2f9_0 conda-forge; mock 5.0.2 pyhd8ed1ab_0 conda-forge; multidict 5.2.0 py36h8f6f2f9_0 conda-forge; ncurses 6.4 hcb278e6_0 conda-forge; numpy 1.16.6 py36h2aa4a07_0 conda-forge; oauth2client 4.1.3 py_0 conda-forge; oauthlib 3.2.2 pyhd8ed1ab_0 conda-forge; openjdk 8.0.332 h166bdaf_0 conda-forge; openssl 1.1.1u hd590300_0 conda-forge; opt_einsum 3.3.0 pyhd8ed1ab_1 conda-forge; pandas 1.1.5 py36h284efc9_0 conda-forge; parallel 20230522 ha770c72_0 conda-forge; perl 5.32.1 2_h7f98852_perl5 conda-forge; pip 21.3.1 pyhd8ed1ab_0 conda-forge; protobuf 3.18.0 py36hc4f0c31_0 conda-forge; psutil 5.8.0 py36h8f6f2f9_1 conda-forge; pyasn1 0.4.8 py_0 conda-forge; pyasn1-modules 0.2.7 py_0 conda-forge; pycparser 2.21 pyhd8ed1ab_0 conda-forge; pyjwt 2.7.0 pyhd8ed1ab_0 conda-forge; pyopenssl 22.0.0 pyhd8ed1ab_1 conda-forge; pyparsing 3.0.9 pyhd8ed1ab_0 conda-forge; pyrsistent 0.17.3 py36h8f6f2f9_2 conda-forge; pysocks 1.7.1 py36h5fab9bb_3 conda-forge; python 3.6.15 hb7a2778_0_cpython conda-forge; python-dateutil ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/664#issuecomment-1593808053:4475,mock,mock,4475,,https://github.com/google/deepvariant/issues/664#issuecomment-1593808053,1,['mock'],['mock']
Testability,"ine 1007, in main; FLAGS.outfile, header=header, round_qualities=True) as vcf_writer, \; File ""/tmp/Bazel.runfiles_gmddntqf/runfiles/com_google_deepvariant/third_party/nucle us/io/genomics_writer.py"", line 170, in __init__; self._writer = self._native_writer(output_path, **kwargs); File ""/tmp/Bazel.runfiles_gmddntqf/runfiles/com_google_deepvariant/third_party/nucle us/io/vcf.py"", line 316, in _native_writer; exclude_header=exclude_header); File ""/tmp/Bazel.runfiles_gmddntqf/runfiles/com_google_deepvariant/third_party/nucle us/io/vcf.py"", line 288, in __init__; writer_options); ValueError: Unknown: Could not open variants_path: /scratch/moldach/bin/quickstart-out put/output.vcf.gz. real 0m3.763s; user 0m2.899s; sys 0m0.651s; I0327 13:32:43.946818 47794500922048 run_deepvariant.py:321] None; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>; app.run(main); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run; _run_main(main, args); File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/scratch/moldach/bin/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --inf ile ""/tmp/tmp63xxmwmi/call_variants_output.tfrecord.gz"" --outfile ""/scratch/moldach/bi n/quickstart-output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmp63xxmwmi/g vcf.tfrecord@1.gz"" --gvcf_outfile ""/scratch/moldach/bin/quickstart-output/output.g.vcf .gz""' returned non-zero exit status 1.; [moldach@cdr767 bin]$ ^C; [moldach@cdr767 bin]$ exit; exit; srun: error: cdr767: task 0: Exited with exit code 130; ```. Any idea what could be causing this?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-605306987:13660,test,testdata,13660,,https://github.com/google/deepvariant/issues/287#issuecomment-605306987,1,['test'],['testdata']
Testability,"ing back to me! Any suggestions would be great. . 1. Your OS version.; NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31"". 2. Your Singularity version.; singularity version 3.4.1-1.2.el7; 3. Your numpy version (I'm not sure whether this affects singularity); 1.17.5; 4. Just to confirm, which *simg file are you using? The command you run? Was this with or without GPU?. I tried using the deepvariant-0.9.0.simg image from here with and without GPU: `https://storage.googleapis.com/deepvariant/singularity_images`; # Pull Singularity images; INPUT_DIR='singularity'; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/singularity_images""; # Non-gpu image; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/deepvariant-0.9.0.simg; # GPU image; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/deepvariant-0.9.0-gpu.simg. # Test Singularity DeepVariant0.9.0 image on test data; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; ${INPUT_DIR}/deepvariant-${BIN_VERSION}.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz . # Errors:. ImportError: No module named _multiarray_umath; ImportError: No module named _multiarray_umath; ImportError: numpy.core._multiarray_umath failed to import; ImportError: numpy.core.umath failed to import; 2020-01-31 01:37:29.333483: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . # Test Singularity DeepVariant0.9.0 GPU image on test data; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; ${INPUT_DIR}/deepvariant-${BIN_VERSION}-gpu.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/265#issuecomment-580549772:979,test,test,979,,https://github.com/google/deepvariant/issues/265#issuecomment-580549772,1,['test'],['test']
Testability,"internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant/labeler:customized_classes_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log); (06:29:10) INFO: From Testing //deepvariant/labeler:customized_classes_labeler_test:; ==================== Test output for //deepvariant/labeler:customized_classes_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/customized_classes_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/customized_classes_labeler_test.py"", line 41, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/customized_classes_labeler_test.runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 69, in <module>; from third_party.nucleus.io import genomics_reader; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/customized_classes_labeler_test.runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 8",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:32847,log,log,32847,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================. FAILED: //deepvariant:make_examples_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; (06:29:20) FAIL: //deepvariant:make_examples_test (shard 1 of 2) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log); (06:29:20) INFO: From Testing //deepvariant:make_examples_test (shard 1 of 2):; ==================== Test output for //deepvariant:make_examples_test (shard 1 of 2):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/deepvariant/make_examples_test.py"", line 48, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:100416,test,testlogs,100416,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"it down below for your reference. Here is an example of how I build and execute DeepVariant binaries:. # First, get a machine to run. In my example, I used a machine from GCP, using a command like this: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-details.md#command-for-a-cpu-only-machine-on-google-cloud-platform. ```bash; gcloud compute instances create ""${USER}-cpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-64"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. # ssh into the machine, and get the latest DeepVariant repo. Then, I ssh into the machine:. ```bash; gcloud compute ssh ${USER}-cpu --zone us-west1-b; ```. Then I get the repo:. ```bash; git clone https://github.com/google/deepvariant.git; cd deepvariant; ```. Following in the instructions in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md. I first run:. ```bash; sudo su; ```. and then:. ```bash; ./build-prereq.sh; ```. This step does a lot of stuff, including checking out other repos such as clif and tensorflow, and using that as part of the build environment. On my machine that I tested with just now, it took me 10m56.021s. and then run:. ```bash; ./build_and_test.sh; ```. This step took about 7min on my machine. . The [build_and_test.sh](https://github.com/google/deepvariant/blob/r1.6/build_and_test.sh) script is one that I recommend you actually read. The last line gave you an example of how you'd run `call_variants`. Something like:. ```bash; python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help; ```; should work. ---. # Further development and debugging. And, from here, if you want to continue to iterate, modify code and re-build. . You can try:. ```bash; source settings.sh; ```. This should allow you to use `bazel` in your terminal. At this point if you run `bazel --help` you should s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872:1508,test,test,1508,,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872,1,['test'],['test']
Testability,"it the same, but don't know what must have gone wrong. i used a different data it ran but gave a different error again, please can you help analyze this for me? . WARNING: Logging before flag parsing goes to stderr.; I1024 02:24:26.300854 140364017985280 client.py:1004] Timeout attempting to reach GCE metadata service.; W1024 02:24:26.301438 140364017985280 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib; [W::hts_idx_load2] The index file is older than the data file: /TCGA-AF-6136-01A.add_rg.bam.bai; I1024 02:24:26.349014 140364017985280 make_examples.py:911] Preparing inputs; [W::hts_idx_load2] The index file is older than the data file: /TCGA-AF-6136-01A.add_rg.bam.bai; [W::hts_idx_load2] The index file is older than the data file: /performance-testdata%2FHG002_GIAB_highconf_IllFB-IllGATKHC-CG-Ion-Solid_CHROM1-22_v3.2.2_highconf.vcf.gz.tbi; [W::hts_idx_load2] The index file is older than the data file: /performance-testdata%2FHG002_GIAB_highconf_IllFB-IllGATKHC-CG-Ion-Solid_CHROM1-22_v3.2.2_highconf.vcf.gz.tbi; Traceback (most recent call last):;   File ""/tmp/Bazel.runfiles_CqnGJt/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>;     tf.app.run();   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run;     _sys.exit(main(_sys.argv[:1] + flags_passthrough));   File ""/tmp/Bazel.runfiles_CqnGJt/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main;     make_examples_runner(options);   File ""/tmp/Bazel.runfiles_CqnGJt/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner;     regions = processing_regions_from_options(options);   File ""/tmp/Bazel.runfiles_CqnGJt/runfiles/genomics/deepvariant/make_examples.py"", line 892, in processing_regions_from_options;     options.min_shared_contigs_basepairs);   File ""/tmp/Bazel.runfiles_CqnGJt/runfiles/genomics/deepvariant/make_examples.py"", line 495,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/111#issuecomment-432491512:1015,test,testdata,1015,,https://github.com/google/deepvariant/issues/111#issuecomment-432491512,1,['test'],['testdata']
Testability,"iving the same QUAL field missing error); ```; 2019-01-29 11:46:16.329383: W third_party/nucleus/io/sam_reader.cc:125] Unknown tag pb: in header line, ignoring: @HD VN:1.5 SO:coordinate pb:3.0.1; 2019-01-29 11:46:16.333216: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0129 11:46:16.334961 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/alignments20_sorted.bam with NativeSamReader; I0129 11:46:16.337215 140471159555840 make_examples.py:1024] Preparing inputs; 2019-01-29 11:46:16.340804: W third_party/nucleus/io/sam_reader.cc:125] Unknown tag pb: in header line, ignoring: @HD VN:1.5 SO:coordinate pb:3.0.1; 2019-01-29 11:46:16.344462: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0129 11:46:16.346041 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/alignments20_sorted.bam with NativeSamReader; I0129 11:46:16.360527 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/NA12878.sorted.vcf.gz with NativeVcfReader; I0129 11:46:16.361952 140471159555840 make_examples.py:946] Common contigs are [u'chr20']; I0129 11:46:16.501434 140471159555840 make_examples.py:1030] Writing examples to prj-NA12878/training-examples/training_set.with_label.tfrecord.gz; 2019-01-29 11:46:16.502209: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728; 2019-01-29 11:46:16.550218: W third_party/nucleus/io/sam_reader.cc:125] Unknown tag pb: in header line, ignoring: @HD VN:1.5 SO:coordinate pb:3.0.1; 2019-01-29 11:46:16.554270: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0129 11:46:16.556066 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/alignments20_sorted.bam with NativeSamReader; I0129 11:46:16.571476 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/NA12878.sorted.vcf.gz with NativeVcfReader; I0129 11:46:20.140141 140471159555840 make_examples.py:7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-458487916:2157,test,testdata,2157,,https://github.com/google/deepvariant/issues/138#issuecomment-458487916,1,['test'],['testdata']
Testability,"ject; +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev; +pip install --upgrade pygobject; +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py ; +; # Configure LLVM 11 apt repository; wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \; add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main""; @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \; libllvm11 \; llvm-11 \; llvm-11-dev \; - llvm-11-linker-tools \; python3-dev \; zlib1g-dev; ; @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then; git checkout ""${CLIF_PIN}""; fi; ; +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake ; ./INSTALL.sh; ```; After these changes, I am stuck again at building clif because of the following error:; ```; [100%] Linking CXX executable clif-matcher; /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':; matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'; /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':; matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217:5272,Log,LogMessage,5272,,https://github.com/google/deepvariant/issues/879#issuecomment-2334801217,2,['Log'],['LogMessage']
Testability,"ke sure you're using the [-v flags](https://docs.docker.com/storage/volumes/) correctly and make sure the files are visible to it. (3) I tested with `sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.2` first and directly running the commands inside. I modified from the WES example because it's faster, but WGS should be the same. I can confirm that I was able to run the following steps without any issues:. 1. Start interactive mode so I can use command similar to yours. I'm not considering how I'm getting the data out.; ```; sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.2; ```. 2. Inside the interactive mode, run the following:; ```; MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wes_standard""; DATA_HTTP_DIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata; N_SHARDS=""64"". ## Download extra packages; sudo apt-get -y update; sudo apt-get -y install parallel; sudo apt-get -y install aria2; ## Download models, and test data; # Copy the model files to your local disk.; aria2c -c -x10 -s10 ""${MODEL_HTTP_DIR}""/model.ckpt.data-00000-of-00001; aria2c -c -x10 -s10 ""${MODEL_HTTP_DIR}""/model.ckpt.index; aria2c -c -x10 -s10 ""${MODEL_HTTP_DIR}""/model.ckpt.meta. # Copy the data; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/agilent_sureselect_human_all_exon_v5_b37_targets.bed; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz.fai; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gz.gzi; aria2c -c -x10 -s10 ${DATA_HTTP_DIR}/hs37d5.fa.gzi; ```. Then, I ran `make_examples` similar to the way you did in your original post:; ```; ## Run `make_examples`; ( time seq",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:2072,test,test,2072,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,1,['test'],['test']
Testability,"l nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl tsc_reliable nonstop_tsc eagerfpu pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx hypervisor lahf_lm 3dnowprefetch arat; bogomips	: 4190.15; clflush size	: 64; cache_alignment	: 64; address sizes	: 40 bits physical, 48 bits virtual; power management:. What I compared was not only call_variant it was make example step too. To make it clear I enclose a part of the log here, however it uses slightly different setting and different example but it shows what I said in my previous comment.; In this case I did not specify any number of core for the cpu and the result are slightly better than if I specify the cpu cores equal to 8. stdout of the process:; input file S-001701867.markdup.bam; I0622 13:05:17.760246 47710258629632 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir; I0622 13:05:17.867540 47710258629632 run_deepvariant.py:405] Creating a directory for logs in /output/logs; I0622 13:05:17.933148 47710258629632 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****; ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001701867.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output. I0622 13:06:39.176360 47468847029248 genomics_reader.py:223] Reading /input/S-001701867.markdup.bam with NativeSamReader; I0622 13:06:39.193307 47468847029248 make_examples.py:648] Preparing inputs; I0622 13:06:39.256251 47468847029248 genomics_reader.py:223] Reading /input/S-001701867.markdup.bam with",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866226252:1673,log,logs,1673,,https://github.com/google/deepvariant/issues/463#issuecomment-866226252,2,['log'],['logs']
Testability,"l_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log; (06:29:16) FAIL: //deepvariant:model_train_test (shard 10 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log); (06:29:16) INFO: From Testing //deepvariant:model_train_test (shard 10 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 10 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:72412,test,testlogs,72412,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"l_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log; (06:29:16) FAIL: //deepvariant:model_train_test (shard 10 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log); (06:29:16) INFO: From Testing //deepvariant:model_train_test (shard 10 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 10 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:72237,test,testlogs,72237,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,l_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log; (06:29:16) FAIL: //deepvariant:model_train_test (shard 10 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log); (06:29:16) INFO: From Testing //deepvariant:model_train_test (shard 10 of 10):; ==================== Test output for //deepvariant:model_trai,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:72062,test,testlogs,72062,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,l_variants_test/test.log; //deepvariant:data_providers_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log; //deepvariant:haplotypes_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log; //deepvariant/labeler:haplotype_labeler_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log; //deepvari,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:119203,test,testlogs,119203,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"lafr-btx , thanks for waiting. It took me a while to get back to this. Before I share my work log, one observation from your error earlier:; It seems like you're using Python 3.10. Note that DeepVariant 1.5.0 is bulit with Python 3.8. So, can you try with Python 3.8?. ---. Here is what I tried. On a GCE instance, I ran:. ```bash; wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; bash Miniconda3-latest-Linux-x86_64.sh -b -u -p $HOME/miniconda; eval ""$(${HOME}/miniconda/bin/conda shell.bash hook)""; ```. Then, I ran:. ```bash; conda config --add channels defaults && \; conda config --add channels bioconda && \; conda config --add channels conda-forge; conda create -y -n dv-env deepvariant; conda activate dv-env; ```. Which seems to work (without error). I don't actually know how to use conda (or deepvariant in conda). But I did see the files here: . ```; (dv-env) pichuan@pichuan-cpu:~$ ls /home/pichuan/miniconda/envs/dv-env/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/; call_variants.zip licenses.zip model_train.zip runtime_by_region_vis.zip; call_variants_keras.zip make_examples.zip multisample_make_examples.zip settings.sh; deeptrio make_examples_somatic.zip postprocess_variants.zip show_examples.zip; freeze_graph.zip model_eval.zip run-prereq.sh vcf_stats_report.zip; ```. These are probably the files that were packaged with the last release: https://github.com/google/deepvariant/releases/tag/v1.5.0. @tgelafr-btx Question for you: Have you consider using Docker or Singularity, which are better supported by our team? Like the example in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md or https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-pacbio-model-case-study.md . Anyway, hopefully my test with conda install was somewhat informative. If you figure out how to install+use it, please update here. I don't think I would be able to provide further support on conda here though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/736#issuecomment-1829204521:1818,test,test,1818,,https://github.com/google/deepvariant/issues/736#issuecomment-1829204521,1,['test'],['test']
Testability,"las.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) [2,506 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test (shard 10 of 10); 0s local ... (17 actions, 2 running). FAILED: //deepvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:71362,test,testlogs,71362,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ld' options: --define framework_shared_object=true --define tsl_protobuf_header_only=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:6434,test,tests,6434,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,5,['test'],"['test', 'tests']"
Testability,"le>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant/labeler:positional_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log); (06:29:10) INFO: From Testing //deepvariant/labeler:positional_labeler_test:; ==================== Test output for //deepvariant/labeler:positional_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/positional_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/positional_labeler_test.py"", line 40, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/positional_labeler_test.runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 69, in <module>; from third_party.nucleus.io import genomics_reader; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/positional_labeler_test.runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 82, in <module>; from tensorflow.python.l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:25616,log,log,25616,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"le>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant/labeler:customized_classes_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log); (06:29:10) INFO: From Testing //deepvariant/labeler:customized_classes_labeler_test:; ==================== Test output for //deepvariant/labeler:customized_classes_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/customized_classes_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/customized_classes_labeler_test.py"", line 41, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/customized_classes_labeler_test.runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 69, in <module>; from third_party.nucleus.io import genomics_reader; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:32781,test,testlogs,32781,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"led filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldn’t expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out “complex variants” (with more than one variant at a position), but .vcf files containing those variants weren’t flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:; ```; 68759 / 72556 (94.8%) full SNP recovery; 71276 / 72556 (98.2%) partial SNP recovery; 3027 / 3648 (83.0%) full insertion recovery; 3413 / 3648 (93.6%) partial insertion recovery; 3119 / 3911 (79.7%) full deletion recovery; 3596 / 3911 (91.9%) partial deletion recovery; ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:; ```; 51417 / 54229 (94.8%) full SNP recovery; 53116 / 54229 (97.9%) partial SNP recovery; 1964 / 2391 (82.1%) full insertion recovery; 2242 / 2391 (93.8%) partial insertion recovery; 2058 / 2537 (81.1%) full deletion recovery; 2349 / 2537 (92.6%) partial deletion recovery; ```. For comparison, you can see what is reported from precisionFDA (when running DeepVariant on my samples) for the [provided .bam alignment](https://precision.fda.gov/comparisons/3435) or the [BWA-MEM re-aligned comparison](https://pre",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:1364,test,test,1364,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,1,['test'],['test']
Testability,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/180#issuecomment-488147736:2087,log,logic,2087,,https://github.com/google/deepvariant/issues/180#issuecomment-488147736,2,"['Benchmark', 'log']","['Benchmarks', 'logic']"
Testability,ler_test/test.log; //deepvariant/labeler:labeled_examples_to_vcf_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log; //deepvariant/labeler:positional_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/positional_labeler_test/test.log; //deepvariant/labeler:variant_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log; //deepvariant/python:allelecounter_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log; //deepvariant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:121115,log,log,121115,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"local/bin/bwa0.7.10 sampe -P reference_files/male.hg19.fa.gz ENCFF182MTO.sai ENCFF949NMY.sai ENCFF182MTO.fastq.gz ENCFF949NMY.fastq.gz; @PG ID:MarkDuplicates PN:MarkDuplicates VN:1.92() CL:net.sf.picard.sam.MarkDuplicates INPUT=[ENCFF182MTOENCFF949NMY.raw.srt.filt.srt.bam] OUTPUT=ENCFF182MTOENCFF949NMY.raw.srt.dupmark.bam METRICS_FILE=ENCFF182MTOENCFF949NMY.raw.srt.dup.qc REMOVE_DUPLICATES=false ASSUME_SORTED=true VALIDATION_STRINGENCY=LENIENT PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 READ_NAME_REGEX=[a-zA-Z0-9]+:[0-9]:([0-9]+):([0-9]+):([0-9]+).* OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 VERBOSITY=INFO QUIET=false COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false; ```. I uploaded the modified file on this public s3 bucket so you can have a look on it directly from here : ; s3://dv-testfiles/hg19.fa; s3://dv-testfiles/ENCFF528VXT.bam. There you can find the genome I used for running too. Before i created the needed files ( done in the following docker container https://hub.docker.com/r/luisas/samtools/ ) :; ```; samtools index ENCFF528VXT.bam; samtools faidx hg19.fa; bgzip -c -i hg19.fa > hg19.fa.gz; samtools faidx ""hg19.fa.gz""; ```. Then I ran in the docker container you provide :; ```; mkdir shardedExamples. time seq 0 1 | parallel --eta --halt 2 python /opt/deepvariant/bin/make_examples.zip --mode calling --ref hg19.fa --regions chr20:10,000,000-10,010,000 --reads ENCFF528VXT.bam --examples shardedExamples/examples.tfrecord@2.gz --task {}. ```. ```; /opt/deepvariant/bin/call_variants --outfile call_variants_output.tfrecord --examples shardedExamples/examples.tfrecord@2.gz --checkpoint dv2/models/model.ckpt; ```. and here the error output:; ```; WARNING: Logging before flag parsing goes to stderr.; W0307 09:54:53.415692 140603705038592 htslib_gcp_oauth.py:88] GCP credentials not found; only l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371096675:2202,test,testfiles,2202,,https://github.com/google/deepvariant/issues/52#issuecomment-371096675,1,['test'],['testfiles']
Testability,"long with other strategies tested***. I genuinely believe it is good to have a variety of freely available programs to use, but I believe the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). Y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:7603,test,test,7603,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,1,['test'],['test']
Testability,"low.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:08) FAIL: //deepvariant/realigner:aligner_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log); (06:29:08) INFO: From Testing //deepvariant/realigner:aligner_test:; ==================== Test output for //deepvariant/realigner:aligner_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/aligner_test.runfiles/com_google_deepvariant/deepvariant/realigner/aligner_test.py"", line 40, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/aligner_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:14332,test,testlogs,14332,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"lp and options for <command>.; bazel help startup_options; Options for the JVM hosting bazel.; bazel help target-syntax; Explains the syntax for specifying targets.; bazel help info-keys; Displays a list of keys used by the info command.; + [[ 1 = \1 ]]; + bazel test -c opt --local_test_jobs=1 --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/...; (06:29:06) WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.; (06:29:06) INFO: Current date is 2019-02-14; (06:29:06) Loading: ; (06:29:06) Loading: 0 packages loaded; (06:29:07) INFO: Analysed 168 targets (0 packages loaded).; (06:29:07) INFO: Found 130 targets and 38 test targets...; (06:29:07) [1 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt; (06:29:08) FAIL: //deepvariant/labeler:variant_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/variant_labeler_test/test.log); (06:29:08) INFO: From Testing //deepvariant/labeler:variant_labeler_test:; ==================== Test output for //deepvariant/labeler:variant_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/variant_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/variant_labeler_test.py"", line 40, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/variant_labeler_test.runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 69, in <module>; from third_party.nucleus.io import genomics_reader; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:11546,test,testlogs,11546,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ls.md#command-for-a-cpu-only-machine-on-google-cloud-platform. ```bash; gcloud compute instances create ""${USER}-cpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-64"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. # ssh into the machine, and get the latest DeepVariant repo. Then, I ssh into the machine:. ```bash; gcloud compute ssh ${USER}-cpu --zone us-west1-b; ```. Then I get the repo:. ```bash; git clone https://github.com/google/deepvariant.git; cd deepvariant; ```. Following in the instructions in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md. I first run:. ```bash; sudo su; ```. and then:. ```bash; ./build-prereq.sh; ```. This step does a lot of stuff, including checking out other repos such as clif and tensorflow, and using that as part of the build environment. On my machine that I tested with just now, it took me 10m56.021s. and then run:. ```bash; ./build_and_test.sh; ```. This step took about 7min on my machine. . The [build_and_test.sh](https://github.com/google/deepvariant/blob/r1.6/build_and_test.sh) script is one that I recommend you actually read. The last line gave you an example of how you'd run `call_variants`. Something like:. ```bash; python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help; ```; should work. ---. # Further development and debugging. And, from here, if you want to continue to iterate, modify code and re-build. . You can try:. ```bash; source settings.sh; ```. This should allow you to use `bazel` in your terminal. At this point if you run `bazel --help` you should see the usage. If you make any changes, you can run:. ```bash; bazel build -c opt ${DV_COPT_FLAGS} deepvariant/...; ```. to re-build all binaries. (And can use `bazel test` to run unit tests). If you're specially looking into just one build target, you can also run something",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872:1763,test,tested,1763,,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872,1,['test'],['tested']
Testability,"mmon reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) [2,506 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test (shard 10 of 10); 0s local ... (17 actions, 2 running). FAILED: //deepvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:71537,test,testlogs,71537,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:123343,log,log,123343,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:21) INFO: Elapsed time: 14.901s, Critical Path: 13.35s; (06:29:21) INFO: 43 processes: 43 local.; (06:29:21) INFO: Build completed, 24 tests FAILED, 44 total actions; //deepvariant:allelecounter_test (cached) PASSED in 0.5s; //deepvariant:dv_vcf_constants_test (cached) PASSED in 1.7s; //deepvariant:exclude_contigs_test (cached) PASSED in 0.9s; //deepvariant:postprocess_variants_lib_test (cached) PASSED in 0.1s; //deepvariant:resources_test (cached) PASSED in 1.7s; //deepvariant:utils_test (cached) PASSED in 0.5s; //deepvariant:variant_calling_test (cached) PASSED in 0.6s; //deepvariant/environment_tests:env_smoke_test (cached) PASSED in 0.7s; //deepvariant/environment_tests:protobuf_implementation_test (cached) PASSED in 1.2s; //deepvariant/realigner:fast_pass_aligner_test (cached) PASSED in 0.6s; //deepvariant/realigner:ssw_test (cached) PASSED in 0.5s; //deepvariant/realigner/python:ssw_misc_test (cached) PASSED in 0.9s; //deepvariant/realigner/python:ssw_wrap_test (cached) PASSED in 1.2s; //deepvariant/vendor:timer_test (cached) PASSED in 0.7s; //deepvariant:call_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:117061,test,tests,117061,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['test'],['tests']
Testability,"mon contigs are ['chr20']; I0629 23:43:41.686007 139796154570496 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; 2021-06-29 23:43:41.686352: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.688519 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.688877 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:43:41.804690 139796154570496 make_examples.py:648] Writing examples to quickstart-output/sing.make_examples.tfrecord.gz; I0629 23:43:41.804903 139796154570496 make_examples.py:648] Writing gvcf records to quickstart-output/sing.gvcf.tfrecord.gz; I0629 23:43:41.805349 139796154570496 make_examples.py:648] Overhead for preparing inputs: 0 seconds; I0629 23:43:41.821153 139796154570496 make_examples.py:648] 0 candidates (0 examples) [0.02s elapsed]; I0629 23:44:41.827408 139796154570496 make_examples.py:648] 102 candidates (110 examples) [60.01s elapsed]; I0629 23:44:45.517579 139796154570496 make_examples.py:648] 202 candidates (223 examples) [3.69s elapsed]; [E::bgzf_read] Read block operation failed with error 4 after 0 of 4 bytes; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_7g_iun5k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads; reads.extend",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:17154,test,testdata,17154,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,1,['test'],['testdata']
Testability,must be specified in calling mode.; I0330 15:47:21.755398 140432560695040 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757477 140432560695040 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.770883 139863230490368 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.773075 139863230490368 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.754880 139747089467136 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.756903 139747089467136 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.754880 139944273491712 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757000 139944273491712 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.759158 140716713432832 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.761278 140716713432832 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.755259 140202003052288 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.757451 140202003052288 errors.py:61] sample_name must be specified in calling mode.; I0330 15:47:21.765991 139705794897664 genomics_reader.py:223] Reading /input/sample.bam with NativeSamReader; E0330 15:47:21.768276 139705794897664 errors.py:61] sample_name must be specified in calling mode.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/ref.fa --reads /input/sample.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@8.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@8.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@8.gz --task 2. ```; I think the bam file is not corrected - would you please let me know which is the best suitable tool for aligning sequencing reads?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/435#issuecomment-810383024:2049,log,logs,2049,,https://github.com/google/deepvariant/issues/435#issuecomment-810383024,1,['log'],['logs']
Testability,"n Power8 & Redhat 7.5. 1. Build the following packages with ""/usr/bin/gcc""; cmake 3.13.3; Protobuf 3.6.1 C++ (static build with --enable-static for bazel); bazel 0.15.0. 2. Install Advance Toolchain 11.0 and build the following packages with /opt/at11.0/bin/gcc; Python 2 and Pip 19.0.2; Protobuf 3.6.1 C++ (uninstall static and build shared); Protobuf 3.6.1 Python (should build and install from source or CLIF will fail); TensorFlow 1.12.0 (fix floatn.h error with the link Floatn.h error: https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f); CLIF; Opencv-python 3.4.5.20 (for tensor2tensor install). Then build DeepVariant will pass, and results here (excepted //deepvariant/labeler:haplotype_labeler_test tracked in issue 154). ```; ================================================================================; (05:42:50) INFO: Elapsed time: 715.015s, Critical Path: 689.68s; (05:42:50) INFO: 1835 processes: 1835 local.; (05:42:50) INFO: Build completed, 1 test FAILED, 2433 total actions; //deepvariant:allelecounter_test PASSED in 0.1s; //deepvariant:call_variants_test PASSED in 59.8s; //deepvariant:data_providers_test PASSED in 11.8s; //deepvariant:dv_vcf_constants_test PASSED in 0.5s; //deepvariant:exclude_contigs_test PASSED in 1.6s; //deepvariant:haplotypes_test PASSED in 1.7s. ▽; //deepvariant:modeling_test PASSED in 48.2s; //deepvariant:pileup_image_test PASSED in 1.8s; //deepvariant:postprocess_variants_lib_test PASSED in 0.1s; //deepvariant:postprocess_variants_test PASSED in 4.8s; //deepvariant:resources_test PASSED in 1.8s; //deepvariant:tf_utils_test PASSED in 3.8s; //deepvariant:utils_test PASSED in 0.1s; //deepvariant:variant_caller_test PASSED in 2.4s; //deepvariant:variant_calling_test PASSED in 0.1s; //deepvariant/environment_tests:env_smoke_test PASSED in 0.4s; //deepvariant/environment_tests:protobuf_implementation_test PASSED in 0.8s; //deepvariant/labeler:customized_classes_labeler_test PASSED in 1.8s; //deepvariant/labeler:labeled_examp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-464686381:1139,test,test,1139,,https://github.com/google/deepvariant/issues/123#issuecomment-464686381,1,['test'],['test']
Testability,"n asking for help.; ================================================================================; (06:29:16) [2,506 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test (shard 10 of 10); 0s local ... (17 actions, 2 running). FAILED: //deepvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:71594,log,log,71594,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"n.org/ftp/python/2.7.15/Python-2.7.15.tgz; tar -zxvf Python-2.7.15.tgz; cd Python-2.7.15. # environment; export HOMEPATH=/home/qilibj; export CPU=power8. # check gcc before build, should be AT11.0; which gcc. # build; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static; make -j20; make install. # set environment; export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin; export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH; export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15; echo ""$(python --version)"". # Pip 19.0.2; wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate; $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst; #pip install --upgrade --force-reinstall pip; echo ""$(pip --version)""; pip install setuptools nose asv cython future protobuf==3.6.1 six mock; pip install --upgrade setuptools; ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash; # download source code; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz; tar -zxvf protobuf-all-3.6.1.tar.gz; cd protobuf-3.6.1/. # clean static protobuf build; make uninstall; make distclean. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static; make clean; make -j20; # optional; make -j20 check # check if protobuf build is good; # install; make install; sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig; #cd .. # verify; echo ""$(which protoc)""; echo ""$(protoc --version)"";",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:5911,mock,mock,5911,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,1,['mock'],['mock']
Testability,"n_deepvariant \; + dkurtaev/deepvariant:latest \; + /opt/deepvariant/bin/run_deepvariant --call_variants_extra_args=use_openvino=true --make_examples_extra_args=regions=chr1 \; --model_type=WGS \; --ref=""/input/${REF}.gz"" \; --reads=""/input/${BAM}"" \; @@ -100,6 +100,6 @@ pkrusche/hap.py /opt/hap.py/bin/hap.py \; -f ""${INPUT_DIR}/${TRUTH_BED}"" \; -r ""${UNCOMPRESSED_REF}"" \; -o ""${OUTPUT_DIR}/happy.output"" \; - --engine=vcfeval; + --engine=vcfeval -l chr1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done."". ```. Runtime:; ```; $ grep '^real' /tmp/open; real 7m38.326s; real 15m12.564s; real 7m15.173s; ```. 2. Use your Docker image, use_openvino=false; The code diff:; ```; $ git diff; diff --git a/scripts/run_wgs_case_study_docker.sh b/scripts/run_wgs_case_study_docker.sh; index 3dc9712..78712d8 100755; --- a/scripts/run_wgs_case_study_docker.sh; +++ b/scripts/run_wgs_case_study_docker.sh; @@ -65,14 +65,14 @@ aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testda; aria2c -c -x10 -s10 ""http://storage.googleapis.com/deepvariant/case-study-testdata/${REF}.fai"" -d ""${INPUT_DIR}""; ; ## Pull the docker image.; -sudo docker pull google/deepvariant:""${BIN_VERSION}""; +sudo docker pull dkurtaev/deepvariant:latest; ; echo ""Run DeepVariant...""; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; - google/deepvariant:""${BIN_VERSION}"" \; - /opt/deepvariant/bin/run_deepvariant \; + dkurtaev/deepvariant:latest \; + /opt/deepvariant/bin/run_deepvariant --call_variants_extra_args=use_openvino=false --make_examples_extra_args=regions=chr1 \; --model_type=WGS \; --ref=""/input/${REF}.gz"" \; --reads=""/input/${BAM}"" \; @@ -100,6 +100,6 @@ pkrusche/hap.py /opt/hap.py/bin/hap.py \; -f ""${INPUT_DIR}/${TRUTH_BED}"" \; -r ""${UNCOMPRESSED_REF}"" \; -o ""${OUTPUT_DIR}/happy.output"" \; - --engine=vcfeval; + --engine=vcfeval -l chr1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done.""; ```. Runtime:; ```; $ grep '^real' /tmp/open; real 7m20.986s; real 21m2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735276044:2277,test,testda,2277,,https://github.com/google/deepvariant/pull/363#issuecomment-735276044,1,['test'],['testda']
Testability,"ncy region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiment",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1659358917:2366,test,test,2366,,https://github.com/google/deepvariant/issues/682#issuecomment-1659358917,1,['test'],['test']
Testability,"nd other forums. I don't see any issues with that. The only thing which is important is to add the changes as a single commit separately from other changes so it can be properly tracked in git history. > Can you help me understand the expected benefit of the changes? It looks like this should improve runtime for call_variants. Do you have any high-level information from benchmark runs for us to understand the percentage improvement to expect. You're right - this PR about efficiency of deep learning part only (call_variants). We need some time to collect some benchmark numbers and check what's is OK to share publicly. Probably, extra optimizations could be applied. > If we are to incorporate these changes, we would want to make sure this would perform well across various hardware. For example, we would want our Docker images to gracefully fallback to working code if it is on a machine with incompatible hardware. Do you expect OpenVINO to have this property (for example, if someone is running on an AMD machine). Proposed changes are very smooth - by default, OpenVINO is not used. We can test other Intel hardware such iGPU and HDDL-R. For non-Intel HW users can always use default implementation. > We will also have to think about how these changes interact with any updates we would make to our use of TensorFlow. We're not directly planning anything in the near future, but it's good for us to consider. I think it won't be an issue. It make sense to isolate some OpenVINO related logic to separate Python script to reduce conflicts during development. Additionally, I just wanted to ask if you're interested in using GitHub Actions so you can perform initial tests for pull requests. In example, https://github.com/dkurt/deepvariant/blob/master_openvino/.github/workflows/main.yml does Docker build and then runs WGS on getting-started data with TensorFlow and OpenVINO and compares the outputs ([logs](https://github.com/dkurt/deepvariant/runs/1259964899?check_suite_focus=true)).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-709941019:1609,test,test,1609,,https://github.com/google/deepvariant/pull/363#issuecomment-709941019,4,"['log', 'test']","['logic', 'logs', 'test', 'tests']"
Testability,"ngularity run -B /usr/lib/locale/:/usr/lib/locale/ \; > docker://google/deepvariant:""${BIN_VERSION}"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; > --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; > --regions ""chr20:10,000,000-10,010,000"" \; > --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; > --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; > --num_shards=1; WARN[0000] ""/run/user/3019658"" directory set by $XDG_RUNTIME_DIR does not exist. Eithe r create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such fil e or directory: Trying to pull image in the event that it is a public image.; I0327 13:31:58.252949 47794500922048 run_deepvariant.py:241] Re-using the directory fo r intermediate results in /tmp/tmp63xxmwmi. ***** Intermediate results will be written to /tmp/tmp63xxmwmi in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mo de calling --ref ""/scratch/moldach/bin/quickstart-testdata/ucsc.hg19.chr20.unittest.fa sta"" --reads ""/scratch/moldach/bin/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmp63xxmwmi/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmp63xxmwmi/gv cf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I0327 13:32:07.160181 47175299967680 make_examples.py:386] ReadRequirements are: min_m apping_quality: 10; min_base_quality: 10; min_base_quality_mode: ENFORCED",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-605306987:1611,test,testdata,1611,,https://github.com/google/deepvariant/issues/287#issuecomment-605306987,1,['test'],['testdata']
Testability,"nherited 'build' options: --define framework_shared_object=true --define tsl_protobuf_header_only=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; (05:40:22) INFO: Reading rc options for 'test' from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:6384,test,tests,6384,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,1,['test'],['tests']
Testability,"nomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:43:41.569230 139796154570496 make_examples.py:648] Common contigs are ['chr20']; I0629 23:43:41.686007 139796154570496 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; 2021-06-29 23:43:41.686352: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.688519 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.688877 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:43:41.804690 139796154570496 make_examples.py:648] Writing examples to quickstart-output/sing.make_examples.tfrecord.gz; I0629 23:43:41.804903 139796154570496 make_examples.py:648] Writing gvcf records to quickstart-output/sing.gvcf.tfrecord.gz; I0629 23:43:41.805349 139796154570496 make_examples.py:648] Overhead for preparing inputs: 0 seconds; I0629 23:43:41.821153 139796154570496 make_examples.py:648] 0 candidates (0 examples) [0.02s elapsed]; I0629 23:44:41.827408 139796154570496 make_examples.py:648] 102 candidates (110 examples) [60.01s elapsed]; I0629 23:44:45.517579 139796154570496 make_examples.py:648] 202 candidates (223 examples) [3.69s elapsed]; [E::bgzf_read] Read block operation failed with error 4 after 0 of 4 byte",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:17018,test,testdata,17018,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,1,['test'],['testdata']
Testability,nput/idt_capture_novogene.grch38.bed \; --output_vcf output/HG003.output.vcf.gz \; --output_gvcf output/HG003.output.g.vcf.gz \; --num_shards $(nproc) \; --intermediate_results_dir output/intermediate_results_dir 2>&1 | tee /tmp/all.log; ```. I'll paste part of the log of each step so that you can compare. ## make_examples; make_examples speed is roughly:; ```; I0622 21:19:25.373434 140610510067456 make_examples.py:648] Task 7/8: 4900 candidates (5187 examples) [27.99s elapsed]; I0622 21:19:35.260825 139809239041792 make_examples.py:648] Task 1/8: 4809 candidates (5065 examples) [32.79s elapsed]; I0622 21:19:37.868103 139727062120192 make_examples.py:648] Task 2/8: 4900 candidates (5208 examples) [37.92s elapsed]; I0622 21:19:37.739557 139786800707328 make_examples.py:648] Task 6/8: 5100 candidates (5441 examples) [29.08s elapsed]; I0622 21:19:44.484720 140667007305472 make_examples.py:648] Task 5/8: 4902 candidates (5241 examples) [37.78s elapsed]; ```. Here are the last few lines from the log:; ```; I0622 21:24:34.005878 140667007305472 make_examples.py:648] Task 5/8: Created 6240 examples; I0622 21:24:38.061186 139897026688768 make_examples.py:648] Task 4/8: 5906 candidates (6318 examples) [17.72s elapsed]; I0622 21:24:43.683619 140528910345984 make_examples.py:648] Task 0/8: 5700 candidates (6127 examples) [24.04s elapsed]; I0622 21:24:44.784906 139897026688768 make_examples.py:648] Task 4/8: 6002 candidates (6422 examples) [6.72s elapsed]; I0622 21:24:46.344424 139897026688768 make_examples.py:648] Task 4/8: Found 6004 candidate variants; I0622 21:24:46.344626 139897026688768 make_examples.py:648] Task 4/8: Created 6424 examples; I0622 21:24:58.252706 140528910345984 make_examples.py:648] Task 0/8: 5800 candidates (6229 examples) [14.57s elapsed]; I0622 21:25:03.072478 140528910345984 make_examples.py:648] Task 0/8: Found 5825 candidate variants; I0622 21:25:03.072677 140528910345984 make_examples.py:648] Task 0/8: Created 6254 examples; ```. Here is a snapshot,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866352316:2439,log,log,2439,,https://github.com/google/deepvariant/issues/463#issuecomment-866352316,1,['log'],['log']
Testability,"nsorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcuda.so.1: cannot open shared object file: No such file or directory. I additionally tried using docker to run the docker images (which worked for me with DeepVariant v.7.0.0, but not 9.0.0): ; `# Pull the deep variant docker image.; sregistry pull docker://gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}""; ​. # Test running docker interactively w/Singularity. ; BIN_VERSION=""0.9.0""; singularity shell --bind '/labs/jandr/walter/tb/test' /home/kwalter/.singularity/shub/deepvariant-docker-deepvariant:${BIN_VERSION}.simg;. /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=ucsc.hg19.chr20.unittest.fasta \; --reads=NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz ; `; I got the same errors with this test. It seems like there is some issue with numpy/tensorflow in this most recent version of the image that makes it incompatible with running via Singularity. Any suggestions or advice would be great. Thank you in advance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/265#issuecomment-580549772:3678,Test,Test,3678,,https://github.com/google/deepvariant/issues/265#issuecomment-580549772,3,"['Test', 'test']","['Test', 'test']"
Testability,"nsorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) FAIL: //deepvariant/labeler:labeled_examples_to_vcf_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_examples_to_vcf_test/test.log); (06:29:20) INFO: From Testing //deepvariant/labeler:labeled_examples_to_vcf_test:; ==================== Test output for //deepvariant/labeler:labeled_examples_to_vcf_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf_test.runfiles/com_google_deepvariant/deepvariant/labeler/labeled_examples_to_vcf_test.py"", line 39, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf_test.runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 69, in <module>; from third_party.nucleus.io import genomics_reader; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf_test.runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 82, in <module>;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:103498,log,log,103498,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"nt it in /mnt. So, that is why I didn't previously have the ""sudo"" commands, but I have added them and tried again. I also tested adding `gcsfuse --file-mode 777 --dir-mode 777` (but that was for a different reason, because I couldn't run executable files from my bucket, and it looks like that solved that particular problem). However, I did quickly test, and I could run ""touch test.txt"" without adding that extra parameter (or using sudo). However, I am unfortunately still getting an error message:. ```; sh deepvariant_run_Exome_BWA_MEM_by-step.sh; Reading package lists... Done; Building dependency tree; Reading state information... Done; time is already the newest version (1.7-25.1+b1).; 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.; Reading package lists... Done; Building dependency tree; Reading state information... Done; parallel is already the newest version (20161222-1).; 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.; mkdir: cannot create directory ‘logs’: Permission denied; 0.00user 0.00system 0:00.00elapsed 0%CPU (0avgtext+0avgdata 1828maxresident)k; 0inputs+0outputs (0major+73minor)pagefaults 0swaps; Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 8 / 8. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 8 AVG: 0.00s local:8/0/100%/0.0s docker: Error response from daemon: error while creating mount source path '/home/cwarden/cdw-genome': mkdir /home/cwarden/cdw-genome: file exists.; time=""2019-04-16T02:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483490946:3836,log,logs,3836,,https://github.com/google/deepvariant/issues/171#issuecomment-483490946,1,['log'],['logs']
Testability,"nt/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log. Executed 24 out of 38 tests: 14 tests ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:126163,test,testlogs,126163,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"nt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 464, in from_regions; for elt in reader(region):; File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 429, in bed_parser; with bed.BedReader(filename) as fin:; File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 211, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader; return NativeBedReader(input_path, **kwargs); File ""/mnt/google/.google/tmp/Bazel.runfiles_qQ5ryq/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__; self._reader = bed_reader.BedReader.from_file(bed_path, options); ValueError: Not found: Could not open gs://gbsc-gcp-project-udn-dev-test/VCRome_2_1_hg19_capture_targets_chrStripped.bed; parallel: This job failed:; Using mount point: /input-gcsfused-48; Opening GCS connection...; Opening bucket...; Mounting file system...; File system has been successfully mounted.; mkdir -p ./input-gcsfused-48 && gcsfuse --implicit-dirs gbsc-gcp-project-udn-dev-deep-variant /input-gcsfused-48 && /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/gbsc-gcp-project-udn-dev-deep-variant/UDN668131_deepVariant_test4/deepvariant_staging_folder/examples/examples_output.tfrecord@64.gz --reads /input-gcsfused-48/UDN668131/UDN668131-P_HGF2YBCX2_deduped.bam --ref /mnt/google/.google/input/gbsc-gcp-project-udn-dev-test/hs37d5_ref/hs37d5.fa --task 48 --regions gs://gbsc-gcp-project-udn-dev-test/VCRome_2_1_hg19_capture_targets_chrStripped.bed. operation id: 3776708258517585322. $ gsutil ls gs://gbsc-gcp-project-udn-dev-test/VCRome_2_1_hg19_capture_targets_chrStripped.bed; gs://gbsc-gcp-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/118#issuecomment-437503051:4296,test,test,4296,,https://github.com/google/deepvariant/issues/118#issuecomment-437503051,1,['test'],['test']
Testability,"nt/make_examples.py"", line 1120, in <module>; tf.app.run(); File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run; _sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main; make_examples_runner(options); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner; regions = processing_regions_from_options(options); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options; options.min_shared_contigs_basepairs); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs; min_coverage_fraction); File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage; ref_bp, common_bp, coverage, format_contig_matches())); ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING; ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt); [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt); [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt); [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt); [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz); [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-448201709:4682,log,log,4682,,https://github.com/google/deepvariant/issues/128#issuecomment-448201709,2,['log'],['log']
Testability,"nt/realigner/allele_count_linear:model_evaluation_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/realigner/allele_count_linear/model_evaluation_test.py"", line 41, in <module>; from deepvariant import testdata; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/testdata.py"", line 39, in <module>; from third_party.nucleus.testing import test_utils as nucleus_test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:78694,test,testing,78694,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['test'],['testing']
Testability,nt/realigner:ssw_test (cached) PASSED in 0.5s; //deepvariant/realigner/python:ssw_misc_test (cached) PASSED in 0.9s; //deepvariant/realigner/python:ssw_wrap_test (cached) PASSED in 1.2s; //deepvariant/vendor:timer_test (cached) PASSED in 0.7s; //deepvariant:call_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log; //deepvariant:data_providers_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log; //deepvariant:haplotypes_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:118779,test,testlogs,118779,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"nt_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:123591,test,testlogs,123591,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"nternal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) [2,506 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test (shard 10 of 10); 0s local ... (17 actions, 2 running). FAILED: //deepvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:71069,log,log,71069,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"ntig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help!; I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file.; I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file.; And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```; python bin/make_examples.zip \; --mode training \; --ref ""project-retraining/testdata/sequence.fasta"" \; --reads ""project-retraining/testdata/aligned_reads.bam"" \; --examples ""project-retraining/training_examples"" \; --confident_regions ""project-retraining/testdata/variants.bed"" \; --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1; ```. and I get the same ValueError as before (from `make_examples.log` file):. ```; 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs; 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-448201709:1163,test,testdata,1163,,https://github.com/google/deepvariant/issues/128#issuecomment-448201709,1,['test'],['testdata']
Testability,"o docker run --runtime=nvidia --gpus 1\; -v ${HOME}:${HOME} \; -w ${HOME} \; google/deepvariant:1.6.1-gpu \; train \; --config=""${BASE}/dv_config.py"":base \; --config.train_dataset_pbtxt=""${BASE}/training_set.pbtxt"" \; --config.tune_dataset_pbtxt=""${BASE}/validation_set.pbtxt"" \; --config.init_checkpoint=""${BASE}/checkpoint/deepvariant.wgs.ckpt"" \; --config.num_epochs=10 \; --config.learning_rate=0.0001 \; --config.num_validation_examples=0 \; --experiment_dir=${TRAINING_DIR} \; --strategy=mirrored \; --config.batch_size=512 \; ) > ""${LOG_DIR}/train.log"" 2>&1 &; ```; ```; I0508 17:53:46.544947 140534986602304 train.py:384] Starting epoch 0; I0508 17:53:46.545100 140534986602304 train.py:391] Performing initial evaluation of warmstart model.; I0508 17:53:46.545171 140534986602304 train.py:361] Running tune at step=0 epoch=0; I0508 17:53:46.545287 140534986602304 train.py:366] Tune step 0 / 15 (0.0%); I0508 17:54:10.069682 140512707213056 logging_writer.py:48] [0] tune/categorical_accuracy=0.22617188096046448, tune/categorical_crossentropy=1.3209192752838135, tune/f1_het=0.02283571846783161, tune/f1_homalt=0.09889934211969376, tune/f1_homref=0.843934178352356, tune/f1_macro=0.3218897581100464, tune/f1_micro=0.22617188096046448, tune/f1_weighted=0.21346084773540497, tune/false_negatives_1=6123.0, tune/false_positives_1=5727.0, tune/loss=1.3209190368652344, tune/precision_1=0.21375617384910583, tune/precision_het=0.19323670864105225, tune/precision_homalt=0.05127762258052826, tune/precision_homref=0.9494163393974304, tune/recall_1=0.20273438096046448, tune/recall_het=0.007176175247877836, tune/recall_homalt=0.834269642829895, tune/recall_homref=0.6971428394317627, tune/true_negatives_1=9633.0, tune/true_positives_1=1557.0; I0508 17:54:10.083408 140534986602304 train.py:394] Warmstart checkpoint best checkpoint metric: tune/f1_weighted=0.21346085. real 1m12.933s; user 0m0.037s; sys 0m0.013s; ```. [train.log](https://github.com/google/deepvariant/files/15253217/train.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/819#issuecomment-2101161904:2447,log,log,2447,,https://github.com/google/deepvariant/issues/819#issuecomment-2101161904,2,['log'],['log']
Testability,"oad the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) [2,519 / 2,523] 34 / 38 tests, 20 failed; Testing //deepvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:106816,log,log,106816,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"odule>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/python:allelecounter_wrap_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/allelecounter_wrap_test/test.log); (06:29:18) INFO: From Testing //deepvariant/python:allelecounter_wrap_test:; ==================== Test output for //deepvariant/python:allelecounter_wrap_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/python/allelecounter_wrap_test.runfiles/com_google_deepvariant/deepvariant/python/allelecounter_wrap_test.py"", line 38, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/python/allelecounter_wrap_test.runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 60, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.pyt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:82806,log,log,82806,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"odule>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) FAIL: //deepvariant/realigner:window_selector_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner:window_selector_test:; ==================== Test output for //deepvariant/realigner:window_selector_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/window_selector_test.runfiles/com_google_deepvariant/deepvariant/realigner/window_selector_test.py"", line 40, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/window_selector_test.runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 60, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.pyt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:90151,log,log,90151,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"odule>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:19) FAIL: //deepvariant/labeler:haplotype_labeler_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log); (06:29:19) INFO: From Testing //deepvariant/labeler:haplotype_labeler_test:; ==================== Test output for //deepvariant/labeler:haplotype_labeler_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/com_google_deepvariant/deepvariant/labeler/haplotype_labeler_test.py"", line 40, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/haplotype_labeler_test.runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 60, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.pyt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:95048,log,log,95048,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"oject ubuntu-os-cloud --machine-type n1-standard-8 --boot-disk-size=200GB --zone us-west1-b --accelerator type=nvidia-tesla-k80,count=1 --maintenance-policy TERMINATE --restart-on-failure`. then I downloaded and built DeepVariant (here you could tweak different build optimization settings, but for now I left it alone):. ```; git clone https://github.com/google/deepvariant.git; cd deepvariant; ./build-prereq.sh; ./build_release_binaries.sh; ```. Then I downloaded and set up some of the variables from the case study doc (https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md); I had to change N_SHARDS to be 8 since we have 8 cpus on this instance. Then I ran make_examples in training mode on a small portion of the genome to create some labeled training data. I adapted the command line from the one used in the case study. You would also want to randomly shuffle the data but I didn't do that here. ```; ( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \; python ""${BIN_DIR}""/make_examples.zip \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM}"" \; --confident_regions ""${TRUTH_BED}"" \; --truth_variants ""${TRUTH_VCF}"" \; --examples ""${EXAMPLES}"" \; --regions ""20:10,000,000-12,000,000"" \; --task {}; ) >""${LOG_DIR}/make_examples.log"" 2>&1; ```. The --confident_regions, and --truth_variants are how you supply the truth data to the program in order to create the labels. Then I created a data.pbtxt config file that is described in the training doc (https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-model-training.md). It looks like:; ```; > cat output/data.pbtxt ; name: ""my-training-dataset""; tfrecord_path: ""/home/rpoplin/case-study/output/HG002.examples.tfrecord-?????-of-00008.gz""; num_examples: 150; ```. Then I launched a training job with model_train.zip:. ```; python ""${BIN_DIR}""/model_train.zip \; --dataset_config_pbtxt output/data.pbtxt \; --start_from_checkpoint """" \; --batch_size 16",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/46#issuecomment-363256889:1363,log,log,1363,,https://github.com/google/deepvariant/issues/46#issuecomment-363256889,1,['log'],['log']
Testability,"ok, here are my steps:. # Get a GPU machine. I used the command here: https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform. My machine:; ```; pichuan@pichuan-gpu:~$ uname -a; Linux pichuan-gpu 5.11.0-1029-gcp #33~20.04.3-Ubuntu SMP Tue Jan 18 12:03:29 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux; ```. # Install GPU driver and Singularity on the machine:; ```; curl https://raw.githubusercontent.com/google/deepvariant/r1.3/scripts/install_nvidia_docker.sh | bash; curl https://raw.githubusercontent.com/google/deepvariant/r1.3/scripts/install_singularity.sh | bash; ```. Singularity version:; ```; pichuan@pichuan-gpu:~$ singularity --version; singularity version 3.7.0; ```. # Got the test data from Quick Start. I followed the steps in https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-quick-start.md to get small test data. # Run Singularity. ```; # Pull the image.; BIN_VERSION=1.3.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run DeepVariant.; # Using ""--nv"" and ""${BIN_VERSION}-gpu"" is important.; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=$(nproc); ```. The command above worked, so I copy/pasted the command from the original post:. ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/514#issuecomment-1035630725:757,test,test,757,,https://github.com/google/deepvariant/issues/514#issuecomment-1035630725,2,['test'],['test']
Testability,oke_test (cached) PASSED in 0.7s; //deepvariant/environment_tests:protobuf_implementation_test (cached) PASSED in 1.2s; //deepvariant/realigner:fast_pass_aligner_test (cached) PASSED in 0.6s; //deepvariant/realigner:ssw_test (cached) PASSED in 0.5s; //deepvariant/realigner/python:ssw_misc_test (cached) PASSED in 0.9s; //deepvariant/realigner/python:ssw_wrap_test (cached) PASSED in 1.2s; //deepvariant/vendor:timer_test (cached) PASSED in 0.7s; //deepvariant:call_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log; //deepvariant:data_providers_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log; //deepvariant:haplotypes_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:118575,test,testlogs,118575,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ome common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) [2,519 / 2,523] 34 / 38 tests, 20 failed; Testing //deepvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:106934,test,testlogs,106934,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"on us-east1; ```. ```; time python3 ${SHUFFLE_SCRIPT_DIR}/shuffle_tfrecords_beam.py \; --project=""${YOUR_PROJECT}"" \; --input_pattern_list=""${OUTPUT_BUCKET}""/validation_set.with_label.tfrecord-?????-of-00064.gz \; --output_pattern_prefix=""${OUTPUT_BUCKET}/validation_set.with_label.shuffled"" \; --output_dataset_name=""HG001"" \; --output_dataset_config_pbtxt=""${OUTPUT_BUCKET}/validation_set.dataset_config.pbtxt"" \; --job_name=shuffle-tfrecords \; --runner=DataflowRunner \; --staging_location=""${OUTPUT_BUCKET}/staging"" \; --temp_location=""${OUTPUT_BUCKET}/tempdir"" \; --save_main_session \; --region us-east1; ```. ```; time gcloud compute tpus create ${USER}-demo-tpu \; --network=default \; --version=2.3 \; --zone=us-central1-c; ```. # Below is the main difference from the instruction in r0.9: How to look up the TPU_IP:. Given that it seems like we didn't have the right library to properly look up `tpu_name` (`pip install cloud-tpu-client` is needed, it seems). I will try to fix this in our future Dockerfile and test it. But for now, I'll show up to manually resolve the tpu_name. First, install this:; ```; pip3 install cloud-tpu-client; ``` . And then:. ```; TPU_NAME=""${USER}-demo-tpu""; TPU_IP=$(python3 -c ""import tensorflow as tf; print(tf.distribute.cluster_resolver.TPUClusterResolver(tpu=['${TPU_NAME}'], zone='us-central1-c').get_master())""); ```; Check the IP:; ```; $ echo ${TPU_IP}; grpc://10.33.164.2:8470; ```. ```; ( time sudo docker run \; -v /home/${USER}:/home/${USER} \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/model_train \; --use_tpu \; --master=""${TPU_IP}"" \; --dataset_config_pbtxt=""${OUTPUT_BUCKET}/training_set.dataset_config.pbtxt"" \; --train_dir=""${TRAINING_DIR}"" \; --model_name=""inception_v3"" \; --number_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=512 \; --learning_rate=0.008 \; --start_from_checkpoint="""" \; ) 2>&1 | tee ""${LOG_DIR}/train.log""; ```. This now seems to be able to see the TPU. But right now I seem to be havi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/469#issuecomment-871936544:6181,test,test,6181,,https://github.com/google/deepvariant/issues/469#issuecomment-871936544,1,['test'],['test']
Testability,"on"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_gvcf_output.g.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.vcf_candidate_importer.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00001-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_single_site_output.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/HG002_ONT_deeptrio.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/golden.vcf_candidate_importer.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/alt_aligned_pileup.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 199, 8], ""channels"": [1, 2, 3, 4, 5, 6, 9, 10]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040:3404,test,testdata,3404,,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040,1,['test'],['testdata']
Testability,"on?. I'm going to walk through what I've tested so far. Maybe you can check which step is different from your experience. ---. Just to make sure I try it myself, here is what I did:. Get a GPU machine to test with:. ```bash; gcloud compute instances create ""${USER}-gpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --maintenance-policy ""TERMINATE"" \; --accelerator=type=nvidia-tesla-p100,count=1 \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-16"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. I ssh to the machine `gcloud compute ssh pichuan-gpu --zone us-west1-b`. Because my machine doesn't have Nvidia driver installed, I used:. ```bash; wget https://raw.githubusercontent.com/google/deepvariant/r1.6/scripts/install_nvidia_docker.sh; sudo bash -x install_nvidia_docker.sh ; ```; (the docker part is probably not necessary. I just need the driver). And then because I want to test Singularity, I install that with:. ```bash; wget https://raw.githubusercontent.com/google/deepvariant/r1.6/scripts/install_singularity.sh; sudo bash -x install_singularity.sh ; ```. Now, my machine has Singularity. I'll start following https://github.com/google/deepvariant/blob/r1.6/docs/deeptrio-quick-start.md#notes-on-singularity. I ran:. ```bash; BIN_VERSION=1.6.0; singularity pull docker://google/deepvariant:deeptrio-""${BIN_VERSION}-gpu""; ```. This created the file `deepvariant_deeptrio-1.6.0-gpu.sif` on my machine. I checked its size:. ```bash; pichuan@pichuan-gpu:~$ ls -lh deepvariant_deeptrio-1.6.0-gpu.sif ; -rwxrwxr-x 1 pichuan pichuan 12G Dec 5 07:38 deepvariant_deeptrio-1.6.0-gpu.sif; ```. ( @alanlamsiu , This is one thing I'd like you to double check. If you're converting from the 1.6.0 version, I don't think you should see `1.6.0rc2` in your .sif filename. Which is why I asked what command you used to that get that .sif file. You might be pulling a previous, unofficial Docke",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389:1097,test,test,1097,,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389,1,['test'],['test']
Testability,"ons_to_include, contig_dict)); File ""/mnt/google/.google/tmp/Bazel.runfiles_34p88R/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions; return cls(ranges=from_regions(regions, contig_map=contig_map)); File ""/mnt/google/.google/tmp/Bazel.runfiles_34p88R/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__; for i, range_ in enumerate(ranges):; File ""/mnt/google/.google/tmp/Bazel.runfiles_34p88R/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 464, in from_regions; for elt in reader(region):; File ""/mnt/google/.google/tmp/Bazel.runfiles_34p88R/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 429, in bed_parser; with bed.BedReader(filename) as fin:; File ""/mnt/google/.google/tmp/Bazel.runfiles_34p88R/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 211, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/mnt/google/.google/tmp/Bazel.runfiles_34p88R/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader; return NativeBedReader(input_path, **kwargs); File ""/mnt/google/.google/tmp/Bazel.runfiles_34p88R/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__; self._reader = bed_reader.BedReader.from_file(bed_path, options); ValueError: Not found: Could not open gs://canis/CNR-data/exomes.bed; parallel: This job failed:; mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs canis /input-gcsfused-0 && /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/canis/CNR-data/deep_variant_files/examples/0/examples_output.tfrecord@8.gz --reads /input-gcsfused-0/CNR-data/TLE_a_001.reheader.bam --ref /mnt/google/.google/input/deepvariant/performance-testdata/hs37d5.fa.gz --task 0 --regions gs://canis/CNR-data/exomes.bed; ```. I've added the BED file to the public bucket:; gs://public-debug/exomes.bed",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437689349:4118,test,testdata,4118,,https://github.com/google/deepvariant/issues/116#issuecomment-437689349,1,['test'],['testdata']
Testability,"oot/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; (05:40:51) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (05:40:51) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportErro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:2293,test,testlogs,2293,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"or message when asking for help.; ================================================================================; (06:29:17) FAIL: //deepvariant:variant_caller_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log); (06:29:17) INFO: From Testing //deepvariant:variant_caller_test:; ==================== Test output for //deepvariant:variant_caller_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/variant_caller_test.runfiles/com_google_deepvariant/deepvariant/variant_caller_test.py"", line 43, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/variant_caller_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:75710,test,testing,75710,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['test'],['testing']
Testability,"ore/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:; Inherited 'build' options: --action_env PYTHON_BIN_PATH=/opt/conda/envs/py38/bin/python3.8 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages --python_path=/opt/conda/envs/py38/bin/python3.8; (05:40:22) INFO: Reading rc options for 'test' from /deepvariant/.bazelrc:; Inherited 'build' options: --jobs 128 --config=monolithic --show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:; 'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium; (05:40:22) INFO: Reading rc options for 'test' from /deepvariant/.bazelrc:; 'test' options: --test_output=errors; (05:40:22) INFO: Found applicable config definition build:short_logs in file /tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; (05:40:22) INFO: Found applicable config definition build:v2 in file /tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; (05:40:22) INFO: Found applicable config definition test:v2 in file /tensorflow/.tf_configure.bazelrc: --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only; (05:40:22) INFO: Found applicable config definition build:monolithic in file /tensorflow/.bazelrc: --define framework_shared_object=false --define tsl_protobuf_header_only=false --experimental_link_static_libraries_once=false; (05:40:22) INFO: Found applicable config definition build:linux in file /tensorflow/.bazelrc: --host_copt=-w --copt=-Wno-all --copt=-Wno-ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:8094,test,test,8094,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,2,['test'],['test']
Testability,"orflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) [2,519 / 2,523] 34 / 38 tests, 20 failed; Testing //deepvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:106586,test,testlogs,106586,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"orflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) [2,506 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test (shard 10 of 10); 0s local ... (17 actions, 2 running). FAILED: //deepvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:71012,test,testlogs,71012,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"orflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:18) [2,512 / 2,523] 28 / 38 tests, 14 failed; Testing //deepvariant/realigner:realigner_test; 0s local ... (11 actions, 2 running); (06:29:18) FAIL: //deepvariant/realigner:realigner_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log); (06:29:18) INFO: From Testing //deepvariant/realigner:realigner_test:; ==================== Test output for //deepvariant/realigner:realigner_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/realigner_test.runfiles/com_google_deepvariant/deepvariant/realigner/realigner_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportErr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:87947,test,testlogs,87947,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"orks.com/genomics/news/false-positives-a-problem-for-snp-chips-345637) - based on low read quality (low MAPQ), or other factors such as over-representation of multi-site aligned reads - where such a call might be labeled `0/1 0/0 0/0`, with IGV supporting more the call of `0/1 0/1 0/0`. Otherwise if the read quality is good, and alignments are unique with proper coverage then it might actually be _de novo_, though the proband (child) calls are the more interesting ones. For this you would need to have more samples to ensure the calls are not false positives, with further IGV inspection and assay validation. If this might be a bit too fun, feel free to skip it, but it's here if you are curious to dive deeper in the possible _de novo_ calls from DeepTrio/GLnexus. Basically the big idea is take it slow and have fun to get the most of out it, as with many moving parts (_programs + parameters_) and varied data you want to be confident in the calls - which can take a lot of finesse. With super-clean data, that's not such a big deal - but that's not why we use these tools :). Hope it helps,; Paul. #### References. [1] [RTG Tools Manual](https://github.com/RealTimeGenomics/rtg-tools/blob/master/installer/resources/tools/RTGOperationsManual.pdf); [2] [dv-trio: a family-based variant calling pipeline using DeepVariant](https://academic.oup.com/bioinformatics/article/36/11/3549/5823297?login=false); [3] [FamSeq: A Variant Calling Program for Family-Based Sequencing Data Using Graphics Processing Units](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003880); [4] [DeepTrio: Variant Calling in Families Using Deep Learning](https://www.biorxiv.org/content/10.1101/2021.04.05.438434v1); [5] [A unified haplotype-based method for accurate and comprehensive variant calling](https://pubmed.ncbi.nlm.nih.gov/33782612/) _(This is the Octopus paper.)_; [6] [DeNovoGear: de novo indel and point mutation discovery and phasing](https://pubmed.ncbi.nlm.nih.gov/23975140/)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/699#issuecomment-1716447969:5671,log,login,5671,,https://github.com/google/deepvariant/issues/699#issuecomment-1716447969,1,['log'],['login']
Testability,"ot/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:124169,log,log,124169,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"ot/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:125520,log,log,125520,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"ot/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log. Executed 24 out of 38 tests: 14 tests pass and 24 fail locally.; There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.; (06:29:21) INFO: Build completed, 24 tests FAILED, 44 total actions. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:126395,log,log,126395,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,17,"['log', 'test']","['log', 'test', 'testlogs', 'tests']"
Testability,"ot/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/exe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:122861,log,log,122861,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"otnote6)</sup>2 HG001, 3 HG002, 3 HG003, 3 HG004, 7 HG005, 6 HG006, 6 HG007, 2 NA12891, 2 NA12892 | 457,420,038; ./docs/deeptrio-details-training-data.md:| 1.6.0 | <sup>[(6)](#vfootnote6)</sup>9 HG001, 7 HG002, 7 HG003, 7 HG004, 8 HG005, 8 HG006, 8 HG007, 9 NA12891, 9 NA12892 | 27,783,324 |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | <sup>[(6)](#vfootnote6)</sup>6 HG002, 6 HG003, 6 HG004, 8 HG005, 8 HG006, 8 HG007 | 13,039,595 |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 9 HG002, 5 HG003, 5 HG004, 1 HG005, 1 HG006, 1 HG007 | 890,016,014<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 9 HG002, 5 HG003, 5 HG004, 1 HG005, 1 HG006, 1 HG007 | 838,515,085<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 1 HG002, 1 HG002, 1 HG004 | 50,249,704<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 1 HG002, 1 HG002, 1 HG004 | 99,675,190<sup>[(5)](#vfootnote5)</sup> |; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/HG002_ONT_deeptrio.denovo.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/customized_classes.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_gvcf_output.g.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.vcf_candidate_importer.calling_examples.tfrecord.gz.example_info.json",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040:1977,test,testdata,1977,,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040,1,['test'],['testdata']
Testability,"ouble-check that the model is trained with the same parameters and version of DeepVariant as you generated the examples with. An error will not appear when these are mismatched because of how InceptionV3 works. Note that if you set --pileup_image_height in DeepVariant, then you must use a model trained with that same parameter.; W1009 18:31:59.770313 48004354086720 call_variants.py:353] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio). Please double-check that the model is trained with the same parameters and version of DeepVariant as you generated the examples with. An error will not appear when these are mismatched because of how InceptionV3 works. Note that if you set --pileup_image_height in DeepVariant, then you must use a model trained with that same parameter.; raise ValueError('`call_variants_outputs` did not pass sanity check.'); ValueError: `call_variants_outputs` did not pass sanity check. **tail -n 50 log**; Traceback (most recent call last):; File ""/TMP_DIR/Bazel.runfiles_eyn11z72/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1249, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/TMP_DIR/Bazel.runfiles_eyn11z72/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/TMP_DIR/Bazel.runfiles_eyn11z72/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/TMP_DIR/Bazel.runfiles_eyn11z72/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1225, in main; merge_and_write_variants_and_nonvariants(variant_generator,; File ""/TMP_DIR/Bazel.runfiles_eyn11z72/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1012, in merge_and_write_variants_and_nonvariants; variant = next_or_none(variant_iterable); File ""/TMP_DIR/Bazel.runfiles_eyn",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/488#issuecomment-939618673:3327,log,log,3327,,https://github.com/google/deepvariant/issues/488#issuecomment-939618673,1,['log'],['log']
Testability,"ow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:17) FAIL: //deepvariant/realigner/allele_count_linear:model_evaluation_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log); (06:29:17) INFO: From Testing //deepvariant/realigner/allele_count_linear:model_evaluation_test:; ==================== Test output for //deepvariant/realigner/allele_count_linear:model_evaluation_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/realigner/allele_count_linear/model_evaluation_test.py"", line 41, in <module>; from deepvariant import testdata; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/testdata.py"", line 39, in <module>; from third_party.nucleus.testing import test_utils a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:77447,test,testlogs,77447,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) [2,506 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test (shard 10 of 10); 0s local ... (17 actions, 2 running). FAILED: //deepvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:71187,test,testlogs,71187,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) [2,519 / 2,523] 34 / 38 tests, 20 failed; Testing //deepvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:106468,log,log,106468,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"p.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) [2,519 / 2,523] 34 / 38 tests, 20 failed; Testing //deepvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:106642,log,log,106642,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) [2,488 / 2,523] 19 / 38 tests, 5 failed; Testing //deepvariant:data_providers_test; 0s local ... (35 actions, 2 running); (06:29:10) FAIL: //deepvariant:data_providers_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log); (06:29:10) INFO: From Testing //deepvariant:data_providers_test:; ==================== Test output for //deepvariant:data_providers_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/data_providers_test.runfiles/com_google_deepvariant/deepvariant/data_providers_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:30650,test,testlogs,30650,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"pes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-1804-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""e2-medium"" \; --zone ""us-west1-b""; ```. After ssh into the machine, I ran:. ```; sudo apt -y update && sudo apt -y install docker.io; ```. And then followed the steps here:. https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md. For the main DeepVariant command, I ran:. ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --intermediate_results_dir /output/intermediate_results_dir \; --num_shards=1 \; --call_variants_extra_args=""use_openvino=true"" \; 2>&1 | tee /tmp/deepvariant.log; ```. With this run above, all steps (including call_variants) completed without errors. After that run, I repeated the call_variants step:; ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/call_variants \; --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" \; --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" \; --checkpoint ""/opt/models/wgs/model.ckpt"" \; --use_openvino; ```; which worked fine too. You mentioned you used DeepVariant1.1.0 version via Docker, but you also mentioned your command was:; `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32`. Can you be more specific about how you run this command?. And, another ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/432#issuecomment-806341687:1249,log,log,1249,,https://github.com/google/deepvariant/issues/432#issuecomment-806341687,1,['log'],['log']
Testability,"piens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main; AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found.; warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated; /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) ; warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated; Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main; AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300:2240,Assert,AssertionError,2240,,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300,1,['Assert'],['AssertionError']
Testability,"pileup_image_height? Yes, our depths can be as much as a few thousands. I haven’t looked at the data set yet, but that’s common. Brad Thomas. From: Ryan Poplin [mailto:notifications@github.com]; Sent: Tuesday, February 13, 2018 10:28 AM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [External]Re: [google/deepvariant] Build and test works, binaries do not (#47). Sounds fun! I haven't tried something similar yet. One thing to maybe keep in mind, for 1% allele fraction that means you probably have depth >100x coverage, so you might find that you want to change the default height of the pileup tensors which is set at 100. Here is the flag for that in make_examples: https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L177. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/47#issuecomment-365321032>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqaTkjYsOD0tc8gRnJIGZ6o5VeAfPks5tUbgmgaJpZM4R5yAT>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/47#issuecomment-365324431:432,test,test,432,,https://github.com/google/deepvariant/issues/47#issuecomment-365324431,1,['test'],['test']
Testability,"pileup_images( ; File ""/tmp/Bazel.runfiles_gd__toh4/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 534, in create_pileup_images ; pileup = _pileup_for_pair_of_alts(alts) ; File ""/tmp/Bazel.runfiles_gd__toh4/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 486, in _pileup_for_pair_of_alts ; ref_image = self.build_pileup( ; File ""/tmp/Bazel.runfiles_gd__toh4/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 435, in build_pileup ; build_pileup_for_one_sample(reads_for_samples[i], sample)) ; File ""/tmp/Bazel.runfiles_gd__toh4/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 355, in build_pileup_for_one_sample ; rows = ([self._encoder.encode_reference(refbases)] * ; ImportError: numpy.core.multiarray failed to import ; I0516 14:57:26.170286 139707932989248 make_examples_core.py:257] Task 0/2: Writing example info to ./make_examples.tfrecord-00000-of-00002.gz.example_info.json ; I0516 14:57:26.170386 139707932989248 make_examples_core.py:2273] example_shape = None ; I0516 14:57:26.170525 139707932989248 make_examples_core.py:2274] example_channels = [1, 2, 3, 4, 5, 6, 19] ; I0516 14:57:26.170763 139707932989248 make_examples_core.py:257] Task 0/2: Found 0 candidate variants ; I0516 14:57:26.170813 139707932989248 make_examples_core.py:257] Task 0/2: Created 0 examples ; parallel: This job failed: ; /opt/deepvariant/bin/make_examples --mode calling --ref genome.fasta --reads test.paired_end.sorted.cram --examples ./make_examples.tfrecord@2.gz --channels ; insert_size --gvcf ./gvcf.tfrecord@2.gz --regions genome.bed --task 1 ; ```. And the command is; ```bash; /opt/deepvariant/bin/run_deepvariant \; --ref=genome.fasta \; --reads=test.paired_end.sorted.cram \; --output_vcf=test_out.vcf.gz \; --output_gvcf=test_out.g.vcf.gz \; --model_type=WGS \; --regions genome.bed \; --intermediate_results_dir=. \; --num_shards=2; ```. Deepvariant version: 1.5.0 (the official docker container); Ran on Ubuntu 20.04 LTS",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/640#issuecomment-1549844072:2955,test,test,2955,,https://github.com/google/deepvariant/issues/640#issuecomment-1549844072,2,['test'],['test']
Testability,"portError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:16) [2,506 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test (shard 10 of 10); 0s local ... (17 actions, 2 running). FAILED: //deepvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:70737,test,tests,70737,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,"['Test', 'test']","['Testing', 'tests']"
Testability,"portError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) [2,519 / 2,523] 34 / 38 tests, 20 failed; Testing //deepvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:106140,test,tests,106140,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,"['Test', 'test']","['Testing', 'tests']"
Testability,"put ${outdir2}/${sample}_haplotagged.bam \ #generate ""C1_haplotagged.bam""、""F1_haplotagged.bam""、""M1_haplotagged.bam""; --reference ${ref}; ${outdir2}/${sample}_deepvariant1.phased.vcf.gz; ${bam}. samtools index ${outdir2}/${sample}_haplotagged.bam. ④The final result of variant calling; #DeepTrio version:1.2.0; /opt/deepvariant/bin/deeptrio/run_deeptrio; --model_type PACBIO; --ref ${ref}; --reads_child ${outdir2}/C1_haplotagged.bam; --reads_parent1 ${outdir2}/F1_haplotagged.bam; --reads_parent2 ${outdir2}/M1_haplotagged.bam; --output_vcf_child ${outdir4}/C1.output.vcf.gz; --output_vcf_parent1 ${outdir4}/F1.output.vcf.gz; --output_vcf_parent2 ${outdir4}/M1.output.vcf.gz; --sample_name_child 'C1'; --sample_name_parent1 'F1'; --sample_name_parent2 'M1'; --num_shards 8; --output_gvcf_child ${outdir4}/C1.g.vcf.gz; --output_gvcf_parent1 ${outdir4}/F1.g.vcf.gz; --output_gvcf_parent2 ${outdir4}/M1.g.vcf.gz; --use_hp_information. **However,the log file of DeepTrio still contains errors：**(The result files have been generated); cat log |grep -i error; W1008 21:26:50.592375 47245352568640 call_variants.py:353] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio). Please double-check that the model is trained with the same parameters and version of DeepVariant as you generated the examples with. An error will not appear when these are mismatched because of how InceptionV3 works. Note that if you set --pileup_image_height in DeepVariant, then you must use a model trained with that same parameter.; W1009 09:06:50.674110 47029842433856 call_variants.py:353] The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio). Please double-check that the model is trained with the same parameters and version of DeepVariant as you generated the examples with. An error will not appear when these are mismatched because of how InceptionV3 works. Note that if you set --pileup_image_height in DeepVariant, then you must u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/488#issuecomment-939618673:1582,log,log,1582,,https://github.com/google/deepvariant/issues/488#issuecomment-939618673,2,['log'],['log']
Testability,"put. One component in make_examples is local realignment, which can be affected by things like depth, read length, etc. Currently I think that might be causing the biggest variance of the runtime of make_examples. This makes it hard for me to give general estimation guidelines.; Can you give us a bit more information on your BAM? Is it WGS or WES? Which Illumina sequencing machine is it from?; If you are okay with sharing the BAM header, it'll help too. If it's easier to share via email, you can email pichuan@google.com. > 2. Any idea of how I do a better job sizing compute resources?. On the GCP DeepVariant tutorial page:; https://cloud.google.com/life-sciences/docs/tutorials/deepvariant; You can see some numbers of runtime and cost estimates on GCP. This might help give you some sense of what type of machine you can choose. Since you're running on AWS, the cost might change based on pricing. > 3. How do I know if docker is making progress or not?. Currently, our one-step script should be outputting some logs as it goes. If make_examples is still running, you should see lines of logs coming out, showing there's progress. There's likely room for improvement on how we show this progress. If you have suggestions or bug reports, please let us know. > I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good!. Sorry to hear that the logs are not coming out promptly. If it's possible, can you tell us where did the log get stuck?. > 4. I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. I haven'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/260#issuecomment-573487475:1187,log,logs,1187,,https://github.com/google/deepvariant/issues/260#issuecomment-573487475,1,['log'],['logs']
Testability,"pvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log; (06:29:16) FAIL: //deepvariant:model_train_test (shard 10 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log); (06:29:16) INFO: From Testing //deepvariant:model_train_test (shard 10 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 10 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorfl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:72645,log,log,72645,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"pvariant:model_eval_test (shard 9 of 10); 0s local ... (4 actions, 1 running). FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; (06:29:20) FAIL: //deepvariant:model_eval_test (shard 9 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:107165,log,log,107165,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,pvariant:model_train_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_10_of_10/test.log; (06:29:16) FAIL: //deepvariant:model_train_test (shard 10 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_tra,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:71887,test,testlogs,71887,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"python/allelecounter_wrap_test/test.log; //deepvariant/python:variant_calling_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/python/variant_calling_wrap_test/test.log; //deepvariant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:122035,log,log,122035,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:13) [2,495 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_eval_test [0s (8 actions)] ... (28 actions, 2 running); (06:29:13) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (06:29:13) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportErro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:46943,test,testlogs,46943,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:14) [2,498 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_eval_test [0s (5 actions)] ... (25 actions, 2 running); (06:29:14) FAIL: //deepvariant:model_eval_test (shard 5 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log); (06:29:14) INFO: From Testing //deepvariant:model_eval_test (shard 5 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 5 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportErro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:53530,test,testlogs,53530,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,; Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-476428247:2549,test,testing,2549,,https://github.com/google/deepvariant/issues/165#issuecomment-476428247,1,['test'],['testing']
Testability,"r job sizing compute resources?. On the GCP DeepVariant tutorial page:; https://cloud.google.com/life-sciences/docs/tutorials/deepvariant; You can see some numbers of runtime and cost estimates on GCP. This might help give you some sense of what type of machine you can choose. Since you're running on AWS, the cost might change based on pricing. > 3. How do I know if docker is making progress or not?. Currently, our one-step script should be outputting some logs as it goes. If make_examples is still running, you should see lines of logs coming out, showing there's progress. There's likely room for improvement on how we show this progress. If you have suggestions or bug reports, please let us know. > I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good!. Sorry to hear that the logs are not coming out promptly. If it's possible, can you tell us where did the log get stuck?. > 4. I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. I haven't tried using nohub. I'll have to try and respond to this later.; > ; > thanks; > ; > Andy; > ; > p.s. I am running in AWS . not sure if that makes a difference or not. I don't expect it to make a difference. But if you do observe any issues, feel free to let us know what kind of AWS instances you're running on, and what's the unexpected behavior, so we can reproduce the issue.; > ; > p.p.s. Is there a better place to ask questions like this?. This is a good place to ask :); It's a public forum, so our team and everyone in the community can see and help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/260#issuecomment-573487475:1790,log,log,1790,,https://github.com/google/deepvariant/issues/260#issuecomment-573487475,1,['log'],['log']
Testability,"r updating:; Please use `layer.__call__` method instead.; I0327 13:32:21.277438 47138345245376 estimator.py:1149] Done calling model_fn.; I0327 13:32:23.167996 47138345245376 monitored_session.py:240] Graph was finalized.; I0327 13:32:23.169671 47138345245376 saver.py:1284] Restoring parameters from /opt/mod els/wgs/model.ckpt; I0327 13:32:28.719004 47138345245376 session_manager.py:500] Running local_init_op.; I0327 13:32:28.854336 47138345245376 session_manager.py:502] Done running local_init_o p.; I0327 13:32:29.648829 47138345245376 modeling.py:413] Reloading EMA...; I0327 13:32:29.650222 47138345245376 saver.py:1284] Restoring parameters from /opt/mod els/wgs/model.ckpt; I0327 13:32:39.446630 47138345245376 call_variants.py:402] Processed 1 examples in 1 b atches [2569.441 sec per 100]; I0327 13:32:39.551621 47138345245376 call_variants.py:404] Done evaluating variants. real 0m29.939s; user 0m20.774s; sys 0m5.396s. ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""/scratch/moldach/bin/quickstart- testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/tmp63xxmwmi/call_variants_outp ut.tfrecord.gz"" --outfile ""/scratch/moldach/bin/quickstart-output/output.vcf.gz"" --non variant_site_tfrecord_path ""/tmp/tmp63xxmwmi/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/scra tch/moldach/bin/quickstart-output/output.g.vcf.gz"". 2020-03-27 13:32:43.691530: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/ tmp63xxmwmi/call_variants_output.tfrecord.gz; 2020-03-27 13:32:43.692692: I deepvariant/postprocess_variants.cc:97] Done reading: /t mp/tmp63xxmwmi/call_variants_output.tfrecord.gz. #entries in single_site_calls = 86; 2020-03-27 13:32:43.692820: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 86; 2020-03-27 13:32:43.692941: I deepvariant/postprocess_variants.cc:103] Start SortSingl eSiteCalls; 2020-03-27 13:32:43.693087: I deepvariant/postprocess_variants.cc:105] Done SortSingle SiteCalls; I0327 13:32:43.6935",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-605306987:10106,test,testdata,10106,,https://github.com/google/deepvariant/issues/287#issuecomment-605306987,1,['test'],['testdata']
Testability,"r1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done.""; ```. Runtime:; ```; $ grep '^real' /tmp/open; real 7m20.986s; real 21m24.429s; real 6m32.705s; ```. 3. Use v1.0.0 image.; The code diff:; ```; $ git diff; diff --git a/scripts/run_wgs_case_study_docker.sh b/scripts/run_wgs_case_study_docker.sh; index 3dc9712..88fb0c1 100755; --- a/scripts/run_wgs_case_study_docker.sh; +++ b/scripts/run_wgs_case_study_docker.sh; @@ -72,7 +72,7 @@ sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}:/output"" \; google/deepvariant:""${BIN_VERSION}"" \; - /opt/deepvariant/bin/run_deepvariant \; + /opt/deepvariant/bin/run_deepvariant --make_examples_extra_args=regions=chr1 \; --model_type=WGS \; --ref=""/input/${REF}.gz"" \; --reads=""/input/${BAM}"" \; @@ -100,6 +100,6 @@ pkrusche/hap.py /opt/hap.py/bin/hap.py \; -f ""${INPUT_DIR}/${TRUTH_BED}"" \; -r ""${UNCOMPRESSED_REF}"" \; -o ""${OUTPUT_DIR}/happy.output"" \; - --engine=vcfeval; + --engine=vcfeval -l chr1; ) 2>&1 | tee ""${LOG_DIR}/happy.log""; echo ""Done.""; ```. Runtime; ```; $ grep '^real' /tmp/openvino.log; real 7m26.887s; real 20m40.889s; real 6m25.257s; ```. ---. # Machine details. I got the machine with this command:. ```; gcloud compute instances create ""${USER}-openvino-expt"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-1604-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""custom-64-131072"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. ## `lscpu`; ```; $ lscpu; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian; CPU(s): 64; On-line CPU(s) list: 0-63; Thread(s) per core: 2; Core(s) per socket: 32; Socket(s): 1; NUMA node(s): 1; Vendor ID: GenuineIntel; CPU family: 6; Model: 85; Model name: Intel(R) Xeon(R) CPU @ 2.00GHz; Stepping: 3; CPU MHz: 2000.178; BogoMIPS: 4000.35; Hypervisor vendor: KVM; Virtualization type: full; L1d cache: 32K; L1i cache: 32K; L2 cache: 1024K; L3 cache: 39424K; NUMA node0 CPU(",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735276044:4152,log,log,4152,,https://github.com/google/deepvariant/pull/363#issuecomment-735276044,1,['log'],['log']
Testability,"r20.unittest.fa sta"" --reads ""/scratch/moldach/bin/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmp63xxmwmi/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmp63xxmwmi/gv cf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. I0327 13:32:07.160181 47175299967680 make_examples.py:386] ReadRequirements are: min_m apping_quality: 10; min_base_quality: 10; min_base_quality_mode: ENFORCED_BY_CLIENT. I0327 13:32:07.206463 47175299967680 genomics_reader.py:223] Reading /scratch/moldach/ bin/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0327 13:32:07.218669 47175299967680 make_examples.py:535] Preparing inputs; I0327 13:32:07.293092 47175299967680 genomics_reader.py:223] Reading /scratch/moldach/ bin/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0327 13:32:07.294783 47175299967680 make_examples.py:535] Common contigs are ['chr20' ]; I0327 13:32:07.296233 47175299967680 make_examples.py:535] Writing examples to /tmp/tm p63xxmwmi/make_examples.tfrecord-00000-of-00001.gz; I0327 13:32:07.296404 47175299967680 make_examples.py:535] Writing gvcf records to /tm p/tmp63xxmwmi/gvcf.tfrecord-00000-of-00001.gz; I0327 13:32:07.298243 47175299967680 make_examples.py:535] Starting from v0.9.0, --use _ref_for_cram is default to true. If you are using CRAM input, note that we will decod e CRAM using the reference you passed in with --ref; 2020-03-27 13:32:07.298857: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OP T_BLOC",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/287#issuecomment-605306987:2647,test,testdata,2647,,https://github.com/google/deepvariant/issues/287#issuecomment-605306987,1,['test'],['testdata']
Testability,"r20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ```. Run make_examples:. ```; OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}""; ```. ```; python bin/make_examples.zip \; --mode calling \; --ref ""${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta"" \; --reads ""${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam"" \; --regions ""chr20:10,000,000-10,010,000"" \; --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"" \; --channels ""insert_size""; ```. (To figure out which flags you need to add for each model, you can read https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L253 . Sorry that we don't have better documentation than that right now). For how to run this with multiple shards, and how to run the rest of the commands, please read https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md. I just tested the steps above and confirmed that it worked for me on v1.4.0, at least for the make_examples step.; If you encounter more issues with other steps, please feel free to ask again. I'd be happy to help. Note that I don't plan to put this into an official documentation page now, because that adds to our maintenance burden to keep it up to date. Given that we have the Docker/Singularity solution that works generally well for our users, I don't expect many of our users to need to use pre-built binaries. @zivlang thank you for your question so I have a chance to test it again and document it here. Hopefully this is helpful for you. Happy to answer more questions if you encounter more problems.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/590#issuecomment-1322695241:3227,test,tested,3227,,https://github.com/google/deepvariant/issues/590#issuecomment-1322695241,2,['test'],"['test', 'tested']"
Testability,rAssignedEvent; instance: google-pipelines-worker-4b16fd95b691baddc54b0c5ec50dc6c7; zone: us-west1-b; timestamp: '2018-11-08T14:27:06.604193Z'; labels: {}; pipeline:; actions:; - commands:; - -c; - /opt/deepvariant_runner/bin/gcp_deepvariant_runner --project valis-194104 --zones; us-west1-b --docker_image gcr.io/deepvariant-docker/deepvariant:0.7.0 --outfile; gs://canis/CNR-data/TLE_a_001_deep_variant.vcf --staging gs://canis/CNR-data/deep_variant_files --model; gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard --regions; gs://canis/CNR-data/CDS-canonical.bed --bam gs://canis/CNR-data/TLE_a_001.bam --bai; gs://canis/CNR-data/TLE_a_001.bam.bai --ref gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz --ref_fai; gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz.fai --ref_gzi gs://canis/CNR-data/GRCh38_Verily_v1.genome.fa.gz.gzi --gcsfuse; entrypoint: bash; environment: {}; flags: []; imageUri: gcr.io/deepvariant-docker/deepvariant_runner:0.7.0; labels: {}; mounts: []; name: ''; pidNamespace: ''; portMappings: {}; - commands:; - /bin/sh; - -c; - gsutil -q cp /google/logs/output gs://canis/CNR-data/deep_variant_files/runner_logs_20181108_082705.log; entrypoint: ''; environment: {}; flags:; - ALWAYS_RUN; imageUri: google/cloud-sdk:alpine; labels: {}; mounts: []; name: ''; pidNamespace: ''; portMappings: {}; environment: {}; resources:; projectId: valis-194104; regions: []; virtualMachine:; accelerators: []; bootDiskSizeGb: 10; bootImage: projects/cos-cloud/global/images/family/cos-stable; cpuPlatform: ''; disks: []; labels: {}; machineType: n1-standard-1; nvidiaDriverVersion: ''; preemptible: false; serviceAccount:; email: default; scopes:; - https://www.googleapis.com/auth/cloud-platform; - https://www.googleapis.com/auth/devstorage.read_write; - https://www.googleapis.com/auth/genomics; zones:; - us-west1-b; timeout: 604800s; startTime: '2018-11-08T14:27:06.604193Z'; name: projects/valis-194104/operations/12097970745380060156; ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437055644:8495,log,logs,8495,,https://github.com/google/deepvariant/issues/116#issuecomment-437055644,2,['log'],"['log', 'logs']"
Testability,"re --copt=-Wno-write-strings'; + bazel; [bazel release 0.15.0]; Usage: bazel <command> <options> ... Available commands:; analyze-profile Analyzes build profile data.; build Builds the specified targets.; canonicalize-flags Canonicalizes a list of bazel options.; clean Removes output files and optionally stops the server.; coverage Generates code coverage report for specified test targets.; cquery Loads, analyzes, and queries the specified targets w/ configurations.; dump Dumps the internal state of the bazel server process.; fetch Fetches external repositories that are prerequisites to the targets.; help Prints help for commands, or the index.; info Displays runtime info about the bazel server.; license Prints the license of this software.; mobile-install Installs targets to mobile devices.; print_action Prints the command line args for compiling a file.; query Executes a dependency graph query.; run Runs the specified target.; shutdown Stops the bazel server.; test Builds and runs the specified test targets.; version Prints version information for bazel. Getting more help:; bazel help <command>; Prints help and options for <command>.; bazel help startup_options; Options for the JVM hosting bazel.; bazel help target-syntax; Explains the syntax for specifying targets.; bazel help info-keys; Displays a list of keys used by the info command.; + [[ 1 = \1 ]]; + bazel test -c opt --local_test_jobs=1 --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/...; (06:29:06) WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.; (06:29:06) INFO: Current date is 2019-02-14; (06:29:06) Loading: ; (06:29:06) Loading: 0 packages loaded; (06:29:07) INFO: Analysed 168 targets (0 packages loaded).; (06:29:07) INFO: Found 130 targets and 38 test targets...; (06:29:07) [1 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt; (06:29:08) FAIL: //deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:10373,test,test,10373,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],['test']
Testability,"red reads), running deepvar 0.9.0 and 1.0.0 with singularity v.3.5.2-1.1.el7 and exactly the same command (`--num_shards=10`). The running time is now almost the same, much longer than my old test with deepvar 0.9.0 on a 30X WGS. . Below I've reported running time in min for make_example+call_variants+post_process:; - **v0.9.0**: 290+1494+281 = 2065min (~34h); - **v1.0.0**: 335+1487+300 = 2122min (~35h); - **v0.9.0 OLD TEST ON 30X WGS**: 198+456+82 = 736min (~12h). The number of variants for the 3 runs are:; - **v0.9.0**: 531371190 g.vcf.gz; 10784757 vcf.gz (4552313 PASS, 6232444 RefCall); - **v1.0.0**: 547491396 g.vcf.gz; 11892262 vcf.gz (4619350 PASS, 7272912 RefCall); - **v0.9.0 OLD TEST ON 30X WGS**: 213244705 g.vcf.gz; 9096927 vcf.gz (4661618 PASS, 4435309 RefCall). So, the first question is: are these running times expected? The running times you reported are much shorter it seems. Can it be that the running time increased from 12 to 34h just because of the lower coverage? . The exact command I've used is below (it is the same for v1.0.0 but using the corresponding singularity image):; ```; singularity exec \; --bind /data/ref/genomes/GRCh38:/genomes \; --bind /data/projects/HICF2_project/BAM:/bam_files \; /well/gel/HICF2/software/singularity/deepvariant-0.9.0.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS --ref=""/genomes/GCA_000001405.15_GRCh38_full_plus_hs38d1_analysis_set.fna"" \; --reads=""/bam_files/${bamfile}"" \; --output_vcf=""VCF/${sampleID}.vcf.gz"" \; --output_gvcf=""VCF/${sampleID}.g.vcf.gz"" \; --intermediate_results_dir=""tmp_data"" \; --num_shards=10; ```. I've uploaded the log files from the 3 runs if you want to take a look:; [deepvar_0.9.0_oldrun.log](https://github.com/google/deepvariant/files/5281370/deepvar_0.9.0_oldrun.log); [deepvar_1.0.0.log](https://github.com/google/deepvariant/files/5281371/deepvar_1.0.0.log); [deepvar_0.9.0.log](https://github.com/google/deepvariant/files/5281372/deepvar_0.9.0.log). Thanks for your support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/346#issuecomment-698786904:1735,log,log,1735,,https://github.com/google/deepvariant/issues/346#issuecomment-698786904,7,['log'],['log']
Testability,"remove and 7 not upgraded.; N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension; Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0); ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting; Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5); Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6); Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3); Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0); Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3); Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0); Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0); Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2); Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0); Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0); Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1); Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13); Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4); Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23); Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7); Requirement already satisfied: scip",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/89#issuecomment-416438760:10739,mock,mock,10739,,https://github.com/google/deepvariant/issues/89#issuecomment-416438760,1,['mock'],['mock']
Testability,"requency). The neural net assigns a genotype probability for all of these positions. The confidence that the neural network has in the variant call is represented in the GQ field (which is the phred-encoded probability that the assigned genotype is correct). When the probability for reference is >50% and 99% (GQ20), the genotype assigned is ./. when the probability for reference is >99% (GQ20+) the genotype assigned is 0/0. In your gVCF calls, only this row is a REF call made by the neural net:; ```; 1	69897	.	T	C,<*>	0.7	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:8:6:2,4,0:0.666667,0:0,8,13,990,990,990; ```. The second way that DeepVariant makes a no-call/reference-call is in the process of gVCF generation. The gVCF was designed as a way to encode the probability of a region with no variant call information is a reference, so that later in joint genotyping of many samples, you can potentially change the genotype call based on what you see in the population. In your gVCF calls all other REF calls fall into this category. DeepVariant makes a gVCF with REF-CALL blocks over stretches where it observes no candidates, with a heuristic logic based on coverage and support determining the probability of these calls. In calls of this nature, there is a different logic that does not apply the GQ20 threshold. In joint genotyping, GLnexus will use the probabilities to determine the VCF call. . In summary, a variant (0/1 or 1/1) will have a variant call if it is the most likely genotype at the position.; A position will receive a 0/0 call if the model observed a site with >GQ20. It can make sense to filter DeepVariant results if you have a substantial preference for precision. In addition to higher overall accuracy, we try to make DeepVariant report well-calibrated confidence probabilities. If you need higher precision for the variant calls, filtering on the call GQ is the best field. This was a long answer. Please let me know what areas remain unclear after reading it. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/639#issuecomment-1526164168:1560,log,logic,1560,,https://github.com/google/deepvariant/issues/639#issuecomment-1526164168,2,['log'],['logic']
Testability,"rflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================. FAILED: //deepvariant:make_examples_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; (06:29:20) FAIL: //deepvariant:make_examples_test (shard 1 of 2) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log); (06:29:20) INFO: From Testing //deepvariant:make_examples_test (shard 1 of 2):; ==================== Test output for //deepvariant:make_examples_test (shard 1 of 2):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/deepvariant/make_examples_test.py"", line 48, in <module>; from third_party.nucleus.io import vcf; Fil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:100240,test,testlogs,100240,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"rflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:; Inherited 'build' options: --action_env PYTHON_BIN_PATH=/opt/conda/envs/py38/bin/python3.8 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages --python_path=/opt/conda/envs/py38/bin/python3.8; (05:40:22) INFO: Reading rc options for 'test' from /deepvariant/.bazelrc:; Inherited 'build' options: --jobs 128 --config=monolithic --show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:; 'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium; (05:40:22) INFO: Reading rc options for 'test' from /deepvariant/.bazelrc:; 'test' options: --test_output=errors; (05:40:22) INFO: Found applicable config definition build:short_logs in file /tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; (05:40:22) INFO: Found applicable config definition build:v2 in file /tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; (05:40:22) INFO: Found applicable config definition test:v2 in file /tensorflow/.tf_configure.bazelrc: --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only; (05:40:22) INFO: Found applicable config definition build:monolithic in file /tensorflow/.baz",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:8046,test,test,8046,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,1,['test'],['test']
Testability,"rflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:13) [2,495 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_eval_test [0s (8 actions)] ... (28 actions, 2 running); (06:29:13) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (06:29:13) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:46999,log,log,46999,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"rflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:14) [2,498 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_eval_test [0s (5 actions)] ... (25 actions, 2 running); (06:29:14) FAIL: //deepvariant:model_eval_test (shard 5 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log); (06:29:14) INFO: From Testing //deepvariant:model_eval_test (shard 5 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 5 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:53586,log,log,53586,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"riant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:124287,test,testlogs,124287,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"riant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:125638,test,testlogs,125638,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"riant/make_examples.py"", line 485, in _ensure_consistent_contigs; min_coverage_fraction); File ""/mnt/google/.google/tmp/Bazel.runfiles_Mu9e5m/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage; ref_bp, common_bp, coverage, format_contig_matches())); ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373 bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MISSING, ""10"" is 135534747 bp and IS MISSING, ""11"" is 135006516 bp and IS MISSING, ""12"" is 133851895 bp and IS MISSING, ""13"" is 115169878 bp and IS MISSING, ""14"" is 107349540 bp and IS MISSING, ""15"" is 102531392 bp and IS MISSING, ""16"" is 90354753 bp and IS MISSING, ""17"" is 81195210 bp and IS MISSING, ""18"" is 78077248 bp and IS MISSING, ""19"" is 59128983 bp and IS MISSING, ""20"" is 63025520 bp and IS MISSING, ""21"" is 48129895 bp and IS MISSING, ""22"" is 51304566 bp and IS MISSING, ""X"" is 155270560 bp and IS MISSING, ""Y"" is 59373566 bp and IS MISSING; parallel: This job failed:; mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs canis /input-gcsfused-0 && /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/canis/CNR-data/deep_variant_files/examples/0/examples_output.tfrecord@8.gz --reads /input-gcsfused-0/CNR-data/TLE_a_001.bam --ref /mnt/google/.google/input/deepvariant/performance-testdata/hs37d5.fa.gz --task 0 --regions gs://canis/CNR-data/exomes.bed; Using mount point: /input-gcsfused-0; Opening GCS connection...; Opening bucket...; Mounting file system...; File system has been successfully mounted.; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/116#issuecomment-437596560:3647,test,testdata,3647,,https://github.com/google/deepvariant/issues/116#issuecomment-437596560,1,['test'],['testdata']
Testability,"rm"" --image-family ""ubuntu-2004-lts"" --image-project ""ubuntu-os-cloud"" --machine-type ""custom-64-131072"" --boot-disk-size ""300"" --zone ""us-west2-b"" --min-cpu-platform ""Intel Skylake""`. ssh into the machine:. ```; gcloud compute ssh pichuan-cpu --zone us-west2-b; ```. Get the binaries and models:. ```; BUCKET=""gs://deepvariant""; BIN_VERSION=""1.4.0""; MODEL_VERSION=""1.4.0"". BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}""; MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". mkdir -p bin; # Download the DeepVariant binaries.; gsutil -m cp ""${BIN_BUCKET}/*"" bin/; chmod a+x bin/*; ```. Then, I ran:; ```; cd bin; bash run-prereq.sh; cd -; ```. The `run-prereq.sh` tends to be the most tricky one - it will require root permission, and it'll install a bunch of stuff on your machine. If you can't use Docker because of root permissions, you likely won't be able to run this as well. Download test data:. ```; INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ```. Run make_examples:. ```; OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}""; ```. ```; python",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/590#issuecomment-1322695241:1532,test,testdata,1532,,https://github.com/google/deepvariant/issues/590#issuecomment-1322695241,1,['test'],['testdata']
Testability,"rmTMP/JobSpecificFolder"" (${TMPDIR}); ```. cd ${TMPDIR}; BIN_VERSION=""1.6.1""; module load singularity/3.5.2. #####################################################################; # singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ulimit -u 10000 # https://stackoverflow.com/questions/52026652/openblas-blas-thread-init-pthread-create-resource-temporarily-unavailable/54746150#54746150. # --model_type=PACBIO \ ##Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**; # docker://google/deepvariant:""${BIN_VERSION}"" \. if ! [ -f ""${WORKINDIR}/${ALIGNMENTNAME}.deepVariant.vcf.gz"" ]; then; cp ""${THEREF}""* ./; cp ""${WORKINDIR}/${ALIGNMENTNAME}.bam""* .; chmod 666 `basename ""${THEREF}""`*; chmod 666 ""${ALIGNMENTNAME}.bam""*; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; /my/path/software/deepVariant/deepvariant_${BIN_VERSION}.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=`basename ""${THEREF}""` \; --reads=""${ALIGNMENTNAME}.bam"" \; --sample_name=${SAMPLENAME} \; --output_vcf=""./${ALIGNMENTNAME}.deepVariant.vcf.gz"" \; --output_gvcf=""./${ALIGNMENTNAME}.deepVariant.g.vcf.gz"" \; --intermediate_results_dir . \; --num_shards=8 \; --logging_dir=.; ; if ! [ -f ""./${ALIGNMENTNAME}.deepVariant.vcf.gz"" ]; then; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; /my/path/software/deepVariant/deepvariant_${BIN_VERSION}.sif \; /opt/deepvariant/bin/postprocess_variants \; --ref=`basename ""${THEREF}""` \; --infile ""./call_variants_output@$(ls ./call_variants_output*.tfrecord.gz | wc -l).tfrecord.gz"" \; --outfile ""./${ALIGNMENTNAME}.deepVariant.vcf.gz"" \; --cpus ""8"" \; --gvcf_outfile ""./${ALIGNMENTNAME}.deepVariant.g.vcf.gz"" \; --nonvariant_site_tfrecord_path ""./gvcf.tfrecord@$(ls ./gvcf.tfrecord*.gz | wc -l).gz"" \; --sample_name=${SAMPLENAME}; fi; cp *.log ${WORKINDIR}/; cp ""./${ALIGNMENTNAME}.deepVariant.vcf.gz""* ${WORKINDIR}/; else; cp ""${WORKINDIR}/${ALIGNMENTNAME}.deepVariant.vcf.gz""* .; fi. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/818#issuecomment-2106784467:2010,log,log,2010,,https://github.com/google/deepvariant/issues/818#issuecomment-2106784467,1,['log'],['log']
Testability,"rnal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:08) FAIL: //deepvariant/realigner:aligner_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log); (06:29:08) INFO: From Testing //deepvariant/realigner:aligner_test:; ==================== Test output for //deepvariant/realigner:aligner_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/aligner_test.runfiles/com_google_deepvariant/deepvariant/realigner/aligner_test.py"", line 40, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/aligner_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:14381,log,log,14381,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; (06:29:20) FAIL: //deepvariant:model_eval_test (shard 9 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log); (06:29:20) INFO: From Testing //deepvariant:model_eval_test (shard 9 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 9 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportErro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:108221,test,testlogs,108221,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"rray numpy extension module failed. Most; > likely you are trying to import a failed build of numpy.; > Here is how to proceed:; > - If you're working with a numpy git repository, try `git clean -xdf`; > (removes all files not under version control) and rebuild numpy.; > - If you are simply trying to use the numpy version that you have installed:; > your installation is broken - please reinstall numpy.; > - If you have already reinstalled and that did not fix the problem, then:; > 1. Check that you are using the Python you expect (you're using /usr/bin/python),; > and that you have no directories in your PATH or PYTHONPATH that can; > interfere with the Python and numpy versions you're trying to use.; > 2. If (1) looks fine, you can open a new issue at; > https://github.com/numpy/numpy/issues. Please include details on:; > - how you installed Python; > - how you installed numpy; > - your operating system; > - whether or not you have multiple versions of Python installed; > - if you built from source, your compiler versions and ideally a build log; > ; > Note: this error has many possible causes, so please don't comment on; > an existing issue about this - open a new one instead.; > ; > Original error was: PyCapsule_Import could not import module ""datetime""; > ; > Traceback (most recent call last):; > File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main; > ""__main__"", fname, loader, pkg_name); > File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code; > exec code in run_globals; > File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 223, in <module>; > File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 204, in Main; > File ""/usr/lib/python2.7/subprocess.py"", line 523, in call; > return Popen(*popenargs, **kwargs).wait(); > File ""/usr/lib/python2.7/subprocess.py"", line 711, in __init__; > errread, errwrite); > File ""/usr/lib/python2.7/subprocess.py"", line 1235, in _execute_child; > self.pid = os.fork(); > OSError: [Errno 11] Re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/274#issuecomment-598179709:2024,log,log,2024,,https://github.com/google/deepvariant/issues/274#issuecomment-598179709,1,['log'],['log']
Testability,"rror_message + '\nFailed to parse BAM/CRAM file. '; ValueError: Data loss: Failed to parse SAM record; Failed to parse BAM/CRAM file. This is often caused by:; (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file.; (2) Your BAM/CRAM file could be corrupted. Please check its md5.; If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues; ```. It seems like for this particular failure mode (BAM file is truncated), the default stackt race was already clear.; But given that I mentioned different level of verbosity. I tried that next. ## Use `-v` to increase verbosity level. if you run `/opt/deepvariant/bin/make_examples --helpfull` you'll see this flag:. ```; -v,--verbosity: Logging verbosity level. Messages logged at this level or; lower will be included. Set to 1 for debug logging. If the flag was not set; or supplied, the value will be changed from the default of -1 (warning) to 0; (info) after flags are parsed.; (default: '-1'); (an integer); ```; You can try to add `-v 1`. But in this case above, my run already had useful logging and didn't seem to produce more useful logs. ## What if we run with Singularity?. I think you were running with Singularity, so I tried that too. I repeated the steps in https://github.com/google/deepvariant/issues/463#issuecomment-866352316 to install Singularity. And then with the same data, I ran:. ```; # Pull the image.; BIN_VERSION=1.1.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" \; --reads ""quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam"" \; --ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:14106,log,logging,14106,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,1,['log'],['logging']
Testability,"runcated.bam with NativeSamReader; I0629 23:43:41.568112 139796154570496 make_examples.py:648] Preparing inputs; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.568638 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:43:41.569230 139796154570496 make_examples.py:648] Common contigs are ['chr20']; I0629 23:43:41.686007 139796154570496 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; 2021-06-29 23:43:41.686352: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.688519 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.688877 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:43:41.804690 139796154570496 make_examples.py:648] Writing examples to quickstart-output/sing.make_examples.tfrecord.gz; I0629 23:43:41.804903 139796154570496 make_examples.py:648] Writing gvcf records to quickstart-output/sing.gvcf.tfrecord.gz; I0629 23:43:41.805349 139796154570496 make_examples.py:648] Overhead for preparing inputs: 0 seconds; I0629 23:43:41.821153 13979615457049",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:16663,test,testdata,16663,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,1,['test'],['testdata']
Testability,"runcated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.568638 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:43:41.569230 139796154570496 make_examples.py:648] Common contigs are ['chr20']; I0629 23:43:41.686007 139796154570496 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; 2021-06-29 23:43:41.686352: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.688519 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [W::hts_idx_load3] The index file is older than the data file: quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam.bai; I0629 23:43:41.688877 139796154570496 genomics_reader.py:223] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.truncated.bam with NativeSamReader; I0629 23:43:41.804690 139796154570496 make_examples.py:648] Writing examples to quickstart-output/sing.make_examples.tfrecord.gz; I0629 23:43:41.804903 139796154570496 make_examples.py:648] Writing gvcf records to quickstart-output/sing.gvcf.tfrecord.gz; I0629 23:43:41.805349 139796154570496 make_examples.py:648] Overhead for preparing inputs: 0 seconds; I0629 23:43:41.821153 139796154570496 make_examples.py:648] 0 candidates (0 examples) [0.02s elapsed]; I0629 23:44:41.827408 139796154570496 make_examples.py:648] 102 candidates (110 examples) [60.01s elapsed]; I0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:16799,test,testdata,16799,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,1,['test'],['testdata']
Testability,"running on your own local hardware, note that the speed will be a function of how new your CPU is, the AVX acceleration used by DeepVariant runs faster on newer machines. However, your estimation of 24 hours on a 4-core machine is 96 total core-hours. This is not particularly slow for DeepVariant, in fact, it is fast. The DeepVariant WGS case study finishes in 242 core-hours, though it is probably possible to finish somewhat more efficiently on a smaller machine. However, if you are able to run GATK Best Practices in 96 CPU hours, this would be surprising based on external estimates, which place the total compute at 300-400 CPU-hours (e.g - https://www.ibm.com/downloads/cas/LY1OY9XJ). When you say you are using an identical command on Google Cloud, are you also using identical hardware?. 1b); With respect to cost, a large factor in the cost-efficiency of DeepVariant will be whether you are using pre-emptible instances on GCP, or spot instances on AWS. Can you clarify which type of instance you are using in these tests?. The 30x WGS case study, which runs for a wall-clock time of 4.5 hours on a 64-CPU standard instance class should consume 288 CPU-hours, which on a pre-emptible GCP machine should cost $0.01 per core-hour at current pricing, for $2.88. This is also not the most cost-efficient way to run DeepVariant. 2\); Your script runs `mkdir -p ${OUTPUT_DIR}`, which I believe does not work since you need sudo permission to create this directory. You will want to modify this command to ensure that `/home/cwarden/cdw-genome/Charles_Human/Genos_Exome/BWA-MEM_Alignment/Genos_BWA-MEM` exists locally prior to mounting. We also recommend updating your script to explicitly use the 0.8.0 image at ` gcr.io/deepvariant-docker/deepvariant:0.8.0`, which is now tagged as `latest`. Models are included in this image. The WES model checkpoint for this image is at `/opt/models/wes/model.ckpt`. To run the v0.8.0 container in interactive mode, you will need to modify the entrypoint as",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483448362:1898,test,tests,1898,,https://github.com/google/deepvariant/issues/171#issuecomment-483448362,1,['test'],['tests']
Testability,"runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:; Inherited 'build' options: --action_env PYTHON_BIN_PATH=/opt/conda/envs/py38/bin/python3.8 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages --python_path=/opt/conda/envs/py38/bin/python3.8; (05:40:22) INFO: Reading rc options for 'test' from /deepvariant/.bazelrc:; Inherited 'build' options: --jobs 128 --config=monolithic --show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:; 'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium; (05:40:22) INFO: Reading rc options for 'test' from /deepvariant/.bazelrc:; 'test' options: --test_output=errors; (05:40:22) INFO: Found applicable config definition build:short_logs in file /tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; (05:40:22) INFO: Found applicable config definition build:v2 in file /tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; (05:40:22) INFO: Found applicable config definition test:v2 in file /tensorflow/.tf_configure.bazelrc:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:7674,test,test,7674,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,1,['test'],['test']
Testability,"s able to build deepvariant! Tests failed, below, and I am happy to open a separate issue for this or take it somewhere else this is TensorFlow-specific. It seems that TensorFlow `r1.12` installed duing the deepvariant build is looking for CUDA 9:. ```; FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:1062,log,log,1062,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"s for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient?. If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:; 1. Run DeepTrio on trio.; 2. BCFtools to cut-out chrX + Y; 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?); 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together...; 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,; Phil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/518#issuecomment-1048108100:2643,test,test,2643,,https://github.com/google/deepvariant/issues/518#issuecomment-1048108100,1,['test'],['test']
Testability,"s like depth, read length, etc. Currently I think that might be causing the biggest variance of the runtime of make_examples. This makes it hard for me to give general estimation guidelines.; Can you give us a bit more information on your BAM? Is it WGS or WES? Which Illumina sequencing machine is it from?; If you are okay with sharing the BAM header, it'll help too. If it's easier to share via email, you can email pichuan@google.com. > 2. Any idea of how I do a better job sizing compute resources?. On the GCP DeepVariant tutorial page:; https://cloud.google.com/life-sciences/docs/tutorials/deepvariant; You can see some numbers of runtime and cost estimates on GCP. This might help give you some sense of what type of machine you can choose. Since you're running on AWS, the cost might change based on pricing. > 3. How do I know if docker is making progress or not?. Currently, our one-step script should be outputting some logs as it goes. If make_examples is still running, you should see lines of logs coming out, showing there's progress. There's likely room for improvement on how we show this progress. If you have suggestions or bug reports, please let us know. > I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good!. Sorry to hear that the logs are not coming out promptly. If it's possible, can you tell us where did the log get stuck?. > 4. I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. I haven't tried using nohub. I'll have to try and respond to this later.; > ; > thanks; > ; > An",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/260#issuecomment-573487475:1263,log,logs,1263,,https://github.com/google/deepvariant/issues/260#issuecomment-573487475,1,['log'],['logs']
Testability,"s to use as input, for helping with the separation into distinct patterns for mapping to the different classes of genotypes confidently. For example, you can see distinct patterns forming as it reaches the later stages: . ![image](https://github.com/google/deepvariant/assets/6555937/9f69f9dc-8dec-4370-aa69-e0295265e7f0). ![image](https://github.com/google/deepvariant/assets/6555937/83edefd6-8d77-4a7a-8fb3-921ec7c3cff1). Once the pattern has been achieved like the following, then one can proceed with testing each genotype's representation of the variant:. ![image](https://github.com/google/deepvariant/assets/6555937/13e95fe0-71b1-40aa-bccc-4d8c5463de6f). We want to see for which genotype the set of patterns (the feature map above) maximizes for, which will indicate the genotype present with a specific maximal probability. First we test for $`homozygous`$ $`reference`$:. ![image](https://github.com/google/deepvariant/assets/6555937/be5e3074-4c2f-4600-9ea3-9cb6bfda58f8). Next we test for $`heterozygous`$:. ![image](https://github.com/google/deepvariant/assets/6555937/1e43b84e-17ae-40ea-8c82-b7e87d0cf3d6). Finally we test for $`homozygous`$ $`alternate`$:. ![image](https://github.com/google/deepvariant/assets/6555937/cedce40f-4fc0-45fe-843b-e2652b31c0af). Now we can see there is a significant correlation with a heterozygous variant call. So to call a variant site's genotype you now have the power to traverse the whole neural network -- through a set of transformations (you can tweak) to identify hidden patterns in the data -- as it is all linked from the start (read encoding) to finish (genotype identification). This ability is enabled through the preservation of the propagation of information (which is deeply and directly linked) in order to help one optimize upon. That's why you don't want to throw anything away, as @AndrewCarroll and @pichuan mentioned as it helps you inspect and tweak the selection power and criteria as it is all interconnected. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1612282088:4777,test,test,4777,,https://github.com/google/deepvariant/issues/666#issuecomment-1612282088,2,['test'],['test']
Testability,"s.; fetch Fetches external repositories that are prerequisites to the targets.; help Prints help for commands, or the index.; info Displays runtime info about the bazel server.; license Prints the license of this software.; mobile-install Installs targets to mobile devices.; print_action Prints the command line args for compiling a file.; query Executes a dependency graph query.; run Runs the specified target.; shutdown Stops the bazel server.; sync Syncs all repositories specified in the workspace file; test Builds and runs the specified test targets.; version Prints version information for bazel. Getting more help:; bazel help <command>; Prints help and options for <command>.; bazel help startup_options; Options for the JVM hosting bazel.; bazel help target-syntax; Explains the syntax for specifying targets.; bazel help info-keys; Displays a list of keys used by the info command.; + [[ 1 = \1 ]]; + bazel test -c opt --local_test_jobs=1 --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11 deepvariant/...; (05:40:22) INFO: Options provided by the client:; Inherited 'common' options: --isatty=1 --terminal_columns=166; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.bazelrc:; Inherited 'common' options: --experimental_repo_remote_exec; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.bazelrc:; Inherited 'build' options: --define framework_shared_object=true --define tsl_protobuf_header_only=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false --deleted_packages=tensorflow/comp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:4872,test,test,4872,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,1,['test'],['test']
Testability,"s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads; error_message + '\nFailed to parse BAM/CRAM file. '; ValueError: Data loss: Failed to parse SAM record; Failed to parse BAM/CRAM file. This is often caused by:; (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file.; (2) Your BAM/CRAM file could be corrupted. Please check its md5.; If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues; ```. It seems like for this particular failure mode (BAM file is truncated), the default stackt race was already clear.; But given that I mentioned different level of verbosity. I tried that next. ## Use `-v` to increase verbosity level. if you run `/opt/deepvariant/bin/make_examples --helpfull` you'll see this flag:. ```; -v,--verbosity: Logging verbosity level. Messages logged at this level or; lower will be included. Set to 1 for debug logging. If the flag was not set; or supplied, the value will be changed from the default of -1 (warning) to 0; (info) after flags are parsed.; (default: '-1'); (an integer); ```; You can try to add `-v 1`. But in this case above, my run already had useful logging and didn't seem to produce more useful logs. ## What if we run with Singularity?. I think you were running with Singularity, so I tried that too. I repeated the steps in https://github.com/google/deepvariant/issues/463#issuecomment-866352316 to install Singularity. And then with the same data, I ran:. ```; # Pull the image.; BIN_VERSION=1.1.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode calling \; --ref ""quickstart-testdata/ucsc.hg19.chr20.un",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:14004,Log,Logging,14004,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,1,['Log'],['Logging']
Testability,"se the r1.5 one (the doc is mostly the same , but I'll remember to use the 1.5 code): https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-build-test.md. To get a machine, I used a command here: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-details.md#command-for-a-cpu-only-machine-on-google-cloud-platform. ```bash; gcloud compute instances create ""${USER}-cpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-64"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. I sshed into the machine. ```bash; gcloud compute ssh pichuan-cpu --zone us-west1-b; ```. Then, on the machine, I get DeepVariant r1.5 source first:. ```bash; git clone https://github.com/google/deepvariant.git; cd deepvariant/; git checkout r1.5; ```. And I confirmed the version:. ```; pichuan@pichuan-cpu:~/deepvariant$ git log | head; commit ab068c4588a02e2167051bd9e74c0c9579462b51; Author: pichuan <pichuan@google.com>; Date: Mon Feb 27 23:03:48 2023 -0800. Update README.md; ; PiperOrigin-RevId: 512838102. ```. From there, I followed the instructions on https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-build-test.md; So I ran:. ```bash; sudo su; ./build-prereq.sh; ```. My run succeeded. I looked at my log to see the section close to where your error occurred. And I see:. ```; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785:1216,log,log,1216,,https://github.com/google/deepvariant/issues/739#issuecomment-1823278785,1,['log'],['log']
Testability,"sg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:08) [2,482 / 2,523] 16 / 38 tests, 2 failed; Testing //deepvariant:call_variants_test; 0s local ... (41 actions, 1 running); (06:29:09) FAIL: //deepvariant:call_variants_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log); (06:29:09) INFO: From Testing //deepvariant:call_variants_test:; ==================== Test output for //deepvariant:call_variants_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_test.runfiles/com_google_deepvariant/deepvariant/call_variants_test.py"", line 48, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-pack",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:16653,test,tests,16653,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,"['Test', 'test']","['Testing', 'tests']"
Testability,"sg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) [2,488 / 2,523] 19 / 38 tests, 5 failed; Testing //deepvariant:data_providers_test; 0s local ... (35 actions, 2 running); (06:29:10) FAIL: //deepvariant:data_providers_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log); (06:29:10) INFO: From Testing //deepvariant:data_providers_test:; ==================== Test output for //deepvariant:data_providers_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/data_providers_test.runfiles/com_google_deepvariant/deepvariant/data_providers_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/sit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:30383,test,tests,30383,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,"['Test', 'test']","['Testing', 'tests']"
Testability,"shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/customized_classes.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_gvcf_output.g.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.vcf_candidate_importer.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00001-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_single_site_output.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/HG002_ONT_deeptrio.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/golden.vcf_candidate_importer.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/alt_aligned_pileup.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 199, 8], ""channels"": [1, 2, 3, 4, 5, 6, 9, 10]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040:3237,test,testdata,3237,,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040,1,['test'],['testdata']
Testability,"show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:; 'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium; (05:40:22) INFO: Reading rc options for 'test' from /deepvariant/.bazelrc:; 'test' options: --test_output=errors; (05:40:22) INFO: Found applicable config definition build:short_logs in file /tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; (05:40:22) INFO: Found applicable config definition build:v2 in file /tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; (05:40:22) INFO: Found applicable config definition test:v2 in file /tensorflow/.tf_configure.bazelrc: --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only; (05:40:22) INFO: Found applicable config definition build:monolithic in file /tensorflow/.bazelrc: --define framework_shared_object=false --define tsl_protobuf_header_only=false --experimental_link_static_libraries_once=false; (05:40:22) INFO: Found applicable config definition build:linux in file /tensorflow/.bazelrc: --host_copt=-w --copt=-Wno-all --copt=-Wno-extra --copt=-Wno-deprecated --copt=-Wno-deprecated-declarations --copt=-Wno-ignored-attributes --copt=-Wno-unknown-warning --copt=-Wno-array-parameter --copt=-Wno-stringop-overflow --copt=-Wno-array-bounds --copt=-Wunused-result --copt=-Werror=unused-result --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; (05:40:22) INFO: Found applicable config definition build:dyna",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:8686,benchmark,benchmark-test,8686,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,2,['benchmark'],['benchmark-test']
Testability,"sk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. # ssh into the machine, and get the latest DeepVariant repo. Then, I ssh into the machine:. ```bash; gcloud compute ssh ${USER}-cpu --zone us-west1-b; ```. Then I get the repo:. ```bash; git clone https://github.com/google/deepvariant.git; cd deepvariant; ```. Following in the instructions in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md. I first run:. ```bash; sudo su; ```. and then:. ```bash; ./build-prereq.sh; ```. This step does a lot of stuff, including checking out other repos such as clif and tensorflow, and using that as part of the build environment. On my machine that I tested with just now, it took me 10m56.021s. and then run:. ```bash; ./build_and_test.sh; ```. This step took about 7min on my machine. . The [build_and_test.sh](https://github.com/google/deepvariant/blob/r1.6/build_and_test.sh) script is one that I recommend you actually read. The last line gave you an example of how you'd run `call_variants`. Something like:. ```bash; python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help; ```; should work. ---. # Further development and debugging. And, from here, if you want to continue to iterate, modify code and re-build. . You can try:. ```bash; source settings.sh; ```. This should allow you to use `bazel` in your terminal. At this point if you run `bazel --help` you should see the usage. If you make any changes, you can run:. ```bash; bazel build -c opt ${DV_COPT_FLAGS} deepvariant/...; ```. to re-build all binaries. (And can use `bazel test` to run unit tests). If you're specially looking into just one build target, you can also run something like:. ```bash; bazel build -c opt ${DV_COPT_FLAGS} deepvariant/call_variants; ```. And, if you want to run the built binary, in addition to the one of using python to run, you can also directly run something like. ```bash; bazel-bin/deepvariant/call_variants --help; ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872:2664,test,test,2664,,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872,2,['test'],"['test', 'tests']"
Testability,"sorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:17) FAIL: //deepvariant:variant_caller_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log); (06:29:17) INFO: From Testing //deepvariant:variant_caller_test:; ==================== Test output for //deepvariant:variant_caller_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/variant_caller_test.runfiles/com_google_deepvariant/deepvariant/variant_caller_test.py"", line 43, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/variant_caller_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:74978,test,testlogs,74978,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"">Reasons for No Call</h3><p style=""color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"">All entries in the GLnexus pVCF include a Reason for No Call (RNC) field, which is filled in if either GT entry is not called (.). The possible values of RNC include:</p>. Code | Reason | Explanation; -- | -- | --; . | N/A | corresponding allele is called; M | Missing data | input (gVCF) had no data at this genome position; P | Partial data | input only partially covered this genome position; D | Depth | read depth too low to call; – | deletion | sample carries a deletion allele that couldn't be unified into this site; there may be more information in overlapping monoallelic site(s).; L | Lost allele | ^ but other than deletion allele; U | Unphased variants | sample carries multiple non-overlapping variants at this position*, whose phase is not known, so the diploid genotype cannot be called safely. There may be more information in overlapping monoallelic site(s).; O | Overlapping variants | sample carries multiple overlapping variants at this position, so the diploid genotype cannot be called safely. (GLnexus does deal with several common, but not all, cases of overlapping variants output by gVCF callers.) There may be more information in overlapping monoallelic site(s).; 1 | monoallelic | this is a monoallelic site; no assertion about presence/absence of any allele here. <!--EndFragment-->; </body>; </html>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/494#issuecomment-1018260954:3931,assert,assertion,3931,,https://github.com/google/deepvariant/issues/494#issuecomment-1018260954,1,['assert'],['assertion']
Testability,"ss.** But, I'm able to see the same issue, if I start my command in a directory where I can't write to. I have two questions for you:; (1) When you run the command, do you have write permission to the directory you're in? (Based on the current code, that's where the converted model files are written to.); (2) What is your Singularity version?. I listed all my steps below in case it's useful. ---. # Worklog. ## Get a Ubuntu16.04 machine; I used the [command here](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-details.md#command-for-a-cpu-only-machine-on-google-cloud-platform) to get a Ubuntu16.04 machine. ## Set up on the machine; After ssh into the machine, before start running the [PacBio tutorial](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md), I'll install things first:. ```; curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh; bash Miniconda3-latest-Linux-x86_64.sh; ```; After installing conda, I logged out and re-logged in. I install Singularity:; ```; curl -O https://raw.githubusercontent.com/google/deepvariant/r1.1/scripts/install_singularity.sh; bash install_singularity.sh; ```. Here is my Singularity version:; ```; (base) pichuan@pichuan-cpu:~$ singularity --version; singularity version 3.3.0-1; ```. ## Run through PacBio tutorial; I follow the steps here:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md; and ran through all commands set up conda, and download all files. When I get to this step:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md#run-deepvariant-on-chromosome-20-alignments. I added `--call_variants_extra_args ""use_openvino=true""`. So my command is:; ```; ulimit -u 10000 # https://stackoverflow.com/questions/52026652/openblas-blas-thread-init-pthread-create-resource-temporarily-unavailable/54746150#54746150; BIN_VERSION=""1.1.0""; mkdir -p deepvariant1. singularity exec --",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-761309014:1276,log,logged,1276,,https://github.com/google/deepvariant/issues/404#issuecomment-761309014,2,['log'],['logged']
Testability,"st probability for the position was as non-variant. Some of the reasons that DeepVariant may suspect a false positive are: strand-bias in reads, low mapping quality in reads, low base quality in reads, and overall low coverage.""; So,is it possible for different RNC to correspond to the above reasons(strand-bias in reads, low mapping quality in reads, low base quality in reads, and overall low coverage)?; When I met './.' ,I have reason to believe that it is 0/0 with greater probability than 0/1.; However,when the ""RNC"" is II,it means""gVCF input site is non-called"",for example: ./.:137:2,129:5:0,13,4:II ./.:137:86,50:6:0,4,39:II.; In this situation,why doesn't DeepVariant call the mutation(DP=137,alt reads=50)?. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">; https://github-wiki-see.page/m/dnanexus-rnd/GLnexus/wiki/Reading-GLnexus-pVCFs; One of GLnexus' main functions is to generate a population-wide ""project"" VCF (pVCF) based on the input gVCFs for each individual sample. ; <html>; <body>; <!--StartFragment--><h3 style=""color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"">Reasons for No Call</h3><p style=""color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium; font-style: normal; fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/494#issuecomment-1018260954:1461,assert,assertion,1461,,https://github.com/google/deepvariant/issues/494#issuecomment-1018260954,1,['assert'],['assertion']
Testability,"st-packages --python_path=/opt/conda/envs/py38/bin/python3.8; (05:40:22) INFO: Reading rc options for 'test' from /deepvariant/.bazelrc:; Inherited 'build' options: --jobs 128 --config=monolithic --show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:; 'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium; (05:40:22) INFO: Reading rc options for 'test' from /deepvariant/.bazelrc:; 'test' options: --test_output=errors; (05:40:22) INFO: Found applicable config definition build:short_logs in file /tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; (05:40:22) INFO: Found applicable config definition build:v2 in file /tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; (05:40:22) INFO: Found applicable config definition test:v2 in file /tensorflow/.tf_configure.bazelrc: --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only; (05:40:22) INFO: Found applicable config definition build:monolithic in file /tensorflow/.bazelrc: --define framework_shared_object=false --define tsl_protobuf_header_only=false --experimental_link_static_libraries_once=false; (05:40:22) INFO: Found applicable config definition build:linux in file /tensorflow/.bazelrc: --host_copt=-w --copt=-Wno-all --copt=-Wno-extra --copt=-Wno-deprecated --copt=-Wno-deprecated-declarations --copt=-Wno-ignored-attributes --copt=-Wno-unknown-warning --copt=-Wno-array-parameter --copt=-Wno-stringop-overflow --copt=-Wno-array-bounds --copt=-Wunused-result --copt=-Werror=unused-result --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:8615,test,test,8615,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,1,['test'],['test']
Testability,"t (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log); (06:29:17) INFO: From Testing //deepvariant/realigner/allele_count_linear:model_evaluation_test:; ==================== Test output for //deepvariant/realigner/allele_count_linear:model_evaluation_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/realigner/allele_count_linear/model_evaluation_test.py"", line 41, in <module>; from deepvariant import testdata; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/testdata.py"", line 39, in <module>; from third_party.nucleus.testing import test_utils as nucleus_test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:78345,test,testdata,78345,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['test'],['testdata']
Testability,"t *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================. FAILED: //deepvariant:make_examples_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; (06:29:20) FAIL: //deepvariant:make_examples_test (shard 1 of 2) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log); (06:29:20) INFO: From Testing //deepvariant:make_examples_test (shard 1 of 2):; ==================== Test output for //deepvariant:make_examples_test (shard 1 of 2):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/deepvariant/make_examples_test.py"", line 48, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:100298,log,log,100298,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"t and log file. code is running but neither output generating or error throwing just running.; please see below code and log file. ###### code #############; #!/usr/bin/env nextflow. nextflow.enable.dsl=2; params.outdir = '/home/deepak/integration/resu1'; params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'; params.refhg38 = '/home/deepak/integration/hg381_22XYM'; params.bed = '/home/deepak/integration'. workflow {; // Define channels for input data; Channel; .fromPath(""${params.data_dir}/*_sorted_md.bam""); .map { file -> ; def sample_id = file.baseName.replace('_sorted_md', ''); return [sample_id, file]; }; .set { read_pairs }; /// Step 1. DeepVariant; DeepVariant(read_pairs, params.refhg38, params.bed); }. process DeepVariant {; tag ""deepavar on ${sample_id}""; publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'; cpus 4; //BIN_VERSION 1.6.1. input:; tuple val(sample_id), path(read_files); val(params.refhg38); val(params.bed); ; output:; //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs; tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:; """"""; docker run \; -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \; google/deepvariant:latest \; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \; --reads /opt/bam/${read_files} \; --regions /opt/bed/hg38_exomeY.bed \; --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \; --num_shards ${task.cpus}; """"""; }. ######## code ################. terminal:; (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1); [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached; [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/883#issuecomment-2352056013:1984,log,log,1984,,https://github.com/google/deepvariant/issues/883#issuecomment-2352056013,3,['log'],['log']
Testability,"t/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; //deepvariant:model_train_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_6_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:125695,log,log,125695,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"t/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:122603,log,log,122603,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,t/data_providers_test/test.log; //deepvariant:haplotypes_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log; //deepvariant/labeler:haplotype_labeler_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/haplotype_labeler_test/test.log; //deepvariant/labeler:labeled_examples_to_vcf_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/labeled_e,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:119417,test,testlogs,119417,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"t/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; (05:40:51) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (05:40:51) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 6 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:1702,test,testlogs,1702,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,t/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; (05:40:51) FAIL: //deepvariant:model_eval_test (shard 6 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log); (05:40:51) INFO: From Testing //deepvariant:model_eval_test (shard 6 of 10):; ==================== Test output for //deepvariant:model_eval_test (sh,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:1528,test,testlogs,1528,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"t/tpu,tensorflow/core/tfrt/utils; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:; Inherited 'build' options: --action_env PYTHON_BIN_PATH=/opt/conda/envs/py38/bin/python3.8 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages --python_path=/opt/conda/envs/py38/bin/python3.8; (05:40:22) INFO: Reading rc options for 'test' from /deepvariant/.bazelrc:; Inherited 'build' options: --jobs 128 --config=monolithic --show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; (05:40:22) INFO: Reading rc options for 'test' from /tensorflow/.tf_configure.bazelrc:; 'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium; (05:40:22) INFO: Reading rc options for 'test' from /deepvariant/.bazelrc:; 'test' options: --test_output=errors; (05:40:22) INFO: Found applicable config definition build:short_logs in file /tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; (05:40:22) INFO: Found applicable config definition build:v2 in file /tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; (05:40:22) INFO: Found applicable config definition test:v2 in file /tensorflow/.tf_configure.bazelrc: --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only; (05:40:22) INFO: Found applicable config definition build:monolithic in file /tensorflow/.bazelrc: --define framework_shared_object=false --define tsl_protobuf_header_only=false --experimental_link_static_libraries_once=false; (05:40:22) INFO: Found applicable config definition build:linux in file /tensorflow/.bazelrc: --host_copt=-w --copt=-Wno-all --copt=-Wno-extra --copt=-Wno-deprecated --copt=-Wno-deprecated-declarations --copt=-Wno-ignored-attributes --copt=-Wno-unknown-warning --copt=-Wno-array-para",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245:8244,test,test,8244,,https://github.com/google/deepvariant/issues/753#issuecomment-1857120245,1,['test'],['test']
Testability,"tch all tags; git fetch --all --tags --prune; # check out tag; git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True; vim ./third_party/clif.bzl. # Build and test; export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH; export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages; export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python; export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages; export BAZEL_PYTHON=/home/qilibj/inst/bin/python; export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11""; # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled; # fix ""ImportError: No module named google.protobuf"" by install protobuf from source; bazel clean; bazel shutdown; bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \; --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \; --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \; --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \; --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \; --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &; bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only; bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary; bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; echo 'Expect a usage message:'; (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:18723,test,test,18723,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,1,['test'],['test']
Testability,"te-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================. FAILED: //deepvariant:make_examples_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; (06:29:20) FAIL: //deepvariant:make_examples_test (shard 1 of 2) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log); (06:29:20) INFO: From Testing //deepvariant:make_examples_test (shard 1 of 2):; ==================== Test output for //deepvariant:make_examples_test (shard 1 of 2):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/deepvariant/make_examples_test.py"", line 48, in <module>; from third_party.nucleus.io import vcf; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_test.runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 69, in <module>; from third_party.nucleus.io import genomics_reader; File ""/roo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:100474,log,log,100474,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"te-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:08) [2,482 / 2,523] 16 / 38 tests, 2 failed; Testing //deepvariant:call_variants_test; 0s local ... (41 actions, 1 running); (06:29:09) FAIL: //deepvariant:call_variants_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log); (06:29:09) INFO: From Testing //deepvariant:call_variants_test:; ==================== Test output for //deepvariant:call_variants_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_test.runfiles/com_google_deepvariant/deepvariant/call_variants_test.py"", line 48, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Trace",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:16918,test,testlogs,16918,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:19) FAIL: //deepvariant:pileup_image_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log); (06:29:19) INFO: From Testing //deepvariant:pileup_image_test:; ==================== Test output for //deepvariant:pileup_image_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/pileup_image_test.runfiles/com_google_deepvariant/deepvariant/pileup_image_test.py"", line 43, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/pileup_image_test.runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 60, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; Fi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:92575,test,testlogs,92575,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:19) FAIL: //deepvariant:pileup_image_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log); (06:29:19) INFO: From Testing //deepvariant:pileup_image_test:; ==================== Test output for //deepvariant:pileup_image_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/pileup_image_test.runfiles/com_google_deepvariant/deepvariant/pileup_image_test.py"", line 43, in <module>; from third_party.nucleus.io import fasta; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/pileup_image_test.runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 60, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:92619,log,log,92619,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"ternal PRs, but this is not because we do not accept community additions. The ""source of truth"" for the DeepVariant GitHub repo resides in internal systems, which are then copied onto GitHub. As a result, to incorporate your changes, we will need to change the internal code and copy that back out. We have done this in the past with community additions, and have attributed the authors for contributions in release notes and other forums. I don't see any issues with that. The only thing which is important is to add the changes as a single commit separately from other changes so it can be properly tracked in git history. > Can you help me understand the expected benefit of the changes? It looks like this should improve runtime for call_variants. Do you have any high-level information from benchmark runs for us to understand the percentage improvement to expect. You're right - this PR about efficiency of deep learning part only (call_variants). We need some time to collect some benchmark numbers and check what's is OK to share publicly. Probably, extra optimizations could be applied. > If we are to incorporate these changes, we would want to make sure this would perform well across various hardware. For example, we would want our Docker images to gracefully fallback to working code if it is on a machine with incompatible hardware. Do you expect OpenVINO to have this property (for example, if someone is running on an AMD machine). Proposed changes are very smooth - by default, OpenVINO is not used. We can test other Intel hardware such iGPU and HDDL-R. For non-Intel HW users can always use default implementation. > We will also have to think about how these changes interact with any updates we would make to our use of TensorFlow. We're not directly planning anything in the near future, but it's good for us to consider. I think it won't be an issue. It make sense to isolate some OpenVINO related logic to separate Python script to reduce conflicts during development. Additi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-709941019:1072,benchmark,benchmark,1072,,https://github.com/google/deepvariant/pull/363#issuecomment-709941019,1,['benchmark'],['benchmark']
Testability,test (cached) PASSED in 0.5s; //deepvariant:dv_vcf_constants_test (cached) PASSED in 1.7s; //deepvariant:exclude_contigs_test (cached) PASSED in 0.9s; //deepvariant:postprocess_variants_lib_test (cached) PASSED in 0.1s; //deepvariant:resources_test (cached) PASSED in 1.7s; //deepvariant:utils_test (cached) PASSED in 0.5s; //deepvariant:variant_calling_test (cached) PASSED in 0.6s; //deepvariant/environment_tests:env_smoke_test (cached) PASSED in 0.7s; //deepvariant/environment_tests:protobuf_implementation_test (cached) PASSED in 1.2s; //deepvariant/realigner:fast_pass_aligner_test (cached) PASSED in 0.6s; //deepvariant/realigner:ssw_test (cached) PASSED in 0.5s; //deepvariant/realigner/python:ssw_misc_test (cached) PASSED in 0.9s; //deepvariant/realigner/python:ssw_wrap_test (cached) PASSED in 1.2s; //deepvariant/vendor:timer_test (cached) PASSED in 0.7s; //deepvariant:call_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log; //deepvariant:data_providers_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log; //deepvariant:haplotypes_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/c,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:118152,test,testlogs,118152,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,test 2,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/426#issuecomment-782298000:0,test,test,0,,https://github.com/google/deepvariant/issues/426#issuecomment-782298000,1,['test'],['test']
Testability,"test; # use lscpu to show the actual CPU number; ################################################################################; python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160; python -c ""import psutil;print(p/sutil.cpu_count; ())"" #160. vim deepvariant/resources.py; --------------------------------; def _get_cpu_count():; """"""Gets the number of physical cores in this machine.; Returns:; int >= 1 if the call to get the cpu_count succeeded, or 0 if not.; """"""; # return psutil.cpu_count(logical=False) or 0 ==> comment; return 20; --------------------------------. vim deepvariant/resources_test.py; --------------------------------; def test_metrics_is_ok_when_cpu_count_returns_none(self):; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):; with resources.ResourceMonitor() as monitor:; #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment; self.assertEqual(monitor.metrics().physical_core_count, 20); --------------------------------. ##########################################################################; # //deepvariant/realigner/allele_count_linear:generate_trained_model_test; # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8; ##########################################################################; # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python; python -c ""import numpy"" # prequests of TF 1.12.0; python -c ""import scipy"" # prequests of TF 1.12.0; pip install Cython --force-reinstall --no-deos; pip install scikit-learn --force-reinstall --no-deos; # build from source; wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz; tar zxvf 0.20.2.tar.gz; cd scikit-learn-0.20.2; python setup.py bdist_wheel; # verify; python -c ""from skle",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:21004,assert,assertEqual,21004,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,1,['assert'],['assertEqual']
Testability,"tet/ref_based_analysis/aligned_reads/ChineseQuartet/LCL5/ChineseQuartet.LCL5.GRCh38.HiFi.minimap2.bam"",; output:; bam=dir_work + ""bams/ChineseQuartet.{region}.bam"",; bed=dir_work + ""bams/ChineseQuartet.{region}.bed"",; run:; chrom, start, end = f""{wildcards.region}"".split(""_""); start = int(start) - 1000; end = int(end) + 1000; shell(""{samtools} view -h -O BAM {input.bam} {chrom}:{start}-{end} > {output.bam}""); shell(""echo '{chrom}\t{start}\t{end}' > {output.bed}""). rule deepvariant:; input:; bam=dir_work + ""bams/ChineseQuartet.{region}.bam"",; bai=dir_work + ""bams/ChineseQuartet.{region}.bam.bai"",; bed=dir_work + ""bams/ChineseQuartet.{region}.bed"",; ref=path_ref; output:; vcf_gz=dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.vcf.gz"",; gvcf_gz=dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.g.vcf.gz""; # gvcf_gz=config[""dir_variants""] + ""dv/dv_details/{sample}/{sample}.{prefix}.dv.raw.g.vcf.gz""; log:; dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.log""; benchmark:; dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.log""; threads: 48; run:; dir_tmp = str(output.vcf_gz).rstrip("".vcf.gz"") + ""_tmp""; file_tmp = dir_tmp.split(""/"")[-1]; shell(""mkdir -p "" + dir_tmp); bam_dir = ""/"".join(str(input.bam).split(""/"")[:-1]); bam_file = str(input.bam).split(""/"")[-1]; bed_file = str(input.bed).split(""/"")[-1]; ref_dir = ""/"".join(str(input.ref).split(""/"")[:-1]); ref_file = str(input.ref).split(""/"")[-1]; output_dir = ""/"".join(str(output.vcf_gz).split(""/"")[:-1]); output_file = str(output.vcf_gz).split(""/"")[-1].rstrip("".vcf.gz""). shell('docker run '; '-v ""{bam_dir}"":""/input"" '; '-v ""{ref_dir}"":""/ref"" '; '-v ""{output_dir}"":""/output"" '; 'google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant '; '--model_type=PACBIO '; '--ref=/ref/{ref_file} '; '--reads=/input/{bam_file} '; '--regions /input/{bed_file} '; '--output_vcf=/output/{output_file}.vcf '; '--output_gvcf=/output/{output_file}.g.vcf '; '--num_shards={threads} '; '--make_examples_extra_args min_mapping_quality=1,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/660#issuecomment-1589724792:2331,log,log,2331,,https://github.com/google/deepvariant/issues/660#issuecomment-1589724792,2,"['benchmark', 'log']","['benchmark', 'log']"
Testability,"thank you very much for your help!; I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file.; I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file.; And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```; python bin/make_examples.zip \; --mode training \; --ref ""project-retraining/testdata/sequence.fasta"" \; --reads ""project-retraining/testdata/aligned_reads.bam"" \; --examples ""project-retraining/training_examples"" \; --confident_regions ""project-retraining/testdata/variants.bed"" \; --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1; ```. and I get the same ValueError as before (from `make_examples.log` file):. ```; 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs; 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'; [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String; [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'; [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-448201709:1370,log,log,1370,,https://github.com/google/deepvariant/issues/128#issuecomment-448201709,1,['log'],['log']
Testability,"thank you, it the same, but don't know what must have gone wrong. i used a different data it ran but gave a different error again, please can you help analyze this for me? . WARNING: Logging before flag parsing goes to stderr.; I1024 02:24:26.300854 140364017985280 client.py:1004] Timeout attempting to reach GCE metadata service.; W1024 02:24:26.301438 140364017985280 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib; [W::hts_idx_load2] The index file is older than the data file: /TCGA-AF-6136-01A.add_rg.bam.bai; I1024 02:24:26.349014 140364017985280 make_examples.py:911] Preparing inputs; [W::hts_idx_load2] The index file is older than the data file: /TCGA-AF-6136-01A.add_rg.bam.bai; [W::hts_idx_load2] The index file is older than the data file: /performance-testdata%2FHG002_GIAB_highconf_IllFB-IllGATKHC-CG-Ion-Solid_CHROM1-22_v3.2.2_highconf.vcf.gz.tbi; [W::hts_idx_load2] The index file is older than the data file: /performance-testdata%2FHG002_GIAB_highconf_IllFB-IllGATKHC-CG-Ion-Solid_CHROM1-22_v3.2.2_highconf.vcf.gz.tbi; Traceback (most recent call last):;   File ""/tmp/Bazel.runfiles_CqnGJt/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>;     tf.app.run();   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run;     _sys.exit(main(_sys.argv[:1] + flags_passthrough));   File ""/tmp/Bazel.runfiles_CqnGJt/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main;     make_examples_runner(options);   File ""/tmp/Bazel.runfiles_CqnGJt/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner;     regions = processing_regions_from_options(options);   File ""/tmp/Bazel.runfiles_CqnGJt/runfiles/genomics/deepvariant/make_examples.py"", line 892, in processing_regions_from_options;     options.min_shared_contigs_basepairs);   File ""/tmp/Bazel.runfiles_CqnGJt/runfiles/genomics/deepvariant/make_examples.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/111#issuecomment-432491512:183,Log,Logging,183,,https://github.com/google/deepvariant/issues/111#issuecomment-432491512,2,"['Log', 'test']","['Logging', 'testdata']"
Testability,"thanks Pi-Chuan, decided to start building from your image with Ubuntu 20.04 to make sure that works before using the Databricks Runtime with Ubuntu 20.04, and got. 18 0.288 ========== [Tue Aug 10 21:03:43 UTC 2021] Stage 'Install bazel' starting; 18 0.297 ./build-prereq.sh: line 50: bazel: command not found; 18 0.298 ~/bazel /opt/deepvariant; 18 0.298 ./build-prereq.sh: line 56: curl: command not found; ------; executor failed running [/bin/sh -c ./build-prereq.sh]: exit code: 127. Assume there's a simple fix to add bazel and curl in, but I have had no time to test further since then, plan to get back on this next month",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/476#issuecomment-902138384:568,test,test,568,,https://github.com/google/deepvariant/issues/476#issuecomment-902138384,1,['test'],['test']
Testability,"thanks for your responses. command line：; docker run \; -v /sfs-grand-med-research/:/sfs-grand-med-research/ \; swr.cn-north-1.myhuaweicloud.com/grand-med-clinical/deepvariant:""1.0.0"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=human_g1k_v37.main_chrom.fasta \; --reads=202022.hg19.pbmm2.sort.MT.bam \; --output_vcf=202022.MT.vcf.gz \; --num_shards=16 \; --intermediate_results_dir=/tmp/. logfile：; [hg19_MT_deepvariant.log](https://github.com/google/deepvariant/files/5436542/hg19_MT_deepvariant.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/366#issuecomment-716272982:417,log,logfile,417,,https://github.com/google/deepvariant/issues/366#issuecomment-716272982,3,['log'],"['log', 'logfile']"
Testability,"that model. That is why you want to shuffle across all your samples. The `make_examples` script only takes one BAM file via the `--reads` parameter, and you don't need to merge multiple BAM files into one, as the shuffling happens afterwards on the generated TFRecords. So the process is roughly as follows: ; 1) Run `make_examples` on training set BAMs, and run `make_examples` on validation set BAMs -- both of which will generate TFRecords.; 2) Shuffle TFRecords for training set, then shuffle the ones for validation set separately.; 3) Run `model_train` on shuffled training set shuffled data.; 4) Run `model_eval` on shuffled validation set data to evaluate generated checkpoints, which will generate `best_checkpoint.txt` and `best_checkpoint.metrics` files.; 5) Pick best model listed in the `best_checkpoint.txt` file.; 6) Test the best model with `run_deepvariant` by providing it to the `--customized_model` parameter, and for the `--reads` parameter setting it with the test data BAM file. ; 7) Benchmark by comparing your VCF with your Truth set VCF via [`hap.py`](https://github.com/Illumina/hap.py), and check the metrics against a baseline appropriate to your study.; 8) Then if you want, you could train/retrain a (new or previous) model by tuning the [modeling parameters](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md#parameters-to-tune) and/or updating the training data - i.e. if you want to make it more flexible to capture more variety in the input data - both of which might improve the model under different conditions. As Maria [mentioned previously](https://github.com/google/deepvariant/issues/698#issuecomment-1681392580), training is done on chromosome 1-19, then evaluation on 21-22, with a test on 20. Usually all training is done on some data, then evaluated on another for picking the best model, and finally the best model would be tested with the test data. Let me know if I should expand on anything. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1711096081:1555,Benchmark,Benchmark,1555,,https://github.com/google/deepvariant/issues/706#issuecomment-1711096081,4,"['Benchmark', 'test']","['Benchmark', 'test', 'tested']"
Testability,"the path forwards a lot clearer. Reading between the lines, is (3) the reason we are advised to shuffle the validation data as well, because it combines all the chr20-22 examples into one dataset?. And, I forgot to reply this part - for validation set, running the shuffling step is mainly for combing the examples into one dataset (and create a text file that describe it). Another reason is - if you specify `max_examples` in model_eval, it just might be safer to have the examples already pre-shuffled:; https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/model_eval.py#L118. ---. One more thing to clarify:; Unfortunately I might be using terminology that are a bit confusing in the doc:. In https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md , ; our **training** set are the labeled examples that our classifier actually learns from. ; This is the same as defined in: https://developers.google.com/machine-learning/glossary/#training_set. **Validation** set is the labeled examples that our classifier never directly learns from, but is used to pick a best model checkpoint. ; This is the same as defined in: https://developers.google.com/machine-learning/glossary/#validation_set; When I wrote our training case study, I tried to not use another term ""**tuning** set"", which is the same thing as ""validation set"". But now I read it again, I think I did accidentally use the term ""tuning set"" at least once. I'll update that in a future release.; Just to clarify again: When I use the term ""tuning set"", I'm referring to the same thing as validation set. There is also **test** set, defined here: https://developers.google.com/machine-learning/glossary/#test_set; When doing machine learning, the best practice is to leave the **test** set alone as much as possible, and NOT to make any decisions (on model picking, paramater tuning) on it at all. Which is why we had a validation set held out in the first place.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/312#issuecomment-638566733:1687,test,test,1687,,https://github.com/google/deepvariant/issues/312#issuecomment-638566733,2,['test'],['test']
Testability,"these sets of transformations. An interesting thing then begins to emerge as you move up the layers of transformation. For example, early on in the neural network's set of transformations you will see patterns like this:. ![image](https://github.com/google/deepvariant/assets/6555937/bc3cff8b-efa8-4029-abbe-75ad06973d24). You might notice an explosion of features, with no specific patterns. These early steps are to generate a large variety of features to be able to have selection power for the later layers to use as input, for helping with the separation into distinct patterns for mapping to the different classes of genotypes confidently. For example, you can see distinct patterns forming as it reaches the later stages: . ![image](https://github.com/google/deepvariant/assets/6555937/9f69f9dc-8dec-4370-aa69-e0295265e7f0). ![image](https://github.com/google/deepvariant/assets/6555937/83edefd6-8d77-4a7a-8fb3-921ec7c3cff1). Once the pattern has been achieved like the following, then one can proceed with testing each genotype's representation of the variant:. ![image](https://github.com/google/deepvariant/assets/6555937/13e95fe0-71b1-40aa-bccc-4d8c5463de6f). We want to see for which genotype the set of patterns (the feature map above) maximizes for, which will indicate the genotype present with a specific maximal probability. First we test for $`homozygous`$ $`reference`$:. ![image](https://github.com/google/deepvariant/assets/6555937/be5e3074-4c2f-4600-9ea3-9cb6bfda58f8). Next we test for $`heterozygous`$:. ![image](https://github.com/google/deepvariant/assets/6555937/1e43b84e-17ae-40ea-8c82-b7e87d0cf3d6). Finally we test for $`homozygous`$ $`alternate`$:. ![image](https://github.com/google/deepvariant/assets/6555937/cedce40f-4fc0-45fe-843b-e2652b31c0af). Now we can see there is a significant correlation with a heterozygous variant call. So to call a variant site's genotype you now have the power to traverse the whole neural network -- through a set of transformations (yo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1612282088:4291,test,testing,4291,,https://github.com/google/deepvariant/issues/666#issuecomment-1612282088,1,['test'],['testing']
Testability,"thon/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:09) [2,484 / 2,523] 17 / 38 tests, 3 failed; Testing //deepvariant:model_train_test [0s (9 actions)] ... (39 actions, 2 running); (06:29:09) FAIL: //deepvariant:model_train_test (shard 2 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log); (06:29:09) INFO: From Testing //deepvariant:model_train_test (shard 2 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 2 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise Import",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:21329,test,testlogs,21329,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"thon/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant:tf_utils_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log); (06:29:10) INFO: From Testing //deepvariant:tf_utils_test:; ==================== Test output for //deepvariant:tf_utils_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/tf_utils_test.runfiles/com_google_deepvariant/deepvariant/tf_utils_test.py"", line 40, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_inte",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:23505,log,log,23505,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"thon/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:15) [2,502 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test [0s (5 actions)] ... (21 actions, 2 running); (06:29:15) FAIL: //deepvariant:model_train_test (shard 9 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log); (06:29:15) INFO: From Testing //deepvariant:model_train_test (shard 9 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 9 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise Import",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:62264,test,testlogs,62264,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"thon/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) FAIL: //deepvariant:modeling_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log); (06:29:20) INFO: From Testing //deepvariant:modeling_test:; ==================== Test output for //deepvariant:modeling_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/modeling_test.runfiles/com_google_deepvariant/deepvariant/modeling_test.py"", line 41, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_inte",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:110392,log,log,110392,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"thread-create-resource-temporarily-unavailable/54746150#54746150; BIN_VERSION=""1.1.0""; mkdir -p deepvariant1. singularity exec --bind /usr/lib/locale/ \; docker://google/deepvariant:${BIN_VERSION} \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref reference/GRCh38_no_alt_analysis_set.fasta \; --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \; --output_vcf deepvariant1/output.vcf.gz \; --num_shards $(nproc) \; --regions chr20 \; --call_variants_extra_args ""use_openvino=true""; ```. This actually worked for me. I'll paste some logs around the model conversion:; ```; Instructions for updating:; Use `tf.compat.v1.graph_util.remove_training_nodes`; Model Optimizer arguments:; Common parameters:; - Path to the Input Model: /home/pichuan/model.pb; - Path for generated IR: /home/pichuan/.; - IR output name: model; - Log level: ERROR; - Batch: Not specified, inherited from the model; - Input layers: Not specified, inherited from the model; - Output layers: Not specified, inherited from the model; - Input shapes: Not specified, inherited from the model; - Mean values: [128,128,128,128,128,128,128,128,128]; - Scale values: Not specified; - Scale factor: 128.0; - Precision of IR: FP32; - Enable fusing: True; - Enable grouped convolutions fusing: True; - Move mean values to preprocess section: False; - Reverse input channels: False; TensorFlow specific parameters:; - Input model in text protobuf format: False; - Path to model dump for TensorBoard: None; - List of shared libraries with TensorFlow custom layers implementation: None; - Update the configuration file with input/output node names: None; - Use configuration file used to generate the model with Object Detection API: None; - Use the config file: None; Model Optimizer version:. [ SUCCESS ] Generated IR version 10 model.; [ SUCCESS ] XML file: /home/pichuan/./model.xml; [ SUCCESS ] BIN file: /home/pichuan/./model.bin; [ SUCCESS ] Total execution time: 24.29 seconds.; [ SUCCESS ] Memory consumed: 761 M",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/404#issuecomment-761309014:2986,Log,Log,2986,,https://github.com/google/deepvariant/issues/404#issuecomment-761309014,1,['Log'],['Log']
Testability,"thub.com/sylabs|github.com/hpcng|' | \; bash -x; ```. Here's the version:; ```; pichuan@pichuan-test-speed:~$ singularity --version; singularity version 3.7.0; ```. I followed:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-exome-case-study.md; to download the data. And then:. ```; mkdir -p output; mkdir -p output/intermediate_results_dir. # Pull the image.; BIN_VERSION=1.1.0; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant.; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref reference/GRCh38_no_alt_analysis_set.fasta \; --reads input/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions input/idt_capture_novogene.grch38.bed \; --output_vcf output/HG003.output.vcf.gz \; --output_gvcf output/HG003.output.g.vcf.gz \; --num_shards $(nproc) \; --intermediate_results_dir output/intermediate_results_dir 2>&1 | tee /tmp/all.log; ```. I'll paste part of the log of each step so that you can compare. ## make_examples; make_examples speed is roughly:; ```; I0622 21:19:25.373434 140610510067456 make_examples.py:648] Task 7/8: 4900 candidates (5187 examples) [27.99s elapsed]; I0622 21:19:35.260825 139809239041792 make_examples.py:648] Task 1/8: 4809 candidates (5065 examples) [32.79s elapsed]; I0622 21:19:37.868103 139727062120192 make_examples.py:648] Task 2/8: 4900 candidates (5208 examples) [37.92s elapsed]; I0622 21:19:37.739557 139786800707328 make_examples.py:648] Task 6/8: 5100 candidates (5441 examples) [29.08s elapsed]; I0622 21:19:44.484720 140667007305472 make_examples.py:648] Task 5/8: 4902 candidates (5241 examples) [37.78s elapsed]; ```. Here are the last few lines from the log:; ```; I0622 21:24:34.005878 140667007305472 make_examples.py:648] Task 5/8: Created 6240 examples; I0622 21:24:38.061186 139897026688768 make_examples.py:648] Task 4/8: 5906 candidates (6318 examples) [17.72s elapsed]; I0622 21",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866352316:1666,log,log,1666,,https://github.com/google/deepvariant/issues/463#issuecomment-866352316,1,['log'],['log']
Testability,timer_test (cached) PASSED in 0.7s; //deepvariant:call_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/call_variants_test/test.log; //deepvariant:data_providers_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/data_providers_test/test.log; //deepvariant:haplotypes_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log; //deepvariant:modeling_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log; //deepvariant:pileup_image_test FAILED in 0.3s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/pileup_image_test/test.log; //deepvariant:postprocess_variants_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log; //deepvariant:tf_utils_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log; //deepvariant:variant_caller_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/variant_caller_test/test.log; //deepvariant/labeler:customized_classes_labeler_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/labeler/customized_classes_labeler_test/test.log; //deepvariant/labeler:ha,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:118985,test,testlogs,118985,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ting system: Ubuntu 22.04.2 LTS; > * DeepVariant version: 1.6.1; > * Installation method (Docker, built from source, etc.): Docker; > * Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Its a Pabcio CLR data. Read Input is provided in Fastq format and reference in FASTA format.; > ; > **Steps to reproduce:**; > ; > * Command: sudo docker run ; > -v ""${INPUT_DIR}"":""/input"" ; > -v ""${OUTPUT_DIR}"":""/output"" ; > google/deepvariant:""${BIN_VERSION}"" ; > /opt/deepvariant/bin/run_deepvariant ; > --model_type=PACBIO ; > --ref=/input/RILWLs1.fasta ; > --reads=/input/Out.fastq ; > --output_vcf=/output/output.vcf.gz ; > --output_gvcf=/output/output.g.vcf.gz ; > --intermediate_results_dir /output/intermediate_results_dir ; > --num_shards=15; > * Error trace: (if applicable); > ; > **Does the quick start test work on your system?** Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Yes. Test data works fine. ![Screenshot from 2024-04-17 12-24-22](https://private-user-images.githubusercontent.com/68117296/323111309-41ac66ff-ff52-493f-b18f-f017921caa86.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTMzMzcyOTIsIm5iZiI6MTcxMzMzNjk5MiwicGF0aCI6Ii82ODExNzI5Ni8zMjMxMTEzMDktNDFhYzY2ZmYtZmY1Mi00OTNmLWIxOGYtZjAxNzkyMWNhYTg2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDE3VDA2NTYzMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTg3ZDQ3ZTBmNDFjYWQ4YWQyNmM4MDdmYTJiYjVjNzlhYmI1MDA2NzQxOGY3MjA1ZjU1ODY3ZDUzOTcyMTkyNzQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.gtqyKpmVpHdy0Yw9XgACJqtqoRcB3SuNknzCYOE8y-g); > ; > Is there any way to reproduce the issue by using the quick start?; > ; > **Any additional context:**. Its a 256GB RAM syst",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/807#issuecomment-2060514080:1212,Test,Test,1212,,https://github.com/google/deepvariant/issues/807#issuecomment-2060514080,1,['Test'],['Test']
Testability,"tobuf build; make uninstall; make distclean. # share build for C++; # install under /usr instead of /usr/local; CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static; make clean; make -j20; # optional; make -j20 check # check if protobuf build is good; # install; make install; sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig; #cd .. # verify; echo ""$(which protoc)""; echo ""$(protoc --version)""; ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash; # share build for Python; python --version # python 2.7 or newer; protoc --version; # build; cd protobuf-3.6.1/python/; python setup.py build; python setup.py test; # install from source as deepvariant needed; python setup.py install; # install from wheel; python setup.py bdist_wheel; pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall; # verify; python -c ""import google.protobuf""; ```. ## OpenBLAS 0.3.5. ```bash; git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5; cd OpenBLAS-0.3.5; make TARGET=power8; make TARGET=power8 PREFIX=$HOMEPATH/inst install; ```. ## Boost 1.66.0. ```bash; wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz; tar xzf boost_1_66_0.tar.gz; cd boost_1_66_0; ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst; ./b2 dll-path=""$HOMEPATH/inst/lib"" install; ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:7391,test,test,7391,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,1,['test'],['test']
Testability,"ts20_sorted.bam with NativeSamReader; I0129 11:46:16.360527 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/NA12878.sorted.vcf.gz with NativeVcfReader; I0129 11:46:16.361952 140471159555840 make_examples.py:946] Common contigs are [u'chr20']; I0129 11:46:16.501434 140471159555840 make_examples.py:1030] Writing examples to prj-NA12878/training-examples/training_set.with_label.tfrecord.gz; 2019-01-29 11:46:16.502209: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728; 2019-01-29 11:46:16.550218: W third_party/nucleus/io/sam_reader.cc:125] Unknown tag pb: in header line, ignoring: @HD VN:1.5 SO:coordinate pb:3.0.1; 2019-01-29 11:46:16.554270: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0129 11:46:16.556066 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/alignments20_sorted.bam with NativeSamReader; I0129 11:46:16.571476 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/NA12878.sorted.vcf.gz with NativeVcfReader; I0129 11:46:20.140141 140471159555840 make_examples.py:782] Found 0 candidates in chr20:1-1000 [3.64s elapsed]; I0129 11:46:20.141022 140471159555840 make_examples.py:782] Found 0 candidates in chr20:1001-2000 [0.00s elapsed]; I0129 11:46:20.141855 140471159555840 make_examples.py:782] Found 0 candidates in chr20:2001-3000 [0.00s elapsed]; I0129 11:46:20.142673 140471159555840 make_examples.py:782] Found 0 candidates in chr20:3001-4000 [0.00s elapsed]; I0129 11:46:20.143475 140471159555840 make_examples.py:782] Found 0 candidates in chr20:4001-5000 [0.00s elapsed]; I0129 11:46:20.144277 140471159555840 make_examples.py:782] Found 0 candidates in chr20:5001-6000 [0.00s elapsed]; I0129 11:46:20.145082 140471159555840 make_examples.py:782] Found 0 candidates in chr20:6001-7000 [0.00s elapsed]; I0129 11:46:20.145899 140471159555840 make_examples.py:782] Found 0 candidates in chr20:7001-8000 [0.00s elapsed]; I0129 11:46:20.146692 140",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-458487916:3043,test,testdata,3043,,https://github.com/google/deepvariant/issues/138#issuecomment-458487916,1,['test'],['testdata']
Testability,"ttplib; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""xx/anaconda/envs/Python27/lib/python2.7/httplib.py"", line 80, in <module>; import mimetools; File ""xx/anaconda/envs/Python27/lib/python2.7/mimetools.py"", line 6, in <module>; import tempfile; File ""xx/anaconda/envs/Python27/lib/python2.7/tempfile.py"", line 35, in <module>; from random import Random as _Random; File ""xx/anaconda/envs/Python27/lib/python2.7/random.py"", line 45, in <module>; from math import log as _log, exp as _exp, pi as _pi, e as _e, ceil as _ceil; ***File ""math.py"", line 79, in <module>***; import numpy as np; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>; from . import add_newdocs; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/add_newdocs.py"", line 13, in <module>; from numpy.lib import add_newdoc; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/lib/__init__.py"", line 8, in <module>; from .type_check import *; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/lib/type_check.py"", line 11, in <module>; import numpy.core.numeric as _nx; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/core/__init__.py"", line 74, in <module>; from numpy.testing.nosetester import _numpy_tester; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/testing/__init__.py"", line 12, in <module>; from . import decorators as dec; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/testing/decorators.py"", line 20, in <module>; from .utils import SkipTest, assert_warns; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/testing/utils.py"", line 15, in <module>; from tempfile import mkdtemp, mkstemp; ImportError: cannot import name mkdtemp; >>> ; ```; As you can see, it attempts to load the local `math.py`, shadowing the standard `math` module.; On the other hand, cd to another path and `import httplib` does not have any problem.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/32#issuecomment-355522771:1978,test,testing,1978,,https://github.com/google/deepvariant/issues/32#issuecomment-355522771,4,['test'],['testing']
Testability,"t}-{end} > {output.bam}""); shell(""echo '{chrom}\t{start}\t{end}' > {output.bed}""). rule deepvariant:; input:; bam=dir_work + ""bams/ChineseQuartet.{region}.bam"",; bai=dir_work + ""bams/ChineseQuartet.{region}.bam.bai"",; bed=dir_work + ""bams/ChineseQuartet.{region}.bed"",; ref=path_ref; output:; vcf_gz=dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.vcf.gz"",; gvcf_gz=dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.g.vcf.gz""; # gvcf_gz=config[""dir_variants""] + ""dv/dv_details/{sample}/{sample}.{prefix}.dv.raw.g.vcf.gz""; log:; dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.log""; benchmark:; dir_work + ""vcfs/ChineseQuartet.{region}.deepvariant.log""; threads: 48; run:; dir_tmp = str(output.vcf_gz).rstrip("".vcf.gz"") + ""_tmp""; file_tmp = dir_tmp.split(""/"")[-1]; shell(""mkdir -p "" + dir_tmp); bam_dir = ""/"".join(str(input.bam).split(""/"")[:-1]); bam_file = str(input.bam).split(""/"")[-1]; bed_file = str(input.bed).split(""/"")[-1]; ref_dir = ""/"".join(str(input.ref).split(""/"")[:-1]); ref_file = str(input.ref).split(""/"")[-1]; output_dir = ""/"".join(str(output.vcf_gz).split(""/"")[:-1]); output_file = str(output.vcf_gz).split(""/"")[-1].rstrip("".vcf.gz""). shell('docker run '; '-v ""{bam_dir}"":""/input"" '; '-v ""{ref_dir}"":""/ref"" '; '-v ""{output_dir}"":""/output"" '; 'google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant '; '--model_type=PACBIO '; '--ref=/ref/{ref_file} '; '--reads=/input/{bam_file} '; '--regions /input/{bed_file} '; '--output_vcf=/output/{output_file}.vcf '; '--output_gvcf=/output/{output_file}.g.vcf '; '--num_shards={threads} '; '--make_examples_extra_args min_mapping_quality=1,keep_supplementary_alignments=true '; '--intermediate_results_dir /output/{file_tmp} 1>{log} 2>{log}'); shell(""{bcftools} view -Oz -o {output.vcf_gz} {output_dir}/{output_file}.vcf""); shell(""{bcftools} view -Oz -o {output.gvcf_gz} {output_dir}/{output_file}.g.vcf""). rule samtools_index:; input:; ""{preifx}.bam""; output:; ""{preifx}.bam.bai""; run:; shell(""{samtools} index {input}""); ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/660#issuecomment-1589724792:3444,log,log,3444,,https://github.com/google/deepvariant/issues/660#issuecomment-1589724792,2,['log'],['log']
Testability,"u"" --scopes ""compute-rw,storage-full,cloud-platform"" --image-family ""ubuntu-2004-lts"" --image-project ""ubuntu-os-cloud"" --machine-type ""custom-64-131072"" --boot-disk-size ""300"" --zone ""us-west2-b"" --min-cpu-platform ""Intel Skylake""`. ssh into the machine:. ```; gcloud compute ssh pichuan-cpu --zone us-west2-b; ```. Get the binaries and models:. ```; BUCKET=""gs://deepvariant""; BIN_VERSION=""1.4.0""; MODEL_VERSION=""1.4.0"". BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}""; MODEL_NAME=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". mkdir -p bin; # Download the DeepVariant binaries.; gsutil -m cp ""${BIN_BUCKET}/*"" bin/; chmod a+x bin/*; ```. Then, I ran:; ```; cd bin; bash run-prereq.sh; cd -; ```. The `run-prereq.sh` tends to be the most tricky one - it will require root permission, and it'll install a bunch of stuff on your machine. If you can't use Docker because of root permissions, you likely won't be able to run this as well. Download test data:. ```; INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ```. Run make_examples:. ```; OUTPUT_DIR=""${PWD}/quickstart-ou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/590#issuecomment-1322695241:1486,test,test,1486,,https://github.com/google/deepvariant/issues/590#issuecomment-1322695241,1,['test'],['test']
Testability,ue for this or take it somewhere else this is TensorFlow-specific. It seems that TensorFlow `r1.12` installed duing the deepvariant build is looking for CUDA 9:. ```; FAILED: //deepvariant:model_eval_test (Summary); /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_4_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_3_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_2_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_8_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_9_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_7_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_10_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_5_of_10/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_6_of_10/test.log; (05:40:51) FAIL: //deepvariant:model_eval_t,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:1180,test,testlogs,1180,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,uild_artifacts/h5py_1604753633596/work; httplib2 @ file:///home/conda/feedstock_root/build_artifacts/httplib2_1679483503307/work; idna @ file:///home/conda/feedstock_root/build_artifacts/idna_1663625384323/work; idna-ssl @ file:///home/conda/feedstock_root/build_artifacts/idna_ssl_1636483491140/work; importlib-metadata @ file:///home/conda/feedstock_root/build_artifacts/importlib-metadata_1630267465156/work; intervaltree @ file:///home/conda/feedstock_root/build_artifacts/intervaltree_1683532206518/work; Jinja2 @ file:///home/conda/feedstock_root/build_artifacts/jinja2_1636510082894/work; jsonschema @ file:///home/conda/feedstock_root/build_artifacts/jsonschema_1634752161479/work; Keras-Applications==1.0.8; Keras-Preprocessing @ file:///home/conda/feedstock_root/build_artifacts/keras-preprocessing_1610713559828/work; Markdown @ file:///home/conda/feedstock_root/build_artifacts/markdown_1679584000376/work; MarkupSafe @ file:///home/conda/feedstock_root/build_artifacts/markupsafe_1621455668064/work; mock @ file:///home/conda/feedstock_root/build_artifacts/mock_1681654098624/work; multidict @ file:///home/conda/feedstock_root/build_artifacts/multidict_1633329770033/work; numpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1607958944856/work; oauth2client==4.1.3; oauthlib @ file:///home/conda/feedstock_root/build_artifacts/oauthlib_1666056362788/work; opt-einsum @ file:///home/conda/feedstock_root/build_artifacts/opt_einsum_1617859230218/work; pandas==1.1.5; protobuf==3.18.0; psutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1610127101219/work; pyasn1==0.4.8; pyasn1-modules==0.2.7; pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work; PyJWT @ file:///home/conda/feedstock_root/build_artifacts/pyjwt_1683676063469/work; pyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1663846997386/work; pyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1652235407899/work; pyrsiste,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/664#issuecomment-1593835553:4621,mock,mock,4621,,https://github.com/google/deepvariant/issues/664#issuecomment-1593835553,1,['mock'],['mock']
Testability,"up>[(6)](#vfootnote6)</sup>6 HG002, 6 HG003, 6 HG004, 8 HG005, 8 HG006, 8 HG007 | 13,039,595 |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 9 HG002, 5 HG003, 5 HG004, 1 HG005, 1 HG006, 1 HG007 | 890,016,014<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 9 HG002, 5 HG003, 5 HG004, 1 HG005, 1 HG006, 1 HG007 | 838,515,085<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 1 HG002, 1 HG002, 1 HG004 | 50,249,704<sup>[(5)](#vfootnote5)</sup> |; ./docs/deeptrio-details-training-data.md:| 1.6.0 | 1 HG002, 1 HG002, 1 HG004 | 99,675,190<sup>[(5)](#vfootnote5)</sup> |; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/HG002_ONT_deeptrio.denovo.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/customized_classes.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_gvcf_output.g.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00002-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.vcf_candidate_importer.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00001-of-00003.example_info.json:{""version"":",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040:2317,test,testdata,2317,,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040,1,['test'],['testdata']
Testability,"urces.ResourceMonitor() as monitor:; #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment; self.assertEqual(monitor.metrics().physical_core_count, 20); --------------------------------. ##########################################################################; # //deepvariant/realigner/allele_count_linear:generate_trained_model_test; # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8; ##########################################################################; # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python; python -c ""import numpy"" # prequests of TF 1.12.0; python -c ""import scipy"" # prequests of TF 1.12.0; pip install Cython --force-reinstall --no-deos; pip install scikit-learn --force-reinstall --no-deos; # build from source; wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz; tar zxvf 0.20.2.tar.gz; cd scikit-learn-0.20.2; python setup.py bdist_wheel; # verify; python -c ""from sklearn.externals import joblib"". ##########################################################################; # //deepvariant/labeler:haplotype_labeler_test; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; ##########################################################################; # fail due to mock data, open an issue in github; https://github.com/google/deepvariant/issues/154. ##########################################################################; # //deepvariant:make_examples_test; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; # internvaltree v3 has some API changes with v2; ##########################################################################; pip install 'intervaltree==2.1.0'; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:22176,test,test,22176,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,3,"['mock', 'test']","['mock', 'test']"
Testability,"ut you didn't notice, then the next step will fail.; Common failure modes I've seen before:; - if you were running make_examples, but abort in the middle by ctrl-c. Sometimes not all the make_examples in the background were killed. If you just re-run make_examples without killing all background make_examples first, the output might be corrupted.; - if make_examples failed completely without outputting HG002.examples.tfrecord*.gz at all, it'll also cause a failure. Our hope is that you'll notice this in the errors that make_examples displayed. If you're creating some kind of workflow yourself, you will need to make sure you check the error code of the runs. If make_examples died, you shouldn't proceed with call_variants. After my make_examples run and confirming that I have the output files, I ran call_variants:; ```; ## Run `call_variants`; ( time \; /opt/deepvariant/bin/call_variants \; --outfile ""HG002.cvo.tfrecord.gz"" \; --examples ""HG002.examples.tfrecord@${N_SHARDS}.gz"" \; --checkpoint ""model.ckpt"" \; ) 2>&1 | tee ""call_variants.log"" &; ```; When I run this on the same 64-core, 128GB RAM machine, it usually only uses about 500% CPU (instead of all of the 64 cores). This step took about 2m. I can confirm that I successfully run this step without the errors you saw. However, if I remove the files first by `rm -f HG002.examples.tfrecord*.gz` and then repeat the call_variants command above, I can see the errors you reported above:; ```; ValueError: Cannot find matching files with the pattern ""HG002.examples.tfrecord@64.gz""; ```. So, please make sure you that your make_examples step completed successfully before you proceed. (4) As you noticed so far, creating a workflow can be complicated (and mostly has nothing to do with variant caller itself). If you end up trying out the Cloud runner and has more questions, please feel free to get in touch with @nmousavi and the Cloud team. I'm sure the team will love to get your feedback if you decide to try it out. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:4832,log,log,4832,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,1,['log'],['log']
Testability,"ut/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log); (06:29:17) INFO: From Testing //deepvariant/realigner/allele_count_linear:model_evaluation_test:; ==================== Test output for //deepvariant/realigner/allele_count_linear:model_evaluation_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/realigner/allele_count_linear/model_evaluation_test.py"", line 41, in <module>; from deepvariant import testdata; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/deepvariant/testdata.py"", line 39, in <module>; from third_party.nucleus.testing import test_utils as nucleus_test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/realigner/allele_count_linear/model_evaluation_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_ten",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:78406,test,testing,78406,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['test'],['testing']
Testability,"variant/realigner:aligner_test FAILED in 0.4s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:122325,log,log,122325,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"variants.bed.txt contigs have name 'chr' when BAM file has contig name 'NC_000913.3'; > Contig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help!; I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file.; I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file.; And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```; python bin/make_examples.zip \; --mode training \; --ref ""project-retraining/testdata/sequence.fasta"" \; --reads ""project-retraining/testdata/aligned_reads.bam"" \; --examples ""project-retraining/training_examples"" \; --confident_regions ""project-retraining/testdata/variants.bed"" \; --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1; ```. and I get the same ValueError as before (from `make_examples.log` file):. ```; 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs; 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader; [W::bcf_hdr_register_hrec] An INFO field has no Type defined.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/128#issuecomment-448201709:1039,test,testdata,1039,,https://github.com/google/deepvariant/issues/128#issuecomment-448201709,1,['test'],['testdata']
Testability,"w I do a better job sizing compute resources?. On the GCP DeepVariant tutorial page:; https://cloud.google.com/life-sciences/docs/tutorials/deepvariant; You can see some numbers of runtime and cost estimates on GCP. This might help give you some sense of what type of machine you can choose. Since you're running on AWS, the cost might change based on pricing. > 3. How do I know if docker is making progress or not?. Currently, our one-step script should be outputting some logs as it goes. If make_examples is still running, you should see lines of logs coming out, showing there's progress. There's likely room for improvement on how we show this progress. If you have suggestions or bug reports, please let us know. > I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good!. Sorry to hear that the logs are not coming out promptly. If it's possible, can you tell us where did the log get stuck?. > 4. I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. I haven't tried using nohub. I'll have to try and respond to this later.; > ; > thanks; > ; > Andy; > ; > p.s. I am running in AWS . not sure if that makes a difference or not. I don't expect it to make a difference. But if you do observe any issues, feel free to let us know what kind of AWS instances you're running on, and what's the unexpected behavior, so we can reproduce the issue.; > ; > p.p.s. Is there a better place to ask questions like this?. This is a good place to ask :); It's a public forum, so our team and everyone in the community can ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/260#issuecomment-573487475:1708,log,logs,1708,,https://github.com/google/deepvariant/issues/260#issuecomment-573487475,1,['log'],['logs']
Testability,"w_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:09) [2,484 / 2,523] 17 / 38 tests, 3 failed; Testing //deepvariant:model_train_test [0s (9 actions)] ... (39 actions, 2 running); (06:29:09) FAIL: //deepvariant:model_train_test (shard 2 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_2_of_10/test.log); (06:29:09) INFO: From Testing //deepvariant:model_train_test (shard 2 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 2 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:21386,log,log,21386,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"w_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:15) [2,502 / 2,523] 22 / 38 tests, 8 failed; Testing //deepvariant:model_train_test [0s (5 actions)] ... (21 actions, 2 running); (06:29:15) FAIL: //deepvariant:model_train_test (shard 9 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_train_test/shard_9_of_10/test.log); (06:29:15) INFO: From Testing //deepvariant:model_train_test (shard 9 of 10):; ==================== Test output for //deepvariant:model_train_test (shard 9 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_train_test.runfiles/com_google_deepvariant/deepvariant/model_train_test.py"", line 44, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call last):; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>; from tensorflow.pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:62321,log,log,62321,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```; python bin/make_examples.zip \; --mode training \; --ref ""data/chr20.fa"" \; --reads ""data/sorted_final_merged.bam"" \; --examples ""training-examples/training_set.with_label.tfrecord.gz"" \; --confident_regions ""data/NA12878.sorted.bed"" \; --regions ""chr20"" \; --truth_variants ""data/NA12878.sorted.vcf.gz"" \; --norealign_reads; ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:; * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. ; * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps!. ```; 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; WARNING: Logging before flag parsing goes to stderr.; I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader; I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs; 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: ; I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader; I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader; I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']; I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-454225947:1403,log,log,1403,,https://github.com/google/deepvariant/issues/138#issuecomment-454225947,1,['log'],['log']
Testability,"with you.; > ; > 1. If I want to test 3 Pacbio WGS datasets using deeptrio1.6, how much memory should I allocate at least?. In our https://github.com/google/deepvariant/blob/r1.6/docs/metrics-deeptrio.md documentation, all experiments were done with n1-standard-64 GCP machines, which has 240 GB memory, and 64 vCPUs. I have not specifically tried machines with smaller memory. Can you tell me what kind of memory constraints you're considering?. > 2. Regarding NGS-deeptrio1.6 analysis, I only saw the benchmark comparison results for WGS-chr20. Do you have any results (Recall, Precision, F1_Score) to share for WES data?. Please see:; https://github.com/google/deepvariant/blob/r1.6/docs/metrics-deeptrio.md#whole-exome-sequencing-illumina. > 3. For Pacbio-deeptrio1.6 analysis, I tested the official WGS HiFi data (HG002, HG003, HG004). The reference genome used for alignment was hs37d5.fa. The bam was hifi_reads_aligned.haplotagged.bam (pbmm2+whatshap haplotag). The region is chr20. However, the benchmark comparison results were worse than the data you published. Does the choice of reference genome affect the precision of the results?. If you're using different reference genome, the numbers are not directly comparable because the truth sets are also different. > 4. Whether it is NGS-WES or Pacbio-WGS, the results from using deeptrio1.6 for analysis are slightly less precision than using deepvariant1.6. Is this normal? In theory, should the results from deeptrio1.6 be better than those from deepvariant1.6?. I suppose you're comparing numbers like https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-pacbio-model-case-study.md#benchmark-output and https://github.com/google/deepvariant/blob/r1.6/docs/metrics-deeptrio.md#hg003-1.; The former has 77+69+25+23=194 total FNs+FPs, and the latter has 53+78+21+35=187. Overall there are fewer errors, even though it is true that not all the error types were better on DeepTrio. We hope to improve all our models in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/720#issuecomment-1781737186:1245,benchmark,benchmark,1245,,https://github.com/google/deepvariant/issues/720#issuecomment-1781737186,2,['benchmark'],"['benchmark', 'benchmark-output']"
Testability,"xsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts md_clear spec_ctrl intel_stibp flush_l1d; bogomips : 4595.05; clflush size : 64; cache_alignment : 64; address sizes : 46 bits physical, 48 bits virtual; power management:; ```; - OS ,kernel & docker version; ```sh; # uname -a; Linux CoreS 3.10.0-1062.12.1.el7.x86_64 #1 SMP Tue Feb 4 23:02:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. # cat /etc/centos-release; CentOS Linux release 7.7.1908 (Core). # docker -v; Docker version 19.03.12, build 48a66213fe; ```. - Test run command; ```sh; # BIN_VERSION=""1.0.0""; # ls -1 ${INPUT_DIR}; NA12878_S1.chr20.10_10p1mb.bam; NA12878_S1.chr20.10_10p1mb.bam.bai; test_nist.b37_chr20_100kbp_at_10mb.bed; test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; ucsc.hg19.chr20.unittest.fasta; ucsc.hg19.chr20.unittest.fasta.fai; ucsc.hg19.chr20.unittest.fasta.gz; ucsc.hg19.chr20.unittest.fasta.gz.fai; ucsc.hg19.chr20.unittest.fasta.gz.gzi. # docker run \; > -v ""${INPUT_DIR}"":""/input"" \; > -v ""${OUTPUT_DIR}"":""/output"" \; > google/deepvariant:""${BIN_VERSION}"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=/input/ucsc.hg19.chr20.unittest.fasta \; > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; > --regions ""chr20:10,000,000-10,010,000"" \; > --output_vcf=/output/output.vcf.gz \; > --output_gvcf=/output/output.g.vcf.gz \; > --intermediate_results_dir /output/intermediate_results_dir \; > --num_shards=1 \; >. Status: Downloaded newer image for google/deepvariant:1.0.0; I0911 0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-690842263:1872,Test,Test,1872,,https://github.com/google/deepvariant/issues/345#issuecomment-690842263,1,['Test'],['Test']
Testability,"y (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2021-06-22 21:25:07.731210: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000170000 Hz; 2021-06-22 21:25:07.731675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e87820 initialized for platform Host (this does not guarantee that XLA will be used). Devices:; 2021-06-22 21:25:07.731713: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version; 2021-06-22 21:25:07.734891: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; ```; which confirms that I'm using AVX optimization. The log for call_variants is pretty short, because WES has fewer examples to run on. My `call_variants` log look like this:; ```; I0622 21:25:17.009006 140301916206848 saver.py:1293] Restoring parameters from /opt/models/wes/model.ckpt; I0622 21:25:24.567713 140301916206848 call_variants.py:454] Processed 1 examples in 1 batches [1678.300 sec per 100]; I0622 21:26:59.442872 140301916206848 call_variants.py:454] Processed 15001 examples in 30 batches [0.744 sec per 100]; I0622 21:28:34.156948 140301916206848 call_variants.py:454] Processed 30001 examples in 59 batches [0.688 sec per 100]; I0622 21:30:08.158901 140301916206848 call_variants.py:454] Processed 45001 examples in 88 batches [0.667 sec per 100]; I0622 21:30:37.846297 140301916206848 call_variants.py:458] Processed 49760 examples in 98 batches [0.663 sec per 100]; I0622 21:30:37.846524 140301916206848 call_variants.py:461] Done calling variants from a total of 49760 examples. real 5m34.074s; user 32m1.122s; sys 0m32.211s; ```. Note that the CPU usage for `call_variants` seems to vary more than `make_examples`. Not all 8 CPUs are at 100% al",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866352316:5496,log,log,5496,,https://github.com/google/deepvariant/issues/463#issuecomment-866352316,1,['log'],['log']
Testability,"y"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:21) FAIL: //deepvariant:postprocess_variants_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/postprocess_variants_test/test.log); (06:29:21) INFO: From Testing //deepvariant:postprocess_variants_test:; ==================== Test output for //deepvariant:postprocess_variants_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants_test.runfiles/com_google_deepvariant/deepvariant/postprocess_variants_test.py"", line 46, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise Impo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:114947,test,testlogs,114947,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"yeap, it's caused by empty shards. I was able to reproduce this by using 64 shards with the quickstart test data. @depristo should I file a separate issue for this as it's not really a docker issue?. @chenshan03: thanks for the report. As a workaround until this bug is fixed, you may reduce the number of shards to avoid having empty ones.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/27#issuecomment-355036534:103,test,test,103,,https://github.com/google/deepvariant/issues/27#issuecomment-355036534,1,['test'],['test']
Testability,"yes @pichuan scripts/run_wes_case_study_binaries.sh does complete with those warnings, just wondering about why the output is binary when the postprocess command is invoked with tfrecord in name [examples.tfrecord.zip](https://github.com/google/deepvariant/files/3456033/examples.tfrecord.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.tfrecord.vcf`. than without [examples.zip](https://github.com/google/deepvariant/files/3456034/examples.zip). `python ./bazel-bin/deepvariant/postprocess_variants.zip --ref quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --infile quickstart-output/examples.tfrecord.cvo.gz --outfile quickstart-output/examples.vcf`. and what does that binary file represent?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/199#issuecomment-517213905:369,test,testdata,369,,https://github.com/google/deepvariant/issues/199#issuecomment-517213905,2,['test'],['testdata']
Testability,"yes, I think this is a real bug that still exists.; Due to the distributed nature of the cloud process, some machines may get shards that are all empty. Also, we actually only supply one of the shards to each process, so (1) doesn't really apply (there is no 'next shard').; You can reproduce this by adding ""--shards 64"" to the quickstart test data configuration in https://cloud.google.com/genomics/deepvariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/27#issuecomment-355996061:340,test,test,340,,https://github.com/google/deepvariant/issues/27#issuecomment-355996061,1,['test'],['test']
Testability,"ython/google/protobuf/pyext/_message.so is probably truncated; Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main; AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found.; Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main; AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found.; parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full?; parallel: Error: Change $TMPDIR with --tmpdir or use --compress.; Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s; user 0m1.215s; sys 0m0.687s. ## command-line plan B:; /share/app/singularity/3.8.1/bin/singularity exec \; --bind /usr/lib/locale/:/usr/lib/locale/ \; --bind $ccsbam:$ccsbam \; --bind $ccsbam.bai:$ccsbam.bai \; --bind $fasta:$fasta \; --bind $fasta.fai:$fasta.fai \; --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \; /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/ou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300:3717,Assert,AssertionError,3717,,https://github.com/google/deepvariant/issues/679#issuecomment-1636707300,1,['Assert'],['AssertionError']
Testability,"ython/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: /usr/local/cuda-10.0/lib64/libcublas.so.9.0: version `libcublas.so.9.0' not found (required by /root/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so); ```. However:. 1. I specified CUDA 10 in `settings.sh`; 1. CUDA 9 is not required for TensorFlow `r1.12`. Additionally:. 1. CUDA 9 is not available for my system, Ubuntu 18; 1. Symlinking to the correct file names as suggested [elsewhere](https://github.com/tensorflow/tensorflow/issues/15604) did not work; 1. I have built TensorFlow `r1.12` (and master) for CUDA 10 (and 9) in my environment previously. Questions:. 1. Does deepvariant have a requirement for CUDA 9(.0?)?; 1. How would you recommend proceeding?. _________. ```; Linux localhost 4.15.0-1032-aws #34-Ubuntu SMP Thu Jan 17 15:18:09 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux; ```. Full log:. ```; + source settings.sh; ++ export DV_USE_PREINSTALLED_TF=0; ++ DV_USE_PREINSTALLED_TF=0; ++ export TF_CUDA_CLANG=0; ++ TF_CUDA_CLANG=0; ++ export TF_ENABLE_XLA=1; ++ TF_ENABLE_XLA=1; ++ export TF_NEED_CUDA=1; ++ TF_NEED_CUDA=1; ++ export TF_NEED_GCP=1; ++ TF_NEED_GCP=1; ++ export TF_NEED_GDR=0; ++ TF_NEED_GDR=0; ++ export TF_NEED_HDFS=0; ++ TF_NEED_HDFS=0; ++ export TF_NEED_JEMALLOC=0; ++ TF_NEED_JEMALLOC=0; ++ export TF_NEED_MKL=1; ++ TF_NEED_MKL=1; ++ export TF_NEED_MPI=0; ++ TF_NEED_MPI=0; ++ export TF_NEED_OPENCL=0; ++ TF_NEED_OPENCL=0; ++ export TF_NEED_OPENCL_SYCL=0; ++ TF_NEED_OPENCL_SYCL=0; ++ export TF_NEED_S3=1; ++ TF_NEED_S3=1; ++ export TF_NEED_VERBS=0; ++ TF_NEED_VERBS=0; ++ export TF_CUDA_VERSION=10.0; ++ TF_CUDA_VERSION=10.0; ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda; ++ CUDA_TOOLKIT_PATH=/usr/local/cuda; ++ export TF_CUDNN_VERSION=7; ++ TF_CUDNN_VERSION=7; ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu; ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:4726,log,log,4726,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,1,['log'],['log']
Testability,"ython/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) [2,492 / 2,523] 21 / 38 tests, 7 failed; Testing //deepvariant:model_eval_test [0s (10 actions)] ... (31 actions, 2 running); (06:29:12) FAIL: //deepvariant:model_eval_test (shard 1 of 10) (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/model_eval_test/shard_1_of_10/test.log); (06:29:12) INFO: From Testing //deepvariant:model_eval_test (shard 1 of 10):; ==================== Test output for //deepvariant:model_eval_test (shard 1 of 10):; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/model_eval_test.runfiles/com_google_deepvariant/deepvariant/model_eval_test.py"", line 43, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportErro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:40100,test,testlogs,40100,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:10) FAIL: //deepvariant:tf_utils_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/tf_utils_test/test.log); (06:29:10) INFO: From Testing //deepvariant:tf_utils_test:; ==================== Test output for //deepvariant:tf_utils_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/tf_utils_test.runfiles/com_google_deepvariant/deepvariant/tf_utils_test.py"", line 40, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:23465,test,testlogs,23465,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ywrap_tensorflow.py"", line 58, in <module>; from tensorflow.python.pywrap_tensorflow_internal import *; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:20) FAIL: //deepvariant:modeling_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/modeling_test/test.log); (06:29:20) INFO: From Testing //deepvariant:modeling_test:; ==================== Test output for //deepvariant:modeling_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/modeling_test.runfiles/com_google_deepvariant/deepvariant/modeling_test.py"", line 41, in <module>; import tensorflow as tf; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>; raise ImportError(msg); ImportError: Traceback (most recent call",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:110352,test,testlogs,110352,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"ywrap_tensorflow_internal.py"", line 28, in <module>; _pywrap_tensorflow_internal = swig_import_helper(); File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper; _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description); ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors. for some common reasons and solutions. Include the entire stack trace; above this error message when asking for help.; ================================================================================; (06:29:12) FAIL: //deepvariant:haplotypes_test (see /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/haplotypes_test/test.log); (06:29:12) INFO: From Testing //deepvariant:haplotypes_test:; ==================== Test output for //deepvariant:haplotypes_test:; Traceback (most recent call last):; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/haplotypes_test.runfiles/com_google_deepvariant/deepvariant/haplotypes_test.py"", line 43, in <module>; from third_party.nucleus.testing import test_utils; File ""/root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/bin/deepvariant/haplotypes_test.runfiles/com_google_deepvariant/third_party/nucleus/testing/test_utils.py"", line 47, in <module>; from tensorflow.python.platform import gfile; File ""/root/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>; from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import; File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>; from tensorflow.python import pywrap_tensorflow; File ""/roo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:42275,log,log,42275,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,3,"['Test', 'log']","['Test', 'Testing', 'log']"
Testability,"z""` in the `make_examples` step generated ; `test.examples.tfrecord-000??-of-00064.gz` (shards from 00 to 63). (2) From the command you pasted, it seems like you're directly running inside docker.; If that is the case, you don't need the [-v flags](https://docs.docker.com/storage/volumes/), but you still need to make sure that the files are actually visible when/where you run call_variants.; If you're still running call_variants inside docker (like you did for your make_examples step), please make sure when you can see `test.examples.tfrecord-000??-of-00064.gz` from where you run the command. So, `ls test.examples.tfrecord-000??-of-00064.gz` should see the files. The command you pasted from our run_wgs_case_study_docker.sh example is actually different from the make_examples command you posted first. If you're using that, you need to make sure you're using the [-v flags](https://docs.docker.com/storage/volumes/) correctly and make sure the files are visible to it. (3) I tested with `sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.2` first and directly running the commands inside. I modified from the WES example because it's faster, but WGS should be the same. I can confirm that I was able to run the following steps without any issues:. 1. Start interactive mode so I can use command similar to yours. I'm not considering how I'm getting the data out.; ```; sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.2; ```. 2. Inside the interactive mode, run the following:; ```; MODEL_HTTP_DIR=""https://storage.googleapis.com/deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wes_standard""; DATA_HTTP_DIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata; N_SHARDS=""64"". ## Download extra packages; sudo apt-get -y update; sudo apt-get -y install parallel; sudo apt-get -y install aria2; ## Download models, and test data; # Copy the model files to your local disk.; aria2c -c -x10 -s10 ""${MODEL_HTTP_DIR}""/model.ckpt.d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:1164,test,tested,1164,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,1,['test'],['tested']
Testability,"zed SAM header type, ignoring:; I0129 11:46:16.346041 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/alignments20_sorted.bam with NativeSamReader; I0129 11:46:16.360527 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/NA12878.sorted.vcf.gz with NativeVcfReader; I0129 11:46:16.361952 140471159555840 make_examples.py:946] Common contigs are [u'chr20']; I0129 11:46:16.501434 140471159555840 make_examples.py:1030] Writing examples to prj-NA12878/training-examples/training_set.with_label.tfrecord.gz; 2019-01-29 11:46:16.502209: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728; 2019-01-29 11:46:16.550218: W third_party/nucleus/io/sam_reader.cc:125] Unknown tag pb: in header line, ignoring: @HD VN:1.5 SO:coordinate pb:3.0.1; 2019-01-29 11:46:16.554270: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:; I0129 11:46:16.556066 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/alignments20_sorted.bam with NativeSamReader; I0129 11:46:16.571476 140471159555840 genomics_reader.py:174] Reading prj-NA12878/testdata/NA12878.sorted.vcf.gz with NativeVcfReader; I0129 11:46:20.140141 140471159555840 make_examples.py:782] Found 0 candidates in chr20:1-1000 [3.64s elapsed]; I0129 11:46:20.141022 140471159555840 make_examples.py:782] Found 0 candidates in chr20:1001-2000 [0.00s elapsed]; I0129 11:46:20.141855 140471159555840 make_examples.py:782] Found 0 candidates in chr20:2001-3000 [0.00s elapsed]; I0129 11:46:20.142673 140471159555840 make_examples.py:782] Found 0 candidates in chr20:3001-4000 [0.00s elapsed]; I0129 11:46:20.143475 140471159555840 make_examples.py:782] Found 0 candidates in chr20:4001-5000 [0.00s elapsed]; I0129 11:46:20.144277 140471159555840 make_examples.py:782] Found 0 candidates in chr20:5001-6000 [0.00s elapsed]; I0129 11:46:20.145082 140471159555840 make_examples.py:782] Found 0 candidates in chr20:6001-7000 [0.00s elapsed]; I0129 11:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-458487916:2906,test,testdata,2906,,https://github.com/google/deepvariant/issues/138#issuecomment-458487916,1,['test'],['testdata']
Testability,"zel-out/k8-opt/testlogs/deepvariant/realigner/aligner_test/test.log; //deepvariant/realigner:realigner_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/realigner_test/test.log; //deepvariant/realigner:window_selector_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/window_selector_test/test.log; //deepvariant/realigner/allele_count_linear:generate_trained_model_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/generate_trained_model_test/test.log; //deepvariant/realigner/allele_count_linear:model_evaluation_test FAILED in 0.5s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/allele_count_linear/model_evaluation_test/test.log; //deepvariant/realigner/python:debruijn_graph_wrap_test FAILED in 0.2s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/realigner/python/debruijn_graph_wrap_test/test.log; //deepvariant:make_examples_test FAILED in 2 out of 2 in 0.4s; Stats over 2 runs: max = 0.4s, min = 0.4s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log; /root/.cache/bazel/_bazel_root/ce699a1ca024b3cb0e615720516790f5/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log; //deepvariant:model_eval_test FAILED in 10 out of 10 in 0.4s; Stats over 10 runs: max = 0.4s, min = 0.3s, avg = 0.4s, dev = 0.0s; /root/.cache/bazel/_bazel_root/ce",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-463596181:122525,test,testlogs,122525,,https://github.com/google/deepvariant/issues/145#issuecomment-463596181,2,['test'],"['test', 'testlogs']"
Testability,"{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.vcf_candidate_importer.calling_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.calling_examples.tfrecord.gz-00001-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.postprocess_single_site_output.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/golden.training_examples.vcf:##DeepVariant_version=1.6.0; ./deeptrio/testdata/HG002_ONT_deeptrio.examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ./deeptrio/testdata/golden.vcf_candidate_importer.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/alt_aligned_pileup.golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [140, 199, 8], ""channels"": [1, 2, 3, 4, 5, 6, 9, 10]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00000-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./deeptrio/testdata/golden.training_examples.tfrecord.gz-00001-of-00003.example_info.json:{""version"": ""1.6.0"", ""shape"": [300, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ./Dockerfile.deepsomatic:ARG VERSION_DEEPSOMATIC=1.6.0; ./deepvariant/testdata/golden.vcf_candidate_importer_calling_examples.tfrecord.example_info.json:{""version"": ""1.6.0"", ""shape"": [100, 221, 6], ""channels"": [1, 2, 3, 4, 5, 6]}; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040:3915,test,testdata,3915,,https://github.com/google/deepvariant/issues/830#issuecomment-2192031040,5,['test'],['testdata']
Testability,"} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; > wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; >; > Run make_examples:; >; > OUTPUT_DIR=""${PWD}/quickstart-output""; > mkdir -p ""${OUTPUT_DIR}""; >; > python bin/make_examples.zip \; > --mode calling \; > --ref ""${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta"" \; > --reads ""${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam"" \; > --regions ""chr20:10,000,000-10,010,000"" \; > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"" \; > --channels ""insert_size""; >; > (To figure out which flags you need to add for each model, you can read; > https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L253; > . Sorry that we don't have better documentation than that right now); >; > For how to run this with multiple shards, and how to run the rest of the; > commands, please read; > https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md; >; > I just tested the steps above and confirmed that it worked for me on; > v1.4.0, at least for the make_examples step.; > If you encounter more issues with other steps, please feel free to ask; > again. I'd be happy to help.; >; > Note that I don't plan to put this into an official documentation page; > now, because that adds to our maintenance burden to keep it up to date.; > Given that we have the Docker/Singularity solution that works generally; > well for our users, I don't expect many of our users to need to use; > pre-built binaries. @zivlang <https://github.com/zivlang> thank you for; > your question so I have a chance to test it again and document it here.; > Hopefully this is helpful for you. Happy to answer more questions if you; > encounter more problems.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/590#issuecomment-1322695241>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALBF75YWC2I4SZFXBKRL4KTWJPVBNANCNFSM6AAAAAASFZYT",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566:3483,test,tested,3483,,https://github.com/google/deepvariant/issues/590#issuecomment-1322701566,1,['test'],['tested']
Testability,"}/tempdir"" \; --save_main_session \; --region us-east1; ```. ```; time gcloud compute tpus create ${USER}-demo-tpu \; --network=default \; --version=2.3 \; --zone=us-central1-c; ```. # Below is the main difference from the instruction in r0.9: How to look up the TPU_IP:. Given that it seems like we didn't have the right library to properly look up `tpu_name` (`pip install cloud-tpu-client` is needed, it seems). I will try to fix this in our future Dockerfile and test it. But for now, I'll show up to manually resolve the tpu_name. First, install this:; ```; pip3 install cloud-tpu-client; ``` . And then:. ```; TPU_NAME=""${USER}-demo-tpu""; TPU_IP=$(python3 -c ""import tensorflow as tf; print(tf.distribute.cluster_resolver.TPUClusterResolver(tpu=['${TPU_NAME}'], zone='us-central1-c').get_master())""); ```; Check the IP:; ```; $ echo ${TPU_IP}; grpc://10.33.164.2:8470; ```. ```; ( time sudo docker run \; -v /home/${USER}:/home/${USER} \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/model_train \; --use_tpu \; --master=""${TPU_IP}"" \; --dataset_config_pbtxt=""${OUTPUT_BUCKET}/training_set.dataset_config.pbtxt"" \; --train_dir=""${TRAINING_DIR}"" \; --model_name=""inception_v3"" \; --number_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=512 \; --learning_rate=0.008 \; --start_from_checkpoint="""" \; ) 2>&1 | tee ""${LOG_DIR}/train.log""; ```. This now seems to be able to see the TPU. But right now I seem to be having some issue of using ${GCS_PRETRAINED_WGS_MODEL} as `--start_from_checkpoint`, so I might need to continue looking into why. And, at this point, I'm done for now. So I manually deleted the TPU:; ```; gcloud compute tpus delete ${TPU_NAME} --zone us-central1-c; ```. ---. @mattwood-codifiedgenomics Thanks for reporting this. I don't think the `--tpu_name` code path is commonly used. I'll see if I can get the right dependencies installed, and see if I can get proper unit tests to cover this. At the very least, I'll try to get a manual run to succeed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/469#issuecomment-871936544:7075,log,log,7075,,https://github.com/google/deepvariant/issues/469#issuecomment-871936544,2,"['log', 'test']","['log', 'tests']"
Usability," GT from the two runs indicates that the neural network assesses the probability of 0/1 and 1/1 calls to be very similar (in the first entry they are rounded identically in the PL field). Your collaborator calls do have a small lean toward 1/1. DeepVariant should give identical results when the same version is run on the same hardware platform (e.g. CPU-CPU). However, there can be floating point differences with very minor (almost never at the level of the variant call, but mostly at the GQ level) between compute platforms. Can you confirm that you and your collaborator ran the exact same version of DeepVariant on the same compute platform, or if there might be a difference (e.g. CPU vs Parabricks GPU). 2) **Why is the call here 0/1 given the pileup**. The IGV screenshot you've attached certainly looks 1/1, and all experts will assess it as a 1/1 from what is shown. We have observed that in rare circumstances, DeepVariant will occasionally call such positions as 0/1 or 0/0 or to decrease the confidence in the calls of certain positions. The signature for this seems to be when DeepVariant assesses a region to be likely to be a segmental duplication or structural variant. Signatures for that often involve a haplotype with dense variants while another haplotype is almost entirely reference, or a high amount of discordant read mapping or low MAPQ. Although your pileup does have a discordantly mapped read present, those patterns generally aren't present. For some reason, in both your and your collaborator's run, DeepVariant seems to think that this region is difficult to call. . In these cases, I'm always interested to see whether this could highlight a bug in DeepVariant, or if it reflects some learning of the model. Would there be any chance for you to share the small window of the BAM file here (maybe +/- 500 bp from the position). People in the team would be interested in whether this could detect any sort of edge case DeepVariant isn't handling well. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/592#issuecomment-1332875716:1909,learn,learning,1909,,https://github.com/google/deepvariant/issues/592#issuecomment-1332875716,1,['learn'],['learning']
Usability," There were 1689 SNP FN and 832 SNP FP. The same sample with the current version of DeepVariant has 1328 SNP FN and 749 SNP FP. . For Indels, the PrecisionFDA submission has 4175 Indel FN and 2839 Indel FP. The current version of DeepVariant has 1428 Indel FN and 924 Indel FP, a reduction in error of almost 50% compared to the most accurate Indel entry in Precision FDA Truth Challenge. The DeepVariant paper has the evaluation numbers for the first open source version (https://www.nature.com/articles/nbt.4235) and compares these results of this with the PrecisionFDA entries. 3) There are good other checks which can provide an indirect estimate of quality and which do not require a particular characterized samples. For example, you can call the same sample with GATK and DeepVariant and take the calls only made in one sample or the other. Comparison of the TiTv for those calls present on one or the other can tell you which (on average) has higher quality (indicated by higher TiTv in the singletons for that caller). We perform these evaluations internally as well and would welcome feedback about a similar analysis from you on your own samples. . 4) When DeepVariant evaluates a candidate, it can call it as a homozygous variant, heterozygous variant, or indicate that it believes that although there is evidence for a variant at a position, the true call for this position is reference (0/0). In the paper referenced, I believe that these reference calls were considered as failing a filter. However, it is not the case that these are variant calls that were made and had to be removed. Directly taking the genotype for each call would arrive at the same number of variants. In effect, these were not really variant calls to filter. They were rows in the VCF that already did not indicate variation. . We would be enthusiastic to collaborate with you to benchmark DeepVariant against other methods on your own samples with various preparations and coverages if you like. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-476392585:2159,feedback,feedback,2159,,https://github.com/google/deepvariant/issues/165#issuecomment-476392585,1,['feedback'],['feedback']
Usability," for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832:2532,learn,learning,2532,,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832,1,['learn'],['learning']
Usability," on many other aspects such as how to pull multiple workers to orchestrate a distributed workflow, or how to run with GPU (which involves installing GPU driver, using the binaries that are built for GPU, etc).; If you want to run on GPU, and if you have everything set up already (such as installing GPU driver correctly), you should be able to do it pretty much the same way. But instead of `sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}""`, you'll pull from gcr.io/deepvariant-docker/**deepvariant_gpu** which is built for GPU.; We have also documented it here:; https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-details.md#call_variants in case you need to build the binaries yourself. Note that even though using GPUs is faster, the overall cost might not be better depending on many other factors. Again, you can look at the [GCP Cloud runner](https://cloud.google.com/genomics/docs/tutorials/deepvariant) as an example of how they configure their run.; If you end up doing more experiments to compare different configurations in your workflow, we would love to learn more about it as well. In addition to the [GCP Cloud runner](https://cloud.google.com/genomics/docs/tutorials/deepvariant) that @nmousavi 's team maintains, we also have seen other examples such as https://github.com/atgenomix/deepvariant-on-spark (and their [WGS case study](https://github.com/atgenomix/deepvariant-on-spark/blob/master/docs/wgs-case-study.md) reports run time as well). In terms of how much details we include on the DeepVariant GitHub page --; Even though I'm personally very interested in the performance and cost of these implementations, I also need to consider the trade-off of the amount of details we include, because too much information can also end up being confusing. If you have more suggestions on how to organize the documentation better in the future, please let me know. Even now it's already a bit messy and I would like to simplify it further. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461426712:1301,learn,learn,1301,,https://github.com/google/deepvariant/issues/151#issuecomment-461426712,2,"['learn', 'simpl']","['learn', 'simplify']"
Usability," price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new mode",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832:2026,simpl,simplified,2026,,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832,1,['simpl'],['simplified']
Usability," this. I'll share my steps below so you can take a look. . ----. Here are my steps trying to test Singularity on CentOS 8. Get a machine:; ```; gcloud compute instances create ""${USER}-centos8"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""centos-8"" \; --image-project ""centos-cloud"" \; --machine-type ""e2-standard-16"" \; --boot-disk-size ""200G"" \; --zone ""us-west1-b""; ```. ssh into the machine:; ```; gcloud compute ssh ${USER}-centos8; ```. Check OS version:; ```; [pichuan@pichuan-centos8 ~]$ cat /etc/os-release; NAME=""CentOS Linux""; VERSION=""8""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""8""; PLATFORM_ID=""platform:el8""; PRETTY_NAME=""CentOS Linux 8""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:8""; HOME_URL=""https://centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/""; CENTOS_MANTISBT_PROJECT=""CentOS-8""; CENTOS_MANTISBT_PROJECT_VERSION=""8""; ```. I installed singularity on the machine following instructions on https://sylabs.io/guides/3.7/admin-guide/installation.html#installation-on-linux. Confirmed the version:; ```; [pichuan@pichuan-centos8 ~]$ singularity --version; singularity version 3.7.0-1.el8; ```. I'm using the data in Quick Start to test. I downloaded data in the Quick Start: https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md. Then, I ran:; ```; BIN_VERSION=1.1.0. singularity build deepvariant.sif docker://google/deepvariant:${BIN_VERSION}. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1; ```. After this, examine the content in ""${OUTPUT_DIR}/intermediate_results_dir"". ```; [pi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/296#issuecomment-767294612:1630,guid,guide,1630,,https://github.com/google/deepvariant/issues/296#issuecomment-767294612,1,['guid'],['guide']
Usability,") that could affect this. I'll share my steps below so you can take a look. . ----. Here are my steps trying to test Singularity on CentOS 8. Get a machine:; ```; gcloud compute instances create ""${USER}-centos8"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""centos-8"" \; --image-project ""centos-cloud"" \; --machine-type ""e2-standard-16"" \; --boot-disk-size ""200G"" \; --zone ""us-west1-b""; ```. ssh into the machine:; ```; gcloud compute ssh ${USER}-centos8; ```. Check OS version:; ```; [pichuan@pichuan-centos8 ~]$ cat /etc/os-release; NAME=""CentOS Linux""; VERSION=""8""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""8""; PLATFORM_ID=""platform:el8""; PRETTY_NAME=""CentOS Linux 8""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:8""; HOME_URL=""https://centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/""; CENTOS_MANTISBT_PROJECT=""CentOS-8""; CENTOS_MANTISBT_PROJECT_VERSION=""8""; ```. I installed singularity on the machine following instructions on https://sylabs.io/guides/3.7/admin-guide/installation.html#installation-on-linux. Confirmed the version:; ```; [pichuan@pichuan-centos8 ~]$ singularity --version; singularity version 3.7.0-1.el8; ```. I'm using the data in Quick Start to test. I downloaded data in the Quick Start: https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md. Then, I ran:; ```; BIN_VERSION=1.1.0. singularity build deepvariant.sif docker://google/deepvariant:${BIN_VERSION}. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1; ```. After this, examine the content in ""${OUTPUT_DIR}/intermediate_re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/296#issuecomment-767294612:1613,guid,guides,1613,,https://github.com/google/deepvariant/issues/296#issuecomment-767294612,1,['guid'],['guides']
Usability,"), can return None depending on; # the environment; make sure we don't crash when that occurs.; with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):; with resources.ResourceMonitor() as monitor:; #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment; self.assertEqual(monitor.metrics().physical_core_count, 20); --------------------------------. ##########################################################################; # //deepvariant/realigner/allele_count_linear:generate_trained_model_test; # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8; ##########################################################################; # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python; python -c ""import numpy"" # prequests of TF 1.12.0; python -c ""import scipy"" # prequests of TF 1.12.0; pip install Cython --force-reinstall --no-deos; pip install scikit-learn --force-reinstall --no-deos; # build from source; wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz; tar zxvf 0.20.2.tar.gz; cd scikit-learn-0.20.2; python setup.py bdist_wheel; # verify; python -c ""from sklearn.externals import joblib"". ##########################################################################; # //deepvariant/labeler:haplotype_labeler_test; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; ##########################################################################; # fail due to mock data, open an issue in github; https://github.com/google/deepvariant/issues/154. ##########################################################################; # //deepvariant:make_examples_test; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:21778,learn,learn,21778,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,1,['learn'],['learn']
Usability,".; with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):; with resources.ResourceMonitor() as monitor:; #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment; self.assertEqual(monitor.metrics().physical_core_count, 20); --------------------------------. ##########################################################################; # //deepvariant/realigner/allele_count_linear:generate_trained_model_test; # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8; ##########################################################################; # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python; python -c ""import numpy"" # prequests of TF 1.12.0; python -c ""import scipy"" # prequests of TF 1.12.0; pip install Cython --force-reinstall --no-deos; pip install scikit-learn --force-reinstall --no-deos; # build from source; wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz; tar zxvf 0.20.2.tar.gz; cd scikit-learn-0.20.2; python setup.py bdist_wheel; # verify; python -c ""from sklearn.externals import joblib"". ##########################################################################; # //deepvariant/labeler:haplotype_labeler_test; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; ##########################################################################; # fail due to mock data, open an issue in github; https://github.com/google/deepvariant/issues/154. ##########################################################################; # //deepvariant:make_examples_test; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; # internvaltree v3 has some API changes with v2; ###########################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:21865,learn,learn,21865,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,2,['learn'],['learn']
Usability,".g.vcf.gz|grep -C 3 ""10764356"" . chromosome_1	10764353	.	C	T,<*>	27.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:27:162:100,62,0:0.382716,0:27,0,51,990,990,990; chromosome_1	10764354	.	A	<*>	0	.	END=10764354	GT:GQ:MIN_DP:PL	0/0:50:162:0,300,2999; chromosome_1	10764355	.	C	T,<*>	26.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:162:100,62,0:0.382716,0:26,0,60,990,990,990; chromosome_1	10764356	.	A	T,<*>	26.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:161:98,63,0:0.391304,0:26,0,64,990,990,990; chromosome_1	10764357	.	T	<*>	0	.	END=10764357	GT:GQ:MIN_DP:PL	0/0:50:162:0,300,2999; chromosome_1	10764358	.	T	C,<*>	33.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:33:172:98,63,0:0.366279,0:33,0,69,990,990,990; chromosome_1	10764359	.	T	<*>	0	.	END=10764381	GT:GQ:MIN_DP:PL	0/0:50:169:0,300,2999. ```; To me in the 3 samples it's the same site that is present. . Here another one (where the SNP is RefCall in one sample and PASS in another). ```; zgrep -w ""chromosome_2"" output.g.vcf.gz|grep -C 2 ""9780248""; chromosome_2	9780195	.	T	<*>	0	.	END=9780244	GT:GQ:MIN_DP:PL	0/0:50:294:0,300,2999; chromosome_2	9780245	.	GGT	G,<*>	37.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:36:294:161,131,0:0.445578,0:37,0,41,990,990,990; chromosome_2	9780248	.	A	<*>	0	.	END=9780249	GT:GQ:MIN_DP:PL	0/0:50:163:0,270,2939; chromosome_2	9780250	.	T	TTG,<*>	36.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:298:161,133,0:0.446309,0:36,0,34,990,990,990; chromosome_2	9780251	.	A	<*>	0	.	END=9780281	GT:GQ:MIN_DP:PL	0/0:50:272:0,300,2999; ```; In this second case, I don't understand why DeepVariant did not even consider there might be a variant there, as the bam clearly shows many reads mapping in that position with a variant site (it's the middle T flanked by 2 homozygous T sites). ![example2](https://user-images.githubusercontent.com/23341393/75358443-2ddbef00-58b3-11ea-9170-dd996a53386b.png). Now I know that calling SNP (in the sense of single nucleotide) variation in the vicinity of more complex events is known to be tricky, therefore this might not be an issue with DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/278#issuecomment-591476042:3374,clear,clearly,3374,,https://github.com/google/deepvariant/issues/278#issuecomment-591476042,1,['clear'],['clearly']
Usability,"/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3; > -v; > /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result; > google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --reads; > /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam; > --ref; > /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/hg38_chrM.fa; > --report_title MITO60_Stats --sample_name MITO60 --output_vcf; > /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result; > --model_type ONT_R104; >; >; > On Wed, Jun 12, 2024 at 12:03 PM Pi-Chuan Chang ***@***.***>; > wrote:; >; >> And, just in case the documentation isn't clear:; >>; >> This part:; >>; >> sudo docker run \; >> -v ""${INPUT_DIR}"":""/input"" \; >> -v ""${OUTPUT_DIR}"":""/output"" \; >> google/deepvariant:""${BIN_VERSION}"" \; >> ...; >>; >> The variable BIN_VERSION was specified in earlier in the steps:; >>; >> BIN_VERSION=""1.6.1""; >>; >> So, in Unix command it's equivalent to:; >>; >> google/deepvariant:""1.6.1"" \; >>; >> —; >> Reply to this email directly, view it on GitHub; >> <https://github.com/google/deepvariant/issues/829#issuecomment-2162210763>,; >> or unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/BDQL2ZE35INJI4WP7BHRNK3ZG7TVPAVCNFSM6AAAAABJFTFWYKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDCNRSGIYTANZWGM>; >> .; >> You are receiving this because you were mentioned.Message ID:; >> ***@***.***>; >>; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/829#issuecomment-2162485508:4235,clear,clear,4235,,https://github.com/google/deepvariant/issues/829#issuecomment-2162485508,1,['clear'],['clear']
Usability,"/github.com/cschin/DeepDiveDeepVariant), you'll see him using `--norealign_reads` which skips the preprocessing step described in the paper. That's why he's getting the `T` which a is a possible sequencing error. 2) The general realignment heuristic is the following: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/realigner.py#L439-L454. 3) The ploidy dictates the most likely haplotypes which is 2 :). 3) The haploytype realignment also been optimized a bit since that paper. Take a look at this section of the code: https://github.com/google/deepvariant/blob/r0.8/deepvariant/realigner/fast_pass_aligner.cc#L117-L166. 4) Yes, the realignment is basically used to update the reads' interpretation via the best-representative haplotype, trying to approach what might be closest-truth if the sequencer were relatively perfect. It's basically a way to correct. 5) Variant calling comes later, and is performed via the following, which is called from [make_examples.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/make_examples.py):. https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_caller.py ; https://github.com/google/deepvariant/blob/r0.8/deepvariant/variant_calling.cc. 6) The [predict(...) in call_variants.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/call_variants.py#L374-L378) emits the `genotype_probabilities`, which Jason used to demonstrate the low probability of `T` as a sequencing error. Just like any machine-learning trained model, if it's not seen the pattern before it will not predict it with a high match - no real magic here :). 7) It might help to read the [deepvariant.proto](https://github.com/google/deepvariant/blob/r0.8/deepvariant/protos/deepvariant.proto), which you can treat like a spec-design document of the general idea behind DeepVariant. The [details doc](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details.md) might help, but it's a bit general. Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/197#issuecomment-512112524:1678,learn,learning,1678,,https://github.com/google/deepvariant/issues/197#issuecomment-512112524,1,['learn'],['learning']
Usability,"/local/lib/python3.8/dist-packages/gast/gast.py:15(create_node); 155316 0.108 0.000 0.183 0.000 /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:6314(get_default_graph); 6015 0.105 0.000 0.105 0.000 {built-in method tensorflow.python.util._tf_stack.extract_stack_for_op}; 6015 0.104 0.000 0.149 0.000 /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1879(_NodeDef); ```. What I'm seeing above is something quite interesting. The execution seems heavy on [eager execution rather than graph execution](https://blog.tensorflow.org/2018/08/code-with-eager-execution-run-with-graphs.html), which could be the culprit. The thing is that there are some quick ways now to make it fast with almost no major code-rewrite, though there are other natural optimizations that are relatively obvious given the analysis. For the `make_examples` analysis, the task is much simpler to fix by localizing I/O through just a shared memory model and/or pass-by-reference approach, as illustrated by the call distribution (with an eye on the serialization/deserialization of ProtoBuf if that becomes more heavily used):. ```; Wed May 17 17:51:33 2023 make_examples_profile.txt. 2790682 function calls (2732833 primitive calls) in 11.860 seconds. Ordered by: internal time; List reduced from 11503 to 100 due to restriction <100>. ncalls tottime percall cumtime percall filename:lineno(function); 171/168 1.927 0.011 1.940 0.012 {built-in method _imp.create_dynamic}; 3159 0.930 0.000 0.930 0.000 {method 'read' of '_io.BufferedReader' objects}; 19018 0.694 0.000 0.694 0.000 {built-in method posix.stat}; 2 0.586 0.293 0.586 0.293 {method 'counts' of 'deepvariant.python.allelecounter.AlleleCounter' objects}; 3136 0.475 0.000 0.475 0.000 {built-in method marshal.loads}; 3136 0.422 0.000 0.422 0.000 {built-in method io.open_code}; 15152 0.183 0.000 0.183 0.000 {method 'reduce' of 'numpy.ufunc' objects}; 3136 0.164 0.000 2.265 0.001 <frozen importlib._bootstrap_external>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/650#issuecomment-1552327826:6092,simpl,simpler,6092,,https://github.com/google/deepvariant/issues/650#issuecomment-1552327826,1,['simpl'],['simpler']
Usability,"1. Docker installation is not DeepVariant specific. You may follow steps from the official docker website https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository; 2. From the output it looks like you run it on a machine with 2 cores. In Google tutorial n1-standard-64 instance is used which has 64 cores. ; 3. From the output of the last command it is not clear what the error is. Could you post the command you used for creating an instance? It could be that call_variants command ran out of memory.; 4. Although Google tutorial page contains the pricing for pre-emptible instances it is only given for the reference. It is not recommended to run this tutorial on a pre-emptible instances because in the case the instance is preemted the job cannot restart automatically. More complex configuration (like Kubernetes) is required in order to use pre-emptible instances.; 5. Recently a new version of DeepVariant was released, so instead of using 0.9.0 the new version 1.1.0 and docker path google/deepvariant should be used. Although, using the latest version is preferred the old 0.9.0 should work as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/399#issuecomment-749327121:376,clear,clear,376,,https://github.com/google/deepvariant/issues/399#issuecomment-749327121,1,['clear'],['clear']
Usability,"1. The type of the data is ONT_R9 simplex.; 2. The basecaller is guppy. ; 3. Threads are set to 48.; I also provide the code as below. Thank you for your help. ; `BIN_VERSION=""1.6.1""; sudo apt -y update; sudo apt-get -y install docker.io; sudo docker pull google/deepvariant:""${BIN_VERSION}""; INPUT_DIR=""/home/user/Masaüstü/BEYZA/input"" OUTPUT_DIR=""/home/user/Masaüstü/BEYZA/output"" THREADS=48 MODEL_NAME=""ONT_R104""; sudo docker run -v ""/home/massive/Desktop/beyza/input"":""/input"" -v ""/home/massive/Desktop/beyza/OUTPUTDEEP"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=ONT_R104 --ref=""/input/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads=""/input/NA12878-minion-ul_GRCh38.bam"" –output_vcf=""/output/deep.vcf"" --threads=48; `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/814#issuecomment-2089912166:34,simpl,simplex,34,,https://github.com/google/deepvariant/issues/814#issuecomment-2089912166,1,['simpl'],['simplex']
Usability,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU; ```; The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name; 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX); 3) contig name or * for unmapped; 4) mapped position of base 1 of a read on the reference sequence; 5) MAPQ mapping quality; 6) CIGAR string describing insertions and deletions; 7) Name of mate; 8) Position of mate; 9) Template length; 10) Read Sequence; 11) Read Quality; 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658769491:2509,learn,learning,2509,,https://github.com/google/deepvariant/issues/682#issuecomment-1658769491,1,['learn'],['learning']
Usability,"> 1. Any idea how I might estimate the expected run time?. The run time of `make_examples` step can be affected by many factors, such as the coverage(depth) of the input. One component in make_examples is local realignment, which can be affected by things like depth, read length, etc. Currently I think that might be causing the biggest variance of the runtime of make_examples. This makes it hard for me to give general estimation guidelines.; Can you give us a bit more information on your BAM? Is it WGS or WES? Which Illumina sequencing machine is it from?; If you are okay with sharing the BAM header, it'll help too. If it's easier to share via email, you can email pichuan@google.com. > 2. Any idea of how I do a better job sizing compute resources?. On the GCP DeepVariant tutorial page:; https://cloud.google.com/life-sciences/docs/tutorials/deepvariant; You can see some numbers of runtime and cost estimates on GCP. This might help give you some sense of what type of machine you can choose. Since you're running on AWS, the cost might change based on pricing. > 3. How do I know if docker is making progress or not?. Currently, our one-step script should be outputting some logs as it goes. If make_examples is still running, you should see lines of logs coming out, showing there's progress. There's likely room for improvement on how we show this progress. If you have suggestions or bug reports, please let us know. > I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good!. Sorry to hear that the logs are not coming out promptly. If it's possible, can you tell us where did the log get stuck?. > 4. I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/260#issuecomment-573487475:433,guid,guidelines,433,,https://github.com/google/deepvariant/issues/260#issuecomment-573487475,1,['guid'],['guidelines']
Usability,"> @dkurt Keeping them in the image is fine! I'm actually more curious about whether I can get rid of that big model.ckpt.data-00000-of-00001 file. :). @pichuan, that's good question. Checkpoint is used to restore model training and that's why it takes a lot of size. Probably, internally it contains not just weights but also gradients and intermediate outputs for layer. `.pb` model can be used for inference but using TensorFlow 1.x API, not sure about Estimator, unfortunately. I moved OpenVINO conversion into runtime anyway - that seems now simpler and doesn't oversize an image. > @dkurt One more question for you -- do you see any downside of enabling --use_openvino as default in our CPU run? Once this is built into our CPU docker image, it'll be nice to have it as default. I want to know if it might crash on non-Intel hardware or not. (I can also test it myself, but haven't got around to do that yet). Just tried the image on [n2d-standard-8](https://cloud.google.com/compute/docs/machine-types#n2d_machine_types) from GCP and it works fine through OpenVINO backend (AMD EPYC 7B12). So seems like we can freely turn OpenVINO by default for CPU only environment. Shall I do it in this PR or you can switch it separately?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-735703602:546,simpl,simpler,546,,https://github.com/google/deepvariant/pull/363#issuecomment-735703602,1,['simpl'],['simpler']
Usability,"> @leedchou is it possible for you to install Docker and/or singularity and run DeepVariant using that?; > ; > This may be an easier route than enabling builds on Ubuntu16.04. Currently we only build/test on Ubuntu 20.04. Sorry, I am a beginner of Docker. I've learned something about docker technology in the past two days, figuring out what you mean. Now I can build an iamge that does not depend on operating system of my device. Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/591#issuecomment-1334703761:261,learn,learned,261,,https://github.com/google/deepvariant/issues/591#issuecomment-1334703761,1,['learn'],['learned']
Usability,"> Hi @X1angyang; > ; > The model is InceptionV3. You can see the layers of one of the DeepVariant models like this:; > ; > ```; > import tensorflow as tf; > ; > !gsutil cp gs://deepvariant/models/DeepVariant/0.10.0/DeepVariant-inception_v3-0.10.0+data-wgs_standard/model* /tmp/; > checkpoint_path = '/tmp/model.ckpt'; > ; > reader = tf.compat.v1.train.NewCheckpointReader(checkpoint_path); > shape_map_for_layers = reader.get_variable_to_shape_map(); > print(shape_map_for_layers); > ```; > ; > I just tested that in Colab (https://colab.research.google.com/).; > ; > However, reimplementing all of DeepVariant from bam to output VCF would be a huge project. If you are interested in something smaller to get started, I'd like to bring this blog post to your attention: https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction/.; > It has an associated Colab notebook that walks through some smaller but still challenging examples of how to use genomic data in machine learning using TensorFlow and Nucleus.; > ; > I hope that helps!; > Maria. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/328#issuecomment-663306398:1031,learn,learning,1031,,https://github.com/google/deepvariant/issues/328#issuecomment-663306398,1,['learn'],['learning']
Usability,"> Hi @linlin-coder , Thank you for bringing up this issue.; > ; > I noticed that you're working on PacBio data.; > ; > The reason why this is happening is:; > ; > In v1.3.0 or older, DeepVariant didn't have the read haplotagging functionality built in. If you see https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md , you'll see that we asked our users to run DeepVariant --> WhatsHap --> DeepVariant with HP information to get the best accuracy.; > ; > Starting from v1.4.0, **DeepVariant** has the read haplotagging functionality built in. However, **DeepTrio** doesn't have this yet, even in the latest version. That's why in https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-pacbio-case-study.md , you'll see this sentence; > ; > > The `--use_hp_information` arg makes use of a phased reads, thus allowing a further improvement of the accuracy. You can use tools like whatshap to phase.; > ; > So, for now, if you want to get the best accuracy using DeepTrio, our suggestion will be: Run DeepVariant first --> Use WhatsHap to get HP tags for your read --> Run DeepTrio with the `--use_hp_information` tag.; > ; > I'm sorry that we were not being a lot more clear in our documentation. In our next release (plan to be out before the end of this year), we will have the read haplotagging feature directly built in in DeepTrio as well, so that you won't have to worry about having to run WhatsHap in between, starting from our next release.; > ; > @linlin-coder Let me know if you have more questions that I can help clarify. Thanks!. Thank you very much for your description of all the details of Deeptrio in the mutation detection environment. In the future, I will follow the process you suggested to redo the mutation detection. If there are no accidents, I will reply to you in the next two days. Thank you again",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/689#issuecomment-1661404840:1213,clear,clear,1213,,https://github.com/google/deepvariant/issues/689#issuecomment-1661404840,1,['clear'],['clear']
Usability,"> Hi @themkdemiiir,; > ; > Although, it is absolutely possible to split the bam into chromosomes and run them separably there are better way to make a pipeline. There are 3 binaries that DeepVariant executes: make_examples, call_variants, and postprocess_variants. You may run those binaries from the docker.; > ; > * make_examples is highly parallelized already. You may shard it to as many shards as needed by simply specifying the output of make_examples as sharded by adding @ to the file name and add `--task` flag that specifies the task number for each shard.; > * call_variants will be run with the same number of shards.; > * postprocess_variants has to be run in a single process.; > ; > Here is an example of running shard 11 of make_examples and call_variants broken into 200 shards:; > ; > ```; > bin/make_examples \; > --examples /tmn/your_examples.tfrecord@200.gz \; > --mode calling \; > --reads /tmp/your_input_bam.bam \; > --realign_reads \; > --ref=/tmp/your_reference.fna \; > --task=11; > ; > # Input for each instance of call_variants is the output of one instance of make_examples:; > bin/call_variants.par \; > --batch_size=32 \; > --checkpoint <Path to the model checkpoint or saved model>.ckpt \; > --examples /tmp/your_examples.tfrecord-00011-of-00200.gz \; > --outfile /tmp/your_call_variants_output.cvo.tfrecord-00011-of-00200.gz; > ; > # Input for for postprocess would be the output of all instances of call_variants:; > /tmp/your_call_variants_output.cvo.tfrecord@200.gz; > ```. So how could I merge the output of the call_variants step?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/744#issuecomment-1855569624:412,simpl,simply,412,,https://github.com/google/deepvariant/issues/744#issuecomment-1855569624,1,['simpl'],['simply']
Usability,"> Hi @vera-gomes , One possible way to get around the RAM issue is to split the run into two or more, using the `--regions` flag (For example, one run can run the first 8 chromosomes, and the second run can run the rest, or something like that). And then at the end you can combine the VCFs. Perhaps a user-friendly way to implement this is to let deepvariant split the job by chromosomes/regions automatically? If this mainly affects the post processing step, perhaps just make this step automatically process the output by chromosome/regions of a fixed window size?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/868#issuecomment-2293266591:302,user-friendly,user-friendly,302,,https://github.com/google/deepvariant/issues/868#issuecomment-2293266591,1,['user-friendly'],['user-friendly']
Usability,"> I'm not very familiar with SINGULARITY_CACHEDIR. But, in your command, if you're running it 3 times, you should use a different --intermediate_results_dir. Output of `make_examples` will be written to that directory. So, if you use the same intermediate_results_dir, that might explain why your data is corrupted. Thank you. I will try and feedback to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/564#issuecomment-1253259881:342,feedback,feedback,342,,https://github.com/google/deepvariant/issues/564#issuecomment-1253259881,1,['feedback'],['feedback']
Usability,"> Is there a way that I could just modify the gcp_deepvariant_runner.py script . Yes, you can easily make deepvariant_runner to generate gVCF output by using `--gvcf_outfile` flag, please refer to [our documentation](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration) for more details. > I'm guessing I would need to fork the gcp-deepvariant-runner repo. That's one way to do it, however, the easier way is to use our docker image; in that case launching DeepVariant will be as simple as running a `gcloud ...` command. Again please refer to [our documentations](https://cloud.google.com/genomics/docs/tutorials/deepvariant#before_you_begin) for more details.; The only issue at the moment is that deepvariant_runner is still working with previous version of DeepVariant (0.7.2) and we are in the process of releasing a new docker image that will be compatible with the latest DeepVairant (0.8.8). Please let me know if you have any difficulties with deepvariant_runner.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/193#issuecomment-508203315:520,simpl,simple,520,,https://github.com/google/deepvariant/issues/193#issuecomment-508203315,1,['simpl'],['simple']
Usability,"> Not at this time. Are there specific dependencies in Ubuntu 20.04 that are required? Or an older version of DV that has been tested on 18.04?. @williambrandler You can try v1.1.0, which builds on 18.04: https://github.com/google/deepvariant/tree/r1.1. In v1.2.0, we updated to Python3.8. When I tested this, I was trying to get Python3.8 to work on Ubuntu18.04, but didn't quite get it to work. Not saying it's impossible, but we think it was easiest to update the whole Dockerfile setup to run on Ubuntu20.04 rather than trying to get it to also work on 18.04. > ; > Would also like some clarification on this statement to help me figure out what is going on,; > ; > `Build clif binary from scratch. Might not be ideal because it installs a bunch of dependencies, but this works fine when we used this in a Dockerfile because we don't do build-prereq.sh in the final image.`. For the build-prereq.sh statement -- what it means is: As part of that script, it runs https://github.com/google/deepvariant/blob/r1.2/tools/build_clif.sh which builds [CLIF](https://github.com/google/clif) from scratch. CLIF is required when you build DeepVariant code. The build_clif.sh script installs a bunch of stuff on your machine. If you directly run ./build-prereq.sh on your machine, you just need to be aware that those things are installed as a side effect. But, if you're using our Dockerfile and using docker build, we only carry over the built binaries to the next stage. So the extra things installed by CLIF wasn't carried over. Hopefully that's more clear?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/476#issuecomment-896293199:1547,clear,clear,1547,,https://github.com/google/deepvariant/issues/476#issuecomment-896293199,1,['clear'],['clear']
Usability,"> Thanks so much, that makes the path forwards a lot clearer. Reading between the lines, is (3) the reason we are advised to shuffle the validation data as well, because it combines all the chr20-22 examples into one dataset?. And, I forgot to reply this part - for validation set, running the shuffling step is mainly for combing the examples into one dataset (and create a text file that describe it). Another reason is - if you specify `max_examples` in model_eval, it just might be safer to have the examples already pre-shuffled:; https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/model_eval.py#L118. ---. One more thing to clarify:; Unfortunately I might be using terminology that are a bit confusing in the doc:. In https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md , ; our **training** set are the labeled examples that our classifier actually learns from. ; This is the same as defined in: https://developers.google.com/machine-learning/glossary/#training_set. **Validation** set is the labeled examples that our classifier never directly learns from, but is used to pick a best model checkpoint. ; This is the same as defined in: https://developers.google.com/machine-learning/glossary/#validation_set; When I wrote our training case study, I tried to not use another term ""**tuning** set"", which is the same thing as ""validation set"". But now I read it again, I think I did accidentally use the term ""tuning set"" at least once. I'll update that in a future release.; Just to clarify again: When I use the term ""tuning set"", I'm referring to the same thing as validation set. There is also **test** set, defined here: https://developers.google.com/machine-learning/glossary/#test_set; When doing machine learning, the best practice is to leave the **test** set alone as much as possible, and NOT to make any decisions (on model picking, paramater tuning) on it at all. Which is why we had a validation set ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/312#issuecomment-638566733:53,clear,clearer,53,,https://github.com/google/deepvariant/issues/312#issuecomment-638566733,2,"['clear', 'learn']","['clearer', 'learns']"
Usability,"> https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md; @MariaNattestad Thank you for the quick response.I guess my question was not clear so, I will try to rewrite my query. 1) I wanted to know the base at all coordinates in a list of interval regions. The VCF file does not output all the positions in that interval region. If VCF file is able to give hom-ref, the. why are multiple locations missed? and out of around 1000bp, I am able to get information of around 200 bp?. Is there an option where we can force the deep variant to give information for all base position? and later filter if they are bad quality of not; Just like GATK has BP resolution option when we run the variant caller. 2) ; #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476; -- | -- | -- | -- | -- | -- | -- | -- | -- | --; 6 | 5285 | . | T | G | 1.6 | RefCall | . | GT:GQ:DP:AD:VAF:PL | ./.:5:213:107,106:0.497653:0,3,31; -- | -- | -- | -- | -- | -- | -- | -- | -- | --; 6 | 5288 | . | G | A | 22.1 | PASS | . | GT:GQ:DP:AD:VAF:PL | 0/1:20:220:106,107:0.486364:22,0,25. When we see allele depth(AD) for both rows, we observed that both the row has the almost same number of reads supporting it(107,106 and 106,107). Why is no call(./.) given for first and not for second? Can you please elaborate in why are multiple places given ./. despite reads supporting it",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/318#issuecomment-645516372:162,clear,clear,162,,https://github.com/google/deepvariant/issues/318#issuecomment-645516372,1,['clear'],['clear']
Usability,@AndrewCarroll I am working with human data for clinical diagnosis of rare disease. There is great interest in the clinical community to call de novo variants in the child from trio data. There is data about the rates of those events. . In 1% of the human genome you should find zero de novo in most cases. In less than 50% of the cases there are one or two that are real. I can run it on some curated data and provide feedback.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/450#issuecomment-830492777:419,feedback,feedback,419,,https://github.com/google/deepvariant/issues/450#issuecomment-830492777,1,['feedback'],['feedback']
Usability,"@AndrewCarroll Thanks for your response and the VCF example I have shared is my own data and not public data. Could you please refer to which part of my query you have answered? Maybe, I am not clear with your replies and which part does it address?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/318#issuecomment-645829089:194,clear,clear,194,,https://github.com/google/deepvariant/issues/318#issuecomment-645829089,1,['clear'],['clear']
Usability,@AndrewCarroll and @pgrosu thanks for your view on things and @pgrosu especially for your fantastic explanation of the model!. From a data scientist perspective this makes totally sense. I fully agree that one should always gather as much data as possible since one can always remove data that seems to be not useful afterwards. My intention was not to say that one do not need those data or that you should not use the information which those HomRef sites emerged from. I talked to some of my colleagues yesterday and they agreed that they would expect a variant caller to produce variant calls and information/statistics related to those and all further information would be opt-in since they would have no need for this. But my team could just be the minority here and simply an opt-out option for this behavior would be highly recommended!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1612713066:772,simpl,simply,772,,https://github.com/google/deepvariant/issues/666#issuecomment-1612713066,1,['simpl'],['simply']
Usability,"@AndrewCarroll, many thanks for such quick response!. > We do not directly accept external PRs, but this is not because we do not accept community additions. The ""source of truth"" for the DeepVariant GitHub repo resides in internal systems, which are then copied onto GitHub. As a result, to incorporate your changes, we will need to change the internal code and copy that back out. We have done this in the past with community additions, and have attributed the authors for contributions in release notes and other forums. I don't see any issues with that. The only thing which is important is to add the changes as a single commit separately from other changes so it can be properly tracked in git history. > Can you help me understand the expected benefit of the changes? It looks like this should improve runtime for call_variants. Do you have any high-level information from benchmark runs for us to understand the percentage improvement to expect. You're right - this PR about efficiency of deep learning part only (call_variants). We need some time to collect some benchmark numbers and check what's is OK to share publicly. Probably, extra optimizations could be applied. > If we are to incorporate these changes, we would want to make sure this would perform well across various hardware. For example, we would want our Docker images to gracefully fallback to working code if it is on a machine with incompatible hardware. Do you expect OpenVINO to have this property (for example, if someone is running on an AMD machine). Proposed changes are very smooth - by default, OpenVINO is not used. We can test other Intel hardware such iGPU and HDDL-R. For non-Intel HW users can always use default implementation. > We will also have to think about how these changes interact with any updates we would make to our use of TensorFlow. We're not directly planning anything in the near future, but it's good for us to consider. I think it won't be an issue. It make sense to isolate some OpenVINO rel",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/363#issuecomment-709941019:1002,learn,learning,1002,,https://github.com/google/deepvariant/pull/363#issuecomment-709941019,1,['learn'],['learning']
Usability,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1722685163:305,guid,guidance,305,,https://github.com/google/deepvariant/issues/682#issuecomment-1722685163,6,"['guid', 'learn', 'simpl']","['guidance', 'learning', 'simple']"
Usability,"@CWYuan08 , for Nanopore R9.4.1, we suggest using [PEPPER](https://github.com/kishwarshafin/pepper). DeepVariant supports R10.4 simplex and duplex modes. Thank you for confirming that it is working for you now. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/673#issuecomment-1638414183:128,simpl,simplex,128,,https://github.com/google/deepvariant/issues/673#issuecomment-1638414183,1,['simpl'],['simplex']
Usability,"@Ge-Lab if possible, please structure your issue using code fences. See [this guide](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-and-highlighting-code-blocks) for details. It will make it easier to read and understand if you place logs inside code blocks, for example. [This guide](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html) suggests a few things to try. Interestingly, it apperas you should set `CUDA_VISIBLE_DEVICES=0` within the container itself, but `SINGULARITYENV_CUDA_VISIBLE_DEVICES=0` outside of the container. Were you setting the variable appropriately, within the container or outside of it?. Additionally, since you have two GPUs you will want to set this variable to 0,1. Do you have the `nvidia-container-cli` installed as suggested on the support page?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/774#issuecomment-1954774836:78,guid,guide,78,,https://github.com/google/deepvariant/issues/774#issuecomment-1954774836,4,['guid'],"['guide', 'guides']"
Usability,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior; ```; # Command 1; time docker run -it -v /data:/data \; google/deepvariant:0.9.0 \; mkdir /data/kishwar/test_ubuntu_docker. # Command 2; docker run -it -u `id -u`:`id -g` -v /data:/data \; google/deepvariant:0.9.0 \; mkdir /data/kishwar/test_ubuntu_docker_u; ```; Output:; ```; root root 4.0K Aug 5 14:55 test_ubuntu_docker/; shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/; ```; Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/550#issuecomment-1206552255:38,simpl,simpler,38,,https://github.com/google/deepvariant/issues/550#issuecomment-1206552255,1,['simpl'],['simpler']
Usability,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/534#issuecomment-2263703106:343,simpl,simply,343,,https://github.com/google/deepvariant/issues/534#issuecomment-2263703106,1,['simpl'],['simply']
Usability,"@MediciPrime We've updated the [quickstart guide](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md) based on your feedback to make it more clear that setting up a Cloud account and enabling billing isn't required to run DeepVariant. Take the new wording in that doc out for a spin and let us know what you think. Cheers,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/9#issuecomment-352087449:43,guid,guide,43,,https://github.com/google/deepvariant/issues/9#issuecomment-352087449,3,"['clear', 'feedback', 'guid']","['clear', 'feedback', 'guide']"
Usability,"@NourMarzouka ,. Closing this issue due to inactivity. Please feel free to reopen. . The conclusion is that if you have the intermediate files, then you can resume. Otherwise, you have to restart the run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/825#issuecomment-2158916014:157,resume,resume,157,,https://github.com/google/deepvariant/issues/825#issuecomment-2158916014,1,['resume'],['resume']
Usability,"@SHuang-Broad Glad to hear it worked, and thank you for the nice visualization! Docker has multiple layers and DV expands with its own within them, which is something we've noticed with other folks in terms of resource requirements -- which you could sort of tell from the memory/cpu utilization profiles. You might be able to profile it more granularly, but it might easier to start with some simple input files, and maybe a modified version of DV where you add debug information in the code to get an idea of the points of memory/disk expansion. This way you can trace the code-execution with correlated flow of data-processing.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/491#issuecomment-961546511:394,simpl,simple,394,,https://github.com/google/deepvariant/issues/491#issuecomment-961546511,1,['simpl'],['simple']
Usability,"@Zjianglin So the last thing you are missing is that you are not binding your `lustre` folder. Basically the `/lustre/Data/toolsDB/HostRefs/Human_hs37d5/` folder is not seen within your Singularity container at runtime, so you will need to bind that folder like this:. ```; singularity run -B /lustre/Data/toolsDB/HostRefs/Human_hs37d5/:/lustre/Data/toolsDB/HostRefs/Human_hs37d5/ /lustre/Data/toolsDB/deepvariant.sif ls -al /lustre/Data/toolsDB/HostRefs/Human_hs37d5/*; ```. For more information on binding paths, below is a link that expands on how it works:. https://docs.sylabs.io/guides/3.0/user-guide/bind_paths_and_mounts.html",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1575943033:585,guid,guides,585,,https://github.com/google/deepvariant/issues/653#issuecomment-1575943033,2,['guid'],"['guide', 'guides']"
Usability,"@aalfi ,. Please follow the instructions here: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md. I see that you have `--dry_run=true` which would not run anything and would simply print out the commands:; ```; --[no]dry_run: Optional. If True, only prints out commands without executing them.; (default: 'false'); ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/561#issuecomment-1234749060:216,simpl,simply,216,,https://github.com/google/deepvariant/issues/561#issuecomment-1234749060,1,['simpl'],['simply']
Usability,"@ardoli, @ink1's suggestion is great, and there are two more:. * You can try [Udocker](https://blog.utar.co/blog/udocker) so that root privileges are not required for a Docker image.; * Tweak the DeepVariant source code to make it compile in user-space for your environment. It's a bit hairy, but can be done. The plus side is that you'll see DeepVariant is a pretty simple and modular pipeline, which you can tweak for your preferred analysis. Deep neural networks can be applied to many areas in the -Omics space besides just variant analysis.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/6#issuecomment-372515026:367,simpl,simple,367,,https://github.com/google/deepvariant/issues/6#issuecomment-372515026,1,['simpl'],['simple']
Usability,"@bkurtoglu , can you please let us know what datatype you are using? The current model only works with ONT R10.4 simplex and duplex data. Can you provide some more details about your data and run:. 1) What chemistry is your ONT data?; 2) What basecaller did you use?; 3) How many cpus are you using to run make_examples?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/814#issuecomment-2089293222:113,simpl,simplex,113,,https://github.com/google/deepvariant/issues/814#issuecomment-2089293222,1,['simpl'],['simplex']
Usability,"@chrisfleisch ; We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:; https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```; sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0; sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest; sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2; sudo docker push localhost:5000/deepvariant:latest; SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest; ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant.simg \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \; --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=output.vcf.gz \; --output_gvcf=output.g.vcf.gz ; ```; (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image; ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-482430728:311,feedback,feedback,311,,https://github.com/google/deepvariant/issues/132#issuecomment-482430728,1,['feedback'],['feedback']
Usability,"@claudiologiudice although this issue was closed some time ago, we have just released a new RNA-seq model and [case study](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md) for Illumina data. . Please take a look if you are still considering this and let us know if you have any feedback.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/283#issuecomment-1281193477:316,feedback,feedback,316,,https://github.com/google/deepvariant/issues/283#issuecomment-1281193477,1,['feedback'],['feedback']
Usability,"@crazysummerW ; I had the same issue here. It turned out to be the problem of the h5 file in the tmp dir.; If multiple programs open the h5 simultaneously, the error would occur. So I avoided this by creating a unique tmp dir for each sample, which used a lot of file handles. @pichuan @kishwarshafin Could you please take a look at this? Probably renaming the h5 file to keep it unique would be a simple and easy solution.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/725#issuecomment-1820853733:398,simpl,simple,398,,https://github.com/google/deepvariant/issues/725#issuecomment-1820853733,1,['simpl'],['simple']
Usability,"@crazysummerW my intuition is that it would not make a big difference, but we have not empirically tested this. My guess is that It could make a difference in variants observed in regions with lower coverage. Here is a similar issue (although, in the context of DNA-seq): https://github.com/google/deepvariant/issues/384",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/652#issuecomment-1555394452:17,intuit,intuition,17,,https://github.com/google/deepvariant/issues/652#issuecomment-1555394452,1,['intuit'],['intuition']
Usability,"@dennishendriksen ,. 1) Totally understandable, please give it a try when you have time and let us know if you are still facing issues. ; 2) Those are R9.4 data. The ONT model only supports R10.4 simplex or duplex. R9.4 has elevated error rate that causes a ton of candidates. DeepTio wouldn't work with R9 data. I am closing this issue. Feel free to reopen in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/724#issuecomment-1819466106:196,simpl,simplex,196,,https://github.com/google/deepvariant/issues/724#issuecomment-1819466106,1,['simpl'],['simplex']
Usability,@depristo thank you for taking the time to help me out. . When I was trying to build DeepVariant on Ubuntu 16.04 it required that I install Google Cloud SDK because it needed the 'gsutil' command. Before installing Google Cloud SDK I started reading the 'deepvariant-quick-start.md' file and it talked a lot about using Google Cloud SDK and setting up a Google Cloud account and 'enable billing for you account'. . Based on your comment I am assuming that Google Cloud Platform is not needed and we can simply ignore 'gsutil' once the build process is complete?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/9#issuecomment-351577610:503,simpl,simply,503,,https://github.com/google/deepvariant/issues/9#issuecomment-351577610,1,['simpl'],['simply']
Usability,"@frapaport ; an update on Singularity - I've tested our latest setting (which will come out in the next release) by converting it in to a Singularity image. It seems to work fine for me. So, if you would be able to install singularity, that will be an easier way forward once our next release is out.; I'll still come back and revisit the usability of our bioconda installation. But might take a while.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-480563989:339,usab,usability,339,,https://github.com/google/deepvariant/issues/137#issuecomment-480563989,1,['usab'],['usability']
Usability,"@githubtefo It might be worth trying a smaller chromosome (like chr20, or try Quick Start) to make sure that things work end-to-end on your machine first.; If you use `--postprocess_variants_extra_args=""cpus=0""` , it's only the last step (`postprocess_variants`) that will be without multiprocessing. That step takes < 1hr for our PacBio BAM - you can see in https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#runtime-2 (this is before multiprocessing was used in postprocess_variants. @githubtefo We understand that speeding up DeepVariant is very important. We're actively making improvements! Thank you for reporting the issue. Our future releases will be better because of your feedback!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/810#issuecomment-2069997953:695,feedback,feedback,695,,https://github.com/google/deepvariant/issues/810#issuecomment-2069997953,1,['feedback'],['feedback']
Usability,"@gunjanbaid I think you're right about it being a configuration for a different pipeline. Thanks, I'll try using bam.bai instead of simply .bai and see if that works.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/149#issuecomment-461160956:132,simpl,simply,132,,https://github.com/google/deepvariant/issues/149#issuecomment-461160956,1,['simpl'],['simply']
Usability,"@hangy1 , can you please run the [quickstart](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md) by simply copy-pasting the commands in your system? That way we could pinpoint the issue in a controlled case.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/839#issuecomment-2207033890:132,simpl,simply,132,,https://github.com/google/deepvariant/issues/839#issuecomment-2207033890,1,['simpl'],['simply']
Usability,"@hangy1 ,. 1) You can see from the log:. ```; Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz; ```. seems like sample_name is not set correctly? Unless you replaced them? Can you confirm if you have set the values correctly by printing them before running DeepVariant?. 2) Please use absolute paths rather than relative paths when you are setting paths. so instead of using:; ```bash; gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz""; ```; Use:; ```bash; gvcf = ""/path/to/vcf/{sample}.deepVariant.g.vcf.gz""; ```; Hope this helps. You can also run the [quickstart](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md) to see if you can simply copy-paste and run the command fully and then adapt it to the command you are planning to run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/839#issuecomment-2195257563:741,simpl,simply,741,,https://github.com/google/deepvariant/issues/839#issuecomment-2195257563,1,['simpl'],['simply']
Usability,"@helizabeth1103 @lucasbrambrink I'll clear up some confusion real quick here - the updated training script will only output checkpoints if tune performance outperforms existing performance. If you look closely in the log file you can see this line:. ```; I0401 03:09:48.932735 140045983049536 train.py:471] Skipping checkpoint with tune/f1_weighted=0.83932966 < previous best tune/f1_weighted=0.8400078; ```. Which states that checkpointing is being skipped because the performance was worse. So in general, if you aren't seeing checkpoints you likely need to adjust parameters or train for longer.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2033443746:37,clear,clear,37,,https://github.com/google/deepvariant/issues/797#issuecomment-2033443746,1,['clear'],['clear']
Usability,"@helizabeth1103 For training / validation sets -- the main point here is to keep them separate. ; And then, for all data that goes into training set, they will need to be shuffle into one set of shards. So that you can get the num_examples, and a consistent path. For example, in our documentation you see something like:. ```; name: ""HG001""; tfrecord_path: ""OUTPUT_GCS_BUCKET/training_set.with_label.shuffled-?????-of-?????.tfrecord.gz""; num_examples: 342758; ```. For training, you need one `tfrecord_path` that refer to all the files (output of shulffling), and a num_examples. For validation, you need a separate file with similar format. Hope that's clear! I'll close this issue now that you're able to run shuffling!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/793#issuecomment-2013124668:655,clear,clear,655,,https://github.com/google/deepvariant/issues/793#issuecomment-2013124668,1,['clear'],['clear']
Usability,"@husamia Unfortunately usually is not a reliable description that can be applied to Docker, as it performs many layers of abstraction that can cause a spike when you are not even aware of it. 80% is definitely not enough, especially with the layers of abstractions that DeepVariant also adds. On top of that you would have the Windows abstraction either running a virtual machine or ""leaner"" Windows Subsystem for Linux, which has its own abstractions. Think about it this way, how would you even be able to tell if there is a 10 second spike when Docker starts using 97-98-99% of resources if you need to wait for the OS process resource queue to clear in order to check the Docker status, but are limited/prevented to do so by multiple layers of resource management systems?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/412#issuecomment-767885510:648,clear,clear,648,,https://github.com/google/deepvariant/issues/412#issuecomment-767885510,1,['clear'],['clear']
Usability,"@japhill But for now, I also wonder if you can use the `-B` option in Singularity?; https://sylabs.io/guides/3.1/user-guide/bind_paths_and_mounts.html#user-defined-bind-paths; Can you try it and let me know if it works for you?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/530#issuecomment-1076923302:102,guid,guides,102,,https://github.com/google/deepvariant/issues/530#issuecomment-1076923302,2,['guid'],"['guide', 'guides']"
Usability,"@jguhlin glad to hear that training curves look reasonable! I want to mention that DV is currently written to be a diploid variant caller. In case you are retraining with data from polyploid organisms, it is not yet clear how DeepVariant will perform. I'll close this issue for now, but feel free to reopen if you have any other questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/251#issuecomment-566180701:216,clear,clear,216,,https://github.com/google/deepvariant/issues/251#issuecomment-566180701,1,['clear'],['clear']
Usability,"@kirti141 from the log, I agree that it isn't quite clear. ; Can you tell us about your machine? How many CPU cores, RAM, what OS, etc.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/482#issuecomment-925047566:52,clear,clear,52,,https://github.com/google/deepvariant/issues/482#issuecomment-925047566,1,['clear'],['clear']
Usability,"@mclaugsf Thanks for the update! ; 1) In terms of failed jobs -- we also noticed that our current recommendation of case studies tend to mask the issues if a run failed in the middle, because we currently pipe all output to log files. We're making some changes so that if anything fails in the middle, it'll be more clear to the users later. I'm still fixing a few more things, hopefully it'll come out in the next release.; For now it's a good idea to just check the log files to make sure previous runs were successfully done before proceeding. 2) For call_variants, can you check your `call_variants.log` file and see what the lines look like?; In my run for the WGS casestudy, it converges to something like:. ```; I0815 18:49:08.438520 140611550078720 call_variants.py:359] Processed 113665 examples in 223 batches [0.222 sec per 100]; I0815 18:49:09.491303 140611550078720 call_variants.py:359] Processed 114177 examples in 224 batches [0.222 sec per 100]; I0815 18:49:10.535501 140611550078720 call_variants.py:359] Processed 114689 examples in 225 batches [0.221 sec per 100]; ```. In our case study, we recommend just running one `call_variants` per machine. `call_variants` itself does utilize multiple CPUs now, so if you use top or htop to check your run, you should see that it uses more than one CPU. In my previous experience, running multiple `call_variants` on the same machine tends to make the run slower. If you're running call_variants separately on each shard, and if you can do each of them on different machines, that's probably most ideal. But if you plan to try running multiple `call_variants` on the same machine, you might want to watch out the speed because it will likely not be linearly faster. (If you find otherwise, let me know. I haven't tried it myself for a while now)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/105#issuecomment-430711053:316,clear,clear,316,,https://github.com/google/deepvariant/issues/105#issuecomment-430711053,1,['clear'],['clear']
Usability,"@nvnieuwk from my understanding, I would be surprised if the numpy error is related to the region. I feel that might be a red herring. Unfortunately I don't have a clear answer for you because I can't reproduce your exact setting.; If you think it can still be related to the small region, the next thing I'd suggest you try is: Start from the setting that worked before (CRAM file that contains the whole chromosome 21). First confirm that still works, and just change one thing: restrict to a smaller region and see if that still works or fails with the numpy error again. Sorry that I don't have better suggestions for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/640#issuecomment-1550815697:164,clear,clear,164,,https://github.com/google/deepvariant/issues/640#issuecomment-1550815697,1,['clear'],['clear']
Usability,@pgrosu ; I am sorry if I was not clear enough. I tried to say that I could not install glibc locally on my system. ; I started the contact with the system administrator to see what they can do.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/137#issuecomment-454145983:34,clear,clear,34,,https://github.com/google/deepvariant/issues/137#issuecomment-454145983,1,['clear'],['clear']
Usability,"@pgrosu @pichuan thanks for your continues help in various questions I raised in this thread. Really helpful. How likely is it to generate a DeepTrio model in the future to use such a data combination? I guess it is much more than simply training a model on such pedigrees, right?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1615137619:231,simpl,simply,231,,https://github.com/google/deepvariant/issues/666#issuecomment-1615137619,1,['simpl'],['simply']
Usability,"@pgrosu Thank you for your guidance!!; So this is what I did for the sections you mentioned:; ```; # note_build_stage ""Install TensorFlow pip package"". # if [[ ""${DV_USE_PREINSTALLED_TF}"" = ""1"" ]]; then; # echo ""Skipping TensorFlow installation at user request; will use pre-installed TensorFlow.""; # else; # # Also pip install the latest TensorFlow with cpu support. We don't build the; # # full TF from source, but instead using prebuilt version. However, we still; # # need the full source version to build DeepVariant. # # Gets the nightly TF build: https://pypi.python.org/pypi/tf-nightly which is; # # necessary right now if we aren't pinning the TF source. We have observed; # # runtime failures if there's too much skew between the released TF package and; # # the source.; # if [[ ""${DV_TF_NIGHTLY_BUILD}"" = ""1"" ]]; then; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # echo ""Installing GPU-enabled TensorFlow nightly wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade tf_nightly_gpu; # else; # echo ""Installing CPU-only TensorFlow nightly wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade tf_nightly; # fi; # else; # # Use the official TF release pip package.; # if [[ ""${DV_GPU_BUILD}"" = ""1"" ]]; then; # echo ""Installing GPU-enabled TensorFlow ${DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION} wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade ""tensorflow-gpu==${DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION}""; # elif [[ ""${DV_USE_GCP_OPTIMIZED_TF_WHL}"" = ""1"" ]]; then; # echo ""Installing Intel's CPU-only MKL TensorFlow ${DV_GCP_OPTIMIZED_TF_WHL_VERSION} wheel""; # pip3 install ""${PIP_ARGS[@]}"" --upgrade ""intel-tensorflow==${DV_GCP_OPTIMIZED_TF_WHL_VERSION}""; # else; echo ""Installing standard CPU-only TensorFlow ${DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION} wheel""; pip3 install ""${PIP_ARGS[@]}"" --upgrade ""tensorflow==${DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION}""; # fi; # fi; # fi. # # A temporary fix.; # # Context: intel-tensorflow 2.7.0 will end up updating markupsafe to 2.1.1,; # # which caused the issue ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518:27,guid,guidance,27,,https://github.com/google/deepvariant/issues/657#issuecomment-1575933518,1,['guid'],['guidance']
Usability,"@pgrosu Thank you for your response.; When you say ""the cloud"" do you mean to run it on a server/a super computer?; I predicted that I will need root access (sudo) which I don't have.; 1. Is there a way to do this? Docker is not even installed there. 2. So are you suggesting that we should not use mac (apple silicon)?. The ubuntu 20.04 that was installed on my mac (using UTM), should this work?. Thank you for your time and guidance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575677888:427,guid,guidance,427,,https://github.com/google/deepvariant/issues/657#issuecomment-1575677888,1,['guid'],['guidance']
Usability,"@pgrosu Thanks Paul, we appreciate the close eye you've given to the codebase. Unfortunately managing all of the dependencies is challenging, and we aren't super happy with how complex the build/run prereqs scripts are. And we agree with you that there's a lot of opportunity to explore extensions, simplifications, and optimizations of DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/41#issuecomment-361436703:299,simpl,simplifications,299,,https://github.com/google/deepvariant/issues/41#issuecomment-361436703,1,['simpl'],['simplifications']
Usability,"@pichuan . As you know, I am running the shuffle script using Spark. I am wondering how many output files are expected from running the script. When I use DirectRunner, I get a single output file. When I use the SparkRunner I get as many output files as there are input files fitting the pattern (I have noticed this mismatch between spark/direct runner in another situation as well: https://stackoverflow.com/questions/64450391/apache-beam-beam-flatten-doesnt-flatten-files-with-sparkrunner-but-does-so-wi). Is this the expected result when using Dataflow runner as well? Basically, I am simply trying to do a sanity check to make sure that the shuffler isn't simply reading in the data and copying it without shuffling, or simply shuffling within each shard. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/360#issuecomment-713149241:589,simpl,simply,589,,https://github.com/google/deepvariant/issues/360#issuecomment-713149241,3,['simpl'],['simply']
Usability,"@pichuan @amwenger ; Thank you very much for your response.; Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. ; Both datasets have been tested successfully. Thank you for your help.; Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/672#issuecomment-1621111780:93,clear,clearly,93,,https://github.com/google/deepvariant/issues/672#issuecomment-1621111780,1,['clear'],['clearly']
Usability,"@pichuan @pgrosu This improves my understanding substantially. After reading the paper, my initial impression was that DeepVariant consists of two parts - one part following traditional callers performing local assembly, haplotype detection and candidate allele generation based on the top-two haplotypes, and a second part which is a DNN used to perform candidate filtration. In such a scheme, the second part would be presented a single image per site and it makes a determination among homozygous-ref, heterozygous, and homozygous-alt in an allele-agnostic way - hence it needs a single image per site. In such a caller, 3 allele candidates at a site wouldn't be possible. I was also surprised that such a method could outperform all others, since this approach simply (approximately) replaces the VQSR step in GATK or the RandomForest in Strelka, and a lot would be riding on heuristic-based algorithms for candidate selection. I understand now that all (reasonable) candidates at a site are evaluated and scored against each other using the DNN, which seems to me to be a much more satisfying approach. I am still interested in how different predictions are combined into a single variant quality score, since they are not normalized; hence my request for guidance towards the code source that combines multiple predictions into a variant call. I will go through these resources over the next day. Thanks a lot! Much appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/197#issuecomment-512127253:765,simpl,simply,765,,https://github.com/google/deepvariant/issues/197#issuecomment-512127253,2,"['guid', 'simpl']","['guidance', 'simply']"
Usability,@pichuan Can you inspect more closely the convolutions in inception v3 to trace out what is happening? How about building an ensemble model where the prediction runs through multiple learned models by either majority vote or a more fine-grained decision boundary.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/109#issuecomment-431125198:183,learn,learned,183,,https://github.com/google/deepvariant/issues/109#issuecomment-431125198,1,['learn'],['learned']
Usability,"@pichuan Thanks for confirming!. I tried GPU-based training, but since the codebase currently doesn't support multi-GPU runs, it may not be efficient for me to use GPU-based training. Hence I am looking into using TPUs for the same. I will gladly provide feedback once I am able to do it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/376#issuecomment-720216342:255,feedback,feedback,255,,https://github.com/google/deepvariant/issues/376#issuecomment-720216342,1,['feedback'],['feedback']
Usability,"@pichuan Thanks for the feedback -- I have altered my WDL (I'm building this as a method on FireCloud) to include the lscpu command, and have run with 1, 4 and 64 cores/shards so hopefully I will get a better sense of what's going on and report back here.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/150#issuecomment-461030330:24,feedback,feedback,24,,https://github.com/google/deepvariant/issues/150#issuecomment-461030330,1,['feedback'],['feedback']
Usability,@pichuan and @pgrosu : Thank you for your feedback. Will keep you posted on the issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/90#issuecomment-418211657:42,feedback,feedback,42,,https://github.com/google/deepvariant/issues/90#issuecomment-418211657,1,['feedback'],['feedback']
Usability,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1; 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X; 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/852#issuecomment-2238167683:401,learn,learn,401,,https://github.com/google/deepvariant/issues/852#issuecomment-2238167683,1,['learn'],['learn']
Usability,"@poddarharsh15, can you please check if the files were downloaded correctly and if their sizes look good. The case studies are designed in a way that you can simply copy-paste the commands and it should work. I just tested the case study and it worked on my end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/853#issuecomment-2238236950:158,simpl,simply,158,,https://github.com/google/deepvariant/issues/853#issuecomment-2238236950,1,['simpl'],['simply']
Usability,"@scott7z Well, my feeling is that would be too much work, which could be fostered elsewhere. Unless there is a defined criteria for working off a specific revision, it is usually less of a benefit to be tied to a specific release. It'll also make the cost of supporting it too much of a headache, as the other dependencies will continue to evolve. I always prefer to simplify and feel it's more practical to push compliance of dependencies to their maintainers, while expanding on the fun part of adding community-driven features. For example, there over 1000 commits between the two SHAs, and it would be hard to keep track of so many contributions:. ```Bash; $ git log | grep commit | cat -n | grep '97a4c226e8a9e7c5c36fc38e2b9f8459c77abd5a\|ab0fcaceda001825654424bf18e8a8e0f8d39df2'; 1 commit 97a4c226e8a9e7c5c36fc38e2b9f8459c77abd5a; 1244 commit ab0fcaceda001825654424bf18e8a8e0f8d39df2; $; ```. Usually more contributions to a dependency might provide us with more opportunities :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/19#issuecomment-353510712:367,simpl,simplify,367,,https://github.com/google/deepvariant/issues/19#issuecomment-353510712,1,['simpl'],['simplify']
Usability,"@sophienguyen01 - from the log file it looks like everything worked. Here are all the tune/categorical accuracies from your training data. ```; tune/categorical_accuracy=0.9944317936897278; tune/categorical_accuracy=0.9909400343894958; tune/categorical_accuracy=0.9915463924407959; tune/categorical_accuracy=0.9925118088722229; tune/categorical_accuracy=0.9921825528144836; tune/categorical_accuracy=0.9924613237380981; tune/categorical_accuracy=0.9926846623420715; tune/categorical_accuracy=0.9929667711257935; tune/categorical_accuracy=0.9925829172134399; tune/categorical_accuracy=0.9926416277885437; tune/categorical_accuracy=0.9923893213272095; tune/categorical_accuracy=0.9925225377082825; ```. The first number represents accuracy direct from the pretrained model. Since none of the subsequent tuning evaluations outperformed the original, no checkpoints were created. One thing you could try: reduce the learning rate, and see if that helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2042819603:912,learn,learning,912,,https://github.com/google/deepvariant/issues/802#issuecomment-2042819603,1,['learn'],['learning']
Usability,"@sophienguyen01 it looks like you are trying to call somatic mutations here. If this is the case, please have a look at https://github.com/google/deepsomatic. DeepSomatic is still experimental, and we don't currently support retraining. However, it is designed to call somatic variants. . We would be very interested in the results you observe with this dataset if you are able to provide feedback.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/728#issuecomment-1802319218:389,feedback,feedback,389,,https://github.com/google/deepvariant/issues/728#issuecomment-1802319218,1,['feedback'],['feedback']
Usability,@ssm0808 FYI on how to shuffle on Spark: http://people.apache.org/~pwendell/spark-nightly/spark-master-docs/latest/rdd-programming-guide.html#shuffle-operations,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/91#issuecomment-423040145:131,guid,guide,131,,https://github.com/google/deepvariant/issues/91#issuecomment-423040145,1,['guid'],['guide']
Usability,"@xunjieli yes, I can. I only extracted the variants where the analyzed sample had the alternative allele (genotype 1/1,0/1,./1). I did this for the single vcf obtained from deepvariant and for the combined vcf (obtained from gatk using the gvcf created with deepvariant).; Then, I compared only the variants (chromosome, position, reference and alternate allele) of this two sets. Is it clear?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/170#issuecomment-482316115:387,clear,clear,387,,https://github.com/google/deepvariant/issues/170#issuecomment-482316115,1,['clear'],['clear']
Usability,"@ziphra ,. You are correct. It does seem like something went wrong with your mapping and you have reads without base-qualities. My suspicion was that the aligner was removing base-qualities from non-primary reads, but that's clearly not the case.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/539#issuecomment-1144255541:225,clear,clearly,225,,https://github.com/google/deepvariant/issues/539#issuecomment-1144255541,1,['clear'],['clearly']
Usability,"A conda package for DeepVariant is now available through bioconda so you should be able to install with:; ```; conda install -c conda-forge -c bioconda deepvariant; ```; It includes wrapper scripts for each of the 3 steps (`dv_make_examples.py`, `dv_call_variants.py`, `dv_postprocess_variants.py`) that handle wrapping the internal locations of the pre-built zip files and models, so you can call these as normal command line options. These don't yet expose all options available in DeepVariant but are hopefully sufficient to run standard germline calling projects. I've also started a separate issue (#29) to discuss improvements we can make to improve portability, but hope the initial package helps for installing and using DeepVariant. I'd be happy for feedback and suggestions on this package as folks have a chance to use it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/9#issuecomment-354748344:759,feedback,feedback,759,,https://github.com/google/deepvariant/issues/9#issuecomment-354748344,1,['feedback'],['feedback']
Usability,"Ah, understood, and thanks very much for the guidance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/519#issuecomment-1054593204:45,guid,guidance,45,,https://github.com/google/deepvariant/issues/519#issuecomment-1054593204,1,['guid'],['guidance']
Usability,"Also, to answer your earlier question:. I may be still in the learning phase about some AWS things, but _m5.4xlarge_ (which is what I was using when I submitted the ticket) is listed as having 16 cores and 64 GB of RAM. I am currently testing running on an _r4.8xlarge_ EC2 instance (part of an ECS cluster, which has Docker installed) is listed as having 32 cores and 244 GB of RAM. If that doesn't work, I think I need to take more time to either look into other strategies (like keep trying to get things set up to run in AWS ""Batch"" and/or seeing if there might be a Docker configuration issue that I can change/fix) and/or go ahead and start my Google Cloud comparison. While I want to be fair and clear about having some costs associated with a learning curve, I've already spent more than $250 in ~2 weeks trying to test DeepVariant in the AWS system. So, in order for this to be a viable option over GATK (which I can run on my local computer for WGS data with 4 cores and 8 GB of ram), I need to be able to confirm that I can in fact perform Exome analysis on Google Cloud for $0.20 (and while ~25 min is not essential, I think you would need to update your page if those two metrics didn't apply to typical usage). Still running that **postprocess_variants** command on AWS, but I will keep you posted until the issue is fixed!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-479522653:62,learn,learning,62,,https://github.com/google/deepvariant/issues/167#issuecomment-479522653,3,"['clear', 'learn']","['clear', 'learning']"
Usability,"Also, while I am still doing some extra testing, I figured out the cause of my problem (which was actually very simple):. **1)** The error message changed a little bit (so, I was focusing on the memory, when there was actually another error):. ```; terminate called after throwing an instance of 'std::system_error'; what(): Resource temporarily unavailable; ```. **2)** I was providing the relevant parts of the code on GitHub without realizing that everything from step 2 (**call_variants**) was commented out, which _included_ the CALL_VARIANTS_OUTPUT variable (which is the _input_ file for **postprocess_variants**). After uncommenting that line, the file reformatting ran within a minute (on an AWS ECS m5.2xlarge instance). I am very sorry that it took so many messages (and time) for me to eventually figure out this problem, but I hope this helps with other people seeing a similar error message.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-482393946:112,simpl,simple,112,,https://github.com/google/deepvariant/issues/167#issuecomment-482393946,1,['simpl'],['simple']
Usability,"And, just in case the documentation isn't clear:. This part:. ```; sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; ...; ```. The variable BIN_VERSION was specified in earlier in the steps:. ```; BIN_VERSION=""1.6.1""; ```. So, in Unix command it's equivalent to:. ```; google/deepvariant:""1.6.1"" \; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/829#issuecomment-2162210763:42,clear,clear,42,,https://github.com/google/deepvariant/issues/829#issuecomment-2162210763,1,['clear'],['clear']
Usability,"Another update on CLIF dependency:; @chapmanb , as you noticed, CLIF is an issue here. We pre-built our own CLIF and directly used it in the DeepVariant build. I also just realized that we didn't release the script that we used to build CLIF, which should totally be released. I was planning to push out a 0.6.1 today, but now it's late so I'm going to wait until Monday for my own sanity and not breaking things over the weekend. However, if it's helpful I'll paste the content here right now. Note that this is used to build for Ubuntu. I did start looking into whether we can modify it for CentOS 6, but stuck at how to get `protoc` and hasn't resumed my work yet. I'll just paste our script for Ubuntu and hopefully that could be helpful if you want to look into building a CentOS compatible CLIF. Next week I'll push a 0.6.1 that has this under the tools/ directory. And I'll also see if I can figure out how to build it for CentOS6. ```; # Builds OSS CLIF binary for DeepVariant.; #; # This script should be run on a cloud VM. Known to work on some versions of; # Linux OS.; #; # OSS CLIF takes a very long time to build (10+ minutes) since it needs to; # compile parts of clang and LLVM. To save this build time, we use this script; # to build CLIF, install it in /usr/local/clif, and then packages up; # /usr/local/clif and shared protobuf libraries from /usr/local/lib into a tgz; # called oss_clif.latest.tgz.; #; # This oss_clif.latest.tgz is used by build-prereq.sh to build DeepVariant.; # Various versions that we built and released can be found under:; # https://console.cloud.google.com/storage/browser/deepvariant/packages/oss_clif; #; # We do recognize that this should be temporary, and will update when there is; # an official solution from CLIF.; # GitHub issues such as https://github.com/google/deepvariant/issues/29 has; # some relevant pointers. set -eux -o pipefail. # Figure out which linux installation we are on to fetch an appropriate version; # of CLIF binary. Note that",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-385130636:647,resume,resumed,647,,https://github.com/google/deepvariant/issues/29#issuecomment-385130636,1,['resume'],['resumed']
Usability,"Apologies in advance for inviting myself into the conversation. I think it's worth mentioning that while there are merits to doing MNV calling, the use-case given (calling amino acid variation from SNPs) isn't the greatest. There's no guarantee that codons occur as triplets in the genome (though they tend to, they can also get split across exons). which suggests that MNV calling doesn't actually solve the problem in general. Phase-aware consequence predictors (bcftools csq) should, on the other hand, work just fine (neglecting phasing errors of course). FWIW, we use the following pipeline: deepvariant or gatk4 -> whatshap -> shapeit4 -> bcftools csq to predict protein polymorphisms (or really, whole proteomes from whole genomes) and that approach should work in this case too. To be clear, having MNV calling would make an excellent addition to DeepVariant, it just may not be a total solution to the problem posed.; -August",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/486#issuecomment-984133927:793,clear,clear,793,,https://github.com/google/deepvariant/issues/486#issuecomment-984133927,1,['clear'],['clear']
Usability,Assigning to @nmousavi for some feedback on why this path changed.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-453148437:32,feedback,feedback,32,,https://github.com/google/deepvariant/issues/132#issuecomment-453148437,1,['feedback'],['feedback']
Usability,"At present we do not have a specific recommendation for joint genotyping DeepVariant gVCFs. Given the accurate genotype likelihood calibration of single-sample DeepVariant calls it may be better to simply merge calls without computing genotype posteriors based on population allelic frequencies and then altering the genotypes. We are actively investigating the performance of different methods to be able to provide a set of best practices. That said, the gVCF outputs of DeepVariant are syntactically and semantically equivalent to those produced by other tools like GATK, so can be used by any existing joint genotyping tools.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/45#issuecomment-363913008:198,simpl,simply,198,,https://github.com/google/deepvariant/issues/45#issuecomment-363913008,1,['simpl'],['simply']
Usability,"Building a deepvariant Singularity image is indeed really quite simple and portable. I did it and test it on CentOS7 and MacOS X and it run in both case with deepvariant quick-test data. I will post the complete ""how-to"" when I'll have a couple of minutes.; Thank's ink1 for the idea.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/6#issuecomment-372953552:64,simpl,simple,64,,https://github.com/google/deepvariant/issues/6#issuecomment-372953552,1,['simpl'],['simple']
Usability,Can you produce a small snippet of your BAM file and an associated command line that reproduces the issue and share it with us? We'd be happy to debug but it'd be great to have a simple example that causes the problem.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-370805635:179,simpl,simple,179,,https://github.com/google/deepvariant/issues/52#issuecomment-370805635,1,['simpl'],['simple']
Usability,Closing this. DeepVariant ran 'successfully' after splitting fastq files - although the output was bizarre. It is pretty clear that using DeepVariant with older PacBio data is not worthwhile -- my impression is that older PacBio data is only useful for finding larger SVs and worth using only if there is nothing better (e.g. PacBio HiFi or ONT).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/614#issuecomment-1457774639:121,clear,clear,121,,https://github.com/google/deepvariant/issues/614#issuecomment-1457774639,1,['clear'],['clear']
Usability,"Dear @gunjanbaid . thanks for your reply,. I am using the docker version, and the quick start with gpu does not work. ; I have Ubuntu 20.04.; I used the exact same command as quickstart. the issue is the TF and CUDA version which is not matched with the deep variant current ubuntu version. I am using RTX 3090 and this card needs a higher version of TF. I tried to make a Docker-based on the versions that I need but unfortunately, this failed too,. Would it be possible to have an additional docker for these gpu cards?. I followed the exact libraries mentioned in this link to make the docker; https://www.fatalerrors.org/a/rtx3090-ubuntu-20.04-tensorflow-2.4.0-installation-guide.html. update:. The issue is with the CUDA version, most recent GPU cards need CUDA 11. ; Is there any plan for an update? . Thanks in advance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/452#issuecomment-834942601:678,guid,guide,678,,https://github.com/google/deepvariant/issues/452#issuecomment-834942601,1,['guid'],['guide']
Usability,"Dear @oschwengers,. I will soon have to call variants from E.coli bacteria genomes and ONT SUP reads and wonder if I can use the newly introduced haploid option to tell Deepvariant that my bacterial reference genome is haploid, like shown in [this page for X and Y](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-xy-calling-case-study.md). `--haploid_contigs ""<Ecoli_chromosome>"" `. Also, will the _ONT_R104_ model be affected by this extra argument?. The paper referred to above by @mbhall88 dates from 2020 and may not be accurate anymore for the haploid aspect of variant calling in bacteria if DeepVariant has evolved in that domain. Thanks for your feedback",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/183#issuecomment-1824632486:672,feedback,feedback,672,,https://github.com/google/deepvariant/issues/183#issuecomment-1824632486,1,['feedback'],['feedback']
Usability,"Dear Andrew,. Thank you for your quick reply. I agree with you that most sequencing and; resequencing projects will move towards HiFi reads rather than CLR reads.; However, there is a lot of CLR sequencing data that has been generated in; the past couple of years and continues to be produced currently and could; still be useful for groups without the means to resequence using the novel; HiFi reads. So, I definitely see a niche in a large part of the; bioinformatics community that do a lot of data reusing (nowadays data; parasites). So, if there is anything we can do to help you n development,; please feel free to let me know how we can collaborate. Kind regards,. Juan D. Montenegro. El mar., 15 sept. 2020 a las 18:37, Andrew Carroll (<; notifications@github.com>) escribió:. > Hi @jdmontenegro <https://github.com/jdmontenegro>; >; > For the question about multi-allelic heterozygous calls - yes, DeepVariant; > is able to all 1/2 events, and will represent these in one line as a GT 1/2; > call in the VCF.; >; > For CLR calling in DeepVariant. It is theoretically possible for us to; > make a model for DeepVariant that can call CLR data. However, this requires; > us to write a special candidate generation logic to deal with the higher; > error rate. Based on what we perceive for the direction of future use in; > the genomics community, we think that data generated will be increasingly; > HiFi, so we have not been able to highly prioritize CLR models. Feedback; > from users like yourself will be useful to us in evaluating if that; > prioritization makes sense. For now, I can't commit to a timeframe under; > which we would support a PacBio CLR model.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/347#issuecomment-693053180>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ACHSLOV5RPVLTVGDW2A44X3SF73E7ANCNFSM4RNQJZYQ>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/347#issuecomment-693080237:1470,Feedback,Feedback,1470,,https://github.com/google/deepvariant/issues/347#issuecomment-693080237,1,['Feedback'],['Feedback']
Usability,"Dear Paul,. Thank you for you suggestions about STR analysis! . Please do not apologize, as you have indeed helped me a lot and saved me a lot of time. Thank you for providing very professional guidance on Deepvariant. I am still unable to reach a conclusion on whether deepvariant can be used in some way on logically paired samples, so I will take a look at the HipSTR and deep repeat you provided, which may be helpful for my research. Thank you very much!. Wich you have a nice day!. Ji",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/697#issuecomment-1683275474:194,guid,guidance,194,,https://github.com/google/deepvariant/issues/697#issuecomment-1683275474,1,['guid'],['guidance']
Usability,"Do you have CUDA installed on your machine?. Check whether CUDA is installed on your machine. For example, run:; ```; rpm -qa | grep cuda; ```; or; ```; nvcc --version; ```. If you don't have CUDA installed, please follow the instructions on https://docs.nvidia.com/cuda/cuda-installation-guide-linux/ to make sure you install it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/619#issuecomment-1471268664:289,guid,guide-linux,289,,https://github.com/google/deepvariant/issues/619#issuecomment-1471268664,1,['guid'],['guide-linux']
Usability,Excellent! Please let us know if you have any other feedback. I will close this issue now.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/624#issuecomment-1496232959:52,feedback,feedback,52,,https://github.com/google/deepvariant/issues/624#issuecomment-1496232959,1,['feedback'],['feedback']
Usability,"From the help page of Singularity Container [link](https://sylabs.io/guides/3.1/user-guide/cli/singularity_run.html):; ```; -B, --bind strings a user-bind path specification. spec has the format src[:dest[:opts]], where src and dest are outside and inside paths. If dest is not given, it is set equal to src. Mount options ('opts') may be specified as 'ro' (read-only) or 'rw' (read/write, which is the default). Multiple bind paths can be given by a comma separated list.; ```. Basically, this option binds your local directory to the directory inside a container. Also see https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-quick-start.md#notes-on-singularity",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/506#issuecomment-1017088492:69,guid,guides,69,,https://github.com/google/deepvariant/issues/506#issuecomment-1017088492,2,['guid'],"['guide', 'guides']"
Usability,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```; E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"".; parallel: This job failed:; python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2; ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/72#issuecomment-412946034:102,guid,guide,102,,https://github.com/google/deepvariant/issues/72#issuecomment-412946034,1,['guid'],['guide']
Usability,"GIAB used a combination of different kinds of sequencing data to get the truth VCF, including long-range technologies that give better results than using short-read sequencing alone. Learning from this truth set with more context is why DeepVariant performs better than purely looking at AD and VAF alone. DeepVariant learns to balance false positives and false negatives, so when it labels some high-AD loci as '0' it is because they look like sites that GIAB labeled as hom-ref. STRs in particular can cause false positives when using simple allele depth approaches. Since DeepVariant sees the base sequence in the pileup image, it effectively already has an STR channel, so it can ""learn"" about STRs and take their presence into account. While the GIAB truth set is not perfect, it has generally performed far better by employing multiple technologies relative to using short-read allele depth alone. I would say it's more likely that these sites were determined by other technologies to be hom-ref than that they were missed by GIAB.; Does that answer your question?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/317#issuecomment-644965403:183,Learn,Learning,183,,https://github.com/google/deepvariant/issues/317#issuecomment-644965403,4,"['Learn', 'learn', 'simpl']","['Learning', 'learn', 'learns', 'simple']"
Usability,"Great! Thank you for letting us know!; If you're interested in sharing more feedback to us, that will be great too. :); I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/581#issuecomment-1317489201:76,feedback,feedback,76,,https://github.com/google/deepvariant/issues/581#issuecomment-1317489201,1,['feedback'],['feedback']
Usability,"Great! The logs you posted confirmed that the checkpoints were not being written, but it's not clear _why_ that was the case. I will close this issue for now, but please don't hesitate to reopen if you encounter it again!. To your second question, that's correct! In 1.6, we migrated our training and inference platform from Slim to Keras, and as part of this effort we combined `model_train` and `model_eval` with a single executable `train` to make training easier.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2033038202:95,clear,clear,95,,https://github.com/google/deepvariant/issues/797#issuecomment-2033038202,1,['clear'],['clear']
Usability,"HI @pichuan,. Please check this screenshot out and see if it is more clear. ![image](https://github.com/google/deepvariant/assets/34832128/82ed1379-29b4-403f-aa07-75002c1d831e). What I did was I first shelled into the container. Then I checked the files in `/opt/deepvariant/bin/` in the container because I tried to look for the `run_deeptrio` file, which could not be found when I followed steps in https://github.com/google/deepvariant/blob/r1.6/docs/deeptrio-quick-start.md#notes-on-singularity and gave the error message as in the title of this issue. Was it possible that I missed anything when running Deeptrio?. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/745#issuecomment-1840119054:69,clear,clear,69,,https://github.com/google/deepvariant/issues/745#issuecomment-1840119054,1,['clear'],['clear']
Usability,"Hello @AndrewCarroll I launched DeepVariant as suggested, and then plotted the GQ distrubution. Here is a Gaussian kernel I fitted on it to better see (some people saw 2 peaks, others 4). So, here is what Gauß would see . ; ![density_gaussian](https://github.com/google/deepvariant/assets/81575666/eeb28721-204b-47b6-9ea0-750aca1ba21f). Clearly 4 peaks (github horribly compresses the plot, actually here it's hard to see the 2 peaks on the right end)... now I am gonna investigate in relation to the AF. I already had a quick look at the data themselves, that's gonna be fun ... some AF are so small. . I will keep you posted. Don't hesitate to comment. EDIT: I changed the plot type, it's much better now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1647816652:337,Clear,Clearly,337,,https://github.com/google/deepvariant/issues/682#issuecomment-1647816652,1,['Clear'],['Clearly']
Usability,"Hello @kishwarshafin, . Thank you for your response and for the useful tips!. It appears that I have several types of flags for my reads presenting no quality score: ; ```; 0; 16; 2048; 2064; 4; ```; All the above flags are also present in my reads having a quality score sequence, except for the flag `4` (= read unmapped), which is absent. Also, it seems that in this case flags should be written without the `0x` prefix, which converts them to hexadecimal when they are written in decimal in the sam file, as I understand. ; `0x16` in https://broadinstitute.github.io/picard/explain-flags.html output a flag that cannot be set when read is not paired, and my read are not paired. However, it now seems clear that something went wrong with the alignment since I have all types of reads with no quality score sequence, not only `0x904` type reads (which are read unmapped `0x4`, not primary alignment `0x100`, and supplementary alignment `0x800`).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/539#issuecomment-1141201135:705,clear,clear,705,,https://github.com/google/deepvariant/issues/539#issuecomment-1141201135,1,['clear'],['clear']
Usability,"Hello @mosh305 . I would like to learn more about what you would like to do with this sample, and, if possible, propose some alternatives that are more likely to succeed. I don't believe that the NA12878 Mt.Sinai set here can be reliably processed. This is a non-CCS PacBio dataset, so there will be far too many candidate examples generated to process efficiently. Also, the DeepVariant models are not trained for non-CCS PacBio reads. May I recommend that instead you consider the CCS dataset for HG002 that was submitted to genome in a bottle:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_CCS_15kb/. If this does sound interesting to you, we can provide to you a model trained for the CCS data type. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/138#issuecomment-458681829:33,learn,learn,33,,https://github.com/google/deepvariant/issues/138#issuecomment-458681829,1,['learn'],['learn']
Usability,"Hello @pgrosu ; Thanks for the bcftools suggestion, exactly what's needed. I will try to digest your comment about how the model was trained. Thank you for explaining! I will report back. ; @AndrewCarroll I am gonna send you the vcf file, from a protonmail address (the proton domain is sometimes blocked by servers). . Thanks everyone for the great disussion, I hav learned a lot.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1649296164:367,learn,learned,367,,https://github.com/google/deepvariant/issues/682#issuecomment-1649296164,1,['learn'],['learned']
Usability,Hello @pichuan I will try your suggestion and let you know the feedback. As to the SIF conversion its just simple command using singularity (version 3.7.2) pull docker://google/deepvariant:1.4 (Now I use 1.5).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/646#issuecomment-1547543795:63,feedback,feedback,63,,https://github.com/google/deepvariant/issues/646#issuecomment-1547543795,2,"['feedback', 'simpl']","['feedback', 'simple']"
Usability,"Hello Andrew,. >Thank you for the plot. This is expected the the found de novo calls are lower in confidence (because DeepTrio has learned that de novo events are rare). Given that a call is a de novo (0/1-0/0-0/0), the higher GQ values will still indicate higher confidence, so more confident de novo calls should be more likely to be true. I have tried to verify the idea and plotted normalized histograms for all DeepTrio calls, filtered DeNovo-like (0/1-0/0-0/0) calls and true DeNovo calls (verified in IGV). Please see an attached picture. True DeNovo calls are still in the middle-low part of proband GQ range for DeNovo-like calls. I have tried to look at several DeNovo-like variants with a higher proband GQ, which were not in my list of true DeNovos, but all of them were false-positives. ![DeepTrio_GQproband2](https://user-images.githubusercontent.com/22089494/115329837-ea041300-a160-11eb-8788-31136171e157.png). I have prepared a few examples of DeepTrio variants in IGV (squished and expanded views) with corresponding output in DeepTrio VCF to show you discrepancies between DeepTrio VCFs and BAMs. I think it could be a part of the GQ issue in DeNovos.; The order of FORMAT fields in multisample VCF is proband, mother, father.; The order of samples in IGV is father, mother, proband (from top to bottom). ### **1) True Denovo, QUAL=3, proband GQ=5. It looks good except very low proband GQ.**. chr5 | 92696737 | chr5_92696737_C_T | C | T | 3 | . | AF=0.166667;AQ=3 | GT:DP:AD:GQ:PL:RNC | 0/1:32:17,15:**5**:3,0,32:.. | 0/0:27:27,0:50:0,108,1079:.. | 0/0:21:21,0:50:0,105,1049:.. ![DT_1_04190_chr5_92696737](https://user-images.githubusercontent.com/22089494/115329914-0902a500-a161-11eb-9ab6-a3dc47a92aaf.png); ![DT_1_04190_chr5_92696737_zoom](https://user-images.githubusercontent.com/22089494/115330134-7d3d4880-a161-11eb-9202-10a392b98c07.png). ### **2) Filtered Denovo-like, QUAL=46, proband GQ=13. Mulitallelic, inherited; when VCF is normalized, it passes DeNovo filter as fat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/440#issuecomment-822947862:131,learn,learned,131,,https://github.com/google/deepvariant/issues/440#issuecomment-822947862,1,['learn'],['learned']
Usability,"Hello Andrew,. Thank you for your quick reply!. > 1. Are you taking the values from the QUAL field of the multisample glnexus VCF. Yes, exactly!. > 2. How have you determined the TP sites? Are these Genome in a Bottle, or do they come from some other source. These are PCGC data, TPs were determined by combination of methods and manually curated. We expect an accuracy of the; found TPs to be > 95% (based on PCR for a similar dataset), although we might still miss some TP calls. > Are these true variants de novos? DeepTrio's quality distribution for de novo variants is very different from its general quality distribution. This occurs because DeepTrio has learned that de novo events are quite rare, and so requires a higher standard of evidence to make a call which is a de novo. In these cases, DeepTrio is not extremely confident in the call, which results in a lower quality value. I am sorry, I did not mention it. Yes, we are looking for denovos in trios. We are comparing efficiency of a few methods to create a pipeline for a big dataset. I thought we might use the QUAL score from DeepTrio to filter calls found by GATK4 pipeline.; If we use GQ fields for further filtering what values do you recommend for parents and proband?. Now, I use the following filters to retrieve denovo calls from the multisample glnexus VCF:; - Heterozygous ratio of proband = 0.2-0.8; - Homozygous ratio of parents <= 0.1; - ALT allele depth of proband >= 7; - Genotype quality of proband >= 60; - Read depth >= 7; - Allele count = 1; - Some regional filters were applied to remove noisy regions; - Common variants were removed based on 1000genome and gnomad population frequencies; Also, I had to split multiallelic calls and recalculate genotypes based on AD fields as I had a lot of ./. and 0/1 for Homozygous reference calls in parents. As results, I obtained 909 SNPs and 1,236 indels for my 10 test trios. My list of TPs contains 698 SNPs and 61 indels. So, I still have a lot of false-positives calls",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/440#issuecomment-820564569:661,learn,learned,661,,https://github.com/google/deepvariant/issues/440#issuecomment-820564569,1,['learn'],['learned']
Usability,"Hello Maria,. Thanks for your reply, this is very clear.; I have such a depth because only a small region of my genome is amplified (~15kb) and several DNA are pooled by ""sample"". As the aim is to find if one out of the pooled DNA contains SNPs, I need to use all PacBio sequences instead of a subset.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/496#issuecomment-992270390:50,clear,clear,50,,https://github.com/google/deepvariant/issues/496#issuecomment-992270390,1,['clear'],['clear']
Usability,"Hello Pi-Chuan, thanks for answer above. Just to make it clear to me... I obtained a VCF file using version 1.4.0, but I cannot see the phase data (e.g., ""|"") in my sample. Does this mean that I need to call variants again using version 1.5.0 and the ""--phase_reads"" flag? Or does DeepVariant not explicitly provide this data, requiring me to run Whatshap + DeepVariant to visualize it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/649#issuecomment-1547108448:57,clear,clear,57,,https://github.com/google/deepvariant/issues/649#issuecomment-1547108448,1,['clear'],['clear']
Usability,"Hello again,. actually the evidence bam folder is borderline unusable, there are so many folders that the file explorer tries to commit suicide every time I attempt to navigate it, same for the ""built-in"" explorer of bam viewers, for example Tablet is simply unusable, it systematically crashes. . I don't know how feasible this is computationally but maybe it would be best if DeepVariant produced a single bam per sample. Or even a single bam per sample per chromosome. If the user wants to subsequently split the bam that's not too complicated (otherwise the bam files themselves are neat I am happy with the results ^^). . Thank you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/297#issuecomment-613950795:252,simpl,simply,252,,https://github.com/google/deepvariant/issues/297#issuecomment-613950795,1,['simpl'],['simply']
Usability,"Hello, . I write here again to say 2 things; - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code ; - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though.; Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1722449849:761,learn,learn,761,,https://github.com/google/deepvariant/issues/682#issuecomment-1722449849,1,['learn'],['learn']
Usability,"Hello, thanks for your answer. Actually my organism is an ancient tetraploid; it's quite old but we are able to find back the old duplicates easily (they just look like alleles with high divergence). The coverage in those regions doesn't deviate from what is expected. . I would bet the rotifers are variant dense, their genome is small (100 Mb) and there doesn't seem to be a lot of repeats. Somehow, it's quite the exact opposite of the human genome (large and full of repeats). ; The thing is, as it is an asexual, I can't replicate the trio strategy, as I only have a mother and a descendant. So I am unsure about what to do here. I was planning to call the variant in the mother and the daughter, assuming there should be all identical. Any new variant in the daughter I would regard as calling errors. (and I see new variants, though most of the variant in the daughter are the same as in the mother). I am unsure if retraining would make sense here. . EDIT: more simply, does the concept of a pedigree make any sense in a clonal organism?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/266#issuecomment-580767025:970,simpl,simply,970,,https://github.com/google/deepvariant/issues/266#issuecomment-580767025,1,['simpl'],['simply']
Usability,"Here I'll try to run Singularity on CentOS7 to see if I can reproduce the issue.; ; # Get a CentOS 7 machine; ```; gcloud compute instances create ""${USER}-centos"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""centos-7"" \; --image-project ""centos-cloud"" \; --machine-type ""e2-standard-16"" \; --zone ""us-west1-b"" \; --boot-disk-size ""200"" ; ```. # Install Singularity 3.5; Following steps here https://sylabs.io/guides/3.5/admin-guide/installation.html#installation-on-linux. Then I have:; ```; [pichuan@pichuan-centos singularity]$ singularity --version; singularity version 3.5.2; ```. # Run Quick Start with Singularity. I downloaded the data from [Quick Start](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md). and then I tried:; ```; singularity pull docker://google/deepvariant:1.1.0"". singularity exec --bind /usr/lib/locale/ \; docker://google/deepvariant:1.1.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --regions ""chr20:10,000,000-10,010,000"" \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --num_shards 24 -v 2; ```. This finished running and output the output.vcf.gz file without an issue. ---. Then, I was searching for ""status 252"" and found this earlier issue: https://github.com/google/deepvariant/issues/345 . At the end the issue seems to be that the CPU didn't have AVX instructions. Specifically, see @tedyun 's comment: https://github.com/google/deepvariant/issues/345#issuecomment-690820723. @williamrowell Can you check whether your CPU supports AVX instruction?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/419#issuecomment-774634611:437,guid,guides,437,,https://github.com/google/deepvariant/issues/419#issuecomment-774634611,2,['guid'],"['guide', 'guides']"
Usability,"Here is a [link to an article](https://neptune.ai/blog/hyperparameter-tuning-in-python-complete-guide) that provides a nice summary of them - with [another describing them more visually](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/) - and [a link to another nice article](https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8) describing what happens during hyperparameter tuning. There are other ways, but they become niche and sometimes based on the data, private. Usually this training is performed automatically [as shown here](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/), but you can generate the search space yourself like in this simple example - though there are [more parameters you can select from](https://github.com/google/deepvariant/blob/r1.5/deepvariant/modeling.py#L68-L110):. $`1)`$ Learning rate usually changes as you get closer to optimal accuracy, since you are getting closer to optimal and do not overshoot the local minimal in the hyperplane. If you are starting from an untrained model, you want learn as much as possible with the default value of `0.064`, but the closer you get to optimal you want to minimize it to something like `0.0005`. If let's say learning rate decreases exponentially with accuracy - meaning you want to tweak the model less as you become more accurate - then it would be something like `learning_rate` $= (1-(e^{accuracy-1})^\alpha)/\gamma$, where $\alpha = 5$ and $\gamma=0.1$, resulting in a chart like this:. ![image](https://github.com/google/deepvariant/assets/6555937/059d6a98-7365-4e06-a3df-a32876042733). Then you use that equation (or your own) to update the learning rate with each iteration of model training. $`2)`$ For batch size, you can have a discrete range like this `batch_sizes = [16, 32, 64]` to select from. Then for each iteration, you look at the metrics and select what to tweak, given the model you wan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294:1738,Learn,Learning,1738,,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294,1,['Learn'],['Learning']
Usability,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/519#issuecomment-1053728841:282,feedback,feedback,282,,https://github.com/google/deepvariant/issues/519#issuecomment-1053728841,1,['feedback'],['feedback']
Usability,"Hi @ASLeonard . This is an interesting question. The ability to sort reads and label them with a phasing tag (specifically HP) is general to DeepVariant (meaning that on the code level it is straightforward to add to DeepVariant). This feature is only used for long reads. We performed experiments in non-trio phasing of short reads, but found there is not enough information for local phasing to add information. . Trio phasing can be much more informative for short reads over long ranges. The main obstacle is that we do not have pre-trained models which have learned how to use this information as we have for long reads. It would, in theory, be possible to train models for this (though it would be a reasonable amount of work). One of the obstacles for us to do this is that we don't know what to recommend as the best practices for the trio binning process. . I don't think that variant calling on an assembly is necessarily a good idea, because the assembly itself will have errors, and the expected distribution of REF, HET, and HOM calls will be quite different from the typical variant calling problem. Assemblies are usually less complete than the reference, especially with short read data, and this is likely to create a lot of mapping artifacts. . I don't have any good recommendations for how to incorporate trio haplotype information at this time, but if you have reasonable suggestions on how to do so, we are happy to consider using them within DeepTrio. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/451#issuecomment-830342295:563,learn,learned,563,,https://github.com/google/deepvariant/issues/451#issuecomment-830342295,1,['learn'],['learned']
Usability,"Hi @AldoCP,. We have not comprehensively investigated performance on RNA-Seq samples yet. Because some components of the RNA-Seq problem more closely resemble variant calling in DNA-Seq exomes, I recommend that you use the exome model instead of the WGS one. A proper investigation would probably involve looking at the variant calls that result from the same sample with both DNA-Seq and RNA-Seq and investigating the concordance of calls. I expect that sort of comparison is probably worth a paper. . In general, we observe that when DeepVariant is applied in other domains beyond its training data, it tends to undercall as opposed to call false positive events, so if you are getting calls in DeepVariant and not HaplotypeCaller, those are worth looking into. If you do so, we would be interested in your feedback.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/115#issuecomment-457857605:809,feedback,feedback,809,,https://github.com/google/deepvariant/issues/115#issuecomment-457857605,1,['feedback'],['feedback']
Usability,"Hi @AndrewCarroll and @pgrosu. Thank you for your clear explanation. I understand the this case now and I am looking forward to seeing your new methods for handling these cases, as I believe it will be a significant improvement. I will explore using the method @pgrosu provided to temporarily process these varaints and ensure their uniformity. I will upgrade the version of DeepVariant in the next release of our project ([Chinese Quartet](https://github.com/xjtu-omics/ChineseQuartetGenome)). Furthermore, I noticed some information about DeepTrio in deepvariant homepage. Does DeepTrio support joint calling for quartet families (parents and **two** children)?. Best! ; Peng",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/660#issuecomment-1591182902:50,clear,clear,50,,https://github.com/google/deepvariant/issues/660#issuecomment-1591182902,1,['clear'],['clear']
Usability,"Hi @AndrewCarroll the output for `samtools view -H maddog_bam_trim_bwaMEM_sort_dedupped.bam | grep @SQ` is. ```; @SQ SN:I LN:15072434; @SQ SN:II LN:15279421; @SQ SN:III LN:13783801; @SQ SN:IV LN:17493829; @SQ SN:V LN:20924180; @SQ SN:X LN:17718942; @SQ SN:MtDNA LN:13794; ```. The alignment was done by a summer student working under the guidance of a post-doc (she recently had a baby so I didn't want to bother her) and it's possible a different reference version was used. In the error above I had used **c_elegans.PRJEB28388.WS274.genomic.fa**. We have another reference genome on our server so I tried it in-case this was the issue. Using **c_elegans.PRJNA13758.WS265.genomic.fa** deepvariant ran for more than 3 hours and then failed on Chromosome V with this error:. ```; ...; I0402 20:41:44.332051 47425001081536 make_examples.py:535] 25500 candidates (27904 examples) [26.82s elapsed]; I0402 20:42:04.004627 47425001081536 make_examples.py:535] 25600 candidates (28010 examples) [19.67s elapsed]; I0402 20:42:27.991226 47425001081536 make_examples.py:535] 25700 candidates (28130 examples) [23.99s elapsed]; I0402 20:42:35.967661 47425001081536 make_examples.py:535] 25813 candidates (28251 examples) [7.98s elapsed]; I0402 20:42:48.188316 47425001081536 make_examples.py:535] 25911 candidates (28355 examples) [12.22s elapsed]; I0402 20:42:49.405055 47425001081536 make_examples.py:535] 26014 candidates (28458 examples) [1.22s elapsed]; [E::fai_retrieve] Failed to retrieve block. (Seeking in a compressed, .gzi unindexed, file?); 2020-04-02 20:46:28.318323: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: Invalid argument: Couldn't fetch bases for reference_name: ""V"" start: 5524980 end: 5526020; Fatal Python error: Aborted. Current thread 0x00002b21fe57cac0 (most recent call first):; File ""/tmp/Bazel.runfiles_e68bsnf0/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 73 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/292#issuecomment-608553986:338,guid,guidance,338,,https://github.com/google/deepvariant/issues/292#issuecomment-608553986,1,['guid'],['guidance']
Usability,"Hi @AndrewCarroll,. Thank you very much for this detailed explanation, it is clear to me what is happening now. Unfortunately, this is rather problematic for my use case because I am processing a cohort (DeepVariant + GLnexus) and I impute the variants afterwards. The imputation is based on the PL values: If there are sites where some samples have an actual variant but most of the other samples have a no call (hence with a discrepancy between GQ and PLs), those sites will end up with a low imputation score. Since my reads are ONT corrected, I rely very much on the imputation scores as a post-filtering step to guarantee the quality of my set. Guillaume",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/403#issuecomment-760221333:77,clear,clear,77,,https://github.com/google/deepvariant/issues/403#issuecomment-760221333,1,['clear'],['clear']
Usability,"Hi @Asppagh ,. It can be many different reasons. ; Your machine setup definitely could be one of the factors.; And, not all inputs will take the same amount of time to run. For example, some regions in some BAMs might take longer to realign, etc. In DeepVariant, we tried to empirically set some thresholds so we hope that even the slowest cases are not too slow. But it's always useful to learn from our users what edge cases might still cause the DeepVariant to be slow. If your input BAM file is publicly sharable, you can also point us to it, and I'm happy to give it try and see if I can identify any reasons why it might be particularly slow. But it's also possible that your data is not publicly available. If that's the case, to diagnose your machine setup, you can start by running on some of our publicly shared data used in https://github.com/google/deepvariant/blob/r1.1/docs/metrics.md. Specifically under:; https://github.com/google/deepvariant/blob/r1.1/docs/metrics.md#how-to-reproduce-the-metrics-on-this-page. For example, you can run on our WGS BAM file: gs://deepvariant/case-study-testdata/HG003.novaseq.pcr-free.35x.dedup.grch38_no_alt.bam on your cluster using singularity , and see what runtime you're getting. And, one more question that will help us provide better support:; Do you know if make_examples finish running on your machine? If so, how long it took on how many cores? If make_examples finished, then what's the runtime on call_variants and postprocess_variants?; (One possible issue we've seen before is that the call_variants stage is slow if users run on CPUs without acceleration)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-864304812:390,learn,learn,390,,https://github.com/google/deepvariant/issues/463#issuecomment-864304812,1,['learn'],['learn']
Usability,"Hi @Asppagh ; From the error above it wasn't very informative. This seems like it failed on the make_examples step already. We should have just stopped there, instead of proceeding into call_variants and next steps. --> This is now fixed in internal code, and will be fixed in the next release. Another question is -- why did the failed make_examples not produce any useful logs?. This one is a bit less clear to me. . With the same setting, instead of using /opt/deepvariant/bin/run_deepvariant (which is a convenient script that combines 3 steps), can you try directly running with . `/opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord.gz""`. This should allow you to just run 1 make_examples, without using GNU parallel as well. Hopefully whatever error messages will be more clear here.; Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870041849:404,clear,clear,404,,https://github.com/google/deepvariant/issues/465#issuecomment-870041849,2,['clear'],['clear']
Usability,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/872#issuecomment-2329912331:431,learn,learned,431,,https://github.com/google/deepvariant/issues/872#issuecomment-2329912331,1,['learn'],['learned']
Usability,"Hi @Axze-rgb and Andrew,. Good catch on the newline character – it’s hard to slow down at times when things are fun :) . Before having a presentation -- as my bandwidth is a bit tight these days (though I usually love presentations) -- I would be curious to see what you first get from Clair3 and Andrew's candidate region, as well as any additional insight Andrew might get from the VCF. I have this funny feeling of what the outcome might be – and we can have the presentation later among the three of us (and anyone else that's interested) as things emerge more clearly. Thank you,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1652518468:565,clear,clearly,565,,https://github.com/google/deepvariant/issues/682#issuecomment-1652518468,1,['clear'],['clearly']
Usability,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832:20,clear,clearly,20,,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832,1,['clear'],['clearly']
Usability,"Hi @BowenKwan you can try modifying the `PILEUP_DEFAULT_WIDTH` contant in [this file](https://github.com/google/deepvariant/blob/r0.10/deepvariant/dv_constants.py#L41). I didn't try this myself, so some additional changes may be needed, but this is a good place to start. For local training, copying the data files locally and updating paths makes sense. Some other changes you will need are below. Does the machine you plan to use have a GPU?. * Run the `model_train` and `model_eval` binaries directly, rather than running via Docker. Examples on how to use binaries directly are in [this WES case study script](https://github.com/google/deepvariant/blob/r0.10/scripts/run_wes_case_study_binaries.sh). DeepVariant comes with scripts to build binaries on Ubuntu, with Ubuntu 16 recommended. Binaries can only be built for a UNIX-based OS. Depending on what system you are using, you will need to modify these scripts. If possible, I would suggest using Docker as that will have the simplest setup. * Currently, we use [DataflowRunner](https://beam.apache.org/documentation/runners/dataflow/) to [shuffle the generated TFRecords](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each). You will probably want to use some other runner here, such as [DirectRunner](https://beam.apache.org/documentation/runners/direct/), since DataflowRunner is for use with Google Cloud.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/291#issuecomment-607407000:983,simpl,simplest,983,,https://github.com/google/deepvariant/issues/291#issuecomment-607407000,1,['simpl'],['simplest']
Usability,"Hi @FarmOmics ,; I'll close this issue. We would love to hear your feedback about the RNAseq caller. Please don't hesitate to reach out again if you have more questions or feedback.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/572#issuecomment-1284746356:67,feedback,feedback,67,,https://github.com/google/deepvariant/issues/572#issuecomment-1284746356,2,['feedback'],['feedback']
Usability,"Hi @Fred-07 . When we investigated Element sequencing for exomes with the out-of-the-box Illumina models, we generally observed accuracy that was as good or better as that observed with Illumina without any retraining. With v1.5 the whole genome models do include joint training with Element data, and including element in WGS training does make Element accuracy somewhat further improved. I expect we'll try to get Element exomes and add them into the exome model training in the future, but for now I think you will see good performance with the existing exome model. If you do have any feedback on performance with Element exomes, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/703#issuecomment-1705737423:589,feedback,feedback,589,,https://github.com/google/deepvariant/issues/703#issuecomment-1705737423,1,['feedback'],['feedback']
Usability,"Hi @GuillaumeHolley . This is a complicated issue, and though I've looked into it, I'm not 100% sure the following is correct, but I am reasonably confident:. DeepVariant is consists of some human-written heuristics which are used to identify positions that are candidate to be variant. Identified candidates are given to the neural network for classification. After this classification, another set of human-written heuristics converts the output probabilities of the network to VCF and gVCF entries. . As part of this process, there are positions that were never proposed as candidates because they do not have enough support to reach the candidate generation threshold (for the PacBio defaults, this is at least 2 reads which support an alternate event with a minimum ALT fraction of 0.12, and where the reads used for the calculation have MAPQ>=5). When this threshold is not met, the site is always considered either a reference or a no-call, and human-written heuristics are used to make a determine the genotype quality of the position for binning in the gVCF. This logic is fairly simple, and can sometimes result in a calculation of HET being the most likely, even if DeepVariant's neural network never made a call. The GQ should be set to 0 in these cases. This occurs because we value the neural network's output much more highly, and would like only it to make calls. . Hopefully this helps clarify what is going on here. The situation and explanation is complicated, so please feel free to ask further questions. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/403#issuecomment-759187363:1089,simpl,simple,1089,,https://github.com/google/deepvariant/issues/403#issuecomment-759187363,1,['simpl'],['simple']
Usability,"Hi @HamiltonG. The one-step script whose usage is shown in https://github.com/google/deepvariant#how-to-run-deepvariant will work on a cluster, just note that giving it something like 64 threads will help it run faster.; Our case study [metrics](https://github.com/google/deepvariant/blob/r1.1/docs/metrics.md) are from runs with 64 CPU cores and no GPU, so those numbers should give you an idea if that works for your purposes. For the simple run_deepvariant case, if Docker isn't available to you on your cluster, the same container and commands can be used with Singularity. This is I think what most people do when running on a cluster. If you really want to optimize a process to run DeepVariant many times, it can be worth running the 3 stages separately and giving them different resources because make_examples wants many CPUs, call_variants runs faster on GPUs, and postprocess_variants really just needs 1 CPU. The [external solutions](https://github.com/google/deepvariant#external-solutions) do variations of this plus their own special sauce. I hope that helps answer your question,; Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/474#issuecomment-883613731:437,simpl,simple,437,,https://github.com/google/deepvariant/issues/474#issuecomment-883613731,1,['simpl'],['simple']
Usability,"Hi @JakeHagen . I took one of our 50x NovaSeq samples that are 150bp PE reads and trimmed the reads into 4 WGS consisting of a sample each for:. 1. first 100bp of the reads; 2. last 100bp of the reads; 3. first 75bp of the reads; 4. last 75bp of the reads. I wasn't able to replicate the effect that you see in any off the output reports. In your approach, did you trim the reads from the end (simply truncating to the first 75bp)? If so, I wasn't able to replicate the effect you see. There might be something more complicated about your sample. One possible explanation is that you have a run with lower sequencing quality and trimming to the first 75bp reads removes some lower quality parts which look suspicious to DeepVariant. If so, I wonder if your results would differ if you retained only the last 75bp reads. But I am not quite sure how to further diagnose. Here are my plots:. <img width=""1264"" alt=""HG003 novaseq 50x_only_first75bp"" src=""https://user-images.githubusercontent.com/583711/205179365-6a05941b-b6ba-47fc-b778-f970a9850651.png"">. <img width=""1266"" alt=""HG003 novaseq 50x_only_last75bp"" src=""https://user-images.githubusercontent.com/583711/205179387-7814e398-1b48-4476-9d35-6f93fafa8fbd.png"">. <img width=""1267"" alt=""HG003 novaseq 50x_only_first100bp"" src=""https://user-images.githubusercontent.com/583711/205179398-b2841a19-cb63-4ea1-9c7e-dfd79fad774d.png"">. <img width=""1286"" alt=""HG003 novaseq 50x_only_last100bp"" src=""https://user-images.githubusercontent.com/583711/205179415-a723bab5-e011-421b-a6a5-a7a750871159.png"">",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/586#issuecomment-1334570619:394,simpl,simply,394,,https://github.com/google/deepvariant/issues/586#issuecomment-1334570619,1,['simpl'],['simply']
Usability,"Hi @JakeHagen . I will take a look at running a similar analysis on our exome samples. I suppose one remaining possibility is that the truncation of the reads reduces how far beyond the capture region the sequencing is getting. The edges of the capture region tend to both have less coverage and it's harder to sample both alleles. That's just a guess, I don't have a clear answer and will still try to collect more data. When you run DeepVariant for the exome, do you restrict to the capture regions only and do you add any padding to those?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/586#issuecomment-1341790338:368,clear,clear,368,,https://github.com/google/deepvariant/issues/586#issuecomment-1341790338,1,['clear'],['clear']
Usability,"Hi @JakeHagen ; Currently there isn't a very clean way to do this. You can modify the code and build DeepVariant from source: https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-build-test.md. I'm personally interested in learning more about what you're trying to do - what is the expected input and output. If there's general enough use cases, maybe in the future we can make things easier to import, even though we don't currently have plans for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/344#issuecomment-689698461:235,learn,learning,235,,https://github.com/google/deepvariant/issues/344#issuecomment-689698461,1,['learn'],['learning']
Usability,"Hi @NIBIL401 . I don't see any other specific issues in your command. Without knowing more about the specific types of differences, it's difficult to give advice on what might be missing. One observation that we do have is that DeepVariant has learned not to call RNA editing events as variants. These are post-transcription changes to the RNA sequence. Those edits appear as A->G and T->C in sequencing data. To give more advice beyond this, I think I would need to know more about the sequencing (the most ideal would be to have some a BAM file or snippet with a variant call not being made that we can diagnose why). Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/775#issuecomment-1962219387:244,learn,learned,244,,https://github.com/google/deepvariant/issues/775#issuecomment-1962219387,1,['learn'],['learned']
Usability,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,; Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/517#issuecomment-1050344301:52,clear,clear,52,,https://github.com/google/deepvariant/issues/517#issuecomment-1050344301,1,['clear'],['clear']
Usability,"Hi @Npaffen , I'm late to this thread. If I'm missing some context please feel free to remind me. Regarding your question ""**why the homref variants and the missings are added to the vcf in the first place**"":. DeepVariant starts with a set of candidates. These candidates came from a set of heuristics that propose a bunch of sites that potentially have variants.; You can find some thresholds we use for the heuristics here: https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L194; which basically means - if there is an alt allele that has a certain number of reads supporting it, and a certain % of reads supporting it, it will be proposed as a potential candidate. Then, DeepVariant applies a classifier on these candidates. To learn more about the representation that DeepVariant uses, https://google.github.io/deepvariant/posts/2020-02-20-looking-through-deepvariants-eyes/ is a good explanation. Each of the example (""image"") has a probability distribution for 3 classes. Based on the probability, the GT is assigned. As mentioned in previous answers, when the probability distribution from DeepVariant shows that it's not as confident, the GT is set to `./.`. By default, DeepVariant outputs the candidates even when they're classified as `0/0`, or when they're set to `./.`. ; This won't affect downstream tools like hap.py, though. Because these are not considered when tools like hap.py calculates accuracy. What DeepVariant outputs complies with the VCF spec, which says ""FILTER - filter status: PASS if this position has passed all filters, i.e., a call is made at this position."" If you look at our VCF, you'll notice that all variants (not including `0/0` and `./.`) should have `PASS`. Hopefully this helps. @Npaffen let me know if there's anything else that's unclear.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1610105430:772,learn,learn,772,,https://github.com/google/deepvariant/issues/666#issuecomment-1610105430,1,['learn'],['learn']
Usability,"Hi @Npaffen . This is an interesting question. One advantage is that is these sites give a complete accounting of all positions that the neural network acts on. This makes it easier for us to debug issues (either internally or user-presented) as we remove the variable of whether a row in the VCF was not present because a candidate was not generated, or because the neural network decided it was reference. From a developer perspective (whether internal or external), this is much cleaner. . There is another advantage in allowing users to determine the ideal threshold for sensitivity (e.g. if they highly value sensitivity, they may want to consider positions which are ./. calls of low GQ). These are more advanced use cases and it does seem that most users opt for simpler approaches. . I also tend to think that including these variants won't confuse users, and that they would be used to variant callers using things like the FILTER field to indicate non-variant calls. But if you have a strong opinion that this will be broadly confusing, I will take that into account.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1611797347:770,simpl,simpler,770,,https://github.com/google/deepvariant/issues/666#issuecomment-1611797347,1,['simpl'],['simpler']
Usability,"Hi @Npaffen . Yes, in phase variants, the reads are assigned a haplotag value. Briefly, in this process, a set of potential variants are scored with heuristics (no neural network) on the likelihood that they are heterozygous variants. A cluster of such variants forms a candidate seed for a haplotype. The evidence from multiple reads across multiple positions are used to identify the putative variants on that haplotype, and then reads are scored based on whether they fall into one of the haplotypes, the other, or cannot be phased. Because this haplotagging uses information from much longer stretches and more candidate variants than the individual process of variant calling, it has the advantage of a broader set of information. This haplotagging is used to populate the information in the ""haplotype channel"" which is one of the inputs for DeepVariant long read data. We [wrote a blog](https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/) describing this channel and its impact. Note that this process is only used to provide the information to the neural network for consider, the neural network will be able to learn when this channel is or is not reliable based on genome context, coverage, etc... the network's call on the genotype is what finally goes into a variant. As a result, haplotag is not used as input to generate the non-ref blocks of the gVCF, and as the final variants called are still from the neural network, the definition of a variant remains the same - a position with an ALT allele that receives a non-reference (0/0 or ./.) call. We are currently working on a deeper description of the phasing logic used in DeepVariant, which may help understand or reproduce the haplotag method more easily. Please let me know if anything in the explanation is unclear or can be elaborated further.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1602118672:1146,learn,learn,1146,,https://github.com/google/deepvariant/issues/666#issuecomment-1602118672,1,['learn'],['learn']
Usability,"Hi @Npaffen,. That's great to hear that it worked! Let me answer each question individually:. `1` DeepVariant for the PACBIO model enables `--phase-reads` as shown below, but it is only used internally for improving the accuracy by [expanding the region of finding candidates](https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_core.py#L1305-L1321):. https://github.com/google/deepvariant/blob/r1.5/scripts/run_deepvariant.py#L255. This will not show phased reads in the VCF file. You are correct in that you will need to use a tool like [`WhatsHap`](https://whatshap.readthedocs.io/en/latest/guide.html) to update the VCF file with phasing information. `2` The output for the filter column is generated in the following way for most cases (biallelic):. `2.1` `call_variants` generates the genotype probabilities using the PACBIO model (for this case), for the candidates generated by `make_examples`. `2.2` `postprocessing_variants` operates all of this through the [`add_call_to_variant()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L304-L340) function:. `2.2.1` For each variant's predicted genotype probabilities it looks at the highest probability, denoting that being the most likely genotype. It then generates it via the [`most_likely_genotype(predictions, ploidy=2, n_alleles=2)`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L193-L273) function. `2.2.2` It then takes that most likely genotype and uses it [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function, to generate the appropriate filter. Basically it, strictly looking at the genotype and it if it sees it as [0, 0] (i.e. 0/0) it will label the Filter column as RefCall. `2.2.3` Then the [`uncall_homref_gt_if_lowqual()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L286-L301) function will label the genotype ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1601744318:616,guid,guide,616,,https://github.com/google/deepvariant/issues/666#issuecomment-1601744318,1,['guid'],['guide']
Usability,"Hi @Npaffen,. To expand a bit on my previous explanation, regarding the way you can view a variant coming from a neural network is through the idea of preserving $`information`$ $`propagation`$. You saw the previous description of how the different channels get encoded, but let's start with a simpler version. Let say you have a one-line matrix with the following columns:. ![image](https://github.com/google/deepvariant/assets/6555937/d46a3924-2ea4-4b92-8c9c-9fcc29bb7219). This could denote a simplified version of your read base representation, where you notice the middle denotes the variant, and the last column the channel it represents. Now I want to create new types of data from this, which will help me with identifying unique areas of patterns within it. This could be of the form of transformation of the values to ranges that are easier to detect differences among columns. One of these can be dividing all the values by 10, and labeling that channel 2. In this transformation, 10 represents a kernel I described previously and the output is a new feature map (a transformed matrix that helps with detecting unique features based on the numerical representation). Now the data would look like this:. ![image](https://github.com/google/deepvariant/assets/6555937/e52786fd-00b8-4dc9-ad60-c400a30b0f79). Now imagine I create different transformations of these rows, to expand on specific areas among these values where intriguing patterns might emerge. Suppose I create 5 different transformations having then 5 channels with multiple copies of each row, in order to have a fuller dataset that mimics the number of reads. This data is multi-dimensional as it contains different values of X. This can be pretty hard to interpret, but we can collapse these differences to a 2D representation using [t-SNE plots](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) to visualize these differences. For example, if I do that to this dataset, I get the following plot:. ![i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/666#issuecomment-1612282088:294,simpl,simpler,294,,https://github.com/google/deepvariant/issues/666#issuecomment-1612282088,2,['simpl'],"['simpler', 'simplified']"
Usability,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/518#issuecomment-1050404831:479,feedback,feedback,479,,https://github.com/google/deepvariant/issues/518#issuecomment-1050404831,1,['feedback'],['feedback']
Usability,"Hi @PlatonB ,; In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/538#issuecomment-1817559748:452,feedback,feedback,452,,https://github.com/google/deepvariant/issues/538#issuecomment-1817559748,1,['feedback'],['feedback']
Usability,"Hi @Qianwangwoo ,; First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). ; ; From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`.; And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/528#issuecomment-1067120303:838,intuit,intuitive,838,,https://github.com/google/deepvariant/issues/528#issuecomment-1067120303,1,['intuit'],['intuitive']
Usability,"Hi @SHuang-Broad . By default, DeepVariant only looks at the content of the QUAL field (column 11) in order to populate the quality values. DeepVariant is able to look at and read in arbitrary additional tags (e.g. we have used the HP tag for phasing in the past). We have not previously experimented with BAQ, but with the framework above it would not be hard to look at it if you have an intuition that it might help. If you think it is promising, we could either do this investigation ourselves, or we could try to give you some instructions on how to do an experimental training if you are interested. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/565#issuecomment-1251305150:390,intuit,intuition,390,,https://github.com/google/deepvariant/issues/565#issuecomment-1251305150,1,['intuit'],['intuition']
Usability,"Hi @Sh1von ,. Thanks for reporting this. Currently that's how our pipeline is designed unfortunately. We don't automatically resume. However, if make_examples and call_variants has completed successfully, you can manually run postprocess_variants separately. The way to figure out the commands to use : You can run your original command with `--dry_run`, and then it'll break down the sequence of commands you need. Then, you can manually rerun the postprocess_variants command. I understand that being able to resume can be a useful feature. To automatically detect existing data robustly will be challenging, because we don't know if there might be corrupted data. But, I think it'll be possible to add a flag for users to skip steps. I will think about it a bit more. For now, please try manually re-run postprocess_variants, and see if that works for you. Sorry for the inconvenience!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/587#issuecomment-1319519059:125,resume,resume,125,,https://github.com/google/deepvariant/issues/587#issuecomment-1319519059,2,['resume'],['resume']
Usability,"Hi @Stikus , ; actually , it seems like simply removing the line; ```; #include <optional>; ```; will build. From the code, we're using ""optional"" from tensorflow::gtl::optional. So we don't really need the #include here. I have confirmed that removing this line builds on Ubuntu14.04. Please give that a try. If it doesn't work, let me know. I will make an internal fix, which will come out in the next release. For now, please make a local edit before you build.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/236#issuecomment-557265475:40,simpl,simply,40,,https://github.com/google/deepvariant/issues/236#issuecomment-557265475,1,['simpl'],['simply']
Usability,"Hi @Suke-fudan , if your confusion is mainly about this line `The height of the input image is not 100 (standard in DeepVariant) or 300 (standard in DeepTrio). `, please ignore it for now. Internally we plan to remove that warning because it is confusing. To be clear:; - Our DeepTrio WGS and PACBIO models are trained with child height=60, and parents height=40. (Therefore 140 total).; - Our DeepTrio WES model was trained with child height and parents height=100, which is 300 total. If you're running PACBIO or WGS, you will see the (incorrect) warning about 140 isn't standard. If that's the case, please feel free to ignore that warning. We will improve in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/488#issuecomment-940505896:262,clear,clear,262,,https://github.com/google/deepvariant/issues/488#issuecomment-940505896,1,['clear'],['clear']
Usability,"Hi @WeiweiBian . In our discussion over email, I recommended that you use a somatic caller instead of trying to adapt DeepVariant to your needs, and I still think this is the best way to go. To answer your questions:; 1. No, this is a limit within Inception V3 that DeepVariant uses.; 2. We don't have any other training tutorials for other systems.; 3. We have done some exploratory work on a somatic variant caller, but it is not available yet, and it is meant for tumor-normal pairs with much lower coverage and higher allele frequency. It will not be possible to use this for your case. I think you would be much better off using a somatic variant caller for your research.; If you want to take transforming DeepVariant into a somatic caller on as a research project, you are welcome to do so, since it's open source. But we unfortunately don't have the bandwidth to guide you very much, since we have other exciting improvements to DeepVariant that we are already working on. Best of luck with your work!; Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/308#issuecomment-628304654:871,guid,guide,871,,https://github.com/google/deepvariant/issues/308#issuecomment-628304654,1,['guid'],['guide']
Usability,"Hi @Wenfei-Xian,. A max MAPQ score of 42 will likely have some effect, but I expect not an enormous one. I suspect that MAPQ at the lower end of the ranges would be more important, since if well-calibrated a difference between PHRED=42 and PHRED=60 is a very low additional absolute error probability. I have some bowtie mapped reads handy for a GIAB sample. I think I can conduct a quick experiment to see if that intuition is right.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/809#issuecomment-2067533385:415,intuit,intuition,415,,https://github.com/google/deepvariant/issues/809#issuecomment-2067533385,1,['intuit'],['intuition']
Usability,"Hi @X1angyang . The model is InceptionV3. You can see the layers of one of the DeepVariant models like this:; ```; import tensorflow as tf. !gsutil cp gs://deepvariant/models/DeepVariant/0.10.0/DeepVariant-inception_v3-0.10.0+data-wgs_standard/model* /tmp/; checkpoint_path = '/tmp/model.ckpt'. reader = tf.compat.v1.train.NewCheckpointReader(checkpoint_path); shape_map_for_layers = reader.get_variable_to_shape_map(); print(shape_map_for_layers); ```; I just tested that in Colab (https://colab.research.google.com/). However, reimplementing all of DeepVariant from bam to output VCF would be a huge project. If you are interested in something smaller to get started, I'd like to bring this blog post to your attention: https://google.github.io/deepvariant/posts/2019-01-31-using-nucleus-and-tensorflow-for-dna-sequencing-error-correction/.; It has an associated Colab notebook that walks through some smaller but still challenging examples of how to use genomic data in machine learning using TensorFlow and Nucleus. I hope that helps!; Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/328#issuecomment-663252998:981,learn,learning,981,,https://github.com/google/deepvariant/issues/328#issuecomment-663252998,1,['learn'],['learning']
Usability,"Hi @Zjianglin , I took a quick look of the script and I'm not sure I fully understand what you're testing here. I tried a simplified version on my side. (The following steps has nothing to do with DeepVariant anymore. I'm mostly just testing `ls` and `singularity` right now). First I got these files in my /tmp; ```; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; wget -P /tmp ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P /tmp ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; ```. Then I made my deepvariant.sif. ```; singularity build deepvariant.sif docker://google/deepvariant:1.5.0; ```. First, I check that I have the files; ```; REF=/tmp/ucsc.hg19.chr20.unittest.fasta; ls -al ${REF}*; ```; This worked.; (Note, you were doing something like `ls -al ""${ref_idx}*""`. Don't add the double quotes around the *. That didn't work for me. ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant.sif \; ls -al ${REF}*; ```. This also worked fine for me. I can see the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/653#issuecomment-1573188242:122,simpl,simplified,122,,https://github.com/google/deepvariant/issues/653#issuecomment-1573188242,1,['simpl'],['simplified']
Usability,"Hi @ZuyaoLiu ,; To confirm what you said -- do you mean that you train your own model (on your own data) and was able to get a much lower Mendelian violation rate? If so, that's great!!. Given that this is a non-human sample (not what we trained on), it seems like the right way to proceed is either to use our DeepTrio model, or like you said, to use your own customized model. So far both approaches seem like they would produce quite decent Mendelian violation rate. In the future, our team is interested in thinking more about making our model more generally robust to all non-human species as well. So thank you for your feedback. Hopefully the two options (either DeepTrio or your own model) will work for you for now. I'll close this issue now, but please feel free to share more thoughts.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/726#issuecomment-1852999418:626,feedback,feedback,626,,https://github.com/google/deepvariant/issues/726#issuecomment-1852999418,1,['feedback'],['feedback']
Usability,"Hi @aderzelle . Thank you, this is a good question. We have observed this phenomenon as well. The answer is somewhat complicated. . DeepVariant seems to have learned something about the concept of segmental duplication, where positions that appear to be variants are actually due to mismapping of similar regions which may (or may not) be captured in the reference genome. The way this manifests in a genome pileup is as one phased haplotype that is mostly reference and (one or more) phased haplotype that is variant-dense. The signal for this is further enhanced when the VAF is closer to 0.33 or 0.25 (more directly suggesting copy number 3 or 4), but it can also occur close to 0.5 (which can still indicate a copy number of 4). These regions can be variants in thee diploid genome that are incorrectly called as REF, or they could be markers of a copy number variant. In human genomes, this can suggest a user look into that region for either known copy number variants or coverage differences. One question to ask - are these regions at generally higher coverage than you would expect? . In certain variant-dense species, we have observed this phenomenon to complicate calling [in this blog we investigate this for mosquito genomes](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). In this blog, we show the ability to re-train for a variant-dense species using a pedigree. If you have a pedigree available, we could also explore this with you. We are working on ways that will allow DeepVariant to more explicitly indicate when it thinks this is the case, and to provide more information (e.g. average coverage in the sample) to DeepVariant that will allow it to better separate variants from makers of segmental duplication.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/266#issuecomment-580713806:158,learn,learned,158,,https://github.com/google/deepvariant/issues/266#issuecomment-580713806,1,['learn'],['learned']
Usability,"Hi @aderzelle . Today we released DeepVariant v0.9, which contains several changes to code and training models. As part of this release, we have introduced changes which fix the issue for the BAM snippets presented, and which we think will generally fix the issue that you observed in other cases. To briefly summarize what we believe to be the cause - in candidate generation, a de Bruijn graph of variant and reference haplotypes is constructed. In rare cases, some graph paths are created in which local connections are valid, but no individual read supports the entire path. In your case, this caused two similar representations to generate candidates at different positions, each of which could be locally supported. In our fix, we require at least some support for the constructed graph of the candidate haplotype. We also noticed a separate fix that resolves your case. Specifically, your case was sensitive to the kmer length used to construct the graph. By default, this is 10, but we noticed that increasing to 15 also resolved your issue. We think this may reflect local repetitiveness. We have exposed this parameter in make_examples as: --dbg_min_k. This is available when running make_examples directly, but not in the Docker image. Since the issue should be resolved in v0.9 without this change, this is mostly for your information if you want to experiment with other tweaks. We would be interested to hear your feedback confirming this case is resolved in v0.9. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/209#issuecomment-553647872:1428,feedback,feedback,1428,,https://github.com/google/deepvariant/issues/209#issuecomment-553647872,1,['feedback'],['feedback']
Usability,"Hi @aderzelle ; First of all, when I first think of ""deterministic"" behavior, I usually think about whether the exact same input yields the same results. Which we've made effort to make sure that running on the same input on the same machine should have deterministic behavior. If you have noticed non-deterministic behavior on the same sample, please do let us know. That said, you're absolutely right. These two represent the exact same event, but simple comparison scripts will not understand those events are in fact identical. ```; 90123; TGGGT; T--GTTC <-- Sample 1; TGTTC <-- Sample 2; ```. I think other users have reported to us in the past. So far we haven't looked closely into the code logic yet, because we mostly rely on tools such as `hap.py` for normalizing these during evaluation. So, this is a known behavior but haven't been investigated yet. And I do agree that it'll be good if we can behavior more consistently. . I will file an internal issue to track this (if we don't have one already). I can't guarantee when it'll be addressed though. If you have more suggestions on whether one representation might be better than the other, let me know. I'm closing this issue, but feel free to add your thoughts here. Thank you for reporting this!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/202#issuecomment-517123277:450,simpl,simple,450,,https://github.com/google/deepvariant/issues/202#issuecomment-517123277,1,['simpl'],['simple']
Usability,"Hi @aderzelle ; thanks for your feedback. If you have a chance to try out the two images I shared:; ```; gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg; gs://deepvariant/singularity_images/deepvariant-0.9.0.simg; ```; Please let me know whether they work for you or not. If you see any issues, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/243#issuecomment-562237254:32,feedback,feedback,32,,https://github.com/google/deepvariant/issues/243#issuecomment-562237254,1,['feedback'],['feedback']
Usability,"Hi @aditya-88, I looked into this issue a bit further. Unfortunately, I don't think using a `disutils.spawn`-style solution will be possible here. There are a few different things to point out. First, we need not just the `pyclif` binary, but other files that get created when you install CLIF. Here are all the files present in my `clif` directory:. ```; $ ls clif; bin clang examples include lib local pip-selfcheck.json python share; ```. Second, even if you did obtain all the needed CLIF files, we still cannot check for them to present at other paths. In our [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L78) for Bazel, we create a `new_local_repository` for CLIF. Creating this `new_local_repository` requires specifying a full absolute path in advance (more details in [the docs](https://docs.bazel.build/versions/master/be/workspace.html#new_local_repository)). Two solutions for you to get around this would be:; 1. Create a symlink to your CLIF directory via `ln -s $SOME_PATH/clif /usr/local/clif`; OR; 2. Modify the path in the [`WORKSPACE` file](https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L81). For example, if your files are at `/home/my_account/clif/`, you can change the path to `/home/my_account`. We can definitely make this more clear in our documentation in the future.; @pichuan Feel free to add on if I missed anything.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/160#issuecomment-472209625:1296,clear,clear,1296,,https://github.com/google/deepvariant/issues/160#issuecomment-472209625,1,['clear'],['clear']
Usability,"Hi @ajsa-nukovic ,; Sorry for the confusion. Starting from v1.1.0, we added an additional channel to our PacBio model, and tried to simplify the flags in the one-step `run_deepvariant` by adding just one flag `--use_hp_information`, which you can set to false if you're BAM is not phased, and set to true if your BAM is phased. Example:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md#run-deepvariant-on-haplotagged-chromosome-20-alignments. However, from your command, I see that you're running make_examples directly, which is a reasonable use. But you're specifying your own make_examples flag for 1.1.0 code and model, you'll need to add `--add_hp_channel` to make sure the last channel is added. So, to summarize, if you're specifying your own flags for the make_examples step:; - If your BAM is NOT phased: use `--sort_by_haplotypes=false --parse_sam_aux_fields=false --add_hp_channel=true`.; - If your BAM is phased: use `--sort_by_haplotypes=true --parse_sam_aux_fields=true --add_hp_channel=true`.; Basically, in v1.1.0, `add_hp_channel` needs to always be set to true when you're running make_examples for PacBio. . I'll see if I can update the r1.1 documentation to avoid future confusions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/458#issuecomment-844317545:132,simpl,simplify,132,,https://github.com/google/deepvariant/issues/458#issuecomment-844317545,1,['simpl'],['simplify']
Usability,"Hi @amy-houseman . The strand of the read is one of the input channels in DeepVariant, so it is able to see that information and to learn the effects of strand bias on variant calling during training. For more information on what data is seen by DeepVariant, you can see the blog [Looking through DeepVariant's eyes](https://google.github.io/deepvariant/posts/2020-02-20-looking-through-deepvariants-eyes/). We don't write the strand information itself in the variant calls. For filtering, we instead recommend using the GQ field, which we find to be well calibrated with the probability of genotype error. Because DeepVariant sees the strand information, it will incorporate this into its confidence about the variant. If you have some specific aspect of your problem which you think the strand of reads will behave different from the genomes and exomes DeepVariant is trained on, and you want to do independent filtering, you would have to find some other method to annotate the strand information as DeepVariant does not write this directly to the VCF.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/719#issuecomment-1767795328:132,learn,learn,132,,https://github.com/google/deepvariant/issues/719#issuecomment-1767795328,1,['learn'],['learn']
Usability,"Hi @anands-repo . This is something that we observe in training as well, and has also been reported by other users - [see this GitHub issue](https://github.com/google/deepvariant/issues/185) for deeper discussion. In short, this occurs because not all variables are loaded when warmstarting a model. Retraining does quickly re-learn, but this is the reason for the initial drop. You should still be able to train models to high accuracy, despite this phenomenon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/383#issuecomment-727745570:327,learn,learn,327,,https://github.com/google/deepvariant/issues/383#issuecomment-727745570,1,['learn'],['learn']
Usability,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/230#issuecomment-546050008:577,learn,learn,577,,https://github.com/google/deepvariant/issues/230#issuecomment-546050008,1,['learn'],['learn']
Usability,"Hi @anands-repo ; Our codebase still supports TPU like before!; We decided to change our training tutorial to use GPU and CPU because it's a more general setting. Even though our code still supports TPU, we think it's better to simplify our tutorial.; If you encounter any issues when using DeepVariant with TPU, and if you suspect the issue might be in our codebase, please let us know.; (Btw, out of curiosity : have you been training DeepVariant model with TPUs? If you are using that, I would actually really love to hear your feedback. I didn't think we have that many external users with this functionality yet.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/376#issuecomment-720015500:228,simpl,simplify,228,,https://github.com/google/deepvariant/issues/376#issuecomment-720015500,2,"['feedback', 'simpl']","['feedback', 'simplify']"
Usability,"Hi @anands-repo, glad you were able to get it working! I don't have any other comments on the fix and will defer to the relevant bazel issue. In general, I would recommend running DeepVariant using Docker for the simplest setup. If you are building from source because you want to experiment with changes to the codebase, I'd still recommend Docker. You can clone the DeepVariant repo, modify the source code, and build a Docker image with your changes using [the provided Dockerfile](https://github.com/google/deepvariant/blob/r1.0/Dockerfile).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/356#issuecomment-698549305:213,simpl,simplest,213,,https://github.com/google/deepvariant/issues/356#issuecomment-698549305,1,['simpl'],['simplest']
Usability,"Hi @andrewrech ; I'll be closing this issue.; To add on the previous answer about `TF_CUDA_VERSION`: currently run-prereq.sh has multiple paths to install tensorflow. If you end up building tensorflow from scratch it self, the env variable `TF_CUDA_VERSION` might be picked up by that. Internally we don't really use that code path anymore so I'm not sure if it actually still works. I'll make a note to simplify and clean up run-prereq.sh in the future. Please feel free to open another bug if you have more questions. If you have more suggestions regarding this particular issue, feel free to follow up here as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/145#issuecomment-467081816:404,simpl,simplify,404,,https://github.com/google/deepvariant/issues/145#issuecomment-467081816,1,['simpl'],['simplify']
Usability,"Hi @anitagh ,; the release won't come out within a week. Sorry for the inconvenience. For now you'll have to run make_examples separately and add the `--sample_name` flag. Another way to fix this is to make sure your BAM file header has one SM tag in it. If your BAM file is not very big, using `samtools reheader` to add a proper SM tag might also be a reasonable solution for now. If you're using GCP, you can try out the Google Cloud version that @samanvp pointed to in earlier comments. (If you have any feedback on that tool, please report to https://github.com/googlegenomics/gcp-deepvariant-runner/issues.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/222#issuecomment-535654563:508,feedback,feedback,508,,https://github.com/google/deepvariant/issues/222#issuecomment-535654563,1,['feedback'],['feedback']
Usability,"Hi @ankurc17 ; Can you tell us more about what the issues are?; For example, what OS are you using, what command did you run and what error messages you've seen.; It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/574#issuecomment-1276221161:234,learn,learn,234,,https://github.com/google/deepvariant/issues/574#issuecomment-1276221161,1,['learn'],['learn']
Usability,"Hi @annabeldekker ,; one more thing to point out -- depending on which version you're using, we actually changed (improved) the way PacBio flags works between version 1.0.0 and 1.1.0. In the older v1.0.0, we asked users to set two flags `sort_by_haplotypes` and `parse_sam_aux_fields`:; https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-pacbio-model-case-study.md#run-deepvariant-on-haplotagged-chromosome-20-alignments. We simplified in the current v1.1.0 by creating one new flag `use_hp_information`: so you only need to set `--use_hp_information` if your BAM has HP tags. You no longer need to set `sort_by_haplotypes` and `parse_sam_aux_fields` separately, and in fact, please just use `use_hp_information` instead of setting the other flags directly to avoid confusion, because you're using v1.1.0. To summarize, for v1.1.0, please set `--use_hp_information=true` if your BAM has HP tags. If your BAM doesn't have HP tags, set `--use_hp_information=false` (or don't specify it - false is the default). Thanks for reporting this. In the future we're looking into whether we can make this simpler by building some phasing functionality into DeepVariant, so we don't have to our users to run the two-step process for PacBio. But for now, it's best to follow the [Quick Start](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md) of the corresponding version, and make sure you use the flags as recommended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/457#issuecomment-844209552:439,simpl,simplified,439,,https://github.com/google/deepvariant/issues/457#issuecomment-844209552,2,['simpl'],"['simpler', 'simplified']"
Usability,"Hi @annabeldekker . I'll paste some similar information from my answer in the other issue: https://github.com/google/deepvariant/issues/458#issuecomment-844317545. Hopefully my answer below will help you as well:. Starting from v1.1.0, we added an additional channel to our PacBio model, and tried to simplify the flags in the one-step `run_deepvariant` by adding just one flag `--use_hp_information`, which you can set to false if you're BAM is not phased, and set to true if your BAM is phased. Example:; https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-pacbio-model-case-study.md#run-deepvariant-on-haplotagged-chromosome-20-alignments. This `--use_hp_information` flag in the one-step `run_deepvariant` command actually controls both `sort_by_haplotypes` and `parse_sam_aux_fields` in the make_examples stage. If you set `--use_hp_information` to true in the one-step `run_deepvariant` command, that means `sort_by_haplotypes` and `parse_sam_aux_fields` are both set to true in make_examples stage. And if you set `--use_hp_information` to false, that means `sort_by_haplotypes` and `parse_sam_aux_fields` are both set to false in make_examples stage. In both cases, if you're running for PacBio, you always have to set `--add_hp_channel` to true in make_examples stage make sure the last channel is added. (If you're using the one-step `run_deepvariant` command, `--add_hp_channel` is automatically added). We tried our best to encaspulate these 3 flags into just one `--use_hp_information` in our one-step `run_deepvariant` command. However, I understand this might have caused further confusion when people tried to use the make_examples binary on its own.; You can find the logic here: ; https://github.com/google/deepvariant/blob/r1.1/scripts/run_deepvariant.py#L240-L242. I will try to update our deepvariant-pacbio-model-case-study.md file to document this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/457#issuecomment-845522247:301,simpl,simplify,301,,https://github.com/google/deepvariant/issues/457#issuecomment-845522247,1,['simpl'],['simplify']
Usability,"Hi @brentp @kokyriakidis ,. We (genomics team in Google Health) have released DeepVariant 0.10 on 3/26, which includes improving consistency and accuracy by turning off `ws_use_window_selector_model` by default, along with the following other changes:; - Updated to Python3 and TensorFlow2; - Improved PacBio model for amplified libraries. For more information, please read our release notes: https://github.com/google/deepvariant/releases/tag/v0.10.0 ; If you have any feedback about your experience with v0.10, please let us know. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/272#issuecomment-605207780:470,feedback,feedback,470,,https://github.com/google/deepvariant/issues/272#issuecomment-605207780,1,['feedback'],['feedback']
Usability,"Hi @chapmanb , another update:. I went through a lot of hacky steps and built CLIF. I'm actually not sure whether it's actually usable or not, so if you have a setup that quickly give it a try, that will be great. Here's the instruction on how to get `pyclif` to run on a CentOS 6 machine:; ```; # Get a machine; gcloud beta compute instances create ""${USER}-centos6"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""centos-6"" --image-project ""centos-cloud"" \; --machine-type ""custom-64-131072"" \; --boot-disk-size ""300"" --boot-disk-type ""pd-ssd"" \; --zone ""us-west1-b"". # ssh into it; gcloud compute ssh ${USER}-centos6 --zone us-west1-b; ```. ```; ##### On the GCE instance #####; # Install Python 2.7; sudo yum install -y centos-release-SCL; sudo yum install -y python27; source /opt/rh/python27/enable. gsutil -m cp gs://deepvariant/packages/oss_clif/oss_clif.centos-6.9.latest.tgz /tmp/; (cd / && sudo tar xzf ""/tmp/oss_clif.centos-6.9.latest.tgz""); sudo ldconfig # Reload shared libraries.; ```; (I had to build with Python 2.7. Didn't figure out how to build with 2.6. Let me know if you actually need Python 2.6?). Once you do this, you can run `/usr/local/clif/bin/pyclif` and should see the usage:; ```; $ /usr/local/clif/bin/pyclif; usage: pyclif [-h] [--py3output] [--matcher_bin MATCHER_BIN] [--nc_test]; [--dump_dir DUMP_DIR] [--binary_dump] [--modname MODNAME]; [--prepend PREPEND] [--include_paths INCLUDE_PATHS]; [--ccdeps_out MODNAME.cc] [--ccinit_out MODNAME_init.cc]; [--header_out MODNAME.h] [--cc_flags CC_FLAGS] [--indent INDENT]; input_filename; pyclif: error: too few arguments; ```. Please let me know once you have a chance to try it.; CentOS 6 is tricky. It feels like everything is old :(; Let me know what other things are blocking you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/29#issuecomment-385864674:128,usab,usable,128,,https://github.com/google/deepvariant/issues/29#issuecomment-385864674,1,['usab'],['usable']
Usability,"Hi @charlesfeigin,. It's great that things are being run as a non-root user. So to simplify the steps for reaching a solution, I just need three things from you:. 1. The complete set of commands that were typed for launching DeepVariant.; 2. The directories where the input files are located.; 3. The complete output of errors that were seen after DeepVariant was launched. This way we can reconstruct a runnable state. If you don't know everything, that's fine but at least steps 1 & 3 are necessary to begin to reconstruct step 2. Thanks,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1699480255:83,simpl,simplify,83,,https://github.com/google/deepvariant/issues/184#issuecomment-1699480255,1,['simpl'],['simplify']
Usability,"Hi @colsen ; thanks for confirming that the file was there. At this point I don't have a clear next guess on what could have been wrong. But can you check these two things:. 1. Confirm that docker see this file:; Run a similar command:. docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" ls /input/hg19.fasta*. This can confirm that docker actually sees the file. (should have both hg19.fasta and hg19.fasta.fai). 2. Run another program to make sure the the fasta file is well-formed. Given that you have tried samtools faidx it without issue, I think this is probably not the issue, but might still be good to check. @Roj4ck if you have more suggestions on this, please feel free to chime in!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/310#issuecomment-637679152:89,clear,clear,89,,https://github.com/google/deepvariant/issues/310#issuecomment-637679152,1,['clear'],['clear']
Usability,"Hi @crazysummerW , ; in your first step, you mentioned ""pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@rg\tID:test1\tSM:test1'"". Can you explain to me what you're trying to do in this step?. You also mentioned DeepConsensus. Are you planning to start from your own PacBio subreads BAM?; Unless you're starting with subreads, you don't need to apply DeepConsensus. If you are starting with PacBio HiFi reads (which I think is most of the DeepVariant users), you should directly map your FASTQ files using pbmm2, which gives you a BAM file, then you apply DeepVariant on the BAM. However, if you are indeed starting from PacBio subreads, you will need to follow https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md to obtain the FASTQ file (which is the output that DeepConsensus gives you). Then, you map the FASTQ file, which gives you a BAM file, then you apply DeepVariant on the BAM. From your original question, it isn't quite clear to me what you're trying to do here. Can you elaborate?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/672#issuecomment-1615164671:982,clear,clear,982,,https://github.com/google/deepvariant/issues/672#issuecomment-1615164671,1,['clear'],['clear']
Usability,"Hi @crazysummerW . Thank you for the pileup and for the trace. The trace makes it clear there isn't a variant here. . With respect to this variant call, there are a few things that I see: . First, DeepVariant has a very low confidence in this call. The GQ of 4 corresponds to a 40% chance of being incorrect. Interestingly, the second most likely call at this position according to DeepVariant is 0/0 (HomRef). This is in spite of a 0.27 variant allele frequency (something that most callers would probably consider as either 0/0 HomRef or 0/1 HET). . This is an indication that DeepVariant may think that one of the haplotypes (either the Ref one or the Alt one) are unreliable (e.g. that they are reads which map from a different part of the genome), but doesn't know which to consider. Some other lines of evidence DeepVariant might use for that is the higher coverage (1200 is a coverage that would often be seen in duplicated parts of the genome) and the unusual allele frequency ratio (70% Ref, 30% Alt). Another piece of evidence we can't see but DeepVariant may use is the Insert Size channel if this is Illumina data. . A few questions -. 1) What is the sequencing technology used here, and which type of instrument. Is this PacBio or Illumina here? ; 2) Is this some form of panel sequencing targeting the region? . One suggestion to try (especially if this is panel short read sequencing) - downsample the region to ~80-100 coverage and see if the call changes. Especially look for the GQ confidence to go up as 4 is very low. If you want to avoid such situations more, you might want to put a higher GQ threshold for downstream filtering, and for a specific case like this look for cases where the PL values show higher probability for HOMREF and ALT than HET. A GQ threshold of 10 would be a 90% probability the call is correct, a GQ threshold of 20 would be a 99% threshold. . Just from the evidence presented here, this site is going to be difficult to call, as just on the VAF this loo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/655#issuecomment-1570674832:82,clear,clear,82,,https://github.com/google/deepvariant/issues/655#issuecomment-1570674832,1,['clear'],['clear']
Usability,"Hi @danielecook , I was trying various things that would require least amount of effort. I ended up just skipping and using the `google/deepvariant` docker image as-is.; I'm no expert in docker, just trying to get things running. ; Then I also have the issue that singularity can't use/convert the deepvariant docker image:; ```; $ singularity build --sandbox deepvariant_1_1_0 docker://gcr.io/deepvariant-docker/deepvariant:1.1.0; WARNING: Building sandbox as non-root may result in wrong file permissions; Docker image path: gcr.io/deepvariant-docker/deepvariant:1.1.0; ERROR MANIFEST_UNKNOWN: Manifest with tag '1.1.0' has media type 'application/vnd.docker.distribution.manifest.v2+json', but client accepts 'application/json'.; Cleaning up...; ```; This may be my inexperience in these things, but I'm simply having trouble getting them running.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/445#issuecomment-822613451:807,simpl,simply,807,,https://github.com/google/deepvariant/issues/445#issuecomment-822613451,1,['simpl'],['simply']
Usability,"Hi @dhwani2410 . Is there any chance that this is from a sample for which publicly available data is present (e.g. HG001). I could look at pileups in the region for a more informed opinion. To your question about different variants - DeepVariant classifies event on a position-by-position basis, so the classifier does not have information about what output it gave at nearby variants. This can cause you to know a bit more than the classifier when looking at its full output. But it explains why the classifier can have a different result when two variants are putatively phased. One phenomenon that we observe with DeepVariant is that it often calls positions with substantial support as reference when they are nearby to other variants. This seems to be related to regions of segmental duplication, where the apparent variants come from reads that are mismapped to the region. We have a poster which documents this effect: https://pbs.twimg.com/media/ERe2bSyWsAcE00h?format=jpg&name=4096x4096. So DeepVariant seems to learn something of the signature of segmental duplication and is likely not calling these positions as variant for this reason. On average, DeepVariant seems to be correct in these cases (that they are not true variants) more often than it is incorrect, which is why it has learned this pattern. However, it will not be correct in all cases. Either way, when you observe this pattern, it is a good idea to look at the region and consider whether the apparent variants may come from a duplication of related sequence.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/318#issuecomment-645810441:1021,learn,learn,1021,,https://github.com/google/deepvariant/issues/318#issuecomment-645810441,2,['learn'],"['learn', 'learned']"
Usability,"Hi @dmarkie . Thank you for your feedback. We did struggle and discuss internally on the representation that we should use for the hemizygous calls to make. Ultimately, we decided to use 0/0 and 1/1 for our presumption that this would break fewer downstream methods. However, some of that is a subjective judgement. The compromise of having the option in postprocess to handle this is an interesting one. We'll talk internally about the amount of effort and maintenance to support this. I can't make a commitment to anything now, but it is a very reasonable proposal.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/751#issuecomment-1854763028:33,feedback,feedback,33,,https://github.com/google/deepvariant/issues/751#issuecomment-1854763028,1,['feedback'],['feedback']
Usability,"Hi @elcortegano . Just to clarify, are you referring to the QUAL field of the VCF (the 6th column of tab-file itself), or the GQ field (the 10th column of a single sample). If you are referring to QUAL as the 6th column, this observation is expected. QUAL measures the probability that the ALT field has at least one allele with the ALT base. So you can think of it as p(HET) + p(HOM), or alternatively as 1 - p(REF). For homozygous positions, they look more clearly non-reference as in many cases they may not have any reference bases. . Heterozygous positions likely have at least some evidence for the Ref allele, which suggests a higher probability that the position might be Ref. If you are interested in filtering, we often recommend that the GQ field in the samples is preferable, as this is a measure of the genotype call itself being correct. There may be some differences between HET and HOM for this due to differences in difficulty in making those types of calls. However, it should be lower.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/547#issuecomment-1194472227:459,clear,clearly,459,,https://github.com/google/deepvariant/issues/547#issuecomment-1194472227,1,['clear'],['clearly']
Usability,"Hi @fardokhtsadat . I realize in looking at the VCF entry, I was mistaken in saying DeepVariant sees a SNP and an Indel. In fact, it sees the candidates as you wrote. CAGCAGCGCT -> C; CAGCAGCGCT -> T. That's entirely on me, it should be clear from the VCF, and I don't have an excuse to make such a basic mistake. The call looks correct, it does look like a HET deletion of AGCAGCGCT. It looks like the realigner has decided to place a gap at this position and left-align the trailing T at the edge of the deletion so that when it is present it looks like a SNP. It's hard to authoritatively say why the realigner is going something without getting the actual BAM snippet and looking at the realignment. That part is in the heuristics of DeepVariant not the neural net. As a result of the re-alignment, DeepVariant sees the T SNP as a candidate but seems to correctly reject it. I think that's what's going on. In any case, a candidate here for the SNP seems to be a function of the realigner? . The behavior should not have changed from DeepVariant v1.2 to v1.5. In general, uncalled multiallelic events should be a relatively rare phenomenon. . Generally, if you need to, you can prune the alleles that are not called in DeepVariant VCF as long as the result of pruning stays compliant with the VCF spec expected by any downstream tools.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/618#issuecomment-1470986150:237,clear,clear,237,,https://github.com/google/deepvariant/issues/618#issuecomment-1470986150,1,['clear'],['clear']
Usability,"Hi @fengcong3 . DeepVariant has been applied to plant species. In the case of rice, there was good evidence of high accuracy superior [some results in this blog](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So in cases with polyploid organisms (which includes wheat), it is not yet clear how DeepVariant will perform. However, I am also not sure how other variant callers perform on polyploid samples. If you (or anyone) knows current polyploid callers for wheat, I would like to know and to run benchmarks between the two. Finally, it is possible to train DeepVariant models for a specific genome. We have a previous example of this in mosquitos [see our blog](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). We hope to explore training a general plant model or a general non-human model in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/200#issuecomment-513411694:502,clear,clear,502,,https://github.com/google/deepvariant/issues/200#issuecomment-513411694,1,['clear'],['clear']
Usability,"Hi @forumsan, thanks for reporting this issue! Others users have reported seeing this message as well. When we looked into this issue internally, we found out that this was actually a problem with logging in TensorFlow, and AVX-512 instructions are being used correctly. If you try running DeepVariant on a CPU-only machine that does not support AVX-512, you should see a clear increase in the overall runtime. The logging issue has since been fixed in TensorFlow, but won't show up in our current Docker images. This is because we are installing a version of the intel-tensorflow package that does not contain the fix. I'll close this issue for now, but feel free to reopen if you still have other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/301#issuecomment-617907163:372,clear,clear,372,,https://github.com/google/deepvariant/issues/301#issuecomment-617907163,1,['clear'],['clear']
Usability,"Hi @genieusbio ,. One thing to note:. In https://gist.github.com/pichuan/baba6ee9bd9890be2a45076a4934dd38 , when you run `run_deepvariant`, this flag is specified: `--regions /input/idt_capture_novogene.grch38.bed`. Which means only the variants within the regions specified in the BED is used. If you look at the BED file:. ```; $ head -5 ./input/idt_capture_novogene.grch38.bed; chr1 69090 70008; chr1 450739 451678; chr1 685715 686654; chr1 925941 926013; chr1 930154 930336; ```. which does not include the region you're looking for. If you want to force call everything in that BAM file, you can simply remove the flag `--regions /input/idt_capture_novogene.grch38.bed` from your run. The downside is that will take longer. Or, if you just want to make sure that particular region is covered, then you can use @pgrosu 's suggestion and specify a small region that covers that range. Hopefully this is clear.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/708#issuecomment-1720730115:601,simpl,simply,601,,https://github.com/google/deepvariant/issues/708#issuecomment-1720730115,2,"['clear', 'simpl']","['clear', 'simply']"
Usability,"Hi @gevro . DeepVariant has two steps in calling variants. In the first (**make_examples**) a fairly simple, human-written heuristic identifies positions that are potentially variant and creates pileup examples of them. In the second stage (**call_variants**), a neural network classifies whether those positions are real variants or not and genotypes them. A RefCall entry occurs when a candidate variant is proposed and then is specifically rejected as non-variant. In addition, the model provides an estimate of its confidence (expressed as the QUAL and GQ fields for the entry). In the gVCF, a separate process determines the confidence for regions of the genome where no candidate is proposed and combines this with the information of the positions that have received a RefCall. For GLnexus, the genotyping is able to include the knowledge that these positions have a proposed alternate allele, but received a reference call.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/386#issuecomment-728248806:101,simpl,simple,101,,https://github.com/google/deepvariant/issues/386#issuecomment-728248806,1,['simpl'],['simple']
Usability,"Hi @githubtefo ,; When you run the command, you should have logs in the terminal.; Can you provide those logs?. And, can you try something simple like https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-pacbio-model-case-study.md first? That should certainly have logs when you run it. If not, there's something else wrong in your environment that we need to understand first.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/810#issuecomment-2068119641:139,simpl,simple,139,,https://github.com/google/deepvariant/issues/810#issuecomment-2068119641,1,['simpl'],['simple']
Usability,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/569#issuecomment-1264952905:639,learn,learned,639,,https://github.com/google/deepvariant/issues/569#issuecomment-1264952905,1,['learn'],['learned']
Usability,"Hi @husamia . I am curious, are you working with human sequence data, or do these come from non-human species?. I will take a look at the ratio of these events in our sample. If we could provide a simple filtering script to postprocess a callset, would this be something that you might use?. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/450#issuecomment-830343312:197,simpl,simple,197,,https://github.com/google/deepvariant/issues/450#issuecomment-830343312,1,['simpl'],['simple']
Usability,"Hi @husamia . Thank you for the extra information. If there is any feedback that you can provide, I would be very grateful for examples. If you would like to follow up by email, you can reach me at awcarroll@google.com. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/450#issuecomment-831068064:67,feedback,feedback,67,,https://github.com/google/deepvariant/issues/450#issuecomment-831068064,1,['feedback'],['feedback']
Usability,"Hi @imdanique ,; Thanks for the update.; Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file.; Does that make sense?; To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/577#issuecomment-1285622624:303,simpl,simplifying,303,,https://github.com/google/deepvariant/issues/577#issuecomment-1285622624,1,['simpl'],['simplifying']
Usability,"Hi @internalsensor , please see my answer below.; (And, can you give us some feedback on why you don't use the Docker version, but decided to use the prebuilt binaries instead? Thank you!). ===; Hi @internalsensor , ; I think it's likely what @pgrosu said about multiple versions installed. It'll be useful to figure out what actually got used. I was not able to reproduce the error you found.; In case it's useful, here is what I did to try to reproduce. I used a modified version of the WES script, in which I made sure I pip install a pinned version of intervaltree, and I downloaded the prebuilt binaries instead of rebuilding on my own:. ```; git clone https://github.com/google/deepvariant.git; cd deepvariant; wget https://gist.githubusercontent.com/pichuan/5a1216e080ccaf286810af062d6cb7a2/raw/20f6b3e9473b8f2e7d520edace1f2bb7a7231f06/run_wes_case_study_prebuilt_binaries.sh; bash -x run_wes_case_study_prebuilt_binaries.sh; ```. This worked with the prebuilt binaries v0.7.2. So I wasn't able to reproduce your error.; You can also use `pip show intervaltree` to double check what pip package you have.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/155#issuecomment-464534790:77,feedback,feedback,77,,https://github.com/google/deepvariant/issues/155#issuecomment-464534790,1,['feedback'],['feedback']
Usability,"Hi @japhill ,; Just to make sure I understand this - are you saying that the Docker image has /mnt in it, and as result was causing problem with Singularity?. I do see a /mnt directory:; ```; $ sudo docker run google/deepvariant:1.3.0 ls -lh /; total 48K; lrwxrwxrwx 1 root root 7 Oct 6 16:47 bin -> usr/bin; drwxr-xr-x 2 root root 4.0K Apr 15 2020 boot; drwxr-xr-x 5 root root 340 Mar 23 23:34 dev; drwxr-xr-x 1 root root 4.0K Mar 23 23:34 etc; drwxr-xr-x 2 root root 4.0K Apr 15 2020 home; lrwxrwxrwx 1 root root 7 Oct 6 16:47 lib -> usr/lib; lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib32 -> usr/lib32; lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib64 -> usr/lib64; lrwxrwxrwx 1 root root 10 Oct 6 16:47 libx32 -> usr/libx32; drwxr-xr-x 2 root root 4.0K Oct 6 16:47 media; drwxr-xr-x 2 root root 4.0K Oct 6 16:47 mnt; drwxr-xr-x 1 root root 4.0K Dec 6 23:17 opt; dr-xr-xr-x 525 root root 0 Mar 23 23:34 proc; drwx------ 1 root root 4.0K Dec 6 23:15 root; drwxr-xr-x 5 root root 4.0K Oct 6 16:58 run; lrwxrwxrwx 1 root root 8 Oct 6 16:47 sbin -> usr/sbin; drwxr-xr-x 2 root root 4.0K Oct 6 16:47 srv; dr-xr-xr-x 13 root root 0 Mar 23 23:34 sys; drwxrwxrwt 1 root root 4.0K Dec 6 23:19 tmp; drwxr-xr-x 1 root root 4.0K Oct 6 16:47 usr; drwxr-xr-x 1 root root 4.0K Oct 6 16:58 var; ```; which is empty, so I think your suggestion of something like ""RUN rm -rf /mnt/"" makes sense. I'll also do a quick search to see if there are better approaches here. Thanks for the feedback. I'll track internally and make sure this is updated in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/530#issuecomment-1076920454:1457,feedback,feedback,1457,,https://github.com/google/deepvariant/issues/530#issuecomment-1076920454,1,['feedback'],['feedback']
Usability,"Hi @jdmontenegro . For the question about multi-allelic heterozygous calls - yes, DeepVariant is able to all 1/2 events, and will represent these in one line as a GT 1/2 call in the VCF. For CLR calling in DeepVariant. It is theoretically possible for us to make a model for DeepVariant that can call CLR data. However, this requires us to write a special candidate generation logic to deal with the higher error rate. Based on what we perceive for the direction of future use in the genomics community, we think that data generated will be increasingly HiFi, so we have not been able to highly prioritize CLR models. Feedback from users like yourself will be useful to us in evaluating if that prioritization makes sense. For now, I can't commit to a timeframe under which we would support a PacBio CLR model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/347#issuecomment-693053180:618,Feedback,Feedback,618,,https://github.com/google/deepvariant/issues/347#issuecomment-693053180,1,['Feedback'],['Feedback']
Usability,"Hi @jguhlin ,; thanks for the feedback, and for letting us know that our users are still interested in Singularity images.; I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. ; But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:; https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```; gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg; gs://deepvariant/singularity_images/deepvariant-0.9.0.simg; ```; Or you can find them in the browser here:; https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you?. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:; https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```; VERSION=0.9.0; sudo apt -y update && sudo apt-get install -y docker.io; sudo docker pull google/deepvariant:${VERSION}; sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest; sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2; sudo docker push localhost:5000/deepvariant:latest; SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest; ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```; singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant-${VERSI",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/243#issuecomment-561996442:30,feedback,feedback,30,,https://github.com/google/deepvariant/issues/243#issuecomment-561996442,1,['feedback'],['feedback']
Usability,"Hi @jkalleberg ,; please see See: https://gist.github.com/pichuan/7ad09bf1fa8f519facf6806eca835ea6. I'll close this issue for now. Feel free to open more issues if you have any questions or feedback for us.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/568#issuecomment-1256836258:190,feedback,feedback,190,,https://github.com/google/deepvariant/issues/568#issuecomment-1256836258,1,['feedback'],['feedback']
Usability,"Hi @jordimaggi ; For anything that is `RefCall`, that means: even though a candidate variant was proposed, our machine learning classifier decided the most likely class is 0 (which means reference). ; You can read this section to get a bit more background on this: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. You could potentially take the finer-grained information (like `PL`) and try to adjust your own threshold. This could increase the sensitivity, but will likely hurt the specificity of DeepVariant's results. I'll ask @AndrewCarroll to add his thoughts here as well. Hi @splaisan , for the existing fields we have in our VCF file, we follow the standard definitions you can find on https://en.wikipedia.org/wiki/Variant_Call_Format#Common_FORMAT_fields (and we only fill in a subset of them). Let us know if there's anything specific that is not clear to you. Happy to explain more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/531#issuecomment-1082175599:119,learn,learning,119,,https://github.com/google/deepvariant/issues/531#issuecomment-1082175599,2,"['clear', 'learn']","['clear', 'learning']"
Usability,"Hi @jumpyknight . **tl;dr - VCF_caller represents experimental functionality not ready for production use**. DeepVariant has three stages **make_examples** identifies candidate positions that may be variants using relatively simple human-written heuristics. **call_variants** applies the trained neural net model to identify which of these candidates are real variants and at what probability. **postprocess_variants** converts these probability to a VCF output. From the first versions of DeepVariant, very_sensitive_caller has been the logic used to generate candidates for make_examples. VCF_caller is an experimental feature we have been developing that would allow the generation of candidates directly from an input VCF, so that different (or third-party) logic could be applied to generate candidates. However, this feature is not ready for production use. Its inclusion here occurs because this code is in our main branch at the release time and reflects our internal use and experiments with it. DeepVariant v0.9 still uses very_sensitive_caller to generate candidates and VCF_caller is not used for any released model. We attempt to fully document and mention in release notes features that are ready for use. Your eyes to the released code are astute, I was not expecting to field questions for VCF_caller.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/256#issuecomment-568660419:225,simpl,simple,225,,https://github.com/google/deepvariant/issues/256#issuecomment-568660419,1,['simpl'],['simple']
Usability,"Hi @kishwarshafin,. Thanks for the feedback, I actually forgot to get back to you about this but I have indeed filtered out the `NoCall` for the small cohort I have after your early feedback and it indeed solved this issue. Good luck with solving this!. Guillaume",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/521#issuecomment-1102489422:35,feedback,feedback,35,,https://github.com/google/deepvariant/issues/521#issuecomment-1102489422,2,['feedback'],['feedback']
Usability,"Hi @kokyriakidis ; MKL is an important part of the speed improvement for the `call_variants` step in the v0.7 release.; We don't currently have tried on AMD, so I can't say what the performance will be like. I'd like to learn more if you try it and have some numbers to share. . In general it's pretty difficult for the DeepVariant team to give advice on hardware or fine-tuning for a specific configuration. I usually think of that as an open-ended research problem itself, because many factors could come into play. I think @pgrosu 's advice above is the best. Start documenting numbers with your current configuration, continue with various hypotheses (""can I use less RAM?"", ""am I building with the optimized flags for my setting?"", etc) and trying them out. Continue to document the numbers and see if your hypotheses got proved or disproved. If you have any observations that are different from the statement we made in our GitHub documentations, we'd really appreciate you let us know. Your original question (in the title) is interesting - I only recently heard about Tensor Cores. We've mostly rely on TensorFlow (which DeepVariant used in the `call_variants` step) to interface with various hardware (CPU/GPU/TPU) below. But as you noticed that there are still things users/developers need to know at the level of DeepVariant, such as making sure we use MKL-enabled TensorFlow version, etc. Regarding Tensor Cores, I don't know enough to answer your question yet. But I'll ask around and reply back when I hear more. For now, I'll close this issue because I think @pgrosu and I have provided enough meta-information as we can. Feel free to open another issue if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/157#issuecomment-465225098:220,learn,learn,220,,https://github.com/google/deepvariant/issues/157#issuecomment-465225098,1,['learn'],['learn']
Usability,"Hi @kyleaoconnell22 . Can I ask a few other questions - first, have you already attempted to use the human model, and, if so, do you have any indication of issues?. Second, do you know some of the rough properties of the genome (does it have a high repeat content? Do you know the approximate variant density and heterozygosity)?. We have been doing some experimentation with silver standard training data. We don't have any conclusive recommendations. We have thought about ising GATK for the silver lablels, but we're worried that this might carry the sort of artifacts that GATK makes into the deep learning model. Another idea we are looking at is to subset the Genome in a Bottle labels to regions which are more similar to the properties of the species to train a model for. I would suggest that this might be more promising as an approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/459#issuecomment-858073154:602,learn,learning,602,,https://github.com/google/deepvariant/issues/459#issuecomment-858073154,1,['learn'],['learning']
Usability,"Hi @leorippel, DeepVariant has previously been applied to plant species. In the case of rice, there was good evidence of high accuracy. You can see [some results in this blog post](https://cloud.google.com/blog/products/data-analytics/analyzing-3024-rice-genomes-characterized-by-deepvariant). However, these rice genomes were diploid and with a similar variant density of humans. DeepVariant is currently written to be a diploid variant caller. So if the plant species you are working with is polyploid, it is not yet clear how DeepVariant will perform. That said, I am also not sure how other variant callers perform on polyploid samples. It would be possible to train DeepVariant models for a specific genome, but this would require a gold set for the training. We have a previous example of this in mosquitos [in this blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/357#issuecomment-698486292:519,clear,clear,519,,https://github.com/google/deepvariant/issues/357#issuecomment-698486292,1,['clear'],['clear']
Usability,"Hi @li1ba . For the question about why does the model have a difficult time calling this 1/1 versus 0/1, we have done further investigation. First, it doesn't look like this is a bug in pre-processing or how the data is represented. It seems to be a property of the model. . Second, the property of the model seems to reflect something learned about exome sequencing as opposed to WGS. To determine that, we ran your snippet through both the WGS and WES models. The WGS model is able to confidently call this site as 1/1:. ```; chr2 24146804 . C T 34.1 PASS . GT:GQ:DP:AD:VAF:PL 1/1:34:162:0,162:1:34,45,0; ```. When we run the WES model, we replicate your finding (this is with the most recent DeepVariant v1.4, so there is a small difference in the GQ values. ; ```; chr2 24146804 . C T 29.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:162:0,162:1:26,0,1; ```. This suggests that there is some aspect of exome sequencing that the DeepVariant WES model has learned makes this variant difficult to genotype, possibly because there is some signal that indicates only one allele is present. The reason for this might be some factor which isn't understood (at least by me). This is an interesting observation, but really understanding the reason for a 0/1 call at this position would probably need more investigation (for example, by going into the GIAB training labels for exome sequencing and seeing how often positions that look like this are 0/1 versus 1/1 and trying to understand why). With respect to why your collaborator has different results from you, it's very likely that the difference in mappers has a small effect on which reads are present and how many map discordantly. This small difference pushes the output for the variant on the edge of probabilities between 0/1 an 1/1 to the other side.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/592#issuecomment-1335960453:336,learn,learned,336,,https://github.com/google/deepvariant/issues/592#issuecomment-1335960453,2,['learn'],['learned']
Usability,"Hi @linlin-coder ,; Thank you for bringing up this issue. I noticed that you're working on PacBio data. The reason why this is happening is:. In v1.3.0 or older, DeepVariant didn't have the read haplotagging functionality built in. If you see https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md , you'll see that we asked our users to run DeepVariant --> WhatsHap --> DeepVariant with HP information to get the best accuracy. Starting from v1.4.0, **DeepVariant** has the read haplotagging functionality built in. However, **DeepTrio** doesn't have this yet, even in the latest version. That's why in https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-pacbio-case-study.md , you'll see this sentence. > The `--use_hp_information` arg makes use of a phased reads, thus allowing a further improvement of the accuracy. You can use tools like whatshap to phase. So, for now, if you want to get the best accuracy using DeepTrio, our suggestion will be:; Run DeepVariant first --> Use WhatsHap to get HP tags for your read --> Run DeepTrio with the `--use_hp_information` tag. I'm sorry that we were not being a lot more clear in our documentation. In our next release (plan to be out before the end of this year), we will have the read haplotagging feature directly built in in DeepTrio as well, so that you won't have to worry about having to run WhatsHap in between, starting from our next release. @linlin-coder Let me know if you have more questions that I can help clarify. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/689#issuecomment-1660748817:1166,clear,clear,1166,,https://github.com/google/deepvariant/issues/689#issuecomment-1660748817,1,['clear'],['clear']
Usability,"Hi @loipf , ; You can use `--help` with the different binaries, for example:. ```; docker run google/deepvariant:1.0.0 /opt/deepvariant/bin/run_deepvariant --help; ```. To see the various binaries, you can use:; ```; docker run google/deepvariant:1.0.0 ls /opt/deepvariant/bin/; ```; to list all the binaries. Then, for example, you can run:. ```; docker run google/deepvariant:1.0.0 /opt/deepvariant/bin/show_examples --help; ```. or any other binaries. I understand your point though. It might be easier if we have a more clear help page without knowing the structure. I'll think about this and see if we can improve in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/362#issuecomment-709713660:524,clear,clear,524,,https://github.com/google/deepvariant/issues/362#issuecomment-709713660,1,['clear'],['clear']
Usability,"Hi @loipf ; I've made changes in internal code. It'll come out in the next release.; After the next release, feel free to let us know if have more feedback.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/362#issuecomment-737653058:147,feedback,feedback,147,,https://github.com/google/deepvariant/issues/362#issuecomment-737653058,1,['feedback'],['feedback']
Usability,"Hi @maca8e . You are correct that DeepVariant_unfiltered is a preferable preset for DeepTrio calling. We had meant to update that in the case study documentation for the most recent release, and failing to do so is an oversight that we will correct. The DeepTrio paper does describe the unfiltered preset as preferable, and it should be reflected here. . With respect to a reference for DeepTrio's workings, have you seen the [DeepTrio preprint](https://www.biorxiv.org/content/10.1101/2021.04.05.438434v1)? If so, is there an item you would like described in greater detail. With respect to why NA12891/NA12892 are not used for training the parent model, this is simply because NIST does not have a truth set for these samples, while a truthset from NIST is available for HG001.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/475#issuecomment-892390206:664,simpl,simply,664,,https://github.com/google/deepvariant/issues/475#issuecomment-892390206,1,['simpl'],['simply']
Usability,"Hi @maryawood ,; The default values in make_examples.py are our recommendations.; We do adjust things a bit based on different datatypes. For example, for PacBio, we changed --vsc_min_fraction_indels to 0.12:; https://github.com/google/deepvariant/blob/r1.1/scripts/run_deepvariant.py#L238; ```; special_args['vsc_min_fraction_indels'] = 0.12; ```. For retraining, it will depend on your data. For example, using different mappers could end up with different expected distributions of the mapping quality, and you might want to adjust accordingly. Given that training is a more advanced topic and it highly depends on your data, I don't have a simple recipe for that. One general rule is that you want to adjust these thresholds so that the candidate generation step is sensitive enough to propose the true variants, but not over sensitive that it ends up proposing too much noise.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/464#issuecomment-867256204:644,simpl,simple,644,,https://github.com/google/deepvariant/issues/464#issuecomment-867256204,1,['simpl'],['simple']
Usability,"Hi @mclaugsf,. Let me give you a bit more context here on the runtime of call_variants. call_variants is the deep learning component of DeepVariant, so it relies on TensorFlow to execute the inception_v3 model used to evaluate our genotype likelihoods. In the 0.7 case study, make_examples creates 5,847,041 genomic tensors that need to be evaluated. When executing using CPUs, TensorFlow by default uses all of the available cores on the machine. So in our case study, which runs on a 64 core machine, we are using all 64 cores to evaluate these tensors. . So a rough estimate of the core-hours needed for the DeepVariant WGS case is:. 64 cores * 205 minutes of runtime ~= 219 core hours ~= 9 days. So if you are running on a machine with a single core, you should see call_variants take ~9 days. This is a bit of an over-estimate because 64 cores isn't 64x more efficient than 1 core. . Based on your 1 day turn around I'd guess you are running on a machine with 8 cores. Note these numbers assume you are using a modern CPU with AVX etc instruction sets. Not having those can increase the runtime by ~4x or so. Also I want to ask - in your original post are you processing exomes? If so, are you providing a capture regions bed to make_examples? Normally an exome produces < 100k examples (contrast that with 5.8M in a whole genome) so the runtime should be 60x less on an exome. That means instead of 9 days on a single core you are looking at 3.5 hours.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/105#issuecomment-430736386:114,learn,learning,114,,https://github.com/google/deepvariant/issues/105#issuecomment-430736386,1,['learn'],['learning']
Usability,"Hi @meghanasp21 . Yes - ""PASS"" variants are the ones that DeepVariant has made a call and indicate that DeepVariant thinks there is a germline variant at the position.; You can also refer to : https://samtools.github.io/hts-specs/VCFv4.2.pdf; ```; FILTER - filter status: PASS if this position has passed all filters, i.e., a call is made at this position. ; ```; Other than the conventional ""PASS"" to indicate that the tool has made a call, you might also see many other values being filled into this field. Especially if you have run somatic callers, you might notice people use it for various reasons why they filter out a variant. Currently, in DeepVariant, you might see another value ""RefCall"" - this means that DeepVariant identifies a position as a potential candidate early on, but the machine learning model decided that it is actually Ref (0/0). . So yes, for DeepVariant, you should just look at the ones that has ""PASS"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/300#issuecomment-617897260:803,learn,learning,803,,https://github.com/google/deepvariant/issues/300#issuecomment-617897260,1,['learn'],['learning']
Usability,"Hi @melkerdawy , thanks for reporting this issue.; In general it is difficult for us (as the developers of DeepVariant) to give advice on the training behavior of other people's data. I can, however, from a perspective of a fellow ML researcher, ask a few more questions here to see if we can help you make progress:. (1) You said ""Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero."" --> The wording you have is confusing. I believe what you see here means that the `model_eval` code takes the checkpoints generated by `model_train`, and evaluated on the tuning data you've generated. And, based on the labeled tuning data, if the model thinks there are either no TNs(True Negatives) or FNs (False Negatives) --> this seems to indicate that it's likely at this point, the model might just don't call any negatives at all. But it's just my guess based on what you observe. (2) Before we even dig deeper into the training behavior, can you check this:; What is the distribution of your labeled data? For example, in the regular DeepVariant formulation, we have 3 classes, ""0"" -- HOM_REF, ""1"" -- HET, ""2"" --HOM_ALT. HET and HOM_ALT are the ones that are consider germline variants, while HOM_REF calls will result in `RefCall` in the final DeepVariant VCF files.; To give you an example, in our [0.8 release](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md#deepvariant-training-data), our total number of examples for WGS was 346,505,686. And the distribution was:; ```; class 0, count: 101,679,899; class 1, count: 145,911,730; class 2, count: 98,914,057; ```; There is no fixed recommendation of what the ratio should be. It depends on a lot of factors such as what is your BAM file like, what is the threshold you're using in the first round of very sensitive caller (which picks the candidat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/203#issuecomment-518462111:365,learn,learning,365,,https://github.com/google/deepvariant/issues/203#issuecomment-518462111,1,['learn'],['learning']
Usability,"Hi @melkerdawy ,; the DeepVariant codebase is currently designed to for DNA data only. The underlying tool and principle (of converting genomic data into a machine learning problem) could be generalized. But the existing tool as is isn't designed or used for RNA-seq data. In another word - it could work, but it will be open-ended research. I'd recommend you looking into how DeepVariant is done, and look into the [Nucleus](https://github.com/google/nucleus) library as well. We just recently announced a pip package for Nucleus. . Feel free to share your experimental results and discuss any issues you've encountered. We'll try our best to answer and discuss with you here. (Closing for now. Feel free to re-open)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/115#issuecomment-436861158:164,learn,learning,164,,https://github.com/google/deepvariant/issues/115#issuecomment-436861158,1,['learn'],['learning']
Usability,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 ; ./. calls - 150,238; 0/1 calls - 2,793,521; 1/1 calls - 1,851,566; 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/241#issuecomment-559228691:218,feedback,feedback,218,,https://github.com/google/deepvariant/issues/241#issuecomment-559228691,1,['feedback'],['feedback']
Usability,"Hi @njbernstein . Performance on STR will be a function of the size of the event. In Illumina data, DeepVariant will likely stop calling events as they start to reach 100bp in size and larger. DeepVariant will call STR events below this size (for example, here is a HET call repeat expansion in one allele and repeat contraction in the other from a DeepVariant HG002 WGS VCF):. 10	50527727	.	CTATATATATATATATATATATATATATATATATATATATA	C,CTATATATATATATATATATATATATATATATATATATATATA	37.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/2:17:56:2,22,29:0.392857,0.517857:37,20,52,20,0,40. I don't have stratified accuracy metrics for STR performance, nor do I have comparisons of this to dedicated STR tools. I would imagine that dedicated STR callers perform better for the long (100bp+) events, due to specific approaches for that class of problem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/180#issuecomment-488147736:857,intuit,intuition,857,,https://github.com/google/deepvariant/issues/180#issuecomment-488147736,1,['intuit'],['intuition']
Usability,"Hi @one-matrix ,. From your original post, you mentioned you ran `python deepvariant/call_variants.py`. That won't work in DeepVariant setup. For DeepVariant, all binaries needs to be built with bazel. Unlike other pure Python setup, simply `python` a .py file won't execute it correctly. This is documented in the https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md page that @danielecook mentioned before. But, for extra clarity, let me run through it again, and write it down below for your reference. Here is an example of how I build and execute DeepVariant binaries:. # First, get a machine to run. In my example, I used a machine from GCP, using a command like this: https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-details.md#command-for-a-cpu-only-machine-on-google-cloud-platform. ```bash; gcloud compute instances create ""${USER}-cpu"" \; --scopes ""compute-rw,storage-full,cloud-platform"" \; --image-family ""ubuntu-2004-lts"" \; --image-project ""ubuntu-os-cloud"" \; --machine-type ""n1-standard-64"" \; --boot-disk-size ""300"" \; --zone ""us-west1-b"" \; --min-cpu-platform ""Intel Skylake""; ```. # ssh into the machine, and get the latest DeepVariant repo. Then, I ssh into the machine:. ```bash; gcloud compute ssh ${USER}-cpu --zone us-west1-b; ```. Then I get the repo:. ```bash; git clone https://github.com/google/deepvariant.git; cd deepvariant; ```. Following in the instructions in https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-build-test.md. I first run:. ```bash; sudo su; ```. and then:. ```bash; ./build-prereq.sh; ```. This step does a lot of stuff, including checking out other repos such as clif and tensorflow, and using that as part of the build environment. On my machine that I tested with just now, it took me 10m56.021s. and then run:. ```bash; ./build_and_test.sh; ```. This step took about 7min on my machine. . The [build_and_test.sh](https://github.com/google/deepvariant/blob/r1.6/build_and_test.sh) script is",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872:234,simpl,simply,234,,https://github.com/google/deepvariant/issues/756#issuecomment-1865388872,1,['simpl'],['simply']
Usability,Hi @oschwengers . Thank you for your suggestion. I am curious if you have tried to run DeepVariant on haploid bacteria yet? We have investigated in-bred rice strains and found that it has a strong tendency to call homozygous sites as expected from the genome structure. I was curious if you have evaluated running DeepVariant on bacterial sequencing and seeing whether the results are reasonable. This could be valuable feedback to understand the differences in current performance versus expectations of the field. There may be some additional complexity in understanding how to express subclonal variants (these might manifest as HET calls). I don't have an intuition about the preferences of the field.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/183#issuecomment-490179510:420,feedback,feedback,420,,https://github.com/google/deepvariant/issues/183#issuecomment-490179510,2,"['feedback', 'intuit']","['feedback', 'intuition']"
Usability,"Hi @pgrosu , I filed an internal issue to track your suggestions in https://github.com/google/deepvariant/issues/87#issuecomment-413745335; I'll need to digest it a bit more, and probably talk to to a few users in more detail to design this experience better. On a high level, I think I'll need to at least think about overhauling the GitHub page to make it super clear how to run - even just with our docker image, it's apparently still not obvious for users to find (because it's hidden in the docs). And, the suggestion of making things as simple as possible is great one - both in terms of the directory structure, and also the output that our programs output. I think I have stared DeepVariant for too long that I'm losing empathy for people who look at it for the first time. I'll close this issue on GitHub, but will plan to think about this in more detail and hope to get back with at least some more plan later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/87#issuecomment-416830583:364,clear,clear,364,,https://github.com/google/deepvariant/issues/87#issuecomment-416830583,2,"['clear', 'simpl']","['clear', 'simple']"
Usability,"Hi @pgrosu , thanks for your feedback!; Thanks to @nmousavi 's work, the Cloud runner page is now updated:; https://cloud.google.com/genomics/docs/tutorials/deepvariant with 0.7.0, and 0.7.0 deepvariant_runner image is now tagged as latest. In terms of our GitHub page --; I fixed a few small thing such as the typo (and ran spell checking and fixed a few more!) Also fixed the `0.4.1` issue. I'll also address the contributing document at some point soon. These changes are right now still just in our internal codebase. I'll get it out when I have a chance to push out some documentation fixes. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/87#issuecomment-415643215:29,feedback,feedback,29,,https://github.com/google/deepvariant/issues/87#issuecomment-415643215,1,['feedback'],['feedback']
Usability,"Hi @pgrosu . The default of `--pileup_image_height=100` was initially determined by the most common use case of Illumina WGS data. In terms of tweaking pileup_image_height, there are 2 past experiments that I can recall right now:. ## Illumina WES:; Before we released an Illumina WES model, I experimented with training a WES model with `--pileup_image_height=200`. At the time (end of 2017), I observed that the Indel F1 dropped quite a bit when increasing the height, but helped SNP F1 a bit. This investigationwas why we didn’t change this default for the Illumina WES model release. ## PacBio:; In Nov 2019, I trained a model with `--pileup_image_height=75` to see if we can decrease runtime without too much accuracy tradeoff. At the time, my results were:. * Reducing height to 75 (from 100) reduces calling time to ~85% (from 3h20m to 2h50m); * Accuracy (on case study chr20); - Indel F1: 0.983872 —> 0.982728; - SNP F1: 0.998913 —> 0.998867. Based on feedback, we decided it’s not a high priority to continue. Because:; 1. Amplicon will likely use the height=100; 2. 30min is not a big bottleneck now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/338#issuecomment-681126260:960,feedback,feedback,960,,https://github.com/google/deepvariant/issues/338#issuecomment-681126260,1,['feedback'],['feedback']
Usability,"Hi @pgrosu,. Thank you very much for looking into the paper. We always try to do our best to present the algorithm, code and experimental design to deliver the message most clearly. Any feedback on how to make it better and more understandable is always highly appreciated. However, as this is not a technical issue about DeepVariant, it would be helpful to do this over email. Please send an email to shafin@google.com at your convenience so we can discuss how to improve the manuscript.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/709#issuecomment-1724108680:173,clear,clearly,173,,https://github.com/google/deepvariant/issues/709#issuecomment-1724108680,2,"['clear', 'feedback']","['clearly', 'feedback']"
Usability,"Hi @pichuan @gunjanbaid . I apologize for overcomplicating this PR. I should have taken the rest of the discussion elsewhere. Thanks for your patient responses and advise so far. Even though I made many commits here, the only PR here is for `shuffle_tfrecords_beam.py`, and the changes are trivial as @gunjanbaid has reviewed already. The purpose of the PR is to enable `shuffle_tfrecords_beam.py` to work with DirectRunner with multiple workers (`--direct_num_workers=2, --direct_running_mode=""multi_processing""` for example), as well as with SparkRunner, FlinkRunner etc. To answer @gunjanbaid 's question on using beam.DoFn instead of a callable, my personal opinion is that that may not be necessary. The issue I saw is that `lambda` functions cannot be invoked through ParDo for these runners/modes. I attribute it to the same issue that we see with python multiprocessing which uses pickle to dispatch functions across processes and lambda functions are not picklable. So in this context, I think a callable meets the minimum requirements to enable this. I have tested on my end that the original deepvariant script and the modified script give the same output for a testcase. I am not trying to push you into accepting this PR, but just trying to clear any confusions that may have been caused by my multiple commits to the same branch, so that if and when you do revisit this matter, there is a summary about what's going on. I understand that the changes may still be far outside the priority of the team, so please take this at the appropriate pace. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/365#issuecomment-723468092:1254,clear,clear,1254,,https://github.com/google/deepvariant/pull/365#issuecomment-723468092,1,['clear'],['clear']
Usability,"Hi @pichuan, thanks for clearing this up! When you get the chance, please let me know what to look for in the call_variants -output. Also, I'm not sure I understand the format, using zcat I get many very short lines. I see AD, DP and VAF but not sure how to read variant positions / probabilities. . Many thanks! ; -Karoliina",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/849#issuecomment-2227870805:24,clear,clearing,24,,https://github.com/google/deepvariant/issues/849#issuecomment-2227870805,1,['clear'],['clearing']
Usability,"Hi @pichuan, thanks for your response! Yes, ideally I'd like to build a variant classifier that could predict those callset values that I could then use as a proxy for the ""confidence level"" of a variant, i.e. a variant identified in multiple callsets might be more likely to be a ""real"" variant than one predicted in just one or two. . Based on your description of the 3-class system in the codebase, would it theoretically be more feasible to feed the algorithm an edited VCF files that bins the callset values into three categories? (E.g. 0 = 1 callset, 1 = 2-4 callsets, 2 = >5 callsets). Thank you for sharing the blog post and other resources, I'll take a look through those to try to learn more as well!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/454#issuecomment-835842617:691,learn,learn,691,,https://github.com/google/deepvariant/issues/454#issuecomment-835842617,1,['learn'],['learn']
Usability,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API.; Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/127#issuecomment-449729322:94,learn,learning,94,,https://github.com/google/deepvariant/issues/127#issuecomment-449729322,2,['learn'],['learning']
Usability,"Hi @prasundutta87 . Both DeepVariant and DeepTrio can produce gVCFs, so you can joint call in a similar manner. In both cases you should use the DeepVariant_unfiltered preset for GLnexus, because there is family structure present which the other filtering presets wouldn't know about. Because you can joint genotype multiple trio gVCFs from either DeepVariant or DeepTrio in the same way, I would use DeepTrio to produce the gVCFs, take all of the gVCFs and run them together through glnexus, and then you can still use allele frequency information. To be clear, the unfiltered preset looks like this:. ```; sudo docker run \; -v ""${PWD}/output"":""/output"" \; quay.io/mlin/glnexus:v1.2.7 \; /usr/local/bin/glnexus_cli \; --config DeepVariant_unfiltered \; /output/child_trio_1.g.vcf.gz\; /output/parent1_trio_1.g.vcf.gz \; /output/parent2_trio_1.g.vcf.gz \; /output/child_trio_2g.vcf.gz\; /output/parent1_trio_2.g.vcf.gz \; /output/parent2_trio_2.g.vcf.gz \; | sudo docker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \; bcftools view - \; | sudo docker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \; bgzip -c > output/trio_cohort_merged.vcf.gz; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/816#issuecomment-2101970308:556,clear,clear,556,,https://github.com/google/deepvariant/issues/816#issuecomment-2101970308,1,['clear'],['clear']
Usability,"Hi @qili93 ; Thank you for looking into this! We have an internal issue to track Python 3 upgrade. I don't have a timeline for this now, but will let you know when we have more clear plans. ; Closing this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/154#issuecomment-464963634:177,clear,clear,177,,https://github.com/google/deepvariant/issues/154#issuecomment-464963634,1,['clear'],['clear']
Usability,"Hi @rabiafidan . We have found the following:. 1. The use of GLnexus preset DeepVariant_unfiltered is preferred for retaining True de novo calls, and we have updated the documentation for this.; 2. We also observe a reduction in 0/1 child, 0/0 parent calls when post-processing the final VCF to set a parent to ./. when that parent is 0/0, the child is 0/1 or 1/1, and that parent has either less than 8 reads covering the variant position, or and allele fraction of > 0.15. . The second filter seems to help reduces cases where there is not enough confidence to clearly call a de novo. Does this filtering strategy seem like it might further help refine your calls? We are considering whether to recommend postprocessing of this nature via a script in the future. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/440#issuecomment-899967692:563,clear,clearly,563,,https://github.com/google/deepvariant/issues/440#issuecomment-899967692,1,['clear'],['clearly']
Usability,"Hi @raphaelbetschart . In addition to what @pgrosu said. We do (rarely) observe genotype calls that differ substantially from the standard observations about HET/HOM/REF. We have made some prior observations about this for Germline data as a [section in our FAQ ](https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data) and you can see a [poster](https://pbs.twimg.com/media/ERe2bSyWsAcE00h?format=jpg&name=4096x4096) describing this observation as well and relating it to situations with a segmental duplication. . A few other questions/observations -. Have you looked at the site in IGV (as @pgrosu mentions)?. What are the MAPQ values for reads? DeepVariant with default parameters won't see reads with MAPQ<5. If there is a clear bias in MAPQ where the REF allele has a much lower MAPQ, DeepVariant may think the REF alleles are mismapped or might not see them in the pileup. The coverage of this region is pretty high (e.g. as an abundant transcript or as a gene family with many isoforms). Do you know which of these two is the case?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/701#issuecomment-1696419700:793,clear,clear,793,,https://github.com/google/deepvariant/issues/701#issuecomment-1696419700,1,['clear'],['clear']
Usability,"Hi @raphaelbetschart,. Just wondering on a few things:. 1) What are your QUAL and GQ scores for that call site?; 2) Is that SNP at an exon boundary?; 3) What tissue is this from? (Different tissue types can have an impact with DeepVariant RNA-Seq.); 4) Is this site in the [REDIportal](http://srv00.recas.ba.infn.it/atlas/search.html)? . Based on this curve, at 5x coverage you should still get a good majority of the CDS label variants that you saw at 3x coverage (this figure is from the Supplementary data available in [the paper](https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031?login=false) listed in the Reference section):. ![image](https://github.com/google/deepvariant/assets/6555937/2f6f8745-89ee-455e-8d20-950ef983875b). Thanks,; Paul. #### References; [1] [A deep-learning-based RNA-seq germline variant caller](https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031?login=false)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/701#issuecomment-1695811605:803,learn,learning-based,803,,https://github.com/google/deepvariant/issues/701#issuecomment-1695811605,1,['learn'],['learning-based']
Usability,"Hi @rickymagner ,; If you want to learn more about channels, you can take look at this blog post:; https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/. Two things to mention:; 1. This would be an advanced use of the DeepVariant codebase, both from the research and engineering aspects. We can try to answer your questions, but can't guarantee that we'll have bandwidth or knowledge to support your use case all the way.; 2. Since r1.6, we've made quite a lot of refactoring regarding the channels internal implementation. These new code will come out (with documentation) in a future r1.7, but right now it's not quite ready yet. That said, if you have a specific use case now, it's worth looking at the blog post and the r1.6 to try to implement your own channel! If you have any findings or questions, feel free to share or ask here. We can try our best to answer. I've always enjoyed seeing our users building on top of DeepVariant!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/790#issuecomment-1996353013:34,learn,learn,34,,https://github.com/google/deepvariant/issues/790#issuecomment-1996353013,1,['learn'],['learn']
Usability,"Hi @ruolin ,; thanks for reporting this issue. I'll try running on your BAM and reference and see if we can reproduce the issue.; We have in the past seen cases where the jobs run out of memory, and our error messages in that situation isn't very clear. So @danielecook 's guess of OOM makes sense. But the memory you're reporting sounds like it should be enough. So let me see if I can reproduce this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/446#issuecomment-826519447:247,clear,clear,247,,https://github.com/google/deepvariant/issues/446#issuecomment-826519447,1,['clear'],['clear']
Usability,"Hi @sclan ; to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur.; The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: ; ```; def main(_):; check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir); check_flags(). commands = create_all_commands(); for command in commands:; print('\n***** Running the command:*****\n{}\n'.format(command)); try:; subprocess.check_call(command, shell=True, executable='/bin/bash'); except subprocess.CalledProcessError as e:; logging.info(e.output); raise; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/232#issuecomment-596040813:184,clear,clear,184,,https://github.com/google/deepvariant/issues/232#issuecomment-596040813,1,['clear'],['clear']
Usability,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/238#issuecomment-557229093:370,feedback,feedback,370,,https://github.com/google/deepvariant/issues/238#issuecomment-557229093,1,['feedback'],['feedback']
Usability,"Hi @sh940202123 , it's not obvious to me why this might be the case. It's strange that no error message comes out at all. Can you try something even simpler, like:; ```; sudo docker run google/deepvariant:1.0.0 /opt/deepvariant/bin/make_examples --help; ```; And see if the information comes out correctly?. I'll also check with my team member tomorrow to see if anyone has other suggestions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/345#issuecomment-690806128:149,simpl,simpler,149,,https://github.com/google/deepvariant/issues/345#issuecomment-690806128,1,['simpl'],['simpler']
Usability,"Hi @shadrinams . From your description, it looks like you are running the DeepTrio merge component in the way that I would recommend. . Can I ask a few questions:. 1. Are you taking the values from the QUAL field of the multisample glnexus VCF; 2. How have you determined the TP sites? Are these Genome in a Bottle, or do they come from some other source. Your QUAL values for all calls match expectations for DeepTrio. However, I would not expect that ""true"" variants would have a distribution which departs from all calls. I can think of one reason that this might be the case:. Are these true variants de novos? DeepTrio's quality distribution for de novo variants is very different from its general quality distribution. This occurs because DeepTrio has learned that de novo events are quite rare, and so requires a higher standard of evidence to make a call which is a de novo. In these cases, DeepTrio is not extremely confident in the call, which results in a lower quality value. . The other things it might be good to look at is the genotype quality (GQ) field. This is the most direct measure of DeepTrio's confidence in a call, and maps directly from the probability for the called class. The QUAL value of a multisample VCF comes from GLnexus, and is a bit less direct measure of call confidence (still, I don't expect the distributions to be off in the manner that you see). I don't think I can immediately answer this puzzle, but hopefully with a little more information we can figure it out. Thanks,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/440#issuecomment-820157988:758,learn,learned,758,,https://github.com/google/deepvariant/issues/440#issuecomment-820157988,1,['learn'],['learned']
Usability,"Hi @shadrinams . Thank you for the plot. This is expected the the found de novo calls are lower in confidence (because DeepTrio has learned that de novo events are rare). Given that a call is a de novo (0/1-0/0-0/0), the higher GQ values will still indicate higher confidence, so more confident de novo calls should be more likely to be true. For calls which are 1/1-0/0-1/1 (or permutations of this), the parent and child models of DeepTrio do not coordinate, so they aren't optimizing for consistency. There is a property of some regions which look like potential segmental duplications where a call that appears to a human as a 1/1/ or 0/1 is actually some kind of CNV. DeepTrio has learned some parts which are predictive of this (generally a variant-dense haplotype and a reference haplotype with higher depth). There may be cases where the child model gives a call a 1/1 and the parent gives a 0/0 when the site itself is similar, but the context is different. If you are looking for homozygous Mendelian violations, you may want to filter regions of high variant density, as apparent calls will come from this phenomenon. . In addition, if you are looking at the sex chromosomes, it would be good to separately call the non-PAR chrX for male samples. For a male sample, running chrX providing only the mother sample provides best results. (chrY should already only have paternal reads outside of the PAR). Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/440#issuecomment-821020591:132,learn,learned,132,,https://github.com/google/deepvariant/issues/440#issuecomment-821020591,2,['learn'],['learned']
Usability,"Hi @shadrinams . Your observations about some apparent de novos originating from undercalling of a parent is interesting. I think that we'll look into whether some harmonization or filtering after calls could make the resulting calls more uniform. With respect to your examples. It is often difficult to be definitive about why DeepVariant does not make certain calls. I cannot give you a reason, but for some cases I can share observations. In all cases, I will list the call followed by observation. ```; chr5 | 92696737 | chr5_92696737_C_T | C | T | 3 | . | AF=0.166667;AQ=3 | GT:DP:AD:GQ:PL:RNC | 0/1:32:17,15:5:3,0,32:.. | 0/0:27:27,0:50:0,108,1079:.. | 0/0:21:21,0:50:0,105,1049:..; ```. This looks clean. DeepTrio's GQ is low probably because it is a clear de novo and it has learned such events are rare. ```; chr5 | 24093912 | chr5_24093912_AAT_A;chr5_24093912_A_AATAT | AAT | A,AATATAT | 46 | . | AF=0.333333,0.166667;AQ=46,15 | GT:DP:AD:GQ:PL:RNC | 1/2:30:5,12,13:13:44,15,55,15,0,53:.. | 0/1:31:16,15,0:46:46,0,70,990,990,990:.. | ./.:30:27,1,0:18:0,18,45,990,990,990:II; ```; One thing I note - it looks to me like there are 3 alleles represented in the reads for the top parent: 1) there is an insertion event in-phase with a downstream HET SNP. 2) There is a reference allele in-phase with REF at that later position. 3) There is evidence for a T SNP that is also in-phase with the downstream HET variant. For the reads that are HET T, it could be interesting to see if they overlap any other variants that would suggest that they come from a copy number variant elsewhere in the genome. It may be the case that DeepTrio does not call a variant in the parent because some of the variant reads may be coming from elsewhere. ```; chr7 | 54624683 | chr7_54624683_A_AATC | A | AATC | 27 | . | AF=0.166667;AQ=27 | GT:DP:AD:GQ:PL:RNC | 0/1:39:22,16:28:27,0,48:.. | 0/0:40:40,0:50:0,120,1199:.. | 0/0:28:28,0:50:0,90,899:..; ```. This is interesting, since the evidence reported by DeepTrio do",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/440#issuecomment-823860823:758,clear,clear,758,,https://github.com/google/deepvariant/issues/440#issuecomment-823860823,2,"['clear', 'learn']","['clear', 'learned']"
Usability,"Hi @situssog ; Is there a specific reason why you have a fastA file and not a fastQ?; PacBio's tool (https://github.com/PacificBiosciences/bam2fastx) can generate either, so we would recommend simply generating the fastQ file to preserve the base quality scores, so then BWA-MEM, DeepVariant, and any other tools can use them.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/270#issuecomment-593729219:193,simpl,simply,193,,https://github.com/google/deepvariant/issues/270#issuecomment-593729219,1,['simpl'],['simply']
Usability,"Hi @tedyun,. 1. In this use case, we have phased and accurate data from the same cohort **X** that we use for the imputation.; 2. I was actually thinking about simply deleting the GQ=0 sites from my GVCFs which seem to be the simpler solution. As you said, they don't provide any useful information. I just wanted to point out here that having those records in output might confuse downstream applications (i.e. imputation).; 3. Unfortunately not. The problem is that our imputation system is exclusively based on the PL values and doesn't even read GT or GQ. Thank you for your questions and suggestions. Guillaume",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/403#issuecomment-760775624:160,simpl,simply,160,,https://github.com/google/deepvariant/issues/403#issuecomment-760775624,2,['simpl'],"['simpler', 'simply']"
Usability,"Hi @tetsuro90 [this documentation](https://github.com/dnanexus-rnd/GLnexus/wiki/Reading-GLnexus-pVCFs) has more information about the representation and the ""half-calls"" specifically. It involves some gnarly issues with overlapping variants in VCF for which there isn't a lot of standardization across tools unfortunately. [This issue](https://github.com/dnanexus-rnd/GLnexus/issues/210) also discusses some potential future developments. Any feedback there is welcome. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/302#issuecomment-620808470:443,feedback,feedback,443,,https://github.com/google/deepvariant/issues/302#issuecomment-620808470,1,['feedback'],['feedback']
Usability,"Hi @themkdemiiir ,; @akolesnikov already mentioned this in his previous answer -- it's totally possible to split by chromosomes first. Especially if that works better for your workflow.; (I know for many users, their workflow already split by chromosomes, so it makes sense to go from these BAMs that are per chromosome.). @akolesnikov 's answer above further explains that DeepVariant does its own sharding for any BAM inputs. You can run DeepVariant on a BAM that includes all chromosomes, but you can also do that on a BAM that include one chromosome (and then combine the VCFs later if you like). Please feel free to follow up if it's not clear. I'll close this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/744#issuecomment-1839946718:643,clear,clear,643,,https://github.com/google/deepvariant/issues/744#issuecomment-1839946718,1,['clear'],['clear']
Usability,"Hi @themkdemiiir,. Although, it is absolutely possible to split the bam into chromosomes and run them separably there are better way to make a pipeline. There are 3 binaries that DeepVariant executes: make_examples, call_variants, and postprocess_variants. You may run those binaries from the docker. * make_examples is highly parallelized already. You may shard it to as many shards as needed by simply specifying the output of make_examples as sharded by adding @<num of shards> to the file name and add `--task` flag that specifies the task number for each shard. ; * call_variants will be run with the same number of shards.; * postprocess_variants has to be run in a single process. Here is an example of running shard 11 of make_examples and call_variants broken into 200 shards:. ```; bin/make_examples \; --examples /tmn/your_examples.tfrecord@200.gz \; --mode calling \; --reads /tmp/your_input_bam.bam \; --realign_reads \; --ref=/tmp/your_reference.fna \; --task=11. # Input for each instance of call_variants is the output of one instance of make_examples:; bin/call_variants.par \; --batch_size=32 \; --checkpoint <Path to the model checkpoint or saved model>.ckpt \; --examples /tmp/your_examples.tfrecord-00011-of-00200.gz \; --outfile /tmp/your_call_variants_output.cvo.tfrecord-00011-of-00200.gz. # Input for for postprocess would be the output of all instances of call_variants:; /tmp/your_call_variants_output.cvo.tfrecord@200.gz; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/744#issuecomment-1836586525:397,simpl,simply,397,,https://github.com/google/deepvariant/issues/744#issuecomment-1836586525,1,['simpl'],['simply']
Usability,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/233#issuecomment-550436768:635,learn,learned,635,,https://github.com/google/deepvariant/issues/233#issuecomment-550436768,1,['learn'],['learned']
Usability,"Hi @yonatansc97 . In the default WGS and exome models, DeepVariant does not expand the content of insertion sequences. Instead, it represents them with a character marker that indicates that an insertion is present at the position. To a human, this visually looks like a SNP in the pileup, but the machine learning model can easily distinguish this from a SNP event. This representation is necessary in order to keep the pileup at a consistent width. The information of the content of the insertion is also implicitly present in the 5th channel (supports variant) which only gets a value of 255 with the read when the insertion sequence matches the event to be called. The representation is in some ways sub-optimal, because in some cases information is lost in the presentation to the network. We have developed an additional process, which aligns reads to the ALT allele as well, which expands insertion sequences and makes the full sequence of ALT insertion events visible. This improves accuracy for calling variants in PacBio HiFi data and Oxford Nanopore data, and is defaulted to on in those models. . The flag for this option is: --alt_aligned_pileup, which can have the values: --alt_aligned_pileup=diff_channels and --alt_aligned_pileup=rows. . From our benchmarks, the --alt_aligned_pileup flag did increase accuracy in Illumina WGS and exome models, but only marginally. Since this also somewhat increases the compute cost, we do not use this option in Illumina WGS and exome models. We discuss this feature in more detail in our [blog on DeepVariant v1.0](https://ai.googleblog.com/2020/09/improving-accuracy-of-genomic-analysis.html)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/379#issuecomment-724880533:306,learn,learning,306,,https://github.com/google/deepvariant/issues/379#issuecomment-724880533,1,['learn'],['learning']
Usability,"Hi @zstephens, thanks for reaching out! The goal of `run_deepvariant` was to provide users with a single command they could use to run DeepVariant using Docker. For the sake of simplicity, this approach only accepts [a few different flags](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py#L53). We still do support the `sample_name` flag for `make_examples`, but it is not possible to use with `run_deepvariant`. To use this and other flags, I would suggest using separate commands for each step of DeepVariant (`make_examples`, `call_variants`, or `postprocess_variants`). Each of these binaries is included in the Docker image and can be run using a command such as below (with any additional desired flags). ```; sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0\ ; /opt/deepvariant/bin/make_examples; ```. I'll close this issue for now, but feel free to reopen if you have any other questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/173#issuecomment-483410868:177,simpl,simplicity,177,,https://github.com/google/deepvariant/issues/173#issuecomment-483410868,1,['simpl'],['simplicity']
Usability,"Hi Again,. I’ve had a chance to do some testing with my own samples, so I thought I should report back:. Going back to _point 4_, I noticed that you could choose to output a gVCF file in DeepVariant. However, that is not what is done by default (and it’s not what I did), and I can also tell that’s probably not what they did either. Namely, there are over 3 _billion_ base pairs in the human genome: if you add up the passed filters and failed filters for DeepVariant, then that is still only about 9 _million_ sites. However, I wanted to wait until I had my own DeepVariant results before I said anything else, since it is always possible there may have been something that I wouldn’t expecting in the VCF from DeepVariant. ***So, in terms of additional feedback***:. **5)** I compared DeepVariant on Google Cloud (v0.7.2, using code similar to [this](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_gcp_deepvariant_runner.sh)) Exome versus WGS variant calls with [a script that I wrote](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/VCF_recovery.pl) as well as precisionFDA. My script filters out “complex variants” (with more than one variant at a position), but .vcf files containing those variants weren’t flagged by precisionFDA (even though I did have to do some file re-processing). So, starting for my test (checking recovery of my CDS Exome variants in my WGS dataset), **the recovery numbers were very close to what I originally expected (98-99% for SNPs, ~90% for indels)**:. **Provided Exome on Provided WGS .bam Alignment**:; ```; 68759 / 72556 (94.8%) full SNP recovery; 71276 / 72556 (98.2%) partial SNP recovery; 3027 / 3648 (83.0%) full insertion recovery; 3413 / 3648 (93.6%) partial insertion recovery; 3119 / 3911 (79.7%) full deletion recovery; 3596 / 3911 (91.9%) partial deletion recovery; ```. **BWA-MEM Exome on WGS (for only on-target alignments)**:; ```; 51417 / 54229 (94.8%) full SNP recovery; 53116 / 54229 (97.9%) pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:756,feedback,feedback,756,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,1,['feedback'],['feedback']
Usability,"Hi Alexey,. sure, the exact command was:. ``` sudo docker run --gpus all --cpus=25.0 -v /home/docker_input:/input -v /home/docker_output:/output google/deepvariant@sha256:fcecf5e3032245dd0b6da2c28ec0d9a9d099537af7d6df054df0e25fe4a29006 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/grch37.75.fa --reads=/input/input.bam --output_vcf=/output/output.vcf --num_shards=25 --make_examples_extra_args logging_every_n_candidates=10000 ```. I think there is nothing special regarding the used parameters. One difference to your quick start guide is the usage of ""docker run --gpus all"" instead of the deprecated nvidia-docker (see https://github.com/NVIDIA/nvidia-docker#quickstart) . I did some additional checks with ""nvidia-smi"" command, when calling is runing. It seems like it's definitly not using the GPU. Is it maybe possible that this is some driver incompatibility with our installed nvidia drivers and the one inside the docker container? I'm wondering where this 410.129.0 version in the logs is comming from. Best regards,. Sebastian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/321#issuecomment-656000987:553,guid,guide,553,,https://github.com/google/deepvariant/issues/321#issuecomment-656000987,1,['guid'],['guide']
Usability,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658889277:594,clear,clearly,594,,https://github.com/google/deepvariant/issues/682#issuecomment-1658889277,3,['clear'],"['clear', 'clearly']"
Usability,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample.; 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,; Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/526#issuecomment-1067196676:1392,simpl,simple,1392,,https://github.com/google/deepvariant/issues/526#issuecomment-1067196676,1,['simpl'],['simple']
Usability,"Hi Andrea, I am getting the same error while I am trying to run the deepvariant code through the conda installation. Did you find a solution for it?. > Thank you for your quick answer. I had to make a couple of changes to the command (see below), but now it seems to be working:; > ; > ```; > conda create -y -n deepvariant -c bioconda -c conda-forge python=2.7 deepvariant google-cloud-sdk=239.0.0; > ```; > ; > Everything is installed correctly. Is there a guide to follow for locally installed variant caller?; > I'm not sure I've been able to find it.; > ; > Thank you again for your support,; > Andrea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/252#issuecomment-567477006:459,guid,guide,459,,https://github.com/google/deepvariant/issues/252#issuecomment-567477006,1,['guid'],['guide']
Usability,"Hi Andrew, sorry for the delay,. I was aiming to get per nucleotide values of read depth, base and mapping qualities. I just come to check that this information can in fact be obtained from `samtools depth` and `samtools mpileup`, so I guess that will work for us. Thank you for the feedback!; Eugenio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/447#issuecomment-830259038:283,feedback,feedback,283,,https://github.com/google/deepvariant/issues/447#issuecomment-830259038,1,['feedback'],['feedback']
Usability,"Hi Andrew, thank you very much for the feedback. This is something new I have learnt about the BAM files. Using the filtered BAM file, the error message disappears. The number of variants called has also increased considerably (~x20 for variants with PASS tag). Our reads are in fact HiFi. We have been doing the alignment with `minimap2 -ax map-pb` because to our understanding `deepvariant` is designed for read alignments (and not assembly-to-reference alignments as achieved with `minimap2 -ax asm`). Is this a misunderstanding? Could `deepvariant` be safely used with BAMs for assembly-to-reference alignments?. Thank you again,; Eugenio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/434#issuecomment-815783472:39,feedback,feedback,39,,https://github.com/google/deepvariant/issues/434#issuecomment-815783472,2,"['feedback', 'learn']","['feedback', 'learnt']"
Usability,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Be",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/518#issuecomment-1696738838:793,simpl,simplified,793,,https://github.com/google/deepvariant/issues/518#issuecomment-1696738838,1,['simpl'],['simplified']
Usability,"Hi Andrew,. Thank you very much for your kind and prompt response. For _point 1_ (and part of _point 2_), thank you very much for that additional information. I think my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that pap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-476428247:185,simpl,simpler,185,,https://github.com/google/deepvariant/issues/165#issuecomment-476428247,2,"['learn', 'simpl']","['learning', 'simpler']"
Usability,"Hi Attila,. Yeah it takes about a week to fully uncover how all the dependencies work together, which can be fun if you have the time. The side-benefit is that then you'll discover that DeepVariant is just a basic collections of tools (and data-structures) with many possibilities to tweak, simplify and expand on - which can be even more fun to play with :). ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/41#issuecomment-361132599:291,simpl,simplify,291,,https://github.com/google/deepvariant/issues/41#issuecomment-361132599,1,['simpl'],['simplify']
Usability,"Hi Brent I will check in on this and get back to you. Just to be clear, are using `FROM google/deepvariant` and then installing bioconda and using that to install bcftools / samtools or are you using bioconda to install deepvariant, samtools, and bcftools?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/445#issuecomment-822571186:65,clear,clear,65,,https://github.com/google/deepvariant/issues/445#issuecomment-822571186,1,['clear'],['clear']
Usability,"Hi Charles,. In addition to what Pi-Chuan said. We run a case study for exome on 128G instance (https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md). postprocess_variants simply converts variants from internal format to VCF format. This error is very generic and from the information you provided there is no way to say it is related to TensorFlow.; It would be helpful if you could provide logs for postprocess_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-479584377:204,simpl,simply,204,,https://github.com/google/deepvariant/issues/167#issuecomment-479584377,1,['simpl'],['simply']
Usability,"Hi Charles,. Thank you for the machine information. For the AWS instance, the 8-core machine has 8-fold fewer CPUs than the 64-cores used in the case study. Given this, the total number of core-hours is 144. This is actually quite efficient for a DeepVariant run. For more similar time to the case study, you could consider the m5.12xlarge or m5.24xlarge, with 48 and 96 cores respectively. The 96-core instance will likely be faster than the case study, though with worse economics. In all cases, the use of spot instances will be far more cost-favorable. For the GCP run posted, this looks to be the GCP cost-optimized execution framework. This framework is built by the Google Cloud, so although I cannot speak as directly to this, I can refer your question to the right place. That GitHub repository is here: https://github.com/googlegenomics/gcp-deepvariant-runner/issues. For your Docker question, I believe that this error reflects that you are not mounting the volumes in the proper way in your script. In your .sh script, you may want to try to more closely align the way your script mounts and creates input and output directories with the case study. I don't feel that I can clearly communicate the details of mounting the Docker volumes. It may be valuable to read Docker's description of this: https://docs.docker.com/storage/volumes/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/171#issuecomment-483500506:1186,clear,clearly,1186,,https://github.com/google/deepvariant/issues/171#issuecomment-483500506,1,['clear'],['clearly']
Usability,"Hi Guillaume,. Thank you for filing the issue and for the detailed explanation of your use case. I'd like to ask you some more questions to better understand the situation and to find a potential solution. 1. If we call the cohort you're processing with DeepVariant+GLnexus ""cohort **X**"", are you (a) using cohort **X** as a reference panel to impute another cohort **Y**, (b) using another cohort **Y** as a reference panel to impute your cohort **X**, or (c) using imputation software (e.g. Beagle) to re-genotype cohort **X** using the PL values in cohort **X** itself?; 2. In the example case you mentioned (""some samples have an actual variant but most of the other samples have a no call""), the no calls in the other samples would imply we don't have enough evidence (in terms of coverage, read quality, mapping quality, etc.) to call the other samples either reference or variant. Would keeping that cohort-level variant desirable for your downstream application? If it is, is there any other type of filters you can use (other than the imputation score) to keep those records (e.g. maximum of GQs in all samples)?; 3. Changing the no-call genotypes `./.` to the reference calls `0/0` is a relatively simple transformation (e.g. `bcftools +missing2ref`) that we use for some specific downstream applications. Would that help in your situation?. Thank you,; Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/403#issuecomment-760500649:1209,simpl,simple,1209,,https://github.com/google/deepvariant/issues/403#issuecomment-760500649,1,['simpl'],['simple']
Usability,"Hi Gunjan,; and thanks a lot for your reply. Yes, the directories where all accessible and under ```root``` (I know it can be done better....).; Indeed when I added to the docker command the option ``` --user root``` the error changed and was very clear: ``` disk full```.; It remains to me to free disk or change docker location, add a docker group to allow users run it without ```sudo``` and rerun it. I am pretty confident it should work. With Regards,; -A",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/325#issuecomment-659193187:248,clear,clear,248,,https://github.com/google/deepvariant/issues/325#issuecomment-659193187,1,['clear'],['clear']
Usability,"Hi Maria,. Thanks for the response. My Intent is to generate frozen graph from the available checkpoints. The code snippet is my own. Do you think it needs any fixing / addition? . Is there anyone who can provide steps/methods/guidance? I tried from inside as well as outside the Docker. I even tried Google Colab with different Hardware configurations -- i.e. combination of CPU, GPU, TPU. And also with different TF versions. I am never able to import the meta graph and restore the checkpoint. I always get ""No Op Kernel was registered"" with different Op names. Additional question: for training:. - Can I train on the ""quickstart-testdata"" provided in deepvariant? ; - And how do I produce a frozen graph during a training run?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/339#issuecomment-681204545:227,guid,guidance,227,,https://github.com/google/deepvariant/issues/339#issuecomment-681204545,1,['guid'],['guidance']
Usability,"Hi Mark (@depristo),. There is a theme of elegance with the current implementation that I tend to appreciate, though I agree that streamlining it for support/growth is rich with opportunities to explore. Let me know if you would like to work on it together - or just bounce off ideas - as some could be low-hanging fruit with simple remedies. Best,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/41#issuecomment-361455478:326,simpl,simple,326,,https://github.com/google/deepvariant/issues/41#issuecomment-361455478,1,['simpl'],['simple']
Usability,"Hi Masaru,; I've filed an internal issue to track - we'll keep usability for beginners in mind for future API change.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/127#issuecomment-450001402:63,usab,usability,63,,https://github.com/google/deepvariant/issues/127#issuecomment-450001402,1,['usab'],['usability']
Usability,"Hi Oskar,. Since your WDL workflow is using Docker, the simplest approach is to include a Docker-specific argument for `--cpuset-cpus`, or change the Session configuration which I've detailed at, the following location:. https://github.com/google/deepvariant/issues/42#issuecomment-360510853. For information regarding the `--cpuset-cpus` here's a reference:. https://docs.docker.com/config/containers/resource_constraints/#configure-the-default-cfs-scheduler. There are many ways to change DeepVariant, but I think this will will get you the quickest results for the issue you're facing. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/49#issuecomment-366745899:56,simpl,simplest,56,,https://github.com/google/deepvariant/issues/49#issuecomment-366745899,1,['simpl'],['simplest']
Usability,"Hi Paul, . I got an error when running on my HPC so I'm just waiting for the IT people to get back to me, I assume its a simple fix since I have managed to get the deepvariant container to work a few months back: . ```; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LANG = ""en_GB.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LANG = ""en_GB.UTF-8""; are supported and installed on your system.; ```. I'll let you know when they reply!; Amy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/691#issuecomment-1667418894:121,simpl,simple,121,,https://github.com/google/deepvariant/issues/691#issuecomment-1667418894,1,['simpl'],['simple']
Usability,"Hi Paul, thanks for mentioning this issue.; I looked at our documentation and noticed that an update was made to our README a few days ago with this extra description:. Pre-built binaries are available at [gs://deepvariant/](https://console.cloud.google.com/storage/browser/deepvariant).; These are compiled to use SSE4 and AVX instructions, so you'll need a CPU (such as Intel Sandy Bridge) that supports them. (The file /proc/cpuinfo lists these features under ""flags"".). But it seems like this new information to the doc hasn't be synced to the external GitHub yet. This should come out in the new year at the latest. I suspect we'd like to keep the pre-built binary having optimization. But we will at least add that line of disclaimer so that it's clear what the binaries are built for.; Would it be ok for you to build DeepVariant for your CPU by following [Building and testing; DeepVariant](docs/deepvariant-build-test.md), or do you need pre-built binaries without AVX from us?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/21#issuecomment-353701703:753,clear,clear,753,,https://github.com/google/deepvariant/issues/21#issuecomment-353701703,1,['clear'],['clear']
Usability,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue.; [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/94#issuecomment-422863842:12,simpl,simplified,12,,https://github.com/google/deepvariant/issues/94#issuecomment-422863842,1,['simpl'],['simplified']
Usability,"Hi Paul,. Thank you again for your replies and sorry mine are so slow (I think we are in very different time zones). So I’m administering this system but am not really a system administrator (I’m a biologist). Since I have root access, if there is something that can be done (or undone) to re-establish the ability of non-root users to run deepvariant, I can do that, I just don’t know enough to fix this specific issue myself. 1) The following gives me ; docker run --mount type=bind,source=""/tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs"",target=""/input"" google/deepvariant:""1.5.0"" ls -l /input. docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist: /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling.; See 'docker run --help'. 2) I’ve run the following, but confess I don’t understand what is going on past the second command and then deleting what was done at the end. If creating volumes can be skirted by changing some admin permission that is doable on my end. docker volume create --name dv-vol; dv-vol. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" touch /input/a-new-file. docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input; total 0; -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file. docker container create --name dv-cp-cont -v dv-vol:/input-path-cont hello-world; 4d2015a9c2dbe3fc6d27854c440ce8505222ed6a8f2a3c945d36315081a832b6. docker cp dv-cp-cont:/input-path-cont . ls input-path-cont. a-new-file; touch input-path-cont/file-2. -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file; -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker cp input-path-cont/file-2 dv-cp-cont:/input-path-cont . docker run --mount source=dv-vol,target=""/input"" google/deepvariant:""1.5.0"" ls -l /input; total 0; -rw-r--r-- 1 root root 0 Sep 1 00:21 a-new-file; -rw-rw-r-- 1 1005 1010 0 Sep 1 00:26 file-2. docker rmi --force hello-world:latest. U",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1701949973:279,undo,undone,279,,https://github.com/google/deepvariant/issues/184#issuecomment-1701949973,1,['undo'],['undone']
Usability,"Hi Paul; Thanks for all the informations. As learnt from above, I should use the ""DeepVariant -> WhatsHap -> DeepTrio"" pipeline for better accuracy of the Deeptrio, as it do not support the functionality of reading haplotagging. But the DeepVariant can do it since 1.4.0, which means in case of trio analysis, ""DeepVariant + GLnexus"" will already be most accurate way currently, am I get it right?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/704#issuecomment-1705891486:45,learn,learnt,45,,https://github.com/google/deepvariant/issues/704#issuecomment-1705891486,1,['learn'],['learnt']
Usability,"Hi Phil,; as you can see from the log you posted, the error actually came from:; ```; File ""/opt/conda/envs/nf-core-deepvariant-1.0/lib/python2.7/site-packages/psutil/_pslinux.py"", line 701, in cpu_freq; ""can't find current frequency file""); ```; If I read this correctly, ""frequency"" isn't referring to anything DeepVariant related, but is referring to ""cpu_freq"". I also did a search in the DeepVariant codebase for the string ""can't find current frequency file"" and I can confirm that error message does not come from us. It is still possible that this is related to some interaction with the DeepVariant code, but from the information you provide, it's not clear to me how.; And, given that this is at the system level, I don't think it's related to what organism you're providing as the input data. To understand whether your input data works on DeepVariant code or not, the best way is probably to try it with just the DeepVariant code. If that doesn't work, it'll be more clear whether there might be different issues. If the data you're running on is publicly accessible, I'm also happy to try running DeepVariant on it. Let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/191#issuecomment-504481029:661,clear,clear,661,,https://github.com/google/deepvariant/issues/191#issuecomment-504481029,2,['clear'],['clear']
Usability,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```; $ build status. Checking DeepVariant build prerequisites... OK; Checking DeepVariant test environment compatibility [GPU]... OK; Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]?. ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/87#issuecomment-413745335:542,simpl,simple,542,,https://github.com/google/deepvariant/issues/87#issuecomment-413745335,1,['simpl'],['simple']
Usability,"Hi Pichuan,. You can close this issue now. I will try with different samples. I tried to lower the learning rate but it still does not exceed the performance of default model. . I will have to train on different samples. Thanks",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/802#issuecomment-2057623016:99,learn,learning,99,,https://github.com/google/deepvariant/issues/802#issuecomment-2057623016,1,['learn'],['learning']
Usability,"Hi Pichuan. > Can you give us a bit more information on your BAM? Is it WGS or WES? Which Illumina sequencing machine is it from?. The am using WES. We assumed this would run faster. We used UC Berkeley HiSeq 4000 illumina machine . > If you are okay with sharing the BAM header, it'll help too. If it's easier to share via email, you can email [pichuan@google.com](mailto:pichuan@google.com); > . I sent the headers to you in email. > > I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good!; > . The run that worked well used WGS. The library was created by a different Lab. Not sure if this is relevant or not. We are running on RNA. We got really good F-scores on our ""gold standard"" data set. > > p.s. I am running in AWS . not sure if that makes a difference or not; > ; > I don't expect it to make a difference. But if you do observe any issues, feel free to let us know what kind of AWS instances you're running on, and what's the unexpected behavior, so we can reproduce the issue.; > . region: oregen; m5dn.8xlarge; 32 CPU; 2 x 600GB SSD; Deep Learning AMI (Ubuntu 16.04) Version 26.0 (ami-07728e9e2742b0662)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/260#issuecomment-573841969:1249,Learn,Learning,1249,,https://github.com/google/deepvariant/issues/260#issuecomment-573841969,1,['Learn'],['Learning']
Usability,"Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```; new (initial_block_) Block(options_.initial_block_size, NULL);; ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/94#issuecomment-422619015:429,simpl,simplify,429,,https://github.com/google/deepvariant/issues/94#issuecomment-422619015,1,['simpl'],['simplify']
Usability,"Hi Saurabh,. Currently the `run_deepvariant_keras` is experimental as we plan to develop this further in the future. The model for `run_deepvariant` is for tf-slim and would not simply extend to keras. For now, you should use `run_deepvariant` as that's the one we officially support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/636#issuecomment-1520586245:178,simpl,simply,178,,https://github.com/google/deepvariant/issues/636#issuecomment-1520586245,1,['simpl'],['simply']
Usability,"Hi Sebastian, . That output doesn't look right. Did you follow [DeepVariant quick start guide](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md#notes-on-gpu-image) ?. Could you please provide the exact commands that you run?. Thank you; Alexey",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/321#issuecomment-655676506:88,guid,guide,88,,https://github.com/google/deepvariant/issues/321#issuecomment-655676506,1,['guid'],['guide']
Usability,"Hi Sophie,. Ambitious endeavor, but some things to be aware of. So a low VAF would probably confuse the model training, as that is usually a homozygous reference call. With a low VAF, the other alleles would probably be automatically be selected as supporting information for training in the pileup to confirm a call, as they would be in the majority. Thus when you run your trained model in the future against new BAM files, it would not look so much for the rare variants, but rather select for the more prevalent ones in your data to call a genotype (GT) and subsequently a GQ score of supporting it. . Regarding training and validation, they always usually must be different. For example, in the original DeepVariant paper under the [Supplementary Text and Figures](https://static-content.springer.com/esm/art%3A10.1038%2Fnbt.4235/MediaObjects/41587_2018_BFnbt4235_MOESM81_ESM.pdf), they trained on chromosomes 1-19, and validated on 20-22:. ![image](https://github.com/google/deepvariant/assets/6555937/83cdb7f3-44e9-4185-99cf-81362489dfcf). If you want to train chromosome-by-chromosome, it is possible to take a previously trained model and continue training it as noted in the [tutorial specified by `GCS_PRETRAINED_WGS_MODEL`](https://github.com/google/deepvariant/blob/ab068c4588a02e2167051bd9e74c0c9579462b51/docs/deepvariant-training-case-study.md#start-model_train-and-model_eval), but that could create batch effects (meaning it will shift the model one way with one chromosome, and then back with another even under shuffling conditions). So it might be better to start with a complete set of chromosomes you select for training. Not trying to discourage you, so give it a try and let's see what happens -- in any case it will be fun learning experience. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/698#issuecomment-1681102936:1749,learn,learning,1749,,https://github.com/google/deepvariant/issues/698#issuecomment-1681102936,1,['learn'],['learning']
Usability,"Hi Sophie,. DeepVariant calls variants based on a trained model for different technologies. I'm not sure it has a model for Horizon Tru-Q 1, and only has models for the following technologies (`WGS`, `WES`, `PACBIO`, `ONT_R104`, `HYBRID_PACBIO_ILLUMINA`):. * NGS (Illumina) data for either a; [whole genome](docs/deepvariant-case-study.md) or; [whole exome](docs/deepvariant-exome-case-study.md).; * [RNA-seq Case Study](docs/deepvariant-rnaseq-case-study.md) for Illumina; RNA-seq.; * PacBio HiFi data, see the; [PacBio case study](docs/deepvariant-pacbio-model-case-study.md).; * Oxford Nanopore R10.4.1 Simplex or Duplex data, see the; [ONT R10.4.1 Simplex case study](docs/deepvariant-ont-r104-simplex-case-study.md); and [ONT R10.4.1 Duplex case study](docs/deepvariant-ont-r104-duplex-case-study.md).; * Hybrid PacBio HiFi + Illumina WGS, see the; [hybrid case study](docs/deepvariant-hybrid-case-study.md).; * Oxford Nanopore R9.4.1 data by using; [PEPPER-DeepVariant](https://github.com/kishwarshafin/pepper). Regarding seeing the pileup images, the command is the following -- which is based [on the following document](https://github.com/google/deepvariant/blob/r1.5/docs/show-examples.md):. ```; INPUT_DIR=""${PWD}/YOUR_INPUT_PATH""; OUTPUT_DIR=""${PWD}/YOUR_OUTPUT_PATH"". BIN_VERSION=""1.5.0"". sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/show_examples \; --examples=/output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz \; --example_info_json=/output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz.example_info.json \; --output=/output/pileup --num_records=20. # And then your images are here:; ls ""${OUTPUT_DIR}""/pileup*.png; ```. There are many reasons why candidate variants are not detected:. 1. The quality of reads in the BAM file.; 2. The reference file used to generate the BAM is different than the one used with DeepVariant.; 3. There might not be ma",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/690#issuecomment-1660589629:606,Simpl,Simplex,606,,https://github.com/google/deepvariant/issues/690#issuecomment-1660589629,3,"['Simpl', 'simpl']","['Simplex', 'simplex-case-study']"
Usability,"Hi Sophie,. So it is best to train across all the samples. The reason is that the model will need to be representative of all those samples, and you don't want to overfit for one sample over another. Today there is more data than computing power and memory, so training happens by batching the data, training on a batch, and then tweaking the model in the follow-up batches. Here's a visual example of what could happen:. ![image](https://github.com/google/deepvariant/assets/6555937/3ff13990-c2cc-4863-a904-bb0219791b06). In the first batch, the coefficients will be biased in a monotonically increasing function. Then when the second batch is used to tweak the model's parameters, it will shift towards a monotonically decreasing function shifting it towards an opposite direction. Then when the third batch comes in it will shift the parameters in the other direction. Sure, the independent variable (x-axis) here is a simple one-dimensional type, but this can become complex with multiple channels (`read base`, `base quality`, `mapping quality`, etc). And of course if the training data is shuffled, then the validation data and tuning data should also be shuffled in order to have the same data representation - with the exception of the test data, which will be used for benchmarking the model as a real scenario (though there is additional read shuffling when downsampling with too many reads for a pileup image). As @akolesnikov mentioned, the `input_pattern_list` parameter of the shuffle script takes a list of files, so you can do it all at once. Let me know if I should expand on anything. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/698#issuecomment-1711046219:922,simpl,simple,922,,https://github.com/google/deepvariant/issues/698#issuecomment-1711046219,1,['simpl'],['simple']
Usability,"Hi Sophie,. So tuning a model is both an art and a science. Yes, accuracy can be lower initially, as in the following result described [by Pi-Chuan in another post](https://github.com/google/deepvariant/issues/185#issuecomment-494919509):. ![image](https://github.com/google/deepvariant/assets/6555937/bf862317-f323-47eb-bd69-6fe255e3223e). Thus no training parameters are the same for any model, since the underlying data is not the same and the goals usually are not equal. Therefore the approach for optimizing model is a journey of discovery performed via hyperparameter tuning. For example, Google uses [Vizier](https://github.com/google/vizier), but the idea falls into one of five general camps: . * Manual Tuning; * Random Search; * Grid Search; * Bayesian Optimization; * Tree-structured Parzen estimators . Here is a [link to an article](https://neptune.ai/blog/hyperparameter-tuning-in-python-complete-guide) that provides a nice summary of them - with [another describing them more visually](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/) - and [a link to another nice article](https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8) describing what happens during hyperparameter tuning. There are other ways, but they become niche and sometimes based on the data, private. Usually this training is performed automatically [as shown here](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/), but you can generate the search space yourself like in this simple example - though there are [more parameters you can select from](https://github.com/google/deepvariant/blob/r1.5/deepvariant/modeling.py#L68-L110):. $`1)`$ Learning rate usually changes as you get closer to optimal accuracy, since you are getting closer to optimal and do not overshoot the local minimal in the hyperplane. If you are starting from an untrained model, you want learn as much as possible with the default",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294:913,guid,guide,913,,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294,1,['guid'],['guide']
Usability,"Hi Sophie,. This is great news! Yes, usually that is the expected behavior after several rounds of training. Let me answer each aspect separately:. $`1)`$ So given a trained model, you can specify a custom checkpoint file via `--customized_model`, as shown under the [*Pick a model*](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md#pick-a-model) section. Probably it would be easiest to pick the one that is specified by the `best_checkpoint.txt` file. $`2)`$ Regarding `.pb` files, these are serialized binary ProtoBuf formatted versions of the model with additional details, denoted as the [*TensorFlow's SavedModel format*](https://www.tensorflow.org/guide/saved_model). When performing variant calling, DeepVariant can only use `.ckpt` model files - not `.pb` files - as specified under the [*Convert model.ckpt to model.pb*](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#convert-modelckpt-to-modelpb-savedmodel-format) section. May I ask why you might need the ProtoBuf formatted file? . $`3)`$ Regarding the `model.ckpt.example_info.json` file, it is used to validate the checkpointed model's JSON file with the JSON file generated for the examples files, matching against a few specs such as channels and shape (tensor image dimensions), to ensure data and model match before performing variant calling. It should have been automatically copied over by the [`copy_over_example_info_json()` function](https://github.com/google/deepvariant/blob/r1.5/deepvariant/model_train.py#L151-L162). Basically it contains the version of DeepVariant, the tensor image shape (rows, columns, channels) and enumerated channels. There are different ones for different technologies, and below is a list of the contents for each instrument:. ##### ONT R10.4; ```Json; {""version"": ""1.5.0"", ""shape"": [100, 199, 9], ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}; ```. ##### PacBio; ```Json; {""version"": ""1.5.0"", ""shape"": [100, 199, 9], ""channels"": [1,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1732869051:694,guid,guide,694,,https://github.com/google/deepvariant/issues/706#issuecomment-1732869051,1,['guid'],['guide']
Usability,"Hi Ted,; Thanks for your feedback. Just to be sure I've got this right. You confirm that variants with 0/0 genotype and zero DP in the merged VCF are actually positions with no reads in that sample and so can be set to missing?; I have also an additional comment about deepvariant v1.0.0. I've noticed that it is much slower than v.0.9.0. I've used them both on the sample samples (30-60X WGS) using singularity and v0.9.0 takes 10-14h while v1.0.0 takes more than 24h per sample. Is this expected?. Many thanks!; Edoardo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/346#issuecomment-694394538:25,feedback,feedback,25,,https://github.com/google/deepvariant/issues/346#issuecomment-694394538,1,['feedback'],['feedback']
Usability,"Hi again,; I didn't read carefully so I missed that you said you want to __train__ a model.; If you want to get `make_examples` to create more candidates, the other flags you need to consider are: `vsc_min_count_snps`, `vsc_min_count_indels`, `vsc_min_fraction_snps`, `vsc_min_fraction_indels`. With the default values of these flags for VSC (Very Sensitive Caller), you simply won't be able to even get candidates generated for low allele fraction variants. So I would suggest playing around with those flags and see if more candidates come out. Thanks! Let us know how it goes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-379110341:371,simpl,simply,371,,https://github.com/google/deepvariant/issues/62#issuecomment-379110341,1,['simpl'],['simply']
Usability,"Hi sorry for the delay,. I reran my sequences with a new copy of the human reference genome from https://www.ncbi.nlm.nih.gov/genome/guide/human/ up until running deepvariant. . I get the same headers as above, it doesn't seem like the bam, sam or even the reference start with the word 'chr1':. sam file header: @SQ	SN:NC_000001.11	LN:248956422; bam file (sorted picard): @HD	VN:1.6	SO:coordinate; @SQ	SN:NC_000001.11	LN:248956422; Original fasta reference file header: >NC_000001.11 Homo sapiens chromosome 1, GRCh38.p13 Primary Assembly; Bed file: chr1	12080	12251. All the code and steps I've done before are on my page under Exome_Pipeline/PE read analysis. I'm not sure! Ah, thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/527#issuecomment-1073019775:133,guid,guide,133,,https://github.com/google/deepvariant/issues/527#issuecomment-1073019775,1,['guid'],['guide']
Usability,"Hi!. DeepVariant is not made to call variants in super high depth datasets, so this is not something we recommend doing.; There are several reasons for this, but one is that the pileup images can't be much taller than around 400 reads total due to limitations in the type of machine learning model we use. The cutoff of 1.5k reads is how many reads are considered when creating candidates, but a random selection of 95 of those are actually shown to the model. Increasing the pileup image height above 95 would require retraining, and we don't find that this helps significantly enough to justify the longer runtime. For high-depth applications we generally recommend that you use a specialized variant caller that is meant to support and make full use of all those reads. . To answer your question of The flags that can be set with call_variants are all the ones listed with ""flags.DEFINE""... in https://github.com/google/deepvariant/blob/r1.2/deepvariant/call_variants.py. The cutoff of 1.5k reads is `max_reads_per_partition` in https://github.com/google/deepvariant/blob/r1.2/deepvariant/make_examples_options.py. This is not a flag we recommend users to change though. Just for my curiosity though, can you share what your application is and why the depth is so high?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/496#issuecomment-990103583:283,learn,learning,283,,https://github.com/google/deepvariant/issues/496#issuecomment-990103583,1,['learn'],['learning']
Usability,"Hi, ; thank you both for the answers and suggestions. > The error comes from the line `output_queue = multiprocessing.Queue()` Could you try a simple test? Run docker in CLI model: `docker run -it <DeepVariant image> bash` Inside docker start Python3 and execute:; > ; > ```; > import multiprocessing; > q = multiprocessing.Queue(); > ```; > ; > Please let us know if that works. No, it doesn't work. I get the following error that parallels the one above (full disclosure: I run it again with udocker, not docker):; ```; Python 3.8.10 (default, May 26 2023, 14:05:08); [GCC 9.4.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import multiprocessing; >>> q = multiprocessing.Queue(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory; ```. Also the approach suggested by @kishwarshafin unfortunately didn't work for me. I thought that udocker could be a viable option considering what said in #669. Maybe I'll try to downgrade to 1.5.0 since it's the version that was mentioned in the orginal post. . I'm not really familiar with multiprocessing but I will have a look. If you have any additional pointers, I would be really grateful for them :) . Thank you! ; Federico . EDIT: I tried running DeepVariant v1.5.0 and indeed it works! So I guess it is an issue of the newer release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/733#issuecomment-1818694916:143,simpl,simple,143,,https://github.com/google/deepvariant/issues/733#issuecomment-1818694916,1,['simpl'],['simple']
Usability,"Hi, it seems like you're using the openvino flag. Please remove that flag and try again.; For context - in recent versions, we haven't been building in openvino because we haven't been able to see extra speedup. In the next version, I'll try to make this more clear and show the proper message a bit earlier (or, just remove the flag). Please let me know if it works after you remove the openvino flag.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/597#issuecomment-1350569462:260,clear,clear,260,,https://github.com/google/deepvariant/issues/597#issuecomment-1350569462,1,['clear'],['clear']
Usability,"Hi, we recently updated the quick start and case studies to use docker.; https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md; https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md. It seems like I should rearrange and simplify our documentation to make it more clear.; Can you tell me where is the place you first read? Is it the main github page, or did you clone the codebase and directly start from there?; I will try to make some improvement next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/89#issuecomment-415984031:271,simpl,simplify,271,,https://github.com/google/deepvariant/issues/89#issuecomment-415984031,2,"['clear', 'simpl']","['clear', 'simplify']"
Usability,"Hi,. Evaluation is done using [Estimator class](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#evaluate). You may create a simple script calling Estimator.evaluate in a loop passing different checkpoints. > checkpoint_path: Path of a specific checkpoint to evaluate. If None, the latest checkpoint in model_dir is used. If there are no checkpoints in model_dir, evaluation is run with newly initialized Variables instead of ones restored from checkpoint. Hope it helps.; Alexey",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/198#issuecomment-512031369:142,simpl,simple,142,,https://github.com/google/deepvariant/issues/198#issuecomment-512031369,1,['simpl'],['simple']
Usability,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/67#issuecomment-383347052:72,clear,clear,72,,https://github.com/google/deepvariant/issues/67#issuecomment-383347052,1,['clear'],['clear']
Usability,"Hi,. I'm sorry for the late reply. I didn't have work yesterday and couldn't conduct the experiment. Thank you very much for the detailed suggestions you provided. I have observed that Paul provided very detailed suggestions regarding the steps he mentioned. I will try them out today and provide feedback here. My research top is about short tandem repeat in DNA, for example, in human reference gene hg 19 chr 2:47641559-47641586,; it has following base sequence:. chr 2:47641559-47641586 CAGGT AAAAAAAAAAAAAAAAAAAAAAAAAAA GGGTT. After search articles about next-generation sequencing, I found that their have so many factors that influence sequencing outout,such as during library construction step, PCR process will cause different repeat times because of polymerase slip. Besides that, during sequencing step, taking the Illumina sequencer as an example, during each round of cleaning, the base may not cleaned thoroughly or successfully combined with the next round of base; or other wise, a continuous series of repeated bases will influence illumination recognition signal in sequencer, and the weakened light intensity will affect the efficiency of the sequencer in identifying each binding base. So the above is the background of my use of Deepvariant. In my research topic, remove noise is very important process, because in somatic cells or cancer cells it's have different repeat times in tandem repeat regions, and I want to call every indel from human cells, but their are so many influence factor that change NGS output data so I can't find truth data in human's gene. Thank you for reading the questions I encountered in my research, I would greatly appreciate it if you could help me,; and wish you a pleasant work and life. Ji",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/697#issuecomment-1683209021:297,feedback,feedback,297,,https://github.com/google/deepvariant/issues/697#issuecomment-1683209021,1,['feedback'],['feedback']
Usability,"Hi,. It is actually possible to train DeepVariant on multiple GPUs, using the [MirroredStrategy](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/train.py#L112). You can find the tensorflow documentation here: [link](https://www.tensorflow.org/guide/distributed_training). . It looks like we need to update the [FAQ](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus) to reflect that—thanks for brining it to our attention! The [training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train) is up-to-date, so feel to continue to reference that. It looks like it already applies the `mirrored ` strategy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/885#issuecomment-2362016240:257,guid,guide,257,,https://github.com/google/deepvariant/issues/885#issuecomment-2362016240,1,['guid'],['guide']
Usability,"Hi,. Thanks for the reply, but it doesn't address my question.; My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:; > ; > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual.; https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667; https://onlinelibrary.wiley.com/doi/10.1111/mec.12105; https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs.; I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it.; I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV?. > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks.; > ; > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/878#issuecomment-2364502771:1797,simpl,simplest,1797,,https://github.com/google/deepvariant/issues/878#issuecomment-2364502771,1,['simpl'],['simplest']
Usability,"Hi,. Yes, my main question has not been addressed, it is about how to make the bam files for DeepVariant. ""DeepVariant is a deep learning-based variant caller that takes aligned reads (in BAM or CRAM format)"". The documentation doesn't say anything about how to make it/them.; For instance, one can filter reads based on mapping quality- which is not mentioned in the workflow of GATK, or mark PCR duplicates and also remove them.; For example, GATK needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________; From: Pi-Chuan Chang ***@***.***>; Sent: Friday, September 20, 2024 6:52:36 PM; To: google/deepvariant ***@***.***>; Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>; Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions).; The core question here is: Would you be able to get truth data for the bats you're studying?. I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> .; I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/878#issuecomment-2364755195:129,learn,learning-based,129,,https://github.com/google/deepvariant/issues/878#issuecomment-2364755195,1,['learn'],['learning-based']
Usability,"Hi,; As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself.; This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally.; The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend.; Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/91#issuecomment-418172888:534,learn,learning,534,,https://github.com/google/deepvariant/issues/91#issuecomment-418172888,2,['learn'],['learning']
Usability,"Hi,; I understand that it's a common use case to be compatible with GATK. We'll consider potentially adding a flag for that conversion. But since we're following the spec (using the VCF v4.3 spec: page 25 of this doc https://samtools.github.io/hts-specs/VCFv4.3.pdf), this won't be of high priority. For now the simple substitution you're doing is correct. I filed a bug internally to track. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/83#issuecomment-403616978:312,simpl,simple,312,,https://github.com/google/deepvariant/issues/83#issuecomment-403616978,1,['simpl'],['simple']
Usability,"Hi,; In the latest release we added this page:; https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-details-training-data.md; As well as a training tutorial:; https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md. If you decide to train a model, we would love to hear your feedback as detailed as you are willing to provide us. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/80#issuecomment-415562625:324,feedback,feedback,324,,https://github.com/google/deepvariant/issues/80#issuecomment-415562625,1,['feedback'],['feedback']
Usability,"Hi,; Thanks for your question! In our [blog post](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/) you mentioned, we showed an example of further training a model to perform better on mosquito data, which has higher variant density than human. Since then, internally we have continued to investigate what properties of the human genome and population structure DeepVariant learns during training. We’re hoping to come up with a suggested non-human model soon, but do not yet have a specific timeframe for releasing such a model. In terms of having a ""universal"" model, that is a good question too! We are currently investigating whether we can reduce the number of models we release while maintaining the high accuracy. Ideally if we can train one model that works well for all scenarios, we will certainly do that. Currently we’re optimizing our model accuracy for each common application, while keeping the number of released models as low as we can.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/204#issuecomment-518518311:457,learn,learns,457,,https://github.com/google/deepvariant/issues/204#issuecomment-518518311,1,['learn'],['learns']
Usability,"I FMA; File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 772, in write_variants_to_vcf; with vcf.VcfWriter(; File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 174, in __init__; self._writer = self._native_writer(output_path, **kwargs); File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 309, in _native_writer; return NativeVcfWriter(; File ""/tmp/Bazel.runfiles_21tufdoh/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 287, in __init__; self._writer = vcf_writer.VcfWriter.to_file(output_path, header,; ValueError: UNKNOWN: Could not open variants_path: /data/shared/clinical/LongRead/Data//Analysis/out_m84011_220902_175841_NFR_sif.vcf.gz. real 0m7.906s; user 0m8.421s; sys 0m8.363s. Work dir:; /data/shared/clinical/LongRead/Pipeline/work/55/335c478f0f7e93d6d5e06cd4d99711. Tip: when you have fixed the problem you can continue the execution adding the option `-resume` to the run command line; Jun-08 12:17:16.749 [Task monitor] DEBUG nextflow.Session - Session aborted -- Cause: Process `pbc_varicall (1)` terminated with an error exit status (1); Jun-08 12:17:16.752 [main] DEBUG nextflow.Session - Session await > all processes finished; Jun-08 12:17:16.764 [main] DEBUG nextflow.Session - Session await > all barriers passed; Jun-08 12:17:16.776 [main] DEBUG nextflow.trace.WorkflowStatsObserver - Workflow completed > WorkflowStats[succeededCount=0; failedCount=1; ignoredCount=0; cachedCount=0; pendingCount=0; submittedCount=0; runningCount=0; retriesCount=0; abortedCount=0; succeedDuration=0ms; failedDuration=15m 11s; cachedDuration=0ms;loadCpus=0; loadMemory=0; peakRunning=1; peakCpus=1; peakMemory=0; ]; Jun-08 12:17:16.977 [main] DEBUG nextflow.cache.CacheDB - Closing CacheDB done; Jun-08 12:17:16.991 [main] DEBUG nextflow.script.ScriptRunner - > Execution complete -- Goodbye; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308:12493,resume,resume,12493,,https://github.com/google/deepvariant/issues/659#issuecomment-1581991308,1,['resume'],['resume']
Usability,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/580#issuecomment-1304648870:95,guid,guides,95,,https://github.com/google/deepvariant/issues/580#issuecomment-1304648870,3,['guid'],"['guide', 'guides']"
Usability,"I can open a separate issue if it's helpful, but just a couple more things related to this... ; First, while the haplotype stuff like in the images above is mostly gone with `ws_use_window_selector_model=false`, I still see the problem in some false positive calls. Another thing that happens with things that DV calls de novos but obviously are not is that the kid will just meet some threshold and have a number of MQ ~40 reads with the de novo, where as the parent will have a number of reads with the allele that are MQ ~18 or lower. But the VCF reports AD[1] == 0 for many of these in the parent. If the count of low-quality alleles were reported in the sample fields in the VCF, it would be simpler to filter to make sure the allele was absent from the parent.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/272#issuecomment-592194090:697,simpl,simpler,697,,https://github.com/google/deepvariant/issues/272#issuecomment-592194090,1,['simpl'],['simpler']
Usability,"I got it. Looking at the source code:. <script type=""text/javascript"" src=""https://storage.googleapis.com/deepvariant/lib/vega/vega@5""></script>; <script type=""text/javascript"" src=""https://storage.googleapis.com/deepvariant/lib/vega/vega-lite@3.4.0""></script>; <script type=""text/javascript"" src=""https://storage.googleapis.com/deepvariant/lib/vega/vega-embed@4""></script>. unfortunately the ""https://storage.googleapis.com"" is blocked here for ""security reasons"" :( . I open in my mobile using external network and I can see the complete output. Thanks for the feedback.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/290#issuecomment-698670947:563,feedback,feedback,563,,https://github.com/google/deepvariant/issues/290#issuecomment-698670947,1,['feedback'],['feedback']
Usability,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/247#issuecomment-563285549:1018,learn,learn,1018,,https://github.com/google/deepvariant/issues/247#issuecomment-563285549,1,['learn'],['learn']
Usability,"I guess the naming pattern is related to second question.; Say I have a 50x depth BAM file that I want to downsample to 20%. I can squeeze about 5 downsampled BAMs out of 50x.; Given I assume i will perform make_examples with ""--training"" within a loop of say 5 iterations, what would the naming scheme look like? Hence the importance of the seed parameter if downsampling same BAM mulitiple times within a loop; i would change seed each time... I hope this clears up the questions and motivations behind them....",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/765#issuecomment-1909090188:458,clear,clears,458,,https://github.com/google/deepvariant/issues/765#issuecomment-1909090188,1,['clear'],['clears']
Usability,"I just checked the code, and you're right that the temp file names will be the same:; https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. For now, please pass in different `intermediate_results_dir` for each run. For example:; `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway.; 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/175#issuecomment-560625427:864,user experience,user experience,864,,https://github.com/google/deepvariant/issues/175#issuecomment-560625427,1,['user experience'],['user experience']
Usability,"I reviewed the anotated vcf.gz files (just utilized a simple search in a text editor for counts and I identified the following counts:. Checking: /home/username/deepvariant-run/output/RBA2s.cohort.vcf.gz; Family: [2114337 + 2114302] -> [2115432]; 17278/323711 (5.34%) records had indeterminate consistency status due to incomplete calls; 64534 of the values were ./. Checking: /home/username/deepvariant-run/output/RBN2s.cohort.vcf.gz; Family: [2114337 + 2114302] -> [2009617]; 25958/358380 (7.24%) records had indeterminate consistency status due to incomplete calls; 59210 of the values were ./. Checking: /home/username/deepvariant-run/output/RBNA2s.cohort.vcf.gz; Family: [2114337 + 2114302] -> [2009617, 2115432]; 25958/358380 (7.24%) records had indeterminate consistency status due to incomplete calls; 118840 of the values were ./.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/311#issuecomment-637256372:54,simpl,simple,54,,https://github.com/google/deepvariant/issues/311#issuecomment-637256372,1,['simpl'],['simple']
Usability,"I see! I am very grateful for the support. Not only the problem is solved, it is everything much more clear now, and I have learned a lot from your feedback. Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/434#issuecomment-816108659:102,clear,clear,102,,https://github.com/google/deepvariant/issues/434#issuecomment-816108659,3,"['clear', 'feedback', 'learn']","['clear', 'feedback', 'learned']"
Usability,"I strongly concur. Singularity images would be nice. Using Docker has already given me multiple diseases. It's such a hassle and from what other colleagues tell me, I am not the only one. ; Note that there is nothing wrong with the deepvariant image, it's the Docker process that can cause many problems running, pulling images, restarting, generating errors, etc ... ; Like this issue, unresolved since 2017: ; https://github.com/docker/for-win/issues/813. Dark Souls bosses are easier to take down than pulling a docker image on some systems. ; So to be clear again, nothing wrong at all with deepvariant, which I love more and more btw, but having something else than Docker would be indeed really great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/243#issuecomment-562108502:556,clear,clear,556,,https://github.com/google/deepvariant/issues/243#issuecomment-562108502,1,['clear'],['clear']
Usability,I think it actually does work with simply reads.bam and reads.bai. Yep!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/149#issuecomment-461539447:35,simpl,simply,35,,https://github.com/google/deepvariant/issues/149#issuecomment-461539447,1,['simpl'],['simply']
Usability,"I think the error is simpler than that. If you grep for these specific flags (i.e. `noparse_sam_aux_fields`, `norealign_reads`, and `nosort_by_haplotypes`) they do not exist in `make_examples` -- though it uses them in the command-line -- and thus it does not know how to process them, which is probably why you are seeing the 252 exit status:. ```Bash; $ grep -E 'noparse_sam_aux_fields|norealign_reads|nosort_by_haplotypes' deepvariant/make_examples.py; $; ```; Hope it helps,; ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/419#issuecomment-774693583:21,simpl,simpler,21,,https://github.com/google/deepvariant/issues/419#issuecomment-774693583,1,['simpl'],['simpler']
Usability,"I was not able to get this working @pichuan , if you could provide any guidance that'd still be helpful for me. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/462#issuecomment-866335254:71,guid,guidance,71,,https://github.com/google/deepvariant/issues/462#issuecomment-866335254,1,['guid'],['guidance']
Usability,"I was suspicious something else might be the issue. So I did a simple test to see if there is an issue with Luisa's BAM file, and noticed that I cannot even create an index - which would naturally make even the prerequisite `make_examples` not complete properly:. ```; paul@gubuntu:~/data/luisa$ wget http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; --2018-03-07 16:20:42-- http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; Resolving dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)... 52.218.52.113; Connecting to dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)|52.218.52.113|:80... connected.; HTTP request sent, awaiting response... 200 OK; Length: 357342653 (341M) [binary/octet-stream]; Saving to: âENCFF528VXT.bamâ. ENCFF528VXT.bam 100%[=========================================================>] 340.79M 1.26MB/s in 5m 17s. 2018-03-07 16:25:59 (1.08 MB/s) - âENCFF528VXT.bamâ saved [357342653/357342653]. paul@gubuntu:~/data/luisa$ samtools index ENCFF528VXT.bam; [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; [E::bgzf_read] Read block operation failed with error -1 after 143 of 246 bytes; samtools index: failed to create index for ""ENCFF528VXT.bam""; paul@gubuntu:~/data/luisa$; paul@gubuntu:~/data/luisa$; paul@gubuntu:~/data/luisa$ cd ~/deepvariant/bazel-bin; paul@gubuntu:~/deepvariant/bazel-bin$ PYTHONPATH=. /usr/bin/python deepvariant/make_examples --mode calling --ref /home/paul/data/luisa/hg19.fa --reads /home/paul/data/luisa/ENCFF528VXT.bam --examples /home/paul/data/luisa/shardedExamples/examples.tfrecord@2.gz --regions chr20:10,000,000-10,010,000 --task 0; WARNING: Logging before flag parsing goes to stderr.; I0307 16:27:52.052795 140569100494592 client.py:1004] Timeout attempting to reach GCE metadata service.; W0307 16:27:52.112967 140569100494592 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib; [W::bam_hdr_read] EOF marker is absent",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371293506:63,simpl,simple,63,,https://github.com/google/deepvariant/issues/52#issuecomment-371293506,1,['simpl'],['simple']
Usability,I'm closing this issue because we aren't likely to provide prebuilt binaries *without* AVX instructions. One reason is that the AVX instructions are critical to efficiently evaluate our deep learning model. Another is that TensorFlow itself will soon provide prebuilt binaries with AVX instructions (https://github.com/tensorflow/tensorflow/releases). . Users who need to run DeepVariant on pre-AVX instruction chipsets should build DeepVariant from sources.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/21#issuecomment-355389148:191,learn,learning,191,,https://github.com/google/deepvariant/issues/21#issuecomment-355389148,1,['learn'],['learning']
Usability,"I'm not completely sure about your setting. Our installation guide currently is done on Ubuntu 16. ; In your case, it seems like you're unable to install python-wheel? I think that's outside the scope of DeepVariant support. A few possible ways to get unstuck : maybe you can see whether you can skip installing python-wheel, and see what you actually need to install to proceed to the next step. I don't think we can be of more help on this issue. I'm closing this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/66#issuecomment-403636246:61,guid,guide,61,,https://github.com/google/deepvariant/issues/66#issuecomment-403636246,1,['guid'],['guide']
Usability,I'm not sure I see how the learning rate or batch_size would affect those metrics -- could you provide more information on your setup? And the two cases you are seeing -- are those randomly occurring or have you pinpointed why it flips one way or the other?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/203#issuecomment-517389773:27,learn,learning,27,,https://github.com/google/deepvariant/issues/203#issuecomment-517389773,1,['learn'],['learning']
Usability,"I've filed an internal issue to track. The update should come out in the next release. I'll close this comment for now, but will post an update once it's out.; Thanks for the feedback!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/414#issuecomment-771075195:175,feedback,feedback,175,,https://github.com/google/deepvariant/issues/414#issuecomment-771075195,1,['feedback'],['feedback']
Usability,"If I remember correctly, wildcards like * and ? should work. We can probably improve the comment there.; But concatenating everything together works too. You can directly cat all `*tfrecord.gz` into another big all.tfrecord.gz file. I would suggest trying wildcard first though. In terms of how to set num_examples: for now if you know roughly how many examples you have (for example, I can't remember if make_examples print out that information), you can just set a rough number. It's only being used here: ; https://github.com/google/deepvariant/blob/r0.4/deepvariant/model_train.py#L211; It does affect the learning rate decay, but it doesn't have to be exact.; I'll see if I can come back with a better example to count examples later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/10#issuecomment-351130156:610,learn,learning,610,,https://github.com/google/deepvariant/issues/10#issuecomment-351130156,1,['learn'],['learning']
Usability,"If you're looking for simply merging the tfrecord files (without having to touch Python code) to one, you can actually just concatenate tfrecord files together.; Something like:; `cat shard.*.tfrecord > merged.tfrecord`. or you can also concatenate zipped tfrecord files:; `cat shard.*.tfrecord.gz > merged.tfrecord.gz`; will work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/49#issuecomment-366848143:22,simpl,simply,22,,https://github.com/google/deepvariant/issues/49#issuecomment-366848143,1,['simpl'],['simply']
Usability,"Indeed the file was truncated, sorry about that. I am still testing locally; with other even smaller files ( like : wget; http://dv-testfiles.s3.amazonaws.com/wgEncodeUwRepliSeqGm12878G1bAlnRep1.bam; which is public and smaller and not truncated ) and I get the same exact; error again. 2018-03-07 22:36 GMT+01:00 Paul Grosu <notifications@github.com>:. > I was suspicious something else might be the issue. So I did a simple test; > to see if there is an issue with Luisa's BAM file, and noticed that I; > cannot even create an index - which would naturally make even the; > prerequisite make_examples not complete properly:; >; > paul@gubuntu:~/data/luisa$ wget http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > --2018-03-07 <http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam--2018-03-07> 16:20:42-- http://dv-testfiles.s3.amazonaws.com/ENCFF528VXT.bam; > Resolving dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)... 52.218.52.113; > Connecting to dv-testfiles.s3.amazonaws.com (dv-testfiles.s3.amazonaws.com)|52.218.52.113|:80... connected.; > HTTP request sent, awaiting response... 200 OK; > Length: 357342653 (341M) [binary/octet-stream]; > Saving to: âENCFF528VXT.bamâ; >; > ENCFF528VXT.bam 100%[=========================================================>] 340.79M 1.26MB/s in 5m 17s; >; > 2018-03-07 16:25:59 (1.08 MB/s) - âENCFF528VXT.bamâ saved [357342653/357342653]; >; > paul@gubuntu:~/data/luisa$ samtools index ENCFF528VXT.bam; > [W::bam_hdr_read] EOF marker is absent. The input is probably truncated; > [E::bgzf_read] Read block operation failed with error -1 after 143 of 246 bytes; > samtools index: failed to create index for ""ENCFF528VXT.bam""; > paul@gubuntu:~/data/luisa$; > paul@gubuntu:~/data/luisa$; > paul@gubuntu:~/data/luisa$ cd ~/deepvariant/bazel-bin; > paul@gubuntu:~/deepvariant/bazel-bin$ PYTHONPATH=. /usr/bin/python deepvariant/make_examples --mode calling --ref /home/paul/data/luisa/hg19.fa --reads /home/paul/data/luisa/ENCFF528VXT.bam --exam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/52#issuecomment-371306075:419,simpl,simple,419,,https://github.com/google/deepvariant/issues/52#issuecomment-371306075,1,['simpl'],['simple']
Usability,"Is it possible to merge the tfrecords files though?. On 19 Feb 2018 5:40 pm, ""Paul Grosu"" <notifications@github.com> wrote:. > Hi Oskar,; >; > Since your WDL workflow is using Docker, the simplest approach is to; > include a Docker-specific argument for --cpuset-cpus, or change the; > Session configuration which I've detailed at, the following location:; >; > #42 (comment); > <https://github.com/google/deepvariant/issues/42#issuecomment-360510853>; >; > For information regarding the --cpuset-cpus here's a reference:; >; > https://docs.docker.com/config/containers/resource_; > constraints/#configure-the-default-cfs-scheduler; >; > There are many ways to change DeepVariant, but I think this will will get; > you the quickest results for the issue you're facing.; >; > Hope it helps,; > Paul; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/49#issuecomment-366745899>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ARIS2lTrmFjJMsaw6LyJkF9atLo9sDIkks5tWaPmgaJpZM4SKal_>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/49#issuecomment-366748047:188,simpl,simplest,188,,https://github.com/google/deepvariant/issues/49#issuecomment-366748047,1,['simpl'],['simplest']
Usability,"It depends on what you want. In the simplest case, people take the genome (fasta) + callset (vcf) as a representation of this individual's genome sequence. This is a bit simplistic, though, as it doesn't differentiate between regions where we are confidently the sample is the same as the reference vs. those where we are uncertain. That information is captured in the ""genome VCF"" or ""gVCF"" which DeepVariant can generate (see `--gvcf` in `make_examples`) but currently isn't so usable as the records come out in TFRecord of Variant proto format. We are working on adding support for creating a normally-formatted gVCF by extending postprocess_variants to merge those gVCF records and the callset together, which we hope to release soon. But in the meantime the best representation you can get from DeepVariant (without coding up merging logic for the gVCF yourself, which you are more than welcome to do) is VCF + genome. . I can't comment on the suitability of FastaAlternateReferenceMaker for your specific needs (despite being the original author of that tool) as I don't believe it was widely used or whether it is maintained now. I would post to biostars or other equivalent forum to ask for recommendations on what people typically do to combine a genome FASTA + VCF to make a diploid (or haploid) reference genome sequence. There are many options (e.g., FASTG, particularly important if you have diploid organisms) but I don't know what's widely used in the community. Hope that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/13#issuecomment-351172185:36,simpl,simplest,36,,https://github.com/google/deepvariant/issues/13#issuecomment-351172185,3,"['simpl', 'usab']","['simplest', 'simplistic', 'usable']"
Usability,"It might not hurt to install a [Jenkins server](https://jenkins-ci.org/) - similar how the protobuf team does it - for continuous integration, as it also plays well with Github PRs and alleviates these simple headaches.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/19#issuecomment-353393763:202,simpl,simple,202,,https://github.com/google/deepvariant/issues/19#issuecomment-353393763,1,['simpl'],['simple']
Usability,"It's all the variants that have been called RefCall, actually, see the command:. ```; bcftools query -f ""%FILTER\t[ %GQ]\n"" OUTPUT_VCF|awk '$1==""RefCall""' > RefCall_all_GQ; ```. So 1/1 and 0/1 should be excluded, unless Deepvariant consider 1/1 as a RefCall. . I am asking around about if I am allowed to share the data, they don't ""belong' to me (though we could talk days about what it means to own scientific data). I am doing my best to get a ""yes"" answer. cheers. PS: precisely, at the moment I wanted to make a kind of hexbin plot of VAF vs GQ, however I am encountering a problem with sites like those: . Chrom_3 7095984 . A ACGAACGTTTTGCGATAGTATTTAACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTCGAGGAACGAAACTAATCGAAATCGAATCTTGATCACAATTTTCTGCATCTTGTTTCAATTTTTGACTTAAAGAT,ATGAACGTTTTGCGATAGTATTTCACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTGGAGGAACGAAACTAATTGAAATCGAATCTTGATCACAATTTTGTGCATCTTGTTTCAATTTTTCACTTAAAGAT 4.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:2:217:3,47,64:0.21659,0.294931:0,12,3,12,2,3. Clearly DeepVariant thinks there are 3 potential alleles, but that in the end it can't determine ... ; While most of the time I have 35 (GQ) against whatever, but a single value. ; This is causing my code to plot complete nonsense with negative GQ showing up in the plot. At the moment I don't know if I should find a way to replace the 2 values by a single one, or find a way to deal with the complexity in my plot. I would appreciate if you have an idea ^^'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1648455718:1155,Clear,Clearly,1155,,https://github.com/google/deepvariant/issues/682#issuecomment-1648455718,1,['Clear'],['Clearly']
Usability,"It's normal for the loss curve to start flattening out, although yours does change pretty abruptly. What exactly did you change (you mentioned using a `very simple topology`, not sure if that means you changed the architecture or something)? Also the commands you used would be helpful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/194#issuecomment-509337028:157,simpl,simple,157,,https://github.com/google/deepvariant/issues/194#issuecomment-509337028,1,['simpl'],['simple']
Usability,"Looks like I was impatient. Now that it's been going for several hours (And reduced learning rate) tensorboard is giving better results. TPs dropped to 0, and everything dropped to 0, but now it's back up. I thought starting with the pre-trained wgs model would let it just improve but I guess it had to re-learn. Planning to scale up to the entire genome next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/251#issuecomment-563508582:84,learn,learning,84,,https://github.com/google/deepvariant/issues/251#issuecomment-563508582,2,['learn'],"['learn', 'learning']"
Usability,"Machine has 64 cores, 2TB RAM, Centos is OS. Deep variant docker code works well when input bam file size is less than; 20 Gb file size, but when I increase the file size / coverage, I get the; error. On Wed, Sep 22, 2021 at 9:08 PM Pi-Chuan Chang ***@***.***>; wrote:. > @kirti141 <https://github.com/kirti141> from the log, I agree that it; > isn't quite clear.; > Can you tell us about your machine? How many CPU cores, RAM, what OS, etc.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/482#issuecomment-925047566>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ANQXTKYZH6MM2EGS7CBSZPTUDHZ7FANCNFSM5DR4DILA>; > .; > Triage notifications on the go with GitHub Mobile for iOS; > <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>; > or Android; > <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.; >; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/482#issuecomment-925379521:357,clear,clear,357,,https://github.com/google/deepvariant/issues/482#issuecomment-925379521,1,['clear'],['clear']
Usability,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/849#issuecomment-2230253485:189,clear,cleared,189,,https://github.com/google/deepvariant/issues/849#issuecomment-2230253485,1,['clear'],['cleared']
Usability,"No problem, your variant of interest isn't a genomic region that may be; hyper variable ie a simple sequence repeat (they can occur in coding; regions) or something else that may lead to the variability your seeing?. Joe. On Mon, 31 Jul 2023, 17:30 Axze-rgb, ***@***.***> wrote:. > nothing is amplified no, it's all PCR free; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/682#issuecomment-1658733075>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/BAYQV2X446P2BMPITLE5763XS7MRXANCNFSM6AAAAAA2QKAKXQ>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658739773:93,simpl,simple,93,,https://github.com/google/deepvariant/issues/682#issuecomment-1658739773,1,['simpl'],['simple']
Usability,"Oh I thought I was using a consistent model and codebase — thanks for the links. *Edit*: I was using the correct model, it was simply that it was not localized in the correct folder apparently. > On Feb 6, 2019, at 11:57 PM, Nima Mousavi <notifications@github.com> wrote:; > ; > Can you verify TF examples (test.gvcf.tfrecord-*) are in ${BASE} path?; > ; > If you use DeepVariant's cloud runner, you won't need to do all these steps manually. It takes care of everything and runs the pipeline on GCP. See instruction here:; > ; > https://cloud.google.com/genomics/docs/tutorials/deepvariant; > ; > Is there any reason why you don't use cloud runner?; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461399048:127,simpl,simply,127,,https://github.com/google/deepvariant/issues/151#issuecomment-461399048,1,['simpl'],['simply']
Usability,"Ok, then this would probably be my approach:. 1) Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". 2) Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. 3) Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/878#issuecomment-2361910524:777,simpl,simplest,777,,https://github.com/google/deepvariant/issues/878#issuecomment-2361910524,1,['simpl'],['simplest']
Usability,"Phil and Pi-Chuan;; That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:; ```; dv_make_examples.py; --ref chr20.fa.gz \; --reads test.bam \; --examples shardedExamples/examples.tfrecord@2.gz \; --regions regions.bed \; --sample test \; --logdir location/to/place/logfiles; --cores 1; ```; Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/101#issuecomment-430171385:69,simpl,simple,69,,https://github.com/google/deepvariant/issues/101#issuecomment-430171385,2,['simpl'],"['simple', 'simplified']"
Usability,"Sorry but simple sequence repeats are mutable in prokaryotes too.... On Mon, 31 Jul 2023, 17:45 Axze-rgb, ***@***.***> wrote:. > that's not a feature of this genome we are not in humans.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/682#issuecomment-1658755258>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/BAYQV2V75T2P2ATODR6Z6QDXS7OLHANCNFSM6AAAAAA2QKAKXQ>; > .; > You are receiving this because you commented.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1658757046:10,simpl,simple,10,,https://github.com/google/deepvariant/issues/682#issuecomment-1658757046,1,['simpl'],['simple']
Usability,"Sorry for my late reply! To be honest, I believe I went with the [quick start](https://github.com/google/deepvariant/blob/r1.1/docs/deepvariant-quick-start.md) and replaced the test data with my own. Then I started to debug on that ValueError, believing that was a potential bug (because of the error saying I was using `--make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`, while I was actually not; I put that first argument to false, not true).; I don't believe there is something wrong with your user flow! Your github is really nice and the docker and dependencies were very easily installed. I wouldn't want to comment more on that without extensively trying your tool, so maybe I can provide with proper feedback later :) I will definitely let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/457#issuecomment-844185505:738,feedback,feedback,738,,https://github.com/google/deepvariant/issues/457#issuecomment-844185505,1,['feedback'],['feedback']
Usability,"Sorry for the confusion here. We're phasing the reads internally to help with DeepVariant accuracy. (""Direct"" is referring to that we're doing this now directly in DeepVariant instead of relying on external HP tags from other tools like WhatsHap). However, DeepVariant currently still doesn't generate phased variant calls. Therefore you won't see ""|"" in the VCF files. Hopefully this is more clear.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/649#issuecomment-1547305204:393,clear,clear,393,,https://github.com/google/deepvariant/issues/649#issuecomment-1547305204,1,['clear'],['clear']
Usability,"Sorry for the delay, I appreciate your feedback in the matter. Closing the issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/403#issuecomment-768232068:39,feedback,feedback,39,,https://github.com/google/deepvariant/issues/403#issuecomment-768232068,1,['feedback'],['feedback']
Usability,"Stage 'Cloning TensorFlow from github as ../tensorflow doesn't exist' starting; Cloning into 'tensorflow'...; remote: Enumerating objects: 1585302, done.; remote: Counting objects: 100% (346968/346968), done.; remote: Compressing objects: 100% (5367/5367), done.; remote: Total 1585302 (delta 342939), reused 342327 (delta 341589), pack-reused 1238334; Receiving objects: 100% (1585302/1585302), 920.91 MiB | 18.57 MiB/s, done.; Resolving deltas: 100% (1307043/1307043), done.; Updating files: 100% (29800/29800), done.; Updating files: 100% (12761/12761), done.; Note: switching to 'v2.11.0'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at d5b57ca93e5 Merge pull request #58598 from tensorflow/vinila21-patch-1; WARNING: current bazel installation is not a release version.; Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.; 	--config=mkl ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804:7106,undo,undo,7106,,https://github.com/google/deepvariant/issues/657#issuecomment-1577053804,1,['undo'],['undo']
Usability,"Successfully run, once again sincerely thank you for your guidance！",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/700#issuecomment-1687514662:58,guid,guidance,58,,https://github.com/google/deepvariant/issues/700#issuecomment-1687514662,1,['guid'],['guidance']
Usability,"Sure! You can find the checkpoints for each sequencing technology at `gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/`. For example, the model for Illumina data can be found at `gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt`. These models are mounted in our [Dockerfile](https://github.com/google/deepvariant/blob/r1.6.1/Dockerfile#L156-L200). Take a look at our [custom training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#advanced-case-study-train-a-customized-snp-and-small-indel-variant-caller-for-bgiseq-500-data) if you want to learn more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/801#issuecomment-2040306496:632,learn,learn,632,,https://github.com/google/deepvariant/issues/801#issuecomment-2040306496,1,['learn'],['learn']
Usability,"Sure! please find attached the logs in the terminal.; In the meantime, I will run the simple case study.; Thank you!; [output.log](https://github.com/google/deepvariant/files/15052710/output.log)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/810#issuecomment-2068128270:86,simpl,simple,86,,https://github.com/google/deepvariant/issues/810#issuecomment-2068128270,1,['simpl'],['simple']
Usability,Thank you - I think these commands will be helpful as I learn about using Google Cloud. Please don't rush the AWS test - I am guessing I will have to wait until at least Sunday to be able to set up an account and confirm that using Google Cloud can resolve this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480271688:56,learn,learn,56,,https://github.com/google/deepvariant/issues/167#issuecomment-480271688,1,['learn'],['learn']
Usability,Thank you - I'm attaching my BED file which simply defines the entire length of the chromosome (I am working on a bacterium):; NC_000962.3 0	4411531; Is this an issue with a non-human genome?. (Saved with a .txt so that I could upload.); [confidence.bed.txt](https://github.com/google/deepvariant/files/1986525/confidence.bed.txt),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/71#issuecomment-387627131:44,simpl,simply,44,,https://github.com/google/deepvariant/issues/71#issuecomment-387627131,1,['simpl'],['simply']
Usability,"Thank you @AndrewCarroll. If the read is treated as a minimal [first-class object](https://en.wikipedia.org/wiki/First-class_citizen) (just a simple map/dictionary) would suffice, then you should be able to perform realignment after mapping. This way, it can become reactive without slowing down the analysis. Basically the information would not reside in a file, but rather encapsulated in the read itself. @PengJia6 The thing is that DeepVariant is position-focused at a specific base. That is how `make_examples` generates the variants from the allele counter for a region of a sample, which gets updated every time a new read is added to it. For instance, if you explore the allele counts, you'll get something like this for the different positions (the output is 0-based, and used the 1-based to identify each one):. ##### For Position: 89013075:. ```; position {; reference_name: ""chr10""; position: 89013074; }; ref_base: ""T""; ref_supporting_read_count: 35; read_alleles {; key: ""m64154_210327_091530/103023686/ccs/0""; value {; bases: ""TC""; type: INSERTION; count: 1; }; }; read_alleles {; key: ""m64154_210327_091530/128910218/ccs/0""; value {; bases: ""TC""; type: INSERTION; count: 1; }; }; ...; ```. ##### For Position: 89013076: . ```; position {; reference_name: ""chr10""; position: 89013075; }; ref_base: ""C""; ref_supporting_read_count: 35; read_alleles {; key: ""m64154_210327_091530/103023686/ccs/0""; value {; bases: ""CA""; type: DELETION; count: 1; }; }; read_alleles {; key: ""m64154_210327_091530/128910218/ccs/0""; value {; bases: ""CA""; type: DELETION; count: 1; }; }; ...; ```. ##### For Position: 89013077: ; ```; position {; reference_name: ""chr10""; position: 89013076; }; ref_base: ""A""; read_alleles {; key: ""m64154_210327_091530/142213575/ccs/0""; value {; bases: ""C""; type: SUBSTITUTION; count: 1; }; }; read_alleles {; key: ""m64154_210327_091530/4130912/ccs/0""; value {; bases: ""C""; type: SUBSTITUTION; count: 1; }; }; ...; ```. Given that the allele type (indel/substitution) changes ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/660#issuecomment-1590833828:142,simpl,simple,142,,https://github.com/google/deepvariant/issues/660#issuecomment-1590833828,1,['simpl'],['simple']
Usability,"Thank you again for your reply, especially on the weekend. While I'd like to have a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480616982:132,feedback,feedback,132,,https://github.com/google/deepvariant/issues/167#issuecomment-480616982,1,['feedback'],['feedback']
Usability,"Thank you for clearing my doubts despite your extremely busy schedule, I hereby present to you my most sincere appreciation",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/713#issuecomment-1746323445:14,clear,clearing,14,,https://github.com/google/deepvariant/issues/713#issuecomment-1746323445,1,['clear'],['clearing']
Usability,"Thank you for the acknowledgement, but more importantly as scientists we require that the experiment be complete by reflecting equivalence in the results. Let's dig a little deeper:. 1. In the article you are right with AVX-512 would give you the ability to ""operate on more information at once"", so have you tried a test where you compiled DeepVariant with just `-mavx512*` without MKL? Let's look at the following article:. https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture. The increased throughput (though significant) via vectorized functions is _*only one*_ aspect of the optimizations. I would suspect you picked MKL for multiple optimization reasons, one of which performs auto-queries for code path dispatches to save space on multiple binaries for users (among many other reasons):. https://software.intel.com/en-us/mkl-linux-developer-guide-instruction-set-specific-dispatching-on-intel-architectures. 2. Yes Mark's proposal is accurate with AVX, but try running with just AVX512 optimizations - which not everyone might have access to such CPUs - and _*without MKL*_ and I think you might surmise the results. To drive the point home, look at the code references in Tensoflow for AVX512 vs MKL:. * 143 for MKL => https://github.com/tensorflow/tensorflow/search?q=mkl&unscoped_q=mkl; * 19 for AVX512 => https://github.com/tensorflow/tensorflow/search?q=avx512&unscoped_q=avx512. Now having said that, what do you think could be done to make DeepVariant even faster besides AVX/MKL/CUDA/TPU optimizations?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/21#issuecomment-489377484:892,guid,guide-instruction-set-specific-dispatching-on-intel-architectures,892,,https://github.com/google/deepvariant/issues/21#issuecomment-489377484,1,['guid'],['guide-instruction-set-specific-dispatching-on-intel-architectures']
Usability,"Thank you for the feedback! @danielecook I can confirm that the files in the tmp directory do look to be normal as you described above. @kishwarshafin, I tested the docker that you suggested and now it seems that Deepvariant did not run at all (vcfs and gvcfs are empty); [deepvarrun_b37_MND_G33.1kei.log](https://github.com/google/deepvariant/files/14458499/deepvarrun_b37_MND_G33.1kei.log); ; I have attached a log file for one of the samples, so you can see what happened.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/776#issuecomment-1972749674:18,feedback,feedback,18,,https://github.com/google/deepvariant/issues/776#issuecomment-1972749674,1,['feedback'],['feedback']
Usability,"Thank you for the reply about TensorFlow. I'll double-check when I get home (I have limited IP access to my AWS Cloud account), but the call_variants file seemed much smaller than I would expect for a file format conversion at the next step. However, I think is probably that it is a binary file. However, the proportions of run time in that case study does match my own experience (the ""call_variants"" step ran the most quickly). I apologize that it will take me a little while to look into all of these things, but I do plan on comparing Google Cloud at some point (possibly for this particular issue). Total time / cost is important, but I am not currently certain what I would recommend to be as clear as possible to users. Using Docker made a huge difference for me for usability. However, at a later point, I am very grateful that you have all of the code open-source (so, if I wanted, I could use DeepVariant to better understand how to use TensorFlow in other applications). For example, even if they don't use COHCAP directly, you can use the [source code](https://github.com/cwarden45/COHCAP/tree/master/src) to see how the Boost libraries for [statistical distributions](https://www.boost.org/doc/libs/1_67_0/libs/math/doc/html/dist.html) (rather than parallel operation) can substantially decrease the run time (relative to the R-base functions). _[I apologize for being a bit off topic, but that is the best analogy that I can think of]_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-479627680:700,clear,clear,700,,https://github.com/google/deepvariant/issues/167#issuecomment-479627680,2,"['clear', 'usab']","['clear', 'usability']"
Usability,"Thank you for your prompt and professional response. I have reviewed my files and reconfigured my IGV. As @AndrewCarroll mentioned, this anomaly is that two different representations of a varaint. While both representations are equivalent, I believe that people might prefer a simpler representation here (e.g., homozygous SNV instead of three heterozygous varaints). Do you have any recommendations for post-processing methods to normalize these types of varaints into a single representation? Alternatively, can DeepVariant introduce more advanced models or encoding methods to handle this situation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/660#issuecomment-1590364272:277,simpl,simpler,277,,https://github.com/google/deepvariant/issues/660#issuecomment-1590364272,1,['simpl'],['simpler']
Usability,"Thank you for your quick answer. I had to make a couple of changes to the command (see below), but now it seems to be working:; ```; conda create -y -n deepvariant -c bioconda -c conda-forge python=2.7 deepvariant google-cloud-sdk=239.0.0; ```; Everything is installed correctly. Is there a guide to follow for locally installed variant caller?; I'm not sure I've been able to find it. . Thank you again for your support,; Andrea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/252#issuecomment-566566093:291,guid,guide,291,,https://github.com/google/deepvariant/issues/252#issuecomment-566566093,1,['guid'],['guide']
Usability,"Thank you for your reply!; For the following code, I don't have permission to modify the path `/usr/bin/`, and I didn't find `/usr/bin/python3` from `subprocess.py`, so I didn't fix the error either.; As a study student, I am working hard to learn to solve these mistakes. It hasn't been resolved yet.; ```; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'; ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/598#issuecomment-1356305359:242,learn,learn,242,,https://github.com/google/deepvariant/issues/598#issuecomment-1356305359,1,['learn'],['learn']
Usability,"Thank you so much.; In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required.; Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation.; For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:; https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/127#issuecomment-446044386:124,learn,learning,124,,https://github.com/google/deepvariant/issues/127#issuecomment-446044386,1,['learn'],['learning']
Usability,"Thank you very much for your prompt response, particularly on the weekend!. I can see that I overlooked the line `MODEL=""${HOME}/${MODEL_NAME}/model.ckpt""` in this [quick-start](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md) guide. I apologize about that. So, if I use `/mnt/efs-genome/Ref/DeepVariant/DeepVariant-inception_v3-0.7.2+data-wes_standard/model.ckpt`, then that works!. If I only put the prefix with ""model,"" I get another error mentioning a checkpoint, but I am assuming that is what the .ckpt extension stands for. Thank you again. **Update (4/1)**: I just remembered that I am supposed to close the issues on GitHub, which is what I did :)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/166#issuecomment-478414504:259,guid,guide,259,,https://github.com/google/deepvariant/issues/166#issuecomment-478414504,1,['guid'],['guide']
Usability,"Thank you very much for your reply. However I have 2 questions regarding the example visualization. . 1. As I am using multiple cores, the example files are splitted in to ; examples.tfrecord-00000-of-00008.gz to examples.tfrecord-00007-of-00008.gz. can I simply use ""examples.tfrecord-00000-of-00008.gz"" as the source path? or do I have to combine the 8 examples file together first?. 2. I cannot run the program as stated in the notebook as the `label` is not one of the features in the example for deepvariant. Is the label in the notebook the same as `alt_allele_indices/encoded` in Deepvariant? If so, how can I extract the information from the feature? I have tried 'alt_allele_indices/encoded': tf.FixedLenFeature([], tf.string), but it just gives my random symbols.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/229#issuecomment-545946241:256,simpl,simply,256,,https://github.com/google/deepvariant/issues/229#issuecomment-545946241,1,['simpl'],['simply']
Usability,"Thank you! ; My experiment was designed for the reference to be as close as possible to the studied populations so that shouldn't be an issue. Thanks for the always fast feedback.; I read in the blog post. > Of the 94,554 Mendelian violations where the child is HOM_REF, **only 17,475 (18%) of those have the HOM_REF call based just upon reference and non-reference read counts, the remaining 82% had the HOM_REF call produced by the CNN**. This seemed suspicious, so we investigated the allele depth fractions for each of HOM_REF, HETEROZYGOUS, and HOM_ALT calls in all three individuals. That's interesting because I also get quite a non trivial number of HOM_REF calls which, just based on the biology and specifics of my experiment (I prefer to remain vague about that publicly) is highly suspicious. In fact, all new homozygous variants are suspicious in my experiment. . I have highlighted a sentence in boldface, simply: how did you do that? How do you know that deepvariant made the call based on non-reference/reference read ratio or that it made the call based on its CNN interpretation? I thought the CNN was used for all calls? Or I am missing something obvious here?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/257#issuecomment-569126095:170,feedback,feedback,170,,https://github.com/google/deepvariant/issues/257#issuecomment-569126095,2,"['feedback', 'simpl']","['feedback', 'simply']"
Usability,"Thank you! I re-ran the training and validation sets with that flag, and re-shuffled them. Now, however, when I go to train the model (using the same parameters as the example case study--I just want to test out the process) I'm not getting any checkpoints in the output training directory, just the event log and the json file. What does this mean? Is the training step failing, or do I simply need to adjust my parameters? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2029425877:388,simpl,simply,388,,https://github.com/google/deepvariant/issues/797#issuecomment-2029425877,1,['simpl'],['simply']
Usability,"Thank you!; You are right.The ""RNC"" comes from GLnexus. ; https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md ""If a candidate is made, but is called as reference (either 0/0 or ./.) it means that the neural network processed the genomic region, but based on all of its learned experience from training data, it decided the highest probability for the position was as non-variant. Some of the reasons that DeepVariant may suspect a false positive are: strand-bias in reads, low mapping quality in reads, low base quality in reads, and overall low coverage.""; So,is it possible for different RNC to correspond to the above reasons(strand-bias in reads, low mapping quality in reads, low base quality in reads, and overall low coverage)?; When I met './.' ,I have reason to believe that it is 0/0 with greater probability than 0/1.; However,when the ""RNC"" is II,it means""gVCF input site is non-called"",for example: ./.:137:2,129:5:0,13,4:II ./.:137:86,50:6:0,4,39:II.; In this situation,why doesn't DeepVariant call the mutation(DP=137,alt reads=50)?. ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">; https://github-wiki-see.page/m/dnanexus-rnd/GLnexus/wiki/Reading-GLnexus-pVCFs; One of GLnexus' main functions is to generate a population-wide ""project"" VCF (pVCF) based on the input gVCFs for each individual sample. ; <html>; <body>; <!--StartFragment--><h3 style=""color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-tran",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/494#issuecomment-1018260954:277,learn,learned,277,,https://github.com/google/deepvariant/issues/494#issuecomment-1018260954,1,['learn'],['learned']
Usability,"Thank you, we're taking a look at the example and expect to have feedback relatively soon (with some delay for holidays in the US).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/388#issuecomment-734139746:65,feedback,feedback,65,,https://github.com/google/deepvariant/issues/388#issuecomment-734139746,1,['feedback'],['feedback']
Usability,"Thanks @jaqueytw . I don't believe we're currently encouraging our users to use GATK tools to process our files. But if you find any documentation that mentioned/encouraged that, please do let me know and I'd like to fix it. We're actively working on coming up with our own recommendation for best practice. Your analysis and feedback is very valuable. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/170#issuecomment-482328482:326,feedback,feedback,326,,https://github.com/google/deepvariant/issues/170#issuecomment-482328482,1,['feedback'],['feedback']
Usability,"Thanks @lvclark for the context of why you're doing this. That's very helpful to know. In that case, you'll want to run the whole pipeline separately as well (meaning, make_examples -> call_variants -> postprocess_variants separately), one using `gvcf1_parent1.tfrecord@32.gz` , the other one with `gvcf3_parent1.tfrecord@32.gz`. And not to combine them mid-way. Our team is working on makeing chrX/Y calling a bit better for DeepVariant and DeepTrio. I'll make sure to pass this feedback as well so we'll think about the use case here a bit more later on.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/413#issuecomment-1480069130:480,feedback,feedback,480,,https://github.com/google/deepvariant/issues/413#issuecomment-1480069130,1,['feedback'],['feedback']
Usability,"Thanks @machomachopadre for your report. Just so I'm 100% clear, you've got python 2.7 and 3.5 on the machine, and our build-prereqs.sh script is installing some packages into python 3.5 and some into 2.7? I don't think we've been clear before about this, but DeepVariant is intended for python 2.7 only, as we've never tested it using python3. . Can you confirm that you can install DeepVariant on a clean Ubuntu 16 instance in the cloud?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/30#issuecomment-355031587:58,clear,clear,58,,https://github.com/google/deepvariant/issues/30#issuecomment-355031587,2,['clear'],['clear']
Usability,"Thanks @nmousavi @chrisfleisch @melkerdawy ; For now, please see if the workaround that @nmousavi suggested can be used. @chrisfleisch I'm actually already planning to take a closer look at the way we build the docker image. Thanks for your feedback. I will take this into account when I do that. I'll add the information in your last comment to our internal tracking bug. Note that this might be a little low on my priority list. But I'll try to get to it soon, and I might check back with you directly to make sure things work for you.; I'll leave this GitHub issue open!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/132#issuecomment-458349387:241,feedback,feedback,241,,https://github.com/google/deepvariant/issues/132#issuecomment-458349387,1,['feedback'],['feedback']
Usability,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply!. Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**; This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**; The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**; 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**; Yes, I have successfully run it. **How much free memory do you have?**; 1.3T . **How much free disk space do you have?**; I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**; 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**; No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/681#issuecomment-1641137274:533,guid,guide,533,,https://github.com/google/deepvariant/issues/681#issuecomment-1641137274,1,['guid'],['guide']
Usability,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10?; 2) What is the basecaller version you used for basecalling this data?; 3) What is the average read length of the reads?. Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/681#issuecomment-1641030077:424,simpl,simplex,424,,https://github.com/google/deepvariant/issues/681#issuecomment-1641030077,1,['simpl'],['simplex']
Usability,"Thanks Paul for your answer,. That's clear now. That means I need to choose EC2 instance type with 1 GPU because instance with more than 1 GPU does not have any better impact on DeepVariant's performance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/696#issuecomment-1679371052:37,clear,clear,37,,https://github.com/google/deepvariant/issues/696#issuecomment-1679371052,1,['clear'],['clear']
Usability,Thanks for all the feedback and discussion above! I'll close this issue now.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/650#issuecomment-1559918325:19,feedback,feedback,19,,https://github.com/google/deepvariant/issues/650#issuecomment-1559918325,1,['feedback'],['feedback']
Usability,"Thanks for clearing that up! I appreciate it. I did use hap.py to compare the customized model to the WGS model and it appears to have performed slightly worse, so I'll keep this in mind for future tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2038129909:11,clear,clearing,11,,https://github.com/google/deepvariant/issues/797#issuecomment-2038129909,1,['clear'],['clearing']
Usability,"Thanks for the comment, @jumpyknight . What you suggest is interesting, but do you think it is plausible even if the insertion is of length 5? If that was the case, I would have expected to have more pixels 'lit up' as snps, or more pixeld 'darkened' as insertions, right after the position at which the insertion took place. However, no such behaviour takes place (referring again to the 6th channel). I'm not sure what infomation is relevant here so I'll post a bunch of stuff:. 1. The variant: as I said it is at chr20-10001435, it is labeled to be a simple SNP, hom-alt 1/1.; 2. The bam-file read I mentioned: . - Starts at: 10001358; - Cigar: 78M, 5I, 18M. That means that we have; 10001358 ... 10001435 X X X X X 10001436 ... 10001453; M ... M I I I I I M ... M; Where M indicated Match and I indicates Insertion. - It is the forward read, with mapping quality 60, ; - Has the following tags: [(RG, NA12878), (XT, U), (NM, 5), (SM, 37), (AM, 37), (X0, 1), (X1, 0), (XM, 0), (XO, 1), (XG, 5), (MD, 96)]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/379#issuecomment-723807366:554,simpl,simple,554,,https://github.com/google/deepvariant/issues/379#issuecomment-723807366,1,['simpl'],['simple']
Usability,"Thanks for the comments. I tried to train a simple 10-cnn-layer architecture and got the above results. Although the final loss still seems to be rather high, the accuracy is acceptable for the simple cnn network. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/194#issuecomment-513082707:44,simpl,simple,44,,https://github.com/google/deepvariant/issues/194#issuecomment-513082707,2,['simpl'],['simple']
Usability,Thanks for the feedback and the good news about the model. I plan to get some WES data from Element for testing.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/703#issuecomment-1708558330:15,feedback,feedback,15,,https://github.com/google/deepvariant/issues/703#issuecomment-1708558330,1,['feedback'],['feedback']
Usability,"Thanks for the feedback, I’m using a published docker image 1.4.0 which also latest at the time of this posting.How do I disable openvino?On Dec 13, 2022, at 11:51 PM, Pi-Chuan Chang ***@***.***> wrote:﻿; Hi, it seems like you're using the openvino flag. Please remove that flag and try again.; For context - in recent versions, we haven't been building in openvino because we haven't been able to see extra speedup.; In the next version, I'll try to make this more clear and show the proper message a bit earlier (or, just remove the flag); Please let me know if it works after you remove the openvino flag. —Reply to this email directly, view it on GitHub, or unsubscribe.You are receiving this because you modified the open/close state.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/597#issuecomment-1350769545:15,feedback,feedback,15,,https://github.com/google/deepvariant/issues/597#issuecomment-1350769545,2,"['clear', 'feedback']","['clear', 'feedback']"
Usability,"Thanks for the feedback. I went back to my files and just realized that my previous comment was inaccurate: the locus I analyzed on RNASeq was ""chr20:10,000,000-10,040,000""; the same exonic variant (chr20:10019093) was detected by both GATK and DeepVariant (WGS model) in my sample. As mentioned, I didn't do extensive tests at all (it was just that one locus) -- I'm happy to do further analysis if relevant,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/115#issuecomment-462075143:15,feedback,feedback,15,,https://github.com/google/deepvariant/issues/115#issuecomment-462075143,1,['feedback'],['feedback']
Usability,"Thanks for the update, @Stikus . In the code I'm working on, I currently changed that block to:; ```; # Because of an issue with pypi's numpy on Ubuntu 14.04. we need to compile from; # source.; # See https://github.com/tensorflow/tensorflow/issues/6968#issuecomment-279061085; if [[ ""$(lsb_release -d)"" == *Ubuntu*14.04.* ]]; then; echo ""Installing numpy with -no-binary=:all:. This will take a bit longer.""; pip3 install ""${PIP_ARGS[@]}"" --no-binary=:all: ""numpy==${DV_TF_NUMPY_VERSION}""; else; pip3 install ""${PIP_ARGS[@]}"" ""numpy==${DV_TF_NUMPY_VERSION}""; fi; ```. But I'm also wondering if I should just remove if/else statement for different Ubuntu versions if we're not internally testing it to make sure everything still runs. So I might end up simplifying this further in the next release. Glad to hear that the fix you mentioned above worked for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/394#issuecomment-742700347:753,simpl,simplifying,753,,https://github.com/google/deepvariant/issues/394#issuecomment-742700347,1,['simpl'],['simplifying']
Usability,Thanks for the update.The differences could be related to a change in the Tensorflow version. We welcome any additional feedback you have.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/624#issuecomment-1499324669:120,feedback,feedback,120,,https://github.com/google/deepvariant/issues/624#issuecomment-1499324669,1,['feedback'],['feedback']
Usability,"Thanks for your comments @gunjanbaid . I think, since everything else works well on single node systems, having the shuffle script work well on single node systems is also desirable. It is good to be able to shuffle only smaller files like you said. But if we limit ourselves to the original tfrecord outputs, that comes with the limitation that the shuffles are localized and not global as in the current script. However, a way to shuffle globally can be constructed from this idea with an additional step. This additional step will simply partition the input data into random buckets. Then we shuffle each bucket. I believe this is equivalent to a global shuffle with uniform probability for each permutation. This would be something like:; ```; input_data = readers | ""FlattenInputs"" >> beam.Flatten(); partitions = input_data | ""PartitionInputs"" >> beam.Partition(<random_partition_function_name>, <num_partitions>); for i, p in enumerate(partitions):; writing = p | ""WritePartition%d"" % i >> beam.io.WriteTFRecord(...); ```. Then each partition may be shuffled individually using the shuffle script. I have rolled both partitioning and shuffling into the same [script](https://github.com/anands-repo/deepvariant/blob/r1.0/tools/shuffle_tfrecords_beam_for_local.py). I will report back regarding whether this works as expected. This depends on beam.Partition behaving properly.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/pull/365#issuecomment-720871901:534,simpl,simply,534,,https://github.com/google/deepvariant/pull/365#issuecomment-720871901,1,['simpl'],['simply']
Usability,"Thanks for your reply. Hopefully reads seem to map with a MAPQ of 60 so Deepvariant should see them. We believe the issue is high SNP density making some standing variant hard to call. It's also very possible there is no signal, i.e. the bdelloids have evolved a very low mutation rate and we are chasing ghosts. Since they reproduce asexually (at least in the lab) by automixis, it is a possibility. We developed a simple script, for each SNP that seems to be a de novo one, we look in the ancestral pileup, and we always find the SNP there but not called. I think the high density messes up callers internal maths, and some SNP get a low chance of being called. Anyway, the ONT sequencing is ongoing. We will see with the pileup there. There are also solutions with comparing assembly graphs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/716#issuecomment-1761318730:416,simpl,simple,416,,https://github.com/google/deepvariant/issues/716#issuecomment-1761318730,1,['simpl'],['simple']
Usability,"Thanks so much! I think I understand the issue now, but Deepvariant is still giving a wrong answer.; You can see that this particular location in the genome has a tandem repeat of 6 copies of a 47 bp sequence:; https://genome.ucsc.edu/cgi-bin/hgc?hgsid=960400993_qiSzxsvvUkaPrDYeYJ2KhGLAK2ay&c=chr3&l=76220845&r=76221817&o=76221234&t=76221509&g=simpleRepeat&i=trf. But I actually have long PacBio reads for this sample, with the zmw consensus sequence at the same location of:; TGAGCTTAATCATAGAACATGGTAATACTAGGAGACATCATGAAGGATCCCTGTGTTGTAGATATACTCTTCTTTACTTCCATTGAGAAGTAGTAGTTCAATTTCCCCAGGTAGTCTGAATCAATAACCCCAGGCAATATTGACTGTTTCTGTGGTGAAAGCATTCCTCCATCTAGAACTAAGTCCTCTTGCCCAACAGAAGATAAAGTCATGAGCATGGGAAGCAAAAATTTTGCTAGTGGGTAACTCAGGGTGATGGTGAGTAGTGCCACTCTCATTTTACAAGTGGGTAACTCAGGGTGATGGTGAGCAGTGCCACTCTCATTTTACAAGTGGGTAACTCAGGGTGATGGTGAGTAGTGCCACTCTCATTTTACAAGTGGGTAACTCAGGGTGATGGTGAGCAGTGCCCCTCTCATTTTACAAGTGGGTAACTCAGGGTGACGGTGAGCAGTGCCACTCTCATTTTACAAGTAACTCAGGGTGATGGTGAGCAGTGCCACTCTCATTTTCCACGCTTTGATTCCTGAACCCATTAATTGTGGCTGTTGATGAAACTACTATATGTTGGAAACTGCTTCAGAGAATATACAACCTTCTGCAGAACCTTGGCCCAGCTGTGTAAGGTATTGCGATCTAGCTGGTACTGTAACTGAATTCAAAAGACCCTTTTATCATTTTTATCAAGTTAGCTGCTTCTGGATGATGGGGAACATGGTAAGACCGATGGACTTCATGACCATGAGCCCATTGCCACACTTTTTTGTCTTTGAGGTGAGTTCCTTGATCAGAAGCAATGCTGTATTTAATACTGTGCCTGTGGATAAGACATTTTATAAGTCCACGGATGGTAGTTTCGGTGGAAGCATTGCACCCACGGAAGACAAATCCATAACCTGAGAAGGGTCTATTCCAATAAGCACAAAATGCTGCCACTTCCATAGTGGAAGCAGTCTAATGTAGATAAACTGCCACTAGGTAGCTGGCTGATCACCCTGGGGAATAATGCCAAATGGGATCACAATGTGGTCTCTACTGCTGGCAGATTGTATAATCTGCCAGTGGTGGCCATAGCTAGGTCAGCCTTGGTGAGTGGAAACCTATGTTGCTGAGTGCATGCATAACCTTCATCCCTGCCACCATGTCCACCTGTTACTGGTGGAATGTATCTGAGCCACGTGGCACCAAAACACGTTACCAGTGGCAAATTGGTATGGGTTTGCAGCAACTTCAGTTCTTGCCTCCTCAGAAGAAAGAATCTGACTGAGAGGCATAAGGTAGAAGGAGGGGCTGAGGCAAGTTTTAGAGCAGGAGTGAATGTTTATTTAAAAAGCCTTAGAGCAGGAATGAAAGGAAGGAAAGAAAGTATACTTGGAAGAGGGCCAAGTGGGTGACTTGAAAGACAAGTGTACATGTTGACCTTGTGACTAGGCTTATACGTTGGCATAATTCCAGGGTCTTGTGTCACTTCTCCCAACCCGCCCAACCCTTGAGATCTTATTGGGAAGCTGCTGATAACCAGT",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/388#issuecomment-735306929:345,simpl,simpleRepeat,345,,https://github.com/google/deepvariant/issues/388#issuecomment-735306929,1,['simpl'],['simpleRepeat']
Usability,"Thanks so much, that makes the path forwards a lot clearer. Reading between the lines, is (3) the reason we are advised to shuffle the validation data as well, because it combines all the chr20-22 examples into one dataset?. Very much looking forward to reading your comments on warmstarting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/312#issuecomment-637523488:51,clear,clearer,51,,https://github.com/google/deepvariant/issues/312#issuecomment-637523488,1,['clear'],['clearer']
Usability,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/94#issuecomment-423408772:83,guid,guiding,83,,https://github.com/google/deepvariant/issues/94#issuecomment-423408772,1,['guid'],['guiding']
Usability,The error comes from the line `output_queue = multiprocessing.Queue()`; Could you try a simple test? ; Run docker in CLI model: `docker run -it <DeepVariant image> bash`; Inside docker start Python3 and execute:; ```; import multiprocessing; q = multiprocessing.Queue(); ```; Please let us know if that works.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/733#issuecomment-1816864777:88,simpl,simple,88,,https://github.com/google/deepvariant/issues/733#issuecomment-1816864777,1,['simpl'],['simple']
Usability,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling.; By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/536#issuecomment-1106635811:181,learn,learning,181,,https://github.com/google/deepvariant/issues/536#issuecomment-1106635811,1,['learn'],['learning']
Usability,The number is referring to the number of steps in training when this checkpoint is saved.; You can see https://www.tensorflow.org/guide/checkpoints for more information.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/192#issuecomment-506979241:130,guid,guide,130,,https://github.com/google/deepvariant/issues/192#issuecomment-506979241,1,['guid'],['guide']
Usability,"There is a simple typo in the `rtg vcfmerge` step above, it should `=` after `Sex`. `--add-header ""##SAMPLE<ID=HG002,Sex=MALE>"" \`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/779#issuecomment-2118639400:11,simpl,simple,11,,https://github.com/google/deepvariant/issues/779#issuecomment-2118639400,1,['simpl'],['simple']
Usability,"These mostly run on nodes with Intel Xeon Gold 6140, occasionally on Intel Xeon E5-2697v4, but these are much slower anyway. . I had noticed the same speed improvement in v1.1.0 with openvino as your metrics, but I haven't tested the new version extensively with and without. However, when rerunning identical samples (both with openvino flags), I've noticed that v1.2.0 takes longer wall clock time compared to v1.1.0, but less CPU time. Maybe it is just node variation or other jobs bottlenecking IO, so hopefully will see a clearer result after more samples run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/416#issuecomment-889821634:527,clear,clearer,527,,https://github.com/google/deepvariant/issues/416#issuecomment-889821634,1,['clear'],['clearer']
Usability,"This has a simple fix. Basically you need to replace `/output/realigned_reads` with a location you have write-access to. For example, you can do the following commands:. Assuming you have write-access to this folder `/scratch/c.c21087028/checking_variant_deepvariant`, you can create a sub-directory called `realigned_reads` like this:. ```; mkdir /scratch/c.c21087028/checking_variant_deepvariant/realigned_reads; ```. Then in your Singularity script you have two options to pick from:. #### Option 1 - update only the following line:. ``` ; --make_examples_extra_args=""emit_realigned_reads=true,realigner_diagnostics=/scratch/c.c21087028/checking_variant_deepvariant/realigned_reads"" \; ```. All other lines for Option 1 remain the same. #### Option 2 - update the following lines (I used -B to make /output accessible inside the container):. ```; sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B /scratch/c.c21087028/checking_variant_deepvariant/:/output/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. ```. The rest of the lines can stay the same for Option 2. Regarding a BED file, you don't need one as they are the same thing as regions -- which you already provide:. https://en.wikipedia.org/wiki/BED_(file_format). Let me know how this runs, and if your run into any other issues. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/691#issuecomment-1667728104:11,simpl,simple,11,,https://github.com/google/deepvariant/issues/691#issuecomment-1667728104,1,['simpl'],['simple']
Usability,"This is a very interesting question, and the answers to it are complex. I assume for the sake of the question that you have FASTQ data from sequencing a single bacterial colony (so this is not a metagenomics question). Let's divide the question between ""can it technically be done"" and ""will the answers be scientifically valid"". To the question ""can it technically be done"", the answer is probably yes. I am not aware that we have specifically attempted this in bacteria. But if you have a FASTA file with a reference for a species and FASTQ reads, you should be able to generate variant calls for it. To the question ""will the answers be scientifically valid"", it is important to note calling variants in bacterial genomes is an area of open research. Using DeepVariant is reasonable, but I don't think you'll able to consider the output of any method (DeepVariant or other) as certain to give you fully correct results on this problem right out of the box. You'll want to use a few methods (use Freebayes and GATK) and compare between them with metrics you can independently validate, then decide what works and doesn't for your use case. One way to do this could be that for a clonal lineage you expect variants to all be called as 1/1 for the non-plasmid genome sequence. Ryan Poplin used this measure in a similar way to compare DeepVariant and other methods on inbred rice strains from the 3000 Rice Genomes Project. We would be quite interested to receive your feedback on how DeepVariant performs in this use case, as this may help us understand the value of DeepVariant and improve it for the community.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/114#issuecomment-434889612:1469,feedback,feedback,1469,,https://github.com/google/deepvariant/issues/114#issuecomment-434889612,1,['feedback'],['feedback']
Usability,"This is very good! . #### For Singularity . You can take a look at the following two links:. https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-quick-start.md#notes-on-singularity. https://github.com/google/deepvariant/blob/r1.5/scripts/install_singularity.sh. #### For your Ubuntu instance . You are getting very close! To simplify the install in the `run-prereq.sh` file you can comment out (with the `#` symbol) the following sections:. 1) For the ""Install TensorFlow pip package"" keep only the ones with **CPU-only**, and comment out the others. 2) For ""Install CUDA"", comment out everthing. 3) For ""Install TensorRT"", comment out everthing. And then run it again. The rest of the errors in the `run-prereq.sh` are easy to fix, which we can do later individually by removing each one, and installing the minimum required version. Before we fix `clif`, could you tell me what you get for the following:. ```; lsb_release -sc. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - . add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". sudo apt-get update. sudo apt-get install -y llvm-11 llvm-11-dev clang-11 llvm-11-tools; ```. You might have a mismatch of a previous version of `clif` or its installed configuration files. You can check that via the following commands:. ```; llvm-config-11 --version; ```. The configs might be an older version, which you can check via the following:. ```; cat /usr/lib/llvm-11/lib/cmake/llvm/LLVMConfig.cmake | grep PACKAGE_VERSION; ```. Below is what I have:. ```; $ cat /usr/lib/llvm-11/lib/cmake/llvm/LLVMConfig.cmake | grep PACKAGE_VERSION; set(LLVM_PACKAGE_VERSION 11.1.0); $ cat /usr/lib/llvm-11/cmake/LLVMConfig.cmake | grep PACKAGE_VERSION; set(LLVM_PACKAGE_VERSION 11.1.0); $ cat /lib/llvm-11/cmake/LLVMConfig.cmake | grep PACKAGE_VERSION; cat: /lib/llvm-11/cmake/LLVMConfig.cmake: No such file or directory; $; ```. If you have a mismatch between the version and config,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/657#issuecomment-1575894236:335,simpl,simplify,335,,https://github.com/google/deepvariant/issues/657#issuecomment-1575894236,1,['simpl'],['simplify']
Usability,This seems like a genuine bug. Is there any way you can share the genome reference and reads along with a command line that reproduces the issue? It's not clear to me what the actual issue is and that would help a lot debugging the actual problem.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/71#issuecomment-387816424:155,clear,clear,155,,https://github.com/google/deepvariant/issues/71#issuecomment-387816424,1,['clear'],['clear']
Usability,"To be 100% clear, are you saying you booted a clean ubuntu 16 instance and it failed to build there? Or is this on an already customized machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/32#issuecomment-355348946:11,clear,clear,11,,https://github.com/google/deepvariant/issues/32#issuecomment-355348946,1,['clear'],['clear']
Usability,"To make it clearer, I put the path structure here.; ```; /deepvariant/core/; cloud_utils_test.py; math.py; ...; ```; And in `cloud_utils_test.py`:; ```; """"""Tests for deepvariant .core.cloud_utils."""""". from __future__ import absolute_import; from __future__ import division; from __future__ import print_function. import httplib; ...; ```; Through `httplib`, it imports `mimetools`, which imports `tempfile`, which imports `ramdom`, which imports `math`. ; But since there is a `math.py` in the same path, it shadows the `math` module in python's standard library, causing an error. To test the hypothesis, simply importing `httplib` in the same path caused the following error:; ```; >>> import httplib; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""xx/anaconda/envs/Python27/lib/python2.7/httplib.py"", line 80, in <module>; import mimetools; File ""xx/anaconda/envs/Python27/lib/python2.7/mimetools.py"", line 6, in <module>; import tempfile; File ""xx/anaconda/envs/Python27/lib/python2.7/tempfile.py"", line 35, in <module>; from random import Random as _Random; File ""xx/anaconda/envs/Python27/lib/python2.7/random.py"", line 45, in <module>; from math import log as _log, exp as _exp, pi as _pi, e as _e, ceil as _ceil; ***File ""math.py"", line 79, in <module>***; import numpy as np; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>; from . import add_newdocs; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/add_newdocs.py"", line 13, in <module>; from numpy.lib import add_newdoc; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/lib/__init__.py"", line 8, in <module>; from .type_check import *; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/lib/type_check.py"", line 11, in <module>; import numpy.core.numeric as _nx; File ""xx/anaconda/envs/Python27/lib/python2.7/site-packages/numpy/core/__init__.py"", line 74, in <module>; from numpy.testing.nosetester impo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/32#issuecomment-355522771:11,clear,clearer,11,,https://github.com/google/deepvariant/issues/32#issuecomment-355522771,2,"['clear', 'simpl']","['clearer', 'simply']"
Usability,Unfortunately it's not clear from your post what might be going wrong here. Is this on a clean install of Ubuntu 16? We'd recommend starting there first to make sure everything is working and then moving to whatever environment you are running on.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/5#issuecomment-349829021:23,clear,clear,23,,https://github.com/google/deepvariant/issues/5#issuecomment-349829021,1,['clear'],['clear']
Usability,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/557#issuecomment-1228968407:132,simpl,simplify,132,,https://github.com/google/deepvariant/issues/557#issuecomment-1228968407,1,['simpl'],['simplify']
Usability,"Update: Internally our team has been making other improvements to postprocess_variants, so I've not been actively looking into this issue. I'll plan to resume in the next few weeks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/811#issuecomment-2235560333:152,resume,resume,152,,https://github.com/google/deepvariant/issues/811#issuecomment-2235560333,1,['resume'],['resume']
Usability,We added a note about needing the `gsutil` from Google Cloud SDK to our [Build and Test guide](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md). Let us know if you are still having issues.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/5#issuecomment-350478903:88,guid,guide,88,,https://github.com/google/deepvariant/issues/5#issuecomment-350478903,1,['guid'],['guide']
Usability,"We have updated the documentation to mention that AVX instructions are needed. These changes will come out with the next release. Thank you for the feedback!. Edit: we specifically mention this requirement again in the quickstart documentation, in addition to the page linked below by @pgrosu. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/248#issuecomment-566700041:148,feedback,feedback,148,,https://github.com/google/deepvariant/issues/248#issuecomment-566700041,1,['feedback'],['feedback']
Usability,"When you say ""_when we use another tool to process the gvcf created by deepvariant, some information are changed_,"" it might worth figuring out what exactly is changed. Without that info, the feedback isn't actionable.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/170#issuecomment-482327182:192,feedback,feedback,192,,https://github.com/google/deepvariant/issues/170#issuecomment-482327182,1,['feedback'],['feedback']
Usability,With a brand new t2.medium instance per the quickstart guide and your command I get:. ```; docker: invalid reference format.; See 'docker run --help'. real	0m0.046s; user	0m0.023s; sys	0m0.028s; ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/462#issuecomment-867185369:55,guid,guide,55,,https://github.com/google/deepvariant/issues/462#issuecomment-867185369,1,['guid'],['guide']
Usability,"Yes i do have a faidx index file too, actually i am doing it with; mitochondrial genome for hg38 version. Again i modified the command kept both input sorted bam and fasta file; along with faidx index in the same directory, By following the given format; https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-ont-r104-simplex-case-study.md; BIN_VERSION=""1.6.1"". sudo docker run \; -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \; -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type ONT_R104 \; --ref ""${INPUT_DIR}/${REF}"" \; --reads ""${INPUT_DIR}/${BAM}"" \; --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \; --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \; --num_shards ""${THREADS}"" \; --regions ""${REGION}"" \; --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"". => Here is my recent command used for docker run. It would be great help if; I am able to resolve this issue. Thank you in advance. sudo docker run -v; */media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3*; -v; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result; google/deepvariant:{BIN_VERSION=""1.6.1""} python; /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py; *--reads; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam; --ref; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/829#issuecomment-2162176427:331,simpl,simplex-case-study,331,,https://github.com/google/deepvariant/issues/829#issuecomment-2162176427,1,['simpl'],['simplex-case-study']
Usability,"Yes, I definitely got each pbtxt file. Attached below are the log files from the model train step. When I ran this step before (when I had not used the --channels flag, and could not test the model), the .err file for the model training step looked as though it reached a stopping point, whereas in this run it looks like it simply stopped and did not reach that same point. It's definitely not a timeout issue, but I'm not sure what's causing it. . The pbtxt file for the validation set (training set looks similar) looks like this:; ```; # Generated by shuffle_tfrecords_beam.py; #; # --input_pattern_list=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_output/validation_set.with_label_channlesize.tfrecord.gz; # --output_pattern_prefix=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_output/validation_set.with_label_channelsize.shuffled; #. name: ""Chromosome3""; tfrecord_path: ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_output/validation_set.with_label_channelsize.shuffled-?????-of-?????.tfrecord.gz""; num_examples: 35759; # class1: 27257; # class0: 1777; # class2: 6725; ```; And here are the log files from the attempted model training: ; [deepvariant_modeltrain-14705863-Atlas-0031.err.txt](https://github.com/google/deepvariant/files/14828238/deepvariant_modeltrain-14705863-Atlas-0031.err.txt); [deepvariant_modeltrain-14705863-Atlas-0031.out.txt](https://github.com/google/deepvariant/files/14828239/deepvariant_modeltrain-14705863-Atlas-0031.out.txt). Thank you for your help!. Best, ; Haley",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/797#issuecomment-2030499725:325,simpl,simply,325,,https://github.com/google/deepvariant/issues/797#issuecomment-2030499725,1,['simpl'],['simply']
Usability,"Yes, it works simply updating singularity. Thanks for figuring this out!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/445#issuecomment-822637152:14,simpl,simply,14,,https://github.com/google/deepvariant/issues/445#issuecomment-822637152,1,['simpl'],['simply']
Usability,"Yup that's right. Sorry, I meant `model.ckpt`, not just `model`.; Feel free to open another issue if you have other questions. In the next release, I'm hoping to make it easier to use. One thing I'm looking into is to not have to specify a super long model path, which is error-prone. When the next release comes out, it'll be good to have your feedback again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/166#issuecomment-478851260:345,feedback,feedback,345,,https://github.com/google/deepvariant/issues/166#issuecomment-478851260,1,['feedback'],['feedback']
Usability,"al daughter2; Chr1 4917 . A G . . MCV=daughter2:0|0+0|0->0|1 GT:DN 0|0 0|0 0|0 0|0 0|0 0|0 0|1:Y; Chr1 15214 . G C . . MCV=daughter2:0|0+0|0->1|0 GT:DN 0|0 0|0 0|0 0|0 0|0 0|0 1|0:Y; Chr2 4883 . T G . . MCV=daughter2:0|0+0|0->0|1 GT:DN 0|0 0|0 0|0 0|0 0|0 0|0 0|1:Y; Chr2 11369 . G A . . MCV=daughter2:0|0+0|0->0|1 GT:DN 0|0 0|0 0|0 0|0 0|0 0|0 0|1:Y; Chr3 11754 . A G . . MCV=daughter2:0|0+0|0->0|1 GT:DN 0|0 0|0 0|0 0|0 0|0 0|0 0|1:Y; Chr4 37470 . C T . . MCV=daughter2:0|0+0|0->1|0 GT:DN 0|0 0|0 0|0 0|0 0|0 0|0 1|0:Y; ```. Below are a few tools that can also perform trio analysis (generating their own VCF), or can perform VCF refinement based on pedigree information:. * [dv-trio](https://github.com/VCCRI/dv-trio) with [FamSeq](https://github.com/wwylab/FamSeq) (This is an earlier version approach of DeepVariant before DeepTrio); * [Octopus](https://github.com/luntergroup/octopus) ([doc example](https://luntergroup.github.io/octopus/docs/guides/models/trio/)); * [GATK HaplotypeCaller + GenotypeGVCFs + CalculateGenotypePosteriors refinement](https://gatk.broadinstitute.org/hc/en-us/articles/360037226592-CalculateGenotypePosteriors), and [an additional informational link](https://hpc.nih.gov/training/gatk_tutorial/workflow-overview.html); * [DeNovoGear](https://github.com/ultimatesource/denovogear). The key point to take away from this is not that there are options, but how these options internally work to infer the genotype and its probability given the data. Some work better with longer reads, and some with shorter reads. You want to play with them to get a feel of what is happening given different data. If you are curious, you can read the papers and mathematics behind each approach, and you'll be surprised by their similarity in approaches of inferring the call and its probability (quality). I have included a list of papers with links in the reference section below. Now if the above is too easy, and you want to make _de novo_ variant calling more exciting, you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/699#issuecomment-1716447969:2318,guid,guides,2318,,https://github.com/google/deepvariant/issues/699#issuecomment-1716447969,1,['guid'],['guides']
Usability,"ces), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-476428247:1376,intuit,intuition,1376,,https://github.com/google/deepvariant/issues/165#issuecomment-476428247,1,['intuit'],['intuition']
Usability,"does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_dqd3ut4s/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '32']"".; E0430 18:57:45.247818 140240365713216 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_8s9w7qaa/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '25']"".; E0430 18:57:45.247906 139736525375296 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_8kqng5_c/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '1']"".; E0430 18:57:45.354531 139703252227904 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_47rk8xc1/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '22']"".; E0430 18:57:45.318170 140515109386048 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_4p5rc3ja/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '35']"".; E0430 18:57:45.306068 140062873229120 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xavizfpc/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '42']"".; E0430 18:57:45.268234 140590012761920 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_ovmu_l59/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '8']"".; parallel: This job failed:. could you provide any guidance on how to run the make_example.zip working on parallel (like create a 48 jobs)? Thanks",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/441#issuecomment-830444850:13854,guid,guidance,13854,,https://github.com/google/deepvariant/issues/441#issuecomment-830444850,1,['guid'],['guidance']
Usability,"e ""us-west1-b""; ```. Check the Linux version:. ```; $ uname -a; Linux pichuan-test.us-west1-b.c.brain-genomics.google.com.internal 5.14.0-362.24.2.el9_3.x86_64 #1 SMP PREEMPT_DYNAMIC Sat Mar 30 14:11:54 EDT 2024 x86_64 x86_64 x86_64 GNU/Linux; ```. And I ran this too:. ```; $ cat /etc/os-release; NAME=""AlmaLinux""; VERSION=""9.3 (Shamrock Pampas Cat)""; ID=""almalinux""; ID_LIKE=""rhel centos fedora""; VERSION_ID=""9.3""; PLATFORM_ID=""platform:el9""; PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)""; ANSI_COLOR=""0;34""; LOGO=""fedora-logo-icon""; CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos""; HOME_URL=""https://almalinux.org/""; DOCUMENTATION_URL=""https://wiki.almalinux.org/""; BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9""; ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3""; REDHAT_SUPPORT_PRODUCT=""AlmaLinux""; REDHAT_SUPPORT_PRODUCT_VERSION=""9.3""; ```. ## Install Singularity. I don't have Singularity on the machine yet, so:. https://docs.sylabs.io/guides/4.1/user-guide/quick_start.html#quick-installation-steps. ```bash; sudo yum update -y && \; sudo yum groupinstall -y 'Development Tools' && \; sudo yum install -y \; openssl-devel \; libuuid-devel \; libseccomp-devel \; wget \; squashfs-tools; ```. ```; sudo yum groupinstall -y 'Development Tools'; # Install RPM packages for dependencies; sudo yum install -y \; autoconf \; automake \; cryptsetup \; fuse3-devel \; git \; glib2-devel \; libseccomp-devel \; libtool \; runc \; squashfs-tools \; wget \; zlib-devel; ```. ```bash; sudo dnf install dnf-plugins-core; sudo dnf copr enable dctrud/squashfs-tools-ng; sudo dnf install squashfs-tools-ng; ```. ```bash; export VERSION=1.21.0 OS=linux ARCH=amd64 && \; wget https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz && \; sudo tar -C /usr/local -xzvf go$VERSION.$OS-$ARCH.tar.gz && \; rm go$VERSION.$OS-$ARCH.tar.gz; ```. ```bash; echo 'export PATH=/usr/local/go/bin:$PATH' >> ~/.bashrc && \; source ~/.bashrc; ```. ```bash; export VERSION=4.1.0 && \; wget https:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/812#issuecomment-2076206716:1445,guid,guide,1445,,https://github.com/google/deepvariant/issues/812#issuecomment-2076206716,1,['guid'],['guide']
Usability,"e under some circumstances. . So let's try the `mount` approach. The reason we used `--mount` instead of `-v` is because it is more granular, telling us specifically which directory it is having an issue with. In this case it is getting stuck on the `variant_calling` directory, and somehow Docker is not able to recognize it. So let's try to determine what type of directory, and what permissions it has (including above and below it). $`1)`$ So if you could please type the following commands, then we can inspect the output to determine what might be the issue:. ```; stat /tiger/home/ajp1/analysis/demography/tasmanian_devil. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling. stat /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling/inputs. ls -l /tiger/home/ajp1/analysis/demography | grep tasmanian_devil. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/ | grep variant_calling. ls -l /tiger/home/ajp1/analysis/demography/tasmanian_devil/variant_calling | grep inputs; ```. $`2)`$ Now I have some minor questions about your system and Docker, in order to determine if there could be other underlying causes. For the following questions, it's okay if you don't remember everything: . * What operating system and version are your running? ; * How long ago did you install Docker?; * What commands did you use to install Docker? ; * What version of Docker are you running? (The command is in the commands below.). You previously mention that `ajp1` is part of the docker group, so we can use that as guidance when we inspect the output from the commands above. Below is a set of commands if you could please run, to answer some of the questions above (except for the installation ones). For Linux usually the commands are as follows (some will provide you information, as I included them for multiple operating systems):. ```; uname -a. cat /etc/lsb-release. cat /etc/redhat-release. cat /etc/os-release. docker --version; ```. Thank you,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/184#issuecomment-1702017107:1925,guid,guidance,1925,,https://github.com/google/deepvariant/issues/184#issuecomment-1702017107,1,['guid'],['guidance']
Usability,"e_examples_runner; candidates, examples, gvcfs, runtimes = region_processor.process(region); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process; reads = self.region_reads(region); File ""/tmp/Bazel.runfiles_im0i33s_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads; error_message + '\nFailed to parse BAM/CRAM file. '; ValueError: Data loss: Failed to parse SAM record; Failed to parse BAM/CRAM file. This is often caused by:; (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file.; (2) Your BAM/CRAM file could be corrupted. Please check its md5.; If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues; ```. It seems like for this particular failure mode (BAM file is truncated), the default stackt race was already clear.; But given that I mentioned different level of verbosity. I tried that next. ## Use `-v` to increase verbosity level. if you run `/opt/deepvariant/bin/make_examples --helpfull` you'll see this flag:. ```; -v,--verbosity: Logging verbosity level. Messages logged at this level or; lower will be included. Set to 1 for debug logging. If the flag was not set; or supplied, the value will be changed from the default of -1 (warning) to 0; (info) after flags are parsed.; (default: '-1'); (an integer); ```; You can try to add `-v 1`. But in this case above, my run already had useful logging and didn't seem to produce more useful logs. ## What if we run with Singularity?. I think you were running with Singularity, so I tried that too. I repeated the steps in https://github.com/google/deepvariant/issues/463#issuecomment-866352316 to install Singularity. And then with the same data, I ran:. ```; # Pull the image.; BIN_VERSION=1.1.0; singular",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/465#issuecomment-870990381:13776,clear,clear,13776,,https://github.com/google/deepvariant/issues/465#issuecomment-870990381,1,['clear'],['clear']
Usability,"eate failed for thread 63 of 64: Resource temporarily unavailable; > OpenBLAS blas_thread_init: RLIMIT_NPROC 4096 current, 8254915 max; > Traceback (most recent call last):; > File ""/tmp/Bazel.runfiles_XqQaQr/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>; > import numpy as np; > File ""/usr/local/lib/python2.7/dist-packages/numpy/__init__.py"", line 142, in <module>; > from . import core; > File ""/usr/local/lib/python2.7/dist-packages/numpy/core/__init__.py"", line 47, in <module>; > raise ImportError(msg); > ImportError:; > ; > IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!; > ; > Importing the multiarray numpy extension module failed. Most; > likely you are trying to import a failed build of numpy.; > Here is how to proceed:; > - If you're working with a numpy git repository, try `git clean -xdf`; > (removes all files not under version control) and rebuild numpy.; > - If you are simply trying to use the numpy version that you have installed:; > your installation is broken - please reinstall numpy.; > - If you have already reinstalled and that did not fix the problem, then:; > 1. Check that you are using the Python you expect (you're using /usr/bin/python),; > and that you have no directories in your PATH or PYTHONPATH that can; > interfere with the Python and numpy versions you're trying to use.; > 2. If (1) looks fine, you can open a new issue at; > https://github.com/numpy/numpy/issues. Please include details on:; > - how you installed Python; > - how you installed numpy; > - your operating system; > - whether or not you have multiple versions of Python installed; > - if you built from source, your compiler versions and ideally a build log; > ; > Note: this error has many possible causes, so please don't comment on; > an existing issue about this - open a new one instead.; > ; > Original error was: PyCapsule_Import could not import module ""datetime""; > ; > Traceback (most recent call last):; > File ""/usr/lib/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/274#issuecomment-598179709:1250,simpl,simply,1250,,https://github.com/google/deepvariant/issues/274#issuecomment-598179709,1,['simpl'],['simply']
Usability,"elow cpu info:. cat /proc/cpuinfo; processor	: 0; vendor_id	: GenuineIntel; cpu family	: 6; model		: 85; model name	: Intel(R) Xeon(R) Silver 4116 CPU @ 2.10GHz; stepping	: 4; microcode	: 0x200004d; cpu MHz		: 2095.078; cache size	: 16896 KB; physical id	: 0; siblings	: 1; core id		: 0; cpu cores	: 1; apicid		: 0; initial apicid	: 0; fpu		: yes; fpu_exception	: yes; cpuid level	: 13; wp		: yes; flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl tsc_reliable nonstop_tsc eagerfpu pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx hypervisor lahf_lm 3dnowprefetch arat; bogomips	: 4190.15; clflush size	: 64; cache_alignment	: 64; address sizes	: 40 bits physical, 48 bits virtual; power management:. What I compared was not only call_variant it was make example step too. To make it clear I enclose a part of the log here, however it uses slightly different setting and different example but it shows what I said in my previous comment.; In this case I did not specify any number of core for the cpu and the result are slightly better than if I specify the cpu cores equal to 8. stdout of the process:; input file S-001701867.markdup.bam; I0622 13:05:17.760246 47710258629632 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir; I0622 13:05:17.867540 47710258629632 run_deepvariant.py:405] Creating a directory for logs in /output/logs; I0622 13:05:17.933148 47710258629632 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****; ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/inp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/463#issuecomment-866226252:1087,clear,clear,1087,,https://github.com/google/deepvariant/issues/463#issuecomment-866226252,1,['clear'],['clear']
Usability,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps!. Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/67#issuecomment-383764665:1425,learn,learn,1425,,https://github.com/google/deepvariant/issues/67#issuecomment-383764665,4,['learn'],"['learn', 'learning']"
Usability,"g the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score; -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --; HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700; HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495; HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688; HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452; HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710; HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina.; 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2.; 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other possible explanations (e.g. that hap.py has trouble in the comparison process correctly annotating sites). Following this current set of metrics, I plan to inspect several of the correctly and incorrectly called variants in IGV with their support and see if I can better understand what factors are making MNPs more difficult to call, and if it seems like there are any specifically addressable issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/520#issuecomment-1558724808:1862,learn,learned,1862,,https://github.com/google/deepvariant/issues/520#issuecomment-1558724808,1,['learn'],['learned']
Usability,"gle/deepvariant/issues/185 . The advice in my comment https://github.com/google/deepvariant/issues/185#issuecomment-494919509 has a code change that you could try out, only if you want to experiment with different warmstarting logic on your own. . What we currently use is what you can find in our r0.10 codebase:; https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/modeling.py#L560. When warmstarting and training with a small(er) amount of data, it's always possible that the curve might look a bit weird at the beginning. Here is a rule of thumb I use: a stable training setup should be mostly reproducible. Meaning, if you run the same training multiple times, the curves should eventually converge to about the same place, and shouldn't behave drastically different. They won't look the exactly same because of randomness in training process. But if half of the runs don't converge, or behave very differently from the other half, then something needs to be improved. You might also have a question on whether you need to warmstart. That is an empirical question. Here is an example from my experience:; For our PacBio training, at this point I actually feel like we have enough data to not have to warmstart from the WGS model. But we're still warmstarting (at least for now) because I find that it converges faster and the resulting accuracy is about the same. We make these decisions based on empirical evidence and our intuition on ML and the data. These decisions can also evolve over time. ( Btw, one thing that we might not have documented - if you want to try with *not* warmstarting from anything, and want to just randomly init, you can set `--start_from_checkpoint=""""`. ). I think your setup above looks reasonable to me. If you want to share more later (like what your training looks like, how long it takes to converge, whether your new model works better on your data, etc), feel free to add more in this issue. I will close it for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/312#issuecomment-638521636:1779,intuit,intuition,1779,,https://github.com/google/deepvariant/issues/312#issuecomment-638521636,1,['intuit'],['intuition']
Usability,"hello @akolesnikov,. I was wondering if you might have some additional guidance towards running deepvariant. I have started running deepvariant successfully in another server, but I would like to be run the process in parallel in multiple servers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/315#issuecomment-640852141:71,guid,guidance,71,,https://github.com/google/deepvariant/issues/315#issuecomment-640852141,1,['guid'],['guidance']
Usability,"iables in the TRAINABLE_VARIABLES collection -- if you need to warm-start non_TRAINABLE vars (such as optimizer accumulators or batch norm statistics), please use the below option.; ```; Because in our code, we use a regular expression like this:; https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/modeling.py#L361. This means that only the variables in the TRAINABLE_VARIABLES get loaded when we warm start.; This explains why warm starting from a checkpoint does not produce the same (or even similar) results as the inference/prediction mode. For example, Batch norms were not being warmstarted. If you do want to load **everything**, one trick we've tried is to change to code into a list:; ```; vars_to_warm_start=['|'.join(vars_to_include)]); ```; which then tricks the code into the model of loading everything (not just TRAINABLE_VARIABLES). But, it doesn't seem very desirable because it also loads things like global_step. The best way is probably to include just BatchNorm and the Trainable variables we want, but it'll require more refactoring here. If try with the small code change above and observe the log -- you'll see that a lot more vars are being used in warm-starting now. (But note that you'll likely want to exclude some variables such as global_step, because those will affect your learning rate). Note that even when warmstarting from an existing checkpoint, we don't currently recommend ""fine-tuning"" with very few steps. Even with our small TPU training case study, we showed an example to train up to 50k steps before we pick a model.; So if you want to use our code to fine tune on your data, please proceed with caution and make sure you carefully benchmark the accuracy and robustness of the resulting model. . Thanks for sharing your findings here. If you have more questions or anything you want to discuss, please feel free to bring up here. (And, adding my teammate @emschorsch who has been looking into warmstarting. )",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/185#issuecomment-494919509:2252,learn,learning,2252,,https://github.com/google/deepvariant/issues/185#issuecomment-494919509,1,['learn'],['learning']
Usability,"isfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2); Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4); Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2); Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0); Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3); Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2); Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7); Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0); Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0); Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2); Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4); Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0); Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3); Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5); Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0); Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7); Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4); Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3); Requirement ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/89#issuecomment-416438760:12932,learn,learn,12932,,https://github.com/google/deepvariant/issues/89#issuecomment-416438760,1,['learn'],['learn']
Usability,"lem, below 100bp, I do not have an intuition as to which approach will perform better. For complex variants, do the extent these are in a size range callable by DeepVariant, DeepVariant will represent the sequence-resolved candidates found for variation. Here is an example from a DeepVariant HG002 WGS VCF):. 1 67310873 . CAAAAAAAAAAAAAAAAAAAGAAAAATTAAA C,CAAAAAAAAAAAAAAAAAAAAAGAAAAATTAAA 45.4 PASS . GT:GQ:DP:AD:VAF:PL 1/2:18:36:2,26,6:0.722222,0.166667:28,4,35,4,0,2. The second ALT allele has insertions of A at multiple places, so that this doesn't cleanly fit into a single contiguous set of inserted or deleted bases. In practice, these complex events will be rare in the size range that DeepVariant is designed to address as a small variant caller. Accidentally (because we did not design or train DeepVariant to do so), DeepVariant will call much larger insertion events in PacBio CCS data. Finally, with respect to your haplotype-aware question. Conceptually the first two steps are quite similar. For the first step, identifying which regions to reassemble, DeepVariant employs a relatively simple model which identifies regions that will benefit from reassembly. The specific implementation differs from GATK (and from the linked description, the GATK logic sounds more complex). Benchmarks reassembling all regions with DeepVariant consistently show the same accuracy to the region selection version. For the second step, conceptually, the methods are very similar. Both construct a de Bruijn graph of reference and alternate contigs. The same authors of these GATK methods are authors of DeepVariant, so apart from writing in C++ for speed, I expect these two to be conceptually similar. For the third step the methods are entirely different. This is where DeepVariant applies a trained convolutional neural network, looking directly at the raw information across the reads, whereas GATK applies a PairHMM to calulate the likelihood of candidate full haplotypes based on their support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/180#issuecomment-488147736:1925,simpl,simple,1925,,https://github.com/google/deepvariant/issues/180#issuecomment-488147736,1,['simpl'],['simple']
Usability,"les with the pattern ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord"". How should I specify the tfrecord_path to get model_train to use the files?. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]; Sent: Thursday, April 5, 2018 6:56 PM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi again,; I didn't read carefully so I missed that you said you want to train a model.; If you want to get make_examples to create more candidates, the other flags you need to consider are: vsc_min_count_snps, vsc_min_count_indels, vsc_min_fraction_snps, vsc_min_fraction_indels. With the default values of these flags for VSC (Very Sensitive Caller), you simply won't be able to even get candidates generated for low allele fraction variants. So I would suggest playing around with those flags and see if more candidates come out. Thanks! Let us know how it goes. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-379110341>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqU5J11c7Zr-VYS_8CjFPh-UF6VIYks5tlq76gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contai",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-380158183:1396,simpl,simply,1396,,https://github.com/google/deepvariant/issues/62#issuecomment-380158183,1,['simpl'],['simply']
Usability,"lieve the ""winner"" designations from the precisionFDA challenge can be a bit misleading (even though, to be fair, they do color similar high percentiles, even though they also award a designation to one group per category). If I was the winner of a precisionFDA challenge, I would probably want to mention that somewhere. However, I don't typically see sections like ""Why DeepVariant"" at the top of most program READMEs. So, along with some observations about [run-time and cost](https://github.com/google/deepvariant/issues/171#issuecomment-483903505), I think it may respectfully be worth considering trimming back some of that information (**while continuing to provide excellent support on the issues section of GitHub!**). **7)** My understanding is that there is not a DeepVariant App on precisionFDA. I think they use AWS, and I may be able to create something unofficial using code similar to [my AWS test](https://github.com/cwarden45/DTC_Scripts/blob/master/Genos_Exome/run_DeepVariant_3steps.sh) (relating to issues #166 and #167). However, perhaps at some point, you could consider offering something that can be more officially (and better) supported by DeepVariant developers? This would be free to the users (since the FDA is covering the costs of using the DNAnexus-based interface), but there are some unique differences (like I had to change the chromosome formatting for my .vcf files, and there was an issue with my [Veritas WGS header](https://www.biostars.org/p/361415/#366669) that I had to fix). I am currently uploading my .fastq files (the .bam alignments are up there and public, but I think the chr format may cause issue with variant calling comparisons). However, all relevant information for these two samples will be publicly available in precisionFDA (from my [charles.warden](https://precision.fda.gov/users/charles.warden) account). You don’t have to re-open the ticket, but I would certainly welcome any feedback / thoughts that you might have. Sincerely,; Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-485283894:8634,feedback,feedback,8634,,https://github.com/google/deepvariant/issues/165#issuecomment-485283894,1,['feedback'],['feedback']
Usability,"low/python/training/saver.py"", line 607, in _get_saver_or_default; saver = Saver(sharded=True, allow_empty=True); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__; self.build(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build; self._build(self._filename, build_save=True, build_restore=True); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build; self.saver_def = self._builder._build_internal( # pylint: disable=protected-access; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal; restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps; self._AddRestoreOps(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps; all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore; return io_ops.restore_v2(filename_tensor, names, slices, dtypes); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper; op = g._create_op_internal(op_type_name, inputs, dtypes=None,; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal; ret = Operation(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__; self._traceback = tf_stack.extract_stack_for_node(self._c_op); ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874:22457,simpl,simple,22457,,https://github.com/google/deepvariant/issues/537#issuecomment-1140056874,1,['simpl'],['simple']
Usability,"me chromosomes? Then finally, once everything is shuffled, run model_train and model_eval. Let me reply to this part first:; ""First step is to run deepvariant make_examples in training mode to create training and validation sets. In the documents, these are individual chromosomes, but in theory these could be whole individuals or multiple individuals, is that correct?"" --> Yes that's correct. ""If for example, I used Chromosome 1 for my training set and Chromosome 2 for my validation set, should those repeated runs be made on different chromosomes, or the same chromosomes?""; If you want Chromosome 1 for your training set, and Chromosome 2 for your validation set, you'll run make_examples twice. One run to generate the training set with chr1, the other run to generate validation set as chr2.; Note that in both runs, you'll run make_examples with the `--mode training` flag. This can be be a bit confusing, but `--mode training` in make_examples just means that we will create examples with truth labels.; And you will need truth labels for your training set and validation set, . > ; > Thank you very much for your time, and if these questions are answered clearly in a doc already, then I apologize and would appreciate being directed there.; > ; > Best, Haley; > . I'll separately look at the dependency issue. I'll plan to repeat what is documented in https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md on a clean machine and see if the dependencies still work. Sometimes when we documented it, things worked, but later on some underlying dependencies might have shifted. This is actually why we packaged our variant calling in Docker to make sure the versions are more consistent. But we haven't done so for our shuffling code in the training tutorial. Anyway, let me plan to walk through https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md myself and see if it still works. I'll document my steps here later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/793#issuecomment-2008095137:2926,clear,clearly,2926,,https://github.com/google/deepvariant/issues/793#issuecomment-2008095137,1,['clear'],['clearly']
Usability,"my question was a simpler one: you can see multiple submissions for some groups, and I was trying to see if I understood all the submissions that used DeepVariant. Since there is only one ""rpoplin"" label (and no other entries from Verily Life Sciences), I'll assume that is the only DeepVariant benchmarks (in contrast to the there being multiple groups using GATK, in pipelines that gave varying results). I am also assuming that no one else was using DeepVariant at that time. However, please correct me if I am wrong. For _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were descri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-476428247:1131,learn,learning,1131,,https://github.com/google/deepvariant/issues/165#issuecomment-476428247,1,['learn'],['learning']
Usability,"ng, it is likely that DeepTrio would call variants on; > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and; > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous; > variant calls in the non-PAR regions of chromosomeX.; > ; > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are; > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference; > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic.; > Since chromosomeX in males is inherited from the mother, we performed calling on; > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to; > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this; > recommends that variant calling should be run with both parents on the autosomal and PAR; > regions using a BED file to restrict location, and additional variant calling should be performed; > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and; > only the father’s provided for the non-PAR regions of chromosomeY.; > ; > This experiment indicates that allowing the model to infer a hemizygous chromosome through; > coverage and explicitly training for hemizygous variants is an opportunity for improvement,; > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,; Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/518#issuecomment-1045294025:3066,feedback,feedback,3066,,https://github.com/google/deepvariant/issues/518#issuecomment-1045294025,1,['feedback'],['feedback']
Usability,"nt please send them our way. There are a few separate issues here; let me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/67#issuecomment-383764665:1238,simpl,simple,1238,,https://github.com/google/deepvariant/issues/67#issuecomment-383764665,1,['simpl'],['simple']
Usability,"o,; > ; > I'm very new to model training and honestly, coding, so thank you for your patience! I'm trying to run my own samples following along with the [advanced training case study](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). I've reached the stage where I need to locally shuffle the training examples using the shuffle_tfrecords_beam.py script.; > ; > I downloaded the latest version of tensorflow (2.15) and was initially getting an error that apache beam was not being recognized, and realized that beam did not install because its latest version (2.54) was incompatible with the current version of numpy (1.26) that was being imported. I uninstalled that new version of numpy in tensorflow and installed an older version that would be compatible (1.24.4), and then was able to install apache beam (2.54). However, now I'm getting even more errors (see below). Do you have any advice on which versions of everything I should make sure to have installed correctly before running the shuffle script? Any guidance is very much appreciated.; > ; > Not so much a question but I want to confirm my understanding of the pipeline from the tutorial, as again I am very new to this. First step is to run deepvariant make_examples in training mode to create training and validation sets. In the documents, these are individual chromosomes, but in theory these could be whole individuals or multiple individuals, is that correct? And then make_examples in training mode should be run multiple times independently for training and validation sets? If for example, I used Chromosome 1 for my training set and Chromosome 2 for my validation set, should those repeated runs be made on different chromosomes, or the same chromosomes? Then finally, once everything is shuffled, run model_train and model_eval. Let me reply to this part first:; ""First step is to run deepvariant make_examples in training mode to create training and validation sets. In the documents,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/793#issuecomment-2008095137:1060,guid,guidance,1060,,https://github.com/google/deepvariant/issues/793#issuecomment-2008095137,1,['guid'],['guidance']
Usability,"oad . This is a good question and the best answer I can give to it is both complicated and not conclusive. TL;DR - for long reads, retraining will (probably) not change things much, but there might be other future opportunities to use T2T truth in training strategies regardless of the reference used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/534#issuecomment-1102014578:972,learn,learned,972,,https://github.com/google/deepvariant/issues/534#issuecomment-1102014578,1,['learn'],['learned']
Usability,"on, and the answers to it are complex. I; > assume for the sake of the question that you have FASTQ data from; > sequencing a single bacterial colony (so this is not a metagenomics; > question).; >; > Let's divide the question between ""can it technically be done"" and ""will; > the answers be scientifically valid""; >; > To the question ""can it technically be done"", the answer is probably yes.; > I am not aware that we have specifically attempted this in bacteria. But if; > you have a FASTA file with a reference for a species and FASTQ reads, you; > should be able to generate variant calls for it.; >; > To the question ""will the answers be scientifically valid"", it is; > important to note calling variants in bacterial genomes is an area of open; > research. Using DeepVariant is reasonable, but I don't think you'll able to; > consider the output of any method (DeepVariant or other) as certain to give; > you fully correct results on this problem right out of the box. You'll want; > to use a few methods (use Freebayes and GATK) and compare between them with; > metrics you can independently validate, then decide what works and doesn't; > for your use case.; >; > One way to do this could be that for a clonal lineage you expect variants; > to all be called as 1/1 for the non-plasmid genome sequence. Ryan Poplin; > used this measure in a similar way to compare DeepVariant and other methods; > on inbred rice strains from the 3000 Rice Genomes Project.; >; > We would be quite interested to receive your feedback on how DeepVariant; > performs in this use case, as this may help us understand the value of; > DeepVariant and improve it for the community.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/114#issuecomment-434889612>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AHCP08xLJBFnbpQzdBn9MXeFKOyacKs9ks5uqjzDgaJpZM4YEtb1>; > .; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/114#issuecomment-435084063:2543,feedback,feedback,2543,,https://github.com/google/deepvariant/issues/114#issuecomment-435084063,1,['feedback'],['feedback']
Usability,"orks.com/genomics/news/false-positives-a-problem-for-snp-chips-345637) - based on low read quality (low MAPQ), or other factors such as over-representation of multi-site aligned reads - where such a call might be labeled `0/1 0/0 0/0`, with IGV supporting more the call of `0/1 0/1 0/0`. Otherwise if the read quality is good, and alignments are unique with proper coverage then it might actually be _de novo_, though the proband (child) calls are the more interesting ones. For this you would need to have more samples to ensure the calls are not false positives, with further IGV inspection and assay validation. If this might be a bit too fun, feel free to skip it, but it's here if you are curious to dive deeper in the possible _de novo_ calls from DeepTrio/GLnexus. Basically the big idea is take it slow and have fun to get the most of out it, as with many moving parts (_programs + parameters_) and varied data you want to be confident in the calls - which can take a lot of finesse. With super-clean data, that's not such a big deal - but that's not why we use these tools :). Hope it helps,; Paul. #### References. [1] [RTG Tools Manual](https://github.com/RealTimeGenomics/rtg-tools/blob/master/installer/resources/tools/RTGOperationsManual.pdf); [2] [dv-trio: a family-based variant calling pipeline using DeepVariant](https://academic.oup.com/bioinformatics/article/36/11/3549/5823297?login=false); [3] [FamSeq: A Variant Calling Program for Family-Based Sequencing Data Using Graphics Processing Units](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003880); [4] [DeepTrio: Variant Calling in Families Using Deep Learning](https://www.biorxiv.org/content/10.1101/2021.04.05.438434v1); [5] [A unified haplotype-based method for accurate and comprehensive variant calling](https://pubmed.ncbi.nlm.nih.gov/33782612/) _(This is the Octopus paper.)_; [6] [DeNovoGear: de novo indel and point mutation discovery and phasing](https://pubmed.ncbi.nlm.nih.gov/23975140/)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/699#issuecomment-1716447969:5925,Learn,Learning,5925,,https://github.com/google/deepvariant/issues/699#issuecomment-1716447969,1,['Learn'],['Learning']
Usability,"ot), I git clone the source code and try to build it from source according to the suggestions. The problem happened while I running the ./build-prereq.sh. The more detail information:. ```; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; + cd clif; + [[ ! -z 9ec44bde4f7f40de342a1286f84f5b608633a2d7 ]]; + git checkout 9ec44bde4f7f40de342a1286f84f5b608633a2d7; Note: switching to '9ec44bde4f7f40de342a1286f84f5b608633a2d7'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at 9ec44bd Replace C++ `#import <...>` with `#include <...>`; + git init; Reinitialized existing Git repository in /root/clif/.git/; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/737#issuecomment-1818093820:1575,undo,undo,1575,,https://github.com/google/deepvariant/issues/737#issuecomment-1818093820,1,['undo'],['undo']
Usability,"ough there are [more parameters you can select from](https://github.com/google/deepvariant/blob/r1.5/deepvariant/modeling.py#L68-L110):. $`1)`$ Learning rate usually changes as you get closer to optimal accuracy, since you are getting closer to optimal and do not overshoot the local minimal in the hyperplane. If you are starting from an untrained model, you want learn as much as possible with the default value of `0.064`, but the closer you get to optimal you want to minimize it to something like `0.0005`. If let's say learning rate decreases exponentially with accuracy - meaning you want to tweak the model less as you become more accurate - then it would be something like `learning_rate` $= (1-(e^{accuracy-1})^\alpha)/\gamma$, where $\alpha = 5$ and $\gamma=0.1$, resulting in a chart like this:. ![image](https://github.com/google/deepvariant/assets/6555937/059d6a98-7365-4e06-a3df-a32876042733). Then you use that equation (or your own) to update the learning rate with each iteration of model training. $`2)`$ For batch size, you can have a discrete range like this `batch_sizes = [16, 32, 64]` to select from. Then for each iteration, you look at the metrics and select what to tweak, given the model you want to start from. Meaning you run through all the batch sizes, and see which one performs best. Then you use that, and go through different learning rates based on the accuracy of the resulting models. If you have other parameters you want to play with, then you empirically determine how they interact with the tuning of the model for reaching optimal accuracy. What does this mean? This means you have to empirically try a lot of combinations, going through many iterations until you find the optimal model representing your data. Again keep in mind this generally is geared for diploid germline variant calling - which still requires some tuning - but you would need play with the tuning more if it varies a lot given your training and validation data. . Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294:2956,learn,learning,2956,,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294,1,['learn'],['learning']
Usability,"p2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3; -v; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result; google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --reads; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam; --ref; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/hg38_chrM.fa; --report_title MITO60_Stats --sample_name MITO60 --output_vcf; /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result; --model_type ONT_R104. On Wed, Jun 12, 2024 at 12:03 PM Pi-Chuan Chang ***@***.***>; wrote:. > And, just in case the documentation isn't clear:; >; > This part:; >; > sudo docker run \; > -v ""${INPUT_DIR}"":""/input"" \; > -v ""${OUTPUT_DIR}"":""/output"" \; > google/deepvariant:""${BIN_VERSION}"" \; > ...; >; > The variable BIN_VERSION was specified in earlier in the steps:; >; > BIN_VERSION=""1.6.1""; >; > So, in Unix command it's equivalent to:; >; > google/deepvariant:""1.6.1"" \; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/google/deepvariant/issues/829#issuecomment-2162210763>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/BDQL2ZE35INJI4WP7BHRNK3ZG7TVPAVCNFSM6AAAAABJFTFWYKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDCNRSGIYTANZWGM>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/829#issuecomment-2162307749:2685,clear,clear,2685,,https://github.com/google/deepvariant/issues/829#issuecomment-2162307749,1,['clear'],['clear']
Usability,"pichuan-test --zone ""us-west1-b""; ```. Check the Linux version:. ```; $ uname -a; Linux pichuan-test.us-west1-b.c.brain-genomics.google.com.internal 5.14.0-362.24.2.el9_3.x86_64 #1 SMP PREEMPT_DYNAMIC Sat Mar 30 14:11:54 EDT 2024 x86_64 x86_64 x86_64 GNU/Linux; ```. And I ran this too:. ```; $ cat /etc/os-release; NAME=""AlmaLinux""; VERSION=""9.3 (Shamrock Pampas Cat)""; ID=""almalinux""; ID_LIKE=""rhel centos fedora""; VERSION_ID=""9.3""; PLATFORM_ID=""platform:el9""; PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)""; ANSI_COLOR=""0;34""; LOGO=""fedora-logo-icon""; CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos""; HOME_URL=""https://almalinux.org/""; DOCUMENTATION_URL=""https://wiki.almalinux.org/""; BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9""; ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3""; REDHAT_SUPPORT_PRODUCT=""AlmaLinux""; REDHAT_SUPPORT_PRODUCT_VERSION=""9.3""; ```. ## Install Singularity. I don't have Singularity on the machine yet, so:. https://docs.sylabs.io/guides/4.1/user-guide/quick_start.html#quick-installation-steps. ```bash; sudo yum update -y && \; sudo yum groupinstall -y 'Development Tools' && \; sudo yum install -y \; openssl-devel \; libuuid-devel \; libseccomp-devel \; wget \; squashfs-tools; ```. ```; sudo yum groupinstall -y 'Development Tools'; # Install RPM packages for dependencies; sudo yum install -y \; autoconf \; automake \; cryptsetup \; fuse3-devel \; git \; glib2-devel \; libseccomp-devel \; libtool \; runc \; squashfs-tools \; wget \; zlib-devel; ```. ```bash; sudo dnf install dnf-plugins-core; sudo dnf copr enable dctrud/squashfs-tools-ng; sudo dnf install squashfs-tools-ng; ```. ```bash; export VERSION=1.21.0 OS=linux ARCH=amd64 && \; wget https://dl.google.com/go/go$VERSION.$OS-$ARCH.tar.gz && \; sudo tar -C /usr/local -xzvf go$VERSION.$OS-$ARCH.tar.gz && \; rm go$VERSION.$OS-$ARCH.tar.gz; ```. ```bash; echo 'export PATH=/usr/local/go/bin:$PATH' >> ~/.bashrc && \; source ~/.bashrc; ```. ```bash; export VERSION=4.1.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/812#issuecomment-2076206716:1429,guid,guides,1429,,https://github.com/google/deepvariant/issues/812#issuecomment-2076206716,1,['guid'],['guides']
Usability,"r _point 2_, I apologize: it is bad form to critique something without having tested it yourself. I sometimes worry that frequent use of deep learning may represent something that is popular (where many applications may not remain in common use in the long-term), but I need to assess each situation individually. So, I am very sorry about my tone in my initial message. Because of this post, I am now using DeepVariant as a way to practice learning some new skills in my free-time (such as using cloud computing options), but that makes it harder for me to provide a timely response. While the practice is something that I would like to gain on my own (I believe that I will lose some intuition about the results if I don't run the analysis myself), you are certainly welcome to work with any of the underlying data that I have uploaded to my [PGP page](https://my.pgp-hms.org/profile/hu832966). For _point 3_, I apologize that I need to take more time to read other papers carefully before citing them. For example, I have pretty much always seen a drop in accuracy for indels versus SNPs. However, if filtering for regions expected to have good concordance, I the loss in indel accuracy wasn't as bad as you might expect from [Figure 4](https://www.nature.com/articles/s41587-019-0054-x/tables/4) in that paper (however, the concordance in off-target regions was noticeably lower). That said, I think comparisons with my own data are in the ballpark of what they were describing in what I quoted above, although I would have expected the indel accuracy to be in-between (perhaps something more like 90-95%). Nevertheless, even though I am trying to learn more about the DeepVariant, I apologize that I should have taken more time to consider my phrasing. For _point 4_, I think I understand your response, but that will probably be more clear as I do some testing with DeepVariant. Thank you again for your time and detailed response. So, please feel free to close this ticket. Sincerely,; Charles",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/165#issuecomment-476428247:2342,learn,learn,2342,,https://github.com/google/deepvariant/issues/165#issuecomment-476428247,2,"['clear', 'learn']","['clear', 'learn']"
Usability,"ransversion)`, or `if Tv = 0` then it will be reported as a string formatted as `'variant_counts(is_transition) / 0'`. $`2)`$ The genotype is calculated as follows. Reads are collected, and sometimes realigned based on the model selected. Call sites are determined by an allele counter that goes through every position of aligned reads. For every viable call site it will generate a set of matrices based on your sets of aligned reads in that region - for some models it will perform local realignment. These matrices will limit themselves to a maximum of 95 reads (as it will downsample the reads if there are too many), with the first 5 rows representing the reference. This will then go through the model, and it generate three genotype probabilities: homozygous ref, het, and homozygous alt. Based on the maximum genotype probability, that will be used to generate the genotype (as the most likely). $`3)`$ The PL is generated from the 3 probabilities to generate the -10*log10() of the genotypes and zeroing to the most likely one (i.e. normalized with the highest genotype probability having PL=0). Now given the three steps above let's tie them together. Simplifying to the common factors, those would be: read realignment, read quality, and predicted genotype likelihoods. Read alignment and read quality determine the call site and type (i.e. SNP). Then these (via a matrix representation processed through a model) determine predicted genotype likelihoods, which in turn determine the GQ, PL and GT. TiTv counts depends strongly on how the call site was determined by the alignment of reads, and the [thresholds being set](https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data). The GQ sometimes might be very low, which affects the GT (i.e. `./.`). This happens with every run, and if you are seeing discrepancies there are other factors that can affect it such as local alignment and read generation. Does that help?. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/702#issuecomment-1698583196:1600,Simpl,Simplifying,1600,,https://github.com/google/deepvariant/issues/702#issuecomment-1698583196,1,['Simpl'],['Simplifying']
Usability,"re collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answere",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/534#issuecomment-1102014578:1997,learn,learn,1997,,https://github.com/google/deepvariant/issues/534#issuecomment-1102014578,1,['learn'],['learn']
Usability,"rself like in this simple example - though there are [more parameters you can select from](https://github.com/google/deepvariant/blob/r1.5/deepvariant/modeling.py#L68-L110):. $`1)`$ Learning rate usually changes as you get closer to optimal accuracy, since you are getting closer to optimal and do not overshoot the local minimal in the hyperplane. If you are starting from an untrained model, you want learn as much as possible with the default value of `0.064`, but the closer you get to optimal you want to minimize it to something like `0.0005`. If let's say learning rate decreases exponentially with accuracy - meaning you want to tweak the model less as you become more accurate - then it would be something like `learning_rate` $= (1-(e^{accuracy-1})^\alpha)/\gamma$, where $\alpha = 5$ and $\gamma=0.1$, resulting in a chart like this:. ![image](https://github.com/google/deepvariant/assets/6555937/059d6a98-7365-4e06-a3df-a32876042733). Then you use that equation (or your own) to update the learning rate with each iteration of model training. $`2)`$ For batch size, you can have a discrete range like this `batch_sizes = [16, 32, 64]` to select from. Then for each iteration, you look at the metrics and select what to tweak, given the model you want to start from. Meaning you run through all the batch sizes, and see which one performs best. Then you use that, and go through different learning rates based on the accuracy of the resulting models. If you have other parameters you want to play with, then you empirically determine how they interact with the tuning of the model for reaching optimal accuracy. What does this mean? This means you have to empirically try a lot of combinations, going through many iterations until you find the optimal model representing your data. Again keep in mind this generally is geared for diploid germline variant calling - which still requires some tuning - but you would need play with the tuning more if it varies a lot given your training and v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294:2558,learn,learning,2558,,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294,1,['learn'],['learning']
Usability,"s one thing I'd like you to double check. If you're converting from the 1.6.0 version, I don't think you should see `1.6.0rc2` in your .sif filename. Which is why I asked what command you used to that get that .sif file. You might be pulling a previous, unofficial Docker file. If so, please remake your .sif file with `1.6.0`. ). Because @alanlamsiu used the .sif file, I'll also do something similar:; So, then I ran:. ```bash; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_deeptrio-1.6.0-gpu.sif \; /opt/deepvariant/bin/deeptrio/run_deeptrio; ```. The command above gave me:; ```. ==========; == CUDA ==; ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License.; By pulling and using the container, you accept the terms and conditions of this license:; https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2023-12-05 07:43:20.303963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-12-05 07:43:24.030774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-12-05 07:43:24.033082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with Ten",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389:2830,learn,learning-container-license,2830,,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389,1,['learn'],['learning-container-license']
Usability,"stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832:1686,learn,learning,1686,,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832,1,['learn'],['learning']
Usability,"suecomment-494919509):. ![image](https://github.com/google/deepvariant/assets/6555937/bf862317-f323-47eb-bd69-6fe255e3223e). Thus no training parameters are the same for any model, since the underlying data is not the same and the goals usually are not equal. Therefore the approach for optimizing model is a journey of discovery performed via hyperparameter tuning. For example, Google uses [Vizier](https://github.com/google/vizier), but the idea falls into one of five general camps: . * Manual Tuning; * Random Search; * Grid Search; * Bayesian Optimization; * Tree-structured Parzen estimators . Here is a [link to an article](https://neptune.ai/blog/hyperparameter-tuning-in-python-complete-guide) that provides a nice summary of them - with [another describing them more visually](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/) - and [a link to another nice article](https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8) describing what happens during hyperparameter tuning. There are other ways, but they become niche and sometimes based on the data, private. Usually this training is performed automatically [as shown here](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/), but you can generate the search space yourself like in this simple example - though there are [more parameters you can select from](https://github.com/google/deepvariant/blob/r1.5/deepvariant/modeling.py#L68-L110):. $`1)`$ Learning rate usually changes as you get closer to optimal accuracy, since you are getting closer to optimal and do not overshoot the local minimal in the hyperplane. If you are starting from an untrained model, you want learn as much as possible with the default value of `0.064`, but the closer you get to optimal you want to minimize it to something like `0.0005`. If let's say learning rate decreases exponentially with accuracy - meaning you want to tweak the model less as",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294:1201,learn,learning-,1201,,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294,1,['learn'],['learning-']
Usability,"t might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832:1175,learn,learn,1175,,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832,2,['learn'],"['learn', 'learning']"
Usability,"t(logical=False) or 0 ==> comment; return 20; --------------------------------. vim deepvariant/resources_test.py; --------------------------------; def test_metrics_is_ok_when_cpu_count_returns_none(self):; # Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.; with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):; with resources.ResourceMonitor() as monitor:; #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment; self.assertEqual(monitor.metrics().physical_core_count, 20); --------------------------------. ##########################################################################; # //deepvariant/realigner/allele_count_linear:generate_trained_model_test; # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8; ##########################################################################; # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python; python -c ""import numpy"" # prequests of TF 1.12.0; python -c ""import scipy"" # prequests of TF 1.12.0; pip install Cython --force-reinstall --no-deos; pip install scikit-learn --force-reinstall --no-deos; # build from source; wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz; tar zxvf 0.20.2.tar.gz; cd scikit-learn-0.20.2; python setup.py bdist_wheel; # verify; python -c ""from sklearn.externals import joblib"". ##########################################################################; # //deepvariant/labeler:haplotype_labeler_test; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; ##########################################################################; # fail due to mock data, open an issue in github; https://github.com/google/deepvariant/issues/154. ##########",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:21574,learn,learn,21574,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,1,['learn'],['learn']
Usability,"t_indels are already small numbers (2), so I changed only the fraction flags from their defaults, 0.12, to 0.01 which the fraction I want. Is that reasonable?. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]; Sent: Thursday, April 5, 2018 6:56 PM; To: google/deepvariant <deepvariant@noreply.github.com>; Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>; Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi again,; I didn't read carefully so I missed that you said you want to train a model.; If you want to get make_examples to create more candidates, the other flags you need to consider are: vsc_min_count_snps, vsc_min_count_indels, vsc_min_fraction_snps, vsc_min_fraction_indels. With the default values of these flags for VSC (Very Sensitive Caller), you simply won't be able to even get candidates generated for low allele fraction variants. So I would suggest playing around with those flags and see if more candidates come out. Thanks! Let us know how it goes. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-379110341>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqU5J11c7Zr-VYS_8CjFPh-UF6VIYks5tlq76gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contai",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/62#issuecomment-379857500:1064,simpl,simply,1064,,https://github.com/google/deepvariant/issues/62#issuecomment-379857500,1,['simpl'],['simply']
Usability,"thanks Pi-Chuan, decided to start building from your image with Ubuntu 20.04 to make sure that works before using the Databricks Runtime with Ubuntu 20.04, and got. 18 0.288 ========== [Tue Aug 10 21:03:43 UTC 2021] Stage 'Install bazel' starting; 18 0.297 ./build-prereq.sh: line 50: bazel: command not found; 18 0.298 ~/bazel /opt/deepvariant; 18 0.298 ./build-prereq.sh: line 56: curl: command not found; ------; executor failed running [/bin/sh -c ./build-prereq.sh]: exit code: 127. Assume there's a simple fix to add bazel and curl in, but I have had no time to test further since then, plan to get back on this next month",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/476#issuecomment-902138384:505,simpl,simple,505,,https://github.com/google/deepvariant/issues/476#issuecomment-902138384,1,['simpl'],['simple']
Usability,"thanks for the great piece of software!; I agree with Jordi and would add that some general guidelines on how to use the numerous INFO fields would be nice, do they live somewhere?; it is a pity to have so many metrics and ignore how to put them to good use",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/531#issuecomment-1081798812:92,guid,guidelines,92,,https://github.com/google/deepvariant/issues/531#issuecomment-1081798812,1,['guid'],['guidelines']
Usability,"the path forwards a lot clearer. Reading between the lines, is (3) the reason we are advised to shuffle the validation data as well, because it combines all the chr20-22 examples into one dataset?. And, I forgot to reply this part - for validation set, running the shuffling step is mainly for combing the examples into one dataset (and create a text file that describe it). Another reason is - if you specify `max_examples` in model_eval, it just might be safer to have the examples already pre-shuffled:; https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/model_eval.py#L118. ---. One more thing to clarify:; Unfortunately I might be using terminology that are a bit confusing in the doc:. In https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md , ; our **training** set are the labeled examples that our classifier actually learns from. ; This is the same as defined in: https://developers.google.com/machine-learning/glossary/#training_set. **Validation** set is the labeled examples that our classifier never directly learns from, but is used to pick a best model checkpoint. ; This is the same as defined in: https://developers.google.com/machine-learning/glossary/#validation_set; When I wrote our training case study, I tried to not use another term ""**tuning** set"", which is the same thing as ""validation set"". But now I read it again, I think I did accidentally use the term ""tuning set"" at least once. I'll update that in a future release.; Just to clarify again: When I use the term ""tuning set"", I'm referring to the same thing as validation set. There is also **test** set, defined here: https://developers.google.com/machine-learning/glossary/#test_set; When doing machine learning, the best practice is to leave the **test** set alone as much as possible, and NOT to make any decisions (on model picking, paramater tuning) on it at all. Which is why we had a validation set held out in the first place.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/312#issuecomment-638566733:1022,learn,learning,1022,,https://github.com/google/deepvariant/issues/312#issuecomment-638566733,5,['learn'],"['learning', 'learns']"
Usability,"tially, as in the following result described [by Pi-Chuan in another post](https://github.com/google/deepvariant/issues/185#issuecomment-494919509):. ![image](https://github.com/google/deepvariant/assets/6555937/bf862317-f323-47eb-bd69-6fe255e3223e). Thus no training parameters are the same for any model, since the underlying data is not the same and the goals usually are not equal. Therefore the approach for optimizing model is a journey of discovery performed via hyperparameter tuning. For example, Google uses [Vizier](https://github.com/google/vizier), but the idea falls into one of five general camps: . * Manual Tuning; * Random Search; * Grid Search; * Bayesian Optimization; * Tree-structured Parzen estimators . Here is a [link to an article](https://neptune.ai/blog/hyperparameter-tuning-in-python-complete-guide) that provides a nice summary of them - with [another describing them more visually](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/) - and [a link to another nice article](https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8) describing what happens during hyperparameter tuning. There are other ways, but they become niche and sometimes based on the data, private. Usually this training is performed automatically [as shown here](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/), but you can generate the search space yourself like in this simple example - though there are [more parameters you can select from](https://github.com/google/deepvariant/blob/r1.5/deepvariant/modeling.py#L68-L110):. $`1)`$ Learning rate usually changes as you get closer to optimal accuracy, since you are getting closer to optimal and do not overshoot the local minimal in the hyperplane. If you are starting from an untrained model, you want learn as much as possible with the default value of `0.064`, but the closer you get to optimal you want to minimize it to something ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294:1030,guid,guide-to-hyperparameters-search-for-deep-learning-models,1030,,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294,1,['guid'],['guide-to-hyperparameters-search-for-deep-learning-models']
Usability,"ut you didn't notice, then the next step will fail.; Common failure modes I've seen before:; - if you were running make_examples, but abort in the middle by ctrl-c. Sometimes not all the make_examples in the background were killed. If you just re-run make_examples without killing all background make_examples first, the output might be corrupted.; - if make_examples failed completely without outputting HG002.examples.tfrecord*.gz at all, it'll also cause a failure. Our hope is that you'll notice this in the errors that make_examples displayed. If you're creating some kind of workflow yourself, you will need to make sure you check the error code of the runs. If make_examples died, you shouldn't proceed with call_variants. After my make_examples run and confirming that I have the output files, I ran call_variants:; ```; ## Run `call_variants`; ( time \; /opt/deepvariant/bin/call_variants \; --outfile ""HG002.cvo.tfrecord.gz"" \; --examples ""HG002.examples.tfrecord@${N_SHARDS}.gz"" \; --checkpoint ""model.ckpt"" \; ) 2>&1 | tee ""call_variants.log"" &; ```; When I run this on the same 64-core, 128GB RAM machine, it usually only uses about 500% CPU (instead of all of the 64 cores). This step took about 2m. I can confirm that I successfully run this step without the errors you saw. However, if I remove the files first by `rm -f HG002.examples.tfrecord*.gz` and then repeat the call_variants command above, I can see the errors you reported above:; ```; ValueError: Cannot find matching files with the pattern ""HG002.examples.tfrecord@64.gz""; ```. So, please make sure you that your make_examples step completed successfully before you proceed. (4) As you noticed so far, creating a workflow can be complicated (and mostly has nothing to do with variant caller itself). If you end up trying out the Cloud runner and has more questions, please feel free to get in touch with @nmousavi and the Cloud team. I'm sure the team will love to get your feedback if you decide to try it out. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/151#issuecomment-461411282:5734,feedback,feedback,5734,,https://github.com/google/deepvariant/issues/151#issuecomment-461411282,1,['feedback'],['feedback']
Usability,"value=None):; with resources.ResourceMonitor() as monitor:; #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment; self.assertEqual(monitor.metrics().physical_core_count, 20); --------------------------------. ##########################################################################; # //deepvariant/realigner/allele_count_linear:generate_trained_model_test; # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8; ##########################################################################; # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python; python -c ""import numpy"" # prequests of TF 1.12.0; python -c ""import scipy"" # prequests of TF 1.12.0; pip install Cython --force-reinstall --no-deos; pip install scikit-learn --force-reinstall --no-deos; # build from source; wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz; tar zxvf 0.20.2.tar.gz; cd scikit-learn-0.20.2; python setup.py bdist_wheel; # verify; python -c ""from sklearn.externals import joblib"". ##########################################################################; # //deepvariant/labeler:haplotype_labeler_test; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; ##########################################################################; # fail due to mock data, open an issue in github; https://github.com/google/deepvariant/issues/154. ##########################################################################; # //deepvariant:make_examples_test; # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH; # internvaltree v3 has some API changes with v2; ##########################################################################; pip install 'in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/123#issuecomment-469190994:21941,learn,learn-,21941,,https://github.com/google/deepvariant/issues/123#issuecomment-469190994,1,['learn'],['learn-']
Usability,"ve a way to run all of the steps, thank you for this feedback. As a sort of similar test, I had a m3.large instance open, so I tested running the command from my home directory. For some reason, I don't get the same error message when I do this, but I also don't get any output and no output files are created. Nevertheless, this did gives me some ideas of other things that I can try. In general, maybe there are a couple things that I need to explain:. **1)** I am using an EC2 instance launched from ECS: https://aws.amazon.com/ecs/. This means Docker is already installed. When I create an instance through ECS, I don't think I have the option to create a micro instance (but that isn't my biggest problem). I thought I created the instance with an extra 100 GB of storage (just in case something extra was needed on the local hard drive, beyond RAM). But I don't think this should be the issue for this last step. There may be some other issue that I am not understanding, but I could run the 1st two steps this way (although with an admittedly longer run-time than I expected), and **postprocess_variants** is what I can't get to work. I also received a reply about converting the regular docker image to an[ ECR](https://aws.amazon.com/ecr/) image (submitted on 4/2), to run in AWS [Batch](https://aws.amazon.com/batch/). If that ends up being helpful, I will let you know. If they at least resolve that issue, the next ticket that I submitted (on 4/4) was for this exact issue (but I haven't heard any feedback from that yet). **2)** I want to be able to have my files (.bam, .fastq, etc.) accessible between instances. While I think Google created a way to do with with S3 buckets, my understanding was that I was supposed to do this with an EFS file system: https://aws.amazon.com/efs/. So, _/mnt/efs-genome_ is the EFS file system that contains my .fastq and .bam files (and DeepVariant output). I have to mount it whenever I create a new instance, but I don't have to re-upload the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/167#issuecomment-480616982:1589,feedback,feedback,1589,,https://github.com/google/deepvariant/issues/167#issuecomment-480616982,1,['feedback'],['feedback']
Usability,"via hyperparameter tuning. For example, Google uses [Vizier](https://github.com/google/vizier), but the idea falls into one of five general camps: . * Manual Tuning; * Random Search; * Grid Search; * Bayesian Optimization; * Tree-structured Parzen estimators . Here is a [link to an article](https://neptune.ai/blog/hyperparameter-tuning-in-python-complete-guide) that provides a nice summary of them - with [another describing them more visually](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/) - and [a link to another nice article](https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8) describing what happens during hyperparameter tuning. There are other ways, but they become niche and sometimes based on the data, private. Usually this training is performed automatically [as shown here](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/), but you can generate the search space yourself like in this simple example - though there are [more parameters you can select from](https://github.com/google/deepvariant/blob/r1.5/deepvariant/modeling.py#L68-L110):. $`1)`$ Learning rate usually changes as you get closer to optimal accuracy, since you are getting closer to optimal and do not overshoot the local minimal in the hyperplane. If you are starting from an untrained model, you want learn as much as possible with the default value of `0.064`, but the closer you get to optimal you want to minimize it to something like `0.0005`. If let's say learning rate decreases exponentially with accuracy - meaning you want to tweak the model less as you become more accurate - then it would be something like `learning_rate` $= (1-(e^{accuracy-1})^\alpha)/\gamma$, where $\alpha = 5$ and $\gamma=0.1$, resulting in a chart like this:. ![image](https://github.com/google/deepvariant/assets/6555937/059d6a98-7365-4e06-a3df-a32876042733). Then you use that equation (or your own) to update the",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294:1455,guid,guide-to-hyperparameters-search-for-deep-learning-models,1455,,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294,2,"['guid', 'simpl']","['guide-to-hyperparameters-search-for-deep-learning-models', 'simple']"
Usability,"what happens during hyperparameter tuning. There are other ways, but they become niche and sometimes based on the data, private. Usually this training is performed automatically [as shown here](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/), but you can generate the search space yourself like in this simple example - though there are [more parameters you can select from](https://github.com/google/deepvariant/blob/r1.5/deepvariant/modeling.py#L68-L110):. $`1)`$ Learning rate usually changes as you get closer to optimal accuracy, since you are getting closer to optimal and do not overshoot the local minimal in the hyperplane. If you are starting from an untrained model, you want learn as much as possible with the default value of `0.064`, but the closer you get to optimal you want to minimize it to something like `0.0005`. If let's say learning rate decreases exponentially with accuracy - meaning you want to tweak the model less as you become more accurate - then it would be something like `learning_rate` $= (1-(e^{accuracy-1})^\alpha)/\gamma$, where $\alpha = 5$ and $\gamma=0.1$, resulting in a chart like this:. ![image](https://github.com/google/deepvariant/assets/6555937/059d6a98-7365-4e06-a3df-a32876042733). Then you use that equation (or your own) to update the learning rate with each iteration of model training. $`2)`$ For batch size, you can have a discrete range like this `batch_sizes = [16, 32, 64]` to select from. Then for each iteration, you look at the metrics and select what to tweak, given the model you want to start from. Meaning you run through all the batch sizes, and see which one performs best. Then you use that, and go through different learning rates based on the accuracy of the resulting models. If you have other parameters you want to play with, then you empirically determine how they interact with the tuning of the model for reaching optimal accuracy. What does this mean? This means you have to empirically ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294:2119,learn,learning,2119,,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294,1,['learn'],['learning']
Usability,"with [another describing them more visually](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/) - and [a link to another nice article](https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8) describing what happens during hyperparameter tuning. There are other ways, but they become niche and sometimes based on the data, private. Usually this training is performed automatically [as shown here](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/), but you can generate the search space yourself like in this simple example - though there are [more parameters you can select from](https://github.com/google/deepvariant/blob/r1.5/deepvariant/modeling.py#L68-L110):. $`1)`$ Learning rate usually changes as you get closer to optimal accuracy, since you are getting closer to optimal and do not overshoot the local minimal in the hyperplane. If you are starting from an untrained model, you want learn as much as possible with the default value of `0.064`, but the closer you get to optimal you want to minimize it to something like `0.0005`. If let's say learning rate decreases exponentially with accuracy - meaning you want to tweak the model less as you become more accurate - then it would be something like `learning_rate` $= (1-(e^{accuracy-1})^\alpha)/\gamma$, where $\alpha = 5$ and $\gamma=0.1$, resulting in a chart like this:. ![image](https://github.com/google/deepvariant/assets/6555937/059d6a98-7365-4e06-a3df-a32876042733). Then you use that equation (or your own) to update the learning rate with each iteration of model training. $`2)`$ For batch size, you can have a discrete range like this `batch_sizes = [16, 32, 64]` to select from. Then for each iteration, you look at the metrics and select what to tweak, given the model you want to start from. Meaning you run through all the batch sizes, and see which one performs best. Then you use that, and go through different lea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294:1959,learn,learn,1959,,https://github.com/google/deepvariant/issues/706#issuecomment-1720360294,1,['learn'],['learn']
Usability,"y use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832:2199,simpl,simple,2199,,https://github.com/google/deepvariant/issues/682#issuecomment-1650719832,1,['simpl'],['simple']
Usability,"you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven?. The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/682#issuecomment-1659358917:1333,simpl,simpler,1333,,https://github.com/google/deepvariant/issues/682#issuecomment-1659358917,1,['simpl'],['simpler']
Usability,"ze:. ```bash; pichuan@pichuan-gpu:~$ ls -lh deepvariant_deeptrio-1.6.0-gpu.sif ; -rwxrwxr-x 1 pichuan pichuan 12G Dec 5 07:38 deepvariant_deeptrio-1.6.0-gpu.sif; ```. ( @alanlamsiu , This is one thing I'd like you to double check. If you're converting from the 1.6.0 version, I don't think you should see `1.6.0rc2` in your .sif filename. Which is why I asked what command you used to that get that .sif file. You might be pulling a previous, unofficial Docker file. If so, please remake your .sif file with `1.6.0`. ). Because @alanlamsiu used the .sif file, I'll also do something similar:; So, then I ran:. ```bash; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_deeptrio-1.6.0-gpu.sif \; /opt/deepvariant/bin/deeptrio/run_deeptrio; ```. The command above gave me:; ```. ==========; == CUDA ==; ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License.; By pulling and using the container, you accept the terms and conditions of this license:; https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2023-12-05 07:43:20.303963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-12-05 07:43:24.030774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389:2666,Learn,Learning,2666,,https://github.com/google/deepvariant/issues/745#issuecomment-1840177389,1,['Learn'],['Learning']
